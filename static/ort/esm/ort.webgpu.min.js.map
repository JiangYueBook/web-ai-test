{
  "version": 3,
  "sources": ["../../../common/lib/backend-impl.ts", "../../../common/lib/backend.ts", "../../../common/lib/version.ts", "../../../common/lib/env-impl.ts", "../../../common/lib/env.ts", "../../../common/lib/tensor-conversion-impl.ts", "../../../common/lib/tensor-factory-impl.ts", "../../../common/lib/tensor-impl-type-mapping.ts", "../../../common/lib/tensor-utils-impl.ts", "../../../common/lib/tensor-impl.ts", "../../../common/lib/tensor.ts", "../../../common/lib/trace.ts", "../../../common/lib/inference-session-impl.ts", "../../../common/lib/inference-session.ts", "../../../common/lib/onnx-value.ts", "../../../common/lib/training-session-impl.ts", "../../../common/lib/training-session.ts", "../../../common/lib/index.ts", "nodejs-ignore:fs", "nodejs-ignore:path", "../../lib/wasm/binding/ort-wasm-simd.jsep.js", "nodejs-ignore:worker_threads", "nodejs-ignore:perf_hooks", "nodejs-ignore:os", "../../lib/wasm/binding/ort-wasm-simd-threaded.jsep.js", "../../lib/wasm/binding/ort-wasm-threaded.worker.js", "../../lib/wasm/wasm-factory.ts", "../../lib/wasm/wasm-utils.ts", "../../lib/wasm/run-options.ts", "../../lib/wasm/session-options.ts", "../../lib/wasm/wasm-common.ts", "../../lib/wasm/jsep/log.ts", "../../lib/wasm/jsep/tensor-view.ts", "../../lib/wasm/jsep/webgpu/types.ts", "../../lib/wasm/jsep/webgpu/gpu-data-manager.ts", "../../lib/wasm/jsep/webgpu/attribute-with-cache-key.ts", "../../lib/wasm/jsep/util.ts", "../../lib/wasm/jsep/webgpu/ops/common.ts", "../../lib/wasm/jsep/webgpu/ops/transpose.ts", "../../lib/wasm/jsep/webgpu/ops/reduce-shared.ts", "../../lib/wasm/jsep/webgpu/ops/reduce.ts", "../../lib/wasm/jsep/webgpu/ops/argminmax.ts", "../../lib/wasm/jsep/webgpu/ops/attention.ts", "../../lib/wasm/jsep/webgpu/ops/batch-norm.ts", "../../lib/wasm/jsep/webgpu/ops/bias-add.ts", "../../lib/wasm/jsep/webgpu/ops/unary-op.ts", "../../lib/wasm/jsep/webgpu/ops/bias-split-gelu.ts", "../../lib/wasm/jsep/webgpu/ops/binary-op.ts", "../../lib/wasm/jsep/webgpu/ops/concat.ts", "../../lib/wasm/jsep/webgpu/ops/fuse-utils.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/activation_util.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_util.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/matmul_packed_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv2d_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-grouped.ts", "../../lib/wasm/jsep/webgpu/ops/matmul.ts", "../../lib/wasm/jsep/webgpu/ops/conv.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-transpose.ts", "../../lib/wasm/jsep/webgpu/ops/cumsum.ts", "../../lib/wasm/jsep/webgpu/ops/einsum.ts", "../../lib/wasm/jsep/webgpu/ops/expand.ts", "../../lib/wasm/jsep/webgpu/ops/gather.ts", "../../lib/wasm/jsep/webgpu/ops/gather-elements.ts", "../../lib/wasm/jsep/webgpu/ops/gemm.ts", "../../lib/wasm/jsep/webgpu/ops/instance-norm.ts", "../../lib/wasm/jsep/webgpu/ops/layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/multi-head-attentiion.ts", "../../lib/wasm/jsep/webgpu/ops/pad.ts", "../../lib/wasm/jsep/webgpu/ops/pool.ts", "../../lib/wasm/jsep/webgpu/ops/range.ts", "../../lib/wasm/jsep/webgpu/ops/resize.ts", "../../lib/wasm/jsep/webgpu/ops/skip-layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/slice.ts", "../../lib/wasm/jsep/webgpu/ops/softmax.ts", "../../lib/wasm/jsep/webgpu/ops/split.ts", "../../lib/wasm/jsep/webgpu/ops/tile.ts", "../../lib/wasm/jsep/webgpu/ops/where.ts", "../../lib/wasm/jsep/webgpu/op-resolve-rules.ts", "../../lib/wasm/jsep/webgpu/program-manager.ts", "../../lib/wasm/jsep/backend-webgpu.ts", "../../lib/wasm/jsep/init.ts", "../../lib/wasm/wasm-core-impl.ts", "proxy-worker:./proxy-worker/main", "../../lib/wasm/proxy-wrapper.ts", "../../lib/wasm/session-handler-inference.ts", "../../lib/backend-wasm.ts", "../../lib/backend-wasm-inference.ts", "../../lib/index.ts", "../../lib/version.ts"],
  "sourcesContent": ["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Backend} from './backend.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, {backend, priority});\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @ignore\n */\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n  const errors = [];\n  for (const backendName of backendNames) {\n    const backendInfo = backends.get(backendName);\n    if (backendInfo) {\n      if (backendInfo.initialized) {\n        return backendInfo.backend;\n      } else if (backendInfo.aborted) {\n        continue;  // current backend is unavailable; try next\n      }\n\n      const isInitializing = !!backendInfo.initPromise;\n      try {\n        if (!isInitializing) {\n          backendInfo.initPromise = backendInfo.backend.init(backendName);\n        }\n        await backendInfo.initPromise;\n        backendInfo.initialized = true;\n        return backendInfo.backend;\n      } catch (e) {\n        if (!isInitializing) {\n          errors.push({name: backendName, err: e});\n        }\n        backendInfo.aborted = true;\n      } finally {\n        delete backendInfo.initPromise;\n      }\n    }\n  }\n\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {TrainingSession} from './training-session.js';\n\n/**\n * @ignore\n */\nexport declare namespace SessionHandler {\n  type FeedsType = {[name: string]: OnnxValue};\n  type FetchesType = {[name: string]: OnnxValue | null};\n  type ReturnType = {[name: string]: OnnxValue};\n}\n\n/**\n * Represents shared SessionHandler functionality\n *\n * @ignore\n */\ninterface SessionHandler {\n  dispose(): Promise<void>;\n\n  readonly inputNames: readonly string[];\n  readonly outputNames: readonly string[];\n}\n\n/**\n * Represent a handler instance of an inference session.\n *\n * @ignore\n */\nexport interface InferenceSessionHandler extends SessionHandler {\n  startProfiling(): void;\n  endProfiling(): void;\n\n  run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n}\n\n/**\n * Represent a handler instance of a training inference session.\n *\n * @ignore\n */\nexport interface TrainingSessionHandler extends SessionHandler {\n  readonly evalInputNames: readonly string[];\n  readonly evalOutputNames: readonly string[];\n\n  lazyResetGrad(): Promise<void>;\n  runTrainStep(\n      feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n  runOptimizerStep(options: InferenceSession.RunOptions): Promise<void>;\n  runEvalStep(\n      feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n\n  getParametersSize(trainableOnly: boolean): Promise<number>;\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n  getContiguousParameters(trainableOnly: boolean): Promise<OnnxValue>;\n}\n\n/**\n * Represent a backend that provides implementation of model inferencing.\n *\n * @ignore\n */\nexport interface Backend {\n  /**\n   * Initialize the backend asynchronously. Should throw when failed.\n   */\n  init(backendName: string): Promise<void>;\n\n  createInferenceSessionHandler(uriOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n\n  createTrainingSessionHandler?\n      (checkpointStateUriOrBuffer: TrainingSession.URIorBuffer, trainModelUriOrBuffer: TrainingSession.URIorBuffer,\n       evalModelUriOrBuffer: TrainingSession.URIorBuffer, optimizerModelUriOrBuffer: TrainingSession.URIorBuffer,\n       options: InferenceSession.SessionOptions): Promise<TrainingSessionHandler>;\n}\n\nexport {registerBackend} from './backend-impl.js';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from './env.js';\nimport {version} from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: {common: version},\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', {enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env as envImpl} from './env-impl.js';\n\nexport declare namespace Env {\n  export type WasmPrefixOrFilePaths = string|{\n    /* eslint-disable @typescript-eslint/naming-convention */\n    'ort-wasm.wasm'?: string;\n    'ort-wasm-threaded.wasm'?: string;\n    'ort-wasm-simd.wasm'?: string;\n    'ort-training-wasm-simd.wasm'?: string;\n    'ort-wasm-simd-threaded.wasm'?: string;\n    /* eslint-enable @typescript-eslint/naming-convention */\n  };\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean;\n\n    /**\n     * set or get a boolean value indicating whether to enable trace.\n     *\n     * @defaultValue `false`\n     */\n    trace?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\n     * an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl'|'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly'|'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuProfilingDataV1TensorMetadata {\n    dims: readonly number[];\n    dataType: string;\n  }\n  export interface WebGpuProfilingDataV1 {\n    version: 1;\n    inputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\n    outputsMetadata: readonly WebGpuProfilingDataV1TensorMetadata[];\n    kernelId: number;\n    kernelType: string;\n    kernelName: string;\n    startTime: number;\n    endTime: number;\n  }\n\n  export type WebGpuProfilingData = WebGpuProfilingDataV1;\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     *\n     * @deprecated Use `env.webgpu.profiling.mode` instead. If `env.webgpu.profiling.mode` is set, this property will be\n     * ignored.\n     */\n    profilingMode?: 'off'|'default';\n    /**\n     * Set or get the profiling configuration.\n     */\n    profiling?: {\n      /**\n       * Set or get the profiling mode.\n       *\n       * @defaultValue `'off'`\n       */\n      mode?: 'off'|'default';\n\n      /**\n       * Set or get a callback function when a profiling data is received. If not set, the profiling data will be\n       * printed to console.\n       */\n      ondata?: (data: WebGpuProfilingData) => void;\n    };\n    /**\n     * Get the device for WebGPU.\n     *\n     * When use with TypeScript, the type of this property is `GPUDevice` defined in \"@webgpu/types\".\n     * Use `const device = env.webgpu.device as GPUDevice;` in TypeScript to access this property with correct type.\n     *\n     * see comments on {@link GpuBufferType} for more details about why not use types defined in \"@webgpu/types\".\n     */\n    readonly device: unknown;\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {Tensor} from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = document.createElement('canvas');\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d');\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n        const A = aTensorPointer === -1 ?\n            255 :\n            ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    return canvas.toDataURL();\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext = document.createElement('canvas').getContext('2d');\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (options.format !== undefined && (channels === 4 && options.format !== 'RGBA') ||\n          (channels === 3 && (options.format !== 'RGB' && options.format !== 'BGR'))) {\n        throw new Error('Tensor format doesn\\'t match input tensor dims');\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (let i = 0; i < height * width;\n         rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n      image.data[aImagePointer] = aTensorPointer === -1 ?\n          255 :\n          ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n    }\n\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OptionsDimensions, OptionsFormat, OptionsNormalizationParameters, OptionsTensorFormat, OptionsTensorLayout, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\ninterface BufferToTensorOptions extends OptionsDimensions, OptionsTensorLayout, OptionsNormalizationParameters,\n                                        OptionsFormat, OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray|undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const {height, width} = options;\n\n  const norm = options.norm ?? {mean: 255, bias: 0};\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof (norm.mean) === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof (norm.bias) === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n      options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n  let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (let i = 0; i < stride;\n       i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor = outputformat === 'RGBA' ? new Tensor('float32', float32Data, [1, 4, height, width]) :\n                                                 new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async(\n    image: ImageData|HTMLImageElement|ImageBitmap|string,\n    options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n    TensorFromUrlOptions): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof (HTMLImageElement) !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof (ImageData) !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray|undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = document.createElement('canvas');\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = tempCanvas.getContext('2d');\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = document.createElement('canvas');\n      const context = canvas.getContext('2d');\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n    texture: TensorInterface.TextureType, options: TensorFromTextureOptions<T>): Tensor => {\n  const {width, height, download, dispose} = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({location: 'texture', type: 'float32', texture, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorInterface.GpuBufferType, options: TensorFromGpuBufferOptions<T>): Tensor => {\n  const {dataType, dims, download, dispose} = options;\n  return new Tensor({location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor =>\n    new Tensor({location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\nexport type SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['float16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt polyfill\n// if available.\nlet isBigIntChecked = false;\nexport const checkBigInt = () => {\n  if (!isBigIntChecked) {\n    isBigIntChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\n    const isBigUint64ArrayAvailable =\n        typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TextureConstructorParameters} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorToDataURL, tensorToImageData} from './tensor-conversion-impl.js';\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {tensorFromGpuBuffer, tensorFromImage, tensorFromPinnedBuffer, tensorFromTexture} from './tensor-factory-impl.js';\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions, TextureConstructorParameters} from './tensor-factory.js';\nimport {checkBigInt, NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP, NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, SupportedTypedArray, SupportedTypedArrayConstructors} from './tensor-impl-type-mapping.js';\nimport {calculateSize, tensorReshape} from './tensor-utils-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n      type: TensorType, data: TensorDataType|readonly string[]|readonly number[]|readonly boolean[],\n      dims?: readonly number[]);\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(data: TensorDataType|readonly string[]|readonly boolean[], dims?: readonly number[]);\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n      arg0: TensorType|TensorDataType|readonly string[]|readonly boolean[]|CpuPinnedConstructorParameters|\n      TextureConstructorParameters|GpuBufferConstructorParameters,\n      arg1?: TensorDataType|readonly number[]|readonly string[]|readonly boolean[], arg2?: readonly number[]) {\n    // perform one-time check for BigInt support\n    checkBigInt();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if ((type !== 'float32' && type !== 'float16' && type !== 'int32' && type !== 'int64' && type !== 'uint32' &&\n               type !== 'bool')) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1|typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError('A string tensor\\'s data must be a string array.');\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if (arg0 === 'float16') {\n              // Throw error here because when user try to use number array as data,\n              // e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              // Uint16Array.from(arg1) which generates wrong data.\n              throw new TypeError(\n                  'Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.');\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else {\n          // get tensor type from TypedArray\n          const mappedType =\n              NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError('A tensor\\'s dims must be a number array');\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n      image: ImageData|HTMLImageElement|ImageBitmap|string,\n      options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n      TensorFromUrlOptions): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n      texture: TensorTextureType, options: TensorFromTextureOptions<T>): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n      gpuBuffer: TensorGpuBufferType, options: TensorFromGpuBufferOptions<T>): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n      type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n          'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.');\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorFactory} from './tensor-factory.js';\nimport {Tensor as TensorImpl} from './tensor-impl.js';\nimport {TypedTensorUtils} from './tensor-utils.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  /**\n   * type alias for WebGPU buffer\n   *\n   * The reason why we don't use type \"GPUBuffer\" defined in webgpu.d.ts from @webgpu/types is because \"@webgpu/types\"\n   * requires \"@types/dom-webcodecs\" as peer dependency when using TypeScript < v5.1 and its version need to be chosen\n   * carefully according to the TypeScript version being used. This means so far there is not a way to keep every\n   * TypeScript version happy. It turns out that we will easily broke users on some TypeScript version.\n   *\n   * for more info see https://github.com/gpuweb/types/issues/127\n   */\n  export type GpuBufferType = {size: number; mapState: 'unmapped' | 'pending' | 'mapped'};\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32'|'float16'|'int32'|'int64'|'uint32'|'bool';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none'|'cpu'|'cpu-pinned'|'texture'|'gpu-buffer';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\n      dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends 'uint64'|'int64'>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly bigint[]|readonly number[],\n      dims?: readonly number[]): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'|'uint64'|'int64'>>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly string[]|readonly bigint[]|readonly boolean[],\n      dims?: readonly number[]): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as (TensorConstructor & TensorFactory);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from './env-impl.js';\n\nexport const TRACE = (deviceType: string, label: string) => {\n  if (!env.wasm.trace) {\n    return;\n  }\n  // eslint-disable-next-line no-console\n  console.timeStamp(`${deviceType}::ORT::${label}`);\n};\n\nconst TRACE_FUNC = (msg: string, extraMsg?: string) => {\n  const stack = new Error().stack?.split(/\\r\\n|\\r|\\n/g) || [];\n  let hasTraceFunc = false;\n  for (let i = 0; i < stack.length; i++) {\n    if (hasTraceFunc && !stack[i].includes('TRACE_FUNC')) {\n      let label = `FUNC_${msg}::${stack[i].trim().split(' ')[1]}`;\n      if (extraMsg) {\n        label += `::${extraMsg}`;\n      }\n      TRACE('CPU', label);\n      return;\n    }\n    if (stack[i].includes('TRACE_FUNC')) {\n      hasTraceFunc = true;\n    }\n  }\n};\n\nexport const TRACE_FUNC_BEGIN = (extraMsg?: string) => {\n  if (!env.wasm.trace) {\n    return;\n  }\n  TRACE_FUNC('BEGIN', extraMsg);\n};\n\nexport const TRACE_FUNC_END = (extraMsg?: string) => {\n  if (!env.wasm.trace) {\n    return;\n  }\n  TRACE_FUNC('END', extraMsg);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {InferenceSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSessionInterface} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\nimport {TRACE_FUNC_BEGIN, TRACE_FUNC_END} from './trace.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    TRACE_FUNC_BEGIN();\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    TRACE_FUNC_END();\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\n      Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\n    TRACE_FUNC_BEGIN();\n    // either load from a file or buffer\n    let filePathOrUint8Array: string|Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (\n        arg0 instanceof ArrayBuffer ||\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError('\\'byteLength\\' must be an integer.');\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'byteLength\\' must be a number.');\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n    }\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, options);\n    TRACE_FUNC_END();\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl.js';\nimport {OnnxValue, OnnxValueDataLocation} from './onnx-value.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: {readonly [dimensionName: string]: number};\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential'|'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Wether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation|{readonly [outputName: string]: OnnxValueDataLocation};\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'xnnpack' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    cpu: CpuExecutionProviderOption;\n    coreml: CoreMlExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface CoreMlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    coreMlFlags?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW'|'NHWC';\n  }\n  export interface WebNNExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webnn';\n    deviceType?: 'cpu'|'gpu'|'npu';\n    numThreads?: number;\n    powerPreference?: 'default'|'low-power'|'high-performance';\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    useCPUOnly?: boolean;\n    enableOnSubgraph?: boolean;\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\ntype NonTensorType = never;\n\n/**\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\n *\n * NOTE: currently not support non-tensor\n */\nexport type OnnxValue = Tensor|NonTensorType;\n\n/**\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\n */\nexport type OnnxValueDataLocation = Tensor.DataLocation;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {SessionHandler, TrainingSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\nimport {TrainingSession as TrainingSessionInterface, TrainingSessionCreateOptions} from './training-session.js';\n\ntype SessionOptions = InferenceSession.SessionOptions;\ntype FeedsType = InferenceSession.FeedsType;\ntype FetchesType = InferenceSession.FetchesType;\ntype ReturnType = InferenceSession.ReturnType;\ntype RunOptions = InferenceSession.RunOptions;\n\nconst noBackendErrMsg: string = 'Training backend could not be resolved. ' +\n    'Make sure you\\'re using the correct configuration & WebAssembly files.';\n\nexport class TrainingSession implements TrainingSessionInterface {\n  private constructor(handler: TrainingSessionHandler, hasOptimizerModel: boolean, hasEvalModel: boolean) {\n    this.handler = handler;\n    this.hasOptimizerModel = hasOptimizerModel;\n    this.hasEvalModel = hasEvalModel;\n  }\n  private handler: TrainingSessionHandler;\n  private hasOptimizerModel: boolean;\n  private hasEvalModel: boolean;\n\n  get trainingInputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get trainingOutputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  get evalInputNames(): readonly string[] {\n    if (this.hasEvalModel) {\n      return this.handler.evalInputNames;\n    } else {\n      throw new Error('This training session has no evalModel loaded.');\n    }\n  }\n  get evalOutputNames(): readonly string[] {\n    if (this.hasEvalModel) {\n      return this.handler.evalOutputNames;\n    } else {\n      throw new Error('This training session has no evalModel loaded.');\n    }\n  }\n\n  static async create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: SessionOptions):\n      Promise<TrainingSession> {\n    const evalModel: string|Uint8Array = trainingOptions.evalModel || '';\n    const optimizerModel: string|Uint8Array = trainingOptions.optimizerModel || '';\n    const options: SessionOptions = sessionOptions || {};\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    if (backend.createTrainingSessionHandler) {\n      const handler = await backend.createTrainingSessionHandler(\n          trainingOptions.checkpointState, trainingOptions.trainModel, evalModel, optimizerModel, options);\n      return new TrainingSession(handler, !!trainingOptions.optimizerModel, !!trainingOptions.evalModel);\n    } else {\n      throw new Error(noBackendErrMsg);\n    }\n  }\n\n  /**\n   * Helper function for runTrainStep and future runStep methods that handles the type-narrowing conversion from\n   * the given parameters to SessionHandler.FetchesType and RunOptions.\n   *\n   * @param inputNames the feeds object is checked that they contain all input names in the provided list of input\n   * names.\n   * @param outputNames the fetches object is checked that their keys match up with valid names in the list of output\n   * names.\n   * @param feeds the required input\n   * @param arg1 narrowed & converted into the SessionHandler.FetchesType or RunOptions object\n   * @param arg2 optional RunOptions object.\n   * @returns\n   */\n  typeNarrowingForRunStep(\n      inputNames: readonly string[], outputNames: readonly string[], feeds: FeedsType, arg1?: FetchesType|RunOptions,\n      arg2?: RunOptions): [SessionHandler.FetchesType, RunOptions] {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSession.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    return [fetches, options];\n  }\n\n  /**\n   * Helper method for runTrainStep and any other runStep methods. Takes the ReturnType result from the SessionHandler\n   * and changes it into a map of Tensors.\n   *\n   * @param results\n   * @returns\n   */\n  convertHandlerReturnTypeToMapOfTensors(results: SessionHandler.ReturnType): ReturnType {\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  async lazyResetGrad(): Promise<void> {\n    await this.handler.lazyResetGrad();\n  }\n\n  runTrainStep(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  runTrainStep(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async runTrainStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const [fetches, options] =\n        this.typeNarrowingForRunStep(this.trainingInputNames, this.trainingOutputNames, feeds, arg1, arg2);\n    const results = await this.handler.runTrainStep(feeds, fetches, options);\n    return this.convertHandlerReturnTypeToMapOfTensors(results);\n  }\n\n  async runOptimizerStep(options?: InferenceSession.RunOptions|undefined): Promise<void> {\n    if (this.hasOptimizerModel) {\n      await this.handler.runOptimizerStep(options || {});\n    } else {\n      throw new Error('This TrainingSession has no OptimizerModel loaded.');\n    }\n  }\n\n  runEvalStep(feeds: FeedsType, options?: RunOptions|undefined): Promise<ReturnType>;\n  runEvalStep(feeds: FeedsType, fetches: FetchesType, options?: RunOptions|undefined): Promise<ReturnType>;\n  async runEvalStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    if (this.hasEvalModel) {\n      const [fetches, options] =\n          this.typeNarrowingForRunStep(this.evalInputNames, this.evalOutputNames, feeds, arg1, arg2);\n      const results = await this.handler.runEvalStep(feeds, fetches, options);\n      return this.convertHandlerReturnTypeToMapOfTensors(results);\n    } else {\n      throw new Error('This TrainingSession has no EvalModel loaded.');\n    }\n  }\n\n  async getParametersSize(trainableOnly = true): Promise<number> {\n    return this.handler.getParametersSize(trainableOnly);\n  }\n\n  async loadParametersBuffer(array: Uint8Array, trainableOnly = true): Promise<void> {\n    const paramsSize = await this.getParametersSize(trainableOnly);\n    // checking that the size of the Uint8Array is equivalent to the byte length of a Float32Array of the number\n    // of parameters\n    if (array.length !== 4 * paramsSize) {\n      throw new Error(\n          'Size of the buffer passed into loadParametersBuffer must match the number of parameters in ' +\n          'the model. Please use getParametersSize method to check.');\n    }\n    return this.handler.loadParametersBuffer(array, trainableOnly);\n  }\n\n  async getContiguousParameters(trainableOnly = true): Promise<OnnxValue> {\n    return this.handler.getContiguousParameters(trainableOnly);\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {TrainingSession as TrainingSessionImpl} from './training-session-impl.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace TrainingSession {\n  /**\n   * Either URI file path (string) or Uint8Array containing model or checkpoint information.\n   */\n  type URIorBuffer = string|Uint8Array;\n}\n\n/**\n * Represent a runtime instance of an ONNX training session,\n * which contains a model that can be trained, and, optionally,\n * an eval and optimizer model.\n */\nexport interface TrainingSession {\n  // #region run()\n\n  /**\n   * Lazily resets the gradients of all trainable parameters to zero. Should happen after the invocation of\n   * runOptimizerStep.\n   */\n  lazyResetGrad(): Promise<void>;\n\n  /**\n   * Run TrainStep asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for\n   detail.\n   * @param options - Optional. A set of options that controls the behavior of model training.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  runTrainStep(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions):\n      Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Run a single train step with the given inputs and options.\n   *\n   * @param feeds - Representation of the model input.\n   * @param fetches - Representation of the model output.\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model training.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runTrainStep(\n      feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Runs a single optimizer step, which performs weight updates for the trainable parameters using the optimizer model.\n   *\n   * @param options - Optional. A set of options that controls the behavior of model optimizing.\n   */\n  runOptimizerStep(options?: InferenceSession.RunOptions): Promise<void>;\n\n  /**\n   * Run a single eval step with the given inputs and options using the eval model.\n   *\n   * @param feeds - Representation of the model input.\n   * @param options - Optional. A set of options that controls the behavior of model eval step.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runEvalStep(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions):\n      Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Run a single eval step with the given inputs and options using the eval model.\n   *\n   * @param feeds - Representation of the model input.\n   * @param fetches - Representation of the model output.\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model eval step.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runEvalStep(\n      feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region copy parameters\n\n  /**\n   * Retrieves the size of all parameters for the training state. Calculates the total number of primitive (datatype of\n   * the parameters) elements of all the parameters in the training state.\n   *\n   * @param trainableOnly - When set to true, the size is calculated for trainable params only. Default value is true.\n   */\n  getParametersSize(trainableOnly: boolean): Promise<number>;\n\n  /**\n   * Copies parameter values from the given array to the training state. Currently, only supporting models with\n   * parameters of type Float32.\n   *\n   * @param buffer - Float32 buffer containing parameters converted to a Uint8Array.\n   * @param trainableOnly - True if trainable parameters only to be modified, false otherwise. Default value is true.\n   */\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n\n  /**\n   * Copies the model parameters to a contiguous buffer. Usually used in the context of Federated Learning.\n   * Currently, only supporting models with parameters of type Float32.\n   *\n   * @param trainableOnly - When set to true, only trainable parameters are copied. Trainable parameters are parameters\n   * for which requires_grad is set to true. Default value is true.\n   * @returns A promise that resolves to a Float32 OnnxValue of the requested parameters.\n   */\n  getContiguousParameters(trainableOnly: boolean): Promise<OnnxValue>;\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded training model.\n   */\n  readonly trainingInputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded training model.\n   */\n  readonly trainingOutputNames: readonly string[];\n\n  /**\n   * Get input names of the loaded eval model. Is an empty array if no eval model is loaded.\n   */\n  readonly evalInputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded eval model. Is an empty array if no eval model is loaded.\n   */\n  readonly evalOutputNames: readonly string[];\n\n  // #endregion\n}\n\n/**\n * Represents the optional parameters that can be passed into the TrainingSessionFactory.\n */\nexport interface TrainingSessionCreateOptions {\n  /**\n   * URI or buffer for a .ckpt file that contains the checkpoint for the training model.\n   */\n  checkpointState: TrainingSession.URIorBuffer;\n  /**\n   * URI or buffer for the .onnx training file.\n   */\n  trainModel: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx optimizer model file.\n   */\n  optimizerModel?: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx eval model file.\n   */\n  evalModel?: TrainingSession.URIorBuffer;\n}\n\n/**\n * Defines method overload possibilities for creating a TrainingSession.\n */\nexport interface TrainingSessionFactory {\n  // #region create()\n\n  /**\n   * Creates a new TrainingSession and asynchronously loads any models passed in through trainingOptions\n   *\n   * @param trainingOptions specify models and checkpoints to load into the Training Session\n   * @param sessionOptions specify configuration for training session behavior\n   *\n   * @returns Promise that resolves to a TrainingSession object\n   */\n  create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: InferenceSession.SessionOptions):\n      Promise<TrainingSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const TrainingSession: TrainingSessionFactory = TrainingSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * # ONNX Runtime JavaScript API\n *\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\n *\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\n *\n * See also:\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript.html)\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\n *\n * @packageDocumentation\n */\n\nexport * from './backend.js';\nexport * from './env.js';\nexport * from './inference-session.js';\nexport * from './tensor.js';\nexport * from './trace.js';\nexport * from './onnx-value.js';\nexport * from './training-session.js';\n", "export const readFile = undefined;", "export const join = undefined;", "\nvar ortWasm = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nvar d=moduleArg,aa,k;d.ready=new Promise((a,b)=>{aa=a;k=b});\"use strict\";\nd.jsepInit=(a,b,c,e,f,h,l,r)=>{d.Za=a;d.Oa=b;d.Qa=c;d.Ja=e;d.Pa=f;d.ra=h;d.Ra=l;d.Sa=r;b=(m,p,n)=>(...u)=>{const w=t,g=p?.();u=m(...u);const q=p?.();g!==q&&(m=q,n(g),p=n=null);return t!=w?ba():u};c=m=>async(...p)=>{try{if(d.Da)throw Error(\"Session already started\");const n=d.Da={Ta:p[0],errors:[]},u=await m(...p);if(d.Da!==n)throw Error(\"Session mismatch\");a.flush();const w=n.errors;if(0<w.length){let g=await Promise.all(w);g=g.filter(q=>q);if(0<g.length)throw Error(g.join(\"\\n\"));}return u}finally{d.Da=\nnull}};d._OrtRun=c(b(d._OrtRun,()=>d._OrtRun,m=>d._OrtRun=m));d._OrtRunWithBinding=c(b(d._OrtRunWithBinding,()=>d._OrtRunWithBinding,m=>d._OrtRunWithBinding=m));d._OrtBindInput=b(d._OrtBindInput,()=>d._OrtBindInput,m=>d._OrtBindInput=m);d.jsepRegisterBuffer=(m,p,n,u)=>a.registerBuffer(m,p,n,u);d.jsepUnregisterBuffers=m=>{a.unregisterBuffers(m)};d.jsepGetBuffer=m=>a.getBuffer(m);d.jsepCreateDownloader=(m,p,n)=>a.createDownloader(m,p,n)};\nvar ca=Object.assign({},d),x=\"./this.program\",y=(a,b)=>{throw b;},da=\"object\"==typeof window,z=\"function\"==typeof importScripts,ea=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,A=\"\",B,C,D;\nif(ea){var fs=require(\"fs\"),fa=require(\"path\");A=z?fa.dirname(A)+\"/\":__dirname+\"/\";B=(a,b)=>{a=a.startsWith(\"file://\")?new URL(a):fa.normalize(a);return fs.readFileSync(a,b?void 0:\"utf8\")};D=a=>{a=B(a,!0);a.buffer||(a=new Uint8Array(a));return a};C=(a,b,c,e=!0)=>{a=a.startsWith(\"file://\")?new URL(a):fa.normalize(a);fs.readFile(a,e?void 0:\"utf8\",(f,h)=>{f?c(f):b(e?h.buffer:h)})};!d.thisProgram&&1<process.argv.length&&(x=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);y=(a,b)=>{process.exitCode=\na;throw b;};d.inspect=()=>\"[Emscripten Module object]\"}else if(da||z)z?A=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(A=document.currentScript.src),_scriptDir&&(A=_scriptDir),0!==A.indexOf(\"blob:\")?A=A.substr(0,A.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):A=\"\",B=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},z&&(D=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),\nC=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)};var ha=d.print||console.log.bind(console),E=d.printErr||console.error.bind(console);Object.assign(d,ca);ca=null;d.thisProgram&&(x=d.thisProgram);d.quit&&(y=d.quit);var F;d.wasmBinary&&(F=d.wasmBinary);var noExitRuntime=d.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&H(\"no native wasm support detected\");\nvar I,J,K=!1,L,M,N,O,P,ia,ja;function ka(){var a=I.buffer;d.HEAP8=M=new Int8Array(a);d.HEAP16=new Int16Array(a);d.HEAP32=O=new Int32Array(a);d.HEAPU8=N=new Uint8Array(a);d.HEAPU16=new Uint16Array(a);d.HEAPU32=P=new Uint32Array(a);d.HEAPF32=ia=new Float32Array(a);d.HEAPF64=ja=new Float64Array(a)}var la=[],ma=[],na=[];function oa(){var a=d.preRun.shift();la.unshift(a)}var Q=0,pa=null,R=null;\nfunction H(a){if(d.onAbort)d.onAbort(a);a=\"Aborted(\"+a+\")\";E(a);K=!0;L=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");k(a);throw a;}function qa(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var S;S=\"ort-wasm-simd.wasm\";if(!qa(S)){var ra=S;S=d.locateFile?d.locateFile(ra,A):A+ra}function sa(a){if(a==S&&F)return new Uint8Array(F);if(D)return D(a);throw\"both async and sync fetching of the wasm failed\";}\nfunction ta(a){if(!F&&(da||z)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>sa(a));if(C)return new Promise((b,c)=>{C(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>sa(a))}function ua(a,b,c){return ta(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{E(\"failed to asynchronously prepare wasm: \"+e);H(e)})}\nfunction va(a,b){var c=S;return F||\"function\"!=typeof WebAssembly.instantiateStreaming||qa(c)||c.startsWith(\"file://\")||ea||\"function\"!=typeof fetch?ua(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(f){E(\"wasm streaming compile failed: \"+f);E(\"falling back to ArrayBuffer instantiation\");return ua(c,a,b)}))}\nvar T,wa={923216:a=>{d.ra(\"Abs\",a,void 0)},923267:a=>{d.ra(\"Neg\",a,void 0)},923318:a=>{d.ra(\"Floor\",a,void 0)},923371:a=>{d.ra(\"Ceil\",a,void 0)},923423:a=>{d.ra(\"Reciprocal\",a,void 0)},923481:a=>{d.ra(\"Sqrt\",a,void 0)},923533:a=>{d.ra(\"Exp\",a,void 0)},923584:a=>{d.ra(\"Erf\",a,void 0)},923635:a=>{d.ra(\"Sigmoid\",a,void 0)},923690:a=>{d.ra(\"Log\",a,void 0)},923741:a=>{d.ra(\"Sin\",a,void 0)},923792:a=>{d.ra(\"Cos\",a,void 0)},923843:a=>{d.ra(\"Tan\",a,void 0)},923894:a=>{d.ra(\"Asin\",a,void 0)},923946:a=>{d.ra(\"Acos\",\na,void 0)},923998:a=>{d.ra(\"Atan\",a,void 0)},924050:a=>{d.ra(\"Sinh\",a,void 0)},924102:a=>{d.ra(\"Cosh\",a,void 0)},924154:a=>{d.ra(\"Asinh\",a,void 0)},924207:a=>{d.ra(\"Acosh\",a,void 0)},924260:a=>{d.ra(\"Atanh\",a,void 0)},924313:a=>{d.ra(\"Tanh\",a,void 0)},924365:a=>{d.ra(\"Not\",a,void 0)},924416:(a,b,c)=>{d.ra(\"Clip\",a,{min:b,max:c})},924485:a=>{d.ra(\"Clip\",a,void 0)},924537:(a,b)=>{d.ra(\"Elu\",a,{alpha:b})},924595:a=>{d.ra(\"Relu\",a,void 0)},924647:(a,b)=>{d.ra(\"LeakyRelu\",a,{alpha:b})},924711:(a,b)=>{d.ra(\"ThresholdedRelu\",\na,{alpha:b})},924781:(a,b)=>{d.ra(\"Cast\",a,{to:b})},924839:a=>{d.ra(\"Add\",a,void 0)},924890:a=>{d.ra(\"Sub\",a,void 0)},924941:a=>{d.ra(\"Mul\",a,void 0)},924992:a=>{d.ra(\"Div\",a,void 0)},925043:a=>{d.ra(\"Pow\",a,void 0)},925094:a=>{d.ra(\"Equal\",a,void 0)},925147:a=>{d.ra(\"Greater\",a,void 0)},925202:a=>{d.ra(\"GreaterOrEqual\",a,void 0)},925264:a=>{d.ra(\"Less\",a,void 0)},925316:a=>{d.ra(\"LessOrEqual\",a,void 0)},925375:(a,b,c,e,f)=>{d.ra(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>\n0,f+e>>>0)):[]})},925539:(a,b,c,e,f)=>{d.ra(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},925702:(a,b,c,e,f)=>{d.ra(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},925865:(a,b,c,e,f)=>{d.ra(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},926029:(a,b,c,e,f)=>{d.ra(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>\n0,f+e>>>0)):[]})},926192:(a,b,c,e,f)=>{d.ra(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},926354:(a,b,c,e,f)=>{d.ra(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},926516:(a,b,c,e,f)=>{d.ra(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},926682:(a,b,c,e,f)=>{d.ra(\"ReduceSumSquare\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>\n0,f+e>>>0)):[]})},926851:(a,b,c,e,f)=>{d.ra(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},927020:a=>{d.ra(\"Where\",a,void 0)},927073:(a,b,c)=>{d.ra(\"Transpose\",a,{perm:b?Array.from(O.subarray(c>>>0,c+b>>>0)):[]})},927186:(a,b,c,e,f,h,l,r,m,p,n,u,w,g,q)=>{d.ra(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,l],strides:[r],wIsConst:()=>!!M[p>>>0],outputPadding:n?Array.from(O.subarray(u>>>0,\nu+n>>>0)):[],outputShape:w?Array.from(O.subarray(g>>>0,g+w>>>0)):[],activation:U(q)})},927600:(a,b,c,e,f,h,l,r,m,p,n,u,w,g)=>{d.ra(\"ConvTranspose\",a,{format:r?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(O.subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(O.subarray(f>>>0,f+2>>>0)),pads:Array.from(O.subarray(h>>>0,h+4>>>0)),strides:Array.from(O.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!M[m>>>0],outputPadding:0<p?Array.from(O.subarray(n>>>0,n+p>>>0)):[],outputShape:0<u?Array.from(O.subarray(w>>>\n0,w+u>>>0)):[],activation:U(g)})},928157:(a,b,c,e,f,h,l,r,m,p,n,u,w,g,q)=>{d.ra(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,l],strides:[r],wIsConst:()=>!!M[p>>>0],outputPadding:n?Array.from(O.subarray(u>>>0,u+n>>>0)):[],outputShape:w?Array.from(O.subarray(g>>>0,g+w>>>0)):[],activation:U(q)})},928571:(a,b,c,e,f,h,l,r,m,p,n,u,w,g)=>{d.ra(\"ConvTranspose\",a,{format:r?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(O.subarray(c>>>0,c+2>>>0)),group:e,\nkernelShape:Array.from(O.subarray(f>>>0,f+2>>>0)),pads:Array.from(O.subarray(h>>>0,h+4>>>0)),strides:Array.from(O.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!M[m>>>0],outputPadding:0<p?Array.from(O.subarray(n>>>0,n+p>>>0)):[],outputShape:0<u?Array.from(O.subarray(w>>>0,w+u>>>0)):[],activation:U(g)})},929128:(a,b)=>{d.ra(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},929219:(a,b,c,e,f,h,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"AveragePool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,\ndilations:[h,l],kernel_shape:[r,m],pads:[p,n,u,w],strides:[g,q]})},929503:(a,b)=>{d.ra(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},929594:(a,b,c,e,f,h,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"AveragePool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,l],kernel_shape:[r,m],pads:[p,n,u,w],strides:[g,q]})},929878:(a,b)=>{d.ra(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},929965:(a,b,c,e,f,h,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"MaxPool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,\nceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,l],kernel_shape:[r,m],pads:[p,n,u,w],strides:[g,q]})},930245:(a,b)=>{d.ra(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},930332:(a,b,c,e,f,h,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"MaxPool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,l],kernel_shape:[r,m],pads:[p,n,u,w],strides:[g,q]})},930612:(a,b,c,e,f)=>{d.ra(\"Gemm\",a,{alpha:b,beta:c,transA:e,transB:f})},930716:a=>{d.ra(\"MatMul\",a,void 0)},930770:(a,\nb,c,e)=>{d.ra(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},930878:(a,b,c,e)=>{d.ra(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},930986:(a,b)=>{d.ra(\"Softmax\",a,{axis:b})},931049:(a,b)=>{d.ra(\"Concat\",a,{axis:b})},931109:(a,b,c,e,f)=>{d.ra(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},931254:a=>{d.ra(\"Expand\",a,void 0)},931308:(a,b)=>{d.ra(\"Gather\",a,{axis:Number(b)})},931379:(a,b)=>{d.ra(\"GatherElements\",a,{axis:Number(b)})},931458:(a,\nb,c,e,f,h,l,r,m,p,n)=>{d.ra(\"Resize\",a,{antialias:b,axes:c?Array.from(O.subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:U(f),cubicCoeffA:h,excludeOutside:l,extrapolationValue:r,keepAspectRatioPolicy:U(m),mode:U(p),nearestMode:U(n)})},931809:(a,b,c,e,f,h,l)=>{d.ra(\"Slice\",a,{starts:b?Array.from(O.subarray(c>>>0,c+b>>>0)):[],ends:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[],axes:h?Array.from(O.subarray(l>>>0,l+h>>>0)):[]})},932040:a=>{d.ra(\"Tile\",a,void 0)},932092:(a,b,c)=>{d.ra(\"LayerNormalization\",\na,{axis:Number(b),epsilon:Number(c)})},932199:(a,b,c)=>{d.ra(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},932313:(a,b,c)=>{d.ra(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},932427:a=>{d.ra(\"Range\",a,void 0)},932480:(a,b)=>{d.ra(\"Einsum\",a,{equation:U(b)})},932561:(a,b,c,e,f)=>{d.ra(\"Pad\",a,{mode:b,value:c,pads:e?Array.from(O.subarray(f>>>0,f+e>>>0)):[]})},932693:(a,b,c,e,f,h)=>{d.ra(\"BatchNormalization\",a,{epsilon:b,momentum:c,spatial:!!f,trainingMode:!!e,format:h?\n\"NHWC\":\"NCHW\"})},932862:(a,b,c,e,f,h)=>{d.ra(\"BatchNormalization\",a,{epsilon:b,momentum:c,spatial:!!f,trainingMode:!!e,format:h?\"NHWC\":\"NCHW\"})},933031:(a,b,c)=>{d.ra(\"CumSum\",a,{exclusive:Number(b),reverse:Number(c)})},933128:(a,b,c,e,f,h,l,r,m)=>{d.ra(\"Attention\",a,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:h,qkvHiddenSizes:l?Array.from(O.subarray(Number(r)>>>0,Number(r)+l>>>0)):[],pastPresentShareBuffer:!!m})},933400:a=>{d.ra(\"Gelu\",a,void 0)},933452:(a,b,c,e,f,h)=>{d.ra(\"MultiHeadAttention\",\na,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:h})},933611:a=>{d.ra(\"BiasAdd\",a,void 0)},933666:a=>{d.ra(\"BiasSplitGelu\",a,void 0)},933727:(a,b)=>{d.ra(\"SkipLayerNormalization\",a,{epsilon:b})},933808:(a,b,c,e,f,h,l,r,m,p,n,u,w)=>{d.ra(\"Conv\",a,{format:m?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:h?Array.from(O.subarray(l>>>0,l+h>>>0)):[],strides:[r],w_is_const:()=>!!M[p>>>0],activation:U(n),activation_params:u?Array.from(ia.subarray(w>>>0,w+u>>>0)):[]})},\n934189:(a,b,c,e,f,h,l,r,m,p,n,u,w,g,q,v)=>{d.ra(\"Conv\",a,{format:u?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,l],pads:r?Array.from(O.subarray(m>>>0,m+r>>>0)):[],strides:[p,n],w_is_const:()=>!!M[w>>>0],activation:U(g),activation_params:q?Array.from(ia.subarray(v>>>0,v+q>>>0)):[]})},934591:a=>{d.Ra(a)},934625:(a,b)=>d.Sa(a,b,d.Da.Ta,d.Da.errors),934737:a=>d.Oa(a),934770:a=>d.Qa(a),934802:(a,b,c)=>{d.Ja(a,b,c,!0)},934841:(a,b,c)=>{d.Ja(a,b,c)}};\nfunction xa(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}var ya=a=>{for(;0<a.length;)a.shift()(d)};function za(a){this.Ha=a-24;this.Ma=function(b){P[this.Ha+4>>2>>>0]=b};this.La=function(b){P[this.Ha+8>>2>>>0]=b};this.Ya=function(b,c){this.Ka();this.Ma(b);this.La(c)};this.Ka=function(){P[this.Ha+16>>2>>>0]=0}}\nvar Aa=0,Ba=0,Ca=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Da=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Ca)return Ca.decode(a.subarray(b,c));for(e=\"\";b<c;){var f=a[b++];if(f&128){var h=a[b++]&63;if(192==(f&224))e+=String.fromCharCode((f&31)<<6|h);else{var l=a[b++]&63;f=224==(f&240)?(f&15)<<12|h<<6|l:(f&7)<<18|h<<12|l<<6|a[b++]&63;65536>f?e+=String.fromCharCode(f):(f-=65536,e+=String.fromCharCode(55296|f>>10,56320|f&1023))}}else e+=String.fromCharCode(f)}return e},\nU=(a,b)=>(a>>>=0)?Da(N,a,b):\"\",Ea=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},Fa=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var f=c;e=c+e-1;for(var h=0;h<a.length;++h){var l=a.charCodeAt(h);if(55296<=l&&57343>=l){var r=a.charCodeAt(++h);l=65536+((l&1023)<<10)|r&1023}if(127>=l){if(c>=e)break;b[c++>>>0]=l}else{if(2047>=l){if(c+1>=e)break;b[c++>>>0]=192|l>>6}else{if(65535>=l){if(c+2>=e)break;b[c++>>>0]=224|l>>12}else{if(c+\n3>=e)break;b[c++>>>0]=240|l>>18;b[c++>>>0]=128|l>>12&63}b[c++>>>0]=128|l>>6&63}b[c++>>>0]=128|l&63}}b[c>>>0]=0;return c-f},V=a=>0===a%4&&(0!==a%100||0===a%400),Ga=[0,31,60,91,121,152,182,213,244,274,305,335],Ha=[0,31,59,90,120,151,181,212,243,273,304,334],Ja=a=>{var b=Ea(a)+1,c=Ia(b);c&&Fa(a,N,c,b);return c},Ka=[],La=(a,b)=>{Ka.length=0;var c;for(b>>=2;c=N[a++>>>0];)b+=105!=c&b,Ka.push(105==c?O[b>>>0]:ja[b++>>>1]),++b;return Ka},Na={},Pa=()=>{if(!Oa){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",\nPWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:x||\"./this.program\"},b;for(b in Na)void 0===Na[b]?delete a[b]:a[b]=Na[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Oa=c}return Oa},Oa,Qa=[null,[],[]],Ra=[31,29,31,30,31,30,31,31,30,31,30,31],Sa=[31,28,31,30,31,30,31,31,30,31,30,31];function Ta(a){var b=Array(Ea(a)+1);Fa(a,b,0,b.length);return b}\nfunction Ua(a,b,c,e){function f(g,q,v){for(g=\"number\"==typeof g?g.toString():g||\"\";g.length<q;)g=v[0]+g;return g}function h(g,q){return f(g,q,\"0\")}function l(g,q){function v(Ma){return 0>Ma?-1:0<Ma?1:0}var G;0===(G=v(g.getFullYear()-q.getFullYear()))&&0===(G=v(g.getMonth()-q.getMonth()))&&(G=v(g.getDate()-q.getDate()));return G}function r(g){switch(g.getDay()){case 0:return new Date(g.getFullYear()-1,11,29);case 1:return g;case 2:return new Date(g.getFullYear(),0,3);case 3:return new Date(g.getFullYear(),\n0,2);case 4:return new Date(g.getFullYear(),0,1);case 5:return new Date(g.getFullYear()-1,11,31);case 6:return new Date(g.getFullYear()-1,11,30)}}function m(g){var q=g.Ba;for(g=new Date((new Date(g.Ca+1900,0,1)).getTime());0<q;){var v=g.getMonth(),G=(V(g.getFullYear())?Ra:Sa)[v];if(q>G-g.getDate())q-=G-g.getDate()+1,g.setDate(1),11>v?g.setMonth(v+1):(g.setMonth(0),g.setFullYear(g.getFullYear()+1));else{g.setDate(g.getDate()+q);break}}v=new Date(g.getFullYear()+1,0,4);q=r(new Date(g.getFullYear(),\n0,4));v=r(v);return 0>=l(q,g)?0>=l(v,g)?g.getFullYear()+1:g.getFullYear():g.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var p=O[e+40>>2>>>0];e={Wa:O[e>>2>>>0],Va:O[e+4>>2>>>0],Ea:O[e+8>>2>>>0],Ia:O[e+12>>2>>>0],Fa:O[e+16>>2>>>0],Ca:O[e+20>>2>>>0],wa:O[e+24>>2>>>0],Ba:O[e+28>>2>>>0],$a:O[e+32>>2>>>0],Ua:O[e+36>>2>>>0],Xa:p?U(p):\"\"};c=U(c);p={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\n\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var n in p)c=c.replace(new RegExp(n,\"g\"),p[n]);var u=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),w=\"January February March April May June July August September October November December\".split(\" \");p={\"%a\":g=>u[g.wa].substring(0,3),\"%A\":g=>u[g.wa],\"%b\":g=>w[g.Fa].substring(0,\n3),\"%B\":g=>w[g.Fa],\"%C\":g=>h((g.Ca+1900)/100|0,2),\"%d\":g=>h(g.Ia,2),\"%e\":g=>f(g.Ia,2,\" \"),\"%g\":g=>m(g).toString().substring(2),\"%G\":g=>m(g),\"%H\":g=>h(g.Ea,2),\"%I\":g=>{g=g.Ea;0==g?g=12:12<g&&(g-=12);return h(g,2)},\"%j\":g=>{for(var q=0,v=0;v<=g.Fa-1;q+=(V(g.Ca+1900)?Ra:Sa)[v++]);return h(g.Ia+q,3)},\"%m\":g=>h(g.Fa+1,2),\"%M\":g=>h(g.Va,2),\"%n\":()=>\"\\n\",\"%p\":g=>0<=g.Ea&&12>g.Ea?\"AM\":\"PM\",\"%S\":g=>h(g.Wa,2),\"%t\":()=>\"\\t\",\"%u\":g=>g.wa||7,\"%U\":g=>h(Math.floor((g.Ba+7-g.wa)/7),2),\"%V\":g=>{var q=Math.floor((g.Ba+\n7-(g.wa+6)%7)/7);2>=(g.wa+371-g.Ba-2)%7&&q++;if(q)53==q&&(v=(g.wa+371-g.Ba)%7,4==v||3==v&&V(g.Ca)||(q=1));else{q=52;var v=(g.wa+7-g.Ba-1)%7;(4==v||5==v&&V(g.Ca%400-1))&&q++}return h(q,2)},\"%w\":g=>g.wa,\"%W\":g=>h(Math.floor((g.Ba+7-(g.wa+6)%7)/7),2),\"%y\":g=>(g.Ca+1900).toString().substring(2),\"%Y\":g=>g.Ca+1900,\"%z\":g=>{g=g.Ua;var q=0<=g;g=Math.abs(g)/60;return(q?\"+\":\"-\")+String(\"0000\"+(g/60*100+g%60)).slice(-4)},\"%Z\":g=>g.Xa,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(n in p)c.includes(n)&&(c=c.replace(new RegExp(n,\n\"g\"),p[n](e)));c=c.replace(/\\0\\0/g,\"%\");n=Ta(c);if(n.length>b)return 0;M.set(n,a>>>0);return n.length-1}function W(a){try{a()}catch(b){H(b)}}function Va(a){var b={},c;for(c in a)(function(e){var f=a[e];b[e]=\"function\"==typeof f?function(){X.push(e);try{return f.apply(null,arguments)}finally{K||(X.pop()===e||H(),t&&1===Y&&0===X.length&&(Y=0,W(Wa),\"undefined\"!=typeof Fibers&&Fibers.ab()))}}:f})(c);return b}var Y=0,t=null,Xa=0,X=[],Ya={},Za={},$a=0,ab=null,bb=[];\nfunction ba(){return new Promise((a,b)=>{ab={resolve:a,reject:b}})}function cb(){var a=Ia(65548),b=a+12;P[a>>2>>>0]=b;P[a+4>>2>>>0]=b+65536;b=X[0];var c=Ya[b];void 0===c&&(c=$a++,Ya[b]=c,Za[c]=b);O[a+8>>2>>>0]=c;return a}\nfunction db(a){if(!K){if(0===Y){var b=!1,c=!1;a((e=0)=>{if(!K&&(Xa=e,b=!0,c)){Y=2;W(()=>eb(t));\"undefined\"!=typeof Browser&&Browser.Ga.Na&&Browser.Ga.resume();e=!1;try{var f=(0,J[Za[O[t+8>>2>>>0]]])()}catch(r){f=r,e=!0}var h=!1;if(!t){var l=ab;l&&(ab=null,(e?l.reject:l.resolve)(f),h=!0)}if(e&&!h)throw f;}});c=!0;b||(Y=1,t=cb(),\"undefined\"!=typeof Browser&&Browser.Ga.Na&&Browser.Ga.pause(),W(()=>fb(t)))}else 2===Y?(Y=0,W(gb),hb(t),t=null,bb.forEach(e=>{if(!K)try{if(e(),!noExitRuntime)try{L=L=e=L;if(!noExitRuntime){if(d.onExit)d.onExit(e);\nK=!0}y(e,new xa(e))}catch(f){f instanceof xa||\"unwind\"==f||y(1,f)}}catch(f){f instanceof xa||\"unwind\"==f||y(1,f)}})):H(`invalid state: ${Y}`);return Xa}}function ib(a){return db(b=>{a().then(b)})}\nvar kb={n:function(a,b,c){return ib(async()=>{await d.Pa(a,b,c)})},a:function(a,b,c){a>>>=0;(new za(a)).Ya(b>>>0,c>>>0);Aa=a;Ba++;throw Aa;},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},G:function(){},l:function(){},A:function(){},x:function(){},I:function(){},y:function(){},m:()=>!0,q:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);O[c>>2>>>0]=a.getUTCSeconds();O[c+4>>2>>>0]=\na.getUTCMinutes();O[c+8>>2>>>0]=a.getUTCHours();O[c+12>>2>>>0]=a.getUTCDate();O[c+16>>2>>>0]=a.getUTCMonth();O[c+20>>2>>>0]=a.getUTCFullYear()-1900;O[c+24>>2>>>0]=a.getUTCDay();O[c+28>>2>>>0]=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864E5|0},r:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);O[c>>2>>>0]=a.getSeconds();O[c+4>>2>>>0]=a.getMinutes();O[c+8>>2>>>0]=a.getHours();O[c+12>>2>>>0]=a.getDate();O[c+16>>2>>>0]=a.getMonth();O[c+20>>2>>>\n0]=a.getFullYear()-1900;O[c+24>>2>>>0]=a.getDay();O[c+28>>2>>>0]=(V(a.getFullYear())?Ga:Ha)[a.getMonth()]+a.getDate()-1|0;O[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();O[c+32>>2>>>0]=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0},s:function(a){a>>>=0;var b=new Date(O[a+20>>2>>>0]+1900,O[a+16>>2>>>0],O[a+12>>2>>>0],O[a+8>>2>>>0],O[a+4>>2>>>0],O[a>>2>>>0],0),c=O[a+32>>2>>>0],e=b.getTimezoneOffset(),\nf=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),h=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),l=Math.min(h,f);0>c?O[a+32>>2>>>0]=Number(f!=h&&l==e):0<c!=(l==e)&&(f=Math.max(h,f),b.setTime(b.getTime()+6E4*((0<c?l:f)-e)));O[a+24>>2>>>0]=b.getDay();O[a+28>>2>>>0]=(V(b.getFullYear())?Ga:Ha)[b.getMonth()]+b.getDate()-1|0;O[a>>2>>>0]=b.getSeconds();O[a+4>>2>>>0]=b.getMinutes();O[a+8>>2>>>0]=b.getHours();O[a+12>>2>>>0]=b.getDate();O[a+16>>2>>>0]=b.getMonth();O[a+20>>2>>>0]=b.getYear();a=b.getTime()/\n1E3;return jb((T=a,1<=+Math.abs(T)?0<T?+Math.floor(T/4294967296)>>>0:~~+Math.ceil((T-+(~~T>>>0))/4294967296)>>>0:0)),a>>>0},o:function(){return-52},p:function(){},v:function(a,b,c){function e(m){return(m=m.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?m[1]:\"GMT\"}c>>>=0;var f=(new Date).getFullYear(),h=new Date(f,0,1),l=new Date(f,6,1);f=h.getTimezoneOffset();var r=l.getTimezoneOffset();P[a>>>0>>2>>>0]=60*Math.max(f,r);O[b>>>0>>2>>>0]=Number(f!=r);a=e(h);b=e(l);a=Ja(a);b=Ja(b);r<f?(P[c>>2>>>0]=a,P[c+\n4>>2>>>0]=b):(P[c>>2>>>0]=b,P[c+4>>2>>>0]=a)},e:()=>{H(\"\")},b:function(a,b,c){a>>>=0;b=La(b>>>0,c>>>0);return wa[a].apply(null,b)},i:function(a,b,c){a>>>=0;b=La(b>>>0,c>>>0);return wa[a].apply(null,b)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(a,b,c){b>>>=0;return N.copyWithin(a>>>0>>>0,b>>>0,b+(c>>>0)>>>0)},u:function(a){a>>>=0;var b=N.length;if(4294901760<a)return!1;for(var c=1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var f=Math;\ne=Math.max(a,e);a:{f=f.min.call(f,4294901760,e+(65536-e%65536)%65536)-I.buffer.byteLength+65535>>>16;try{I.grow(f);ka();var h=1;break a}catch(l){}h=void 0}if(h)return!0}return!1},D:function(a,b){a>>>=0;b>>>=0;var c=0;Pa().forEach(function(e,f){var h=b+c;f=P[a+4*f>>2>>>0]=h;for(h=0;h<e.length;++h)M[f++>>0>>>0]=e.charCodeAt(h);M[f>>0>>>0]=0;c+=e.length+1});return 0},E:function(a,b){a>>>=0;b>>>=0;var c=Pa();P[a>>2>>>0]=c.length;var e=0;c.forEach(function(f){e+=f.length+1});P[b>>2>>>0]=e;return 0},f:()=>\n52,k:function(){return 52},t:function(){return 70},j:function(a,b,c,e){b>>>=0;c>>>=0;e>>>=0;for(var f=0,h=0;h<c;h++){var l=P[b>>2>>>0],r=P[b+4>>2>>>0];b+=8;for(var m=0;m<r;m++){var p=N[l+m>>>0],n=Qa[a];0===p||10===p?((1===a?ha:E)(Da(n,0)),n.length=0):n.push(p)}f+=r}P[e>>2>>>0]=f;return 0},F:Ua,d:function(a,b,c,e){return Ua(a>>>0,b>>>0,c>>>0,e>>>0)}};\n(function(){function a(c){c=c.exports;c=Va(c);J=c=lb(c);I=J.M;ka();ma.unshift(J.N);Q--;d.monitorRunDependencies&&d.monitorRunDependencies(Q);if(0==Q&&(null!==pa&&(clearInterval(pa),pa=null),R)){var e=R;R=null;e()}return c}var b={a:kb};Q++;d.monitorRunDependencies&&d.monitorRunDependencies(Q);if(d.instantiateWasm)try{return d.instantiateWasm(b,a)}catch(c){E(\"Module.instantiateWasm callback failed with error: \"+c),k(c)}va(b,function(c){a(c.instance)}).catch(k);return{}})();\nd._OrtInit=(a,b)=>(d._OrtInit=J.O)(a,b);d._OrtGetLastError=(a,b)=>(d._OrtGetLastError=J.P)(a,b);d._OrtCreateSessionOptions=(a,b,c,e,f,h,l,r,m,p)=>(d._OrtCreateSessionOptions=J.Q)(a,b,c,e,f,h,l,r,m,p);d._OrtAppendExecutionProvider=(a,b)=>(d._OrtAppendExecutionProvider=J.R)(a,b);d._OrtAddFreeDimensionOverride=(a,b,c)=>(d._OrtAddFreeDimensionOverride=J.S)(a,b,c);d._OrtAddSessionConfigEntry=(a,b,c)=>(d._OrtAddSessionConfigEntry=J.T)(a,b,c);d._OrtReleaseSessionOptions=a=>(d._OrtReleaseSessionOptions=J.U)(a);\nd._OrtCreateSession=(a,b,c)=>(d._OrtCreateSession=J.V)(a,b,c);d._OrtReleaseSession=a=>(d._OrtReleaseSession=J.W)(a);d._OrtGetInputOutputCount=(a,b,c)=>(d._OrtGetInputOutputCount=J.X)(a,b,c);d._OrtGetInputName=(a,b)=>(d._OrtGetInputName=J.Y)(a,b);d._OrtGetOutputName=(a,b)=>(d._OrtGetOutputName=J.Z)(a,b);d._OrtFree=a=>(d._OrtFree=J._)(a);d._OrtCreateTensor=(a,b,c,e,f,h)=>(d._OrtCreateTensor=J.$)(a,b,c,e,f,h);d._OrtGetTensorData=(a,b,c,e,f)=>(d._OrtGetTensorData=J.aa)(a,b,c,e,f);\nd._OrtReleaseTensor=a=>(d._OrtReleaseTensor=J.ba)(a);d._OrtCreateRunOptions=(a,b,c,e)=>(d._OrtCreateRunOptions=J.ca)(a,b,c,e);d._OrtAddRunConfigEntry=(a,b,c)=>(d._OrtAddRunConfigEntry=J.da)(a,b,c);d._OrtReleaseRunOptions=a=>(d._OrtReleaseRunOptions=J.ea)(a);d._OrtCreateBinding=a=>(d._OrtCreateBinding=J.fa)(a);d._OrtBindInput=(a,b,c)=>(d._OrtBindInput=J.ga)(a,b,c);d._OrtBindOutput=(a,b,c,e)=>(d._OrtBindOutput=J.ha)(a,b,c,e);d._OrtClearBoundOutputs=a=>(d._OrtClearBoundOutputs=J.ia)(a);\nd._OrtReleaseBinding=a=>(d._OrtReleaseBinding=J.ja)(a);d._OrtRunWithBinding=(a,b,c,e,f)=>(d._OrtRunWithBinding=J.ka)(a,b,c,e,f);d._OrtRun=(a,b,c,e,f,h,l,r)=>(d._OrtRun=J.la)(a,b,c,e,f,h,l,r);d._OrtEndProfiling=a=>(d._OrtEndProfiling=J.ma)(a);d._JsepOutput=(a,b,c)=>(d._JsepOutput=J.na)(a,b,c);d._JsepGetNodeName=a=>(d._JsepGetNodeName=J.oa)(a);\nvar Ia=d._malloc=a=>(Ia=d._malloc=J.pa)(a),hb=d._free=a=>(hb=d._free=J.qa)(a),jb=a=>(jb=J.sa)(a),mb=()=>(mb=J.ta)(),nb=a=>(nb=J.ua)(a),ob=a=>(ob=J.va)(a),fb=a=>(fb=J.xa)(a),Wa=()=>(Wa=J.ya)(),eb=a=>(eb=J.za)(a),gb=()=>(gb=J.Aa)();d.___start_em_js=934874;d.___stop_em_js=935035;function lb(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>f=>e(f)>>>0;a.__errno_location=b(a.__errno_location);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}d.stackAlloc=ob;\nd.stackSave=mb;d.stackRestore=nb;d.UTF8ToString=U;d.stringToUTF8=(a,b,c)=>Fa(a,N,b,c);d.lengthBytesUTF8=Ea;var Z;R=function pb(){Z||qb();Z||(R=pb)};\nfunction qb(){function a(){if(!Z&&(Z=!0,d.calledRun=!0,!K)){ya(ma);aa(d);if(d.onRuntimeInitialized)d.onRuntimeInitialized();if(d.postRun)for(\"function\"==typeof d.postRun&&(d.postRun=[d.postRun]);d.postRun.length;){var b=d.postRun.shift();na.unshift(b)}ya(na)}}if(!(0<Q)){if(d.preRun)for(\"function\"==typeof d.preRun&&(d.preRun=[d.preRun]);d.preRun.length;)oa();ya(la);0<Q||(d.setStatus?(d.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){d.setStatus(\"\")},1);a()},1)):a())}}\nif(d.preInit)for(\"function\"==typeof d.preInit&&(d.preInit=[d.preInit]);0<d.preInit.length;)d.preInit.pop()();qb();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasm;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasm);\n", "", "", "export const cpus = undefined;", "\nvar ortWasmThreaded = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nfunction d(){l.buffer!=p.buffer&&t();return p}function v(){l.buffer!=p.buffer&&t();return aa}function z(){l.buffer!=p.buffer&&t();return ba}function A(){l.buffer!=p.buffer&&t();return ca}function da(){l.buffer!=p.buffer&&t();return ea}function fa(){l.buffer!=p.buffer&&t();return ha}var B=moduleArg,ia,C;B.ready=new Promise((a,b)=>{ia=a;C=b});\"use strict\";\nB.jsepInit=(a,b,c,e,f,h,k,q)=>{B.Qb=a;B.xb=b;B.zb=c;B.kb=e;B.yb=f;B.Ea=h;B.Ab=k;B.Bb=q;b=(m,n,r)=>(...w)=>{const y=D,g=n?.();w=m(...w);const u=n?.();g!==u&&(m=u,r(g),n=r=null);return D!=y?ja():w};c=m=>async(...n)=>{try{if(B.bb)throw Error(\"Session already started\");const r=B.bb={Fb:n[0],errors:[]},w=await m(...n);if(B.bb!==r)throw Error(\"Session mismatch\");a.flush();const y=r.errors;if(0<y.length){let g=await Promise.all(y);g=g.filter(u=>u);if(0<g.length)throw Error(g.join(\"\\n\"));}return w}finally{B.bb=\nnull}};B._OrtRun=c(b(B._OrtRun,()=>B._OrtRun,m=>B._OrtRun=m));B._OrtRunWithBinding=c(b(B._OrtRunWithBinding,()=>B._OrtRunWithBinding,m=>B._OrtRunWithBinding=m));B._OrtBindInput=b(B._OrtBindInput,()=>B._OrtBindInput,m=>B._OrtBindInput=m);B.jsepRegisterBuffer=(m,n,r,w)=>a.registerBuffer(m,n,r,w);B.jsepUnregisterBuffers=m=>{a.unregisterBuffers(m)};B.jsepGetBuffer=m=>a.getBuffer(m);B.jsepCreateDownloader=(m,n,r)=>a.createDownloader(m,n,r)};\nvar ka=Object.assign({},B),la=\"./this.program\",E=(a,b)=>{throw b;},ma=\"object\"==typeof window,F=\"function\"==typeof importScripts,G=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,H=B.ENVIRONMENT_IS_PTHREAD||!1,I=\"\";function na(a){return B.locateFile?B.locateFile(a,I):I+a}var oa,J,pa;\nif(G){var fs=require(\"fs\"),qa=require(\"path\");I=F?qa.dirname(I)+\"/\":__dirname+\"/\";oa=(b,c)=>{b=b.startsWith(\"file://\")?new URL(b):qa.normalize(b);return fs.readFileSync(b,c?void 0:\"utf8\")};pa=b=>{b=oa(b,!0);b.buffer||(b=new Uint8Array(b));return b};J=(b,c,e,f=!0)=>{b=b.startsWith(\"file://\")?new URL(b):qa.normalize(b);fs.readFile(b,f?void 0:\"utf8\",(h,k)=>{h?e(h):c(f?k.buffer:k)})};!B.thisProgram&&1<process.argv.length&&(la=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);E=(b,c)=>{process.exitCode=\nb;throw c;};B.inspect=()=>\"[Emscripten Module object]\";let a;try{a=require(\"worker_threads\")}catch(b){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),b;}global.Worker=a.Worker}else if(ma||F)F?I=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(I=document.currentScript.src),(typeof _scriptDir !== \"undefined\" && _scriptDir)&&(I=_scriptDir),0!==I.indexOf(\"blob:\")?I=I.substr(0,I.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):I=\"\",G||(oa=a=>{var b=\nnew XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},F&&(pa=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),J=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)});G&&\"undefined\"==typeof performance&&(global.performance=require(\"perf_hooks\").performance);\nvar ra=console.log.bind(console),sa=console.error.bind(console);G&&(ra=(...a)=>fs.writeSync(1,a.join(\" \")+\"\\n\"),sa=(...a)=>fs.writeSync(2,a.join(\" \")+\"\\n\"));var ta=B.print||ra,K=B.printErr||sa;Object.assign(B,ka);ka=null;B.thisProgram&&(la=B.thisProgram);B.quit&&(E=B.quit);var L;B.wasmBinary&&(L=B.wasmBinary);var noExitRuntime=B.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&M(\"no native wasm support detected\");var l,N,ua,P=!1,Q,p,aa,ba,ca,ea,ha;\nfunction t(){var a=l.buffer;B.HEAP8=p=new Int8Array(a);B.HEAP16=new Int16Array(a);B.HEAP32=ba=new Int32Array(a);B.HEAPU8=aa=new Uint8Array(a);B.HEAPU16=new Uint16Array(a);B.HEAPU32=ca=new Uint32Array(a);B.HEAPF32=ea=new Float32Array(a);B.HEAPF64=ha=new Float64Array(a)}var va=B.INITIAL_MEMORY||16777216;5242880<=va||M(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+va+\"! (STACK_SIZE=5242880)\");\nif(H)l=B.wasmMemory;else if(B.wasmMemory)l=B.wasmMemory;else if(l=new WebAssembly.Memory({initial:va/65536,maximum:65536,shared:!0}),!(l.buffer instanceof SharedArrayBuffer))throw K(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),G&&K(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),\nError(\"bad memory\");t();va=l.buffer.byteLength;var wa=[],xa=[],ya=[],za=0;function Aa(){return noExitRuntime||0<za}var R=0,Ba=null,S=null;function Ca(){R++;B.monitorRunDependencies&&B.monitorRunDependencies(R)}function Da(){R--;B.monitorRunDependencies&&B.monitorRunDependencies(R);if(0==R&&(null!==Ba&&(clearInterval(Ba),Ba=null),S)){var a=S;S=null;a()}}\nfunction M(a){if(B.onAbort)B.onAbort(a);a=\"Aborted(\"+a+\")\";K(a);P=!0;Q=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");C(a);throw a;}function Ea(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var T;T=\"ort-wasm-simd-threaded.wasm\";Ea(T)||(T=na(T));function Fa(a){if(a==T&&L)return new Uint8Array(L);if(pa)return pa(a);throw\"both async and sync fetching of the wasm failed\";}\nfunction Ga(a){if(!L&&(ma||F)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>Fa(a));if(J)return new Promise((b,c)=>{J(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>Fa(a))}function Ha(a,b,c){return Ga(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{K(\"failed to asynchronously prepare wasm: \"+e);M(e)})}\nfunction Ia(a,b){var c=T;return L||\"function\"!=typeof WebAssembly.instantiateStreaming||Ea(c)||c.startsWith(\"file://\")||G||\"function\"!=typeof fetch?Ha(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(f){K(\"wasm streaming compile failed: \"+f);K(\"falling back to ArrayBuffer instantiation\");return Ha(c,a,b)}))}\nvar U,Ja={924476:a=>{B.Ea(\"Abs\",a,void 0)},924527:a=>{B.Ea(\"Neg\",a,void 0)},924578:a=>{B.Ea(\"Floor\",a,void 0)},924631:a=>{B.Ea(\"Ceil\",a,void 0)},924683:a=>{B.Ea(\"Reciprocal\",a,void 0)},924741:a=>{B.Ea(\"Sqrt\",a,void 0)},924793:a=>{B.Ea(\"Exp\",a,void 0)},924844:a=>{B.Ea(\"Erf\",a,void 0)},924895:a=>{B.Ea(\"Sigmoid\",a,void 0)},924950:a=>{B.Ea(\"Log\",a,void 0)},925001:a=>{B.Ea(\"Sin\",a,void 0)},925052:a=>{B.Ea(\"Cos\",a,void 0)},925103:a=>{B.Ea(\"Tan\",a,void 0)},925154:a=>{B.Ea(\"Asin\",a,void 0)},925206:a=>{B.Ea(\"Acos\",\na,void 0)},925258:a=>{B.Ea(\"Atan\",a,void 0)},925310:a=>{B.Ea(\"Sinh\",a,void 0)},925362:a=>{B.Ea(\"Cosh\",a,void 0)},925414:a=>{B.Ea(\"Asinh\",a,void 0)},925467:a=>{B.Ea(\"Acosh\",a,void 0)},925520:a=>{B.Ea(\"Atanh\",a,void 0)},925573:a=>{B.Ea(\"Tanh\",a,void 0)},925625:a=>{B.Ea(\"Not\",a,void 0)},925676:(a,b,c)=>{B.Ea(\"Clip\",a,{min:b,max:c})},925745:a=>{B.Ea(\"Clip\",a,void 0)},925797:(a,b)=>{B.Ea(\"Elu\",a,{alpha:b})},925855:a=>{B.Ea(\"Relu\",a,void 0)},925907:(a,b)=>{B.Ea(\"LeakyRelu\",a,{alpha:b})},925971:(a,b)=>{B.Ea(\"ThresholdedRelu\",\na,{alpha:b})},926041:(a,b)=>{B.Ea(\"Cast\",a,{to:b})},926099:a=>{B.Ea(\"Add\",a,void 0)},926150:a=>{B.Ea(\"Sub\",a,void 0)},926201:a=>{B.Ea(\"Mul\",a,void 0)},926252:a=>{B.Ea(\"Div\",a,void 0)},926303:a=>{B.Ea(\"Pow\",a,void 0)},926354:a=>{B.Ea(\"Equal\",a,void 0)},926407:a=>{B.Ea(\"Greater\",a,void 0)},926462:a=>{B.Ea(\"GreaterOrEqual\",a,void 0)},926524:a=>{B.Ea(\"Less\",a,void 0)},926576:a=>{B.Ea(\"LessOrEqual\",a,void 0)},926635:(a,b,c,e,f)=>{B.Ea(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>\n0,f+e>>>0)):[]})},926799:(a,b,c,e,f)=>{B.Ea(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},926962:(a,b,c,e,f)=>{B.Ea(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},927125:(a,b,c,e,f)=>{B.Ea(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},927289:(a,b,c,e,f)=>{B.Ea(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>\n0,f+e>>>0)):[]})},927452:(a,b,c,e,f)=>{B.Ea(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},927614:(a,b,c,e,f)=>{B.Ea(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},927776:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},927942:(a,b,c,e,f)=>{B.Ea(\"ReduceSumSquare\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>\n0,f+e>>>0)):[]})},928111:(a,b,c,e,f)=>{B.Ea(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},928280:a=>{B.Ea(\"Where\",a,void 0)},928333:(a,b,c)=>{B.Ea(\"Transpose\",a,{perm:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[]})},928446:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,u)=>{B.Ea(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],wIsConst:()=>!!d()[n>>>0],outputPadding:r?Array.from(z().subarray(w>>>\n0,w+r>>>0)):[],outputShape:y?Array.from(z().subarray(g>>>0,g+y>>>0)):[],activation:V(u)})},928860:(a,b,c,e,f,h,k,q,m,n,r,w,y,g)=>{B.Ea(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(z().subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[m>>>0],outputPadding:0<n?Array.from(z().subarray(r>>>0,r+n>>>0)):[],outputShape:0<w?Array.from(z().subarray(y>>>\n0,y+w>>>0)):[],activation:V(g)})},929417:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,u)=>{B.Ea(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,k],strides:[q],wIsConst:()=>!!d()[n>>>0],outputPadding:r?Array.from(z().subarray(w>>>0,w+r>>>0)):[],outputShape:y?Array.from(z().subarray(g>>>0,g+y>>>0)):[],activation:V(u)})},929831:(a,b,c,e,f,h,k,q,m,n,r,w,y,g)=>{B.Ea(\"ConvTranspose\",a,{format:q?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(z().subarray(c>>>0,c+2>>>0)),\ngroup:e,kernelShape:Array.from(z().subarray(f>>>0,f+2>>>0)),pads:Array.from(z().subarray(h>>>0,h+4>>>0)),strides:Array.from(z().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!d()[m>>>0],outputPadding:0<n?Array.from(z().subarray(r>>>0,r+n>>>0)):[],outputShape:0<w?Array.from(z().subarray(y>>>0,y+w>>>0)):[],activation:V(g)})},930388:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},930479:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,u,x)=>{B.Ea(\"AveragePool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,\nstorage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,u]})},930763:(a,b)=>{B.Ea(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},930854:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,u,x)=>{B.Ea(\"AveragePool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,u]})},931138:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},931225:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,u,x)=>{B.Ea(\"MaxPool\",a,{format:x?\n\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,u]})},931505:(a,b)=>{B.Ea(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},931592:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,u,x)=>{B.Ea(\"MaxPool\",a,{format:x?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,k],kernel_shape:[q,m],pads:[n,r,w,y],strides:[g,u]})},931872:(a,b,c,e,f)=>{B.Ea(\"Gemm\",a,{alpha:b,beta:c,transA:e,transB:f})},931976:a=>{B.Ea(\"MatMul\",\na,void 0)},932030:(a,b,c,e)=>{B.Ea(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},932138:(a,b,c,e)=>{B.Ea(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},932246:(a,b)=>{B.Ea(\"Softmax\",a,{axis:b})},932309:(a,b)=>{B.Ea(\"Concat\",a,{axis:b})},932369:(a,b,c,e,f)=>{B.Ea(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},932514:a=>{B.Ea(\"Expand\",a,void 0)},932568:(a,b)=>{B.Ea(\"Gather\",a,{axis:Number(b)})},932639:(a,b)=>{B.Ea(\"GatherElements\",a,{axis:Number(b)})},\n932718:(a,b,c,e,f,h,k,q,m,n,r)=>{B.Ea(\"Resize\",a,{antialias:b,axes:c?Array.from(z().subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:V(f),cubicCoeffA:h,excludeOutside:k,extrapolationValue:q,keepAspectRatioPolicy:V(m),mode:V(n),nearestMode:V(r)})},933069:(a,b,c,e,f,h,k)=>{B.Ea(\"Slice\",a,{starts:b?Array.from(z().subarray(c>>>0,c+b>>>0)):[],ends:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[],axes:h?Array.from(z().subarray(k>>>0,k+h>>>0)):[]})},933300:a=>{B.Ea(\"Tile\",a,void 0)},933352:(a,b,c)=>{B.Ea(\"LayerNormalization\",\na,{axis:Number(b),epsilon:Number(c)})},933459:(a,b,c)=>{B.Ea(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},933573:(a,b,c)=>{B.Ea(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},933687:a=>{B.Ea(\"Range\",a,void 0)},933740:(a,b)=>{B.Ea(\"Einsum\",a,{equation:V(b)})},933821:(a,b,c,e,f)=>{B.Ea(\"Pad\",a,{mode:b,value:c,pads:e?Array.from(z().subarray(f>>>0,f+e>>>0)):[]})},933953:(a,b,c,e,f,h)=>{B.Ea(\"BatchNormalization\",a,{epsilon:b,momentum:c,spatial:!!f,trainingMode:!!e,format:h?\n\"NHWC\":\"NCHW\"})},934122:(a,b,c,e,f,h)=>{B.Ea(\"BatchNormalization\",a,{epsilon:b,momentum:c,spatial:!!f,trainingMode:!!e,format:h?\"NHWC\":\"NCHW\"})},934291:(a,b,c)=>{B.Ea(\"CumSum\",a,{exclusive:Number(b),reverse:Number(c)})},934388:(a,b,c,e,f,h,k,q,m)=>{B.Ea(\"Attention\",a,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:h,qkvHiddenSizes:k?Array.from(z().subarray(Number(q)>>>0,Number(q)+k>>>0)):[],pastPresentShareBuffer:!!m})},934660:a=>{B.Ea(\"Gelu\",a,void 0)},934712:(a,b,c,e,f,h)=>{B.Ea(\"MultiHeadAttention\",\na,{numHeads:b,isUnidirectional:c,maskFilterValue:e,scale:f,doRotary:h})},934871:a=>{B.Ea(\"BiasAdd\",a,void 0)},934926:a=>{B.Ea(\"BiasSplitGelu\",a,void 0)},934987:(a,b)=>{B.Ea(\"SkipLayerNormalization\",a,{epsilon:b})},935068:(a,b,c,e,f,h,k,q,m,n,r,w,y)=>{B.Ea(\"Conv\",a,{format:m?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:h?Array.from(z().subarray(k>>>0,k+h>>>0)):[],strides:[q],w_is_const:()=>!!d()[n>>>0],activation:V(r),activation_params:w?Array.from(da().subarray(y>>>0,y+w>>>\n0)):[]})},935449:(a,b,c,e,f,h,k,q,m,n,r,w,y,g,u,x)=>{B.Ea(\"Conv\",a,{format:w?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,k],pads:q?Array.from(z().subarray(m>>>0,m+q>>>0)):[],strides:[n,r],w_is_const:()=>!!d()[y>>>0],activation:V(g),activation_params:u?Array.from(da().subarray(x>>>0,x+u>>>0)):[]})},935851:a=>{B.Ab(a)},935885:(a,b)=>B.Bb(a,b,B.bb.Fb,B.bb.errors),935997:a=>B.xb(a),936030:a=>B.zb(a),936062:(a,b,c)=>{B.kb(a,b,c,!0)},936101:(a,b,c)=>{B.kb(a,b,c)}};\nfunction Ka(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}function La(a){a.terminate();a.onmessage=()=>{}}function Ma(a){(a=W.Qa[a])||M();W.Eb(a)}function Na(a){var b=W.ub();if(!b)return 6;W.Za.push(b);W.Qa[a.Xa]=b;b.Xa=a.Xa;var c={cmd:\"run\",start_routine:a.Gb,arg:a.sb,pthread_ptr:a.Xa};G&&b.unref();b.postMessage(c,a.Mb);return 0}\nvar Oa=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Pa=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Oa)return Oa.decode(a.buffer instanceof SharedArrayBuffer?a.slice(b,c):a.subarray(b,c));for(e=\"\";b<c;){var f=a[b++];if(f&128){var h=a[b++]&63;if(192==(f&224))e+=String.fromCharCode((f&31)<<6|h);else{var k=a[b++]&63;f=224==(f&240)?(f&15)<<12|h<<6|k:(f&7)<<18|h<<12|k<<6|a[b++]&63;65536>f?e+=String.fromCharCode(f):(f-=65536,e+=String.fromCharCode(55296|f>>\n10,56320|f&1023))}}else e+=String.fromCharCode(f)}return e},V=(a,b)=>(a>>>=0)?Pa(v(),a,b):\"\";function Qa(a){if(H)return X(1,1,a);Q=a;if(!Aa()){W.Hb();if(B.onExit)B.onExit(a);P=!0}E(a,new Ka(a))}\nvar Sa=a=>{Q=a;if(H)throw Ra(a),\"unwind\";Qa(a)},W={Ya:[],Za:[],ob:[],Qa:{},gb:function(){H?W.wb():W.vb()},vb:function(){for(var a=B.numThreads;a--;)W.jb();wa.unshift(()=>{Ca();W.Cb(()=>Da())})},wb:function(){W.receiveObjectTransfer=W.Db;W.threadInitTLS=W.nb;W.setExitStatus=W.mb;noExitRuntime=!1},mb:function(a){Q=a},Sb:[\"$terminateWorker\"],Hb:function(){for(var a of W.Za)La(a);for(a of W.Ya)La(a);W.Ya=[];W.Za=[];W.Qa=[]},Eb:function(a){var b=a.Xa;delete W.Qa[b];W.Ya.push(a);W.Za.splice(W.Za.indexOf(a),\n1);a.Xa=0;Ta(b)},Db:function(){},nb:function(){W.ob.forEach(a=>a())},lb:a=>new Promise(b=>{a.onmessage=h=>{h=h.data;var k=h.cmd;if(h.targetThread&&h.targetThread!=Ua()){var q=W.Qa[h.Rb];q?q.postMessage(h,h.transferList):K('Internal error! Worker sent a message \"'+k+'\" to target pthread '+h.targetThread+\", but that thread no longer exists!\")}else if(\"checkMailbox\"===k)Va();else if(\"spawnThread\"===k)Na(h);else if(\"cleanupThread\"===k)Ma(h.thread);else if(\"killThread\"===k)h=h.thread,k=W.Qa[h],delete W.Qa[h],\nLa(k),Ta(h),W.Za.splice(W.Za.indexOf(k),1),k.Xa=0;else if(\"cancelThread\"===k)W.Qa[h.thread].postMessage({cmd:\"cancel\"});else if(\"loaded\"===k)a.loaded=!0,G&&!a.Xa&&a.unref(),b(a);else if(\"alert\"===k)alert(\"Thread \"+h.threadId+\": \"+h.text);else if(\"setimmediate\"===h.target)a.postMessage(h);else if(\"callHandler\"===k)B[h.handler](...h.args);else k&&K(\"worker sent an unknown command \"+k)};a.onerror=h=>{K(\"worker sent an error! \"+h.filename+\":\"+h.lineno+\": \"+h.message);throw h;};G&&(a.on(\"message\",function(h){a.onmessage({data:h})}),\na.on(\"error\",function(h){a.onerror(h)}));var c=[],e=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],f;for(f of e)B.hasOwnProperty(f)&&c.push(f);a.postMessage({cmd:\"load\",handlers:c,urlOrBlob:B.mainScriptUrlOrBlob||_scriptDir,wasmMemory:l,wasmModule:ua})}),Cb:function(a){if(H)return a();Promise.all(W.Ya.map(W.lb)).then(a)},jb:function(){var a=na(\"ort-wasm-simd-threaded.worker.js\");a=new Worker(a);W.Ya.push(a)},ub:function(){0==W.Ya.length&&(W.jb(),W.lb(W.Ya[0]));return W.Ya.pop()}};B.PThread=W;\nvar Wa=a=>{for(;0<a.length;)a.shift()(B)};B.establishStackSpace=function(){var a=Ua(),b=z()[a+52>>2>>>0];a=z()[a+56>>2>>>0];Xa(b,b-a);Ya(b)};function Ra(a){if(H)return X(2,0,a);Sa(a)}B.invokeEntryPoint=function(a,b){a=Za.apply(null,[a,b]);Aa()?W.mb(a):$a(a)};function ab(a){this.fb=a-24;this.rb=function(b){A()[this.fb+4>>2>>>0]=b};this.qb=function(b){A()[this.fb+8>>2>>>0]=b};this.gb=function(b,c){this.pb();this.rb(b);this.qb(c)};this.pb=function(){A()[this.fb+16>>2>>>0]=0}}var bb=0,cb=0;\nfunction db(a,b,c,e){return H?X(3,1,a,b,c,e):eb(a,b,c,e)}function eb(a,b,c,e){a>>>=0;b>>>=0;c>>>=0;e>>>=0;if(\"undefined\"==typeof SharedArrayBuffer)return K(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var f=[];if(H&&0===f.length)return db(a,b,c,e);a={Gb:c,Xa:a,sb:e,Mb:f};return H?(a.Ob=\"spawnThread\",postMessage(a,f),0):Na(a)}function fb(a,b,c){return H?X(4,1,a,b,c):0}function gb(a,b){if(H)return X(5,1,a,b)}\nvar hb=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},ib=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var f=c;e=c+e-1;for(var h=0;h<a.length;++h){var k=a.charCodeAt(h);if(55296<=k&&57343>=k){var q=a.charCodeAt(++h);k=65536+((k&1023)<<10)|q&1023}if(127>=k){if(c>=e)break;b[c++>>>0]=k}else{if(2047>=k){if(c+1>=e)break;b[c++>>>0]=192|k>>6}else{if(65535>=k){if(c+2>=e)break;b[c++>>>0]=224|k>>12}else{if(c+3>=e)break;b[c++>>>0]=240|k>>\n18;b[c++>>>0]=128|k>>12&63}b[c++>>>0]=128|k>>6&63}b[c++>>>0]=128|k&63}}b[c>>>0]=0;return c-f},jb=(a,b,c)=>ib(a,v(),b,c);function kb(a,b){if(H)return X(6,1,a,b)}function lb(a,b,c){if(H)return X(7,1,a,b,c)}function mb(a,b,c){return H?X(8,1,a,b,c):0}function nb(a,b){if(H)return X(9,1,a,b)}function ob(a,b,c){if(H)return X(10,1,a,b,c)}function pb(a,b,c,e){if(H)return X(11,1,a,b,c,e)}function qb(a,b,c,e){if(H)return X(12,1,a,b,c,e)}function rb(a,b,c,e){if(H)return X(13,1,a,b,c,e)}\nfunction sb(a){if(H)return X(14,1,a)}function tb(a,b){if(H)return X(15,1,a,b)}function ub(a,b,c){if(H)return X(16,1,a,b,c)}var vb=a=>{if(!P)try{if(a(),!Aa())try{H?$a(Q):Sa(Q)}catch(b){b instanceof Ka||\"unwind\"==b||E(1,b)}}catch(b){b instanceof Ka||\"unwind\"==b||E(1,b)}};function wb(a){a>>>=0;\"function\"===typeof Atomics.Nb&&(Atomics.Nb(z(),a>>2,a).value.then(Va),a+=128,Atomics.store(z(),a>>2,1))}B.__emscripten_thread_mailbox_await=wb;function Va(){var a=Ua();a&&(wb(a),vb(()=>xb()))}B.checkMailbox=Va;\nvar Y=a=>0===a%4&&(0!==a%100||0===a%400),yb=[0,31,60,91,121,152,182,213,244,274,305,335],zb=[0,31,59,90,120,151,181,212,243,273,304,334];function Ab(a,b,c,e,f,h,k,q){return H?X(17,1,a,b,c,e,f,h,k,q):-52}function Bb(a,b,c,e,f,h,k){if(H)return X(18,1,a,b,c,e,f,h,k)}var Db=a=>{var b=hb(a)+1,c=Cb(b);c&&jb(a,c,b);return c},Eb=[],Fb=(a,b)=>{Eb.length=0;var c;for(b>>=2;c=v()[a++>>>0];)b+=105!=c&b,Eb.push(105==c?z()[b>>>0]:fa()[b++>>>1]),++b;return Eb},Hb=a=>{var b=Gb();a=a();Ya(b);return a};\nfunction X(a,b){var c=arguments.length-2,e=arguments;return Hb(()=>{for(var f=Ib(8*c),h=f>>3,k=0;k<c;k++){var q=e[2+k];fa()[h+k>>>0]=q}return Jb(a,c,f,b)})}\nvar Kb=[],Lb={},Nb=()=>{if(!Mb){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:la||\"./this.program\"},b;for(b in Lb)void 0===Lb[b]?delete a[b]:a[b]=Lb[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Mb=c}return Mb},Mb;\nfunction Ob(a,b){if(H)return X(19,1,a,b);a>>>=0;b>>>=0;var c=0;Nb().forEach(function(e,f){var h=b+c;f=A()[a+4*f>>2>>>0]=h;for(h=0;h<e.length;++h)d()[f++>>0>>>0]=e.charCodeAt(h);d()[f>>0>>>0]=0;c+=e.length+1});return 0}function Pb(a,b){if(H)return X(20,1,a,b);a>>>=0;b>>>=0;var c=Nb();A()[a>>2>>>0]=c.length;var e=0;c.forEach(function(f){e+=f.length+1});A()[b>>2>>>0]=e;return 0}function Qb(a){return H?X(21,1,a):52}function Rb(a,b,c,e){return H?X(22,1,a,b,c,e):52}\nfunction Sb(a,b,c,e,f){return H?X(23,1,a,b,c,e,f):70}var Tb=[null,[],[]];function Vb(a,b,c,e){if(H)return X(24,1,a,b,c,e);b>>>=0;c>>>=0;e>>>=0;for(var f=0,h=0;h<c;h++){var k=A()[b>>2>>>0],q=A()[b+4>>2>>>0];b+=8;for(var m=0;m<q;m++){var n=v()[k+m>>>0],r=Tb[a];0===n||10===n?((1===a?ta:K)(Pa(r,0)),r.length=0):r.push(n)}f+=q}A()[e>>2>>>0]=f;return 0}var Wb=[31,29,31,30,31,30,31,31,30,31,30,31],Xb=[31,28,31,30,31,30,31,31,30,31,30,31];function Yb(a){var b=Array(hb(a)+1);ib(a,b,0,b.length);return b}\nvar Zb=(a,b)=>{d().set(a,b>>>0)};\nfunction $b(a,b,c,e){function f(g,u,x){for(g=\"number\"==typeof g?g.toString():g||\"\";g.length<u;)g=x[0]+g;return g}function h(g,u){return f(g,u,\"0\")}function k(g,u){function x(Ub){return 0>Ub?-1:0<Ub?1:0}var O;0===(O=x(g.getFullYear()-u.getFullYear()))&&0===(O=x(g.getMonth()-u.getMonth()))&&(O=x(g.getDate()-u.getDate()));return O}function q(g){switch(g.getDay()){case 0:return new Date(g.getFullYear()-1,11,29);case 1:return g;case 2:return new Date(g.getFullYear(),0,3);case 3:return new Date(g.getFullYear(),\n0,2);case 4:return new Date(g.getFullYear(),0,1);case 5:return new Date(g.getFullYear()-1,11,31);case 6:return new Date(g.getFullYear()-1,11,30)}}function m(g){var u=g.$a;for(g=new Date((new Date(g.ab+1900,0,1)).getTime());0<u;){var x=g.getMonth(),O=(Y(g.getFullYear())?Wb:Xb)[x];if(u>O-g.getDate())u-=O-g.getDate()+1,g.setDate(1),11>x?g.setMonth(x+1):(g.setMonth(0),g.setFullYear(g.getFullYear()+1));else{g.setDate(g.getDate()+u);break}}x=new Date(g.getFullYear()+1,0,4);u=q(new Date(g.getFullYear(),\n0,4));x=q(x);return 0>=k(u,g)?0>=k(x,g)?g.getFullYear()+1:g.getFullYear():g.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var n=z()[e+40>>2>>>0];e={Kb:z()[e>>2>>>0],Jb:z()[e+4>>2>>>0],cb:z()[e+8>>2>>>0],ib:z()[e+12>>2>>>0],eb:z()[e+16>>2>>>0],ab:z()[e+20>>2>>>0],Wa:z()[e+24>>2>>>0],$a:z()[e+28>>2>>>0],Tb:z()[e+32>>2>>>0],Ib:z()[e+36>>2>>>0],Lb:n?V(n):\"\"};c=V(c);n={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\n\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var r in n)c=c.replace(new RegExp(r,\"g\"),n[r]);var w=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),y=\"January February March April May June July August September October November December\".split(\" \");n={\"%a\":g=>w[g.Wa].substring(0,3),\"%A\":g=>w[g.Wa],\"%b\":g=>\ny[g.eb].substring(0,3),\"%B\":g=>y[g.eb],\"%C\":g=>h((g.ab+1900)/100|0,2),\"%d\":g=>h(g.ib,2),\"%e\":g=>f(g.ib,2,\" \"),\"%g\":g=>m(g).toString().substring(2),\"%G\":g=>m(g),\"%H\":g=>h(g.cb,2),\"%I\":g=>{g=g.cb;0==g?g=12:12<g&&(g-=12);return h(g,2)},\"%j\":g=>{for(var u=0,x=0;x<=g.eb-1;u+=(Y(g.ab+1900)?Wb:Xb)[x++]);return h(g.ib+u,3)},\"%m\":g=>h(g.eb+1,2),\"%M\":g=>h(g.Jb,2),\"%n\":()=>\"\\n\",\"%p\":g=>0<=g.cb&&12>g.cb?\"AM\":\"PM\",\"%S\":g=>h(g.Kb,2),\"%t\":()=>\"\\t\",\"%u\":g=>g.Wa||7,\"%U\":g=>h(Math.floor((g.$a+7-g.Wa)/7),2),\"%V\":g=>\n{var u=Math.floor((g.$a+7-(g.Wa+6)%7)/7);2>=(g.Wa+371-g.$a-2)%7&&u++;if(u)53==u&&(x=(g.Wa+371-g.$a)%7,4==x||3==x&&Y(g.ab)||(u=1));else{u=52;var x=(g.Wa+7-g.$a-1)%7;(4==x||5==x&&Y(g.ab%400-1))&&u++}return h(u,2)},\"%w\":g=>g.Wa,\"%W\":g=>h(Math.floor((g.$a+7-(g.Wa+6)%7)/7),2),\"%y\":g=>(g.ab+1900).toString().substring(2),\"%Y\":g=>g.ab+1900,\"%z\":g=>{g=g.Ib;var u=0<=g;g=Math.abs(g)/60;return(u?\"+\":\"-\")+String(\"0000\"+(g/60*100+g%60)).slice(-4)},\"%Z\":g=>g.Lb,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(r in n)c.includes(r)&&\n(c=c.replace(new RegExp(r,\"g\"),n[r](e)));c=c.replace(/\\0\\0/g,\"%\");r=Yb(c);if(r.length>b)return 0;Zb(r,a);return r.length-1}function ac(a){try{a()}catch(b){M(b)}}function bc(a){var b={},c;for(c in a)(function(e){var f=a[e];b[e]=\"function\"==typeof f?function(){cc.push(e);try{return f.apply(null,arguments)}finally{P||(cc.pop()===e||M(),D&&1===Z&&0===cc.length&&(Z=0,za+=1,ac(dc),\"undefined\"!=typeof Fibers&&Fibers.Ub()))}}:f})(c);return b}var Z=0,D=null,ec=0,cc=[],fc={},gc={},hc=0,ic=null,jc=[];\nfunction ja(){return new Promise((a,b)=>{ic={resolve:a,reject:b}})}function kc(){var a=Cb(65548),b=a+12;A()[a>>2>>>0]=b;A()[a+4>>2>>>0]=b+65536;b=cc[0];var c=fc[b];void 0===c&&(c=hc++,fc[b]=c,gc[c]=b);b=c;z()[a+8>>2>>>0]=b;return a}function lc(){var a=z()[D+8>>2>>>0];a=N[gc[a]];--za;return a()}\nfunction mc(a){if(!P){if(0===Z){var b=!1,c=!1;a((e=0)=>{if(!P&&(ec=e,b=!0,c)){Z=2;ac(()=>nc(D));\"undefined\"!=typeof Browser&&Browser.hb.tb&&Browser.hb.resume();e=!1;try{var f=lc()}catch(q){f=q,e=!0}var h=!1;if(!D){var k=ic;k&&(ic=null,(e?k.reject:k.resolve)(f),h=!0)}if(e&&!h)throw f;}});c=!0;b||(Z=1,D=kc(),\"undefined\"!=typeof Browser&&Browser.hb.tb&&Browser.hb.pause(),ac(()=>oc(D)))}else 2===Z?(Z=0,ac(pc),qc(D),D=null,jc.forEach(e=>vb(e))):M(`invalid state: ${Z}`);return ec}}\nfunction rc(a){return mc(b=>{a().then(b)})}W.gb();\nvar sc=[null,Qa,Ra,db,fb,gb,kb,lb,mb,nb,ob,pb,qb,rb,sb,tb,ub,Ab,Bb,Ob,Pb,Qb,Rb,Sb,Vb],vc={r:function(a,b,c){return rc(async()=>{await B.yb(a,b,c)})},b:function(a,b,c){a>>>=0;(new ab(a)).gb(b>>>0,c>>>0);bb=a;cb++;throw bb;},O:function(a){tc(a>>>0,!F,1,!ma,131072,!1);W.nb()},l:function(a){a>>>=0;H?postMessage({cmd:\"cleanupThread\",thread:a}):Ma(a)},I:eb,i:fb,U:gb,E:kb,G:lb,V:mb,S:nb,K:ob,R:pb,p:qb,F:rb,C:sb,T:tb,D:ub,q:()=>!0,A:function(a,b){a>>>=0;a==b>>>0?setTimeout(()=>Va()):H?postMessage({targetThread:a,\ncmd:\"checkMailbox\"}):(a=W.Qa[a])&&a.postMessage({cmd:\"checkMailbox\"})},M:function(){return-1},N:wb,X:function(a){G&&W.Qa[a>>>0].ref()},u:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getUTCSeconds();z()[c+4>>2>>>0]=a.getUTCMinutes();z()[c+8>>2>>>0]=a.getUTCHours();z()[c+12>>2>>>0]=a.getUTCDate();z()[c+16>>2>>>0]=a.getUTCMonth();z()[c+20>>2>>>0]=a.getUTCFullYear()-1900;z()[c+24>>2>>>0]=a.getUTCDay();a=(a.getTime()-Date.UTC(a.getUTCFullYear(),\n0,1,0,0,0,0))/864E5|0;z()[c+28>>2>>>0]=a},v:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);z()[c>>2>>>0]=a.getSeconds();z()[c+4>>2>>>0]=a.getMinutes();z()[c+8>>2>>>0]=a.getHours();z()[c+12>>2>>>0]=a.getDate();z()[c+16>>2>>>0]=a.getMonth();z()[c+20>>2>>>0]=a.getFullYear()-1900;z()[c+24>>2>>>0]=a.getDay();b=(Y(a.getFullYear())?yb:zb)[a.getMonth()]+a.getDate()-1|0;z()[c+28>>2>>>0]=b;z()[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),\n6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();a=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0;z()[c+32>>2>>>0]=a},w:function(a){a>>>=0;var b=new Date(z()[a+20>>2>>>0]+1900,z()[a+16>>2>>>0],z()[a+12>>2>>>0],z()[a+8>>2>>>0],z()[a+4>>2>>>0],z()[a>>2>>>0],0),c=z()[a+32>>2>>>0],e=b.getTimezoneOffset(),f=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),h=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),k=Math.min(h,f);0>c?z()[a+32>>2>>>0]=Number(f!=h&&k==e):\n0<c!=(k==e)&&(f=Math.max(h,f),b.setTime(b.getTime()+6E4*((0<c?k:f)-e)));z()[a+24>>2>>>0]=b.getDay();c=(Y(b.getFullYear())?yb:zb)[b.getMonth()]+b.getDate()-1|0;z()[a+28>>2>>>0]=c;z()[a>>2>>>0]=b.getSeconds();z()[a+4>>2>>>0]=b.getMinutes();z()[a+8>>2>>>0]=b.getHours();z()[a+12>>2>>>0]=b.getDate();z()[a+16>>2>>>0]=b.getMonth();z()[a+20>>2>>>0]=b.getYear();a=b.getTime()/1E3;return uc((U=a,1<=+Math.abs(U)?0<U?+Math.floor(U/4294967296)>>>0:~~+Math.ceil((U-+(~~U>>>0))/4294967296)>>>0:0)),a>>>0},s:Ab,t:Bb,\nz:function(a,b,c){function e(n){return(n=n.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?n[1]:\"GMT\"}a>>>=0;b>>>=0;c>>>=0;var f=(new Date).getFullYear(),h=new Date(f,0,1),k=new Date(f,6,1);f=h.getTimezoneOffset();var q=k.getTimezoneOffset(),m=Math.max(f,q);A()[a>>2>>>0]=60*m;z()[b>>2>>>0]=Number(f!=q);a=e(h);b=e(k);a=Db(a);b=Db(b);q<f?(A()[c>>2>>>0]=a,A()[c+4>>2>>>0]=b):(A()[c>>2>>>0]=b,A()[c+4>>2>>>0]=a)},d:()=>{M(\"\")},c:function(a,b,c){a>>>=0;b=Fb(b>>>0,c>>>0);return Ja[a].apply(null,b)},k:function(a,\nb,c){a>>>=0;b=Fb(b>>>0,c>>>0);return Ja[a].apply(null,b)},m:function(){},j:function(){return Date.now()},W:()=>{za+=1;throw\"unwind\";},B:function(){return 4294901760},f:()=>performance.timeOrigin+performance.now(),g:function(){return G?require(\"os\").cpus().length:navigator.hardwareConcurrency},L:function(a,b,c,e){W.Pb=b>>>0;Kb.length=c;b=e>>>0>>3;for(e=0;e<c;e++)Kb[e]=fa()[b+e>>>0];return(0>a?Ja[-a-1]:sc[a]).apply(null,Kb)},y:function(a){a>>>=0;var b=v().length;if(a<=b||4294901760<a)return!1;for(var c=\n1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var f=Math;e=Math.max(a,e);a:{f=f.min.call(f,4294901760,e+(65536-e%65536)%65536)-l.buffer.byteLength+65535>>>16;try{l.grow(f);t();var h=1;break a}catch(k){}h=void 0}if(h)return!0}return!1},P:Ob,Q:Pb,H:Sa,h:Qb,o:Rb,x:Sb,n:Vb,a:l||B.wasmMemory,J:$b,e:function(a,b,c,e){return $b(a>>>0,b>>>0,c>>>0,e>>>0)}};\n(function(){function a(c,e){c=c.exports;c=bc(c);N=c=wc(c);W.ob.push(N.Da);xa.unshift(N.Y);ua=e;Da();return c}var b={a:vc};Ca();if(B.instantiateWasm)try{return B.instantiateWasm(b,a)}catch(c){K(\"Module.instantiateWasm callback failed with error: \"+c),C(c)}Ia(b,function(c){a(c.instance,c.module)}).catch(C);return{}})();B._OrtInit=(a,b)=>(B._OrtInit=N.Z)(a,b);B._OrtGetLastError=(a,b)=>(B._OrtGetLastError=N._)(a,b);\nB._OrtCreateSessionOptions=(a,b,c,e,f,h,k,q,m,n)=>(B._OrtCreateSessionOptions=N.$)(a,b,c,e,f,h,k,q,m,n);B._OrtAppendExecutionProvider=(a,b)=>(B._OrtAppendExecutionProvider=N.aa)(a,b);B._OrtAddFreeDimensionOverride=(a,b,c)=>(B._OrtAddFreeDimensionOverride=N.ba)(a,b,c);B._OrtAddSessionConfigEntry=(a,b,c)=>(B._OrtAddSessionConfigEntry=N.ca)(a,b,c);B._OrtReleaseSessionOptions=a=>(B._OrtReleaseSessionOptions=N.da)(a);B._OrtCreateSession=(a,b,c)=>(B._OrtCreateSession=N.ea)(a,b,c);\nB._OrtReleaseSession=a=>(B._OrtReleaseSession=N.fa)(a);B._OrtGetInputOutputCount=(a,b,c)=>(B._OrtGetInputOutputCount=N.ga)(a,b,c);B._OrtGetInputName=(a,b)=>(B._OrtGetInputName=N.ha)(a,b);B._OrtGetOutputName=(a,b)=>(B._OrtGetOutputName=N.ia)(a,b);B._OrtFree=a=>(B._OrtFree=N.ja)(a);B._OrtCreateTensor=(a,b,c,e,f,h)=>(B._OrtCreateTensor=N.ka)(a,b,c,e,f,h);B._OrtGetTensorData=(a,b,c,e,f)=>(B._OrtGetTensorData=N.la)(a,b,c,e,f);B._OrtReleaseTensor=a=>(B._OrtReleaseTensor=N.ma)(a);\nB._OrtCreateRunOptions=(a,b,c,e)=>(B._OrtCreateRunOptions=N.na)(a,b,c,e);B._OrtAddRunConfigEntry=(a,b,c)=>(B._OrtAddRunConfigEntry=N.oa)(a,b,c);B._OrtReleaseRunOptions=a=>(B._OrtReleaseRunOptions=N.pa)(a);B._OrtCreateBinding=a=>(B._OrtCreateBinding=N.qa)(a);B._OrtBindInput=(a,b,c)=>(B._OrtBindInput=N.ra)(a,b,c);B._OrtBindOutput=(a,b,c,e)=>(B._OrtBindOutput=N.sa)(a,b,c,e);B._OrtClearBoundOutputs=a=>(B._OrtClearBoundOutputs=N.ta)(a);B._OrtReleaseBinding=a=>(B._OrtReleaseBinding=N.ua)(a);\nB._OrtRunWithBinding=(a,b,c,e,f)=>(B._OrtRunWithBinding=N.va)(a,b,c,e,f);B._OrtRun=(a,b,c,e,f,h,k,q)=>(B._OrtRun=N.wa)(a,b,c,e,f,h,k,q);B._OrtEndProfiling=a=>(B._OrtEndProfiling=N.xa)(a);B._JsepOutput=(a,b,c)=>(B._JsepOutput=N.ya)(a,b,c);B._JsepGetNodeName=a=>(B._JsepGetNodeName=N.za)(a);var Ua=B._pthread_self=()=>(Ua=B._pthread_self=N.Aa)(),Cb=B._malloc=a=>(Cb=B._malloc=N.Ba)(a),qc=B._free=a=>(qc=B._free=N.Ca)(a);B.__emscripten_tls_init=()=>(B.__emscripten_tls_init=N.Da)();\nvar tc=B.__emscripten_thread_init=(a,b,c,e,f,h)=>(tc=B.__emscripten_thread_init=N.Fa)(a,b,c,e,f,h);B.__emscripten_thread_crashed=()=>(B.__emscripten_thread_crashed=N.Ga)();\nvar Jb=(a,b,c,e)=>(Jb=N.Ha)(a,b,c,e),Ta=a=>(Ta=N.Ia)(a),$a=B.__emscripten_thread_exit=a=>($a=B.__emscripten_thread_exit=N.Ja)(a),xb=B.__emscripten_check_mailbox=()=>(xb=B.__emscripten_check_mailbox=N.Ka)(),uc=a=>(uc=N.La)(a),Xa=(a,b)=>(Xa=N.Ma)(a,b),Gb=()=>(Gb=N.Na)(),Ya=a=>(Ya=N.Oa)(a),Ib=a=>(Ib=N.Pa)(a),Za=B.dynCall_ii=(a,b)=>(Za=B.dynCall_ii=N.Ra)(a,b),oc=a=>(oc=N.Sa)(a),dc=()=>(dc=N.Ta)(),nc=a=>(nc=N.Ua)(a),pc=()=>(pc=N.Va)();B.___start_em_js=936134;B.___stop_em_js=936295;\nfunction wc(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>f=>e(f)>>>0;a.__errno_location=b(a.__errno_location);a.pthread_self=b(a.pthread_self);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}B.keepRuntimeAlive=Aa;B.wasmMemory=l;B.stackAlloc=Ib;B.stackSave=Gb;B.stackRestore=Ya;B.UTF8ToString=V;B.stringToUTF8=jb;B.lengthBytesUTF8=hb;B.ExitStatus=Ka;B.PThread=W;var xc;S=function yc(){xc||zc();xc||(S=yc)};\nfunction zc(){function a(){if(!xc&&(xc=!0,B.calledRun=!0,!P)){H||Wa(xa);ia(B);if(B.onRuntimeInitialized)B.onRuntimeInitialized();if(!H){if(B.postRun)for(\"function\"==typeof B.postRun&&(B.postRun=[B.postRun]);B.postRun.length;){var b=B.postRun.shift();ya.unshift(b)}Wa(ya)}}}if(!(0<R))if(H)ia(B),H||Wa(xa),startWorker(B);else{if(B.preRun)for(\"function\"==typeof B.preRun&&(B.preRun=[B.preRun]);B.preRun.length;)wa.unshift(B.preRun.shift());Wa(wa);0<R||(B.setStatus?(B.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){B.setStatus(\"\")},\n1);a()},1)):a())}}if(B.preInit)for(\"function\"==typeof B.preInit&&(B.preInit=[B.preInit]);0<B.preInit.length;)B.preInit.pop()();zc();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasmThreaded;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasmThreaded);\n", "\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason||e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(Module.__embind_initialize_bindings(),initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(`worker.js received unknown command ${e.data.cmd}`),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport * as path from 'node:path';\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from './binding/ort-wasm';\nimport {OrtWasmThreadedModule} from './binding/ort-wasm-threaded';\n\n/* eslint-disable @typescript-eslint/no-require-imports */\nlet ortWasmFactory: EmscriptenModuleFactory<OrtWasmModule>;\n\nif (!BUILD_DEFS.DISABLE_TRAINING) {\n  ortWasmFactory = require('./binding/ort-training-wasm-simd.js');\n} else {\n  ortWasmFactory =\n      BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm.js') : require('./binding/ort-wasm-simd.jsep.js');\n}\n\nconst ortWasmFactoryThreaded: EmscriptenModuleFactory<OrtWasmModule> = !BUILD_DEFS.DISABLE_WASM_THREAD ?\n    (BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm-threaded.js') :\n                                 require('./binding/ort-wasm-simd-threaded.jsep.js')) :\n    ortWasmFactory;\n/* eslint-enable @typescript-eslint/no-require-imports */\n\nlet wasm: OrtWasmModule|undefined;\nlet initialized = false;\nlet initializing = false;\nlet aborted = false;\n\nconst isMultiThreadSupported = (): boolean => {\n  try {\n    // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\n    if (typeof SharedArrayBuffer === 'undefined') {\n      return false;\n    }\n\n    // Test for transferability of SABs (for browsers. needed for Firefox)\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\n    if (typeof MessageChannel !== 'undefined') {\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\n    }\n\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing threaded instructions.\n    return WebAssembly.validate(new Uint8Array([\n      0, 97, 115, 109, 1, 0,  0,  0, 1, 4, 1,  96, 0,   0,  3, 2, 1,  0, 5,\n      4, 1,  3,   1,   1, 10, 11, 1, 9, 0, 65, 0,  254, 16, 2, 0, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst isSimdSupported = (): boolean => {\n  try {\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing SIMD instructions.\n\n    // The binary data is generated from the following code by wat2wasm:\n    //\n    // (module\n    //   (type $t0 (func))\n    //   (func $f0 (type $t0)\n    //     (drop\n    //       (i32x4.dot_i16x8_s\n    //         (i8x16.splat\n    //           (i32.const 0))\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\n\n    return WebAssembly.validate(new Uint8Array([\n      0,   97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1,   28,  0, 65, 0,\n      253, 15, 253, 12,  0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0,  0,  253, 186, 1, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst getWasmFileName = (useSimd: boolean, useThreads: boolean) => {\n  if (useSimd) {\n    if (!BUILD_DEFS.DISABLE_TRAINING) {\n      return 'ort-training-wasm-simd.wasm';\n    }\n    return useThreads ? 'ort-wasm-simd-threaded.wasm' : 'ort-wasm-simd.wasm';\n  } else {\n    return useThreads ? 'ort-wasm-threaded.wasm' : 'ort-wasm.wasm';\n  }\n};\n\nexport const initializeWebAssembly = async(flags: Env.WebAssemblyFlags): Promise<void> => {\n  if (initialized) {\n    return Promise.resolve();\n  }\n  if (initializing) {\n    throw new Error('multiple calls to \\'initializeWebAssembly()\\' detected.');\n  }\n  if (aborted) {\n    throw new Error('previous call to \\'initializeWebAssembly()\\' failed.');\n  }\n\n  initializing = true;\n\n  // wasm flags are already initialized\n  const timeout = flags.initTimeout!;\n  const numThreads = flags.numThreads!;\n  const simd = flags.simd!;\n\n  const useThreads = numThreads > 1 && isMultiThreadSupported();\n  const useSimd = simd && isSimdSupported();\n\n  const wasmPaths = flags.wasmPaths;\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\n  const wasmFileName = getWasmFileName(useSimd, useThreads);\n  const wasmPathOverride = typeof wasmPaths === 'object' ? wasmPaths[wasmFileName] : undefined;\n\n  let isTimeout = false;\n\n  const tasks: Array<Promise<void>> = [];\n\n  // promise for timeout\n  if (timeout > 0) {\n    tasks.push(new Promise((resolve) => {\n      setTimeout(() => {\n        isTimeout = true;\n        resolve();\n      }, timeout);\n    }));\n  }\n\n  // promise for module initialization\n  tasks.push(new Promise((resolve, reject) => {\n    const factory = useThreads ? ortWasmFactoryThreaded : ortWasmFactory;\n    const config: Partial<OrtWasmModule> = {\n      locateFile: (fileName: string, scriptDirectory: string) => {\n        if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads && fileName.endsWith('.worker.js') &&\n            typeof Blob !== 'undefined') {\n          return URL.createObjectURL(new Blob(\n              [\n                // This require() function is handled by esbuild plugin to load file content as string.\n                // eslint-disable-next-line @typescript-eslint/no-require-imports\n                require('./binding/ort-wasm-threaded.worker.js')\n              ],\n              {type: 'text/javascript'}));\n        }\n\n        if (fileName.endsWith('.wasm')) {\n          if (wasmPathOverride) {\n            return wasmPathOverride;\n          }\n\n          const prefix = wasmPrefixOverride ?? scriptDirectory;\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            if (wasmFileName === 'ort-wasm-simd.wasm') {\n              return prefix + 'ort-wasm-simd.jsep.wasm';\n            } else if (wasmFileName === 'ort-wasm-simd-threaded.wasm') {\n              return prefix + 'ort-wasm-simd-threaded.jsep.wasm';\n            }\n          }\n\n          return prefix + wasmFileName;\n        }\n\n        return scriptDirectory + fileName;\n      }\n    };\n\n    if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads) {\n      config.numThreads = numThreads;\n      if (typeof Blob === 'undefined') {\n        config.mainScriptUrlOrBlob = path.join(__dirname, 'ort-wasm-threaded.js');\n      } else {\n        const scriptSourceCode = `var ortWasmThreaded=${factory.toString()};`;\n        config.mainScriptUrlOrBlob = new Blob([scriptSourceCode], {type: 'text/javascript'});\n      }\n    }\n\n    factory(config).then(\n        // wasm module initialized successfully\n        module => {\n          initializing = false;\n          initialized = true;\n          wasm = module;\n          resolve();\n        },\n        // wasm module failed to initialize\n        (what) => {\n          initializing = false;\n          aborted = true;\n          reject(what);\n        });\n  }));\n\n  await Promise.race(tasks);\n\n  if (isTimeout) {\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\n  }\n};\n\nexport const getInstance = (): OrtWasmModule => {\n  if (initialized && wasm) {\n    return wasm;\n  }\n\n  throw new Error('WebAssembly is not initialized yet.');\n};\n\nexport const dispose = (): void => {\n  if (initialized && !initializing && !aborted) {\n    initializing = true;\n\n    (wasm as OrtWasmThreadedModule).PThread?.terminateAllThreads();\n    wasm = undefined;\n\n    initializing = false;\n    initialized = false;\n    aborted = true;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {getInstance} from './wasm-factory';\n\nexport const allocWasmString = (data: string, allocs: number[]): number => {\n  const wasm = getInstance();\n\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\n  const dataOffset = wasm._malloc(dataLength);\n  wasm.stringToUTF8(data, dataOffset, dataLength);\n  allocs.push(dataOffset);\n\n  return dataOffset;\n};\n\ninterface ExtraOptionsHandler {\n  (name: string, value: string): void;\n}\n\nexport const iterateExtraOptions =\n    (options: Record<string, unknown>, prefix: string, seen: WeakSet<Record<string, unknown>>,\n     handler: ExtraOptionsHandler): void => {\n      if (typeof options == 'object' && options !== null) {\n        if (seen.has(options)) {\n          throw new Error('Circular reference in options');\n        } else {\n          seen.add(options);\n        }\n      }\n\n      Object.entries(options).forEach(([key, value]) => {\n        const name = (prefix) ? prefix + key : key;\n        if (typeof value === 'object') {\n          iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\n        } else if (typeof value === 'string' || typeof value === 'number') {\n          handler(name, value.toString());\n        } else if (typeof value === 'boolean') {\n          handler(name, (value) ? '1' : '0');\n        } else {\n          throw new Error(`Can't handle extra config type: ${typeof value}`);\n        }\n      });\n    };\n\n/**\n * check web assembly API's last error and throw error if any error occurred.\n * @param message a message used when an error occurred.\n */\nexport const checkLastError = (message: string): void => {\n  const wasm = getInstance();\n\n  const stack = wasm.stackSave();\n  try {\n    const paramsOffset = wasm.stackAlloc(8);\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + 4);\n    const errorCode = wasm.HEAP32[paramsOffset / 4];\n    const errorMessagePointer = wasm.HEAPU32[paramsOffset / 4 + 1];\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let runOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const runOptions: InferenceSession.RunOptions = options || {};\n\n  try {\n    if (options?.logSeverityLevel === undefined) {\n      runOptions.logSeverityLevel = 2;  // Default to warning\n    } else if (\n        typeof options.logSeverityLevel !== 'number' || !Number.isInteger(options.logSeverityLevel) ||\n        options.logSeverityLevel < 0 || options.logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${options.logSeverityLevel}`);\n    }\n\n    if (options?.logVerbosityLevel === undefined) {\n      runOptions.logVerbosityLevel = 0;  // Default to 0\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\n    }\n\n    if (options?.terminate === undefined) {\n      runOptions.terminate = false;\n    }\n\n    let tagDataOffset = 0;\n    if (options?.tag !== undefined) {\n      tagDataOffset = allocWasmString(options.tag, allocs);\n    }\n\n    runOptionsHandle = wasm._OrtCreateRunOptions(\n        runOptions.logSeverityLevel!, runOptions.logVerbosityLevel!, !!runOptions.terminate!, tagDataOffset);\n    if (runOptionsHandle === 0) {\n      checkLastError('Can\\'t create run options.');\n    }\n\n    if (options?.extra !== undefined) {\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [runOptionsHandle, allocs];\n  } catch (e) {\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string|unknown): number => {\n  switch (graphOptimizationLevel) {\n    case 'disabled':\n      return 0;\n    case 'basic':\n      return 1;\n    case 'extended':\n      return 2;\n    case 'all':\n      return 99;\n    default:\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\n  }\n};\n\nconst getExecutionMode = (executionMode: 'sequential'|'parallel'): number => {\n  switch (executionMode) {\n    case 'sequential':\n      return 0;\n    case 'parallel':\n      return 1;\n    default:\n      throw new Error(`unsupported execution mode: ${executionMode}`);\n  }\n};\n\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\n  if (!options.extra) {\n    options.extra = {};\n  }\n  if (!options.extra.session) {\n    options.extra.session = {};\n  }\n  const session = options.extra.session as Record<string, string>;\n  if (!session.use_ort_model_bytes_directly) {\n    // eslint-disable-next-line camelcase\n    session.use_ort_model_bytes_directly = '1';\n  }\n\n  // if using JSEP with WebGPU, always disable memory pattern\n  if (options.executionProviders &&\n      options.executionProviders.some(ep => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')) {\n    options.enableMemPattern = false;\n  }\n};\n\nconst setExecutionProviders =\n    (sessionOptionsHandle: number, executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\n     allocs: number[]): void => {\n      for (const ep of executionProviders) {\n        let epName = typeof ep === 'string' ? ep : ep.name;\n\n        // check EP name\n        switch (epName) {\n          case 'xnnpack':\n            epName = 'XNNPACK';\n            break;\n          case 'webnn':\n            epName = 'WEBNN';\n            if (typeof ep !== 'string') {\n              const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\n              if (webnnOptions?.deviceType) {\n                const keyDataOffset = allocWasmString('deviceType', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.deviceType, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'deviceType' - ${webnnOptions.deviceType}.`);\n                }\n              }\n              if (webnnOptions?.numThreads) {\n                let numThreads = webnnOptions.numThreads;\n                // Just ignore invalid webnnOptions.numThreads.\n                if (typeof numThreads != 'number' || !Number.isInteger(numThreads) || numThreads < 0) {\n                  numThreads = 0;\n                }\n                const keyDataOffset = allocWasmString('numThreads', allocs);\n                const valueDataOffset = allocWasmString(numThreads.toString(), allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'numThreads' - ${webnnOptions.numThreads}.`);\n                }\n              }\n              if (webnnOptions?.powerPreference) {\n                const keyDataOffset = allocWasmString('powerPreference', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.powerPreference, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'powerPreference' - ${webnnOptions.powerPreference}.`);\n                }\n              }\n            }\n            break;\n          case 'webgpu':\n            epName = 'JS';\n            if (typeof ep !== 'string') {\n              const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\n              if (webgpuOptions?.preferredLayout) {\n                if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\n                  throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\n                }\n                const keyDataOffset = allocWasmString('preferredLayout', allocs);\n                const valueDataOffset = allocWasmString(webgpuOptions.preferredLayout, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'preferredLayout' - ${webgpuOptions.preferredLayout}.`);\n                }\n              }\n            }\n            break;\n          case 'wasm':\n          case 'cpu':\n            continue;\n          default:\n            throw new Error(`not supported execution provider: ${epName}`);\n        }\n\n        const epNameDataOffset = allocWasmString(epName, allocs);\n        if (getInstance()._OrtAppendExecutionProvider(sessionOptionsHandle, epNameDataOffset) !== 0) {\n          checkLastError(`Can't append execution provider: ${epName}.`);\n        }\n      }\n    };\n\nexport const setSessionOptions = (options?: InferenceSession.SessionOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let sessionOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\n  appendDefaultOptions(sessionOptions);\n\n  try {\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\n    const logIdDataOffset =\n        typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\n\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2;  // Default to 2 - warning\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${logSeverityLevel}`);\n    }\n\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0;  // Default to 0 - verbose\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\n    }\n\n    const optimizedModelFilePathOffset = typeof sessionOptions.optimizedModelFilePath === 'string' ?\n        allocWasmString(sessionOptions.optimizedModelFilePath, allocs) :\n        0;\n\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\n        graphOptimizationLevel, !!sessionOptions.enableCpuMemArena, !!sessionOptions.enableMemPattern, executionMode,\n        !!sessionOptions.enableProfiling, 0, logIdDataOffset, logSeverityLevel, logVerbosityLevel,\n        optimizedModelFilePathOffset);\n    if (sessionOptionsHandle === 0) {\n      checkLastError('Can\\'t create session options.');\n    }\n\n    if (sessionOptions.executionProviders) {\n      setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\n    }\n\n    if (sessionOptions.freeDimensionOverrides) {\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\n        if (typeof name !== 'string') {\n          throw new Error(`free dimension override name must be a string: ${name}`);\n        }\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\n        }\n        const nameOffset = allocWasmString(name, allocs);\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\n        }\n      }\n    }\n\n    if (sessionOptions.extra !== undefined) {\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [sessionOptionsHandle, allocs];\n  } catch (e) {\n    if (sessionOptionsHandle !== 0) {\n      wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\n\n/**\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\n */\nexport const enum DataType {\n  undefined = 0,\n  float = 1,\n  uint8 = 2,\n  int8 = 3,\n  uint16 = 4,\n  int16 = 5,\n  int32 = 6,\n  int64 = 7,\n  string = 8,\n  bool = 9,\n  float16 = 10,\n  double = 11,\n  uint32 = 12,\n  uint64 = 13,\n  complex64 = 14,\n  complex128 = 15,\n  bfloat16 = 16\n}\n\n/**\n * Map string tensor data to enum value\n */\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\n  switch (type) {\n    case 'int8':\n      return DataType.int8;\n    case 'uint8':\n      return DataType.uint8;\n    case 'bool':\n      return DataType.bool;\n    case 'int16':\n      return DataType.int16;\n    case 'uint16':\n      return DataType.uint16;\n    case 'int32':\n      return DataType.int32;\n    case 'uint32':\n      return DataType.uint32;\n    case 'float16':\n      return DataType.float16;\n    case 'float32':\n      return DataType.float;\n    case 'float64':\n      return DataType.double;\n    case 'string':\n      return DataType.string;\n    case 'int64':\n      return DataType.int64;\n    case 'uint64':\n      return DataType.uint64;\n\n    default:\n      throw new Error(`unsupported data type: ${type}`);\n  }\n};\n\n/**\n * Map enum value to string tensor data\n */\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\n  switch (typeProto) {\n    case DataType.int8:\n      return 'int8';\n    case DataType.uint8:\n      return 'uint8';\n    case DataType.bool:\n      return 'bool';\n    case DataType.int16:\n      return 'int16';\n    case DataType.uint16:\n      return 'uint16';\n    case DataType.int32:\n      return 'int32';\n    case DataType.uint32:\n      return 'uint32';\n    case DataType.float16:\n      return 'float16';\n    case DataType.float:\n      return 'float32';\n    case DataType.double:\n      return 'float64';\n    case DataType.string:\n      return 'string';\n    case DataType.int64:\n      return 'int64';\n    case DataType.uint64:\n      return 'uint64';\n\n    default:\n      throw new Error(`unsupported data type: ${typeProto}`);\n  }\n};\n\n/**\n * get tensor element size in bytes by the given data type\n * @returns size in integer or undefined if the data type is not supported\n */\nexport const getTensorElementSize = (dateType: number): number|\n    undefined => [undefined, 4, 1, 1, 2, 2, 4, 8, undefined, 1, 2, 8, 4, 8, undefined, undefined, undefined][dateType];\n\n/**\n * get typed array constructor by the given tensor type\n */\nexport const tensorTypeToTypedArrayConstructor = (type: Tensor.Type): Float32ArrayConstructor|Uint8ArrayConstructor|\n    Int8ArrayConstructor|Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|\n    Uint8ArrayConstructor|Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor => {\n      switch (type) {\n        case 'float16':\n          return Uint16Array;\n        case 'float32':\n          return Float32Array;\n        case 'uint8':\n          return Uint8Array;\n        case 'int8':\n          return Int8Array;\n        case 'uint16':\n          return Uint16Array;\n        case 'int16':\n          return Int16Array;\n        case 'int32':\n          return Int32Array;\n        case 'bool':\n          return Uint8Array;\n        case 'float64':\n          return Float64Array;\n        case 'uint32':\n          return Uint32Array;\n        case 'int64':\n          return BigInt64Array;\n        case 'uint64':\n          return BigUint64Array;\n        default:\n          throw new Error(`unsupported type: ${type}`);\n      }\n    };\n\n/**\n * Map string log level to integer value\n */\nexport const logLevelStringToEnum = (logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal'): number => {\n  switch (logLevel) {\n    case 'verbose':\n      return 0;\n    case 'info':\n      return 1;\n    case 'warning':\n      return 2;\n    case 'error':\n      return 3;\n    case 'fatal':\n      return 4;\n    default:\n      throw new Error(`unsupported logging level: ${logLevel}`);\n  }\n};\n\n/**\n * Check whether the given tensor type is supported by GPU buffer\n */\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes => type === 'float32' ||\n    type === 'int32' || type === 'int64' || type === 'bool' || type === 'float16' || type === 'uint32';\n\n/**\n * Map string data location to integer value\n */\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\n  switch (location) {\n    case 'none':\n      return 0;\n    case 'cpu':\n      return 1;\n    case 'cpu-pinned':\n      return 2;\n    case 'texture':\n      return 3;\n    case 'gpu-buffer':\n      return 4;\n    default:\n      throw new Error(`unsupported data location: ${location}`);\n  }\n};\n\n/**\n * Map integer data location to string value\n */\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation|undefined =>\n    (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer'] as const)[location];\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {logLevelStringToEnum} from '../wasm-common';\n\ntype LogLevel = NonNullable<Env['logLevel']>;\ntype MessageString = string;\ntype MessageFunction = () => string;\ntype Message = MessageString|MessageFunction;\n\nconst logLevelPrefix = ['V', 'I', 'W', 'E', 'F'];\n\nconst doLog = (level: number, message: string): void => {\n  // eslint-disable-next-line no-console\n  console.log(`[${logLevelPrefix[level]},${new Date().toISOString()}]${message}`);\n};\n\nlet configLogLevel: LogLevel|undefined;\nlet debug: boolean|undefined;\n\nexport const configureLogger = ($configLogLevel: LogLevel, $debug: boolean): void => {\n  configLogLevel = $configLogLevel;\n  debug = $debug;\n};\n\n/**\n * A simple logging utility to log messages to the console.\n */\nexport const LOG = (logLevel: LogLevel, msg: Message): void => {\n  const messageLevel = logLevelStringToEnum(logLevel);\n  const configLevel = logLevelStringToEnum(configLogLevel);\n  if (messageLevel >= configLevel) {\n    doLog(messageLevel, typeof msg === 'function' ? msg() : msg);\n  }\n};\n\n/**\n * A simple logging utility to log messages to the console. Only logs when debug is enabled.\n */\nexport const LOG_DEBUG: typeof LOG = (...args: Parameters<typeof LOG>) => {\n  if (debug) {\n    LOG(...args);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\nimport {tensorTypeToTypedArrayConstructor} from '../wasm-common';\n\nexport const createView = (dataBuffer: ArrayBuffer, type: Tensor.Type): Int32Array|Uint32Array|BigInt64Array|\n    BigUint64Array|Uint8Array|Float32Array|Float64Array|Int8Array|Int16Array|Uint16Array =>\n        new (tensorTypeToTypedArrayConstructor(type))(dataBuffer);\n\n/**\n * a TensorView does not own the data.\n */\nexport interface TensorView {\n  readonly data: number;\n  readonly dataType: number;\n  readonly dims: readonly number[];\n\n  /**\n   * get a Float32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getFloat32Array(): Float32Array;\n\n  /**\n   * get a BigInt64Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getBigInt64Array(): BigInt64Array;\n\n  /**\n   * get a Int32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getInt32Array(): Int32Array;\n\n  /**\n   * create a new tensor view with the same data but different dimensions.\n   */\n  reshape(newDims: readonly number[]): TensorView;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../tensor-view';\n\nimport {ShaderHelper} from './ops/common';\n\nexport enum GpuDataType {\n  default = 0,\n  upload = 1,\n  profile = 2\n}\nexport type GpuDataId = number;\n\nexport interface GpuData {\n  type: GpuDataType;\n  id: GpuDataId;\n  buffer: GPUBuffer;\n}\n\nexport interface TensorInfo {\n  dims: readonly number[];\n  dataType: number;\n}\n\n\nexport interface ProgramUniform {\n  type: 'int32'|'float32'|'uint32';\n  data: number|readonly number[];\n}\n\n/**\n * Represent the dependency of a program on a specific input tensor.\n *\n * - 'none': the shader/uniform does not depend on this input's info\n * - 'type': the shader/uniform depends on data type of this input\n * - 'rank': the shader/uniform depends on data type and the rank of this input\n * - 'dims': the shader/uniform depends on data type and the dims of this input\n * - 'data': the shader/uniform depends on data type, the dims and the data of this input\n */\nexport type ProgramInputTensorInfoDependency = 'none'|'type'|'rank'|'dims'|'data';\n\n/**\n * Represent information about a program's cache for shader.\n */\nexport interface ProgramShaderCacheInfo {\n  /**\n   * an optional string as a cache hint in the artifact cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains initializing-time information, such as the attributes or any information of\n   * initializers. It should NOT contain any runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'dims' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n/**\n * Represent information about a program's cache for uniform.\n */\nexport interface ProgramUniformCacheInfo {\n  /**\n   * an optional string as a cache hint in the uniform cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'none' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n\n/**\n * A set of data that represent a shader program\n */\nexport interface ProgramInfo {\n  /**\n   * the name of the program. used for debugging and profiling\n   */\n  name: string;\n\n  /**\n   * an optional object describing the cache information of the program shader.\n   *\n   * If this is not specified, assume hint is empty and inputDependencies are ['dims'] for all inputs.\n   */\n  shaderCache?: ProgramShaderCacheInfo;\n\n  /**\n   * the shader's processing source code.\n   *\n   * This function will be called when shader cache missed.\n   */\n  getShaderSource: (shaderHelper: ShaderHelper) => string;\n\n  /**\n   * A function to get run data required to run the program.\n   *\n   * This function will be called every time the program is executed. Should keep this function as simple as possible.\n   */\n  getRunData: (inputs: readonly TensorView[]) => {\n    outputs: readonly TensorInfo[];\n    dispatchGroup: {x: number; y?: number; z?: number};\n    programUniforms?: readonly ProgramUniform[];\n  };\n}\n\nexport interface Artifact {\n  programInfo: ProgramInfo;\n  computePipeline: GPUComputePipeline;\n}\n\nexport interface ComputeContextInputsOutputsMapping {\n  /**\n   * specify the mapping to the program's inputs. the value can be a number or a tensor view.\n   * - if it's a number, it's the index of the kernel's input\n   * - if it's a tensor view, it's an existing tensor view that will be used as the input\n   *\n   * if inputs is not specified, the mapping will be the kernel's inputs in order.\n   */\n  readonly inputs?: ReadonlyArray<TensorView|number>;\n  /**\n   * specify the mapping to the program's outputs. the value must be a number.\n   * - if it's a non-negative number, it's the index of the kernel's output\n   * - if it's -1, it's an output that will be created as a temporary value. this value will be released after\n   * the kernel is executed.\n   * - if it's -2, it's an output that will be created as a persistent value. this value will be released when the\n   * kernel is released.\n   *\n   * if outputs is not specified, the mapping will be the kernel's outputs in order.\n   */\n  readonly outputs?: readonly number[];\n}\n\n/**\n * A ComputeContext instance carries the states that representing the current running of a kernel.\n */\nexport interface ComputeContext {\n  /**\n   * stores the pointer to OpKernelContext\n   */\n  readonly opKernelContext: number;\n\n  /**\n   * a list of inputs, each input is an instance of TensorView\n   */\n  readonly inputs: readonly TensorView[];\n\n  /**\n   * a custom data object that can be used to store any data that is needed by the kernel\n   */\n  readonly kernelCustomData: {[key: string]: unknown};\n\n  /**\n   * a buffer that can be used to access custom data created each time the kernel is executed\n   */\n  readonly customDataBuffer: Uint8Array;\n\n  /**\n   * a number of outputs for the node\n   */\n  readonly outputCount: number;\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[];\n  output(index: number, dims: readonly number[]): number;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\n\nimport {GpuData, GpuDataId, GpuDataType} from './types';\n\n/**\n * manages GpuDataId -> GpuBuffer\n */\nexport interface GpuDataManager {\n  /**\n   * copy data from CPU to GPU.\n   */\n  upload(id: GpuDataId, data: Uint8Array): void;\n  /**\n   * copy data from GPU to GPU.\n   */\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void;\n  /**\n   * create new data on GPU.\n   */\n  create(size: number, usage?: number): GpuData;\n  /**\n   * get GPU data by ID.\n   */\n  get(id: GpuDataId): GpuData|undefined;\n  /**\n   * release the data on GPU by ID.\n   *\n   * @return size of the data released\n   */\n  release(id: GpuDataId): number;\n  /**\n   * copy data from GPU to CPU.\n   */\n  download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void>;\n\n  /**\n   * refresh the buffers that marked for release.\n   *\n   * when release() is called, the buffer is not released immediately. this is because we need to wait for the commands\n   * to be submitted to the GPU. this function is called after the commands are submitted so that the buffers can be\n   * actually released.\n   */\n  refreshPendingBuffers(): void;\n\n  /**\n   * register an external buffer for IO Binding. If the buffer is already registered, return the existing GPU data ID.\n   *\n   * GPU data manager only manages a mapping between the buffer and the GPU data ID. It will not manage the lifecycle of\n   * the external buffer.\n   */\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number;\n\n  /**\n   * unregister an external buffer for IO Binding.\n   */\n  unregisterExternalBuffer(buffer: GPUBuffer): void;\n\n  /**\n   * destroy all gpu buffers. Call this when the session.release is called.\n   */\n  dispose(): void;\n}\n\ninterface StorageCacheValue {\n  gpuData: GpuData;\n  originalSize: number;\n}\n\n/**\n * normalize the buffer size so that it fits the 128-bits (16 bytes) alignment.\n */\nconst calcNormalizedBufferSize = (size: number) => Math.ceil(size / 16) * 16;\n\nlet guid = 1;\nconst createNewGpuDataId = () => guid++;\n\n/**\n * exported standard download function. This function is used by the session to download the data from GPU, and also by\n * factory to create GPU tensors with the capacity of downloading data from GPU.\n *\n * @param backend - the WebGPU backend\n * @param gpuBuffer - the GPU buffer to download\n * @param originalSize - the original size of the data\n * @param getTargetBuffer - optional. If provided, the data will be copied to the target buffer. Otherwise, a new buffer\n * will be created and returned.\n */\nexport const downloadGpuData =\n    async(backend: WebGpuBackend, gpuBuffer: GPUBuffer, originalSize: number, getTargetBuffer?: () => Uint8Array):\n        Promise<Uint8Array> => {\n          const bufferSize = calcNormalizedBufferSize(originalSize);\n          const gpuReadBuffer = backend.device.createBuffer(\n              // eslint-disable-next-line no-bitwise\n              {size: bufferSize, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ});\n          try {\n            const commandEncoder = backend.getCommandEncoder();\n            backend.endComputePass();\n            commandEncoder.copyBufferToBuffer(\n                gpuBuffer /* source buffer */, 0 /* source offset */, gpuReadBuffer /* destination buffer */,\n                0 /* destination offset */, bufferSize /* size */\n            );\n            backend.flush();\n\n            await gpuReadBuffer.mapAsync(GPUMapMode.READ);\n\n            const arrayBuffer = gpuReadBuffer.getMappedRange();\n            if (getTargetBuffer) {\n              // if we already have a CPU buffer to accept the data, no need to clone the ArrayBuffer.\n              const targetBuffer = getTargetBuffer();\n              targetBuffer.set(new Uint8Array(arrayBuffer, 0, originalSize));\n              return targetBuffer;\n            } else {\n              // the mapped ArrayBuffer will be released when the GPU buffer is destroyed. Need to clone the\n              // ArrayBuffer.\n              return new Uint8Array(arrayBuffer.slice(0, originalSize));\n            }\n          } finally {\n            gpuReadBuffer.destroy();\n          }\n        };\n\nclass GpuDataManagerImpl implements GpuDataManager {\n  // GPU Data ID => GPU Data ( storage buffer )\n  private storageCache: Map<GpuDataId, StorageCacheValue>;\n\n  // pending buffers for uploading ( data is unmapped )\n  private buffersForUploadingPending: GPUBuffer[];\n  // pending buffers for computing\n  private buffersPending: GPUBuffer[];\n\n  // The reusable storage buffers for computing.\n  private freeBuffers: Map<number, GPUBuffer[]>;\n  // The reusable uniform buffers\n  private freeUniformBuffers: Map<number, GPUBuffer[]>;\n\n  // The external buffers registered users for IO Binding.\n  private externalBuffers: Map<GPUBuffer, GpuDataId>;\n\n  constructor(private backend: WebGpuBackend) {\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n    this.buffersForUploadingPending = [];\n    this.buffersPending = [];\n    this.externalBuffers = new Map();\n  }\n\n  upload(id: GpuDataId, data: Uint8Array): void {\n    const srcArrayBuffer = data.buffer;\n    const srcOffset = data.byteOffset;\n    const srcLength = data.byteLength;\n    const size = calcNormalizedBufferSize(srcLength);\n\n    // get destination gpu buffer\n    const gpuDataCache = this.storageCache.get(id);\n    if (!gpuDataCache) {\n      throw new Error('gpu data for uploading does not exist');\n    }\n    if (gpuDataCache.originalSize !== srcLength) {\n      throw new Error(`inconsistent data size. gpu data size=${gpuDataCache.originalSize}, data size=${srcLength}`);\n    }\n\n    // create gpu buffer\n    const gpuBufferForUploading = this.backend.device.createBuffer(\n        // eslint-disable-next-line no-bitwise\n        {mappedAtCreation: true, size, usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC});\n\n    // copy (upload) data\n    const arrayBuffer = gpuBufferForUploading.getMappedRange();\n    new Uint8Array(arrayBuffer).set(new Uint8Array(srcArrayBuffer, srcOffset, srcLength));\n    gpuBufferForUploading.unmap();\n\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(gpuBufferForUploading, 0, gpuDataCache.gpuData.buffer, 0, size);\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.upload(id=${id})`);\n\n    this.buffersForUploadingPending.push(gpuBufferForUploading);\n  }\n\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void {\n    // get source gpu buffer\n    const sourceGpuDataCache = this.storageCache.get(sourceId);\n    if (!sourceGpuDataCache) {\n      throw new Error('source gpu data for memcpy does not exist');\n    }\n    // get destination gpu buffer\n    const destinationGpuDataCache = this.storageCache.get(destinationId);\n    if (!destinationGpuDataCache) {\n      throw new Error('destination gpu data for memcpy does not exist');\n    }\n    if (sourceGpuDataCache.originalSize !== destinationGpuDataCache.originalSize) {\n      throw new Error('inconsistent source and destination gpu data size');\n    }\n    const size = calcNormalizedBufferSize(sourceGpuDataCache.originalSize);\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(\n        sourceGpuDataCache.gpuData.buffer, 0, destinationGpuDataCache.gpuData.buffer, 0, size);\n  }\n\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number {\n    let id: number|undefined;\n    if (previousBuffer) {\n      id = this.externalBuffers.get(previousBuffer);\n      if (id === undefined) {\n        throw new Error('previous buffer is not registered');\n      }\n      if (buffer === previousBuffer) {\n        LOG_DEBUG(\n            'verbose',\n            () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${\n                id}, buffer is the same, skip.`);\n        return id;\n      }\n      this.externalBuffers.delete(previousBuffer);\n    } else {\n      id = createNewGpuDataId();\n    }\n\n    this.storageCache.set(id, {gpuData: {id, type: GpuDataType.default, buffer}, originalSize});\n    this.externalBuffers.set(buffer, id);\n    LOG_DEBUG(\n        'verbose',\n        () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${id}, registered.`);\n    return id;\n  }\n\n  unregisterExternalBuffer(buffer: GPUBuffer): void {\n    const id = this.externalBuffers.get(buffer);\n    if (id !== undefined) {\n      this.storageCache.delete(id);\n      this.externalBuffers.delete(buffer);\n      LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${id}`);\n    }\n  }\n\n  // eslint-disable-next-line no-bitwise\n  create(size: number, usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST): GpuData {\n    const bufferSize = calcNormalizedBufferSize(size);\n\n    let gpuBuffer;\n    // Currently, only storage buffers are reused.\n    // eslint-disable-next-line no-bitwise\n    const isStorage = (usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE;\n    // eslint-disable-next-line no-bitwise\n    const isUniform = (usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM;\n    if (isStorage || isUniform) {\n      const freeBuffers = isStorage ? this.freeBuffers : this.freeUniformBuffers;\n      let buffers = freeBuffers.get(bufferSize);\n      if (!buffers) {\n        buffers = [];\n        freeBuffers.set(bufferSize, buffers);\n      }\n      if (buffers.length > 0) {\n        gpuBuffer = buffers.pop() as GPUBuffer;\n      } else {\n        // create gpu buffer\n        gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n      }\n    } else {\n      // create gpu buffer\n      gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n    }\n\n    const gpuData = {id: createNewGpuDataId(), type: GpuDataType.default, buffer: gpuBuffer};\n    this.storageCache.set(gpuData.id, {gpuData, originalSize: size});\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.create(size=${size}) => id=${gpuData.id}`);\n    return gpuData;\n  }\n\n  get(id: GpuDataId): GpuData|undefined {\n    return this.storageCache.get(id)?.gpuData;\n  }\n\n  release(id: GpuDataId): number {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('releasing data does not exist');\n    }\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.release(id=${id}), gpuDataId=${cachedData.gpuData.id}`);\n\n    this.storageCache.delete(id);\n    this.buffersPending.push(cachedData.gpuData.buffer);\n    // cachedData.gpuData.buffer.destroy();\n\n    return cachedData.originalSize;\n  }\n\n  async download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void> {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('data does not exist');\n    }\n\n    await downloadGpuData(this.backend, cachedData.gpuData.buffer, cachedData.originalSize, getTargetBuffer);\n  }\n\n  refreshPendingBuffers(): void {\n    for (const buffer of this.buffersForUploadingPending) {\n      // upload buffer is only useful in the session creation time. So we don't need to reuse them in session running.\n      buffer.destroy();\n    }\n    this.buffersForUploadingPending = [];\n    for (const buffer of this.buffersPending) {\n      // eslint-disable-next-line no-bitwise\n      if ((buffer.usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE) {\n        // Put the pending buffer to freeBuffers list instead of really destroying it for buffer reusing.\n        this.freeBuffers.get(buffer.size)!.push(buffer);\n        // eslint-disable-next-line no-bitwise\n      } else if ((buffer.usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM) {\n        // Put the pending buffer to freeUniformBuffers list instead of really destroying it for buffer reusing.\n        this.freeUniformBuffers.get(buffer.size)!.push(buffer);\n      } else {\n        buffer.destroy();\n      }\n    }\n    this.buffersPending = [];\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n    this.freeUniformBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.storageCache.forEach((storage) => {\n      storage.gpuData.buffer.destroy();\n    });\n\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n  }\n}\n\nexport const createGpuDataManager = (...args: ConstructorParameters<typeof GpuDataManagerImpl>): GpuDataManager =>\n    new GpuDataManagerImpl(...args);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nclass AttributeWithCacheKeyImpl {\n  constructor(attribute: Record<string, unknown>) {\n    Object.assign(this, attribute);\n  }\n\n  private key: string;\n  public get cacheKey(): string {\n    if (!this.key) {\n      this.key =\n          Object.getOwnPropertyNames(this).sort().map(name => `${(this as Record<string, unknown>)[name]}`).join(';');\n    }\n    return this.key;\n  }\n}\n\nexport interface AttributeWithCacheKey {\n  readonly cacheKey: string;\n}\n\n/**\n * create a new object from the given attribute, and add a cacheKey property to it\n */\nexport const createAttributeWithCacheKey = <T extends Record<string, unknown>>(attribute: T): T&AttributeWithCacheKey =>\n    new AttributeWithCacheKeyImpl(attribute) as unknown as T & AttributeWithCacheKey;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable no-param-reassign */\n\nexport class MatMulUtil {\n  /**\n   * Calculate the expected shape when matrix multiplication\n   * @param a The shape of tensor A. Should be a tuple of 2 positive integers\n   * @param b The shape of tensor B. Should be a tuple of 2 positive integers\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcMatMulShape(a: [number, number], b: [number, number]): [number, number]|undefined {\n    return (a[1] !== b[0]) ? undefined : [a[0], b[1]];\n  }\n}\n\n\nexport class BroadcastUtil {\n  /**\n   * Calculate the expected shape when broadcasting 2 tensors\n   * @param a The shape of tensor A. Should be an array of positive integers\n   * @param b The shape of tensor B. Should be an array of positive integers\n   * @param isMatMul Whether the operation is MatMul\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcShape(adims: readonly number[], bdims: readonly number[], isMatMul = false): readonly number[]|undefined {\n    const arank = adims.length;\n    const brank = bdims.length;\n    if (arank === 0) {\n      return bdims;\n    }\n    if (brank === 0) {\n      return adims;\n    }\n    const crank = Math.max(adims.length, bdims.length);\n    const cdims = new Array<number>(crank);\n\n    // calculate the last 2 dimension if it is MatMul\n    if (isMatMul) {\n      if (arank < 2 || brank < 2) {\n        return undefined;\n      }\n      const cShapeMatMul =\n          MatMulUtil.calcMatMulShape([adims[arank - 2], adims[arank - 1]], [bdims[brank - 2], bdims[brank - 1]]);\n      if (cShapeMatMul === undefined) {\n        return undefined;\n      }\n      [cdims[crank - 2], cdims[crank - 1]] = cShapeMatMul;\n    }\n\n    for (let i = isMatMul ? 3 : 1; i <= crank; i++) {\n      const aLen = arank - i < 0 ? 1 : adims[arank - i];\n      const bLen = brank - i < 0 ? 1 : bdims[brank - i];\n\n      if (aLen !== bLen && aLen > 1 && bLen > 1) {\n        return undefined;\n      }\n      cdims[crank - i] = Math.max(aLen, bLen);\n    }\n\n    return cdims;\n  }\n\n  /**\n   * Determine if a shape is unidirectional broadcastable to another shape\n   * @param shape The input shape\n   * @param finalShape The desired shape after broadcasting\n   */\n  static isValidBroadcast(shape: readonly number[], finalShape: readonly number[]): boolean {\n    // align shape to the right\n    const inputRank = shape.length;\n    const finalRank = finalShape.length;\n    if (inputRank > finalRank) {\n      return false;\n    }\n    for (let i = 1; i <= inputRank; i++) {\n      if (shape[inputRank - i] !== 1 && shape[inputRank - i] !== finalShape[finalRank - i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n\n\nexport class ShapeUtil {\n  /**\n   * calculate the size (number of elements)\n   */\n  static size(dims: readonly number[]): number {\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) from the given axis (inclusive)\n   */\n  static sizeFromDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeFromDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, axis, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) to the given axis (exclusive)\n   */\n  static sizeToDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeToDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, axis);\n  }\n\n  /**\n   * calculate the size (number of elements) from and to the given axis [start, end)\n   */\n  static getSizeFromDimensionRange(dims: readonly number[], start: number, end: number): number {\n    let size = 1;\n    for (let i = start; i < end; i++) {\n      // safety check as this method is called by multiple other methods requiring size.\n      // size cannot be negative.\n      if (dims[i] < 0) {\n        throw new Error(\n            // eslint-disable-next-line max-len\n            'cannot get valid size from specified dimension range. Most likely the range contains negative values in them.');\n      }\n      size *= dims[i];\n    }\n    return size;\n  }\n\n  static computeStrides(dims: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    if (rank === 0) {\n      return [];\n    } else if (rank === 1) {\n      return [1];\n    }\n    const strides = new Array(rank);\n    strides[rank - 1] = 1;\n    strides[rank - 2] = dims[rank - 1];\n    for (let i = rank - 3; i >= 0; --i) {\n      strides[i] = strides[i + 1] * dims[i + 1];\n    }\n    return strides;\n  }\n\n  /**\n   * normailze axis of range [-r, r) into [0, r).\n   */\n  static normalizeAxis(axis: number, tensorRank: number): number {\n    if (axis < -tensorRank && axis >= tensorRank) {\n      throw new Error('unsupported axis for this operation.');\n    }\n    return axis < 0 ? axis + tensorRank : axis;\n  }\n\n  static normalizeAxes(axes: readonly number[], tensorRank?: number): number[] {\n    return axes.map(x => this.normalizeAxis(x, tensorRank ?? axes.length));\n  }\n\n  /**\n   * Sorts a given array based on the indices in the Perm array\n   * Used in Transpose\n   * @param a Array to be sorted such as dims or strides\n   * @param perm Perm given; if null a will be reversed\n   */\n  static sortBasedOnPerm(a: readonly number[], perm?: readonly number[]): readonly number[] {\n    if (perm) {\n      return perm.map((v) => a[v]);\n    } else {\n      return a.slice().reverse();\n    }\n  }\n\n  /**\n   * Pads a given shape according to the padding values\n   * @param dims shape of the Tensor to be padded\n   * @param pad pad values\n   */\n  static padShape(dims: readonly number[], pad: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    return dims.map((v, i) => v + pad[i] + pad[i + rank]);\n  }\n\n  /**\n   * Determines if the two shapes are identical\n   * @param shape1\n   * @param shape2\n   */\n  static areEqual(shape1: readonly number[], shape2: readonly number[]): boolean {\n    if (shape1.length !== shape2.length) {\n      return false;\n    }\n    return shape1.every((v, i) => v === shape2[i]);\n  }\n}\n\nexport class PoolConvUtil {\n  /**\n   * Adjust the kernel, strides, pads to correct rank. Set to default value if not present\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   */\n  static adjustPoolAttributes(\n      isGlobalOperator: boolean, inputDims: readonly number[], kernelShape: number[], strides: number[],\n      dilations: number[], pads: number[]): void {\n    if (!isGlobalOperator && kernelShape.length !== inputDims.length - 2) {\n      throw new Error('length of specified kernel shapes should be 2 less than length of input dimensions');\n    }\n\n    if (isGlobalOperator) {\n      // adjust kernel shape to cover the input dims\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        if (dim >= kernelShape.length) {\n          kernelShape.push(inputDims[dim + 2]);\n        } else {\n          kernelShape[dim] = inputDims[dim + 2];\n        }\n      }\n    }\n\n    // adjust strides length to match kernel shape length\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < strides.length) {\n        if (strides[dim] < 0) {\n          throw new Error('strides should be greater than or equal to 1');\n        }\n      } else {\n        strides.push(1);\n      }\n    }\n\n    // adjust dilation value\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < dilations.length) {\n        if (dilations[dim] < 0) {\n          throw new Error('dilations should be greater than or equal to 1');\n        }\n      } else {\n        dilations.push(1);\n      }\n    }\n\n    // adjust pads length to match 2 * kernel shape length\n    for (let dim = 0; dim < kernelShape.length * 2; dim++) {\n      if (dim < pads.length) {\n        if (pads[dim] < 0) {\n          throw new Error('pad should be greater than or equal to 1');\n        }\n      } else {\n        pads.push(0);\n      }\n    }\n\n    // sanity checks for values in kernel shapes and pads\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (kernelShape[dim] <= 0) {\n        throw new Error('kernel shapes need to be greater than 0');\n      }\n\n      if (pads[dim] >= kernelShape[dim] || pads[dim + kernelShape.length] >= kernelShape[dim]) {\n        throw new Error('pads should be smaller than kernel');\n      }\n    }\n  }\n\n  // adjust pad values based on 'autoPad' attribute\n  static adjustPadsBasedOnAutoPad(\n      inputDims: readonly number[], strides: readonly number[], dilations: readonly number[],\n      kernelShape: readonly number[], pads: number[], isChannelLast: boolean, autoPad?: string): void {\n    if (!autoPad) {\n      return;\n    }\n\n    if (pads.length !== 2 * (inputDims.length - 2)) {\n      throw new Error('length of pads should be twice the length of data dimensions');\n    }\n\n    if (strides.length !== (inputDims.length - 2)) {\n      throw new Error('length of strides should be the length of data dimensions');\n    }\n\n    if (kernelShape.length !== (inputDims.length - 2)) {\n      throw new Error('length of kernel shapes should be the length of data dimensions');\n    }\n\n    for (let dim = 0; dim < inputDims.length - 2; dim++) {\n      PoolConvUtil.adjustPadAndReturnShape(\n          inputDims[dim + (isChannelLast ? 1 : 2)], strides[dim], dilations[dim], kernelShape[dim], pads, dim,\n          dim + inputDims.length - 2, autoPad);\n    }\n  }\n\n  /**\n   * Calculate the output shape for Pool ops based on input attributes. (Should be used only for Pool ops)\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computePoolOutputShape(\n      isGlobalOperator: boolean, inputDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0) {\n      throw new Error('input shape must be of size greater than 0');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], inputDims[1]];\n\n    PoolConvUtil.computeShapeHelper(\n        isGlobalOperator, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  /**\n   * Calculate the output shape for Conv op based on input attributes. (Should be used only for Conv op)\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param filterDims The filter tensor dimension. (inputs[1].dims)\n   * @param strides Stride along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computeConvOutputShape(\n      inputDims: readonly number[], filterDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0 || filterDims.length <= 0) {\n      throw new Error('invalid input tensor dims or invalid filter tensor dims');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], filterDims[0]];\n\n    PoolConvUtil.computeShapeHelper(false, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  // will compute output shapes for data dimensions ONLY (i.e.) no batch size and channels\n  // called by computePoolOutputShape() and computeConvOutputShape()\n  // adjust pads based on 'autoPad' attribute prior to shape computation\n  private static computeShapeHelper(\n      isGlobalOperator: boolean, inputDims: readonly number[], outputDims: number[], strides: readonly number[],\n      dilations: readonly number[], kernelShape: readonly number[], pads: number[], autoPad?: string) {\n    if (isGlobalOperator) {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(1);\n      }\n    } else {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(PoolConvUtil.adjustPadAndReturnShape(\n            inputDims[dim + 2], strides[dim], dilations[dim], kernelShape[dim], pads, dim, dim + inputDims.length - 2,\n            autoPad));\n      }\n    }\n  }\n\n  // helper for computeShapeHelper() and adjustPadsBasedOnAutoPad()\n  // adjusts pad value for given 'autoPad' string and computes output shape along a particular dimension\n  private static adjustPadAndReturnShape(\n      inSize: number, stride: number, dilation: number, kernel: number, pads: number[], padHeadIndex: number,\n      padTailIndex: number, autoPad?: string): number {\n    const dkernel = dilation * (kernel - 1) + 1;\n    if (autoPad && autoPad !== 'NOTSET') {\n      switch (autoPad) {\n        case 'VALID':\n          pads[padHeadIndex] = 0;\n          pads[padTailIndex] = 0;\n          return Math.floor(((inSize - dkernel) / stride) + 1);\n        case 'SAME_LOWER':\n        case 'SAME_UPPER':\n          if (dilation !== 1) {\n            throw new Error('Dilation not supported for SAME_UPPER or SAME_LOWER');\n          } else {\n            const legacyTargetSize = (inSize + stride - 1) / stride;\n            const padNeeded = (legacyTargetSize - 1) * stride + kernel - inSize;\n            pads[padHeadIndex] =\n                (autoPad === 'SAME_LOWER') ? Math.floor((padNeeded + 1) / 2) : Math.floor(padNeeded / 2);\n            pads[padTailIndex] = padNeeded - pads[padHeadIndex];\n            return Math.floor(((inSize + padNeeded - kernel) / stride) + 1);\n          }\n        default:\n          throw new Error('Unsupported AutoPad type');\n      }\n    } else {\n      return Math.floor(((inSize + pads[padHeadIndex] + pads[padTailIndex] - dkernel) / stride) + 1);\n    }\n  }\n}\n\nexport class GemmUtil {\n  // will make sure input shapes are compatible for this op\n  // and return back the shape of the output in the form of a tuple\n  // will throw exception if the input shapes are not compatible\n  static getShapeOfGemmResult(\n      leftShape: readonly number[], transLeft: boolean, rightShape: readonly number[], transRight: boolean,\n      biasShape?: readonly number[]): readonly number[] {\n    if (leftShape.length !== 2 || rightShape.length !== 2) {\n      throw new Error('shape need to be of size 2');\n    }\n\n    let M: number;\n    let K: number;\n    let N: number;\n\n    if (transLeft) {\n      M = leftShape[1];\n      K = leftShape[0];\n    } else {\n      M = leftShape[0];\n      K = leftShape[1];\n    }\n\n    let kDim = -1;\n\n    if (transRight) {\n      N = rightShape[0];\n      kDim = 1;\n    } else {\n      N = rightShape[1];\n      kDim = 0;\n    }\n\n    if (rightShape[kDim] !== K) {\n      throw new Error('dimension mismatch');\n    }\n\n    if (M <= 0 || N <= 0 || K <= 0) {\n      throw new Error('invalid shape specified');\n    }\n\n    if (biasShape && !BroadcastUtil.isValidBroadcast(biasShape, [M, N])) {\n      throw new Error('gemm: invalid bias shape for broadcast');\n    }\n\n    return [M, N, K];\n  }\n}\n\n\nexport const MIN_CLIP = -3.4028234663852886e+38;\nexport const MAX_CLIP = 3.4028234663852886e+38;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {ShapeUtil} from '../../util';\nimport {ProgramUniform} from '../types';\n\n/**\n * constant value for a workgroup size.\n *\n * We definitely can do further optimization in future, but for now we use 64.\n *\n * rule of thumb: Use [a workgroup size of] 64 unless you know what GPU you are targeting or that your workload\n *                needs something different.\n *\n * from: https://surma.dev/things/webgpu/\n **/\nexport const WORKGROUP_SIZE = 64;\n\ninterface IndicesHelperTypes {\n  /**\n   * WGSL type of indices expression\n   */\n  readonly indices: string;\n\n  /**\n   * WGSL type of a value\n   */\n  readonly value: string;\n\n  /**\n   * WGSL type of storage type representing a value\n   *\n   * This is usually the same to `value`, but for some type (eg. bool), we need to use `u32` as storage type for\n   * value type `vec4<bool>`\n   */\n  readonly storage: string;\n\n  /**\n   * tensor type as represented in TensorView\n   */\n  readonly tensor: number;\n}\n\n/**\n * A helper class for generating WGSL code for manipulating indices and data for a shader's input or output.\n *\n * This class is designed to offer a unified way to generate WGSL code for manipulating indices and data for a shader's\n * input or output.\n *\n * The following is a list of terminologies used in this class:\n * - `offset`: a uint32 value representing the offset of an element in the data buffer.\n * - `indices`: an abstraction of a multi-dimensional array's indices representing the data's index on each dimension.\n * - `value`: a value of a data element.\n *\n * Users are expected to create an instance of this class for each shader's input or output, and use the instance to\n * generate WGSL code for manipulating indices and data. The following 2 exported functions are for users to call to\n * create an instance of an indices helper:\n * - `inputVariable()`: create an indices helper instance for an input.\n * - `outputVariable()`: create an indices helper instance for an output.\n * - `internalVariable()`: create an indices helper instance for an internal variable.\n *\n * An indices helper instance contains helper functions for the following operations:\n * - access readonly basic information, including: `name`(the name of the input or output), `usage`(whether it's an\n * input, an output or an internal variable) and `shape`(the passed in shape).\n * - `type`: access readonly type information, including: `indices`(the type of indices), `value`(the type of value at\n * runtime), `storage`(the type of value at storage) and `tensor`(the tensor type as represented in TensorView).\n * - generate WGSL code for getting indices from offset. Use `offsetToIndices()` for WGSL code snippet to calculate\n * indices from offset, and use `indicesToOffset()` for WGSL code snippet to calculate offset from indices.\n * - to manipulate an instance of indices, use `setIndices()` and `getIndices()` to set and get the indices on an\n * indices variable.\n * - to manipulate data, use `set()`/`get()` to access data at the given indices from parameter list, use\n * `setByIndices()`/`getByIndices()` to access data at the given indices from an indices variable, and use\n * `setByOffset()`/`getByOffset()` to access data at the given offset.\n * - `impl`: get WGSL code of function implementation for the util functions mentioned above.\n */\nexport interface IndicesHelper {\n  /**\n   * get WGSL code of function implementation for the util functions.\n   *\n   */\n  readonly impl: () => string;\n\n  /**\n   * get type info\n   */\n  readonly type: IndicesHelperTypes;\n\n  /**\n   * WGSL code of a expression for getting indices from offset.\n   *\n   * @param varOffset - a u32 expression representing the offset.\n   *\n   * @returns an `type.indices` expression\n   */\n  readonly offsetToIndices: (varOffset: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting offset from indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the indices.\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesToOffset: (varIndices: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting original offset from broadcasted indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the output indices.\n   * @param output - output IndicesHelper.\n   *\n   * @returns an `u32` expression\n   */\n  readonly broadcastedIndicesToOffset: (varIndices: string, output: IndicesHelper) => string;\n\n  /**\n   * WGSL code of generating an indices literal\n   *\n   * @param init - initial value.\n   */\n  readonly indices: (...init: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code of a statement for setting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to set. can be a number or a string (WGSL `u32` expression).\n   * @param value - the value to set. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns a WGSL statement\n   */\n  readonly indicesSet: (varIndices: string, idx: number|string, value: number|string) => void;\n\n  /**\n   * WGSL code of an `u32` expression for getting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to get. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesGet: (varIndices: string, idx: number|string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices.\n   *\n   * @param indicesAndValue - an array of numbers or strings (WGSL `u32` expression) representing the indices, followed\n   *     by the value to set. This array should have exactly `shape.length + 1` elements.\n   */\n  readonly set: (...indicesAndValue: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByIndices: (varIndices: string, value: string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByOffset: (offset: number|string, value: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices.\n   *\n   * @param indices - an array of numbers or strings (WGSL `u32` expression) representing the indices.\n   */\n  readonly get: (...indices: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   */\n  readonly getByIndices: (varIndices: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   */\n  readonly getByOffset: (offset: number|string) => string;\n\n  /**\n   * name of the data variable\n   */\n  readonly name: string;\n\n  /**\n   * whether the helper is for an input, an output or an internal variable.\n   */\n  readonly usage: 'input'|'output'|'internal';\n\n  /**\n   * the rank of the input or output.\n   */\n  readonly rank: number;\n\n  /**\n   * a string representing the variable name for the shape of the input or output.\n   */\n  readonly shape: string;\n\n  /**\n   * a string representing the variable name for the strides of the input or output.\n   */\n  readonly strides: string;\n}\n\nconst getWgslMappedType = (type: number, components: 1|2|3|4): string|[string, string] => {\n  if (components === 3) {\n    throw new Error('vec3 has same alignment as vec4, use vec4 instead');\n  }\n\n  // return type is [ storage type, runtime type ] or a single string for both\n  switch (type) {\n    case DataType.float16:\n      return components > 1 ? `vec${components}<f16>` : 'f16';\n    case DataType.float:\n      return components > 1 ? `vec${components}<f32>` : 'f32';\n    case DataType.int32:\n      return components > 1 ? `vec${components}<i32>` : 'i32';\n    case DataType.uint32:\n      return components > 1 ? `vec${components}<u32>` : 'u32';\n    case DataType.int64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'i32'];\n    case DataType.uint64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'u32'];\n    case DataType.bool:\n      if (components !== 4) {\n        throw new Error('bool must be vec4');\n      }\n      return ['u32', 'vec4<bool>'];\n\n    default:\n      throw new Error(`Unknown data type: ${type}`);\n  }\n};\n\nexport const tensorTypeToWsglStorageType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[0];\n};\n\nexport const tensorTypeToWsglValueType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[1];\n};\n\nexport const createTensorShapeVariables = (dims: readonly number[]): ProgramUniform[] =>\n    dims.length === 0 ? [] : [{type: 'uint32', data: dims}, {type: 'uint32', data: ShapeUtil.computeStrides(dims)}];\n\n/**\n * A helper function to get maximum vector size for specified data length\n * @param size\n */\nexport const getMaxComponents = (size: number) => {\n  // we cannot use vec3 type since it has alignment of 16 bytes\n  if (size % 4 === 0) {\n    return 4;\n  } else if (size % 2 === 0) {\n    return 2;\n  }\n\n  return 1;\n};\n\n/**\n * A helper function that initializes variable as a scalar or vector. e.g. f32(0) or vec4f(0,0,0,0)\n * @param dataType\n * @param components\n * @param value\n */\nexport const fillVector = (dataType = 'f32', components?: number, value = '0') => {\n  if (!components || components === 1) {\n    return `${dataType}(${value})`;\n  }\n\n  return `vec${components}<${dataType}>(${value})`;\n};\n\n/**\n * A helper function that casts value or vector to f32\n * @param dataType\n * @param components\n * @param value\n */\nexport const castToF32 = (dataType: string, components: number, value: string) => {\n  if (dataType === 'f32') {\n    return value;\n  }\n  if (components === 1) {\n    return `f32(${value})`;\n  }\n\n  return `vec${components}f(${value})`;\n};\n\n/**\n * A helper function that returns scalar or sums all components of a vector\n * @param name\n * @param components\n */\nexport const sumVector = (name: string, components: number) => {\n  if (components === 4) {\n    return `(${name}.x + ${name}.y + ${name}.z + ${name}.w)`;\n  } else if (components === 2) {\n    return `(${name}.x + ${name}.y)`;\n  } else if (components === 3) {\n    return `(${name}.x + ${name}.y + ${name}.z)`;\n  }\n\n  return name;\n};\n\n/**\n * A helper function that returns variable element at index.\n * @param name - the name of variable.\n * @param index - the index of variable element.\n * @param length - the length of variable.\n */\nexport const getElementAt = (name: string, index: number|string, length: number): string => {\n  if (name.startsWith('uniforms.') && length > 4) {\n    if (typeof (index) === 'string') {\n      return `${name}[(${index}) / 4][(${index}) % 4]`;\n    } else {\n      return `${name}[${Math.floor(index / 4)}][${index % 4}]`;\n    }\n  } else {\n    return length > 1 ? `${name}[${index}]` : name;\n  }\n};\n\n/**\n * A helper function to get a IndicesHelper for a given input or output.\n *\n * @param name - the name of the input or output.\n * @param tensorType - the tensor type of the input or output.\n * @param shapeOrRank - the tensor shape or the rank of the input or output.\n * @param usage - the usage of the indices helper.\n * @param components - indicates the number of components of each element. 1 for scalar, 2 for vec2, 3 for vec3, 4 for\n *    vec4.\n */\nconst createIndicesHelper =\n    (name: string, tensorType: number, shapeOrRank: number|readonly number[], usage: IndicesHelper['usage'],\n     components: 1|2|3|4): IndicesHelper => {\n      const useUniform = typeof shapeOrRank === 'number';\n      const rank = useUniform ? shapeOrRank : shapeOrRank.length;\n      const rankIdentity = [...new Array(rank).keys()];\n      const indicesType = rank < 2 ? 'u32' : rank <= 4 ? `vec${rank}<u32>` : `array<u32, ${rank}>`;\n      const mappedType = getWgslMappedType(tensorType, components);\n      const valueType = typeof mappedType === 'string' ? mappedType : mappedType[1];\n      const storageType = typeof mappedType === 'string' ? mappedType : mappedType[0];\n      const type = {indices: indicesType, value: valueType, storage: storageType, tensor: tensorType};\n\n      const normalizeDim = (dim: number|string): string => typeof dim === 'string' ? dim : `${dim}u`;\n\n      const implementationUsed = {\n        offsetToIndices: false,\n        indicesToOffset: false,\n        broadcastedIndicesToOffset: false,\n        set: false,\n        setByIndices: false,\n        get: false,\n        getByIndices: false,\n      };\n\n      const uniformPrefix = useUniform ? 'uniforms.' : '';\n      const shape = `${uniformPrefix}${name}_shape`;\n      const strides = `${uniformPrefix}${name}_strides`;\n\n      let o2iSnippet = '';\n      for (let i = 0; i < rank - 1; i++) {\n        o2iSnippet += `\n    let dim${i} = current / ${getElementAt(strides, i, rank)};\n    let rest${i} = current % ${getElementAt(strides, i, rank)};\n    indices[${i}] = dim${i};\n    current = rest${i};\n    `;\n      }\n      o2iSnippet += `indices[${rank - 1}] = current;`;\n\n      const offsetToIndicesImplementation = rank < 2 ? '' : `\n  fn o2i_${name}(offset: u32) -> ${type.indices} {\n    var indices: ${type.indices};\n    var current = offset;\n    ${o2iSnippet}\n    return indices;\n  }`;\n\n      const offsetToIndices = (varOffset: string) => {\n        implementationUsed.offsetToIndices = true;\n        return rank < 2 ? varOffset : `o2i_${name}(${varOffset})`;\n      };\n\n      const offsets: string[] = [];\n      if (rank >= 2) {\n        for (let i = rank - 1; i >= 0; i--) {\n          offsets.push(`${getElementAt(strides, i, rank)} * (indices[${i}])`);\n        }\n      }\n\n      const indicesToOffsetImplementation = rank < 2 ? '' : `\n  fn i2o_${name}(indices: ${type.indices}) -> u32 {\n    return ${offsets.join('+')};\n  }`;\n\n      const indicesToOffset = (varIndices: string) => {\n        implementationUsed.indicesToOffset = true;\n        return rank < 2 ? varIndices : `i2o_${name}(${varIndices})`;\n      };\n\n      const indices = (...init: ReadonlyArray<number|string>) =>\n          rank === 0 ? '0u' : `${type.indices}(${init.map(normalizeDim).join(',')})`;\n\n      const indicesGet = (varIndices: string, idx: number|string) => {\n        if (rank < 2) {\n          return `${varIndices}`;\n        } else {\n          return `${getElementAt(varIndices, idx, rank)}`;\n        }\n      };\n\n      const indicesSet = (varIndices: string, idx: number|string, value: string) => {\n        if (rank < 2) {\n          return `${varIndices}=${value};`;\n        } else {\n          return `${getElementAt(varIndices, idx, rank)}=${value};`;\n        }\n      };\n\n      const broadcastedIndicesToOffsetImplementation: {[key: string]: string} = {};\n      const broadcastedIndicesToOffset = (varIndices: string, output: IndicesHelper) => {\n        implementationUsed.broadcastedIndicesToOffset = true;\n        const implKey = `${output.name}broadcastedIndicesTo${name}Offset`;\n        if (implKey in broadcastedIndicesToOffsetImplementation) {\n          return `${implKey}(${varIndices})`;\n        }\n        const offsets = [];\n        for (let i = rank - 1; i >= 0; i--) {\n          const idx = output.indicesGet('outputIndices', i + output.rank - rank);\n          offsets.push(`${indicesGet(strides, i)} * (${idx} % ${indicesGet(shape, i)})`);\n        }\n        broadcastedIndicesToOffsetImplementation[implKey] =\n            `fn ${implKey}(outputIndices: ${output.type.indices}) -> u32 {\n             return ${offsets.length > 0 ? offsets.join('+') : '0u'};\n           }`;\n\n        return `${implKey}(${varIndices})`;\n      };\n\n      const setByOffset = (offset: number|string, value: string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]=${value};`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), select(0u, 0xFFFFFFFFu, ${value} < 0));`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), 0u);`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `${name}[${offset}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${value}));`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByOffset = (offset: number|string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `i32(${name}[${offset}].x)`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `u32(${name}[${offset}].x)`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `vec4<bool>(bool(${name}[${offset}] & 0xFFu), bool(${name}[${offset}] & 0xFF00u), bool(${name}[${\n              offset}] & 0xFF0000u), bool(${name}[${offset}] & 0xFF000000u))`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByIndicesImplementation = rank < 2 ? '' : `\n  fn get_${name}ByIndices(indices: ${type.indices}) -> ${valueType} {\n    return ${getByOffset(`i2o_${name}(indices)`)};\n  }`;\n\n      const getImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn get_${name}(${functionParams}) -> ${valueType} {\n    return get_${name}ByIndices(${indices(dimsParams)});\n  }`;\n      })();\n\n      const get = (...indices: ReadonlyArray<number|string>) => {\n        if (indices.length !== rank) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n\n        const normalizedIndices = indices.map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return getByOffset('0u');\n        } else if (rank === 1) {\n          return getByOffset(normalizedIndices[0]);\n        } else {\n          implementationUsed.get = true;\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}(${normalizedIndices})`;\n        }\n      };\n\n      const getByIndices = (varIndices: string) => {\n        if (rank < 2) {\n          return getByOffset(varIndices);\n        } else {\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}ByIndices(${varIndices})`;\n        }\n      };\n\n      const setByIndicesImplementation = rank < 2 ? '' : `\n  fn set_${name}ByIndices(indices: ${type.indices}, value: ${valueType}) {\n    ${setByOffset(`i2o_${name}(indices)`, 'value')}\n  }`;\n\n      const setImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn set_${name}(${functionParams}, value: ${valueType}) {\n    set_${name}ByIndices(${indices(dimsParams)}, value);\n  }`;\n      })();\n\n      const set = (...indicesAndValue: ReadonlyArray<number|string>) => {\n        if (indicesAndValue.length !== rank + 1) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n        const value = indicesAndValue[rank];\n        if (typeof value !== 'string') {\n          throw new Error('value must be string');\n        }\n\n        const normalizedIndices = indicesAndValue.slice(0, rank).map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return setByOffset('0u', value);\n        } else if (rank === 1) {\n          return setByOffset(normalizedIndices[0], value);\n        } else {\n          implementationUsed.set = true;\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}(${normalizedIndices}, ${value})`;\n        }\n      };\n\n      const setByIndices = (varIndices: string, value: string) => {\n        if (rank < 2) {\n          return setByOffset(varIndices, value);\n        } else {\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}ByIndices(${varIndices}, ${value});`;\n        }\n      };\n\n      const impl = () => {\n        const impls = [];\n        let needShapeStrides = false;\n        if (implementationUsed.offsetToIndices) {\n          impls.push(offsetToIndicesImplementation);\n          needShapeStrides = true;\n        }\n        if (implementationUsed.indicesToOffset) {\n          impls.push(indicesToOffsetImplementation);\n          needShapeStrides = true;\n        }\n        if (implementationUsed.broadcastedIndicesToOffset) {\n          Object.values(broadcastedIndicesToOffsetImplementation).forEach(impl => impls.push(impl));\n          needShapeStrides = true;\n        }\n        if (implementationUsed.set) {\n          impls.push(setImplementation);\n          needShapeStrides = true;\n        }\n        if (implementationUsed.setByIndices) {\n          impls.push(setByIndicesImplementation);\n          needShapeStrides = true;\n        }\n        if (implementationUsed.get) {\n          impls.push(getImplementation);\n          needShapeStrides = true;\n        }\n        if (implementationUsed.getByIndices) {\n          impls.push(getByIndicesImplementation);\n          needShapeStrides = true;\n        }\n        if (!useUniform && needShapeStrides) {\n          impls.unshift(\n              `const ${shape} = ${type.indices}(${shapeOrRank.join(',')});`,\n              `const ${strides} = ${type.indices}(${ShapeUtil.computeStrides(shapeOrRank).join(',')});`);\n        }\n        return impls.join('\\n');\n      };\n\n      return {\n        impl,\n        type,\n        offsetToIndices,\n        indicesToOffset,\n        broadcastedIndicesToOffset,\n        indices,\n        indicesGet,\n        indicesSet,\n        set,\n        setByOffset,\n        setByIndices,\n        get,\n        getByOffset,\n        getByIndices,\n        // isVec4,\n        usage,\n        name,\n        strides,\n        shape,\n        rank\n      };\n    };\n\n/**\n * Create a IndicesHelper for an input.\n *\n * @param name - the name of the input.\n * @param type - the tensor type of the input.\n * @param shapeOrRank - the tensor shape or the rank of the input.\n * @param components - the number of components of the input. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the input.\n */\nexport const inputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, 'input', components);\n\n/**\n * Create a IndicesHelper for an output.\n *\n * @param name - the name of the output.\n * @param type - the tensor type of the output.\n * @param shapeOrRank - the tensor shape or the rank of the output.\n * @param components - the number of components of the output. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the output.\n */\nexport const outputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, 'output', components);\n\n/**\n * Create a IndicesHelper for an internal variable.\n *\n * @param name - the name of the variable.\n * @param type - the tensor type of the variable.\n * @param shapeOrRank - the tensor shape or the rank of the variable.\n * @param components - the number of components of the variable. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the variable.\n */\nexport const internalVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, 'internal', components);\n\nexport type UniformDataElementType = 'u32'|'f32'|'i32';\nexport type UniformsArrayType = Array<{name: string; type: UniformDataElementType; length?: number}>;\n\n/**\n * A ShaderHelper is a helper class for generating WGSL code.\n */\nexport interface ShaderHelper {\n  /**\n   * A helper function to generate the start of main function in WGSL source code.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param workgroupSize - an optional workgroup size. default is WORKGROUP_SIZE.\n   */\n  mainStart(workgroupSize?: number|[number, number, number]): string;\n\n  /**\n   * A helper function to generate the code snippet for guarding against out-of-bounds size.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n   *\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param size - the size of the data to guard against. can be a number or a string (WGSL `u32` expression).\n   */\n  guardAgainstOutOfBoundsWorkgroupSizes(size: unknown): string;\n\n  /**\n   * A helper function to generate the code snippet for declaring multiple inputs or outputs.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  declareVariables(...variables: IndicesHelper[]): string;\n\n  /**\n   * A helper function to register one uniform. Can be called multiple times to register multiple uniforms.\n   *\n   * @param name - the name of the uniform.\n   * @param type - the type of the uniform.\n   * @param length - the length of the uniform, default to 1 when it is not provided.\n   */\n  registerUniform(name: string, type: string, length?: number): ShaderHelper;\n\n  /**\n   * A helper function to register multiple uniforms. Can be called multiple times to register multiple uniforms.\n   *\n   * @param uniforms - an array of uniforms. Each element of the array is an object with 2 properties: `name` and\n   *     `type`.\n   */\n  registerUniforms(uniforms: UniformsArrayType): ShaderHelper;\n\n  /**\n   * A helper function to register multiple internal variables. Can be called multiple times to register multiple\n   * internal variables.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  registerInternalVariables(...variables: IndicesHelper[]): ShaderHelper;\n}\n\nclass ShaderHelperImpl implements ShaderHelper {\n  constructor(private normalizedDispatchGroup: [number, number, number]) {}\n\n  guardAgainstOutOfBoundsWorkgroupSizes(size: number|string): string {\n    // Guard against out-of-bounds work group sizes\n    const sizeInCode = typeof size === 'number' ? `${size}u` : size;\n    return `if (global_idx >= ${sizeInCode}) { return; }`;\n  }\n\n  mainStart(workgroupSize: number|[number, number, number] = WORKGROUP_SIZE) {\n    const workgroupSizeX = typeof workgroupSize === 'number' ? workgroupSize : workgroupSize[0];\n    const workgroupSizeY = typeof workgroupSize === 'number' ? 1 : workgroupSize[1];\n    const workgroupSizeZ = typeof workgroupSize === 'number' ? 1 : workgroupSize[2];\n\n    const is1DimensionDispatch = this.normalizedDispatchGroup[1] === 1 && this.normalizedDispatchGroup[2] === 1;\n    const paramList = is1DimensionDispatch ? `@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>` :\n                                             `@builtin(local_invocation_id) local_id : vec3<u32>,\n    @builtin(local_invocation_index) local_idx : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>`;\n    const globalIdxDefinition = is1DimensionDispatch ?\n        'let global_idx = global_id.x; let local_idx = local_id.x;' :\n        `let global_idx = (workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n          workgroup_id.y * num_workgroups[0] + workgroup_id.x) * ${\n            workgroupSizeX * workgroupSizeY * workgroupSizeZ}u + local_idx;`;\n\n    return `@compute @workgroup_size(${workgroupSizeX}, ${workgroupSizeY}, ${workgroupSizeZ})\n  fn main(${paramList}) {\n    ${globalIdxDefinition}\n  `;\n  }\n\n  private appendVariableUniforms(variable: IndicesHelper): void {\n    if (variable.rank !== 0) {\n      if (variable.shape.startsWith('uniforms.')) {\n        this.uniforms.push({name: variable.shape.replace('uniforms.', ''), type: 'u32', length: variable.rank});\n      }\n      if (variable.strides.startsWith('uniforms.')) {\n        this.uniforms.push({name: variable.strides.replace('uniforms.', ''), type: 'u32', length: variable.rank});\n      }\n    }\n  }\n\n  private declareVariable(variable: IndicesHelper, bindingIndex: number): string {\n    if (variable.usage === 'internal') {\n      throw new Error('cannot use internal variable with declareVariable(). use registerInternalVariables() instead.');\n    }\n    this.variables.push(variable);\n    this.appendVariableUniforms(variable);\n\n    const access = variable.usage === 'input' ? 'read' : 'read_write';\n    const storageType = variable.type.storage;\n    return `@group(0) @binding(${bindingIndex}) var<storage, ${access}> ${variable.name}: array<${storageType}>;`;\n  }\n\n  declareVariables(...variables: IndicesHelper[]): string {\n    return variables.map(v => this.declareVariable(v, this.variableIndex++)).join('\\n');\n  }\n\n  private registerInternalVariable(variable: IndicesHelper): void {\n    if (variable.usage !== 'internal') {\n      throw new Error(\n          'cannot use input or output variable with registerInternalVariable(). use declareVariables() instead.');\n    }\n\n    this.internalVariables.push(variable);\n    this.appendVariableUniforms(variable);\n  }\n\n  registerInternalVariables(...variables: IndicesHelper[]): ShaderHelper {\n    variables.forEach(v => this.registerInternalVariable(v));\n    return this;\n  }\n\n  registerUniform(name: string, type: UniformDataElementType, length = 1): ShaderHelper {\n    this.uniforms.push({name, type, length});\n    return this;\n  }\n\n  registerUniforms(additionalUniforms: UniformsArrayType): ShaderHelper {\n    this.uniforms = this.uniforms.concat(additionalUniforms);\n    return this;\n  }\n\n  private internalVariables: IndicesHelper[] = [];\n  private variables: IndicesHelper[] = [];\n  private uniforms: UniformsArrayType = [];\n  private uniformDeclaration(): string {\n    if (this.uniforms.length === 0) {\n      return '';\n    }\n\n    const uniformSnippets: string[] = [];\n    for (const {name, type, length} of this.uniforms) {\n      if (length && length > 4) {\n        uniformSnippets.push(`${name}:array<vec4<${type}>, ${Math.ceil(length / 4)}>`);\n      } else {\n        const typeTemp = length == null || length === 1 ? type : `vec${length}<${type}>`;\n        uniformSnippets.push(`${name}:${typeTemp}`);\n      }\n    }\n\n    return `\n      struct Uniforms { ${uniformSnippets.join(', ')} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`;\n  }\n  private variableIndex = 0;\n\n  /**\n   * Get additional implementation that needs to be added to the shader source.\n   */\n  get additionalImplementations(): string {\n    return this.uniformDeclaration() + this.variables.map(i => i.impl()).join('\\n') +\n        this.internalVariables.map(i => i.impl()).join('\\n');\n  }\n}\n\nexport const createShaderHelper = (dispatchGroup: [number, number, number]) => new ShaderHelperImpl(dispatchGroup);\n\n/**\n * This function comes from https://github.com/tensorflow/tfjs/blob/master/tfjs-core/src/ops/broadcast_util.ts#L18-L40\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport const getBroadcastDims = (inShape: readonly number[], outShape: readonly number[]): number[] => {\n  const inRank = inShape.length;\n  const dims: number[] = [];\n  for (let i = 0; i < inRank; i++) {\n    const dim = inRank - 1 - i;\n    const a = inShape[dim] || 1;\n    const b = outShape[outShape.length - 1 - i] || 1;\n    if (b > 1 && a === 1) {\n      dims.unshift(dim);\n    }\n  }\n  return dims;\n};\n\n// TODO: remove this when all related uses have been removed.\nexport const enableShapesUniforms = (_rank: number): boolean => true;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface TransposeAttributes extends AttributeWithCacheKey {\n  readonly perm: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Transpose requires 1 input.');\n  }\n};\n\nconst getAdjustedPerm = (inputRank: number, perm: number[]): number[] =>\n    (perm && perm.length !== inputRank) ? [...(new Array(inputRank).keys())].reverse() : perm;\n\nconst getOutputShape = (inputShape: readonly number[], perm: number[]): readonly number[] =>\n    ShapeUtil.sortBasedOnPerm(inputShape, getAdjustedPerm(inputShape.length, perm));\n\nconst permFunctionBody = (perm: number[], rank: number, input: IndicesHelper, output: IndicesHelper): string => {\n  const reverseFunc = [];\n  reverseFunc.push(`fn perm(i: ${output.type.indices}) -> ${input.type.indices} {\n    var a: ${input.type.indices};`);\n  for (let i = 0; i < rank; ++i) {\n    reverseFunc.push(input.indicesSet('a', perm[i], `i[${i}]`));\n  }\n  reverseFunc.push('return a;}');\n  return reverseFunc.join('\\n');\n};\n\nexport const createTransposeProgramInfo = (inputTensor: TensorView, permAttr: number[]): ProgramInfo => {\n  const inputDataType = inputTensor.dataType;\n  const inputRank = inputTensor.dims.length;\n  const perm = getAdjustedPerm(inputRank, permAttr);\n  const useShapesUniforms = enableShapesUniforms(inputRank);\n  const outputShape = getOutputShape(inputTensor.dims, perm);\n  const outShapeOrRank = useShapesUniforms ? outputShape.length : outputShape;\n  const inShapeOrRank = useShapesUniforms ? inputRank : inputTensor.dims;\n  const output = outputVariable('output', inputDataType, outShapeOrRank);\n  const input = inputVariable('a', inputDataType, inShapeOrRank);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n\n  ${permFunctionBody(perm, inputRank, input, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let indices = ${output.offsetToIndices('global_idx')};\n    let aIndices = perm(indices);\n\n    ${output.setByOffset('global_idx', input.getByIndices('aIndices'))}\n  }`;\n  return {\n    name: 'Transpose',\n    shaderCache: {hint: `${permAttr}`, inputDependencies: useShapesUniforms ? ['rank'] : ['dims']},\n    getRunData: (inputs) => {\n      const outputSize = ShapeUtil.size(outputShape);\n      return {\n        outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n        dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        programUniforms: useShapesUniforms ?\n            [\n              {type: 'uint32', data: outputSize},\n              ...createTensorShapeVariables(inputs[0].dims),\n              ...createTensorShapeVariables(outputShape),\n            ] :\n            [\n              {type: 'uint32', data: outputSize},\n            ],\n      };\n    },\n    getShaderSource,\n  };\n};\n\nexport const transpose = (context: ComputeContext, attributes: TransposeAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createTransposeProgramInfo(context.inputs[0], attributes.perm));\n};\n\nexport const parseTransposeAttributes = (attributes: Record<string, unknown>): TransposeAttributes =>\n    createAttributeWithCacheKey({perm: attributes.perm as number[]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {createReduceAttributesFromInputs, ReduceAttributes} from './reduce';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst reduceOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate * candidate',\n  logSumExp: 'bestValue + exp(candidate)',\n  l1: 'bestValue + abs(candidate)',\n  l2: 'bestValue + candidate * candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceSharedOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate',\n  logSumExp: 'bestValue + candidate',\n  l1: 'bestValue + candidate',\n  l2: 'bestValue + candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceInitValues: {[key: string]: string} = {\n  max: '_A[offset]',\n  min: '_A[offset]',\n  mean: '0',\n  sum: '0',\n  prod: '1',\n  sumSquare: '0',\n  logSumExp: '0',\n  l1: '0',\n  l2: '0',\n  logSum: '0'\n};\n\nconst reduceOutputValues: {[key: string]: string} = {\n  max: 'bestValue',\n  min: 'bestValue',\n  sum: 'bestValue',\n  prod: 'bestValue',\n  sumSquare: 'bestValue',\n  logSumExp: 'log(bestValue)',\n  l1: 'bestValue',\n  l2: 'sqrt(bestValue)',\n  logSum: 'log(bestValue)'\n};\n\nconst getInnerMostAxes = (numInnerAxes: number, rank: number): number[] => {\n  const res = [];\n  for (let i = rank - numInnerAxes; i < rank; ++i) {\n    res.push(i);\n  }\n  return res;\n};\n\nconst computeOutAndReduceShapes = (shape: readonly number[], axes: readonly number[]): [number[], number[]] => {\n  const outputShape = [];\n  const rank = shape.length;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      outputShape.push(shape[dim]);\n    }\n  }\n  const reduceShape = axes.map(dim => shape[dim]);\n  return [outputShape, reduceShape];\n};\n\nconst expandShapeToKeepDim = (shape: number[], axes: number[]): number[] => {\n  const rank = shape.length + axes.length;\n  const expandShape = [];\n  let shapeIdx = 0;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      expandShape.push(shape[shapeIdx++]);\n    } else {\n      expandShape.push(1);\n    }\n  }\n  return expandShape;\n};\n\nconst areAxesInnerMostDims = (axes: number[], rank: number): boolean => {\n  for (let i = 0; i < axes.length; ++i) {\n    if (axes[axes.length - i - 1] !== rank - 1 - i) {\n      return false;\n    }\n  }\n  return true;\n};\n\nconst getAxesPermutation = (axes: number[], rank: number): number[] => {\n  const res = [];\n  if (!areAxesInnerMostDims(axes, rank)) {\n    for (let i = 0; i < rank; ++i) {\n      if (axes.indexOf(i) === -1) {\n        res.push(i);\n      }\n    }\n    axes.forEach(axis => res.push(axis));\n  }\n  return res;\n};\n\nexport const createReduceSharedProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceType: string,\n     outputDataType: DataType, outputShape: number[], reduceShape: number[]): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const reduceSize = ShapeUtil.size(reduceShape);\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n\n      const workgroupSize = 32;\n\n      const sharedMemorySnippet = `\n          var<workgroup> aBestValues : array<${output.type.storage}, ${workgroupSize}>;\n       `;\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.registerUniform('reduceSize', 'u32').declareVariables(input, output)}\n        ${sharedMemorySnippet}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${shaderHelper.mainStart(workgroupSize)}\n\n          let outputIndex = global_idx / ${workgroupSize};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${output.type.storage}(${reduceInitValues[reduceType]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${workgroupSize}) {\n           let candidate = ${output.type.storage}(${input.getByOffset('offset + k')});\n           bestValue = ${reduceOps[reduceType]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${workgroupSize}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${reduceSharedOps[reduceType]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${\n          output.setByOffset(\n              'outputIndex',\n              `${\n                  reduceType === 'mean' ? `bestValue / ${output.type.storage}(uniforms.reduceSize)` :\n                                          `${reduceOutputValues[reduceType]}`}`)};\n         }\n        }`;\n\n      // One work group is responsible for only one element of output.\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: outputSize},\n          programUniforms: [{type: 'uint32', data: reduceSize}]\n        }),\n      };\n    };\n\nconst reduceCommon =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes,\n     reduceType: 'sum'|'sumSquare'|'prod'|'min'|'max'|'mean'|'logSumExp'|'l1'|'l2'|'logSum'): void => {\n      const updatedAttributes: ReduceAttributes =\n          context.inputs.length === 1 ? attributes : createReduceAttributesFromInputs(context.inputs, attributes);\n\n      let updatedAxes = updatedAttributes.axes;\n      if (updatedAxes.length === 0 && !updatedAttributes.noopWithEmptyAxes) {\n        updatedAxes = context.inputs[0].dims.map((_dim, i) => i);\n      }\n      const normalizeAxes = ShapeUtil.normalizeAxes(updatedAxes, context.inputs[0].dims.length);\n\n      let axes = normalizeAxes;\n      let input = context.inputs[0];\n      const permutedAxes = getAxesPermutation(axes, context.inputs[0].dims.length);\n      if (permutedAxes.length > 0) {\n        input = context.compute(\n            createTransposeProgramInfo(context.inputs[0], permutedAxes), {inputs: [0], outputs: [-1]})[0];\n        axes = getInnerMostAxes(axes.length, input.dims.length);\n      }\n\n      const [outputShape, reduceShape] = computeOutAndReduceShapes(input.dims, axes);\n      let finalOutputShape = outputShape;\n      if (updatedAttributes.keepDims) {\n        finalOutputShape = expandShapeToKeepDim(outputShape, normalizeAxes);\n      }\n\n      context.compute(\n          createReduceSharedProgramInfo(\n              name, {hint: updatedAttributes.cacheKey, inputDependencies: ['type']}, [input], reduceType,\n              context.inputs[0].dataType, finalOutputShape, reduceShape),\n          {inputs: [input]});\n    };\n\nexport const reduceMeanShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMeanShared', attributes, 'mean');\n};\n\nexport const reduceL1Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL1Shared', attributes, 'l1');\n};\n\nexport const reduceL2Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL2Shared', attributes, 'l2');\n};\n\nexport const reduceLogSumExpShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumExpShared', attributes, 'logSumExp');\n};\n\nexport const reduceMaxShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMaxShared', attributes, 'max');\n};\n\nexport const reduceMinShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMinShared', attributes, 'min');\n};\n\nexport const reduceProdShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceProdShared', attributes, 'prod');\n};\n\nexport const reduceSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumShared', attributes, 'sum');\n};\n\nexport const reduceSumSquareShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumSquareShared', attributes, 'sumSquare');\n};\n\nexport const reduceLogSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumShared', attributes, 'logSum');\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {createTensorShapeVariables, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\nimport {reduceL1Shared, reduceL2Shared, reduceLogSumExpShared, reduceLogSumShared, reduceMaxShared, reduceMeanShared, reduceMinShared, reduceProdShared, reduceSumShared, reduceSumSquareShared} from './reduce-shared';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('Reduce op requires 1 or 2 inputs.');\n  }\n\n  if (inputs.length === 2 && inputs[1].dims.length !== 1) {\n    throw new Error('Invalid axes input dims.');\n  }\n};\n\nexport interface ReduceAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  noopWithEmptyAxes: boolean;\n  axes: number[];\n}\n\nexport type ReduceOp =\n    (input: IndicesHelper, output: IndicesHelper,\n     axes: readonly number[]) => [string, string, string, string, ...string[]];\n\nconst noOp: ReduceOp = (input) => ['', '', `var value = ${input.getByIndices('input_indices')};`, ''];\nexport const createReduceProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceOp: ReduceOp,\n     axesInput: number[], outputDataType: DataType, keepDims = false, noopWithEmptyAxes = false): ProgramInfo => {\n      const outputShape: number[] = [];\n      const inputShape = inputs[0].dims;\n      const inputRank = inputShape.length;\n      const axes = ShapeUtil.normalizeAxes(axesInput, inputRank);\n      const reduceOnAllAxes = !noopWithEmptyAxes && axes.length === 0;\n      inputShape.forEach((d, i) => {\n        if (reduceOnAllAxes || axes.indexOf(i) >= 0) {\n          if (keepDims) {\n            outputShape.push(1);\n          }  // else { // skip this axis}\n        } else {\n          outputShape.push(d);\n        }\n      });\n      const outputRank = outputShape.length;\n      const outputSize = ShapeUtil.size(outputShape);\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const idxCopy: string[] = [];  // copy output indexes to input indexes\n\n        const input = inputVariable('_A', inputs[0].dataType, inputRank);\n        const output = outputVariable('output', outputDataType, outputRank);\n        const ops = reduceOp(input, output, axes);\n        let reduceOps = ops[2];\n\n        for (let k = 0, l = 0; k < inputRank; k++) {\n          // if this axis is reduced\n          if (reduceOnAllAxes || axes.indexOf(k) >= 0) {\n            if (keepDims) {\n              l++;\n            }\n            // loop over the d-th axis\n            reduceOps = `for(var j${k}: u32 = 0; j${k} < ${inputShape[k]}; j${k}++) {\n                  ${ops[2].includes('last_index') ? `let last_index = j${k};` : ''}\n                  ${input.indicesSet('input_indices', k, `j${k}`)}\n                  ${reduceOps}\n                }`;\n          } else {\n            idxCopy.push(`${input.indicesSet('input_indices', k, output.indicesGet('output_indices', l))};`);\n            l++;\n          }\n        }\n        return `\n\n        ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n          var input_indices: ${input.type.indices};\n          let output_indices = ${output.offsetToIndices('global_idx')};\n\n          ${idxCopy.join('\\n')}\n          ${ops[0]}       // init ops for reduce max/min\n          ${ops[1]}\n          ${reduceOps}\n          ${ops[3]}\n          ${ops.length === 4 ? output.setByOffset('global_idx', 'value') : ops.slice(4).join('\\n')}\n        }`;\n      };\n\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n          programUniforms: [\n            {type: 'uint32', data: outputSize}, ...createTensorShapeVariables(inputShape),\n            ...createTensorShapeVariables(outputShape)\n          ]\n        }),\n      };\n    };\n\nexport const createReduceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: ReduceAttributes): ReduceAttributes => {\n      const axes: number[] = [];\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => axes.push(Number(v)));\n      }\n      return createAttributeWithCacheKey(\n          {axes, keepDims: attributes.keepDims, noopWithEmptyAxes: attributes.noopWithEmptyAxes});\n    };\n\nconst runReduceProgram =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes, reduceOp: ReduceOp): void => {\n      const inputs = context.inputs;\n      const updatedAttributes: ReduceAttributes =\n          inputs.length === 1 ? attributes : createReduceAttributesFromInputs(inputs, attributes);\n\n      context.compute(\n          createReduceProgramInfo(\n              name, {hint: updatedAttributes.cacheKey, inputDependencies: ['rank']}, [inputs[0]],\n              updatedAttributes.noopWithEmptyAxes && updatedAttributes.axes.length === 0 ? noOp : reduceOp,\n              updatedAttributes.axes, inputs[0].dataType, updatedAttributes.keepDims,\n              updatedAttributes.noopWithEmptyAxes),\n          {inputs: [0]});\n    };\n\nconst reduceLogSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByIndices('input_indices')};`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSum', attributes, reduceOp);\n};\n\nconst reduceL1Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += abs(${input.getByIndices('input_indices')});`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceL1', attributes, reduceOp);\n};\n\nconst reduceL2Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByIndices('input_indices')}; value += (t * t);`,\n       'value = sqrt(value);',\n  ];\n  runReduceProgram(context, 'ReduceL2', attributes, reduceOp);\n};\n\nconst reduceLogSumExpNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += exp(${input.getByIndices('input_indices')});`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSumExp', attributes, reduceOp);\n};\n\nconst reduceMaxNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(input.indicesSet('input_indices', k, 0));\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByIndices('input_indices')};`,\n      `value = max(value, ${input.getByIndices('input_indices')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMax', attributes, reduceOp);\n};\n\nconst reduceMeanNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output, axes) => {\n    let size = 1.0;\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        // TODO: this depends on the input dims. If we want to use uniform, this need to be updated.\n        size *= context.inputs[0].dims[k];\n      }\n    }\n\n    return [\n      'var sum = f32(0);',\n      '',\n      `sum += f32(${input.getByIndices('input_indices')});`,\n      `let value = ${output.type.value}(sum / ${size});`,\n    ];\n  };\n  runReduceProgram(context, 'ReduceMean', attributes, reduceOp);\n};\n\nconst reduceMinNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`input_indices[${k}] = 0;`);  // first element\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByIndices('input_indices')};`,\n      `value = min(value, ${input.getByIndices('input_indices')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMin', attributes, reduceOp);\n};\n\nconst reduceProdNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(1);`,\n       '',\n       `value *= ${input.getByIndices('input_indices')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceProd', attributes, reduceOp);\n};\n\nconst reduceSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByIndices('input_indices')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSum', attributes, reduceOp);\n};\n\nconst reduceSumSquareNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByIndices('input_indices')}; value += t * t;`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSumSquare', attributes, reduceOp);\n};\n\nconst useNaiveReduceMethod =\n    (shape: readonly number[], axes: readonly number[], noopWithEmptyAxes: boolean): boolean => {\n      if (axes.length === 0) {\n        return noopWithEmptyAxes;\n      }\n\n      let outputSize = 1;\n      let reduceSize = 1;\n      for (let dim = 0; dim < axes.length; dim++) {\n        if (axes.indexOf(dim) === -1) {\n          outputSize *= shape[dim];\n        } else {\n          reduceSize *= shape[dim];\n        }\n      }\n\n      // The condition data is very rough, although considering the count of Execution Unit (EU), the potential\n      // work groups in a EU and the counts of loops in the naive and shared methods, also doing experiments\n      // on some machines.\n      return reduceSize < 32 && outputSize > 1024;\n    };\n\nexport const reduceMean = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMeanNaive(context, attributes);\n  } else {\n    reduceMeanShared(context, attributes);\n  }\n};\n\nexport const reduceL1 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL1Naive(context, attributes);\n  } else {\n    reduceL1Shared(context, attributes);\n  }\n};\n\nexport const reduceL2 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL2Naive(context, attributes);\n  } else {\n    reduceL2Shared(context, attributes);\n  }\n};\n\nexport const reduceLogSumExp = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumExpNaive(context, attributes);\n  } else {\n    reduceLogSumExpShared(context, attributes);\n  }\n};\n\nexport const reduceMax = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMaxNaive(context, attributes);\n  } else {\n    reduceMaxShared(context, attributes);\n  }\n};\n\nexport const reduceMin = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMinNaive(context, attributes);\n  } else {\n    reduceMinShared(context, attributes);\n  }\n};\n\nexport const reduceProd = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceProdNaive(context, attributes);\n  } else {\n    reduceProdShared(context, attributes);\n  }\n};\n\nexport const reduceSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumNaive(context, attributes);\n  } else {\n    reduceSumShared(context, attributes);\n  }\n};\n\nexport const reduceSumSquare = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumSquareNaive(context, attributes);\n  } else {\n    reduceSumSquareShared(context, attributes);\n  }\n};\n\nexport const reduceLogSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumNaive(context, attributes);\n  } else {\n    reduceLogSumShared(context, attributes);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createReduceProgramInfo, ReduceOp} from './reduce';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('ArgMinMaxOp op requires 1 or 2 inputs.');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Invalid input type.');\n  }\n};\n\nexport interface ArgMinMaxAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  axis: number;\n  selectLastIndex: number;\n}\n\nexport const argMin = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`input_indices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByIndices('input_indices')};\\nvar best_index : i32 = 0;`,\n      `if (${input.getByIndices('input_indices')} ${attributes.selectLastIndex > 0 ? '<=' : '<'} value) {\n         value = ${input.getByIndices('input_indices')};\n         best_index = i32(last_index);\n       }`,\n      '', output.setByOffset('global_idx', 'best_index')\n    ];\n  };\n\n  context.compute(\n      createReduceProgramInfo(\n          'ArgMin', {hint: attributes.cacheKey, inputDependencies: ['rank']}, [context.inputs[0]], argMinMaxOp,\n          [attributes.axis], DataType.int64, attributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const argMax = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`input_indices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByIndices('input_indices')};\\nvar best_index : i32 = 0;`,\n      `if (${input.getByIndices('input_indices')} ${attributes.selectLastIndex > 0 ? '>=' : '>'} value) {\n         value = ${input.getByIndices('input_indices')};\n         best_index = i32(last_index);\n       }`,\n      '', output.setByOffset('global_idx', 'best_index')\n    ];\n  };\n\n  context.compute(\n      createReduceProgramInfo(\n          'argMax', {hint: attributes.cacheKey, inputDependencies: ['rank']}, [context.inputs[0]], argMinMaxOp,\n          [attributes.axis], DataType.int64, attributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const parseArgMinMaxAttributes = (attributes: Record<string, unknown>): ArgMinMaxAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ArgMinMaxAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorDataTypeEnumToString} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ComputeContext, GpuDataType, ProgramUniform} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType, tensorTypeToWsglValueType, UniformDataElementType, UniformsArrayType} from './common';\n\nexport const enum AttentionQkvFormat {\n  unknown,          // enum value not set, or depends on qkv projection implementation details\n  qkvBNSH,          // for non-packed qkv, permuted\n  qkvBSNH,          // for non-packed qkv, not permuted, used by memory efficient attention or MultiHeadAttention\n  qkvBSN3H,         // for TRT fused attention, qkv are packed\n  qkvBNSHqkvBS3NH,  // for TRT fused causal attention, data has two formats (qkv is 3BNSH, gemm_buffer is BS3NH)\n  qKvBSNHxBSN2H,    // for TRT fused cross attention, kv are packed\n  qkvTNH,           // for memory efficient attention, qkv are not packed, and paddings are removed.\n  qkvTN3H,          // for TRT fused attention, qkv are packed and paddings are removed\n}\n\nexport const enum AttentionMaskType {\n  none,                  // No mask\n  mask1dKeySeqLen,       // [batch_size], key sequence length\n  mask1dEndStart,        // [2 * batch_size] with end positions and start positions\n  mask1DKeySeqLenStart,  // [3 * batch_size + 2] with [key_len[0], ..., key_len[batch_size - 1], query_start[0],\n                         // ..., query_start[batch_size - 1], query_end[batch_size - 1], key_start[0], ...,\n                         // key_start[batch_size - 1], key_end[batch_size - 1]]\n  mask2dDummy,           // dummy mask with shape [1, 1] or [batch_size, 1]. It has same effect as no mask.\n  mask2dKeyPadding,      // [batch_size, total_sequence_length]\n  mask3dAttention,       // [batch_size, sequence_length, total_sequence_length]\n  mask4dMegatron,        // Megatron causal mask with shape [batch_size, 1, max_sequence_length, max_sequence_length]\n  maskUnknown\n}\n\nexport interface AttentionParameters {\n  batchSize: number;\n  sequenceLength: number;\n  pastSequenceLength: number;\n  kvSequenceLength: number;\n  totalSequenceLength: number;\n  maxSequenceLength: number;\n  inputHiddenSize: number;\n  hiddenSize: number;\n  vHiddenSize: number;\n  headSize: number;\n  vHeadSize: number;\n  numHeads: number;\n  isUnidirectional: boolean;\n  pastPresentShareBuffer: boolean;\n  maskFilterValue: number;\n  maskType: AttentionMaskType;\n  scale: number;\n  broadcastResPosBias: boolean;\n  passPastInKv: boolean;\n  qkvFormat: AttentionQkvFormat;\n}\n\nexport interface AttentionAttrs {\n  numHeads: number;\n  isUnidirectional: number;\n  maskFilterValue: number;\n  scale: number;\n  doRotary: number;\n  qkvHiddenSizes: number[];\n  pastPresentShareBuffer: boolean;\n}\n\nconst validateAttentionInputs = (inputs: readonly TensorView[], attributes: AttentionAttrs): AttentionParameters => {\n  // Abbreviation and Meanings:\n  //   B:    batch_size\n  //   S:    sequence_length (input sequence length of query)\n  //   P:    past_sequence_length (past sequence length of key or value)\n  //   L:    kv_sequence_length (input sequence length of key or value)\n  //   M:    max_sequence_length\n  //   T:    total_sequence_length = past_sequence_length + kv_sequence_length\n  //   N:    num_heads\n  //   H:    head size for Q and K, aka q_head_size or k_head_size or qk_head_size\n  //   H_v:  v_head_size\n  //   D_i:  input hidden size\n  //   D:    hidden size for Q and K (D = N * H), aka q_hidden_size or k_hidden_size or qk_hidden_size\n  //   D_v:  v_hidden_size = num_heads * v_head_size\n\n  // When past state is used, Q, K and V should have same hidden size (unless we split it into past_key and past_value).\n\n  // Input shapes:\n  //   input        (Q/K/V)    : (B, S, D_i)\n  //   weights      (Q/K/V)    : (D_i, D + D + D_v)\n  //   bias         (Q/K/V)    : (D + D + D_v)\n  //   mask_index              : see below\n  //   past         (K/V)      : (2, B, N, P, H) or NULL\n  //   relative_position_bias            : (B, N, S, T) or NULL\n\n  // For mask_index, the following shapes are supported:\n  //     NULL, (B, 1), (1, 1)\n  //     (B), (2 * B), (3 * B + 2)\n  //     (B, T)\n  //     (B, S, T)\n  //     (B, 1, M, M)\n  //\n  // When a model is pruned (like some attention heads are removed in Q/K/V), input_hidden_size could be larger\n  // than hidden dimension of Q, K and V.\n\n  const input = inputs[0];\n  const weights = inputs[1];\n  const bias = inputs[2];\n  const maskIndex = inputs[3];\n  const past = inputs[4];\n  const relativePositionBias = inputs[5];\n\n  if (past && relativePositionBias) {\n    throw new Error('Attention cannot have both past and relative_position_bias');\n  }\n\n  if (input.dims.length !== 3) {\n    throw new Error('Input \"input\" must have 3 dimensions');\n  }\n\n  const batchSize = input.dims[0];\n  const sequenceLength = input.dims[1];\n  const inputHiddenSize = input.dims[2];\n\n  if (bias.dims.length !== 1) {\n    throw new Error('Input \"bias\" is expected to have 1 dimensions');\n  }\n\n  if (weights.dims.length !== 2) {\n    throw new Error('Input \"weights\" is expected to have 2 dimensions');\n  }\n\n  if (weights.dims[0] !== inputHiddenSize) {\n    throw new Error('Input 1 dimension 0 should have same length as dimension 2 of input 0');\n  }\n\n  if (bias.dims[0] !== weights.dims[1]) {\n    throw new Error('Input \"bias\" dimension 0 should have same length as dimension 1 of input \"weights\"');\n  }\n\n  let qHiddenSize = bias.dims[0] / 3;\n  let kHiddenSize = qHiddenSize;\n  let vHiddenSize = kHiddenSize;\n  if (attributes.qkvHiddenSizes.length > 0) {\n    if (attributes.qkvHiddenSizes.length !== 3) {\n      throw new Error('qkv_hidden_sizes attribute should have 3 elements');\n    }\n    for (const sz of attributes.qkvHiddenSizes) {\n      if (sz % attributes.numHeads !== 0) {\n        throw new Error('qkv_hidden_sizes should be divisible by num_heads');\n      }\n    }\n\n    qHiddenSize = attributes.qkvHiddenSizes[0];\n    kHiddenSize = attributes.qkvHiddenSizes[1];\n    vHiddenSize = attributes.qkvHiddenSizes[2];\n  }\n\n  const kvSequenceLength = sequenceLength;\n\n  if (qHiddenSize !== kHiddenSize) {\n    throw new Error('qkv_hidden_sizes first element should be same as the second');\n  }\n\n  if (bias.dims[0] !== qHiddenSize + kHiddenSize + vHiddenSize) {\n    throw new Error('Input \"bias\" dimension 0 should have same length as sum of Q/K/V hidden sizes');\n  }\n\n  let pastSequenceLength = 0;\n  if (past) {\n    if (kHiddenSize !== vHiddenSize) {\n      throw new Error('Input \"past\" expect k_hidden_size == v_hidden_size');\n    }\n    if (past.dims.length !== 5) {\n      throw new Error('Input \"past\" must have 5 dimensions');\n    }\n    if (past.dims[0] !== 2) {\n      throw new Error('Input \"past\" first dimension must be 2');\n    }\n    if (past.dims[1] !== batchSize) {\n      throw new Error('Input \"past\" second dimension must be batch_size');\n    }\n    if (past.dims[2] !== attributes.numHeads) {\n      throw new Error('Input \"past\" third dimension must be num_heads');\n    }\n    if (past.dims[4] !== kHiddenSize / attributes.numHeads) {\n      throw new Error('Input \"past\" fifth dimension must be k_hidden_size / num_heads');\n    }\n\n    if (!attributes.pastPresentShareBuffer) {\n      pastSequenceLength = past.dims[3];\n    }\n    // TODO: handle past_seq_len\n  }\n\n  const totalSequenceLength = kvSequenceLength + pastSequenceLength;\n  const maxSequenceLength = -1;\n\n  const maskType = AttentionMaskType.none;\n  if (maskIndex) {\n    // maskType = AttentionMaskType.MASK_UNKNOWN;\n    // TODO: handle mask\n    throw new Error('Mask not supported');\n  }\n\n  if (past) {\n    throw new Error('past is not supported');\n  }\n  if (relativePositionBias) {\n    throw new Error('relativePositionBias is not supported');\n  }\n\n  return {\n    batchSize,\n    sequenceLength,\n    pastSequenceLength,\n    kvSequenceLength,\n    totalSequenceLength,\n    maxSequenceLength,\n    inputHiddenSize,\n    hiddenSize: qHiddenSize,\n    vHiddenSize,\n    headSize: Math.floor(qHiddenSize / attributes.numHeads),\n    vHeadSize: Math.floor(vHiddenSize / attributes.numHeads),\n    numHeads: attributes.numHeads,\n    isUnidirectional: false,\n    pastPresentShareBuffer: false,\n    maskFilterValue: attributes.maskFilterValue,\n    maskType,\n    scale: attributes.scale,\n    broadcastResPosBias: false,\n    passPastInKv: false,\n    qkvFormat: AttentionQkvFormat.qkvBNSH,\n  };\n};\n\nexport const computeInPlaceSoftmax = (context: ComputeContext, input: TensorView, n: number, d: number) => {\n  const components = getMaxComponents(d);\n  let WG = 64;\n  const dComp = d / components;\n  if (dComp < WG) {\n    WG = 1;\n  } else if (dComp / 8 < 64) {\n    WG = Math.ceil(dComp / 8);\n  }\n  const elementsPerWG = Math.ceil(d / components / WG);\n  const tensorDataType = tensorDataTypeEnumToString(input.dataType) as ProgramUniform['type'];\n  const programUniforms: ProgramUniform[] =\n      [{type: tensorDataType, data: 1 / d}, {type: 'uint32', data: dComp}, {type: 'uint32', data: elementsPerWG}];\n  const dataType = tensorTypeToWsglStorageType(input.dataType, components);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const inputHelper = outputVariable('x', input.dataType, input.dims, components);\n    let threadMaxValue = 'thread_max_vector';\n    if (components === 2) {\n      threadMaxValue = 'max(thread_max_vector.x, thread_max_vector.y)';\n    } else if (components === 4) {\n      threadMaxValue =\n          'max(max(thread_max_vector.x, thread_max_vector.y), max(thread_max_vector.z, thread_max_vector.w))';\n    }\n    const elemValueType = tensorTypeToWsglValueType(input.dataType);\n    const uniforms: UniformsArrayType = [\n      {name: 'd_inv', type: elemValueType as UniformDataElementType}, {name: 'd_comp', type: 'u32'},\n      {name: 'elements_per_wg', type: 'u32'}\n    ];\n\n    return `\n  var<workgroup> wgMax: array<f32, ${WG}>;\n  var<workgroup> wgSum: array<f32, ${WG}>;\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(inputHelper)}\n  ${shaderHelper.mainStart([\n      WG, 1, 1\n    ])}\n    let localOffset = local_idx * uniforms.elements_per_wg;\n    let offset: u32 = workgroup_id.x * uniforms.d_comp + localOffset;\n\n    var thread_max_vector = ${fillVector('f32', components, '-3.402823e+38f')};\n    for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n      thread_max_vector = max(${castToF32(elemValueType, components, 'x[offset + i]')}, thread_max_vector);\n    }\n    wgMax[local_idx] = ${threadMaxValue};\n    workgroupBarrier();\n\n    var maxValue = -3.402823e+38f;\n    for (var i = 0u; i < ${WG}; i++) {\n      maxValue = max(wgMax[i], maxValue);\n    }\n\n    var sumVector = ${fillVector('f32', components, '0')};\n    for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n      sumVector += exp(${castToF32(elemValueType, components, 'x[offset + i]')} - maxValue);\n    }\n    wgSum[local_idx] = ${sumVector('sumVector', components)};\n    workgroupBarrier();\n\n    var sum: f32 = 0;\n    for (var i = 0u; i < ${WG}; i++) {\n      sum += wgSum[i];\n    }\n\n    if (sum == 0) {\n      for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n        x[offset + i] = ${fillVector('f32', components, 'uniforms.d_inv')};\n      }\n    } else {\n      for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n        let f32input = ${castToF32(elemValueType, components, 'x[offset + i]')};\n        x[offset + i] = ${inputHelper.type.value}(exp(f32input - maxValue) / sum);\n      }\n    }\n  }`;\n  };\n\n  context.compute(\n      {\n        name: 'AttentionProbsSoftmax',\n        shaderCache: {hint: `${WG};${dataType};${components}`},\n        getShaderSource,\n        getRunData: () => ({outputs: [], dispatchGroup: {x: n}, programUniforms}),\n      },\n      {inputs: [input], outputs: []});\n};\n\nconst computeAttentionProbs =\n    (context: ComputeContext, q: TensorView, key: TensorView, _bias: TensorView|undefined,\n     parameters: AttentionParameters, attributes: AttentionAttrs) => {\n      const probsShape = [\n        parameters.batchSize, parameters.numHeads, parameters.sequenceLength,\n        parameters.kvSequenceLength + parameters.pastSequenceLength\n      ];\n      // TODO: handle mask\n\n      const alpha = attributes.scale === 0 ? 1.0 / Math.sqrt(parameters.headSize) : attributes.scale;\n      const components = getMaxComponents(parameters.headSize);\n      const vectorizedHeadSize = parameters.headSize / components;\n      const TILE_SIZE = 12;\n      const dispatch = {\n        x: Math.ceil(parameters.totalSequenceLength / TILE_SIZE),\n        y: Math.ceil(parameters.sequenceLength / TILE_SIZE),\n        z: parameters.batchSize * parameters.numHeads\n      };\n      const tensorDataType = tensorDataTypeEnumToString(q.dataType) as ProgramUniform['type'];\n      const programUniforms: ProgramUniform[] = [\n        {type: 'uint32', data: parameters.sequenceLength}, {type: 'uint32', data: vectorizedHeadSize},\n        {type: 'uint32', data: parameters.totalSequenceLength}, {type: 'uint32', data: parameters.kvSequenceLength},\n        {type: tensorDataType, data: alpha}\n      ];\n\n      const inputs = [q, key];\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const qInput = inputVariable('q', q.dataType, q.dims, components);\n        const kInput = inputVariable('key', key.dataType, key.dims, components);\n        const output = outputVariable('output', q.dataType, probsShape);\n        const dataType = tensorTypeToWsglStorageType(q.dataType);\n\n        const uniforms: UniformsArrayType = [\n          {name: 'M', type: 'u32'}, {name: 'K', type: 'u32'}, {name: 'N', type: 'u32'},\n          {name: 'kv_sequence_length', type: 'u32'}, {name: 'alpha', type: dataType as UniformDataElementType}\n        ];\n        return `\n  const beta: ${dataType} = 1.0;\n  const TILE_SIZE = ${TILE_SIZE}u;\n\n  var<workgroup> tileQ: array<${qInput.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileK: array<${qInput.type.storage}, ${TILE_SIZE * TILE_SIZE}>;\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(qInput, kInput, output)}\n  ${shaderHelper.mainStart([\n          TILE_SIZE, TILE_SIZE, 1\n        ])}\n    // x holds the N and y holds the M\n    let headIdx = workgroup_id.z;\n    let m = workgroup_id.y * TILE_SIZE;\n    let n = workgroup_id.x * TILE_SIZE;\n    let lm = m + local_id.y;\n    let ln = n + local_id.x;\n\n    let qOffset = uniforms.M * uniforms.K * headIdx + m * uniforms.K;\n    let kOffset = uniforms.kv_sequence_length * uniforms.K * headIdx + n * uniforms.K;\n\n    var value = ${fillVector(dataType, components)};\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (m + local_id.y < uniforms.M && w + local_id.x < uniforms.K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * uniforms.K + w + local_id.x];\n      }\n      if (n + local_id.y < uniforms.N && w + local_id.x < uniforms.K) {\n        tileK[TILE_SIZE * local_id.y + local_id.x] = key[kOffset + local_id.y * uniforms.K + w + local_id.x];\n      }\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n        value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = headIdx * uniforms.M * uniforms.N;\n    if (lm < uniforms.M && ln < uniforms.N) {\n      let outputIdx = headOffset + lm * uniforms.N + ln;\n      output[outputIdx] = ${sumVector('value', components)} * uniforms.alpha;\n    }\n  }`;\n      };\n\n      const probs = context.compute(\n          {\n            name: 'AttentionProbs',\n            shaderCache: {hint: `${components}`, inputDependencies: ['type', 'type']},\n            getRunData: () => ({\n              outputs: [{dims: probsShape, dataType: q.dataType, gpuDataType: GpuDataType.default}],\n              dispatchGroup: dispatch,\n              programUniforms\n            }),\n            getShaderSource,\n          },\n          {inputs, outputs: [-1]})[0];\n\n      computeInPlaceSoftmax(\n          context, probs, parameters.batchSize * parameters.numHeads * parameters.sequenceLength,\n          parameters.totalSequenceLength);\n\n      return probs;\n    };\n\nconst computeVxAttentionScore =\n    (context: ComputeContext, probs: TensorView, v: TensorView, params: AttentionParameters) => {\n      const outputShape = [params.batchSize, params.sequenceLength, params.vHiddenSize];\n      const TILE_SIZE = 12;\n      const dispatch = {\n        x: Math.ceil(params.vHeadSize / TILE_SIZE),\n        y: Math.ceil(params.sequenceLength / TILE_SIZE),\n        z: params.batchSize * params.numHeads\n      };\n      const programUniforms: ProgramUniform[] = [\n        {type: 'uint32', data: params.sequenceLength}, {type: 'uint32', data: params.totalSequenceLength},\n        {type: 'uint32', data: params.vHeadSize}, {type: 'uint32', data: params.numHeads},\n        {type: 'uint32', data: params.vHiddenSize}\n      ];\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const probsHelper = inputVariable('probs', probs.dataType, probs.dims);\n        const vHelper = inputVariable('v', v.dataType, v.dims);\n        const output = outputVariable('output', probs.dataType, outputShape);\n        const uniforms: UniformsArrayType = [\n          {name: 'M', type: 'u32'}, {name: 'K', type: 'u32'}, {name: 'N', type: 'u32'},\n          {name: 'num_heads', type: 'u32'}, {name: 'v_hidden_size', type: 'u32'}\n        ];\n        return `\n  const TILE_SIZE = ${TILE_SIZE}u;\n  var<workgroup> tileQ: array<${probsHelper.type.value}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileK: array<${probsHelper.type.value}, ${TILE_SIZE * TILE_SIZE}>;\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(probsHelper, vHelper, output)}\n  ${shaderHelper.mainStart([\n          TILE_SIZE, TILE_SIZE, 1\n        ])}\n   let headIdx = workgroup_id.z;\n   let m = workgroup_id.y * TILE_SIZE + local_id.y;\n   let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n   let offsetA = headIdx * (uniforms.M * uniforms.K) + m * uniforms.K;\n   let offsetB = headIdx * (uniforms.N * uniforms.K) + n;\n\n   var value = ${probsHelper.type.storage}(0);\n   for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n     if (m < uniforms.M && w + local_id.x < uniforms.K) {\n       tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];\n     }\n     if (n < uniforms.N && w + local_id.y < uniforms.K) {\n       tileK[TILE_SIZE * local_id.y + local_id.x] = v[offsetB + (w + local_id.y) * uniforms.N];\n     }\n     workgroupBarrier();\n     for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n       value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * k + local_id.x];\n     }\n     workgroupBarrier();\n   }\n\n   // we need to transpose output from BNSH_v to BSND_v\n   let batchIdx = workgroup_id.z / uniforms.num_heads;\n   let currentBatchHeadNumber = workgroup_id.z % uniforms.num_heads;\n   let headOffset = (batchIdx * uniforms.M * uniforms.num_heads + currentBatchHeadNumber) * uniforms.N;\n   if (m < uniforms.M && n < uniforms.N) {\n     let outputIdx = batchIdx * uniforms.M *uniforms.v_hidden_size + m * uniforms.v_hidden_size\n       + currentBatchHeadNumber * uniforms.N + n;\n     output[outputIdx] = value;\n   }\n  }`;\n      };\n\n      return context.compute(\n          {\n            name: 'AttentionScore',\n            shaderCache: {inputDependencies: ['type', 'type']},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: probs.dataType, gpuDataType: GpuDataType.default}],\n              dispatchGroup: dispatch,\n              programUniforms\n            }),\n            getShaderSource,\n          },\n          {inputs: [probs, v], outputs: [0]})[0];\n    };\n\nexport const applyAttention =\n    (context: ComputeContext, q: TensorView, k: TensorView, v: TensorView, _maskIndex: TensorView|undefined,\n     _past: TensorView|undefined, _pastKey: TensorView|undefined, _pastValue: TensorView|undefined,\n     relativePositionBias: TensorView|undefined, parameters: AttentionParameters, attributes: AttentionAttrs) => {\n      const probs = computeAttentionProbs(context, q, k, relativePositionBias, parameters, attributes);\n\n      computeVxAttentionScore(context, probs, v, parameters);\n    };\n\nconst prepare = (context: ComputeContext, parameters: AttentionParameters) => {\n  const outputShape = [\n    parameters.batchSize,\n    parameters.numHeads,\n    parameters.sequenceLength,\n    parameters.headSize,\n  ];\n  const M = parameters.sequenceLength;\n  const K = parameters.inputHiddenSize;\n  const N = parameters.headSize;\n  const TILE_SIZE = 12;\n  const dispatch = {\n    x: Math.ceil(parameters.headSize / TILE_SIZE),\n    y: Math.ceil(parameters.sequenceLength / TILE_SIZE),\n    z: parameters.batchSize * parameters.numHeads\n  };\n  const inputs = [context.inputs[0], context.inputs[1], context.inputs[2]];\n  const programUniforms: ProgramUniform[] = [\n    {type: 'uint32', data: M}, {type: 'uint32', data: K}, {type: 'uint32', data: N},\n    {type: 'uint32', data: parameters.numHeads}, {type: 'uint32', data: parameters.headSize},\n    {type: 'uint32', data: parameters.hiddenSize},\n    {type: 'uint32', data: parameters.hiddenSize + parameters.hiddenSize + parameters.vHiddenSize}\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const outputQ = outputVariable('output_q', inputs[0].dataType, outputShape);\n    const outputK = outputVariable('output_k', inputs[0].dataType, outputShape);\n    const outputV = outputVariable('output_v', inputs[0].dataType, outputShape);\n    const input = inputVariable('input', inputs[0].dataType, inputs[0].dims);\n    const weight = inputVariable('weight', inputs[1].dataType, inputs[1].dims);\n    const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims);\n    const dataType = input.type.storage;\n\n    const uniforms: UniformsArrayType = [\n      {name: 'M', type: 'u32'}, {name: 'K', type: 'u32'}, {name: 'N', type: 'u32'}, {name: 'num_heads', type: 'u32'},\n      {name: 'head_size', type: 'u32'}, {name: 'hidden_size', type: 'u32'}, {name: 'ldb', type: 'u32'}\n    ];\n    return `\n  const TILE_SIZE = ${TILE_SIZE}u;\n  var<workgroup> tileInput: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightQ: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightK: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  var<workgroup> tileWeightV: array<${dataType}, ${TILE_SIZE * TILE_SIZE}>;\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(input, weight, bias, outputQ, outputK, outputV)}\n  ${shaderHelper.mainStart([\n      TILE_SIZE, TILE_SIZE, 1\n    ])}\n    let batchIndex = workgroup_id.z / uniforms.num_heads;\n    let headNumber = workgroup_id.z % uniforms.num_heads;\n    let m = workgroup_id.y * TILE_SIZE + local_id.y;\n    let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n    let inputOffset = batchIndex * (uniforms.M * uniforms.K) + m * uniforms.K;\n    let biasOffsetQ = headNumber * uniforms.head_size;\n    let biasOffsetK = uniforms.hidden_size + biasOffsetQ;\n    let biasOffsetV = uniforms.hidden_size + biasOffsetK;\n\n    var valueQ = ${dataType}(0);\n    var valueK = ${dataType}(0);\n    var valueV = ${dataType}(0);\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (m < uniforms.M && w + local_id.x < uniforms.K) {\n        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];\n      }\n      if (n < uniforms.N && w + local_id.y < uniforms.K) {\n        let offset = n + (w + local_id.y) * uniforms.ldb;\n        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];\n        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];\n        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];\n      }\n      workgroupBarrier();\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n        let inputTileOffset = TILE_SIZE * local_id.y + k;\n        let weightTileOffset = TILE_SIZE * k + local_id.x;\n        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];\n        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];\n        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = (m * uniforms.N + n) % uniforms.head_size;\n    valueQ += bias[headOffset + biasOffsetQ];\n    valueK += bias[headOffset + biasOffsetK];\n    valueV += bias[headOffset + biasOffsetV];\n\n    let offset = workgroup_id.z * uniforms.M * uniforms.N;\n    if (m < uniforms.M && n < uniforms.N) {\n      let outputIdx = offset + m * uniforms.N + n;\n      output_q[outputIdx] = valueQ;\n      output_k[outputIdx] = valueK;\n      output_v[outputIdx] = valueV;\n    }\n  }`;\n  };\n\n  return context.compute(\n      {\n        name: 'AttentionPrepare',\n        shaderCache: {inputDependencies: ['type', 'type', 'type']},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default},\n            {dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default},\n            {dims: outputShape, dataType: context.inputs[0].dataType, gpuDataType: GpuDataType.default},\n          ],\n          dispatchGroup: dispatch,\n          programUniforms\n        }),\n        getShaderSource,\n      },\n      {inputs, outputs: [-1, -1, -1]});\n};\n\nexport const attention = (context: ComputeContext, attributes: AttentionAttrs): void => {\n  const params = validateAttentionInputs(context.inputs, attributes);\n\n  const [q, k, v] = prepare(context, params);\n\n  return applyAttention(\n      context, q, k, v, context.inputs[4], undefined, undefined, undefined, context.inputs[5], params, attributes);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from 'onnxruntime-common';\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, getMaxComponents, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface BatchNormAttributes extends AttributeWithCacheKey {\n  readonly epsilon: number;\n  readonly momentum: number;\n  readonly spatial: boolean;\n  readonly trainingMode: boolean;\n  readonly format: 'NHWC'|'NCHW';\n  readonly outputCount: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: BatchNormAttributes): void => {\n  if (!inputs || inputs.length !== 5) {\n    throw new Error('BatchNormalization requires 5 inputs');\n  }\n\n  const checkShapeEqual = (actual: readonly number[], expected: readonly number[], message: string) => {\n    const r = expected.length;\n    if (r !== actual.length) {\n      throw new Error(`${message}: num dimensions != ${r}`);\n    }\n    expected.forEach((v, i) => {\n      if (v !== actual[i]) {\n        throw new Error(`${message}: dim[${i}] do not match`);\n      }\n    });\n  };\n\n  if (inputs[0].dims.length > 1) {\n    const shape = attributes.format === 'NHWC' ?\n        (attributes.spatial ? inputs[0].dims.slice(-1) :\n                              inputs[0].dims.slice(-1).concat(inputs[0].dims.slice(1, inputs[0].dims.length - 1))) :\n        inputs[0].dims.slice(1, attributes.spatial ? 2 : undefined);\n    checkShapeEqual(inputs[1].dims, shape, 'Invalid input scale');\n    checkShapeEqual(inputs[2].dims, shape, 'Invalid input B');\n    checkShapeEqual(inputs[3].dims, shape, 'Invalid input mean');\n    checkShapeEqual(inputs[4].dims, shape, 'Invalid input var');\n  } else {\n    checkShapeEqual(inputs[1].dims, [1], 'Invalid input scale');\n    checkShapeEqual(inputs[2].dims, [1], 'Invalid input B');\n    checkShapeEqual(inputs[3].dims, [1], 'Invalid input mean');\n    checkShapeEqual(inputs[4].dims, [1], 'Invalid input var');\n  }\n};\n\nconst createBatchNormInferenceProgramInfo =\n    (inputs: readonly TensorView[], attributes: BatchNormAttributes): ProgramInfo => {\n      const {epsilon, spatial, format} = attributes;\n      const yShape = inputs[0].dims;\n      const components = spatial ? getMaxComponents(yShape[yShape.length - 1]) : 1;\n      const cComponents = format === 'NHWC' && yShape.length > 1 ? components : 1;\n      const outputSize = ShapeUtil.size(yShape) / components;\n      // Only support uniforms for opset version >= 9 (spatial = true).\n      const useShapesUniforms = enableShapesUniforms(yShape.length) && spatial;\n      const shapeOrRank = useShapesUniforms ? yShape.length : yShape;\n      const x = inputVariable('x', inputs[0].dataType, inputs[0].dims, components);\n      const scale = inputVariable('scale', inputs[1].dataType, inputs[1].dims, cComponents);\n      const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims, cComponents);\n      const inputMean = inputVariable('inputMean', inputs[3].dataType, inputs[3].dims, cComponents);\n      const inputVar = inputVariable('inputVar', inputs[4].dataType, inputs[4].dims, cComponents);\n      const y = outputVariable('y', inputs[0].dataType, shapeOrRank, components);\n      // TODO: support inputs with different data type. Current we need to make sure all inputs have the same data type.\n      // Otherwise, the shader compilation will fail.\n      const calcCOffset = (): string => {\n        let cOffset = '';\n        if (spatial) {\n          cOffset = `let cOffset = ${\n              yShape.length === 1   ? '0u' :\n                  format === 'NHWC' ? `outputIndices[${yShape.length - 1}] / ${components}` :\n                                      'outputIndices[1]'};`;\n        } else {\n          if (format === 'NCHW') {\n            cOffset = `\n            ${y.indicesSet('outputIndices', '0', '0')}\n            let cOffset = ${y.indicesToOffset('outputIndices')};`;\n          } else {\n            // update C channel.\n            cOffset = `var cIndices = ${scale.type.indices}(0);\n                       cIndices[0] = outputIndices[${yShape.length - 1}];`;\n            // update D1 x ... x Dn channels.\n            for (let i = 1; i < scale.rank; i++) {\n              cOffset += `cIndices[${i}] = outputIndices[${i}];`;\n            }\n            cOffset += `let cOffset = ${scale.indicesToOffset('cIndices')};`;\n          }\n        }\n        return cOffset;\n      };\n      const getInferenceModeShaderSource = (helper: ShaderHelper) => `\n  const epsilon = ${epsilon};\n  ${helper.registerUniform('outputSize', 'u32').declareVariables(x, scale, bias, inputMean, inputVar, y)}\n  ${helper.mainStart()}\n  ${helper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n    var outputIndices = ${y.offsetToIndices(`global_idx * ${components}`)};\n    ${calcCOffset()}\n    let scale = ${scale.getByOffset('cOffset')};\n    let bias = ${bias.getByOffset('cOffset')};\n    let inputMean = ${inputMean.getByOffset('cOffset')};\n    let inputVar = ${inputVar.getByOffset('cOffset')};\n    let x = ${x.getByOffset('global_idx')};\n    let value = (x - inputMean) / sqrt(inputVar + epsilon) * scale + bias;\n    ${y.setByOffset('global_idx', 'value')}\n  }`;\n      return {\n        name: 'BatchNormalization',\n        shaderCache: {\n          hint: `${attributes.epsilon}_${attributes.format}_${spatial}_${components}`,\n          inputDependencies: useShapesUniforms ? ['rank', 'type', 'type', 'type', 'type'] : undefined,\n        },\n        getShaderSource: getInferenceModeShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: inputs[0].dims, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n          programUniforms: useShapesUniforms ?\n              [\n                {type: 'uint32', data: outputSize},\n                ...createTensorShapeVariables(yShape),\n              ] :\n              [\n                {type: 'uint32', data: outputSize},\n              ],\n        }),\n      };\n    };\n\nexport const parseBatchNormAttributes = (attributes: Record<string, unknown>): BatchNormAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<BatchNormAttributes, keyof AttributeWithCacheKey>);\n\nexport const batchNorm = (context: ComputeContext, attributes: Record<string, unknown>): void => {\n  const {inputs, outputCount} = context;\n  const updatedAttributes = parseBatchNormAttributes({...attributes, outputCount});\n  if (env.webgpu.validateInputContent) {\n    validateInputs(inputs, updatedAttributes);\n  }\n  if (attributes.trainingMode) {\n    throw new Error('BatchNormalization trainingMode is not supported yet.');\n  } else {\n    context.compute(createBatchNormInferenceProgramInfo(inputs, updatedAttributes));\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![320, 640, 1280].includes(inputs[0].dims[2])) {\n    throw new Error('number of channels should be 320, 640 or 1280');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasAddProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims;\n\n  const channels = inputs[0].dims[2];\n  // since channel number can be only 320/640/1280, it's always divisable by 4\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, outputShape, 4);\n  const bias = inputVariable('bias', dataType, [channels], 4);\n  const residual = inputVariable('residual', dataType, outputShape, 4);\n  const output = outputVariable('output', dataType, outputShape, 4);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const channels = ${channels}u / 4;\n  ${shaderHelper.declareVariables(input, bias, residual, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let value = ${input.getByOffset('global_idx')}\n      + ${bias.getByOffset('global_idx % channels')} + ${residual.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n\n  return {\n    name: 'BiasAdd',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasAdd = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasAddProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {MAX_CLIP, MIN_CLIP, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglValueType} from './common';\n\ntype BuiltinFunctionName = string;\ntype ElementwiseCustomExpression = (expression: string) => string;\ntype ElementwiseFunctionCall = BuiltinFunctionName|ElementwiseCustomExpression;\n\nconst createElementwiseProgramShader =\n    (shaderHelper: ShaderHelper, datasize: number, inputDataType: number, outputDataType: number,\n     funcCall: ElementwiseFunctionCall, additionalImplementation?: string): string => {\n      const vecSize = Math.ceil(datasize / 4);\n\n      let expression = '';\n      if (typeof funcCall === 'string') {\n        expression = `${funcCall}(a)`;\n      } else {\n        expression = funcCall('a');\n      }\n\n      const input = inputVariable('inputData', inputDataType, [vecSize], 4);\n      const output = outputVariable('outputData', outputDataType, [vecSize], 4);\n\n      return `\n      ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(input, output)}\n\n  ${additionalImplementation ?? ''}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n\n    let a = ${input.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', expression)}\n  }`;\n    };\n\nconst createElementwiseProgramInfo =\n    (input: TensorView, name: string, funcCall: ElementwiseFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType: number = input.dataType): ProgramInfo => ({\n      name,\n      shaderCache: {hint: cacheKey, inputDependencies: ['type']},\n      getShaderSource: shaderHelper => createElementwiseProgramShader(\n          shaderHelper, ShapeUtil.size(input.dims), input.dataType, outputDataType, funcCall, additionalImplementation),\n      getRunData: (inputTensors) => ({\n        outputs: [{dims: input.dims, dataType: outputDataType}],\n        dispatchGroup:\n            {x: Math.ceil(ShapeUtil.size(inputTensors[0].dims) / 64 /* workgroup size */ / 4 /* vec size */)},\n        programUniforms: [\n          {type: 'uint32', data: Math.ceil(ShapeUtil.size(input.dims) / 4)},\n        ],\n      })\n    });\n\nexport const abs = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Abs', 'abs'));\n};\n\nexport const acos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acos', 'acos'));\n};\n\nexport const acosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acosh', 'acosh'));\n};\n\nexport const asin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asin', 'asin'));\n};\n\nexport const asinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asinh', 'asinh'));\n};\n\nexport const atan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atan', 'atan'));\n};\nexport const atanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atanh', 'atanh'));\n};\n\nexport interface CastAttributes extends AttributeWithCacheKey {\n  readonly to: number;\n  readonly saturate?: boolean;\n}\n\nexport const parseCastAttributes = (attributes: Record<string, unknown>): CastAttributes =>\n    createAttributeWithCacheKey(attributes as {to: number});\n\n\nexport const cast = (context: ComputeContext, attributes: CastAttributes): void => {\n  let func: ElementwiseFunctionCall;\n  switch (attributes.to) {\n    case DataType.float16:\n      func = 'vec4<f16>';\n      break;\n    case DataType.float:\n      func = 'vec4<f32>';\n      break;\n    case DataType.uint32:\n      func = 'vec4<u32>';\n      break;\n    case DataType.int32:\n      func = 'vec4<i32>';\n      break;\n    case DataType.bool:\n      func = 'vec4<bool>';\n      break;\n    default:\n      throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${attributes.to}`);\n  }\n  context.compute(\n      createElementwiseProgramInfo(context.inputs[0], 'Cast', func, undefined, attributes.cacheKey, attributes.to));\n};\n\nexport interface ClipAttributes extends AttributeWithCacheKey {\n  readonly min: number;\n  readonly max: number;\n}\n\nconst generateClipAttributesFromInputs = (inputs: readonly TensorView[]): ClipAttributes => {\n  const min = (inputs.length >= 2 && inputs[1].data !== 0) ? inputs[1].getFloat32Array()[0] : MIN_CLIP;\n  const max = (inputs.length >= 3 && inputs[2].data !== 0) ? inputs[2].getFloat32Array()[0] : MAX_CLIP;\n  return createAttributeWithCacheKey({min, max});\n};\n\nexport const clip = (context: ComputeContext, clipAttributes: ClipAttributes): void => {\n  const attributes = context.inputs.length === 1 ? clipAttributes : generateClipAttributesFromInputs(context.inputs);\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(\n      createElementwiseProgramInfo(\n          context.inputs[0], 'Clip', a => `clamp(${a}, clip_min_, clip_max_)`, `\n    const clip_min_: vec4<${dataType}> = vec4(${dataType}(${attributes.min}));\n    const clip_max_: vec4<${dataType}> = vec4(${dataType}(${attributes.max}));\n`,\n          attributes.cacheKey),\n      {inputs: [0]});\n};\n\nexport const ceil = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Ceil', 'ceil'));\n};\n\nexport const cos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cos', 'cos'));\n};\n\nexport const cosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cosh', 'cosh'));\n};\n\nexport interface AlphaAttributes extends AttributeWithCacheKey {\n  readonly alpha: number;\n}\n\nexport const parseAlphaAttributes = (attributes: Record<string, unknown>): AlphaAttributes =>\n    createAttributeWithCacheKey(attributes as {alpha: number});\n\nexport const elu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Elu', a => `elu_vf32(${a})`, `\n  const elu_alpha_ = ${dataType}(${attributes.alpha});\n\n  fn elu_f32(a: ${dataType}) -> ${dataType} {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<${dataType}>) -> vec4<${dataType}> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,\n      attributes.cacheKey));\n};\n\nexport const erfImpl = (dataType: string, varType = 'f32') => `\nconst r0: ${varType} = 0.3275911;\nconst r1: ${varType} = 0.254829592;\nconst r2: ${varType} = -0.284496736;\nconst r3: ${varType} = 1.421413741;\nconst r4: ${varType} = -1.453152027;\nconst r5: ${varType} = 1.061405429;\n\nfn erf_vf32(v: ${dataType}) -> ${dataType} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`;\n\nexport const erf = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Erf', a => `erf_vf32(${a})`, erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const exp = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Exp', 'exp'));\n};\n\nexport const floor = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Floor', 'floor'));\n};\n\nexport const gelu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Gelu', a => `0.5 * ${a} * (1.0 + erf_vf32(${a} * 0.7071067811865475))`,\n      erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const leakyRelu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'LeakyRelu', a => `select(leaky_relu_alpha_ * ${a}, ${a}, ${a} >= vec4<${dataType}>(0.0))`,\n      `const leaky_relu_alpha_ = ${dataType}(${attributes.alpha});`, attributes.cacheKey));\n};\n\nexport const not = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Not', a => `!${a}`));\n};\n\nexport const neg = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Neg', a => `-${a}`));\n};\n\nexport const reciprocal = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Reciprocal', a => `1.0/${a}`));\n};\n\nexport const relu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Relu', a => `select(vec4<${dataType}>(0.0), ${a}, ${a} > vec4<${dataType}>(0.0))`));\n};\n\nexport const sigmoid = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sigmoid', a => `(1.0 / (1.0 + exp(-${a})))`));\n};\n\nexport const sin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sin', 'sin'));\n};\n\nexport const sinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sinh', 'sinh'));\n};\n\nexport const sqrt = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sqrt', 'sqrt'));\n};\n\nexport const tan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tan', 'tan'));\n};\n\nexport const tanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tanh', 'tanh'));\n};\n\nexport const thresholdedRelu = (context: ComputeContext, attributes: AlphaAttributes): number => {\n  const dataType = tensorTypeToWsglValueType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'ThresholdedRelu', a => `select(vec4<${dataType}>(0.0), ${a}, ${a} > thresholded_relu_alpha_)`,\n      `const thresholded_relu_alpha_ = vec4<${dataType}>(${attributes.alpha});`, attributes.cacheKey));\n  return 0;\n};\n\nexport const log = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Log', 'log'));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\nimport {erfImpl} from './unary-op';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![2560, 5120, 10240].includes(inputs[0].dims[2])) {\n    throw new Error('hidden state should be 2560, 5120 or 10240');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasSplitGeluProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims.slice();\n  outputShape[2] = outputShape[2] / 2;\n\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims, 4);\n  const bias = inputVariable('bias', inputs[0].dataType, [inputs[0].dims[2]], 4);\n  const output = outputVariable('output', inputs[0].dataType, outputShape, 4);\n\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n  const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${inputs[0].dims[2] / 4 / 2}u;\n\n  ${shaderHelper.declareVariables(input, bias, output)}\n\n  ${erfImpl(`vec4<${dataType}>`, dataType)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${output.setByOffset('global_idx', 'valueLeft * geluRight')}\n  }`;\n\n  return {\n    name: 'BiasSplitGelu',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasSplitGelu = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasSplitGeluProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype BuiltinFunctionName = string;\ntype BinaryCustomExpression = (expressionA: string, expressionB: string) => string;\ntype BinaryFunctionCall = BuiltinFunctionName|BinaryCustomExpression|{\n  scalar: BinaryCustomExpression;\n  vector: BinaryCustomExpression;\n};\n\nconst createBinaryOpProgramShader =\n    (shaderHelper: ShaderHelper, dimsA: readonly number[], dimsB: readonly number[], dimsOutput: readonly number[],\n     vectorize: boolean, doBroadcast: boolean, sharedDimensionDivisibleBy4: boolean, funcCall: BinaryFunctionCall,\n     typeA: number, typeB: number, typeOutput: number, useShapesUniforms: boolean,\n     additionalImplementation?: string) => {\n      let expressionScalar: BinaryCustomExpression;\n      let expressionVector: BinaryCustomExpression;\n      if (typeof funcCall === 'string') {\n        expressionScalar = expressionVector = (a, b) => `${funcCall}((${a}),(${b}))`;\n      } else if (typeof funcCall === 'function') {\n        expressionScalar = expressionVector = funcCall;\n      } else {\n        expressionScalar = funcCall.scalar;\n        expressionVector = funcCall.vector;\n      }\n\n      const inputAShapeOrRank = useShapesUniforms ? dimsA.length : dimsA;\n      const inputBShapeOrRank = useShapesUniforms ? dimsB.length : dimsB;\n      const outputShapeOrRank = useShapesUniforms ? dimsOutput.length : dimsOutput;\n      const output = outputVariable('outputData', typeOutput, outputShapeOrRank, 4);\n      const a = inputVariable('aData', typeA, inputAShapeOrRank, 4);\n      const b = inputVariable('bData', typeB, inputBShapeOrRank, 4);\n\n      let assignment: string;\n      if (vectorize) {\n        if (doBroadcast) {\n          const isAOneElement = ShapeUtil.size(dimsA) === 1;\n          const isBOneElement = ShapeUtil.size(dimsB) === 1;\n          const aLastDimDivisibleBy4 = dimsA.length > 0 && dimsA[dimsA.length - 1] % 4 === 0;\n          const bLastDimDivisibleBy4 = dimsB.length > 0 && dimsB[dimsB.length - 1] % 4 === 0;\n          if (isAOneElement || isBOneElement) {\n            assignment = output.setByOffset(\n                'global_idx',\n                expressionVector(\n                    isAOneElement ? `${a.type.value}(${a.getByOffset('0')}.x)` : a.getByOffset('global_idx'),\n                    isBOneElement ? `${b.type.value}(${b.getByOffset('0')}.x)` : b.getByOffset('global_idx')));\n          } else {\n            assignment = `\n            let outputIndices = ${output.offsetToIndices('global_idx * 4u')};\n            let offsetA = ${a.broadcastedIndicesToOffset('outputIndices', output)};\n            let offsetB = ${b.broadcastedIndicesToOffset('outputIndices', output)};\n            ${\n                output.setByOffset(\n                    'global_idx',\n                    expressionVector(\n                        sharedDimensionDivisibleBy4 || aLastDimDivisibleBy4 ?\n                            a.getByOffset('offsetA / 4u') :\n                            `${a.type.value}(${a.getByOffset('offsetA / 4u')}[offsetA % 4u])`,\n                        sharedDimensionDivisibleBy4 || bLastDimDivisibleBy4 ?\n                            b.getByOffset('offsetB / 4u') :\n                            `${b.type.value}(${b.getByOffset('offsetB / 4u')}[offsetB % 4u])`))}\n          `;\n          }\n        } else {\n          assignment = output.setByOffset(\n              'global_idx', expressionVector(a.getByOffset('global_idx'), b.getByOffset('global_idx')));\n        }\n      } else {\n        if (!doBroadcast) {\n          throw new Error('no necessary to use scalar implementation for element-wise binary op implementation.');\n        }\n\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expressionScalar(expressionA, expressionB)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(a, b, output)}\n\n        ${additionalImplementation ?? ''}\n\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n        ${assignment}\n      }`;\n    };\n\nconst createBinaryOpProgramInfo =\n    (name: string, cacheKey: string, a: TensorView, b: TensorView, funcCall: BinaryFunctionCall,\n     additionalImplementation?: string, outputDataType: number = a.dataType): ProgramInfo => {\n      const isBroadcast = !ShapeUtil.areEqual(a.dims, b.dims);\n      let outputShape = a.dims;\n      let outputSize = ShapeUtil.size(a.dims);\n\n      let vectorize = false;\n      let sharedDimensionDivisibleBy4 = false;\n\n      // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n      const cacheKeyAux = [isBroadcast];\n      if (isBroadcast) {\n        const calculatedShape = BroadcastUtil.calcShape(a.dims, b.dims, false);\n        if (!calculatedShape) {\n          throw new Error('Can\\'t perform binary op on the given tensors');\n        }\n        outputShape = calculatedShape;\n        outputSize = ShapeUtil.size(outputShape);\n        const isAOneElement = ShapeUtil.size(a.dims) === 1;\n        const isBOneElement = ShapeUtil.size(b.dims) === 1;\n        const aLastDimDivisibleBy4 = a.dims.length > 0 && a.dims[a.dims.length - 1] % 4 === 0;\n        const bLastDimDivisibleBy4 = b.dims.length > 0 && b.dims[b.dims.length - 1] % 4 === 0;\n        cacheKeyAux.push(isAOneElement);\n        cacheKeyAux.push(isBOneElement);\n        cacheKeyAux.push(aLastDimDivisibleBy4);\n        cacheKeyAux.push(bLastDimDivisibleBy4);\n        // check whether vectorize can be enabled\n        let sharedDimension = 1;\n        for (let i = 1; i < outputShape.length; i++) {\n          const dimA = a.dims[a.dims.length - i] ?? 1;\n          const dimB = b.dims[b.dims.length - i] ?? 1;\n          if (dimA === dimB) {\n            sharedDimension *= dimA;\n          } else {\n            break;\n          }\n        }\n        if (sharedDimension % 4 === 0) {\n          sharedDimensionDivisibleBy4 = true;\n          vectorize = true;\n        } else if (isAOneElement || isBOneElement || aLastDimDivisibleBy4 || bLastDimDivisibleBy4) {\n          vectorize = true;\n        }\n      } else {\n        // element-wise\n        vectorize = true;\n      }\n      cacheKeyAux.push(vectorize);\n      const useShapesUniforms = enableShapesUniforms(a.dims.length) && enableShapesUniforms(b.dims.length) &&\n          enableShapesUniforms(outputShape.length);\n      return {\n        name,\n        shaderCache: {\n          hint: cacheKey + cacheKeyAux.map((x) => x.toString()).join('_'),\n          inputDependencies: useShapesUniforms ? ['rank', 'rank'] : ['dims', 'dims'],\n        },\n        getShaderSource: (shaderHelper) => createBinaryOpProgramShader(\n            shaderHelper, a.dims, b.dims, outputShape, vectorize, isBroadcast, sharedDimensionDivisibleBy4, funcCall,\n            a.dataType, b.dataType, outputDataType, useShapesUniforms, additionalImplementation),\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* component size */)},\n          programUniforms: useShapesUniforms ?\n              [\n                {type: 'uint32', data: Math.ceil(ShapeUtil.size(outputShape) / 4)},\n                ...createTensorShapeVariables(a.dims),\n                ...createTensorShapeVariables(b.dims),\n                ...createTensorShapeVariables(outputShape),\n              ] :\n              [\n                {type: 'uint32', data: Math.ceil(ShapeUtil.size(outputShape) / 4)},\n              ],\n        }),\n      };\n    };\n\nconst runBinaryOp =\n    (context: ComputeContext, name: string, funcCall: BinaryFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType?: number): void => {\n      context.compute(createBinaryOpProgramInfo(\n          name, cacheKey ?? '', context.inputs[0], context.inputs[1], funcCall, additionalImplementation,\n          outputDataType));\n    };\n\nexport const add = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Add', (a, b) => `${a}+${b}`);\n};\n\nexport const div = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Div', (a, b) => `${a}/${b}`);\n};\n\nexport const equal = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Equal', ({scalar: (a, b) => `u32(${a}==${b})`, vector: (a, b) => `vec4<u32>(${a}==${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const mul = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Mul', (a, b) => `${a}*${b}`);\n};\n\nexport const pow = (context: ComputeContext): void => {\n  const type = inputVariable('input', context.inputs[0].dataType, context.inputs[0].dims).type.value;\n  const roundStr = type === 'i32' ? 'round' : '';\n  runBinaryOp(\n      context, 'Pow', ({scalar: (a, b) => `pow_custom(${a},${b})`, vector: (a, b) => `pow_vector_custom(${a},${b})`}),\n      `\n    fn pow_custom(a : ${type}, b : ${type}) -> ${type} {\n      if (b == ${type}(0.0)) {\n        return ${type}(1.0);\n      } else if (a < ${type}(0.0) && f32(b) != floor(f32(b))) {\n        return ${type}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${type}(1.0), round(f32(abs(b) % ${type}(2.0))) != 1.0) * ${type}(${\n          roundStr}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${type}>, b : vec4<${type}>) -> vec4<${type}> {\n      // TODO: implement vectorized pow\n      return vec4<${type}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `);\n};\n\nexport const sub = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Sub', (a, b) => `${a}-${b}`);\n};\n\nexport const greater = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Greater', ({scalar: (a, b) => `u32(${a}>${b})`, vector: (a, b) => `vec4<u32>(${a}>${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const less = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Less', ({scalar: (a, b) => `u32(${a}<${b})`, vector: (a, b) => `vec4<u32>(${a}<${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const greaterOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'GreaterOrEqual', ({scalar: (a, b) => `u32(${a}>=${b})`, vector: (a, b) => `vec4<u32>(${a}>=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n\nexport const lessOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'LessOrEqual', ({scalar: (a, b) => `u32(${a}<=${b})`, vector: (a, b) => `vec4<u32>(${a}<=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface ConcatAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n\n  const inputType = inputs[0].dataType;\n  const inputDimensionality = inputs[0].dims.length;\n\n  for (const input of inputs) {\n    // make sure types of all inputs match\n    if (input.dataType !== inputType) {\n      throw new Error('input tensors should be one type');\n    }\n\n    // make sure the dimensionality of all inputs are the same\n    if (input.dims.length !== inputDimensionality) {\n      throw new Error('input tensors should have the same shape');\n    }\n  }\n};\n\nconst calculateInputIndexImpl = (numberOfTensors: number, sizeInConcatAxisStr: string): string => `\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${numberOfTensors}u>(${sizeInConcatAxisStr});\n    for (var i: u32 = 0u; i < ${numberOfTensors}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${numberOfTensors}u;\n  }`;\n\nconst assignOutputData = (inputs: readonly IndicesHelper[], output: IndicesHelper) => {\n  const numberOfTensors = inputs.length;\n\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = output.setByOffset('global_idx', inputs[i].getByIndices('indices'));\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (inputIndex == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (inputIndex == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return codeLines.join('\\n');\n};\n\nconst createConcatProgramInfo = (inputs: readonly TensorView[], axis: number): ProgramInfo => {\n  const inputShape = inputs[0].dims.slice();\n  if (axis >= inputShape.length || axis < (-1 * inputShape.length)) {\n    throw new Error('axis specified for concat doesn\\'t match input dimensionality');\n  }\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  // ensure all of the non-concatenated axes match each other\n  // calculate the shape of the output tensor while we do that\n  const outputShape = inputShape.slice(0);\n  for (let i = 1; i < inputs.length; i++) {\n    const dataNShape = inputs[i].dims.slice();\n    for (let axisIndex = 0; axisIndex < inputShape.length; axisIndex++) {\n      // add to the placeholder for computing output shape\n      if (axisIndex === adjustedAxis) {\n        outputShape[adjustedAxis] += dataNShape[axisIndex];\n      }\n      // ensure all non-cancatenated axes match each other\n      else if (inputShape[axisIndex] !== dataNShape[axisIndex]) {\n        throw new Error('non concat dimensions must match');\n      }\n    }\n  }\n\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const sizeInConcatAxis = new Array<number>(inputs.length);\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  const dataType = inputs[0].dataType;\n\n  let previousSum = 0;\n  const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n  const inputShapeOrRanks = [];\n  const enableInputShapesUniforms = [];\n  const programUniforms: ProgramUniform[] = [{type: 'uint32', data: outputSize}];\n  for (let i = 0; i < inputs.length; ++i) {\n    previousSum += inputs[i].dims[adjustedAxis];\n    sizeInConcatAxis[i] = previousSum;\n    enableInputShapesUniforms.push(enableShapesUniforms(inputs[i].dims.length));\n    inputShapeOrRanks.push(enableInputShapesUniforms[i] ? inputs[i].dims.length : inputs[i].dims);\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputShapeOrRanks[i]);\n    inputDependencies.push(enableInputShapesUniforms[i] ? 'rank' : 'dims');\n    programUniforms.push({type: 'uint32', data: sizeInConcatAxis[i]});\n  }\n  for (let i = 0; i < inputs.length; ++i) {\n    if (enableInputShapesUniforms[i]) {\n      programUniforms.push(...createTensorShapeVariables(inputs[i].dims));\n    }\n  }\n\n  const enableOutputShapesUniforms = enableShapesUniforms(outputShape.length);\n  if (enableOutputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n\n  const outputShapeOrRank = enableOutputShapesUniforms ? outputShape.length : outputShape;\n  const output = outputVariable('output', dataType, outputShapeOrRank);\n\n  const indicesAxis = output.indicesGet('indices', adjustedAxis);\n  const sizeInConcatAxisStr =\n      Array.from(Array(sizeInConcatAxis.length).keys()).map(i => `uniforms.sizeInConcatAxis${i}`).join(',');\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  ${(() => {\n    shaderHelper.registerUniform('outputSize', 'u32');\n    for (let i = 0; i < inputs.length; i++) {\n      shaderHelper.registerUniform(`sizeInConcatAxis${i}`, 'u32');\n    }\n    return shaderHelper.declareVariables(...inputVars, output);\n  })()}\n\n  ${calculateInputIndexImpl(sizeInConcatAxis.length, sizeInConcatAxisStr)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n\n    var indices = ${output.offsetToIndices('global_idx')};\n\n    let inputIndex = calculateInputIndex(${indicesAxis});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}u>(${sizeInConcatAxisStr});\n      ${indicesAxis} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${assignOutputData(inputVars, output)}\n  }`;\n\n  return {\n    name: 'Concat',\n    shaderCache: {hint: `${axis}`, inputDependencies},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const concat = (context: ComputeContext, attributes: ConcatAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createConcatProgramInfo(context.inputs, attributes.axis));\n};\n\nexport const parseConcatAttributes = (attributes: Record<string, unknown>): ConcatAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {MAX_CLIP, MIN_CLIP} from '../../util';\n\nexport interface InternalActivationAttributes {\n  readonly activation: string;\n  readonly clipMin?: number;\n  readonly clipMax?: number;\n  readonly activationCacheKey: string;\n}\n\nexport const getActivationSnippet = (attributes: InternalActivationAttributes, valueType: string):\n    {activationFunction: string; applyActivation: string} => {\n      switch (attributes.activation) {\n        case 'Relu':\n          return {activationFunction: '', applyActivation: `value = max(value, ${valueType}(0.0));`};\n        case 'Sigmoid':\n          return {\n            activationFunction: '',\n            applyActivation: `value = (${valueType}(1.0) / (${valueType}(1.0) + exp(-value)));`\n          };\n        case 'Clip':\n          return {\n            activationFunction: `const clip_min_=${valueType}(${attributes.clipMin!});const clip_max_=${valueType}(${\n                attributes.clipMax!});`,\n            applyActivation: 'value = clamp(value, clip_min_, clip_max_);'\n          };\n          // TODO: adding other activations that can be fused.\n        default:\n          return {activationFunction: '', applyActivation: ''};\n      }\n    };\n\nexport const parseInternalActivationAttributes =\n    (attributes: Record<string, unknown>|undefined): InternalActivationAttributes => {\n      const activation = attributes?.activation as string || '';\n\n      if (activation === 'Clip') {\n        const [clipMin, clipMax] = attributes?.activation_params as [number, number] || [MIN_CLIP, MAX_CLIP];\n        return {activation, clipMax, clipMin, activationCacheKey: `${activation}:${clipMin},${clipMax}`};\n      }\n      return {activation, activationCacheKey: activation};\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/activation_util.ts\n//\n// modified to fit the needs of the project\n\nexport const typeSnippet = (component: number, dataType: string) => {\n  switch (component) {\n    case 1:\n      return dataType;\n    case 2:\n      return `vec2<${dataType}>`;\n    case 3:\n      return `vec3<${dataType}>`;\n    case 4:\n      return `vec4<${dataType}>`;\n    default:\n      throw new Error(`${component}-component is not supported.`);\n  }\n};\n\nexport const biasSnippet = (hasBias: boolean): string => `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      `;\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-core/src/ops/conv_util.ts\n//\n// modified to fit the needs of the project\n\nexport const utilFunctions = (strideStr: string) => (`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    i32(${strideStr}.x), i32(${strideStr}.y), i32(${strideStr}.z), 1));\n}\n`);\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/matmul_packed_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../../types';\nimport {createTensorShapeVariables, enableShapesUniforms, getBroadcastDims, IndicesHelper, inputVariable, internalVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {getActivationSnippet, InternalActivationAttributes} from '../fuse-utils';\n\nimport {typeSnippet} from './activation_util';\n\nconst writeDataToSubAVec4Snippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n  }\n};\n\nconst calculateResultSnippet = (transposeA: boolean, innerElementSize: number) => {\n  if (transposeA) {\n    return `\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${innerElementSize === 3 ? '' : 'let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];'}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached3[i] + acc[i];'}\n        }`;\n  } else {\n    return `\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached.w + acc[i];'}\n        }`;\n  }\n};\n\nexport const makeMatMulPackedVec4Source =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32): string => {\n      const tileAOuter = workgroupSize[1] * workPerThread[1];\n      const tileBOuter = workgroupSize[0] * workPerThread[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n      const innerElementSize = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n\n      if (!(((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n             (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n            tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4)) {\n        throw new Error(`If transposeA ${transposeA} is true, innerElementSize ${\n            innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n      Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n  tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${\n            tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${\n            workPerThread[0]} must be 4.`);\n      }\n      return `\nvar<workgroup> mm_Asub: array<array<vec${innerElementSize}<${type}>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${type}>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\nconst rowPerThread = ${workPerThread[1]};\nconst colPerThread = ${workPerThread[0]};\nconst innerElementSize = ${innerElementSize};\nconst tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n  ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(uniforms.dimInner - 1) / tileInner + 1'};\n  var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n  var acc: array<vec4<${type}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${rowPerThreadB};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${writeDataToSubAVec4Snippet(transposeA, batchDims)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${\n          batchDims ? ', batchIndices' : ''});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${innerElementSize === 3 ? '' : 'let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];'}\n\n          ${calculateResultSnippet(transposeA, innerElementSize)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`;\n    };\n\nconst writeDataToSubASnippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n\n  } else {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) =>\n    transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' : 'let ACached = mm_Asub[tileRow + innerRow][k];';\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport const makeMatMulPackedSource =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n     sequentialAccessByThreads = false): string => {\n      const tileAOuter = workPerThread[1] * workgroupSize[1];\n      const tileBOuter = workPerThread[0] * workgroupSize[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n\n      if (!(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 &&\n            tileInner % workgroupSize[1] === 0)) {\n        throw new Error(`tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n            workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n            workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n      }\n      const rowPerThreadA = tileAHight / workgroupSize[1];\n      const colPerThreadA = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n      const matmulSnippet = sequentialAccessByThreads ?\n          `\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n    let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n        for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n          ${writeDataToSubASnippet(transposeA, batchDims)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n            for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${batchDims ? ', batchIndices' : ''});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${type}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${\n              transposeA ? `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n                           `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    ` :\n          `\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\nlet tileRowA = i32(localId.y) * ${rowPerThreadA};\nlet tileColA = i32(localId.x) * ${colPerThreadA};\nlet tileRowB = i32(localId.y) * ${rowPerThreadB};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${writeDataToSubASnippet(transposeA, batchDims)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${batchDims ? ', batchIndices' : ''});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${type}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${readDataFromSubASnippet(transposeA)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;\n\n      return `\n  var<workgroup> mm_Asub : array<array<${type}, ${tileAWidth}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<${type}, ${tileBOuter}>, ${tileInner}>;\n  const rowPerThread = ${workPerThread[1]};\n  const colPerThread = ${workPerThread[0]};\n  const tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n    let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(uniforms.dimInner - 1) / tileInner + 1'};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc : array<array<${type}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${matmulSnippet}\n  }\n`;\n    };\n\nconst matMulReadWriteFnSource =\n    (component: number, hasBias: boolean, applyActivation: string, variables: IndicesHelper[],\n     batchShapes: Array<readonly number[]>, isChannelsLast = false): string => {\n      const [batchAShape, batchBShape, batchShape] = batchShapes;\n      const [batchVariable, aVariable, bVariable, outputVariable] = variables;\n      const broadCastADims = getBroadcastDims(batchAShape, batchShape);\n      const broadCastBDims = getBroadcastDims(batchBShape, batchShape);\n      const dataType = tensorTypeToWsglStorageType(variables[0].type.tensor);\n      const getAIndices = () => {\n        const aRank = aVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var aIndices: ${aVariable.type.indices};`;\n        for (let i = aRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\naIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastADims.forEach(i => {\n          resStr += `\\naIndices[${i}] = 0;`;\n        });\n        resStr += `\\naIndices[${aRank - 2}] = u32(row);\n                   aIndices[${aRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const getBIndices = () => {\n        const bRank = bVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var bIndices: ${bVariable.type.indices};`;\n        for (let i = bRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\nbIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastBDims.forEach(i => {\n          resStr += `\\nbIndices[${i}] = 0;`;\n        });\n        resStr += `\\nbIndices[${bRank - 2}] = u32(row);\n                   bIndices[${bRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const source = `\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < uniforms.dimAOuter && col < uniforms.dimInner)\n      {\n        ${getAIndices()}\n        value = ${aVariable.getByIndices('aIndices')};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < uniforms.dimInner && col < uniforms.dimBOuter)\n      {\n        ${getBIndices()}\n        value = ${bVariable.getByIndices('bIndices')};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${typeSnippet(component, dataType)}) {\n      let col = colIn * ${component};\n      if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${\n          hasBias ?\n              `value = value + ${isChannelsLast ? 'bias[colIn]' : `${typeSnippet(component, dataType)}(bias[row])`};` :\n                                                  ''                                    }\n        ${applyActivation}\n        ${outputVariable.setByIndices('vec3<u32>(coords)', 'value')}\n      }\n    }\n    `;\n      return source;\n    };\n\nexport const createMatmulProgramInfo =\n    (inputs: readonly TensorView[], activationAttributes: InternalActivationAttributes, outputShape: readonly number[],\n     reshapedOutputShape?: readonly number[],\n     isChannelsLast = false /* only used for conv2dByMatMul*/): ProgramInfo => {\n      const aShape = inputs[0].dims;\n      const bShape = inputs[1].dims;\n\n      const outerDimsA = aShape.slice(0, -2);\n      const outerDimsB = bShape.slice(0, -2);\n\n      const outerDims = reshapedOutputShape ? reshapedOutputShape.slice(0, -2) : outputShape.slice(0, -2);\n      const enableBatchUniforms = enableShapesUniforms(outerDims.length);\n      const batchShapeOrRank = enableBatchUniforms ? outerDims.length : outerDims;\n      const batchDims = internalVariable('batchDims', inputs[0].dataType, batchShapeOrRank, 1);\n      const batchSize = ShapeUtil.size(outerDims);\n\n      const dimAOuter = aShape[aShape.length - 2];\n      const dimInner = aShape[aShape.length - 1];\n      const dimBOuter = bShape[bShape.length - 1];\n      const isVec4 = dimInner % 4 === 0 && dimBOuter % 4 === 0;\n\n      // TODO: fine tune size\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const workgroupSize: [number, number, number] = [8, 8, 1];\n      const dispatch = [\n        Math.ceil(dimBOuter / workgroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dimAOuter / workgroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workgroupSize[2] / elementsPerThread[2])\n      ];\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const components = isVec4 ? 4 : 1;\n\n      const aShapeTemp = [...outerDimsA, dimAOuter, dimInner / components];\n      const enableAShapesUniforms = enableShapesUniforms(aShapeTemp.length);\n      const aShapeOrRank = enableAShapesUniforms ? aShapeTemp.length : aShapeTemp;\n\n      const bShapeTemp = [...outerDimsB, dimInner, dimBOuter / components];\n      const enableBShapesUniforms = enableShapesUniforms(bShapeTemp.length);\n      const bShapeOrRank = enableBShapesUniforms ? bShapeTemp.length : bShapeTemp;\n\n      const outputShapeTemp = [batchSize, dimAOuter, dimBOuter / components];\n\n      const A = inputVariable('a', inputs[0].dataType, aShapeOrRank, components);\n      const B = inputVariable('b', inputs[1].dataType, bShapeOrRank, components);\n      const output = outputVariable('result', inputs[0].dataType, outputShapeTemp.length, components);\n      const inputVariables = [A, B];\n      const programUniforms: ProgramUniform[] =\n          [{type: 'int32', data: dimAOuter}, {type: 'int32', data: dimBOuter}, {type: 'int32', data: dimInner}];\n      if (enableBatchUniforms) {\n        programUniforms.push(...createTensorShapeVariables(outerDims));\n      }\n      if (enableAShapesUniforms) {\n        programUniforms.push(...createTensorShapeVariables(aShapeTemp));\n      }\n      if (enableBShapesUniforms) {\n        programUniforms.push(...createTensorShapeVariables(bShapeTemp));\n      }\n      const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n      inputDependencies.push(enableAShapesUniforms ? 'rank' : 'dims');\n      inputDependencies.push(enableBShapesUniforms ? 'rank' : 'dims');\n\n      const hasBias = inputs.length > 2;\n      const {activationFunction, applyActivation} = getActivationSnippet(activationAttributes, output.type.value);\n      const declareFunctions = matMulReadWriteFnSource(\n          components, hasBias, applyActivation, [batchDims, A, B, output], [outerDimsA, outerDimsB, outerDims],\n          isChannelsLast);\n      if (hasBias) {\n        const biasComponents = isChannelsLast ? components : 1;\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, biasComponents));\n        programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n\n        inputDependencies.push('rank');\n      }\n      programUniforms.push(...createTensorShapeVariables(outputShapeTemp));\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${\n          shaderHelper.registerUniform('dimAOuter', 'i32')\n              .registerUniform('dimBOuter', 'i32')\n              .registerUniform('dimInner', 'i32')\n              .registerInternalVariables(batchDims)\n              .declareVariables(...inputVariables, output)}\n  ${activationFunction}\n  ${declareFunctions}\n  ${\n          isVec4 ? makeMatMulPackedVec4Source(elementsPerThread, workgroupSize, dataType, batchDims) :\n                   makeMatMulPackedSource(elementsPerThread, workgroupSize, dataType, batchDims)}\n                   `;\n      // TODO: turn clipMax and clipMin to uniforms.\n      return {\n        name: 'MatMul',\n        shaderCache: {\n          hint: activationAttributes.activationCacheKey + `${elementsPerThread}` +\n              `${isVec4}` +\n              `${isChannelsLast}`,\n          inputDependencies\n        },\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          programUniforms\n        }),\n        getShaderSource,\n      };\n    };\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ProgramInfo, ProgramUniform} from '../../types';\nimport {createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {ConvAttributes} from '../conv';\nimport {getActivationSnippet} from '../fuse-utils';\n\nimport {biasSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dCommonSnippet =\n    (isChannelsLast: boolean, fitAOuter: boolean, fitBOuter: boolean, fitInner: boolean, addBias = false,\n     attributes: ConvAttributes, innerElementSizeX = 4, innerElementSizeW = 4, innerElementSize = 4,\n     dataType = 'f32'): string => {\n      const getXSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'resData = x[xIndex];';\n          case 3:\n            return `resData = vec3<${dataType}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;\n          case 4:\n            return 'resData = x[xIndex / 4];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return w[row * i32(uniforms.w_shape[3]) + colIn];';\n          case 4:\n            return 'return w[row * i32(uniforms.w_shape[3]) / 4 + colIn];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    ` :\n                                             `\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'i32(uniforms.x_shape[1])' : 'i32(uniforms.x_shape[2])';\n      const xWidth = isChannelsLast ? 'i32(uniforms.x_shape[2])' : 'i32(uniforms.x_shape[3])';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n      const readXSnippet = `\n    let inChannels = i32(uniforms.w_shape[2]);\n    let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n    let outRow = ${row} / outWidth;\n    let outCol = ${row} % outWidth;\n\n    let WRow = ${col} / (filterDims[1] * inChannels);\n    let WCol = ${col} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${col} % inChannels;\n    var resData = ${typeSnippet(innerElementSizeX, dataType)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${xHeight} && xCol >= 0 && xCol < ${xWidth}) {\n      ${coordASnippet}\n      let xIndex = getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape));\n      ${getXSnippet(innerElementSizeX)}\n    }\n    return resData;`;\n\n      const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`) :\n                                       (fitInner && fitBOuter ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`);\n\n      const sampleW = `${getWSnippet(innerElementSizeW)}`;\n\n      const resType = typeSnippet(innerElementSize, dataType);\n      const aType =\n          isChannelsLast ? typeSnippet(innerElementSizeX, dataType) : typeSnippet(innerElementSizeW, dataType);\n      const bType =\n          isChannelsLast ? typeSnippet(innerElementSizeW, dataType) : typeSnippet(innerElementSizeX, dataType);\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, resType);\n      const userCode = `\n    ${activationFunction}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${aType} {\n      ${isChannelsLast ? sampleX : sampleW}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${bType} {\n      ${isChannelsLast ? sampleW : sampleX}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${resType}) {\n      let col = colIn * ${innerElementSize};\n      if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n      ${coordResSnippet}\n      ${biasSnippet(addBias)}\n      ${applyActivation}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`;\n      return userCode;\n    };\n\nexport const createConv2DMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes, outputShape: readonly number[], dimAOuter: number,\n     dimBOuter: number, dimInner: number, hasBias: boolean, sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      // TODO: enable vec4 for NCHW\n      const isVec4 = isChannelsLast && (inChannels % 4 === 0 || inChannels % 3 === 0) && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = [8, 8, 1];\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv2d_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? (isChannelsLast && inChannels % 4 !== 0 ? 3 : 4) : 1;\n\n      const tileAOuter = workGroupSize[1] * elementsPerThread[1];\n      const tileBOuter = workGroupSize[0] * elementsPerThread[0];\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n      const fitAOuter = dimAOuter % tileAOuter === 0;\n      const fitBOuter = dimBOuter % tileBOuter === 0;\n      const fitInner = dimInner % tileInner === 0;\n\n      const elementsSize = isVec4 ? [innerElementSize, 4, 4] : [1, 1, 1];\n      const t = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n      // TODO: support component 2, 3.\n      const components = isVec4 ? 4 : 1;\n      const programUniforms: ProgramUniform[] =\n          [{type: 'int32', data: dimAOuter}, {type: 'int32', data: dimBOuter}, {type: 'int32', data: dimInner}];\n      const x =\n          inputVariable('x', inputs[0].dataType, inputs[0].dims.length, innerElementSize === 3 ? 1 : innerElementSize);\n      const w = inputVariable('w', inputs[1].dataType, inputs[1].dims.length, components);\n      const inputVariables = [x, w];\n\n      programUniforms.push(...createTensorShapeVariables(inputs[0].dims));\n      programUniforms.push(...createTensorShapeVariables(inputs[1].dims));\n\n      let declareFunctions = `\n      fn setOutputAtIndex(flatIndex : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        result[flatIndex] = ${isVec4 ? `vec4<${t}>` : t}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${isVec4 ? '/ 4' : ''}, value);\n      }`;\n      if (hasBias) {\n        const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, components);\n        inputVariables.push(bias);\n\n        programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? `vec4<${t}>` : t} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n      const output = outputVariable('result', inputs[0].dataType, outputShape.length, components);\n      programUniforms.push(...createTensorShapeVariables(outputShape));\n      return {\n        name: 'Conv2DMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          programUniforms,\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => `\n        ${utilFunctions('uniforms.result_strides')}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${\n            shaderHelper.registerUniform('dimAOuter', 'i32')\n                .registerUniform('dimBOuter', 'i32')\n                .registerUniform('dimInner', 'i32')\n                .declareVariables(...inputVariables, output)}\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[0]}, ${attributes.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${attributes.pads[0]}, ${attributes.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        ${declareFunctions}\n        ${\n            conv2dCommonSnippet(\n                isChannelsLast, fitAOuter, fitBOuter, fitInner, hasBias, attributes, elementsSize[0], elementsSize[1],\n                elementsSize[2], t)}\n            ${\n            isVec4 ?\n                makeMatMulPackedVec4Source(elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner) :\n                makeMatMulPackedSource(\n                    elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner, false, undefined,\n                    sequentialAccessByThreads)}`\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {calculateOutputShape, ConvAttributes} from './conv';\nimport {getActivationSnippet} from './fuse-utils';\n\n/**\n * naive grouped conv implementation, supports 1d/2d conv\n * @param squeezeOutputShapeFunction - an optional function to squeeze the output shape, only used in conv1d\n */\nexport const createGroupedConvProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      const processBias = hasBias ? 'value += b[output_channel];' : '';\n      const xShape = inputs[0].dims;\n      const wShape = inputs[1].dims;\n      const outputChannelsPerGroup = wShape[0] / attributes.group;\n\n      const isChannelLast = attributes.format === 'NHWC';\n      const outputShape = calculateOutputShape(\n          xShape, wShape, attributes.dilations, attributes.pads, attributes.strides, isChannelLast);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const output = outputVariable('output', inputs[0].dataType, outputShape);\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, output.type.value);\n      const x = inputVariable('x', inputs[0].dataType, xShape);\n      const w = inputVariable('w', inputs[1].dataType, wShape);\n      const inputVars = [x, w];\n      if (hasBias) {\n        inputVars.push(inputVariable('b', inputs[2].dataType, inputs[2].dims));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const strides: vec2<u32> = vec2(${attributes.strides[0]}u, ${attributes.strides[1]}u);\n  const pads: vec2<u32> = vec2(${attributes.pads[0]}u, ${attributes.pads[1]}u);\n\n  ${shaderHelper.declareVariables(...inputVars, output)}\n\n  ${activationFunction}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${isChannelLast ? 3 : 1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${isChannelLast ? 1 : 2}], outputIndices[${\n          isChannelLast ? 2 : 3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${outputChannelsPerGroup}u;\n\n    var value: ${output.type.value} = ${output.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${wShape[1]}u; wInChannel++) {\n      let input_channel = group_id * ${wShape[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${wShape[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${attributes.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${xShape[isChannelLast ? 1 : 2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${wShape[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${attributes.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${xShape[isChannelLast ? 2 : 3]}u) {\n            continue;\n          }\n\n          let xVal = ${\n          isChannelLast ? x.get('batch', 'xHeight', 'xWidth', 'input_channel') :\n                          x.get('batch', 'input_channel', 'xHeight', 'xWidth')};\n          let wVal = ${w.get('output_channel', 'wInChannel', 'wHeight', 'wWidth')};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${processBias}\n    ${applyActivation}\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n      return {\n        name: 'GroupedConv',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        }),\n        getShaderSource,\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramUniform} from '../types';\n\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\nimport {createTensorShapeVariables, getBroadcastDims, getMaxComponents, IndicesHelper, inputVariable, internalVariable, outputVariable, ShaderHelper,} from './common';\nimport {getActivationSnippet, InternalActivationAttributes} from './fuse-utils';\n\nexport const createNaiveMatmulProgramInfo =\n    (inputs: readonly TensorView[], activationAttributes: InternalActivationAttributes, outputShape: readonly number[],\n     reshapedOutputShape?: readonly number[],\n     isChannelsLast = false /* only used for conv2dByMatMul*/): ProgramInfo => {\n      const aShape = inputs[0].dims;\n      const bShape = inputs[1].dims;\n\n      const M = aShape[aShape.length - 2];\n      const N = bShape[bShape.length - 1];\n      const K = aShape[aShape.length - 1];\n      const components = getMaxComponents(N);\n      const aComponents = getMaxComponents(K);\n      const outputNumber = getMaxComponents(M);\n      const outputSize = ShapeUtil.size(outputShape) / components / outputNumber;\n      const hasBias = inputs.length > 2;\n      const outerDims = reshapedOutputShape ? reshapedOutputShape.slice(0, -2) : outputShape.slice(0, -2);\n      const batchSize = ShapeUtil.size(outerDims);\n      const outputShapeInShader = [batchSize, M, N];\n      const programUniforms: ProgramUniform[] = [\n        {type: 'uint32', data: outputSize}, {type: 'uint32', data: M}, {type: 'uint32', data: N},\n        {type: 'uint32', data: K}, ...createTensorShapeVariables(outerDims), ...createTensorShapeVariables(aShape),\n        ...createTensorShapeVariables(bShape)\n      ];\n      if (hasBias) {\n        programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n      }\n      programUniforms.push(...createTensorShapeVariables(outputShapeInShader));\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const batchDims = internalVariable('batch_dims', inputs[0].dataType, outerDims.length);\n        const a = inputVariable('a', inputs[0].dataType, aShape.length, aComponents);\n        const b = inputVariable('b', inputs[1].dataType, bShape.length, components);\n        const output = outputVariable('output', inputs[0].dataType, outputShapeInShader.length, components);\n        const {activationFunction, applyActivation} = getActivationSnippet(activationAttributes, output.type.value);\n        const inputVariables = [a, b];\n        let processBias = '';\n        if (hasBias) {\n          const biasComponents = isChannelsLast ? components : 1;\n          inputVariables.push(inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, biasComponents));\n          processBias = `${\n              isChannelsLast ? `value += bias[col / ${biasComponents}];` :\n                               `value += ${output.type.value}(bias[row + i]);`}`;\n        }\n\n        const outerDimsA = aShape.slice(0, -2);\n        const outerDimsB = bShape.slice(0, -2);\n        const broadCastADims = getBroadcastDims(outerDimsA, outerDims);\n        const broadCastBDims = getBroadcastDims(outerDimsB, outerDims);\n        const getIndices = (variable: IndicesHelper, broadCastDims: number[]) => {\n          const rank = variable.rank;\n          const name = variable.name;\n          if (rank === 2) {\n            return `var ${name}_indices = ${variable.type.indices}(0u, 0u);`;\n          }\n          const batchRank = batchDims.rank;\n          let resStr = `var ${name}_indices: ${variable.type.indices};`;\n          for (let i = rank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n            resStr += `\\n${name}_indices[${i}] = ${batchRank > 1 ? `batch_indices[${j}]` : 'batch_indices'};`;\n          }\n          broadCastDims.forEach(i => {\n            resStr += `\\n${name}_indices[${i}] = 0;`;\n          });\n          resStr += `${name}_indices[${rank - 2}] = 0u;\n                     ${name}_indices[${rank - 1}] = 0u;`;\n          return resStr;\n        };\n\n        const calcResult = (): string => {\n          let calcStr = `var a_data: ${a.type.value};`;\n          for (let i = 0; i < aComponents; i++) {\n            calcStr += `\n              let b_data${i} = b[(b_offset + (k + ${i}) * uniforms.N + col) / ${components}];`;\n          }\n          for (let i = 0; i < outputNumber; i++) {\n            calcStr += `a_data = a[(a_offset + (row + ${i}) * uniforms.K + k) / ${aComponents}];`;\n\n            for (let j = 0; j < aComponents; j++) {\n              calcStr += `\n            values[${i}] = fma(${b.type.value}(a_data${aComponents === 1 ? '' : `[${j}]`}), b_data${j}, values[${\n                  i}]);\\n`;\n            }\n          }\n          return calcStr;\n        };\n\n        return `\n  ${\n            shaderHelper.registerUniform('outputSize', 'u32')\n                .registerUniform('M', 'u32')\n                .registerUniform('N', 'u32')\n                .registerUniform('K', 'u32')\n                .registerInternalVariables(batchDims)\n                .declareVariables(...inputVariables, output)}\n  ${activationFunction}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n    let col = (global_idx % (uniforms.N / ${components})) * ${components};\n    var index1 = global_idx / (uniforms.N / ${components});\n    let stride1 = uniforms.M / ${outputNumber};\n    let row = (index1 % stride1) * ${outputNumber};\n    let batch = index1 / stride1;\n\n    ${outputShape.length === 2 ? '' : `let batch_indices = ${batchDims.offsetToIndices('batch')};`}\n    ${getIndices(a, broadCastADims)}\n    let a_offset = ${a.indicesToOffset('a_indices')};\n    ${getIndices(b, broadCastBDims)}\n    let b_offset = ${b.indicesToOffset('b_indices')};\n    var values: array<${output.type.value}, ${outputNumber}>;\n    for (var k: u32 = 0u; k < uniforms.K; k = k + ${aComponents}) {\n      ${calcResult()}\n    }\n    for (var i = 0u; i < ${outputNumber}u; i++) {\n      var value = values[i];\n      ${processBias}\n      ${applyActivation}\n      let cur_indices = ${output.type.indices}(batch, row + i, col);\n      let offset = ${output.indicesToOffset('cur_indices')};\n      ${output.setByOffset(`offset / ${components}`, 'value')};\n    }\n  }\n  `;\n      };\n      return {\n        name: 'MatMulNaive',\n        shaderCache: {\n          hint: `${activationAttributes.activationCacheKey}_${components}_${aComponents}_${outputNumber}_${\n              isChannelsLast}`,\n          inputDependencies: hasBias ? ['rank', 'rank', 'rank'] : ['rank', 'rank']\n        },\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n          programUniforms\n        }),\n        getShaderSource\n      };\n    };\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('MatMul requires 2 inputs.');\n  }\n\n  if (inputs[0].dims[inputs[0].dims.length - 1] !== inputs[1].dims[inputs[1].dims.length - 2]) {\n    throw new Error('shared dimension does not match.');\n  }\n};\n\nexport const matMul = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  const outputShape = BroadcastUtil.calcShape(context.inputs[0].dims, context.inputs[1].dims, true);\n  if (!outputShape) {\n    throw new Error('Can\\'t use matmul on the given tensors');\n  }\n  const N = outputShape[outputShape.length - 1];\n  const K = context.inputs[0].dims[context.inputs[0].dims.length - 1];\n  if (N < 8 && K < 8) {\n    context.compute(\n        createNaiveMatmulProgramInfo(context.inputs, {activation: '', activationCacheKey: ''}, outputShape));\n  } else {\n    context.compute(createMatmulProgramInfo(context.inputs, {activation: '', activationCacheKey: ''}, outputShape));\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DMatMulProgramInfo} from './3rd-party/conv2d_mm_webgpu';\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\nimport {createGroupedConvProgramInfo} from './conv-grouped';\nimport {InternalActivationAttributes, parseInternalActivationAttributes} from './fuse-utils';\nimport {createNaiveMatmulProgramInfo} from './matmul';\nimport {createTransposeProgramInfo} from './transpose';\n\nexport const calculateOutputShape =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[],\n     adjustPads: readonly number[], strides: readonly number[], isChannelLast: boolean): number[] => {\n      const batchSize = inputShape[0];\n      const inputSpatialShape = inputShape.slice(isChannelLast ? 1 : 2, isChannelLast ? 3 : 4);\n      const spatialRank = inputSpatialShape.length;\n      const outChannels = kernelShape[0];\n      const kernelSpatialShape = kernelShape.slice(2);\n      const dilatedKernelShape = kernelSpatialShape.map((v, i) => v + (v - 1) * (dilations[i] - 1));\n      const inputSpatialShapeWithPad = inputSpatialShape.map((v, i) => v + adjustPads[i] + adjustPads[i + spatialRank]);\n      const outputShape =\n          inputSpatialShapeWithPad.map((v, i) => Math.floor((v - dilatedKernelShape[i] + strides[i]) / strides[i]));\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n      return outputShape;\n    };\n\nexport interface ConvAttributes extends InternalActivationAttributes, AttributeWithCacheKey {\n  readonly autoPad: string;\n  readonly dilations: readonly number[];\n  readonly format: 'NHWC'|'NCHW';\n  readonly group: number;\n  readonly kernelShape: readonly number[];\n  readonly pads: readonly number[];\n  readonly strides: readonly number[];\n  readonly wIsConst: boolean;\n}\n\n// for transposing weight tensor from [M, C/group, KH, KW] to [KH, KW, C/group, M]\nconst weightTransposeAttribute = [2, 3, 1, 0];\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support conv 1D and 2D');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[1] * attributes.group;\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[1].dims[0] !== inputs[2].dims[0])) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  // wrong dilations dimension\n  if (attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  // Wrong strides dimension\n  if (attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  if (attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  if (attributes.kernelShape.length !== 0 && attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n};\n\nconst getAdjustedConvAttributes = <T extends ConvAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n  const kernelShape = attributes.kernelShape.slice();\n  // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n  for (let i = 2; i < inputs[1].dims.length; ++i) {\n    if (kernelShape[i - 2] === 0) {\n      kernelShape[i - 2] = inputs[1].dims[i];\n    }\n  }\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPadsBasedOnAutoPad(\n      inputs[0].dims, attributes.strides, attributes.dilations, kernelShape, pads, attributes.format === 'NHWC',\n      attributes.autoPad);\n\n  // always return a new object so does not modify the original attributes\n  const newAttributes: T = Object.assign({}, attributes);\n  Object.assign(newAttributes, {kernelShape, pads, cacheKey: attributes.cacheKey});\n  return newAttributes;\n};\n\nexport const parseConvAttributes = (attributes: Record<string, unknown>): ConvAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad = ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernel_shape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.w_is_const as () => boolean)();\n\n  return createAttributeWithCacheKey(\n      {autoPad, format, dilations, group, kernelShape, pads, strides, wIsConst, ...activationAttributes});\n};\n\nconst conv2d = (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  const adjustedAttributes = getAdjustedConvAttributes(attributes, inputs);\n\n  // check attributes\n\n  // const hasPreluActivationWeights = false; /* TODO: add support for prelu activation weights */\n  if (attributes.group !== 1) {\n    context.compute(createGroupedConvProgramInfo(inputs, adjustedAttributes));\n    return;\n  }\n\n  const isChannelsLast = attributes.format === 'NHWC';\n  const hasBias = inputs.length === 3;\n  const inputHeight = inputs[0].dims[isChannelsLast ? 1 : 2];\n  const inputWidth = inputs[0].dims[isChannelsLast ? 2 : 3];\n  const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n  const weightHeight = inputs[1].dims[2];\n  const weightWidth = inputs[1].dims[3];\n\n  const outputShape = calculateOutputShape(\n      inputs[0].dims, inputs[1].dims, attributes.dilations, adjustedAttributes.pads, attributes.strides,\n      isChannelsLast);\n  const outHeight = outputShape[isChannelsLast ? 1 : 2];\n  const outWidth = outputShape[isChannelsLast ? 2 : 3];\n  const outChannels = outputShape[isChannelsLast ? 3 : 1];\n\n  const sameSize = isChannelsLast && weightHeight === inputHeight && weightWidth === inputWidth &&\n      attributes.pads[0] === 0 && attributes.pads[1] === 0;\n  if (sameSize ||\n      (weightHeight === 1 && weightWidth === 1 && attributes.dilations[0] === 1 && attributes.dilations[1] === 1 &&\n       attributes.strides[0] === 1 && attributes.strides[1] === 1 && attributes.pads[0] === 0 &&\n       attributes.pads[1] === 0)) {\n    // conv2dByMatMul\n    const batch = outputShape[0];\n    let xReshaped, wReshaped, matmulOutputShape;\n    const matmulInputs = [];\n    if (isChannelsLast) {\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n      if (sameSize) {\n        const sharedDim = inputHeight * inputWidth * inputChannels;\n        xReshaped = inputs[0].reshape([1, batch, sharedDim]);\n        wReshaped = transposedWeight.reshape([1, sharedDim, outChannels]);\n        matmulOutputShape = [1, batch, outChannels];\n      } else {\n        xReshaped = inputs[0].reshape([batch, inputHeight * inputWidth, inputChannels]);\n        wReshaped = transposedWeight.reshape([1, inputChannels, outChannels]);\n        matmulOutputShape = [batch, outHeight * outWidth, outChannels];\n      }\n      matmulInputs.push(xReshaped);\n      matmulInputs.push(wReshaped);\n    } else {\n      xReshaped = inputs[0].reshape([batch, inputChannels, inputHeight * inputWidth]);\n      wReshaped = inputs[1].reshape([1, outChannels, inputChannels]);\n      matmulOutputShape = [batch, outChannels, outHeight * outWidth];\n      matmulInputs.push(wReshaped);\n      matmulInputs.push(xReshaped);\n    }\n    if (hasBias) {\n      matmulInputs.push(inputs[2]);\n    }\n    const N = matmulOutputShape[2];\n    const K = matmulInputs[0].dims[matmulInputs[0].dims.length - 1];\n    // Tune the threshold.\n    if (N < 8 && K < 8) {\n      context.compute(\n          createNaiveMatmulProgramInfo(\n              matmulInputs, adjustedAttributes, outputShape, matmulOutputShape, isChannelsLast),\n          {inputs: matmulInputs});\n    } else {\n      context.compute(\n          createMatmulProgramInfo(matmulInputs, adjustedAttributes, outputShape, matmulOutputShape, isChannelsLast),\n          {inputs: matmulInputs});\n    }\n    return;\n  }\n\n  // TODO: implement conv2dWithIm2Col()\n\n  const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n  // STEP.1: transpose weight\n  const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n      context.compute(\n          createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n          {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n  if (attributes.wIsConst && !context.kernelCustomData.wT) {\n    context.kernelCustomData.wT = transposedWeight;\n  }\n\n  // STEP.2: prepare reshaped inputs\n  const convInputs = [inputs[0], transposedWeight];\n  if (hasBias) {\n    convInputs.push(inputs[2]);\n  }\n\n  // STEP.3: compute matmul\n  const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n  const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n  const dimInner = weightHeight * weightWidth * inputChannels;\n  context.compute(\n      createConv2DMatMulProgramInfo(\n          convInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n          sequentialAccessByThreads),\n      {inputs: convInputs});\n};\n\nconst conv1d = (context: ComputeContext, attributes: ConvAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (context.inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  const pads = [0, attributes.pads[0], 0, attributes.pads[1]];\n  const strides = [1].concat(attributes.strides);\n  const dilations = [1].concat(attributes.dilations);\n  const kernelShape = [1].concat(attributes.kernelShape);\n  const adjustedAttributes = getAdjustedConvAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createGroupedConvProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] : []));\n};\n\nexport const conv = (context: ComputeContext, attributes: ConvAttributes): void => {\n  validateInputs(context.inputs, attributes);  // currently will fail if not conv1D/2D\n  if (context.inputs[0].dims.length === 3) {\n    conv1d(context, attributes);\n  } else {\n    conv2d(context, context.inputs, attributes);\n  }\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ProgramInfo, ProgramUniform} from '../../types';\nimport {createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper} from '../common';\nimport {ConvTransposeAttributes} from '../conv-transpose';\nimport {getActivationSnippet} from '../fuse-utils';\n\nimport {biasSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dTransposeCommonSnippet =\n    (isChannelsLast: boolean, addBias = false, attributes: ConvTransposeAttributes, innerElementSize = 4): string => {\n      const type = typeSnippet(innerElementSize, 'f32');\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];';\n          case 4:\n            return `\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];\n            let v1 = w[getIndexFromCoords4D(coord1, vec4<i32>(uniforms.w_shape))];\n            let v2 = w[getIndexFromCoords4D(coord2, vec4<i32>(uniforms.w_shape))];\n            let v3 = w[getIndexFromCoords4D(coord3, vec4<i32>(uniforms.w_shape))];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      ` :\n                                             `\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'outBackprop[1]' : 'outBackprop[2]';\n      const xWidth = isChannelsLast ? 'outBackprop[2]' : 'outBackprop[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n\n      const readASnippet = `\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n      let outRow = ${row} / outWidth;\n      let outCol = ${row} % outWidth;\n\n      let WRow = ${col} / (filterDims[1] * inChannels);\n      let WCol = ${col} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${xHeight}) || fract(xR) > 0.0) {\n        return ${type}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${xWidth}) || fract(xC) > 0.0) {\n        return ${type}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${col} % inChannels;\n      ${coordASnippet}\n      return x[getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape))/${innerElementSize}];`;\n\n      const sampleA = isChannelsLast ? `\n      let col = colIn * ${innerElementSize};\n      if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);` :\n                                       `\n      let col = colIn * ${innerElementSize};\n      if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);`;\n\n      const sampleW = `\n      let col = colIn * ${innerElementSize};\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${\n          isChannelsLast ? 'row < uniforms.dimInner && col < uniforms.dimBOuter' :\n                           'row < uniforms.dimInner && col < uniforms.dimAOuter'}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${getWSnippet(innerElementSize)}\n      }\n      return ${type}(0.0);\n      `;\n\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, type);\n      const userCode = `\n      ${activationFunction}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleA : sampleW}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleW : sampleA}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${type}) {\n    let col = colIn * ${innerElementSize};\n    if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${isChannelsLast ? 'i32(uniforms.result_shape[2])' : 'i32(uniforms.result_shape[3])'};\n      ${coordResSnippet}\n      ${biasSnippet(addBias)}\n      ${applyActivation}\n      result[getIndexFromCoords4D(coords, vec4<i32>(uniforms.result_shape))/${innerElementSize}] = value;\n    }\n  }`;\n      return userCode;\n    };\n\nexport const createConv2DTransposeMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes, outputShape: readonly number[],\n     dimAOuter: number, dimBOuter: number, dimInner: number, hasBias: boolean,\n     sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      const isVec4 =\n          isChannelsLast ? inChannels % 4 === 0 && outChannels % 4 === 0 : outWidth % 4 === 0 && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = isVec4 ?\n          [8, 8, 1] :\n          [(dispatchX <= 4 || dispatchY <= 4) ? 4 : 16, dispatchX > 4 && dispatchY <= 4 ? 4 : 16, 1];\n      const elementsPerThread =\n          isVec4 ? [4, 4, 1] : [dispatchX <= 4 ? 1 : 4, dispatchX > 4 && dispatchY <= 4 ? 1 : 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv_backprop_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? 4 : 1;\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n      const components = isVec4 ? 4 : 1;\n      const programUniforms: ProgramUniform[] =\n          [{type: 'int32', data: dimAOuter}, {type: 'int32', data: dimBOuter}, {type: 'int32', data: dimInner}];\n      const x = inputVariable('x', inputs[0].dataType, inputs[0].dims.length, components);\n      const w = inputVariable('w', inputs[1].dataType, inputs[1].dims.length, 1);\n      const output = outputVariable('result', inputs[0].dataType, outputShape.length, components);\n      const inputVariables = [x, w];\n      programUniforms.push(...createTensorShapeVariables(inputs[0].dims));\n      programUniforms.push(...createTensorShapeVariables(inputs[1].dims));\n\n      let declareFunctions = '';\n      if (hasBias) {\n        const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims.length, components);\n        inputVariables.push(bias);\n        programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? 'vec4<f32>' : 'f32'} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n\n      programUniforms.push(...createTensorShapeVariables(outputShape));\n\n      return {\n        name: 'Conv2DTransposeMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          programUniforms\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => `\n        ${utilFunctions('uniforms.result_strides')}\n        ${\n            shaderHelper.registerUniform('dimAOuter', 'i32')\n                .registerUniform('dimBOuter', 'i32')\n                .registerUniform('dimInner', 'i32')\n                .declareVariables(...inputVariables, output)};\n        const outBackprop : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n            attributes.kernelShape[isChannelsLast ? 2 : 3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${\n            attributes.dilations[0] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n              ${\n            attributes.dilations[1] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${\n            attributes.pads[0] + attributes.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${\n            attributes.pads[1] + attributes.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${conv2dTransposeCommonSnippet(isChannelsLast, hasBias, attributes, innerElementSize)}\n        ${\n            isVec4 ? makeMatMulPackedVec4Source(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner) :\n                     makeMatMulPackedSource(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner, false,\n                         undefined, sequentialAccessByThreads)}`\n      };\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_webgpu.ts\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {ConvTransposeAttributes} from '../conv-transpose';\n\nconst createConvTranspose2DOpProgramShaderSource =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     outputShape: readonly number[], hasBias: boolean, is1DimensionDispatch: boolean, isVec4 = false,\n     dataType: string): string => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const rowDim = isChannelsLast ? 1 : 2;\n      const colDim = isChannelsLast ? 2 : 3;\n      const channelDim = isChannelsLast ? 3 : 1;\n      const outputSize = ShapeUtil.size(outputShape);\n      const workPerThread = isVec4 ? 2 : 1;\n      const group = attributes.group;\n      const wShape = inputs[1].dims;\n      const inputChannelsPerGroup = wShape[0] / group;\n      const outputChannelsPerGroup = wShape[1];\n\n      let declareFunctions = `\n  fn setOutputAtIndex(flatIndex : u32, value : ${isVec4 ? `vec4<${dataType}>` : dataType}) {\n    result[flatIndex] = ${isVec4 ? `vec4<${dataType}>` : dataType}(value);\n  }`;\n      if (hasBias) {\n        declareFunctions += `\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${isVec4 ? `vec4<${dataType}>` : dataType} {\n      return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n    }`;\n      }\n      const components = isVec4 ? 4 : 1;\n      const w = inputVariable('W', inputs[1].dataType, inputs[1].dims, components);\n      const dy = inputVariable('Dy', inputs[0].dataType, inputs[0].dims, components);\n      const inputVariables = [dy, w];\n      if (hasBias) {\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, [outputShape[channelDim]], components));\n      }\n      const output = outputVariable('result', inputs[0].dataType, outputShape, components);\n      const codeSnippet4 = `{\n        let batch: u32 = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} / outShape[1];\n        let r = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} % outShape[1];\n        let c = ${is1DimensionDispatch ? 'global_id.y' : 'workgroup_id.y'} * ${workPerThread};\n        let d1: u32 = ${is1DimensionDispatch ? 'global_id.x' : 'workgroup_id.x'} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${dataType}>, ${workPerThread}>;\n        for (var i = 0; i < ${workPerThread}; i++) {\n          dotProd[i] = vec4<${dataType}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${dataType}(dyCorner.x) + ${dataType}(wR)) / ${dataType}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${dataType}(dyCorner.y) + ${dataType}(wC)) / ${dataType}(strides.y);\n            let dyC2 = (${dataType}(dyCorner.y) + 1.0 + ${dataType}(wC)) / ${dataType}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${dataType}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n\n                dotProd[1] = dotProd[1] + vec4<${dataType}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${channelDim}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${workPerThread}; i = i + 1) {\n          let value = dotProd[i] + ${hasBias ? 'bias[c+i]' : `vec4<${dataType}>(0.0)`};\n          ${output.set('batch', 'r', 'c + i', 'd1', 'value')};\n        }\n      }`;\n      const codeSnippet = `\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let batch = ${output.indicesGet('outputIndices', 0)};\n          let d1 = ${output.indicesGet('outputIndices', channelDim)};\n          let r = ${output.indicesGet('outputIndices', rowDim)};\n          let c = ${output.indicesGet('outputIndices', colDim)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${outputChannelsPerGroup};\n          let wOutChannel = d1 - groupId * ${outputChannelsPerGroup};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = ${dataType}(0.0);\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${dataType}(dyRCorner) + ${dataType}(wR)) / ${dataType}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[${rowDim}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${dataType}(dyCCorner) + ${dataType}(wC)) / ${dataType}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[${colDim}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${inputChannelsPerGroup};\n              for (var d2: u32 = 0; d2 < ${inputChannelsPerGroup}; d2 = d2 + 1) {\n                let xValue = ${\n          isChannelsLast ? dy.get('batch', 'idyR', 'idyC', 'inputChannel') :\n                           dy.get('batch', 'inputChannel', 'idyR', 'idyC')};\n                let wValue = ${w.get('inputChannel', 'wOutChannel', 'u32(wRPerm)', 'u32(wCPerm)')};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${hasBias ? 'bias[d1]' : `${dataType}(0.0)`};\n          ${output.setByOffset('global_idx', 'value')};\n        `;\n\n      return `\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${declareFunctions}\n  const outShape : vec4<u32> = vec4<u32>(${outputShape.join(',')});\n  const outBackprop : vec4<u32> = vec4<u32>(${inputs[0].dims.join(',')});\n  const strides : vec2<u32> = vec2<u32>(${attributes.strides[0]}, ${attributes.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n          attributes.kernelShape[isChannelsLast ? 2 : 3]});\n  const dilations : vec2<u32> = vec2<u32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${\n          attributes.dilations[0] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n          ${\n          attributes.dilations[1] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${attributes.pads[0] + attributes.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${attributes.pads[1] + attributes.pads[3]})/2);\n    ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)};\n  ${isVec4 ? codeSnippet4 : codeSnippet}}`;\n    };\n\nexport const createConvTranspose2DProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      // const isChannelsLast = attributes.format === 'NHWC';\n      const outputShape = attributes.outputShape;\n      const outputSize = ShapeUtil.size(outputShape);\n\n      // const inChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n      // TODO Enable isVec4 for performance\n      // Disabled due to weight matrix layout issue\n      // const isVec4 = attributes.group === 1 && isChannelsLast && inChannels % 4 === 0 && outChannels % 4 === 0;\n      const dispatch = [\n        Math.ceil(outputSize / 64),\n        1,\n        1,\n      ];\n      LOG_DEBUG('verbose', () => `[conv2d_backprop_webgpu] dispatch = ${dispatch}`);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      return {\n        name: 'ConvTranspose2D',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }]\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => createConvTranspose2DOpProgramShaderSource(\n            shaderHelper, inputs, attributes, outputShape, hasBias, dispatch[1] === 1 && dispatch[2] === 1, false,\n            dataType),\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DTransposeMatMulProgramInfo} from './3rd-party/conv_backprop_mm_webgpu';\nimport {createConvTranspose2DProgramInfo} from './3rd-party/conv_backprop_webgpu';\nimport {ConvAttributes} from './conv';\nimport {parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst computeTotalPad =\n    (inDim: number, stride: number, adj: number, kernel: number, dilation: number, outSize: number) =>\n        (inDim - 1) * stride + adj + (kernel - 1) * dilation + 1 - outSize;\n\nconst distributePadding = (totalPad: number, autoPad: string, pads: number[], head: number, tail: number) => {\n  const smallPad = Math.floor(totalPad / 2);\n  if (autoPad === 'SAME_UPPER') {\n    pads[head] = smallPad;\n    pads[tail] = totalPad - smallPad;\n  } else if (autoPad === 'SAME_LOWER') {\n    pads[head] = totalPad - smallPad;\n    pads[tail] = smallPad;\n  }\n};\n\nconst calculateOutputShapeAndPads =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[], autoPad: string,\n     group: number, pads: number[], strides: readonly number[], isChannelLast: boolean, outputPadding: number[],\n     outputShape: number[]) => {\n      const spatialRank = inputShape.length - 2;\n      const updateOutputShape = outputShape.length === 0;\n      if (outputPadding.length === 0) {\n        for (let i = 0; i < spatialRank; ++i) {\n          outputPadding.push(0);\n        }\n      }\n      const batchSize = inputShape[0];\n      const outChannels = kernelShape[isChannelLast ? 3 : 1] * group;\n      for (let i = 0, j = inputShape.length - spatialRank - (isChannelLast ? 1 : 0); i < spatialRank; ++i, ++j) {\n        const inSize = inputShape[j];\n        const outSize = updateOutputShape ? inSize * strides[i] : outputShape[i];\n        const totalPad = computeTotalPad(inSize, strides[i], pads[i], kernelShape[j], dilations[i], outSize);\n        distributePadding(totalPad, autoPad, pads, i, i + spatialRank);\n        if (updateOutputShape) {\n          outputShape.push(\n              strides[i] * (inSize - 1) + outputPadding[i] + (kernelShape[j] - 1) * dilations[i] + 1 - pads[i] -\n              pads[i + spatialRank]);\n        }\n      }\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n    };\n\nexport interface ConvTransposeAttributes extends ConvAttributes {\n  readonly outputPadding: readonly number[];\n  readonly outputShape: readonly number[];\n}\n\n\nconst getAdjustedConvTransposeAttributes =\n    <T extends ConvTransposeAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n      const kernelShape = attributes.kernelShape.slice();\n      // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n      if (attributes.kernelShape.length === 0 || attributes.kernelShape.reduce((a, b) => a * b, 1) === 0) {\n        kernelShape.length = 0;\n        for (let i = 2; i < inputs[1].dims.length; ++i) {\n          kernelShape.push(inputs[1].dims[i]);\n        }\n      }\n      const isChannelsLast = attributes.format === 'NHWC';\n      kernelShape.splice(0, 0, inputs[1].dims[0]);\n      kernelShape.splice(isChannelsLast ? 3 : 1, 0, inputs[1].dims[1]);\n\n      const pads = attributes.pads.slice();\n      const outputShape = attributes.outputShape.slice();\n      const outputPadding = attributes.outputPadding.slice();\n      const inputShape = inputs[0].dims;\n      let dilations = attributes.dilations.slice();\n      if (dilations.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        dilations = new Array(spatialRank).fill(1);\n      }\n      let strides = attributes.strides.slice();\n      if (strides.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        strides = new Array(spatialRank).fill(1);\n      }\n      // If outputShape is not specified in the attributes of this op, infer it from the parameters\n      // Similarly, automatically infer pads if not specified\n      calculateOutputShapeAndPads(\n          inputShape, kernelShape, dilations, attributes.autoPad, attributes.group, pads, strides, isChannelsLast,\n          outputPadding, outputShape);\n\n      // always return a new object so does not modify the original attributes\n      const newAttributes: T = Object.assign({}, attributes);\n      const cacheKey = attributes.cacheKey + [\n        kernelShape.join('n,'), pads.join(','), strides.join(','), outputPadding.join(','), outputShape.join(','),\n        dilations.join(',')\n      ].join('_');\n      Object.assign(newAttributes, {kernelShape, pads, outputPadding, outputShape, dilations, strides, cacheKey});\n      return newAttributes;\n    };\n\nexport const parseConvTransposeAttributes = (attributes: Record<string, unknown>): ConvTransposeAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad =\n      ['NOTSET', 'VALID', 'SAME_UPPER',\n       'SAME_LOWER'][typeof attributes.autoPad == 'undefined' ? 0 : attributes.autoPad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernelShape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.wIsConst as () => boolean)();\n  const outputPadding = attributes.outputPadding as [number, number, number, number];\n  const outputShape = attributes.outputShape as [number, number];\n  return createAttributeWithCacheKey({\n    autoPad,\n    format,\n    dilations,\n    group,\n    kernelShape,\n    outputPadding,\n    outputShape,\n    pads,\n    strides,\n    wIsConst,\n    ...activationAttributes\n  });\n};\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support 2-dimensional conv');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[0];\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  const featureMaps = inputs[1].dims[1] * attributes.group;\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[2].dims[0] !== featureMaps)) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  const dilationsSet = attributes.dilations.reduce((a, b) => a + b, 0) > 0;\n  // wrong dilations dimension\n  if (dilationsSet && attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  const stridesSet = attributes.strides.reduce((a, b) => a + b, 0) > 0;\n  // Wrong strides dimension\n  if (stridesSet && attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  const padsSet = attributes.pads.reduce((a, b) => a + b, 0) > 0;\n  if (padsSet && attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // Wrong output padding dimension\n  if (attributes.outputPadding.length !== spatialRank && attributes.outputPadding.length !== 0) {\n    throw new Error(`output_padding should be ${spatialRank}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  const kernelShapeSet = attributes.kernelShape.reduce((a, b) => a + b, 0) > 0;\n  if (kernelShapeSet && attributes.kernelShape.length !== 0 &&\n      attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n\n  // as with kernelShape, must have same number of spatial dims as input\n  if (attributes.outputShape.length !== 0 && attributes.outputShape.length !== inputs[0].dims.length - 2) {\n    throw new Error('invalid output shape');\n  }\n};\n\n// for transposing weight tensor from [C, M/group, KH, KW] to [KH, KW, M/group, C]\nconst weightTransposePerm = [2, 3, 1, 0];\n\nconst convTranspose2d =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n      const adjustedAttributes = getAdjustedConvTransposeAttributes(attributes, inputs);\n      const isChannelsLast = attributes.format === 'NHWC';\n      const outputShape = adjustedAttributes.outputShape;\n      const outChannels = outputShape[isChannelsLast ? 3 : 1];\n      const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n      // Switch to naive method when outChannels and inputChannels are very small. It's because that in this case it's\n      // not suitable for matmul version since matmul uses tile size 32x32 resulting the underlying execution unit\n      // utilization rate is very low.\n      if (adjustedAttributes.group !== 1 || (outChannels === 1 && inputChannels === 1)) {\n        context.compute(createConvTranspose2DProgramInfo(inputs, adjustedAttributes));\n        return;\n      }\n      const outHeight = outputShape[isChannelsLast ? 1 : 2];\n      const outWidth = outputShape[isChannelsLast ? 2 : 3];\n      const weightHeight = inputs[1].dims[2];\n      const weightWidth = inputs[1].dims[3];\n\n      const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n      const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n      const dimInner = weightHeight * weightWidth * inputChannels;\n\n      const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n\n      // STEP.1: transpose weight\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposePerm),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n\n      // STEP.2: prepare reshaped inputs\n      const convTransposeInputs = [inputs[0], transposedWeight];\n      const hasBias = inputs.length === 3;\n      if (hasBias) {\n        if (!isChannelsLast && inputs[2].dims.length === 1) {\n          convTransposeInputs.push(inputs[2].reshape([inputs[2].dims[0], 1, 1]));\n        } else {\n          convTransposeInputs.push(inputs[2]);\n        }\n      }\n\n      // STEP.3: compute matmul\n      context.compute(\n          createConv2DTransposeMatMulProgramInfo(\n              convTransposeInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n              sequentialAccessByThreads),\n          {inputs: convTransposeInputs});\n    };\n\nconst convTranspose1d = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  let kernelShape = attributes.kernelShape;\n  if (kernelShape.length === 0 || kernelShape[0] === 0) {\n    kernelShape = [context.inputs[1].dims[2]];\n  }\n  let dilations = attributes.dilations;\n  if (dilations.length === 0 || dilations[0] === 0) {\n    dilations = [1];\n  }\n  let strides = attributes.strides;\n  if (strides.length === 0 || strides[0] === 0) {\n    strides = [1];\n  }\n  let pads = attributes.pads;\n  if (pads.length === 0) {\n    pads = [0, 0];\n  }\n  pads = [0, pads[0], 0, pads[1]];\n  strides = [1].concat(strides);\n  dilations = [1].concat(dilations);\n  kernelShape = [1].concat(kernelShape);\n  const adjustedAttributes =\n      getAdjustedConvTransposeAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createConvTranspose2DProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] :\n                                     [outputShape[0], outputShape[1], outputShape[3]]));\n};\n\nexport const convTranspose = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  if (context.inputs[0].dims.length === 3) {\n    convTranspose1d(context, attributes);\n  } else {\n    convTranspose2d(context, context.inputs, attributes);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, getElementAt, inputVariable, outputVariable, ShaderHelper} from './common';\n\n\nexport interface CumSumAttributes extends AttributeWithCacheKey {\n  readonly exclusive: boolean;\n  readonly reverse: boolean;\n}\nconst createCumsumProgramInfo =\n    (inputType: number, inputShape: readonly number[], axisInput: TensorView, attributes: CumSumAttributes):\n        ProgramInfo => {\n          const outputSize = ShapeUtil.size(inputShape);  // outputShape is same as inputShape.\n          const rank = inputShape.length;                 // input/output rank\n          const input = inputVariable('input', inputType, rank);\n          const output = outputVariable('output', inputType, rank);\n          const axisValue = axisInput.dataType === DataType.int32 ? axisInput.getInt32Array()[0] :\n                                                                    Number(axisInput.getBigInt64Array()[0]);\n          const axis = ShapeUtil.normalizeAxis(axisValue, rank);\n          const getShaderSource = (shaderHelper: ShaderHelper) => {\n            const index = ` i32(${input.indicesGet('inputIndices', 'uniforms.axis')}) `;\n            const max = getElementAt('uniforms.input_shape', 'uniforms.axis', rank);\n            const lowerLimit = attributes.reverse ? index + (attributes.exclusive ? ' + 1' : '') : '0';\n            const upperLimit = attributes.reverse ? max : index + (attributes.exclusive ? '' : ' + 1');\n            return `\n                ${\n                shaderHelper.registerUniform('outputSize', 'u32')\n                    .registerUniform('axis', 'u32')\n                    .declareVariables(input, output)}\n                ${shaderHelper.mainStart()}\n                  ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n                  var inputIndices = ${output.offsetToIndices('global_idx')};\n                  var sum = ${output.type.value}(0);\n                  let first : i32 = ${lowerLimit};\n                  let last : i32 = ${upperLimit};\n                  for (var i : i32 = first; i < last; i++) {\n                    ${input.indicesSet('inputIndices', 'uniforms.axis', 'u32(i)')};\n                    sum = sum + ${input.getByIndices('inputIndices')};\n                  }\n                  ${output.setByOffset('global_idx', 'sum')};\n                }`;\n          };\n          return {\n            name: 'CumSum',\n            shaderCache: {hint: attributes.cacheKey, inputDependencies: ['rank']},\n            getRunData: () => ({\n              outputs: [{dims: inputShape, dataType: inputType}],\n              dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n              programUniforms: [\n                {type: 'uint32', data: outputSize}, {type: 'int32', data: axis},\n                ...createTensorShapeVariables(inputShape), ...createTensorShapeVariables(inputShape)\n              ]\n\n            }),\n            getShaderSource\n          };\n        };\n\n\nexport const cumsum = (context: ComputeContext, attributes: CumSumAttributes): void => {\n  const inputShape = context.inputs[0].dims;\n  const inputType = context.inputs[0].dataType;\n  const axis = context.inputs[1];\n  context.compute(createCumsumProgramInfo(inputType, inputShape, axis, attributes), {inputs: [0]});\n};\n\nexport const parseCumSumAttributes = (attributes: Record<string, unknown>): CumSumAttributes => {\n  const exclusive = attributes.exclusive as number === 1;\n  const reverse = attributes.reverse as number === 1;\n  return createAttributeWithCacheKey({exclusive, reverse});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\n\nexport interface EinsumAttributes extends AttributeWithCacheKey {\n  readonly equation: string;\n}\n// The equation attribute value is a string which consists of left hand side (LHS) and optionally right hand side (RHS)\n// separated by '->'. Ex. \"ij,jk -> ik\" expresses matrix multiplication\n//     \"ij->ji\" expresses matrix transpose\n//      \"ii->i\" diagonal elements of a square matrix\n// LHS consists of a sequence of terms separated by commas. Each term corresponds to an input variable.\n// Each symbol corresponds to a dimension in the input variable. The symbol can be either a letter, 'a' to 'z' or 'A' to\n// 'Z' or '...' to represent arbitrary dimensions.\n\nconst symbolPattern =\n    '[a-zA-Z]|\\\\.\\\\.\\\\.';  // The pattern each symbol in each term in the symbolic equation should match\nconst termPattern = '(' + symbolPattern + ')+';   // The pattern each term in the symbolic equation should match\nconst termPatternOnly = '^' + termPattern + '$';  // The patterns only matchs a term begin to end.\nconst lhsPattern = '(' + termPattern + ',)*' + termPattern;  // The pattern the LHS should match\nconst lhsPatternOnly = '^' + lhsPattern + '$';               // The patterns only matchs a LHS begin to end.\n\ninterface SymbolInfo {\n  count: number;           // Symbol corresponding to a dimmension of an input\n  inputIndices: number[];  // Number of input variables the symbol corresponds to\n  dimValue: number;        // Number of dimensions the symbol corresponds to\n}\n\nclass EinsumTerm {\n  constructor(inputIndex = -1) {\n    this.symbolToIndices = new Map<string, number[]>();\n    this.inputIndex = inputIndex;\n  }\n\n  // Add a symbol to the term\n  addSymbol(symbol: string, index: number) {\n    let value = this.symbolToIndices.get(symbol);\n    if (value === undefined) {\n      value = [index];\n    } else {\n      value.push(index);\n    }\n    this.symbolToIndices.set(symbol, value);\n  }\n\n  symbolToIndices: Map<string, number[]>;  // Map from symbol to dimensions of the input corresponding to the term\n  inputIndex: number;                      // -1 for output and 0, 1, 2, ... for inputs\n}\n\nclass EinsumEquation {\n  constructor(inputs: readonly TensorView[], public readonly equation: string) {\n    this.hasEllipsis = false;\n    this.symbolToInfo = new Map<string, SymbolInfo>();\n    this.lhs = new Array<EinsumTerm>();\n    this.outputDims = [];\n    // As rhs needs to be updated allow using let instead of const for both lhs and rhs.\n    // eslint-disable-next-line prefer-const\n    let [lhs, rhs] = equation.includes('->') ? equation.split('->', 2) : [equation, ''];\n    if (!lhs.match(RegExp(lhsPatternOnly))) {\n      throw new Error('Invalid LHS term');\n    }\n    const inputTerms = lhs.split(',');\n    inputTerms.forEach((inputTerm, index) => {\n      const dims = inputs[index].dims.slice();\n      if (!inputTerm.match(RegExp(termPatternOnly))) {\n        throw new Error('Invalid LHS term');\n      }\n      const einsumTerm = this.processTerm(inputTerm, true, dims, index);\n      this.lhs.push(einsumTerm);\n    });\n\n    // Initialize the RHS if not specified\n    if (rhs === '') {\n      // Construct RHS from LHS terms/symbols\n      rhs += [...this.symbolToInfo.entries()]\n                 .filter(([sym, info]) => (info.count === 1 || sym === '...'))\n                 .map(([sym]) => sym)\n                 .join('');\n    } else {\n      if (!rhs.match(RegExp(termPattern))) {\n        throw new Error('Invalid RHS');\n      }\n    }\n\n    // Compute output dims\n    const rhsSymbols = rhs.match(RegExp(symbolPattern, 'g'));\n    rhsSymbols?.forEach((symbol) => {\n      if (symbol === '...') {\n        this.outputDims = this.outputDims.concat(this.ellipsisDims);\n      } else {\n        const info = this.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid RHS symbol');\n        }\n        this.outputDims.push(info.dimValue);\n      }\n    });\n    this.rhs = this.processTerm(rhs, false, this.outputDims);\n  }  // End of EinsumEqation constructor\n\n  // Add a symbol to the equation\n  addSymbol(symbol: string, dimValue: number, inputIndex: number) {\n    let info = this.symbolToInfo.get(symbol);\n    if (info !== undefined) {\n      if (info.dimValue !== dimValue && info.count !== 1) {\n        throw new Error('Dimension mismatch');\n      } else {\n        info.count++;\n        info.inputIndices.push(inputIndex);\n      }\n    } else {\n      info = {count: 1, dimValue, inputIndices: [inputIndex]};\n    }\n    this.symbolToInfo.set(symbol, info);\n  }\n\n  // Process one input/output term\n  processTerm(term: string, isInput: boolean, dims: readonly number[], index = -1): EinsumTerm {\n    const rank = dims.length;\n    let ellipsis = false;\n    let ellipsisDims = [];\n    let nextDim = 0;\n    // For output empty string is allowed because the output may be reduced to a scalar value\n    if (!term.match(RegExp(termPatternOnly)) && (!isInput && term !== '')) {\n      throw new Error('Invalid LHS term');\n    }\n    const indexSymbols = term.match(RegExp(symbolPattern, 'g'));\n    const einsumTerm = new EinsumTerm(index);\n    // symbol can be either a lettre, 'a' to 'z' or 'A' to 'Z', or '...'\n    indexSymbols?.forEach((symbol: string, i: number) => {\n      if (symbol === '...') {\n        if (ellipsis) {\n          throw new Error('Only one ellipsis is allowed per input term');\n        }\n        ellipsis = true;\n        const ellipsisDimLength = rank - indexSymbols.length + 1;\n        if (ellipsisDimLength < 0) {\n          throw new Error('Ellipsis out of bounds');\n        }\n        ellipsisDims = dims.slice(nextDim, nextDim + ellipsisDimLength);\n        if (this.hasEllipsis) {\n          if (this.ellipsisDims.length !== ellipsisDims.length ||\n              this.ellipsisDims.toString() !== ellipsisDims.toString()) {\n            throw new Error('Ellipsis dimensions mismatch');\n          }\n        } else if (isInput) {\n          this.hasEllipsis = true;\n          this.ellipsisDims = ellipsisDims;\n        } else {\n          throw new Error('Ellipsis must be specified in the LHS');\n        }\n        // Add '0', '1', '2', '3', '4', etc to represent ellipsis dimensions to avoid special handling\n        for (let j = 0; j < ellipsisDims.length; j++) {\n          const symbol = String.fromCharCode('0'.charCodeAt(0) + j);\n          einsumTerm.addSymbol(symbol, i + j);\n          this.addSymbol(symbol, dims[nextDim++], index);\n        }\n      } else {\n        einsumTerm.addSymbol(symbol, i + (this.hasEllipsis ? this.ellipsisDims.length - 1 : 0));\n        this.addSymbol(symbol, dims[nextDim++], index);\n      }\n    });\n    return einsumTerm;\n  }\n\n  symbolToInfo: Map<string, SymbolInfo>;  // All symbols in the equation\n  hasEllipsis: boolean;                   // The equation has ellipsis or not\n  ellipsisDims: number[];                 // The dimensions of the equation ellipsis corresponds to.\n  lhs: EinsumTerm[];                      // Terms on the left-hand side of the equation\n  rhs: EinsumTerm;                        // Term on the right-hand side of the equation\n  outputDims: number[];                   // Output dimensions of the equation\n}  // End of class EinsumEquation\n\nconst appendMax = (name: string): string => name + '_max';\n\nconst createEinsumProgramInfo =\n    (enableInputShapesUniforms: readonly boolean[], inputShapes: Array<readonly number[]>, dataType: number,\n     einsumEquation: EinsumEquation, outputShape: readonly number[]): ProgramInfo => {\n      const shapeOrRanks = inputShapes.map((dims, index) => enableInputShapesUniforms[index] ? dims.length : dims);\n      const inputVars = shapeOrRanks.map((shapeOrRank, index) => inputVariable(`input${index}`, dataType, shapeOrRank));\n      const outputSize = ShapeUtil.size(outputShape);\n      const enableOutputShapesUniforms = enableShapesUniforms(outputShape.length);\n      const outputShapeOrRank = enableOutputShapesUniforms ? outputShape.length : outputShape;\n      const output = outputVariable('output', dataType, outputShapeOrRank);\n      const uniformsSymbols =\n          [...einsumEquation.symbolToInfo.keys()].filter((symbol) => !einsumEquation.rhs.symbolToIndices.has(symbol));\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const idxCopy: string[] = [];\n        const initProd = 'var prod = 1.0;';\n        const initSum = 'var sum = 0.0;';\n        const updateSum = 'sum += prod;';\n        const reduceOpsSetIndices: string[] = [];\n        const reduceOpsLoopHeaders: string[] = [];\n        const reduceOpsLoopFooters: string[] = [];\n        const reduceOpCompute: string[] = [];\n        const isReduceOpsWithoutLoop = einsumEquation.symbolToInfo.size === einsumEquation.rhs.symbolToIndices.size;\n        einsumEquation.symbolToInfo.forEach((info, symbol) => {\n          if (einsumEquation.rhs.symbolToIndices.has(symbol)) {\n            const outputIndex = einsumEquation.rhs.symbolToIndices.get(symbol)?.[0];\n            if (outputIndex !== undefined) {\n              einsumEquation.lhs.forEach((term, i) => {\n                if (info.inputIndices.includes(i)) {\n                  const indices = term.symbolToIndices.get(symbol);\n                  if (indices === undefined) {\n                    throw new Error('Invalid symbol error');\n                  }\n                  indices.forEach((index) => {\n                    idxCopy.push(`${\n                        inputVars[i].indicesSet(\n                            `input${i}Indices`, index, output.indicesGet('outputIndices', outputIndex))}`);\n                  });\n                }\n              });\n            }\n          } else {\n            einsumEquation.lhs.forEach((term, i) => {\n              if (info.inputIndices.includes(i)) {\n                const indices = term.symbolToIndices.get(symbol);\n                if (indices === undefined) {\n                  throw new Error('Invalid symbol error');\n                }\n                indices.forEach((index) => {\n                  reduceOpsSetIndices.push(`${inputVars[i].indicesSet(`input${i}Indices`, index, `${symbol}`)}`);\n                });\n                reduceOpCompute.push(`prod *= ${inputVars[i].getByIndices(`input${i}Indices`)};`);\n              }\n            });\n            reduceOpsLoopHeaders.push(\n                `for(var ${symbol}: u32 = 0; ${symbol} < uniforms.${appendMax(symbol)}; ${symbol}++) {`);\n            reduceOpsLoopFooters.push('}');\n          }\n        });\n        const reduceOps = isReduceOpsWithoutLoop ?\n            [\n              ...idxCopy,\n              `let sum = ${inputVars.map((inputVar, i) => inputVar.getByIndices(`input${i}Indices`)).join(' * ')};`\n            ] :\n            [\n              ...idxCopy,\n              initSum,\n              ...reduceOpsLoopHeaders,\n              ...reduceOpsSetIndices,\n              initProd,\n              ...reduceOpCompute,\n              updateSum,\n              ...reduceOpsLoopFooters,\n            ];\n        return `\n            ${\n            shaderHelper\n                .registerUniforms(uniformsSymbols.map((symbol) => ({name: `${appendMax(symbol)}`, type: 'u32'})))\n                .registerUniform('outputSize', 'u32')\n                .declareVariables(...inputVars, output)}\n\n            ${shaderHelper.mainStart()}\n            ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n            var outputIndices = ${output.offsetToIndices('global_idx')};\n            ${inputVars.map((_var, i) => `var input${i}Indices: ${inputVars[i].type.indices};`).join('\\n')}\n            ${reduceOps.join('\\n')};\n            ${output.setByOffset('global_idx', 'sum')};\n          }`;\n      };\n      return {\n        name: 'Einsum',\n        shaderCache: {\n          hint: einsumEquation.equation,\n          inputDependencies: enableInputShapesUniforms.map((enableShapeUniform) => enableShapeUniform ? 'rank' : 'dims')\n        },\n        getRunData: () => {\n          // The symbols from uniformSymbols array are guaranteed to exist in einsumEquations.symbolToInfo map. The\n          // filter is added to make sure that dimValue is never 0.\n          const programUniformsInit: ProgramUniform[] =\n              uniformsSymbols.filter((symbol) => einsumEquation.symbolToInfo.has(symbol))\n                  .map((symbol) => ({type: 'uint32', data: einsumEquation.symbolToInfo.get(symbol)?.dimValue || 0}));\n          programUniformsInit.push({type: 'uint32', data: outputSize});\n          const programUniforms: ProgramUniform[] =\n              inputShapes.filter((_, index) => enableInputShapesUniforms[index])\n                  .map((dims, _) => [...createTensorShapeVariables(dims)])\n                  .reduce((acc, inputProgramUniforms) => acc.concat(inputProgramUniforms), programUniformsInit);\n          if (enableOutputShapesUniforms) {\n            programUniforms.push(...createTensorShapeVariables(outputShape));\n          }\n          return ({\n            outputs: [{dims: outputShape, dataType}],\n            dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n            programUniforms\n          });\n        },\n        getShaderSource,\n      };\n    };\n\nexport const einsum = (context: ComputeContext, attributes: EinsumAttributes): void => {\n  const einsumEquation = new EinsumEquation(context.inputs, attributes.equation);\n  const enableInputShapesUniforms = context.inputs.map((input, _) => enableShapesUniforms(input.dims.length));\n  const outputShape = einsumEquation.outputDims;\n  const inputShapes = context.inputs.map((input, _) => input.dims);\n  context.compute(createEinsumProgramInfo(\n      enableInputShapesUniforms, inputShapes, context.inputs[0].dataType, einsumEquation, outputShape));\n};\n\nexport const parseEinsumAttributes = (attributes: Record<string, unknown>): EinsumAttributes => {\n  const equation = (attributes.equation as string).replace(/\\s+/g, '');\n  return createAttributeWithCacheKey({equation});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Expand requires 2 input.');\n  }\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n\n  let shapeIndex = shape.length < inputShape.length ? 0 : shape.length - inputShape.length;\n  let inputShapeIndex = inputShape.length < shape.length ? 0 : inputShape.length - shape.length;\n  for (; shapeIndex < shape.length && inputShapeIndex < inputShape.length; ++shapeIndex, ++inputShapeIndex) {\n    if (shape[shapeIndex] !== inputShape[inputShapeIndex] && shape[shapeIndex] !== 1 &&\n        inputShape[inputShapeIndex] !== 1) {\n      throw new Error('Expand requires shape to be broadcastable to input');\n    }\n  }\n};\n\nconst getAdjustedShape = (shape1: readonly number[], shape2: readonly number[]): number[] => {\n  const diff = shape1.length - shape2.length;\n  const shape: number[] = [];\n  for (let i = 0; i < diff; ++i) {\n    shape.push(shape1[i]);\n  }\n  for (let i = 0; i < shape2.length; ++i) {\n    shape.push(shape2[i] === 1 ? shape1[i + diff] : shape2[i]);\n  }\n  return shape;\n};\n\nconst calculateOutputShape = (inputShape: readonly number[], shape: readonly number[]): number[] =>\n    (inputShape.length > shape.length) ? getAdjustedShape(inputShape, shape) : getAdjustedShape(shape, inputShape);\n\n\nconst createExpandProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n  const outputShape: number[] = calculateOutputShape(inputShape, shape);\n  const dataType = inputs[0].dataType;\n  const components = dataType === DataType.bool ? 4 : 1;\n  const outputSize = Math.ceil(ShapeUtil.size(outputShape) / components);\n\n  const enableInputShapeUniform = enableShapesUniforms(inputShape.length);\n  const enableOutputShapeUniform = enableShapesUniforms(outputShape.length);\n\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const inputShapeOrRank = enableInputShapeUniform ? inputShape.length : inputShape;\n    const outputShapeOrRank = enableOutputShapeUniform ? outputShape.length : outputShape;\n    const input = inputVariable('input', dataType, inputShapeOrRank, components);\n    const output = outputVariable('output', dataType, outputShapeOrRank, components);\n    let assignment: string;\n    if (dataType === DataType.bool) {\n      const singleAssignment = (resStr: string, x: number, typeCast = '') => `\n          let outputIndices${x} = ${output.offsetToIndices(`outputOffset + ${x}u`)};\n          let offset${x} = ${input.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n          let index${x} = offset${x} / 4u;\n          let component${x} = offset${x} % 4u;\n          ${resStr}[${x}] = ${typeCast}(${input.getByOffset(`index${x}`)}[component${x}]);\n        `;\n      assignment = `\n        let outputOffset = global_idx * ${components};\n        var data = vec4<u32>(0);\n        ${singleAssignment('data', 0, 'u32')}\n        ${singleAssignment('data', 1, 'u32')}\n        ${singleAssignment('data', 2, 'u32')}\n        ${singleAssignment('data', 3, 'u32')}\n        ${output.setByOffset('global_idx', 'data')}\n      }`;\n    } else {\n      assignment = `\n        let outputIndices = ${output.offsetToIndices('global_idx')};\n        let inputOffset = ${input.broadcastedIndicesToOffset('outputIndices', output)};\n        ${output.setByOffset('global_idx', input.getByOffset('inputOffset'))}\n      }`;\n    }\n    return `\n    ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(input, output)}\n    ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n    ${assignment}`;\n  };\n\n  const programUniforms: ProgramUniform[] = [{type: 'uint32', data: outputSize}];\n  if (enableInputShapeUniform) {\n    programUniforms.push(...createTensorShapeVariables(inputShape));\n  }\n  if (enableOutputShapeUniform) {\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n  return {\n    name: 'Expand',\n    shaderCache: {hint: `${outputShape.length}`, inputDependencies: [enableInputShapeUniform ? 'rank' : 'dims']},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms\n    })\n  };\n};\n\nexport const expand = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createExpandProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Gather requires 2 inputs.');\n  }\n};\n\nconst createGatherProgramInfo = (inputs: readonly TensorView[], attributes: GatherAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const indicesShape = inputs[1].dims;\n\n  const inputRank = inputShape.length;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n\n  const outputShape = inputShape.slice(0);\n  outputShape.splice(axis, 1, ...indicesShape);\n\n  const axisDimLimit = inputShape[axis];\n  const components = inputs[0].dataType === DataType.bool ? 4 : 1;\n  const outputSize = Math.ceil(ShapeUtil.size(outputShape) / components);\n\n  const enableInputShapesUniforms = enableShapesUniforms(inputs[0].dims.length);\n  const inputShapeOrRank = enableInputShapesUniforms ? inputs[0].dims.length : inputs[0].dims;\n  const enableIndicesShapesUniforms = enableShapesUniforms(inputs[1].dims.length);\n  const indicesShapeOrRank = enableIndicesShapesUniforms ? inputs[1].dims.length : inputs[1].dims;\n  const enableOutputShapesUniforms = enableShapesUniforms(outputShape.length);\n  const outputShapeOrRank = enableOutputShapesUniforms ? outputShape.length : outputShape;\n\n  const programUniforms: ProgramUniform[] =\n      [{type: 'uint32', data: outputSize}, {type: 'int32', data: axisDimLimit}, {type: 'uint32', data: axis}];\n  if (enableInputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(inputs[0].dims));\n  }\n  if (enableIndicesShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(inputs[1].dims));\n  }\n  if (enableOutputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n\n  const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n  inputDependencies.push(enableInputShapesUniforms ? 'rank' : 'dims');\n  inputDependencies.push(enableIndicesShapesUniforms ? 'rank' : 'dims');\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const data = inputVariable('data', inputs[0].dataType, inputShapeOrRank, components);\n    const indices = inputVariable('inputIndices', inputs[1].dataType, indicesShapeOrRank);\n    const output = outputVariable('output', inputs[0].dataType, outputShapeOrRank, components);\n\n    const calcDataIndices = (x: number|string): string => {\n      const indicesRank = indicesShape.length;\n      let calcStr = `var indicesIndices${x}  = ${indices.type.indices}(0);`;\n      for (let i = 0; i < indicesRank; i++) {\n        calcStr += `${indicesRank > 1 ? `indicesIndices${x}[${i}]` : `indicesIndices${x}`} = ${\n            outputShape.length > 1 ? `outputIndices${x}[uniforms.axis + ${i}]` : `outputIndices${x}`};`;\n      }\n      calcStr += `\n          var idx${x} = ${indices.getByIndices(`indicesIndices${x}`)};\n          if (idx${x} < 0) {\n            idx${x} = idx${x} + uniforms.axisDimLimit;\n          }\n          var dataIndices${x} = ${data.type.indices}(0);\n        `;\n      for (let i = 0, j = 0; i < inputRank; i++) {\n        if (i === axis) {\n          calcStr += `${inputRank > 1 ? `dataIndices${x}[${i}]` : `dataIndices${x}`} = u32(idx${x});`;\n          j += indicesRank;\n        } else {\n          calcStr += `${inputRank > 1 ? `dataIndices${x}[${i}]` : `dataIndices${x}`} = ${\n              outputShape.length > 1 ? `outputIndices${x}[${j}]` : `outputIndices${x}`};`;\n          j++;\n        }\n      }\n      return calcStr;\n    };\n    let assignment: string;\n    if (inputs[0].dataType === DataType.bool) {\n      const singleAssignment = (resStr: string, x: number, typeCast = '') => `\n          let outputIndices${x} = ${output.offsetToIndices(`outputOffset + ${x}u`)};\n          ${calcDataIndices(x)};\n          let offset${x} = ${data.indicesToOffset(`dataIndices${x}`)};\n          let index${x} = offset${x} / 4u;\n          let component${x} = offset${x} % 4u;\n          ${resStr}[${x}] = ${typeCast}(${data.getByOffset(`index${x}`)}[component${x}]);\n        `;\n      assignment = `\n        let outputOffset = global_idx * ${components};\n        var value = vec4<u32>(0);\n        ${singleAssignment('value', 0, 'u32')}\n        ${singleAssignment('value', 1, 'u32')}\n        ${singleAssignment('value', 2, 'u32')}\n        ${singleAssignment('value', 3, 'u32')}\n        ${output.setByOffset('global_idx', 'value')}\n      `;\n    } else {\n      assignment = `\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n      ${calcDataIndices('')};\n      let value = ${data.getByIndices('dataIndices')};\n      ${output.setByOffset('global_idx', 'value')};\n      `;\n    }\n    return `\n      ${\n        shaderHelper.registerUniform('outputSize', 'u32')\n            .registerUniform('axisDimLimit', 'i32')\n            .registerUniform('axis', 'u32')\n            .declareVariables(data, indices, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n        ${assignment}\n      }`;\n  };\n  return {\n    name: 'Gather',\n    shaderCache: {hint: attributes.cacheKey, inputDependencies},\n    getRunData: () => ({\n      outputs: [\n        {dims: outputShape, dataType: inputs[0].dataType},\n      ],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGatherAttributes = (attributes: Record<string, unknown>): GatherAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gather = (context: ComputeContext, attributes: GatherAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherElementsAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('GatherElements requires 2 inputs.');\n  }\n\n  if (inputs[0].dims.length < 1) {\n    throw new Error('GatherElements requires that the data input be rank >= 1.');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`);\n  }\n};\n\nconst createGatherElementsProgramInfo =\n    (inputs: readonly TensorView[], attributes: GatherElementsAttributes): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n      const inputOutputDataType = inputs[0].dataType;\n      const inputRank = inputShape.length;\n\n      const indicesShape = inputs[1].dims;\n      const indicesDataType = inputs[1].dataType;\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n      const axisDimLimit = inputShape[axis];\n\n      const outputShape = indicesShape.slice(0);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const input = inputVariable('input', inputOutputDataType, inputRank);\n      const indices = inputVariable('indicesInput', indicesDataType, indicesShape.length);\n      const output = outputVariable('output', inputOutputDataType, outputShape.length);\n\n\n      const programUniforms: ProgramUniform[] =\n          [{type: 'uint32', data: outputSize}, {type: 'int32', data: axisDimLimit}, {type: 'uint32', data: axis}];\n      programUniforms.push(...createTensorShapeVariables(inputShape));\n      programUniforms.push(...createTensorShapeVariables(indicesShape));\n      programUniforms.push(...createTensorShapeVariables(outputShape));\n      const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank', 'rank'];\n\n      // int64 indices would be treated as little endian i32 with assumption they fall in i32 limits\n      // That assumption is safe as it's not possible to allocate >2gb buffer for input tensor\n      // Input data will be treated as u32 or two u32 for 8-byte tensors\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${\n          shaderHelper.registerUniform('outputSize', 'u32')\n              .registerUniform('axisDimLimit', 'i32')\n              .registerUniform('axis', 'u32')\n              .declareVariables(input, indices, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n\n      var idx = ${indices.getByOffset('global_idx')};\n      if (idx < 0) {\n        idx = idx + uniforms.axisDimLimit;\n      }\n      var inputIndices = ${input.type.indices}(outputIndices);\n      ${input.indicesSet('inputIndices', 'uniforms.axis', 'u32(idx)')};\n      let value = ${input.getByIndices('inputIndices')};\n\n      ${output.setByOffset('global_idx', 'value')};\n  }`;\n\n      return {\n        name: 'GatherElements',\n        shaderCache: {inputDependencies},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n          programUniforms\n        }),\n        getShaderSource,\n      };\n    };\n\nexport const parseGatherElementsAttributes = (attributes: Record<string, unknown>): GatherElementsAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gatherElements = (context: ComputeContext, attributes: GatherElementsAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherElementsProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {GemmUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, IndicesHelper, inputVariable, outputVariable, ShaderHelper, UniformsArrayType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs) {\n    throw new Error('Input is missing');\n  }\n  if (inputs.length < 2 || inputs.length > 3) {\n    throw new Error('Invaid input number.');\n  }\n\n  // 'C' can be of dimensionality 0, 1 or 2 only\n  if (inputs.length === 3 && inputs[2].dims.length > 2) {\n    throw new Error('Invalid input shape of C');\n  }\n\n  if ((inputs[0].dataType !== inputs[1].dataType) ||\n      (inputs.length === 3 && inputs[0].dataType !== inputs[2].dataType)) {\n    throw new Error('Input types are mismatched');\n  }\n};\n\nexport interface GemmAttributes extends AttributeWithCacheKey {\n  transA: boolean;\n  transB: boolean;\n  alpha: number;\n  beta: number;\n}\n\nconst createGemmProgramInfo = (inputs: readonly TensorView[], attributes: GemmAttributes): ProgramInfo => {\n  const aShape = inputs[0].dims.slice();\n  const bShape = inputs[1].dims.slice();\n  const [M, N, K] = GemmUtil.getShapeOfGemmResult(\n      aShape, attributes.transA, bShape, attributes.transB, inputs.length === 3 ? inputs[2].dims : undefined);\n  const outputShape = [M, N];\n  if (!outputShape) {\n    throw new Error('Can\\'t use gemm on the given tensors');\n  }\n  const outputSize = ShapeUtil.size(outputShape);\n  const programUniforms: ProgramUniform[] = [\n    {type: 'uint32', data: outputSize}, {type: 'uint32', data: M}, {type: 'uint32', data: N}, {type: 'uint32', data: K},\n    {type: 'float32', data: attributes.alpha}, {type: 'float32', data: attributes.beta}\n  ];\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'type'];\n  if (inputs.length === 3) {\n    programUniforms.push(...createTensorShapeVariables(inputs[2].dims));\n    inputDependencies.push('rank');\n  }\n  programUniforms.push(...createTensorShapeVariables(outputShape));\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    let line = '';\n    if (attributes.transA && attributes.transB) {\n      line = 'value += a[k * uniforms.M + m] * b[n * uniforms.K + k];';\n    } else if (attributes.transA && !attributes.transB) {\n      line = 'value += a[k * uniforms.M + m] * b[k * uniforms.N + n];';\n    } else if (!attributes.transA && attributes.transB) {\n      line = 'value += a[m * uniforms.K + k] * b[n * uniforms.K + k];';\n    } else if (!attributes.transA && !attributes.transB) {\n      line = 'value += a[m * uniforms.K + k] * b[k * uniforms.N + n];';\n    }\n\n    const calculateAlpha = attributes.alpha === 1 ? '' : 'value *= uniforms.alpha;';\n    const a = inputVariable('a', inputs[0].dataType, inputs[0].dims);\n    const b = inputVariable('b', inputs[1].dataType, inputs[1].dims);\n    const dataType = a.type.value;\n    let c: IndicesHelper|null = null;\n    const variables = [a, b];\n    if (inputs.length === 3) {\n      c = inputVariable('c', inputs[2].dataType, inputs[2].dims.length);\n      variables.push(c);\n    }\n    const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n    variables.push(output);\n    const uniforms: UniformsArrayType = [\n      {name: 'output_size', type: 'u32'}, {name: 'M', type: 'u32'}, {name: 'N', type: 'u32'}, {name: 'K', type: 'u32'},\n      {name: 'alpha', type: 'f32'}, {name: 'beta', type: 'f32'}\n    ];\n    return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...variables)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let m = global_idx / uniforms.N;\n    let n = global_idx % uniforms.N;\n\n    var value = ${dataType}(0);\n    for (var k: u32 = 0u; k < uniforms.K; k++) {\n      ${line}\n    }\n\n    ${calculateAlpha}\n    ${(() => {\n      if (c != null) {\n        return `let cOffset = ${c.broadcastedIndicesToOffset('vec2(m, n)', output)}; value += uniforms.beta * ${\n            c.getByOffset('cOffset')};`;\n      }\n      return '';\n    })()}\n    output[global_idx] = value;\n  }`;\n  };\n\n  return {\n    name: 'Gemm',\n    shaderCache: {hint: `${attributes.cacheKey}`, inputDependencies},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGemmAttributes = (attributes: Record<string, unknown>): GemmAttributes => {\n  const transA = attributes.transA as boolean;\n  const transB = attributes.transB as boolean;\n  const alpha = attributes.alpha as number;\n  const beta = attributes.beta as number;\n  return {transA, transB, alpha, beta, cacheKey: `${attributes.transA};${attributes.transB};${attributes.alpha === 1}`};\n};\n\nexport const gemm = (context: ComputeContext, attributes: GemmAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createGemmProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType, UniformsArrayType} from './common';\n\nexport interface InstanceNormAttributes {\n  epsilon: number;\n  format: 'NHWC'|'NCHW';\n}\n\nconst createInstanceNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: InstanceNormAttributes): ProgramInfo => {\n      const xShape = inputs[0].dims;\n      const outputShape = xShape;\n      const axis = 2;\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n      const components = getMaxComponents(normSize);\n      const normPackedSize = normSize / components;\n      const inputShape = [xShape[0], xShape[1], normPackedSize];\n      const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank', 'type', 'type'];\n      const programUniforms: ProgramUniform[] =\n          [{type: 'uint32', data: normSize}, {type: 'uint32', data: normPackedSize}];\n      programUniforms.push(...createTensorShapeVariables(inputShape), ...createTensorShapeVariables(inputShape));\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const x = inputVariable('x', inputs[0].dataType, inputShape.length, components);\n        const scale = inputVariable('scale', inputs[1].dataType, inputs[1].dims);\n        const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims);\n        const output = outputVariable('output', inputs[0].dataType, inputShape.length, components);\n        const variables = [x, scale, bias, output];\n        const dataType = x.type.value;\n        const f32Type = components === 1 ? 'f32' : `vec${components}<f32>`;\n        const workgroupSize = 64;\n\n        const uniforms: UniformsArrayType = [{name: 'normSize', type: 'u32'}, {name: 'normPackedSize', type: 'u32'}];\n        return `\n  var<workgroup> meanShared : f32;\n  var<workgroup> squaredNormShared : f32;\n  var<workgroup> workgroupShared : array<${f32Type}, ${workgroupSize}>;\n  const workgroupSize = ${workgroupSize}u;\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...variables)}\n  ${shaderHelper.mainStart(workgroupSize)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / uniforms.x_shape[1];\n    let channel = norm % uniforms.x_shape[1];\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial = ${f32Type}(0);\n    for (var h = localIndex; h < uniforms.normPackedSize; h += workgroupSize) {\n      initial = initial + ${f32Type}(${x.get('batch', 'channel', 'h')});\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = ${sumVector('workgroupShared[0]', components)} / f32(uniforms.normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = ${f32Type}(0);\n    for (var h = localIndex; h < uniforms.normPackedSize; h += workgroupSize) {\n      let deviation =  ${f32Type}(${x.get('batch', 'channel', 'h')}) - ${f32Type}(meanShared);\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = ${sumVector('workgroupShared[0]', components)};\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / f32(uniforms.normSize) + f32(${attributes.epsilon}));\n    let channelScale = invStdDev * f32(${scale.getByOffset('channel')});\n    let channelShift = f32(${bias.getByOffset('channel')}) - meanShared * channelScale;\n    for (var h = localIndex; h < uniforms.normPackedSize; h += workgroupSize) {\n      let value = ${x.get('batch', 'channel', 'h')} * ${dataType}(${f32Type}(channelScale)) + ${dataType}(${\n            f32Type}(channelShift));\n      ${output.set('batch', 'channel', 'h', 'value')};\n    }\n  }`;\n      };\n      return {\n        ...{name: 'InstanceNormalization'},\n        // TODO: use epsilon as uniform. Currently epsilon as uniform fails test_instancenorm_epsilon.\n        shaderCache: {hint: `${attributes.epsilon};${components}`, inputDependencies},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: inputs[0].dataType},\n          ],\n          dispatchGroup: {x: normCount},\n          programUniforms\n        }),\n        getShaderSource,\n      };\n    };\n\nconst computeMean =\n    (context: ComputeContext, input: TensorView, scale: TensorView, bias: TensorView, n: number, h: number, c: number,\n     epsilon: number) => {\n      const components = getMaxComponents(c);\n      const WG = 64;\n      // we will store channel scale and channel shift in [2, components] matrix\n      // or in vec2 when components == 1\n      const outputType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n      const sumCastType = components === 1 ? 'f32' : `vec${components}f`;\n      const setOutputValue = (var1: string, var2: string) => `${outputType}(${var1}, ${var2})`;\n      const unitsOfWork = n * c / components;\n      const wgSize = Math.ceil(h / WG);\n\n      const meanInputDependencies: ProgramInputTensorInfoDependency[] = ['type'];\n      const meanProgramUniforms: ProgramUniform[] = [\n        {type: 'uint32', data: wgSize}, {type: 'uint32', data: h}, {type: 'uint32', data: Math.floor(c / components)},\n        {type: 'uint32', data: Math.floor(h * c / components)}\n      ];\n\n      const getMeanShaderSource = (shaderHelper: ShaderHelper) => {\n        const inputHelper = inputVariable('input', input.dataType, input.dims, components);\n        return `\n  ${shaderHelper.declareVariables(inputHelper)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${outputType}>;\n  struct Uniforms {wg_size:u32, H:u32, C:u32, image_size:u32};\n  @group(0) @binding(2) var<uniform> uniforms: Uniforms;\n\n  ${shaderHelper.mainStart(WG)}\n    let currentImageNumber = global_idx / ${WG} / uniforms.C;\n    let currentChannelNumber = (global_idx / ${WG}) % uniforms.C;\n    let wgId = global_idx % ${WG};\n    let wgOffset = wgId * uniforms.wg_size;\n    if (wgOffset >= uniforms.H) {\n        return;\n    }\n    let wgMax = min(wgOffset + uniforms.wg_size, uniforms.H);\n\n    let offset = currentImageNumber * uniforms.image_size + currentChannelNumber;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${sumCastType}(input[offset + i * uniforms.C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${setOutputValue('sum', 'squaredSum')};\n  }`;\n      };\n\n      const meanValues = context.compute(\n          {\n            name: 'InstanceNormComputeMean',\n            shaderCache: {hint: `${components}`, inputDependencies: meanInputDependencies},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, WG, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: n * c / components},\n              programUniforms: meanProgramUniforms\n            }),\n            getShaderSource: getMeanShaderSource,\n          },\n          {inputs: [input], outputs: [-1]})[0];\n\n      const programUniforms: ProgramUniform[] = [\n        {type: 'uint32', data: unitsOfWork}, {type: 'uint32', data: h},\n        {type: 'uint32', data: Math.floor(c / components)}, {type: 'uint32', data: Math.floor(WG * c / components)}\n      ];\n      const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'type', 'type'];\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const scaleHelper = inputVariable('scale', scale.dataType, scale.dims, components);\n        const biasHelper = inputVariable('bias', bias.dataType, bias.dims, components);\n        return `\n  @group(0) @binding(0) var<storage, read> input : array<${outputType}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${scaleHelper.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${biasHelper.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${outputType}>;\n  struct Uniforms {units_of_work : u32, H: u32, C : u32, image_size : u32};\n  @group(0) @binding(4) var<uniform> uniforms: Uniforms;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.units_of_work')}\n    let currentImageNumber = global_idx / uniforms.C;\n    let currentChannelNumber = global_idx % uniforms.C;\n\n    let offset = currentImageNumber * uniforms.image_size;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = 0; i < ${WG}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${WG}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(uniforms.H);\n    squaredSum = squaredSum / f32(uniforms.H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + f32(${epsilon}));\n    let channelScale = invStdDev * ${sumCastType}(scale[currentChannelNumber]);\n    let channelShift = ${sumCastType}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${setOutputValue('channelScale', 'channelShift')};\n  }`;\n      };\n      return context.compute(\n          {\n            name: 'InstanceNormComputeChannelScaleShift',\n            // TODO: use epsilon as uniform. Currently epsilon as uniform fails test_instancenorm_epsilon.\n            shaderCache: {hint: `${components};${epsilon}`, inputDependencies},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: Math.ceil(unitsOfWork / 64 /* workgroup size */)},\n              programUniforms\n            }),\n            getShaderSource,\n          },\n          {inputs: [meanValues, scale, bias], outputs: [-1]})[0];\n    };\n\nconst createInstanceNormNHWCProgramInfo =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: InstanceNormAttributes) => {\n      const xShape = inputs[0].dims;\n      const outputShape = xShape;\n      const N = xShape[0];\n      const C = xShape[xShape.length - 1];\n      const H = ShapeUtil.sizeFromDimension(xShape, 1) / C;\n      const components = getMaxComponents(C);\n      const outputSize = ShapeUtil.size(outputShape) / components;\n      const programUniforms: ProgramUniform[] =\n          [{type: 'uint32', data: H}, {type: 'uint32', data: Math.floor(C / components)}];\n      const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'type'];\n      // first compute mean\n      const channelScaleShift = computeMean(context, inputs[0], inputs[1], inputs[2], N, H, C, attributes.epsilon);\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n        const scaleType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n        const scaleCastType = components === 1 ? dataType : `vec${components}<${dataType}>`;\n\n        const inputHelper = inputVariable('input', inputs[0].dataType, inputs[0].dims, components);\n        const outputHelper = outputVariable('output', inputs[0].dataType, outputShape, components);\n\n        return `\n  @group(0) @binding(0) var<storage, read> input : array<${inputHelper.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${scaleType}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${outputHelper.type.storage}>;\n  struct Uniforms {H: u32, C : u32};\n  @group(0) @binding(3) var<uniform> uniforms: Uniforms;\n\n  ${shaderHelper.mainStart()}\n    let currentImageNumber = global_idx / (uniforms.C * uniforms.H);\n    let currentChannelNumber = global_idx % uniforms.C;\n\n    let scaleOffset = currentImageNumber * uniforms.C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${scaleCastType}(scale[0]), ${scaleCastType}(scale[1]));\n  }`;\n      };\n      context.compute(\n          {\n            name: 'InstanceNormalizationNHWC',\n            shaderCache: {hint: `${components}`, inputDependencies},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n              dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n              programUniforms\n            }),\n            getShaderSource,\n          },\n          {inputs: [inputs[0], channelScaleShift]});\n    };\n\nexport const instanceNorm = (context: ComputeContext, attributes: InstanceNormAttributes): void => {\n  if (attributes.format === 'NHWC') {\n    createInstanceNormNHWCProgramInfo(context, context.inputs, attributes);\n  } else {\n    context.compute(createInstanceNormProgramInfo(context.inputs, attributes));\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType, UniformsArrayType,} from './common';\n\ninterface LayerNormAttributes {\n  axis: number;\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 2) {\n    throw new Error('layerNorm requires at least 2 inputs.');\n  }\n};\n\nconst createLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: LayerNormAttributes, outputCount: number): ProgramInfo => {\n      const xShape = inputs[0].dims;\n      const scale = inputs[1];\n      const bias = inputs[2];\n\n      const outputShape = xShape;\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, xShape.length);\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n\n      const scaleSize = ShapeUtil.size(scale.dims);\n      const biasSize = bias ? ShapeUtil.size(bias.dims) : 0;\n      if (scaleSize !== normSize || (bias && biasSize !== normSize)) {\n        throw new Error(`Size of X.shape()[axis:] == ${normSize}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${scaleSize} and bias size of ${biasSize}`);\n      }\n\n      const meanInvStdDevDim: number[] = [];\n      for (let i = 0; i < xShape.length; ++i) {\n        if (i < axis) {\n          meanInvStdDevDim.push(xShape[i]);\n        } else {\n          meanInvStdDevDim.push(1);\n        }\n      }\n      const components = getMaxComponents(normSize);\n      const inputDependencies: ProgramInputTensorInfoDependency[] = ['type', 'type'];\n      const programUniforms: ProgramUniform[] = [\n        {type: 'uint32', data: normCount}, {type: 'float32', data: normSize},\n        {type: 'uint32', data: Math.floor(normSize / components)}, {type: 'float32', data: attributes.epsilon}\n      ];\n      if (bias) {\n        inputDependencies.push('type');\n      }\n      const hasMeanDataOutput = outputCount > 1;\n      const hasInvStdOutput = outputCount > 2;\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n        const variables = [\n          inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n          inputVariable('scale', scale.dataType, scale.dims, components),\n        ];\n        if (bias) {\n          variables.push(inputVariable('bias', bias.dataType, bias.dims, components));\n        }\n        variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n        if (hasMeanDataOutput) {\n          variables.push(outputVariable('mean_data_output', DataType.float, meanInvStdDevDim));\n        }\n        if (hasInvStdOutput) {\n          variables.push(outputVariable('inv_std_output', DataType.float, meanInvStdDevDim));\n        }\n\n        const uniforms: UniformsArrayType = [\n          {name: 'norm_count', type: 'u32'}, {name: 'norm_size', type: 'f32'},\n          {name: 'norm_size_vectorized', type: 'u32'}, {name: 'epsilon', type: 'f32'}\n        ];\n        return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(...variables)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.norm_count')}\n    let offset = global_idx * uniforms.norm_size_vectorized;\n    var meanVector = ${fillVector('f32', components)};\n    var meanSquareVector = ${fillVector('f32', components)};\n\n    for (var h: u32 = 0u; h < uniforms.norm_size_vectorized; h++) {\n      let value = ${castToF32(dataType, components, 'x[h + offset]')};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${sumVector('meanVector', components)} / uniforms.norm_size;\n    let meanSquare = sqrt(${sumVector('meanSquareVector', components)}\n      / uniforms.norm_size - mean * mean + uniforms.epsilon);\n\n    for (var j: u32 = 0; j < uniforms.norm_size_vectorized; j++) {\n      let f32input = ${castToF32(dataType, components, 'x[j + offset]')};\n      let f32scale = ${castToF32(dataType, components, 'scale[j]')};\n      output[j + offset] = ${variables[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${bias ? `+ ${castToF32(dataType, components, 'bias[j]')}` : ''}\n      );\n    }\n\n    ${hasMeanDataOutput ? 'mean_data_output[global_idx] = mean' : ''};\n    ${hasInvStdOutput ? 'inv_std_output[global_idx] = 1 / meanSquare' : ''};\n  }`;\n      };\n      const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n      if (hasMeanDataOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n      if (hasInvStdOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n\n      return {\n        name: 'LayerNormalization',\n        shaderCache: {hint: `${components};${outputCount}`, inputDependencies},\n        getRunData: () =>\n            ({outputs, dispatchGroup: {x: Math.ceil(normCount / 64 /* workgroup size */)}, programUniforms}),\n        getShaderSource,\n      };\n    };\n\nexport const layerNorm = (context: ComputeContext, attributes: LayerNormAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createLayerNormProgramInfo(context.inputs, attributes, context.outputCount));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, GpuDataType, ProgramUniform} from '../types';\n\nimport {applyAttention, AttentionAttrs, AttentionMaskType, AttentionParameters, AttentionQkvFormat} from './attention';\nimport {inputVariable, outputVariable, ShaderHelper, UniformsArrayType} from './common';\nimport {createTransposeProgramInfo, TransposeAttributes} from './transpose';\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: AttentionAttrs): AttentionParameters => {\n  const query = inputs[0];\n  const key = inputs[1];\n  const value = inputs[2];\n  const bias = inputs[3];\n  const keyPaddingMask = inputs[4];\n  const relativePositionBias = inputs[5];\n  const pastKey = inputs[6];\n  const pastValue = inputs[7];\n\n  // Abbreviation and Meanings:\n  //   B:    batch_size\n  //   S:    sequence_length (input sequence length of query)\n  //   P:    past_sequence_length (past sequence length of key or value)\n  //   L:    kv_sequence_length (input sequence length of key or value)\n  //   M:    max_sequence_length\n  //   T:    total_sequence_length = past_sequence_length + kv_sequence_length\n  //   N:    num_heads\n  //   H:    head size for Q and K, aka q_head_size or k_head_size or qk_head_size\n  //   H_v:  v_head_size\n  //   D_i:  input hidden size\n  //   D:    hidden size for Q and K (D = N * H), aka q_hidden_size or k_hidden_size or qk_hidden_size\n  //   D_v:  v_hidden_size = num_heads * v_head_size\n\n  //     key_padding_mask (K/V)     : (B) or (2*B + 1) or (B, L) or None\n  //     relative_position_bias     : (B, 1, S, L)\n  //     past_key                   : (B, N, S*, H)\n  //     past_value                 : (B, N, S*, H)\n  // When no packing for q/k/v:\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, L, D) or (B, N, S*, H)\n  //     value            (V)       : (B, L, D_v) or (B, N, S*, H)\n  //     bias             (Q/K/V)   : (D + D + D_v)\n  // When packed kv is used:\n  //     query            (Q)       : (B, S, D)\n  //     key              (K)       : (B, L, N, 2, H)\n  //     value            (V)       : None\n  //     bias             (Q/K/V)   : None\n  // When packed qkv is used:\n  //     query            (Q)       : (B, L, N, 3, H) or (B, S, 3*D)\n  //     key              (K)       : None\n  //     value            (V)       : None\n  //     bias             (Q/K/V)   : None or (D + D + D_v)\n\n  if (query.dims.length !== 3 && query.dims.length !== 5) {\n    throw new Error('Input query is expected to have 3 or 5 dimensions');\n  }\n\n  const dmmhaPacking = false;\n  const batchSize = query.dims[0];\n  const sequenceLength = query.dims[1];\n  const hiddenSize = query.dims.length === 3 ? (dmmhaPacking ? query.dims[2] / 3 : query.dims[2]) :\n                                               attributes.numHeads * query.dims[4];\n  let kvSequenceLength = sequenceLength;\n\n  let pastSequenceLength = 0;\n  let maxSequenceLength = 0;\n  const headSize = Math.floor(hiddenSize / attributes.numHeads);\n  if (pastKey && pastValue) {\n    if (pastKey.dims.length !== 4) {\n      throw new Error('Input \"past_key\" is expected to have 4 dimensions');\n    }\n    if (pastValue.dims.length !== 4) {\n      throw new Error('Input \"past_value\" is expected to have 4 dimensions');\n    }\n    pastSequenceLength = pastKey.dims[2];\n    maxSequenceLength = pastKey.dims[2];\n  } else if (pastKey || pastValue) {\n    throw new Error('Input \"past_key\" and \"past_value\" shall be both present or both absent');\n  }\n\n  let qkvFormat: AttentionQkvFormat;\n  if (key) {\n    if (query.dims.length !== 3) {\n      throw new Error('Input \"query\" is expected to have 3 dimensions when key is given');\n    }\n    if (key.dims.length < 3 || key.dims.length > 5) {\n      throw new Error('Input \"key\" is expected to have 3, 4, or 5 dimensions');\n    }\n    if (query.dims[0] !== key.dims[0]) {\n      throw new Error('Input \"query\" and \"key\" shall have same dim 0 (batch size)');\n    }\n\n    if (key.dims.length === 3) {\n      if (key.dims[2] !== query.dims[2]) {\n        throw new Error('Input \"query\" and \"key\" shall have same dim 2 (hidden_size)');\n      }\n      qkvFormat = AttentionQkvFormat.qkvBSNH;\n      kvSequenceLength = key.dims[1];\n    } else if (key.dims.length === 5) {\n      if (key.dims[2] !== attributes.numHeads || key.dims[3] !== 2 || key.dims[4] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');\n      }\n      if (value) {\n        throw new Error('Expect \"value\" be none when \"key\" has packed kv format.');\n      }\n      qkvFormat = AttentionQkvFormat.qKvBSNHxBSN2H;\n      kvSequenceLength = key.dims[1];\n    } else {  // key_dims.size() == 4 (cross-attention with past_key)\n      if (key.dims[1] !== attributes.numHeads || key.dims[3] !== headSize) {\n        throw new Error('Expect \"key\" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');\n      }\n\n      qkvFormat = AttentionQkvFormat.unknown;\n      kvSequenceLength = key.dims[2];\n    }\n  } else {  // packed QKV\n    if (query.dims.length !== 3 && query.dims.length !== 5) {\n      throw new Error('Input \"query\" is expected to have 3 or 5 dimensions when key is empty');\n    }\n    if (query.dims.length === 5 && (query.dims[2] !== attributes.numHeads || query.dims[3] !== 3)) {\n      throw new Error('Expect \"query\" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');\n    }\n\n    qkvFormat = AttentionQkvFormat.qkvBSN3H;\n  }\n\n  if (bias) {\n    if (bias.dims.length !== 1) {\n      throw new Error('Input \"bias\" is expected to have 1 dimension');\n    }\n\n    if (value) {\n      if (query.dims.length === 5 && query.dims[3] === 2) {\n        throw new Error('bias is not allowed for packed kv.');\n      }\n    }\n  }\n\n  let maskType: AttentionMaskType = AttentionMaskType.none;\n  if (keyPaddingMask) {\n    maskType = AttentionMaskType.maskUnknown;\n    const maskDims = keyPaddingMask.dims;\n    if (maskDims.length === 1) {\n      if (maskDims[0] === batchSize) {\n        maskType = AttentionMaskType.mask1dKeySeqLen;\n      } else if (maskDims[0] === 3 * batchSize + 2) {\n        maskType = AttentionMaskType.mask1DKeySeqLenStart;\n      }\n    } else if (maskDims.length === 2 && maskDims[0] === batchSize && maskDims[1] === kvSequenceLength) {\n      maskType = AttentionMaskType.mask2dKeyPadding;\n    }\n    if (maskType === AttentionMaskType.maskUnknown) {\n      throw new Error('Input \"key_padding_mask\" shape shall be (batch_size) or (batch_size, kv_sequence_length)');\n    }\n    throw new Error('Mask not supported');\n  }\n\n  let passPastInKv = false;\n  let vHiddenSize = hiddenSize;\n  if (value) {\n    if (value.dims.length !== 3 && value.dims.length !== 4) {\n      throw new Error('Input \"value\" is expected to have 3 or 4 dimensions');\n    }\n\n    if (query.dims[0] !== value.dims[0]) {\n      throw new Error('Input \"query\" and \"value\" shall have same dim 0 (batch_size)');\n    }\n\n    if (value.dims.length === 3) {\n      if (kvSequenceLength !== value.dims[1]) {\n        throw new Error('Input \"key\" and \"value\" shall have the same dim 1 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[2];\n    } else {\n      if (kvSequenceLength !== value.dims[2]) {\n        throw new Error('Input \"past_key\" and \"past_value\" shall have the same dim 2 (kv_sequence_length)');\n      }\n      vHiddenSize = value.dims[1] * value.dims[3];\n      passPastInKv = true;\n    }\n  }\n\n  const totalSequenceLength = pastSequenceLength + kvSequenceLength;\n  const broadcastResPosBias = false;\n  // if (extraAddQk) {\n  //   if (extraAddQk.dims[0] === 1) {\n  //     broadcastResPosBias = true;\n  //   }\n  // }\n\n  if (keyPaddingMask) {\n    throw new Error('Key padding mask is not supported');\n  }\n  if (relativePositionBias) {\n    throw new Error('extraAddQk is not supported');\n  }\n  if (pastKey) {\n    throw new Error('pastKey is not supported');\n  }\n  if (pastValue) {\n    throw new Error('pastValue is not supported');\n  }\n\n  return {\n    batchSize,\n    sequenceLength,\n    pastSequenceLength,\n    kvSequenceLength,\n    totalSequenceLength,\n    maxSequenceLength,\n    inputHiddenSize: 0,\n    hiddenSize,\n    vHiddenSize,\n    headSize,\n    vHeadSize: Math.floor(vHiddenSize / attributes.numHeads),\n    numHeads: attributes.numHeads,\n    isUnidirectional: false,\n    pastPresentShareBuffer: false,\n    maskFilterValue: attributes.maskFilterValue,\n    maskType,\n    scale: attributes.scale,\n    broadcastResPosBias,\n    passPastInKv,\n    qkvFormat,\n  };\n};\n\nexport const parseMultiHeadAttentionAttributes = (attributes: AttentionAttrs): AttentionAttrs =>\n    createAttributeWithCacheKey({...attributes});\n\nconst weightTransposeAttribute: TransposeAttributes = createAttributeWithCacheKey({perm: [0, 2, 1, 3]});\n\nconst addBiasTranspose =\n    (context: ComputeContext, qkv: TensorView, bias: TensorView, batchSize: number, sequenceLength: number,\n     hiddenSize: number, biasOffset: number) => {\n      const outputShape = [batchSize, sequenceLength, hiddenSize];\n      const outputSize = ShapeUtil.size(outputShape);\n      const programUniforms: ProgramUniform[] =\n          [{type: 'uint32', data: outputSize}, {type: 'uint32', data: biasOffset}, {type: 'uint32', data: hiddenSize}];\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => {\n        const output = outputVariable('qkv_with_bias', qkv.dataType, outputShape);\n        const qkvInput = inputVariable('qkv', qkv.dataType, outputShape);\n        const biasInput = inputVariable('bias', bias.dataType, outputShape);\n\n        const uniforms: UniformsArrayType = [\n          {name: 'output_size', type: 'u32'}, {name: 'bias_offset', type: 'u32'}, {name: 'hidden_size', type: 'u32'}\n        ];\n        return `\n  ${shaderHelper.registerUniforms(uniforms).declareVariables(qkvInput, biasInput, output)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n    let bias_offset_idx = (global_idx % uniforms.hidden_size) + uniforms.bias_offset;\n\n    qkv_with_bias[global_idx] = qkv[global_idx] + bias[bias_offset_idx];\n  }`;\n      };\n\n      return context.compute(\n          {\n            name: 'MultiHeadAttentionAddBias',\n            shaderCache: {inputDependencies: ['type', 'type']},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: qkv.dataType, gpuDataType: GpuDataType.default}],\n              dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n              programUniforms\n            }),\n            getShaderSource,\n          },\n          {inputs: [qkv, bias], outputs: [-1]})[0];\n    };\n\nconst maybeTransposeToBNSHAndAddBias =\n    (context: ComputeContext, batchSize: number, numHeads: number, sequenceLength: number, headSize: number,\n     input: TensorView, bias?: TensorView, biasOffset?: number) => {\n      // const newDims = [];\n\n      let reshapedInput = input;\n      if (!bias) {\n        if (input.dims.length === 3) {\n          reshapedInput = input.reshape([batchSize, sequenceLength, numHeads, headSize]);\n        }\n        return context.compute(\n            createTransposeProgramInfo(reshapedInput, weightTransposeAttribute.perm),\n            {inputs: [reshapedInput], outputs: [-1]})[0];\n      } else {\n        if (sequenceLength === 1) {\n          throw new Error('AddBiasReshape is not implemented. Please export your model with packed QKV or KV');\n        } else {\n          reshapedInput =\n              addBiasTranspose(context, input, bias, batchSize, sequenceLength, numHeads * headSize, biasOffset!);\n          reshapedInput = reshapedInput.reshape([batchSize, sequenceLength, numHeads, headSize]);\n          return context.compute(\n              createTransposeProgramInfo(reshapedInput, weightTransposeAttribute.perm),\n              {inputs: [reshapedInput], outputs: [-1]})[0];\n        }\n      }\n    };\n\nexport const multiHeadAttention = (context: ComputeContext, attributes: AttentionAttrs): void => {\n  const params = validateInputs(context.inputs, attributes);\n\n  if (context.inputs[0].dims.length === 5) {\n    throw new Error('Packed QKV is not implemented');\n  }\n\n  if (context.inputs[1]?.dims.length === 5) {\n    throw new Error('Packed KV is not implemented');\n  }\n\n  // applyAttention expects BNSH inputs\n  const kvBNSH = context.inputs[1] && context.inputs[2] && context.inputs[1].dims.length === 4 &&\n      context.inputs[2].dims.length === 4;\n\n  const Q = maybeTransposeToBNSHAndAddBias(\n      context, params.batchSize, params.numHeads, params.sequenceLength, params.headSize, context.inputs[0],\n      context.inputs[3], 0);\n\n  if (kvBNSH) {\n    return applyAttention(\n        context, Q, context.inputs[1], context.inputs[2], context.inputs[4], undefined, undefined, undefined,\n        context.inputs[5], params, attributes);\n  }\n\n  const K = maybeTransposeToBNSHAndAddBias(\n      context, params.batchSize, params.numHeads, params.kvSequenceLength, params.headSize, context.inputs[1],\n      context.inputs[3], params.hiddenSize);\n\n  const V = maybeTransposeToBNSHAndAddBias(\n      context, params.batchSize, params.numHeads, params.kvSequenceLength, params.vHeadSize, context.inputs[2],\n      context.inputs[3], 2 * params.hiddenSize);\n\n  applyAttention(\n      context, Q, K, V, context.inputs[4], undefined, context.inputs[6], context.inputs[7], context.inputs[5], params,\n      attributes);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType, tensorDataTypeEnumToString} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, getElementAt, IndicesHelper, inputVariable, outputVariable, ShaderHelper, UniformDataElementType, UniformsArrayType} from './common';\n\ninterface PadAttributes {\n  // 0-constant, 1-reflect, 2-edge, 3-wrap\n  readonly mode: number;\n  readonly value: number;\n  readonly pads: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('Too few inputs');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Input type must be float.');\n  }\n\n  if (inputs.length >= 2) {\n    let validPads = inputs[0].dims.length * 2 === inputs[1].dims[0];\n    if (inputs.length === 4) {\n      validPads = inputs[3].dims[0] * 2 === inputs[1].dims[0];\n    }\n    if (!validPads) {\n      throw new Error('The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].');\n    }\n  }\n};\n\nconst getPadConstant = (output: IndicesHelper, inputRank: number, padsLength: number): string => {\n  let block = '';\n  for (let i = inputRank - 1; i >= 0; --i) {\n    block += `\n            k = i32(${output.indicesGet('indices', i)}) - ${getElementAt('uniforms.pads', i, padsLength)};\n            if (k < 0) {\n              break;\n            }\n            if (k >= i32(${getElementAt('uniforms.x_shape', i, inputRank)})) {\n              break;\n            }\n            offset += k * i32(${getElementAt('uniforms.x_strides', i, inputRank)});\n        `;\n  }\n\n  return `\n          value = ${output.type.value}(uniforms.constant_value);\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${block}\n            value = x[offset];\n          }\n      `;\n};\n\nconst getPadReflect = (output: IndicesHelper, inputRank: number, padsLength: number): string => {\n  let block = '';\n  for (let i = inputRank - 1; i >= 0; --i) {\n    block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${getElementAt('uniforms.pads', i, padsLength)};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = 2 * (i32(${getElementAt('uniforms.x_shape', i, inputRank)}) - 1);\n                  k = k % _2n_1;\n                  if(k >= i32(${getElementAt('uniforms.x_shape', i, inputRank)})) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * i32(${getElementAt('uniforms.x_strides', i, inputRank)});\n            `;\n  }\n\n  return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n};\n\nconst getPadEdge = (output: IndicesHelper, inputRank: number, padsLength: number): string => {\n  let block = '';\n  for (let i = inputRank - 1; i >= 0; --i) {\n    block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${getElementAt('uniforms.pads', i, padsLength)};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= i32(${getElementAt('uniforms.x_shape', i, inputRank)})) {\n                  k = i32(${getElementAt('uniforms.x_shape', i, inputRank)}) - 1;\n                }\n                offset += k * i32(${getElementAt('uniforms.x_strides', i, inputRank)});\n            `;\n  }\n\n  return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n};\n\nconst getPadWrap = (output: IndicesHelper, inputRank: number, padsLength: number): string => {\n  let block = '';\n  for (let i = inputRank - 1; i >= 0; --i) {\n    block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${getElementAt('uniforms.pads', i, padsLength)};\n                if (k < 0)  {\n                  k += i32(${getElementAt('uniforms.x_shape', i, inputRank)}]);\n                }\n                if (k >= i32(${getElementAt('uniforms.x_shape', i, inputRank)})) {\n                  k -= i32(${getElementAt('uniforms.x_shape', i, inputRank)});\n                }\n                offset += k * i32(${getElementAt('uniforms.x_strides', i, inputRank)});\n            `;\n  }\n\n  return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n};\n\nconst getPadSnippet = (output: IndicesHelper, inputRank: number, attributes: PadAttributes): string => {\n  switch (attributes.mode) {\n    case 0:\n      return getPadConstant(output, inputRank, attributes.pads.length);\n    case 1:\n      return getPadReflect(output, inputRank, attributes.pads.length);\n    case 2:\n      return getPadEdge(output, inputRank, attributes.pads.length);\n    case 3:\n      return getPadWrap(output, inputRank, attributes.pads.length);\n    default:\n      throw new Error('Invalid mode');\n  }\n};\n\nconst createPadProgramInfo = (inputs: readonly TensorView[], attributes: PadAttributes): ProgramInfo => {\n  const outputShape = ShapeUtil.padShape(inputs[0].dims.slice(), attributes.pads);\n  const inputDims = inputs[0].dims;\n  const outputSize = ShapeUtil.size(outputShape);\n  const programUniforms: ProgramUniform[] =\n      [{type: 'uint32', data: outputSize}, {type: 'uint32', data: attributes.pads}];\n  if (attributes.mode === 0) {\n    const tensorDataType = tensorDataTypeEnumToString(inputs[0].dataType) as ProgramUniform['type'];\n    programUniforms.push({type: tensorDataType, data: attributes.value});\n  }\n\n  programUniforms.push(...createTensorShapeVariables(inputs[0].dims), ...createTensorShapeVariables(outputShape));\n  const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank'];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n    const input = inputVariable('x', inputs[0].dataType, inputDims.length);\n    const dataType = input.type.value;\n    const padSnippet = getPadSnippet(output, inputDims.length, attributes);\n    const uniforms: UniformsArrayType =\n        [{name: 'output_size', type: 'u32'}, {name: 'pads', type: 'i32', length: attributes.pads.length}];\n    if (attributes.mode === 0) {\n      uniforms.push({name: 'constant_value', type: dataType as UniformDataElementType});\n    }\n\n    return `\n            ${shaderHelper.registerUniforms(uniforms).declareVariables(input, output)}\n            ${shaderHelper.mainStart()}\n            ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n            let indices = ${output.offsetToIndices('global_idx')};\n\n            var value = ${dataType}(0);\n            ${padSnippet}\n            output[global_idx] = value;\n        }`;\n  };\n\n  return {\n    name: 'Pad',\n    shaderCache: {hint: `${attributes.mode}`, inputDependencies},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)},\n      programUniforms\n    }),\n    getShaderSource,\n  };\n};\n\nconst createPadAttributesFromInputs = (inputs: readonly TensorView[], attributes: PadAttributes): PadAttributes => {\n  if (inputs.length > 1) {\n    const bigInt64Pads = inputs[1].getBigInt64Array();\n    const value = (inputs.length >= 3 && inputs[2].data) ? inputs[2].getFloat32Array()[0] : 0.0;\n\n    const inputRank = inputs[0].dims.length;\n    const updatePads = new Int32Array(2 * inputRank).fill(0);\n    if (inputs.length >= 4) {\n      const axes = inputs[3].getBigInt64Array();\n      for (let i = 0; i < axes.length; i++) {\n        updatePads[Number(axes[i])] = Number(bigInt64Pads[i]);\n        updatePads[Number(axes[i]) + inputRank] = Number(bigInt64Pads[i + axes.length]);\n      }\n    } else {\n      bigInt64Pads.forEach((v, i) => updatePads[Number(i)] = (Number(v)));\n    }\n\n    const pads: number[] = [];\n    updatePads.forEach(v => pads.push(v));\n\n    return {mode: attributes.mode, value, pads};\n  } else {\n    return attributes;\n  }\n};\n\nexport const pad = (context: ComputeContext, attributes: PadAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes = createPadAttributesFromInputs(context.inputs, attributes);\n  context.compute(createPadProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from 'onnxruntime-common';\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, getElementAt, IndicesHelper, inputVariable, outputVariable, ShaderHelper, UniformsArrayType} from './common';\n\n// TODO: support:\n// - ceil_mode                 \"test_maxpool_2d_ceil\"\n// - storage_order             \"test_maxpool_with_argmax_2d_precomputed_strides\"\n// - [MaxPool] dilations       \"test_maxpool_2d_dilations\"\n// - [MaxPool] output[1]       \"test_maxpool_with_argmax_2d_precomputed_pads\"\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (env.webgpu.validateInputContent && (!inputs || inputs.length !== 1)) {\n    throw new Error('Pool ops requires 1 input.');\n  }\n};\n\nconst getAdjustedPoolAttributesAndOutputShape = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    input: TensorView, attributes: AttributeType, isGlobalOperator: boolean): [AttributeType, number[]] => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputShapeAsChannelFirst = input.dims.slice();\n  if (isChannelsLast) {\n    inputShapeAsChannelFirst.splice(1, 0, inputShapeAsChannelFirst.pop()!);  // Move channel to the second position.\n  }\n  const hasDilations = Object.hasOwnProperty.call(attributes, 'dilations');\n  const kernelShape = attributes.kernelShape.slice();\n  const strides = attributes.strides.slice();\n  const dilations: number[] = hasDilations ? (attributes as MaxPoolAttributes).dilations.slice() : [];\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPoolAttributes(isGlobalOperator, inputShapeAsChannelFirst, kernelShape, strides, dilations, pads);\n\n  const outputShapeAsChannelFirst = PoolConvUtil.computePoolOutputShape(\n      isGlobalOperator, inputShapeAsChannelFirst, strides, dilations, kernelShape, pads, attributes.autoPad);\n\n  const newAttributes = Object.assign({}, attributes);\n  if (hasDilations) {\n    Object.assign(newAttributes, {kernelShape, strides, pads, dilations, cacheKey: attributes.cacheKey});\n  } else {\n    Object.assign(newAttributes, {kernelShape, strides, pads, cacheKey: attributes.cacheKey});\n  }\n  const outputShapeAsChannelLast = outputShapeAsChannelFirst.slice();\n  outputShapeAsChannelLast.push(outputShapeAsChannelLast.splice(1, 1)[0]);\n  return [newAttributes, isChannelsLast ? outputShapeAsChannelLast : outputShapeAsChannelFirst];\n};\n\nconst getUniformAndPadInfo = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    outputShape: readonly number[],\n    attributes: AttributeType): [ProgramUniform[], UniformsArrayType, boolean, boolean, boolean] => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const outputSize = ShapeUtil.size(outputShape);\n  const kernelSize = ShapeUtil.size(attributes.kernelShape);\n  const programUniforms: ProgramUniform[] = [{type: 'uint32', data: outputSize}, {type: 'uint32', data: kernelSize}];\n  const uniforms: UniformsArrayType = [{name: 'outputSize', type: 'u32'}, {name: 'kernelSize', type: 'u32'}];\n  if (attributes.kernelShape.length <= 2) {\n    const kw = attributes.kernelShape[attributes.kernelShape.length - 1];\n    const sw = attributes.strides[attributes.strides.length - 1];\n    const pwStart = attributes.pads[attributes.pads.length / 2 - 1];\n    const pwEnd = attributes.pads[attributes.pads.length - 1];\n    const pwStartEndNotZero = !!(pwStart + pwEnd);\n    programUniforms.push(\n        {type: 'uint32', data: kw},\n        {type: 'uint32', data: sw},\n        {type: 'uint32', data: pwStart},\n        {type: 'uint32', data: pwEnd},\n    );\n    uniforms.push(\n        {name: 'kw', type: 'u32'}, {name: 'sw', type: 'u32'}, {name: 'pwStart', type: 'u32'},\n        {name: 'pwEnd', type: 'u32'});\n\n    let phStartEndNotZero = false;\n    if (attributes.kernelShape.length === 2) {\n      const kh = attributes.kernelShape[attributes.kernelShape.length - 2];\n      const sh = attributes.strides[attributes.strides.length - 2];\n      const phStart = attributes.pads[attributes.pads.length / 2 - 2];\n      const phEnd = attributes.pads[attributes.pads.length - 2];\n      phStartEndNotZero = !!(phStart + phEnd);\n      programUniforms.push(\n          {type: 'uint32', data: kh}, {type: 'uint32', data: sh}, {type: 'uint32', data: phStart},\n          {type: 'uint32', data: phEnd});\n\n      uniforms.push(\n          {name: 'kh', type: 'u32'}, {name: 'sh', type: 'u32'}, {name: 'phStart', type: 'u32'},\n          {name: 'phEnd', type: 'u32'});\n    }\n    return [programUniforms, uniforms, true, pwStartEndNotZero, phStartEndNotZero];\n  } else {\n    if (isChannelsLast) {\n      throw new Error('Pooling with kernelShape.length > 2 is not supported for NHWC format.');\n    }\n    const kernelStrides = ShapeUtil.computeStrides(attributes.kernelShape);\n    programUniforms.push(\n        {type: 'uint32', data: kernelStrides}, {type: 'uint32', data: attributes.pads},\n        {type: 'uint32', data: attributes.strides});\n    uniforms.push(\n        {name: 'kernelStrides', type: 'u32', length: kernelStrides.length},\n        {name: 'pads', type: 'u32', length: attributes.pads.length},\n        {name: 'strides', type: 'u32', length: attributes.strides.length});\n\n    const hasPads = attributes.pads.reduce((sum, cur) => sum + cur);\n    return [programUniforms, uniforms, !!hasPads, false, false];\n  }\n};\n\nconst generatePoolingCode = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    shaderHelper: ShaderHelper, x: IndicesHelper, rank: number, outputShapeRank: number, attributes: AttributeType,\n    op1: string, op2: string, start: number, uniforms: UniformsArrayType, hasPads: boolean, pwStartEndNotZero: boolean,\n    phStartEndNotZero: boolean): string => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const dataType = x.type.value;\n  const output = outputVariable('output', x.type.tensor, outputShapeRank);\n\n  if (attributes.kernelShape.length <= 2) {\n    let codeW = '';\n    let codeH = '';\n    let codeHEnd = '';\n    const dimIdxW = rank - (isChannelsLast ? 2 : 1);\n    if (pwStartEndNotZero) {\n      codeW = `\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * uniforms.sw - uniforms.pwStart + i;\n                  if (xIndices[${dimIdxW}] < 0 || xIndices[${dimIdxW}]\n                      >= uniforms.x_shape[${dimIdxW}]) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    } else {\n      codeW = `\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * uniforms.sw - uniforms.pwStart + i;\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    }\n\n    if (attributes.kernelShape.length === 2) {\n      const dimIdxH = rank - (isChannelsLast ? 3 : 2);\n      if (phStartEndNotZero) {\n        codeH = `\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * uniforms.sh - uniforms.phStart + j;\n                  if (xIndices[${dimIdxH}] < 0 || xIndices[${dimIdxH}] >= uniforms.x_shape[${dimIdxH}]) {\n                    pad += i32(uniforms.kw);\n                    continue;\n                  }\n              `;\n      } else {\n        codeH = `\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * uniforms.sh - uniforms.phStart + j;\n                `;\n      }\n      codeHEnd = `\n              }\n            `;\n    }\n\n    const poolingCode = `\n            ${shaderHelper.registerUniforms(uniforms).declareVariables(x, output)}\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              var xIndices = ${output.offsetToIndices('global_idx')};\n\n              var value = ${dataType}(${start});\n              var pad = 0;\n              ${codeH}\n              ${codeW}\n              ${codeHEnd}\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  } else {\n    if (isChannelsLast) {\n      throw new Error('Pooling with kernelShape.length > 2 is not supported for NHWC format.');\n    }\n    const stridesRank = attributes.kernelShape.length;\n    const padsRank = attributes.pads.length;\n    let padCode = '';\n    if (hasPads) {\n      padCode = `\n                if (xIndices[j] >= uniforms.x_shape[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${x.indicesToOffset('xIndices')}];\n                ${op1}\n              }`;\n    } else {\n      padCode = `\n              }\n              let x_val = x[${x.indicesToOffset('xIndices')}];\n              ${op1}\n            `;\n    }\n    const poolingCode = `\n            ${shaderHelper.registerUniforms(uniforms).declareVariables(x, output)}\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n              let indices = ${output.offsetToIndices('global_idx')};\n              var xIndices = ${output.offsetToIndices('global_idx')};\n\n              var offsets: array<u32, ${stridesRank}>;\n\n              var value = ${dataType}(${start});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < uniforms.kernelSize; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${stridesRank - 1}u; j++) {\n                  offsets[j] = offset / ${getElementAt('uniforms.kernelStrides', 'j', stridesRank)};\n                  offset -= offsets[j] * ${getElementAt('uniforms.kernelStrides', 'j', stridesRank)};\n                }\n                offsets[${stridesRank - 1}] = offset;\n\n                isPad = false;\n                for (var j = ${rank - stridesRank}u; j < ${rank}u; j++) {\n                  xIndices[j] = indices[j] * ${\n        getElementAt('uniforms.strides', `j - ${rank - stridesRank}u`, stridesRank)}\n                    + offsets[j - ${rank - stridesRank}u] - ${getElementAt('uniforms.pads', 'j - 2u', padsRank)};\n                  ${padCode}\n              }\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  }\n};\n\nexport interface FormatAttributes {\n  readonly format: 'NHWC'|'NCHW';\n}\n\nexport interface PoolCommonAttributes extends FormatAttributes {\n  readonly autoPad: string;\n  readonly ceilMode: number;\n  readonly kernelShape: readonly number[];\n  readonly strides: readonly number[];\n  readonly pads: readonly number[];\n}\n\nconst createShaderKeyFromAttributes = (attributes: PoolCommonAttributes): string =>\n    (`${attributes.format};${attributes.ceilMode};${attributes.autoPad};${attributes.kernelShape.length}`);\n\nconst createAveragePoolShaderKeyFromAttributes = (attributes: AveragePoolAttributes): string =>\n    (`${createShaderKeyFromAttributes(attributes)};${attributes.countIncludePad}`);\n\nconst createMaxPoolShaderKeyFromAttributes = (attributes: MaxPoolAttributes): string =>\n    (`${createShaderKeyFromAttributes(attributes)};${attributes.storageOrder};${attributes.dilations}`);\n\nconst parsePoolCommonAttributes = (attributes: Record<string, unknown>): PoolCommonAttributes => ({\n  format: attributes.format as FormatAttributes['format'],\n  autoPad: ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number],\n  ceilMode: attributes.ceil_mode as number,\n  kernelShape: attributes.kernel_shape as [number, number],\n  strides: attributes.strides as [number, number],\n  pads: attributes.pads as [number, number, number, number]\n});\n\nexport interface AveragePoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly countIncludePad: boolean;\n}\n\nconst createAveragePoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: AveragePoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const x = inputVariable('x', input.dataType, input.dims.length);\n      const dataType = x.type.value;\n\n      const op1 = 'value += x_val;';\n      let op2 = '';\n      if (adjustedAttributes.countIncludePad) {\n        op2 += `value /= ${dataType}(uniforms.kernelSize);`;\n      } else {\n        op2 += `value /= ${dataType}(i32(uniforms.kernelSize) - pad);`;\n      }\n      const [programUniforms, uniforms, hasPads, pwStartEndNotZero, phStartEndNotZero] =\n          getUniformAndPadInfo(outputShape, adjustedAttributes);\n      programUniforms.push(...createTensorShapeVariables(input.dims), ...createTensorShapeVariables(outputShape));\n      const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank'];\n      return {\n        name,\n        shaderCache:\n            {hint: `${attributes.cacheKey};${hasPads};${pwStartEndNotZero};${phStartEndNotZero}`, inputDependencies},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)},\n          programUniforms\n        }),\n        getShaderSource: shaderHelper => generatePoolingCode(\n            shaderHelper, x, input.dims.length, outputShape.length, adjustedAttributes, op1, op2, 0.0, uniforms,\n            hasPads, pwStartEndNotZero, phStartEndNotZero),\n      };\n    };\n\nexport const parseAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const countIncludePad = (attributes.count_include_pad as number) === 0 ? false : true;\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode'\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for AveragePool');\n  }\n  const averagePoolAttributes = {countIncludePad, ...attr, cacheKey: ''};\n  return {...averagePoolAttributes, cacheKey: createAveragePoolShaderKeyFromAttributes(averagePoolAttributes)};\n};\n\nexport const averagePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('AveragePool', context.inputs[0], false, attributes));\n};\n\nconst globalPoolAttributes = {\n  autoPad: '',\n  ceilMode: 0,\n  countIncludePad: false,\n  kernelShape: [],\n  strides: [],\n  pads: [],\n  storageOrder: 0,\n  dilations: []\n};\n\nexport const parseGlobalAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalAveragePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('GlobalAveragePool', context.inputs[0], true, attributes));\n};\n\nexport interface MaxPoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly storageOrder: number;\n  readonly dilations: number[];\n}\n\nconst createMaxPoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: MaxPoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const op1 = `\n      value = max(x_val, value);\n    `;\n      const op2 = '';\n      const x = inputVariable('x', input.dataType, input.dims.length);\n      const inputDependencies: ProgramInputTensorInfoDependency[] = ['rank'];\n      const [programUniforms, uniforms, hasPads, pwStartEndNotZero, phStartEndNotZero] =\n          getUniformAndPadInfo(outputShape, adjustedAttributes);\n      programUniforms.push(...createTensorShapeVariables(input.dims), ...createTensorShapeVariables(outputShape));\n      return {\n        name,\n        shaderCache:\n            {hint: `${attributes.cacheKey};${hasPads};${pwStartEndNotZero};${phStartEndNotZero}`, inputDependencies},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)},\n          programUniforms\n        }),\n        getShaderSource: shaderHelper => generatePoolingCode(\n            shaderHelper, x, input.dims.length, outputShape.length, adjustedAttributes, op1, op2, -1e5, uniforms,\n            hasPads, pwStartEndNotZero, phStartEndNotZero),\n      };\n    };\n\nexport const maxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('MaxPool', context.inputs[0], false, attributes));\n};\n\nexport const parseMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const storageOrder = attributes.storage_order as number;\n  const dilations = attributes.dilations as [number, number];\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode' and 'storage_order'\n  if (storageOrder !== 0) {\n    throw new Error('column major storage order is not yet supported for MaxPool');\n  }\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for MaxPool');\n  }\n  const maxPoolAttributes = {storageOrder, dilations, ...attr, cacheKey: ''};\n  return {...maxPoolAttributes, cacheKey: createMaxPoolShaderKeyFromAttributes(maxPoolAttributes)};\n};\n\nexport const parseGlobalMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalMaxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('GlobalMaxPool', context.inputs[0], true, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from 'onnxruntime-common';\n\nimport {DataType, tensorDataTypeEnumToString} from '../../../wasm-common';\nimport {ComputeContext, ProgramInfo, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, outputVariable, ShaderHelper, UniformDataElementType, UniformsArrayType} from './common';\n\nconst validateInputsContent = (start: number, limit: number, delta: number): void => {\n  const sameStartLimit = start === limit;\n  const increasingRangeNegativeStep = start < limit && delta < 0;\n  const decreasingRangePositiveStep = start > limit && delta > 0;\n\n  if (sameStartLimit || increasingRangeNegativeStep || decreasingRangePositiveStep) {\n    throw new Error('Range these inputs\\' contents are invalid.');\n  }\n};\n\nconst createRangeProgramInfo = (start: number, limit: number, delta: number, dataType: DataType): ProgramInfo => {\n  const numElements = Math.abs(Math.ceil((limit - start) / delta));\n  const outputShape: number[] = [numElements];\n  const outputSize = numElements;\n  const tensorDataType = tensorDataTypeEnumToString(dataType) as ProgramUniform['type'];\n  const programUniforms: ProgramUniform[] = [\n    {type: 'uint32', data: outputSize}, {type: tensorDataType, data: start}, {type: tensorDataType, data: delta},\n    ...createTensorShapeVariables(outputShape)\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => {\n    const output = outputVariable('output', dataType, outputShape.length);\n    const wgslType = output.type.value;\n    const uniforms: UniformsArrayType = [\n      {name: 'outputSize', type: 'u32'}, {name: 'start', type: wgslType as UniformDataElementType},\n      {name: 'delta', type: wgslType as UniformDataElementType}\n    ];\n    return `\n        ${shaderHelper.registerUniforms(uniforms).declareVariables(output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n        output[global_idx] = uniforms.start + ${wgslType}(global_idx) * uniforms.delta;\n      }`;\n  };\n\n  return {\n    name: 'Range',\n    shaderCache: {hint: `${dataType}`},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms\n    })\n  };\n};\n\nexport const range = (context: ComputeContext): void => {\n  let start = 0;\n  let limit = 0;\n  let delta = 0;\n  if (context.inputs[0].dataType === DataType.int32) {\n    start = context.inputs[0].getInt32Array()[0];\n    limit = context.inputs[1].getInt32Array()[0];\n    delta = context.inputs[2].getInt32Array()[0];\n  } else if (context.inputs[0].dataType === DataType.float) {\n    start = context.inputs[0].getFloat32Array()[0];\n    limit = context.inputs[1].getFloat32Array()[0];\n    delta = context.inputs[2].getFloat32Array()[0];\n  }\n  if (env.webgpu.validateInputContent) {\n    validateInputsContent(start, limit, delta);\n  }\n\n  context.compute(createRangeProgramInfo(start, limit, delta, context.inputs[0].dataType), {inputs: []});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, getElementAt, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype CoordinateTransformMode = 'half_pixel'|'asymmetric'|'pytorch_half_pixel'|'tf_half_pixel_for_nn'|'align_corners'|\n    'tf_crop_and_resize'|'half_pixel_symmetric';\n\ntype KeepAspectRatioPolicy = 'stretch'|'not_smaller'|'not_larger';\n\ntype Mode = 'nearest'|'linear'|'cubic';\n\ntype NearestMode = 'round_prefer_floor'|'round_prefer_ceil'|'floor'|'ceil'|'simple';\n\nexport interface ResizeAttributes extends AttributeWithCacheKey {\n  antialias: number;\n  axes: number[];\n  coordinateTransformMode: CoordinateTransformMode;\n  cubicCoeffA: number;\n  excludeOutside: boolean;\n  extrapolationValue: number;\n  keepAspectRatioPolicy: KeepAspectRatioPolicy;\n  mode: Mode;\n  nearestMode: NearestMode;\n}\n\nconst validateScales = (scales: number[], attributes: ResizeAttributes): void => {\n  scales.every((value) => value > 0 || (() => {\n                            throw new Error('Resize requires scales input values to be positive');\n                          }));\n  // Check scales dims based on mode: LINEAR, CUBIC\n  if (scales.length > 0) {\n    if (attributes.mode === 'linear') {\n      if (!(scales.length === 2 || scales.length === 3 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1) ||\n            (scales.length === 5 && scales[0] === 1 && scales[1] === 1))) {\n        throw new Error(\n            `For linear mode, Resize requires scales to be 2D, 3D, 4D with either two outermost or one innermost and\n            one outermost scale values equal to 1, or 5D with two outermost scale values equal to 1`);\n      }\n    } else if (attributes.mode === 'cubic') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for cubic mode');\n      }\n    }\n  }\n};\n\nconst updateScales = (scales: readonly number[], axes: readonly number[], rank: number): number[] => {\n  axes.every((value) => value >= 0 && value < rank || (() => {\n                          throw new Error('Resize requires axes input values to be positive and less than rank');\n                        }));\n  const newScales = new Array(rank).fill(1.0);\n  axes.forEach((value, index) => newScales[value] = scales[index]);\n  return newScales;\n};\n\nconst validateInputs =\n    (inputs: readonly TensorView[], attributes: ResizeAttributes, opsetVersion: number, scales: number[],\n     sizes: number[], roi: number[]): void => {\n      const [roiInputIndex, scalesInputIndex, sizesInputIndex] =\n          (opsetVersion > 10) ? [1, 2, 3] : [-1, (inputs.length > 1) ? 1 : -1, -1];\n      const rank = inputs[0].dims.length;\n      if (roiInputIndex > 0 && inputs.length > roiInputIndex && inputs[roiInputIndex].dims.length > 0) {\n        inputs[roiInputIndex].getFloat32Array().forEach((value) => roi.push(value));\n\n      } else if (attributes.coordinateTransformMode === 'tf_crop_and_resize') {\n        throw new Error('Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize');\n      }\n\n      if (scalesInputIndex > 0 && inputs.length > scalesInputIndex && inputs[scalesInputIndex].dims.length > 0) {\n        inputs[scalesInputIndex].getFloat32Array().forEach((value) => scales.push(value));\n        if (scales.length !== 0 &&\n            (scales.length !== rank && (opsetVersion >= 18 && scales.length !== attributes.axes.length))) {\n          throw new Error(\n              'Resize requires scales input size to be same as input rank or axes size for opset 18 and up');\n        }\n        validateScales(scales, attributes);\n        if (attributes.axes.length > 0) {\n          updateScales(scales, attributes.axes, rank).forEach((value, index) => scales[index] = value);\n        }\n      }\n      if (sizesInputIndex > 0 && inputs.length > sizesInputIndex) {\n        inputs[sizesInputIndex].getBigInt64Array().forEach((value) => sizes.push(Number(value)));\n        if (sizes.length !== rank || (opsetVersion >= 18 && sizes.length === attributes.axes.length)) {\n          throw new Error('Resize requires sizes input size to be same as input rank or axes size for opset 18 and up');\n        }\n      }\n\n      if (attributes.axes.length > 0) {\n        if (scales.length !== attributes.axes.length) {\n          throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');\n        }\n        if (sizes.length !== attributes.axes.length) {\n          throw new Error(\n              'Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified');\n        }\n      }\n      if (typeof scales !== 'undefined' && typeof sizes !== 'undefined' && scales.length > 0 && sizes.length > rank) {\n        throw new Error('Resize requires only of scales or sizes to be specified');\n      }\n    };\n\nconst getOriginalCoordinateFromResizedCoordinate =\n    (coordinateTransferMode: CoordinateTransformMode, dType: string): string =>\n        `fn getOriginalCoordinateFromResizedCoordinate(xResized: u32, xScale: ${dType}, lengthResized: u32,\n     lengthOriginal: u32, roiStart: ${dType}, roiEnd: ${dType}) -> ${dType} { ` +\n    (() => {\n          switch (coordinateTransferMode) {\n            case 'asymmetric':\n              return `return ${dType}(xResized) / xScale;`;\n            case 'pytorch_half_pixel':\n              return `if (lengthResized > 1) {\n                    return (${dType}(xResized) + 0.5) / xScale - 0.5;\n                  } else {\n                    return 0.0;\n                  }`;\n            case 'tf_half_pixel_for_nn':\n              return `return (${dType}(xResized) + 0.5) / xScale;`;\n            case 'align_corners':\n              return `if (lengthResized == 1) {\n                    return 0.0;\n                  } else {\n                    // The whole part and the fractional part are calculated separately due to inaccuracy of floating\n                    // point division. As an example, f32(21) / f32(7) may evaluate to 2.99... instead of 3, causing an\n                    // offset-by-one error later in floor().\n                    let whole = ${dType}(xResized * (lengthOriginal - 1) / (lengthResized - 1));\n                    let fract =\n                        ${dType}(xResized * (lengthOriginal - 1) % (lengthResized - 1)) / ${dType}(lengthResized - 1);\n                    return whole + fract;\n                  }`;\n            case 'tf_crop_and_resize':\n              return `if (lengthResized > 1) {\n                    return roiStart * ${dType}(lengthOriginal - 1) +\n                        (${dType}(xResized) * (roiEnd - roiStart) * ${dType}(lengthOriginal - 1)) /\n                        ${dType}(lengthResized - 1);\n                  } else {\n                    return 0.5 * (roiStart + roiEnd) * ${dType}(lengthOriginal - 1);\n                  }`;\n            case 'half_pixel_symmetric':\n              return `const outputWidth = xScale * ${dType}(lengthResized);\n                  const adjustment = ${dType}(lengthResized) / outputWidth;\n                  const center = ${dType}(lengthOriginal) / 2;\n                  const offset = center * (1 - adjustment);\n                  return offset + ((${dType}(xResized) + 0.5) / xScale) - 0.5;`;\n            case 'half_pixel':\n              return `return ((${dType}(xResized) + 0.5) / xScale) - 0.5;`;\n            default:\n              throw new Error(`Coordinate transform mode ${coordinateTransferMode} is not supported`);\n          }\n        })() +\n    '}';\n\nconst getNearestPixelFromOriginal = (nearestMode: NearestMode, opsetVersion: number, dType: string): string =>\n    `fn getNearestPixelFromOriginal(xOriginal: ${dType}, isDownSample: bool) -> ${dType} {` + (() => {\n      switch (nearestMode) {\n        case 'round_prefer_ceil':\n          return 'if (fract(xOriginal) == 0.5) { \\\n            return ceil(xOriginal); \\\n          } else { \\\n            return round(xOriginal); \\\n          }';\n        case 'floor':\n          return 'return floor(xOriginal);';\n        case 'ceil':\n          return 'return ceil(xOriginal);';\n        case 'round_prefer_floor':\n          return 'if (fract(xOriginal) == 0.5) { \\\n                    return floor(xOriginal); \\\n                  } else { \\\n                    return round(xOriginal); \\\n                  }';\n        case 'simple':\n        default:\n          if (opsetVersion < 11) {\n            return 'if (isDownSample) \\\n                    { \\\n                      return ceil(xOriginal); \\\n                    } else { \\\n                      return xOriginal; \\\n                    }';\n          }\n          throw new Error(`Nearest mode ${nearestMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst updateRoI = (roi: readonly number[], axes: readonly number[], rank: number): number[] => {\n  const roiTmp = new Array(rank).fill(0).concat(new Array(rank).fill(1));\n  const roiLocal = roi.length === 0 ? roiTmp : roi.slice();\n  if (axes.length > 0) {\n    axes.forEach((v, i) => {\n      roiTmp[v] = roiLocal[i];\n      roiTmp[i + rank] = roiLocal[axes.length + i];\n    });\n    return roiTmp;\n  }\n  return roiLocal;\n};\n\nconst initOutputShape =\n    (inputShape: readonly number[], scales: readonly number[], sizes: readonly number[], axes: readonly number[]):\n        number[] => {\n          let outputShape: number[] = [];\n          if (sizes.length > 0) {\n            if (axes.length > 0) {\n              inputShape.forEach((v) => outputShape.push(v));\n              if (Math.max(...axes) > inputShape.length) {\n                throw new Error('axes is out of bound');\n              }\n              axes.forEach((v, i) => outputShape[v] = sizes[i]);\n            } else {\n              sizes.forEach((v) => outputShape.push(v));\n            }\n          } else {\n            if (scales.length === 0) {\n              throw new Error('Resize requires either scales or sizes.');\n            } else {\n              outputShape = inputShape.map((value, index) => Math.round(value * scales[index]));\n            }\n          }\n          return outputShape;\n        };\n\nconst adjustOutputShape = (inputShape: readonly number[], scales: number[], attributes: ResizeAttributes) => {\n  const scaleInPolicy = (() => {\n    switch (attributes.keepAspectRatioPolicy) {\n      case 'not_larger':\n        return attributes.axes.length > 0 ? Math.min(...attributes.axes.map(i => scales[i]), Number.MAX_VALUE) :\n                                            Math.min(...scales, Number.MAX_VALUE);\n      case 'not_smaller':\n        return attributes.axes.length > 0 ? Math.max(...attributes.axes.map(i => scales[i]), Number.MIN_VALUE) :\n                                            Math.max(...scales, Number.MIN_VALUE);\n      default:\n        throw new Error(`Keep aspect ratio policy ${attributes.keepAspectRatioPolicy} is not supported`);\n    }\n  })();\n  scales.fill(1.0, 0, scales.length);\n  const adjustedOutputShape = inputShape.slice();\n  if (attributes.axes.length > 0) {\n    attributes.axes.forEach((v) => scales[v] = scaleInPolicy);\n    attributes.axes.forEach((v) => adjustedOutputShape[v] = Math.round(inputShape[v] * scales[v]));\n  } else {\n    scales.fill(scaleInPolicy, 0, scales.length);\n    adjustedOutputShape.forEach((v, i) => adjustedOutputShape[i] = Math.round(v * scales[i]));\n  }\n  return adjustedOutputShape;\n};\n\nconst calculateOriginalIndicesFromOutputIndices =\n    (output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[], scalesLength: number,\n     roiLength: number): string => `\n    fn calculateOriginalIndicesFromOutputIndices(output_indices: ${output.type.indices}) -> array<${\n        output.type.value}, ${outputShape.length}> {\n      var original_indices: array<${output.type.value}, ${outputShape.length}>;\n      for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n        var output_index = ${output.indicesGet('output_indices', 'i')};\n        var scale = ${getElementAt('uniforms.scales', 'i', scalesLength)};\n        var roi_low = ${getElementAt('uniforms.roi', 'i', roiLength)};\n        var roi_hi = ${getElementAt('uniforms.roi', `i + ${inputShape.length}`, roiLength)};\n        if (scale == 1.0) {\n          original_indices[i] = ${output.type.value}(output_index);\n        } else {\n          var input_shape_i = ${getElementAt('uniforms.input_shape', 'i', inputShape.length)};\n          var output_shape_i = ${getElementAt('uniforms.output_shape', 'i', outputShape.length)};\n          original_indices[i] = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                           input_shape_i, roi_low, roi_hi);\n        }\n      }\n      return original_indices;\n    }`;\n\nconst calculateInputIndicesFromOutputIndices =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scalesLength: number, roiLength: number, useExtrapolation: boolean): string => `\n    fn calculateInputIndicesFromOutputIndices(output_indices: ${output.type.indices}) -> ${input.type.indices} {\n      var input_indices: ${input.type.indices};\n      for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n        var output_index = ${output.indicesGet('output_indices', 'i')};\n        var input_index: u32;\n        var scale = ${getElementAt('uniforms.scales', 'i', scalesLength)};\n        if (scale == 1.0) {\n          input_index = output_index;\n        } else {\n          var roi_low = ${getElementAt('uniforms.roi', 'i', roiLength)};\n          var roi_hi = ${getElementAt('uniforms.roi', `i + ${inputShape.length}`, roiLength)};\n          var input_shape_i = ${getElementAt('uniforms.input_shape', 'i', inputShape.length)};\n          var output_shape_i = ${getElementAt('uniforms.output_shape', 'i', outputShape.length)};\n          var original_idx = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                        input_shape_i, roi_low, roi_hi);\n          if (!${useExtrapolation} || (original_idx >= 0 && original_idx < ${output.type.value}(input_shape_i))) {\n            if (original_idx < 0) {\n              input_index = 0;\n            } else if (original_idx > ${output.type.value}(input_shape_i - 1)) {\n              input_index = input_shape_i - 1;\n            } else {\n              input_index = u32(getNearestPixelFromOriginal(original_idx, scale < 1));\n            }\n          } else {\n            input_index = u32(original_idx);\n          }\n        }\n        ${input.indicesSet('input_indices', 'i', ' input_index')}\n      }\n      return input_indices;\n    }`;\nconst checkInputIndices = (input: IndicesHelper, inputShape: readonly number[]): string => `\n    fn checkInputIndices(input_indices: ${input.type.indices}) -> bool {\n      for (var i:u32 = 0; i < ${inputShape.length}; i++) {\n        var input_index = ${input.indicesGet('input_indices', 'i')};\n        if (input_index < 0 || input_index >= ${getElementAt('uniforms.input_shape', 'i', inputShape.length)}) {\n          return false;\n        }\n      }\n      return true;\n    }`;\n\nconst setChannelAndBatchIndices =\n    (input: IndicesHelper, channelIdx: number, batchIdx: number, spacialDims: number): string =>\n        input.rank > spacialDims ? `\n    ${input.indicesSet('input_indices', channelIdx, 'channel')};\n    ${input.indicesSet('input_indices', batchIdx, 'batch')};\n` :\n                                   '';\n\nconst bilinearInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], useExtrapolation: boolean,\n     extrapolationValue: number): string => {\n      const isNchw = true;\n      const [batchIdx, heightIdx, widthIdx, channelIdx] =\n          inputShape.length === 2 ? [-1, 0, 1, -1] : (isNchw ? [0, 2, 3, 1] : [0, 1, 2, 3]);\n      const dType = input.type.value;\n      return `\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> ${dType} {\n      var input_indices: ${input.type.indices};\n      ${input.indicesSet('input_indices', heightIdx, `max(0, min(row, ${inputShape[heightIdx]} - 1))`)};\n      ${input.indicesSet('input_indices', widthIdx, `max(0, min(col, ${inputShape[widthIdx]} - 1))`)};\n      ${setChannelAndBatchIndices(input, channelIdx, batchIdx, 2)}\n      return ${input.getByIndices('input_indices')};\n    }\n\n    fn bilinearInterpolation(output_indices: ${output.type.indices}) -> ${dType} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var row:${dType} = originalIndices[${heightIdx}];\n      var col:${dType} = originalIndices[${widthIdx}];\n      ${\n          useExtrapolation ?\n              `if (row < 0 || row > (${inputShape[heightIdx]} - 1) || col < 0 || col > (${inputShape[widthIdx]} - 1)) {\n        return ${extrapolationValue};\n      }` :\n              ''};\n      row = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      col = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = ${inputShape.length > 2 ? `u32(originalIndices[${channelIdx}])` : '0'};\n      var batch: u32 =  ${inputShape.length > 2 ? `u32(originalIndices[${batchIdx}])` : '0'};\n      var x11: ${dType} = getInputValue(batch, channel, row1, col1);\n      var x12: ${dType} = getInputValue(batch, channel, row1, col2);\n      var x21: ${dType} = getInputValue(batch, channel, row2, col1);\n      var x22: ${dType} = getInputValue(batch, channel, row2, col2);\n      var dx1: ${dType} = abs(row - ${dType}(row1));\n      var dx2: ${dType} = abs(${dType}(row2) - row);\n      var dy1: ${dType} = abs(col - ${dType}(col1));\n      var dy2: ${dType} = abs(${dType}(col2) - col);\n      if (row1 == row2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (col1 == col2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`;\n    };\n\nconst bicubicInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], cubicCoeffA: number, useExtrapolation: boolean,\n     extrapolationValue: number, excludeOutside: boolean): string => {\n      const is2D = inputShape.length === 2;\n      const isNchw = true;\n      const [heightIdx, widthIdx] = is2D ? [0, 1] : isNchw ? [2, 3] : [1, 2];\n      const dType = input.type.value;\n      const createCubicInterpolationFunction = (idx: number): string => {\n        const direction = idx === heightIdx ? 'row' : 'col';\n        return `\n      fn ${direction}CubicInterpolation(input_indices: ${input.type.indices}, output_indices: ${\n            output.type.indices}) -> ${dType} {\n        var output_index = ${output.indicesGet('output_indices', idx)};\n        var originalIdx: ${dType} = getOriginalCoordinateFromResizedCoordinate(output_index, ${scales[idx]},\n        ${outputShape[idx]}, ${inputShape[idx]}, ${roi[idx]}, ${roi[idx]} + ${inputShape.length});\n        var fractOriginalIdx: ${dType} = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${useExtrapolation} && (originalIdx < 0 || originalIdx > (${inputShape[idx]} - 1))) {\n          return ${extrapolationValue};\n        }\n        var data: array<${dType}, 4> = array<${dType}, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${direction}: ${dType} = originalIdx + ${dType}(i);\n          if (${direction} < 0 || ${direction} >= ${inputShape[idx]}) {\n            ${(() => {\n          if (excludeOutside) {\n            return `coefs[i + 1] = 0.0;\n                        continue;`;\n          } else if (useExtrapolation) {\n            return `return ${extrapolationValue};`;\n          } else {\n            return `${direction} = max(0, min(${direction}, ${inputShape[idx]} - 1));`;\n          }\n        })()};\n          }\n        var input_indices_copy: ${input.type.indices} = input_indices;\n          ${input.indicesSet('input_indices_copy', idx, `u32(${direction})`)};\n          data[i + 1] = ${\n            idx === heightIdx ? input.getByIndices('input_indices_copy') :\n                                'rowCubicInterpolation(input_indices_copy, output_indices)'};\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`;\n      };\n\n      return `\n    ${createCubicInterpolationFunction(heightIdx)};\n    ${createCubicInterpolationFunction(widthIdx)};\n  fn getCubicInterpolationCoefs(s: ${dType}) -> array<${dType}, 4> {\n    var absS = abs(s);\n    var coeffs: array<${dType}, 4> = array<${dType}, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: ${dType} = 1.0 - absS;\n    var twoMinusAbsS: ${dType} = 2.0 - absS;\n    var onePlusAbsS: ${dType} = 1.0 + absS;\n    coeffs[0] = ((${cubicCoeffA} * onePlusAbsS - 5 * ${cubicCoeffA}) * onePlusAbsS + 8 * ${\n          cubicCoeffA}) * onePlusAbsS - 4 * ${cubicCoeffA};\n    coeffs[1] = ((${cubicCoeffA} + 2) * absS - (${cubicCoeffA} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${cubicCoeffA} + 2) * oneMinusAbsS - (${cubicCoeffA} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${cubicCoeffA} * twoMinusAbsS - 5 * ${cubicCoeffA}) * twoMinusAbsS + 8 * ${\n          cubicCoeffA}) * twoMinusAbsS - 4 * ${cubicCoeffA};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<${dType}, 4>, coefs: array<${dType}, 4>) -> ${dType} {\n    var coefsSum: ${dType} = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(output_indices: ${output.type.indices}) -> ${dType} {\n    var input_indices: ${input.type.indices} = output_indices;\n    return colCubicInterpolation(input_indices, output_indices);\n  }\n    `;\n    };\n\nconst trilinearInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], useExtrapolation: boolean,\n     extrapolationValue: number): string => {\n      const isNchw = true;\n      const [batchIdx, depthIdx, heightIdx, widthIdx, channelIdx] =\n          inputShape.length === 3 ? [-1, 0, 1, 2, -1] : (isNchw ? [0, 2, 3, 4, 1] : [0, 1, 2, 3, 4]);\n      const dType = input.type.value;\n      return `\n    fn getInputValue(batch: u32, channel: u32, depth:u32, height: u32, width: u32) -> ${dType} {\n      var input_indices: ${input.type.indices};\n      ${input.indicesSet('input_indices', depthIdx, `max(0, min(depth, ${inputShape[depthIdx]} - 1))`)};\n      ${input.indicesSet('input_indices', heightIdx, `max(0, min(height, ${inputShape[heightIdx]} - 1))`)};\n      ${input.indicesSet('input_indices', widthIdx, `max(0, min(width, ${inputShape[widthIdx]} - 1))`)};\n      ${setChannelAndBatchIndices(input, channelIdx, batchIdx, 3)}\n      return ${input.getByIndices('input_indices')};\n    }\n\n    fn trilinearInterpolation(output_indices: ${output.type.indices}) -> ${dType} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var depth:${dType} = originalIndices[${depthIdx}];\n      var height:${dType} = originalIndices[${heightIdx}];\n      var width:${dType} = originalIndices[${widthIdx}];\n      ${\n          useExtrapolation ? `if (depth < 0 || depth > (${inputShape[depthIdx]} - 1) || height < 0 || height > (${\n                                 inputShape[heightIdx]} - 1) || width < 0 || (width > ${inputShape[widthIdx]} - 1)) {\n      return ${extrapolationValue};\n        }` :\n                             ''};\n\n    depth = max(0, min(depth, ${inputShape[depthIdx]} - 1));\n      height = max(0, min(height, ${inputShape[heightIdx]} - 1));\n      width = max(0, min(width, ${inputShape[widthIdx]} - 1));\n      var depth1: u32 = u32(depth);\n      var height1: u32 = u32(height);\n      var width1: u32 = u32(width);\n      var depth2: u32 = u32(depth + 1);\n      var height2: u32 = u32(height + 1);\n      var width2: u32 = u32(width + 1);\n      var channel: u32 = ${inputShape.length > 3 ? `u32(originalIndices[${channelIdx}])` : '0'};\n      var batch: u32 =  ${inputShape.length > 3 ? `u32(originalIndices[${batchIdx}])` : '0'};\n\n      var x111: ${dType} = getInputValue(batch, channel, depth1, height1, width1);\n      var x112: ${dType} = getInputValue(batch, channel, depth1, height1, width2);\n      var x121: ${dType} = getInputValue(batch, channel, depth1, height2, width1);\n      var x122: ${dType} = getInputValue(batch, channel, depth1, height2, width2);\n      var x211: ${dType} = getInputValue(batch, channel, depth2, height1, width1);\n      var x212: ${dType} = getInputValue(batch, channel, depth2, height1, width2);\n      var x221: ${dType} = getInputValue(batch, channel, depth2, height2, width1);\n      var x222: ${dType} = getInputValue(batch, channel, depth2, height2, width2);\n      var dx1: ${dType} = abs(depth - ${dType}(depth1));\n      var dx2: ${dType} = abs(${dType}(depth2) - depth);\n      var dy1: ${dType} = abs(height - ${dType}(height1));\n      var dy2: ${dType} = abs(${dType}(height2) - height);\n      var dz1: ${dType} = abs(width - ${dType}(width1));\n      var dz2: ${dType} = abs(${dType}(width2) - width);\n      if (depth1 == depth2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (height1 == height2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      if (width1 == width2) {\n        dz1 = 0.5;\n        dz2 = 0.5;\n      }\n      return (x111 * dx2 * dy2 * dz2 + x112 * dx2 * dy2 * dz1 + x121 * dx2 * dy1 *dz2 + x122 * dx2 * dy1 * dz1 +\n              x211 * dx1 * dy2 * dz2 + x212 * dx1 * dy2 * dz1 + x221 * dx1 * dy1 *dz2 + x222 * dx1 * dy1 * dz1);\n    }`;\n    };\n\nconst createResizeProgramInfo =\n    (inputTensor: TensorView, attributes: ResizeAttributes, opsetVersion: number, scalesInput: readonly number[],\n     sizes: readonly number[], roiInput: readonly number[]): ProgramInfo => {\n      const inputShape = inputTensor.dims;\n      const roi = updateRoI(roiInput, attributes.axes, inputShape.length);\n\n      let outputShape = initOutputShape(inputShape, scalesInput, sizes, attributes.axes);\n      let scales = scalesInput.slice();\n      if (scalesInput.length === 0) {\n        scales = inputShape.map((value, index) => value === 0 ? 1.0 : outputShape[index] / value);\n        if (attributes.keepAspectRatioPolicy !== 'stretch') {\n          outputShape = adjustOutputShape(inputShape, scales, attributes);\n        }\n      }\n      const output = outputVariable('output', inputTensor.dataType, outputShape.length);\n      const input = inputVariable('input', inputTensor.dataType, inputShape.length);\n      const outputSize = ShapeUtil.size(outputShape);\n      const noScale = inputShape.length === outputShape.length && inputShape.every((d, i) => d === outputShape[i]);\n      const useExtrapolation = attributes.coordinateTransformMode === 'tf_crop_and_resize';\n      const extrapolationValue = attributes.extrapolationValue;\n      const dataType = input.type.value;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${noScale ? '' : `\n      ${getOriginalCoordinateFromResizedCoordinate(attributes.coordinateTransformMode, dataType)};\n      ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `\n              ${checkInputIndices(input, inputShape)};\n              ${getNearestPixelFromOriginal(attributes.nearestMode, opsetVersion, dataType)};\n              ${\n                calculateInputIndicesFromOutputIndices(\n                    input, output, inputShape, outputShape, scales.length, roi.length, useExtrapolation)};\n              `;\n          case 'linear':\n            return `\n              ${calculateOriginalIndicesFromOutputIndices(output, inputShape, outputShape, scales.length, roi.length)};\n              ${(() => {\n              if (inputShape.length === 2 || inputShape.length === 4) {\n                return `${bilinearInterpolation(input, output, inputShape, useExtrapolation, extrapolationValue)}`;\n              } else if (inputShape.length === 3 || inputShape.length === 5) {\n                return `${trilinearInterpolation(input, output, inputShape, useExtrapolation, extrapolationValue)}`;\n              } else {\n                throw Error('Linear mode only supports input dims 2, 3, 4 and 5 are supported in linear mode.');\n              }\n            })()};\n            `;\n          case 'cubic':\n            return `\n            ${(() => {\n              if (inputShape.length === 2 || inputShape.length === 4) {\n                return `${\n                    bicubicInterpolation(\n                        input, output, inputShape, outputShape, scales, roi, attributes.cubicCoeffA, useExtrapolation,\n                        attributes.extrapolationValue, attributes.excludeOutside)}`;\n              } else {\n                throw Error('Cubic mode only supports input dims 2 and 4 are supported in linear mode.');\n              }\n            })()};\n            `;\n          default:\n            throw Error('Invalid resize mode');\n        }\n      })()};\n      `}\n      ${\n          shaderHelper.registerUniform('output_size', 'u32')\n              .registerUniform('scales', 'f32', scales.length)\n              .registerUniform('roi', 'f32', roi.length)\n              .declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n        ${noScale ? 'output[global_idx] = input[global_idx];' : `\n        let output_indices = ${output.offsetToIndices('global_idx')};\n        var input_indices: ${input.type.indices};\n        ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `input_indices = calculateInputIndicesFromOutputIndices(output_indices);\n                if (checkInputIndices(input_indices)) {\n                  output[global_idx] = ${input.getByIndices('input_indices')};\n                } else {\n                  output[global_idx] = ${attributes.extrapolationValue};\n                }`;\n          case 'linear':\n            return `output[global_idx] = ${\n                (inputShape.length === 2 || inputShape.length === 4) ? 'bilinearInterpolation' :\n                                                                       'trilinearInterpolation'}(output_indices);`;\n          case 'cubic':\n            return 'output[global_idx] = bicubicInterpolation(output_indices);';\n          default:\n            throw Error(`Unsupported resize mode: ${attributes.mode}`);\n        }\n      })()};\n`}\n      }`;\n\n      return {\n        name: 'Resize',\n        shaderCache: {\n          hint: `${attributes.cacheKey}|${opsetVersion}|${scales.length > 0 ? scales : ''}|${\n              sizes.length > 0 ? sizes : ''}|${roi.length > 0 ? roi : ''}|${noScale}|${inputShape}`,\n          inputDependencies: ['rank']\n        },\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputTensor.dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n          programUniforms: [\n            {type: 'uint32', data: outputSize},\n            {type: 'float32', data: scales},\n            {type: 'float32', data: roi},\n            ...createTensorShapeVariables(inputShape),\n            ...createTensorShapeVariables(outputShape),\n          ]\n        })\n      };\n    };\n\nconst getOpsetVersionFromCustomDataBuffer = (context: ComputeContext): number => {\n  const customDataBuffer = context.customDataBuffer;\n  const customDataBuffer32 = new Uint32Array(customDataBuffer, customDataBuffer.byteOffset, 1);\n  const opsetVersion = customDataBuffer32[0];\n  return opsetVersion;\n};\n\nexport const resize = (context: ComputeContext, attributes: ResizeAttributes): void => {\n  const scales: number[] = [];\n  const sizes: number[] = [];\n  const roi: number[] = [];\n  const opsetVersion = getOpsetVersionFromCustomDataBuffer(context);\n  if (attributes.antialias !== 0) {\n    throw Error('Only default value (0) for Antialias attribute is supported');\n  }\n  validateInputs(context.inputs, attributes, opsetVersion, scales, sizes, roi);\n  context.compute(\n      createResizeProgramInfo(context.inputs[0], attributes, opsetVersion, scales, sizes, roi), {inputs: [0]});\n};\n\nexport const parseResizeAttributes = (attributes: Record<string, unknown>): ResizeAttributes => {\n  const antialias = attributes.antialias as number;\n  const axes = attributes.axes as number[];\n  const coordinateTransformMode: CoordinateTransformMode =\n      attributes.coordinateTransformMode as CoordinateTransformMode;\n  const cubicCoeffA = attributes.cubicCoeffA as number;\n  const excludeOutside = attributes.excludeOutside as number !== 0;\n  const extrapolationValue = attributes.extrapolationValue as number;\n  const keepAspectRatioPolicy: KeepAspectRatioPolicy = attributes.keepAspectRatioPolicy as KeepAspectRatioPolicy;\n  const mode: Mode = attributes.mode as Mode;\n  // If nearestMode is not specified, use simple mode.\n  const nearestMode: NearestMode = (attributes.nearestMode === '' ? 'simple' : attributes.nearestMode) as NearestMode;\n  return createAttributeWithCacheKey({\n    antialias,\n    axes,\n    coordinateTransformMode,\n    cubicCoeffA,\n    excludeOutside,\n    extrapolationValue,\n    keepAspectRatioPolicy,\n    mode,\n    nearestMode\n  });\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType,} from './common';\n\nexport interface SkipLayerNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 3) {\n    throw new Error('layerNorm requires at least 3 inputs.');\n  }\n\n  const input: TensorView = inputs[0];\n  const skip: TensorView = inputs[1];\n  const gamma: TensorView = inputs[2];\n\n  if (input.dataType !== skip.dataType || input.dataType !== gamma.dataType) {\n    throw new Error('All inputs must have the same data type');\n  }\n\n  if (input.dims.length !== 3 && input.dims.length !== 2) {\n    throw new Error('Input must be 2D or 3D');\n  }\n\n  if (skip.dims.length !== 3 && skip.dims.length !== 2) {\n    throw new Error('Skip must be 2D or 3D');\n  }\n\n  const hiddenSize = input.dims[input.dims.length - 1];\n  const sequenceLength = input.dims[input.dims.length - 2];\n  if (skip.dims[skip.dims.length - 1] !== hiddenSize) {\n    throw new Error('Skip must have the same hidden size as input');\n  }\n  if (skip.dims[skip.dims.length - 2] !== sequenceLength) {\n    throw new Error('Skip must have the same sequence length as input');\n  }\n\n  if (gamma.dims.length !== 1) {\n    throw new Error('Gamma must be 1D');\n  }\n  if (gamma.dims[gamma.dims.length - 1] !== hiddenSize) {\n    throw new Error('Gamma must have the same hidden size as input');\n  }\n  if (inputs.length > 3) {\n    const beta: TensorView = inputs[3];\n    if (beta.dims.length !== 1) {\n      throw new Error('Beta must be 1D');\n    }\n    if (beta.dims[beta.dims.length - 1] !== hiddenSize) {\n      throw new Error('Beta must have the same hidden size as input');\n    }\n  }\n\n  if (inputs.length > 4) {\n    const bias: TensorView = inputs[4];\n    if (bias.dims.length !== 1) {\n      throw new Error('Bias must be 1D');\n    }\n    if (bias.dims[bias.dims.length - 1] !== hiddenSize) {\n      throw new Error('Bias must have the same hidden size as input');\n    }\n  }\n};\n\nconst createSkipLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: SkipLayerNormAttributes, outputCount: number, isTraining: boolean):\n        ProgramInfo => {\n          const inputShape = inputs[0].dims;\n          const inputSize = ShapeUtil.size(inputShape);\n          const outputShape = inputShape;\n          const outputSize = inputSize;\n          const hiddenSize = inputShape.slice(-1)[0];\n          const meanInvStdDevDim = isTraining ? inputShape.slice(0, -1).concat(1) : [];\n          const hasBetaInput = inputs.length > 3;\n          const hasBiasInput = inputs.length > 4;\n          const hasMeanOutput = isTraining && outputCount > 1;\n          const hasInvStdDevOutput = isTraining && outputCount > 2;\n          const hasInputSkipBiasSumOutput = outputCount > 3;\n\n          const components = getMaxComponents(hiddenSize);\n          const variables = [\n            inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n            inputVariable('skip', inputs[1].dataType, inputs[1].dims, components),\n            inputVariable('gamma', inputs[2].dataType, inputs[2].dims, components),\n          ];\n          if (hasBetaInput) {\n            variables.push(inputVariable('beta', inputs[3].dataType, inputs[3].dims, components));\n          }\n          if (hasBiasInput) {\n            variables.push(inputVariable('bias', inputs[4].dataType, inputs[4].dims, components));\n          }\n          variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n          if (hasMeanOutput) {\n            variables.push(outputVariable('meanOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInvStdDevOutput) {\n            variables.push(outputVariable('invStdOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInputSkipBiasSumOutput) {\n            variables.push(outputVariable('inputSkipBiasSum', inputs[0].dataType, outputShape, components));\n          }\n          const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n          const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const hiddenSize: f32 = ${hiddenSize};\n      const hiddenSizeVectorized: u32 = ${hiddenSize / components};\n      const epsilon: f32 = ${attributes.epsilon};\n\n      ${shaderHelper.declareVariables(...variables)}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize / hiddenSize)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${fillVector('f32', components)};\n        var squareSum = ${fillVector('f32', components)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${hasBiasInput ? 'bias[i]' : '0.0'};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${hasInputSkipBiasSumOutput ? 'inputSkipBiasSum[offset + i] = value;' : ''}\n          output[offset + i] = value;\n          let f32Value = ${castToF32(dataType, components, 'value')};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${sumVector('sum', components)} / hiddenSize;\n        let variance = sqrt(${sumVector('squareSum', components)} / hiddenSize - mean * mean + epsilon);\n        ${hasMeanOutput ? 'meanOutput[global_idx] = mean;' : ''}\n        ${hasInvStdDevOutput ? 'invStdOutput[global_idx] = 1.0 / variance;' : ''}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${dataType}(mean)) / ${dataType}(variance) * gamma[i]\n           + ${hasBetaInput ? 'beta[i]' : '0.0'};\n        }\n      }`;\n          const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n          if (outputCount > 1) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 2) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 3) {\n            outputs.push({dims: inputShape, dataType: inputs[0].dataType});\n          }\n\n          return {\n            name: 'SkipLayerNormalization',\n            shaderCache: {hint: attributes.cacheKey},\n            getShaderSource,\n            getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(outputSize / hiddenSize / 64)}}),\n          };\n        };\n\nexport const skipLayerNorm = (context: ComputeContext, attributes: SkipLayerNormAttributes): void => {\n  // TODO: initialize isTraining from ComputeContext\n  const isTraining = false;\n  validateInputs(context.inputs);\n  // Mean and InvStdDev are only used in training mode and are not required for inference.\n  // They are added here for completeness only.\n  const outputs = [0];\n  if (context.outputCount > 1) {\n    outputs.push(isTraining ? 1 : -3);\n  }\n  if (context.outputCount > 2) {\n    outputs.push(isTraining ? 2 : -3);\n  }\n  if (context.outputCount > 3) {\n    outputs.push(3);\n  }\n  context.compute(\n      createSkipLayerNormProgramInfo(context.inputs, attributes, context.outputCount, isTraining), {outputs});\n};\n\nexport const parseSkipLayerNormAttributes = (attributes: Record<string, unknown>): SkipLayerNormAttributes => {\n  const epsilon = attributes.epsilon as number;\n  return createAttributeWithCacheKey({epsilon});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramUniform, TensorInfo} from '../types';\n\nimport {createTensorShapeVariables, getElementAt, IndicesHelper, inputVariable, outputVariable, ShaderHelper, UniformsArrayType} from './common';\n\nexport interface SliceAttributes extends AttributeWithCacheKey {\n  readonly starts: number[];\n  readonly ends: number[];\n  readonly axes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: SliceAttributes): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n  if (attributes.axes.length !== 0) {\n    if (attributes.axes.length !== attributes.starts.length || attributes.axes.length !== attributes.ends.length) {\n      throw new Error('axes, starts and ends must have the same length');\n    }\n  } else if (attributes.starts.length !== attributes.ends.length) {\n    throw new Error('starts and ends must have the same length');\n  }\n  inputs.slice(1).forEach((_, idx) => {\n    if (inputs[idx + 1].dataType !== DataType.int32 && inputs[idx + 1].dataType !== DataType.int64) {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  });\n};\n\nconst readInput = (inputs: readonly TensorView[], idx: number): number[] => {\n  const input: number[] = [];\n  if (inputs.length > idx) {\n    if (inputs[idx].dataType === DataType.int64) {\n      inputs[idx].getBigInt64Array().forEach(v => input.push(Number(v)));\n    } else if (inputs[idx].dataType === DataType.int32) {\n      inputs[idx].getInt32Array().forEach(v => input.push(Number(v)));\n    } else {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  }\n  return input;\n};\n\nconst createSliceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SliceAttributes): SliceAttributes => {\n      if (inputs.length > 1) {\n        const starts: number[] = readInput(inputs, 1);\n        const ends: number[] = readInput(inputs, 2);\n        let axes: number[] = readInput(inputs, 3);\n        if (axes.length === 0) {\n          axes = [...Array(inputs[0].dims.length).keys()];\n        }\n        return createAttributeWithCacheKey({starts, ends, axes});\n      } else {\n        return attributes;\n      }\n    };\n\nconst fixStartEndValues =\n    (value: number, index: number, inputShape: readonly number[], axes: readonly number[], steps: readonly number[]):\n        number => {\n          let newValue = value;\n          if (value < 0) {\n            newValue += inputShape[axes[index]];\n          }\n          if (steps[index] < 0) {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]] - 1));\n          } else {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]]));\n          }\n        };\n\nconst calculateInputIndicesImpl =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[]): string =>\n        `fn calculateInputIndices(output_indices: ${output.type.indices}) -> ${input.type.indices} {\n          var input_indices: ${input.type.indices};\n          var carry = 0u;\n          for (var i = ${inputShape.length}; i >= 0; i--) {\n            let input_shape_i = ${getElementAt('uniforms.input_shape', 'i', inputShape.length)};\n            let steps_i = ${getElementAt('uniforms.steps', 'i', inputShape.length)};\n            let signs_i = ${getElementAt('uniforms.signs', 'i', inputShape.length)};\n            let starts_i = ${getElementAt('uniforms.starts', 'i', inputShape.length)};\n            var output_index = ${output.indicesGet('output_indices', 'i')};\n            var input_index = output_index * steps_i + starts_i + carry;\n            carry = input_index / input_shape_i;\n            input_index = input_index % input_shape_i;\n            if (signs_i < 0) {\n              input_index = input_shape_i - input_index - 1u + starts_i;\n            }\n            ${input.indicesSet('input_indices', 'i', 'input_index')};\n          }\n          return input_indices;\n      }`;\n\nconst createSliceProgramInfo = (inputs: readonly TensorView[], attributes: SliceAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const axes = (attributes.axes.length > 0) ? ShapeUtil.normalizeAxes(attributes.axes, inputShape.length) :\n                                              [...Array(inputShape.length).keys()];\n  let steps = readInput(inputs, 4);\n  steps.forEach((step) => step !== 0 || (() => {\n                            throw new Error('step cannot be 0');\n                          }));\n  if (steps.length === 0) {\n    steps = Array(axes.length).fill(1);\n  }\n  const starts = attributes.starts.map((start, i) => fixStartEndValues(start, i, inputShape, axes, steps));\n\n  const ends = attributes.ends.map((end, i) => fixStartEndValues(end, i, inputShape, axes, steps));\n\n  if (axes.length !== starts.length || axes.length !== ends.length) {\n    throw new Error('start, ends and axes should have the same number of elements');\n  }\n\n  if (axes.length !== inputShape.length) {\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (!axes.includes(i)) {\n        starts.splice(i, 0, 0);\n        ends.splice(i, 0, inputShape[i]);\n        steps.splice(i, 0, 1);\n      }\n    }\n  }\n  const signs = steps.map(step => Math.sign(step));\n  // Convert negative steps to positive steps and reverse starts and ends\n  steps.forEach((step, i, array) => {\n    if (step < 0) {\n      const numSteps = (ends[i] - starts[i]) / step;\n      const newEnd = starts[i];\n      const newStart = newEnd + numSteps * steps[i];\n      starts[i] = newStart;\n      ends[i] = newEnd;\n      array[i] = -step;\n    }\n  });\n  // Output rank is expected to be less than or equal to the input rank.\n  const outputShape = inputShape.slice(0);\n  axes.forEach((axis, _) => {\n    outputShape[axis] = Math.ceil((ends[axis] - starts[axis]) / steps[axis]);\n  });\n  const outputTensorInfo: TensorInfo = {dims: outputShape, dataType: inputs[0].dataType};\n\n  const output = outputVariable('output', inputs[0].dataType, outputShape.length);\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims.length);\n  const outputSize = ShapeUtil.size(outputShape);\n  const uniforms: UniformsArrayType = [\n    {name: 'outputSize', type: 'u32'}, {name: 'starts', type: 'u32', length: starts.length},\n    {name: 'signs', type: 'i32', length: signs.length}, {name: 'steps', type: 'u32', length: steps.length}\n  ];\n\n  const programUniforms: ProgramUniform[] = [\n    {type: 'uint32', data: outputSize}, {type: 'uint32', data: starts}, {type: 'int32', data: signs},\n    {type: 'uint32', data: steps}, ...createTensorShapeVariables(inputs[0].dims),\n    ...createTensorShapeVariables(outputShape)\n  ];\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.registerUniforms(uniforms).declareVariables(input, output)}\n        ${calculateInputIndicesImpl(input, output, inputShape)}\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n          let output_indices = ${output.offsetToIndices('global_idx')};\n          let input_indices = calculateInputIndices(output_indices);\n          ${output.setByOffset('global_idx', input.getByIndices('input_indices'))}\n      }`;\n  return {\n    name: 'Slice',\n    shaderCache: {hint: `${signs.length}_${starts.length}_${steps.length}`, inputDependencies: ['rank']},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [outputTensorInfo],\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n      programUniforms\n    })\n  };\n};\n\nexport const slice = (context: ComputeContext, attributes: SliceAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  const updatedAttributes = createSliceAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSliceProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n  // if (ShapeUtil.size(program.outputs[0].dims) > 0) {\n  //   context.compute(programInfoLoader, {inputs: [0]});\n  // } else {\n  //   // TODO: support empty output\n  //   throw new Error('slice: output size is 0');\n  // }\n};\n\nexport const parseSliceAttributes = (attributes: Record<string, unknown>): SliceAttributes => {\n  const starts = attributes.starts as number[];\n  const ends = attributes.ends as number[];\n  const axes = attributes.axes as number[];\n  return createAttributeWithCacheKey({starts, ends, axes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Softmax op requires 1 input.');\n  }\n};\n\nexport interface SoftmaxAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst createSoftmaxProgramInfo = (input: TensorView, attributes: SoftmaxAttributes): ProgramInfo => {\n  const shape = input.dims;\n  const outputSize = ShapeUtil.size(shape);\n  const WG = 64;\n  let axis = attributes.axis;\n  if (axis < 0) {\n    axis = shape.length + axis;\n  }\n  if (axis < shape.length - 1) {\n    throw new Error('softmax only supports last axis for now.');\n  }\n\n  const cols = shape[axis];\n  const rows = outputSize / cols;\n  const components = getMaxComponents(cols);\n  const packedCols = cols / components;\n\n  const maxVector = (name: string, components: number) => {\n    if (components === 4) {\n      return `max(max(${name}.x, ${name}.y), max(${name}.z, ${name}.w))`;\n    } else if (components === 2) {\n      return `max(${name}.x, ${name}.y)`;\n    } else if (components === 3) {\n      return `max(max(${name}.x, ${name}.y), ${name}.z)`;\n    }\n\n    return name;\n  };\n  const x = inputVariable('x', input.dataType, input.dims, components);\n  const output = outputVariable('result', input.dataType, input.dims, components);\n  const valueType = x.type.value;\n  // 6.2.4 in wgsl spec\n  const threadMaxDecl = tensorTypeToWsglStorageType(input.dataType) === 'f32' ?\n      `var threadMax = ${valueType}(-3.402823e+38f);` :\n      `var threadMax = ${valueType}(-65504.0h);`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      var<workgroup> rowMaxShared : ${valueType};\n      var<workgroup> rowSumShared : ${valueType};\n      var<workgroup> threadShared : array<${valueType}, ${WG}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${valueType} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${valueType}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${shaderHelper.registerUniform('packedCols', 'i32').declareVariables(x, output)}\n      ${shaderHelper.mainStart()}\n        let gindex = i32(global_idx);\n        let lindex = i32(local_idx);\n        const wg = ${WG};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${threadMaxDecl}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${valueType}(${maxVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${valueType}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${valueType}(${sumVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;\n  return {\n    name: 'Softmax',\n    shaderCache: {hint: `${components}`, inputDependencies: ['type']},\n    getRunData: () => ({\n      outputs: [{dims: shape, dataType: input.dataType}],\n      dispatchGroup: {x: rows},\n      programUniforms: [{type: 'uint32', data: packedCols}]\n    }),\n    getShaderSource,\n  };\n};\n\nexport const softmax = (context: ComputeContext, attributes: SoftmaxAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createSoftmaxProgramInfo(context.inputs[0], attributes));\n};\n\nexport const parseSoftmaxAttributes = (attributes: Record<string, unknown>): SoftmaxAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramUniform, TensorInfo} from '../types';\n\nimport {createTensorShapeVariables, getElementAt, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface SplitAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n  readonly numOutputs: number;\n  readonly splitSizes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n};\n\nconst createSplitAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SplitAttributes): SplitAttributes => {\n      const splitSizes: number[] = [];\n      let numOutputs: number = attributes.numOutputs;\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => splitSizes.push(Number(v)));\n        numOutputs = splitSizes.length;\n      }\n      return createAttributeWithCacheKey({numOutputs, axis: attributes.axis, splitSizes});\n    };\n\nconst calculateOutputIndexImpl = (numberOfTensors: number): string => `\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${numberOfTensors}u; i += 1u ) {\n    if (index < ${getElementAt('uniforms.size_in_split_axis', 'i', numberOfTensors)}) {\n        return i;\n    }\n    }\n    return ${numberOfTensors}u;\n}`;\nconst writeBufferDataImpl = (outputs: readonly IndicesHelper[]) => {\n  const numberOfTensors = outputs.length;\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = outputs[i].setByIndices('indices', 'input[global_idx]');\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (output_number == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (output_number == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return `\n      fn writeBufferData(output_number: u32, indices: ${outputs[0].type.indices}, global_idx: u32) {\n        ${codeLines.join('\\n')}\n      }`;\n};\n\nconst createSplitProgramInfo = (inputs: readonly TensorView[], attributes: SplitAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const dataType = inputs[0].dataType;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputShape.length);\n  const outputs = new Array<IndicesHelper>(attributes.numOutputs);\n  const input = inputVariable('input', dataType, inputShape);\n  const sizeInSplitAxis = new Array<number>(attributes.numOutputs);\n  const outputsTensorInfo: TensorInfo[] = [];\n  const outputShapes: number[][] = [];\n  let previousSum = 0;\n  const programUniforms: ProgramUniform[] = [{type: 'uint32', data: inputSize}];\n  for (let i = 0; i < attributes.numOutputs; i++) {\n    previousSum += attributes.splitSizes[i];\n    sizeInSplitAxis[i] = previousSum;\n    const outputShape = inputShape.slice();\n    outputShape[attributes.axis] = attributes.splitSizes[i];\n    outputShapes.push(outputShape);\n    outputs[i] = outputVariable(`output${i}`, dataType, outputShape);\n    outputsTensorInfo.push({dims: outputShapes[i], dataType: inputs[0].dataType});\n  }\n  programUniforms.push({type: 'uint32', data: sizeInSplitAxis});\n  programUniforms.push(...createTensorShapeVariables(inputShape));\n  outputShapes.forEach((outputShape) => programUniforms.push(...createTensorShapeVariables(outputShape)));\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${\n      shaderHelper.registerUniform('input_size', 'u32')\n          .registerUniform('size_in_split_axis', 'u32', sizeInSplitAxis.length)\n          .declareVariables(input, ...outputs)}\n  ${calculateOutputIndexImpl(sizeInSplitAxis.length)}\n  ${writeBufferDataImpl(outputs)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.input_size')}\n\n    var indices = ${input.offsetToIndices('global_idx')};\n    var index = ${input.indicesGet('indices', axis)};\n    let output_number = calculateOutputIndex(index);\n    if (output_number != 0) {\n      index -= ${getElementAt('uniforms.size_in_split_axis', 'output_number - 1u', sizeInSplitAxis.length)};\n      ${input.indicesSet('indices', axis, 'index')};\n    }\n    writeBufferData(output_number, indices, global_idx);\n  }`;\n  return {\n    name: 'Split',\n    shaderCache: {hint: attributes.cacheKey, inputDependencies: ['rank']},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: outputsTensorInfo,\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n      programUniforms\n    })\n  };\n};\n\nexport const split = (context: ComputeContext, attributes: SplitAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes =\n      context.inputs.length === 1 ? attributes : createSplitAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSplitProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parseSplitAttributes = (attributes: Record<string, unknown>): SplitAttributes => {\n  const axis = attributes.axis as number;\n  const splitSizes: number[] = attributes.splitSizes as number[];\n  const numOutputs = attributes.numOutputs as number < 0 ? splitSizes.length : attributes.numOutputs as number;\n  if (numOutputs !== splitSizes.length) {\n    throw new Error('numOutputs and splitSizes lengh must be equal');\n  }\n  return createAttributeWithCacheKey({axis, numOutputs, splitSizes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst getRepeats = (repeatsTensorView: TensorView): readonly number[] =>\n    Array.from(repeatsTensorView.getBigInt64Array(), Number);\n\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Tile requires 2 inputs.');\n  }\n\n  if (inputs[0].dataType !== DataType.float && inputs[0].dataType !== DataType.int32 &&\n      inputs[0].dataType !== DataType.uint32) {\n    throw new Error('Tile only support float, int32, and uint32 data types');\n  }\n\n  if (inputs[1].dataType !== DataType.int64) {\n    throw new Error('Tile `repeats` input should be of int64 data type');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('Tile `repeats` input should be 1-D');\n  }\n\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n\n  if (repeats.length !== inputs[0].dims.length) {\n    throw new Error('Tile `repeats` input should have same number of elements as rank of input data tensor');\n  }\n};\n\nconst getOutputShape = (inputShape: readonly number[], repeats: readonly number[]): readonly number[] => {\n  const outputShape: number[] = [];\n\n  for (let i = 0; i < inputShape.length; ++i) {\n    outputShape.push(inputShape[i] * repeats[i]);\n  }\n\n  return outputShape;\n};\n\nexport const createTileProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n  const outputShape = getOutputShape(inputShape, repeats);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape.length);\n  const output = outputVariable('output', dataType, outputShape.length);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputShape = ${input.indices(...inputShape)};\n      ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n      let output_indices = ${output.offsetToIndices('global_idx')};\n      var input_indices: ${input.type.indices};\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        let input_dim_i = ${input.indicesGet('uniforms.input_shape', 'i')};\n        let input_dim_value = ${output.indicesGet('output_indices', 'i')}  % input_dim_i;\n\n        ${input.indicesSet('input_indices', 'i', 'input_dim_value')}\n      }\n      ${output.setByOffset('global_idx', input.getByIndices('input_indices'))}\n    }`;\n\n  return {\n    name: 'Tile',\n    shaderCache: {hint: `${repeats}`, inputDependencies: ['rank']},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms: [\n        {type: 'uint32', data: outputSize}, ...createTensorShapeVariables(inputs[0].dims),\n        ...createTensorShapeVariables(outputShape)\n      ],\n    }),\n    getShaderSource,\n  };\n};\n\nexport const tile = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createTileProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst createWhereOpProgramShader =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], dimsOutput: readonly number[], isBroadcast: boolean,\n     typeOutput: number) => {\n      const output = outputVariable('output_data', typeOutput, dimsOutput.length, 4);\n      const a = inputVariable('a_data', inputs[1].dataType, inputs[1].dims.length, 4);\n      const b = inputVariable('b_data', inputs[2].dataType, inputs[2].dims.length, 4);\n      const c = inputVariable('c_data', inputs[0].dataType, inputs[0].dims.length, 4);\n\n      let assignment: string;\n      const expression = (a: string, b: string, c: string) => `select(${b}, ${a}, ${c})`;\n      if (!isBroadcast) {\n        assignment = output.setByOffset(\n            'global_idx',\n            expression(a.getByOffset('global_idx'), b.getByOffset('global_idx'), c.getByOffset('global_idx')));\n      } else {\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `a_data[index_a${x}][component_a${x}]`;\n          const expressionB = `b_data[index_b${x}][component_b${x}]`;\n          // eslint-disable-next-line no-bitwise\n          const expressionC = `bool(c_data[index_c${x}] & ${0xff000000 >>> ((3 - x) * 8)}u)`;\n          return `\n            let output_indices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offset_a${x} = ${a.broadcastedIndicesToOffset(`output_indices${x}`, output)};\n            let offset_b${x} = ${b.broadcastedIndicesToOffset(`output_indices${x}`, output)};\n            let offset_c${x} = ${c.broadcastedIndicesToOffset(`output_indices${x}`, output)};\n            let index_a${x} = offset_a${x} / 4u;\n            let index_b${x} = offset_b${x} / 4u;\n            let index_c${x} = offset_c${x} / 4u;\n            let component_a${x} = offset_a${x} % 4u;\n            let component_b${x} = offset_b${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expression(expressionA, expressionB, expressionC)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            output_data[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('output_data[global_idx]', 0)}\n            ${singleAssignment('output_data[global_idx]', 1)}\n            ${singleAssignment('output_data[global_idx]', 2)}\n            ${singleAssignment('output_data[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(c, a, b, output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n        ${assignment}\n      }`;\n    };\n\nconst createWhereOpProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const dimsA = inputs[1].dims;\n  const dimsB = inputs[2].dims;\n  const dimsC = inputs[0].dims;\n  const outputDataType = inputs[1].dataType;\n\n  const isBroadcast = !(ShapeUtil.areEqual(dimsA, dimsB) && ShapeUtil.areEqual(dimsB, dimsC));\n  let outputShape = dimsA;\n  let outputSize = ShapeUtil.size(dimsA);\n  const vecSize = Math.ceil(outputSize / 4);\n  // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n\n  if (isBroadcast) {\n    const calculatedShape = BroadcastUtil.calcShape(BroadcastUtil.calcShape(dimsA, dimsB, false)!, dimsC, false);\n    if (!calculatedShape) {\n      throw new Error('Can\\'t perform where op on the given tensors');\n    }\n    outputShape = calculatedShape;\n    outputSize = ShapeUtil.size(outputShape);\n  }\n\n  return {\n    name: 'Where',\n    shaderCache: {inputDependencies: ['rank', 'rank', 'rank']},\n    getShaderSource: (shaderHelper) =>\n        createWhereOpProgramShader(shaderHelper, inputs, outputShape, isBroadcast, outputDataType),\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: outputDataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* vec size */)},\n      programUniforms: [\n        {type: 'uint32', data: vecSize}, ...createTensorShapeVariables(dimsC), ...createTensorShapeVariables(dimsA),\n        ...createTensorShapeVariables(dimsB), ...createTensorShapeVariables(outputShape)\n      ],\n    }),\n  };\n};\n\nexport const where = (context: ComputeContext): void => {\n  context.compute(createWhereOpProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {argMax, argMin, parseArgMinMaxAttributes} from './ops/argminmax';\nimport {attention} from './ops/attention';\nimport {batchNorm} from './ops/batch-norm';\nimport {biasAdd} from './ops/bias-add';\nimport {biasSplitGelu} from './ops/bias-split-gelu';\nimport * as binaryOps from './ops/binary-op';\nimport {concat, parseConcatAttributes} from './ops/concat';\nimport {conv, parseConvAttributes} from './ops/conv';\nimport {convTranspose, parseConvTransposeAttributes} from './ops/conv-transpose';\nimport {cumsum, parseCumSumAttributes} from './ops/cumsum';\nimport {einsum, parseEinsumAttributes} from './ops/einsum';\nimport {expand} from './ops/expand';\nimport {gather, parseGatherAttributes} from './ops/gather';\nimport {gatherElements, parseGatherElementsAttributes} from './ops/gather-elements';\nimport {gemm, parseGemmAttributes} from './ops/gemm';\nimport {instanceNorm} from './ops/instance-norm';\nimport {layerNorm} from './ops/layer-norm';\nimport {matMul} from './ops/matmul';\nimport {multiHeadAttention, parseMultiHeadAttentionAttributes} from './ops/multi-head-attentiion';\nimport {pad} from './ops/pad';\nimport * as pool from './ops/pool';\nimport {range} from './ops/range';\nimport {reduceL1, reduceL2, reduceLogSum, reduceLogSumExp, reduceMax, reduceMean, reduceMin, reduceProd, reduceSum, reduceSumSquare} from './ops/reduce';\nimport {parseResizeAttributes, resize} from './ops/resize';\nimport {parseSkipLayerNormAttributes, skipLayerNorm} from './ops/skip-layer-norm';\nimport {parseSliceAttributes, slice} from './ops/slice';\nimport {parseSoftmaxAttributes, softmax} from './ops/softmax';\nimport {parseSplitAttributes, split} from './ops/split';\nimport {tile} from './ops/tile';\nimport {parseTransposeAttributes, transpose} from './ops/transpose';\nimport * as unaryOps from './ops/unary-op';\nimport {where} from './ops/where';\nimport {ComputeContext} from './types';\n\nexport type RunFunction = (context: ComputeContext, attribute?: unknown) => void;\nexport type ParseAttributeFunction = (attributeRaw: unknown) => unknown;\nexport type OperatorImplementation = [RunFunction]|[RunFunction, ParseAttributeFunction];\n\nexport const WEBGPU_OP_RESOLVE_RULES: Map<string, OperatorImplementation> = new Map([\n  ['Abs', [unaryOps.abs]],\n  ['Acos', [unaryOps.acos]],\n  ['Acosh', [unaryOps.acosh]],\n  ['Add', [binaryOps.add]],\n  ['ArgMax', [argMax, parseArgMinMaxAttributes]],\n  ['ArgMin', [argMin, parseArgMinMaxAttributes]],\n  ['Asin', [unaryOps.asin]],\n  ['Asinh', [unaryOps.asinh]],\n  ['Atan', [unaryOps.atan]],\n  ['Atanh', [unaryOps.atanh]],\n  ['Attention', [attention]],\n  // TODO: support new attributes for AveragePool-10\n  ['AveragePool', [pool.averagePool, pool.parseAveragePoolAttributes]],\n  ['BatchNormalization', [batchNorm]],\n  ['BiasAdd', [biasAdd]],\n  ['BiasSplitGelu', [biasSplitGelu]],\n  ['Cast', [unaryOps.cast, unaryOps.parseCastAttributes]],\n  ['Ceil', [unaryOps.ceil]],\n  ['Clip', [unaryOps.clip]],\n  ['Concat', [concat, parseConcatAttributes]],\n  ['Conv', [conv, parseConvAttributes]],\n  ['ConvTranspose', [convTranspose, parseConvTransposeAttributes]],\n  ['Cos', [unaryOps.cos]],\n  ['Cosh', [unaryOps.cosh]],\n  ['CumSum', [cumsum, parseCumSumAttributes]],\n  ['Div', [binaryOps.div]],\n  ['Einsum', [einsum, parseEinsumAttributes]],\n  ['Elu', [unaryOps.elu, unaryOps.parseAlphaAttributes]],\n  ['Equal', [binaryOps.equal]],\n  ['Erf', [unaryOps.erf]],\n  ['Exp', [unaryOps.exp]],\n  ['Expand', [expand]],\n  ['Floor', [unaryOps.floor]],\n  ['FusedConv', [conv, parseConvAttributes]],\n  ['Gather', [gather, parseGatherAttributes]],\n  ['GatherElements', [gatherElements, parseGatherElementsAttributes]],\n  ['Gelu', [unaryOps.gelu]],\n  ['Gemm', [gemm, parseGemmAttributes]],\n  ['GlobalAveragePool', [pool.globalAveragePool, pool.parseGlobalAveragePoolAttributes]],\n  ['GlobalMaxPool', [pool.globalMaxPool, pool.parseGlobalMaxPoolAttributes]],\n  ['Greater', [binaryOps.greater]],\n  ['GreaterOrEqual', [binaryOps.greaterOrEqual]],\n  ['InstanceNormalization', [instanceNorm]],\n  ['LayerNormalization', [layerNorm]],\n  ['LeakyRelu', [unaryOps.leakyRelu, unaryOps.parseAlphaAttributes]],\n  ['Less', [binaryOps.less]],\n  ['LessOrEqual', [binaryOps.lessOrEqual]],\n  ['Log', [unaryOps.log]],\n  ['MatMul', [matMul]],\n  // TODO: support new attributes for MaxPool-8 and MaxPool-10\n  ['MaxPool', [pool.maxPool, pool.parseMaxPoolAttributes]],\n  ['Mul', [binaryOps.mul]],\n  ['MultiHeadAttention', [multiHeadAttention, parseMultiHeadAttentionAttributes]],\n  ['Neg', [unaryOps.neg]],\n  ['Not', [unaryOps.not]],\n  ['Pad', [pad]],\n  ['Pow', [binaryOps.pow]],\n  ['Range', [range]],\n  ['Reciprocal', [unaryOps.reciprocal]],\n  ['ReduceMin', [reduceMin]],\n  ['ReduceMean', [reduceMean]],\n  ['ReduceMax', [reduceMax]],\n  ['ReduceSum', [reduceSum]],\n  ['ReduceProd', [reduceProd]],\n  ['ReduceL1', [reduceL1]],\n  ['ReduceL2', [reduceL2]],\n  ['ReduceLogSum', [reduceLogSum]],\n  ['ReduceLogSumExp', [reduceLogSumExp]],\n  ['ReduceSumSquare', [reduceSumSquare]],\n  ['Relu', [unaryOps.relu]],\n  ['Resize', [resize, parseResizeAttributes]],\n  ['Sigmoid', [unaryOps.sigmoid]],\n  ['Sin', [unaryOps.sin]],\n  ['Sinh', [unaryOps.sinh]],\n  ['Slice', [slice, parseSliceAttributes]],\n  ['SkipLayerNormalization', [skipLayerNorm, parseSkipLayerNormAttributes]],\n  ['Split', [split, parseSplitAttributes]],\n  ['Sqrt', [unaryOps.sqrt]],\n  ['Softmax', [softmax, parseSoftmaxAttributes]],\n  ['Sub', [binaryOps.sub]],\n  ['Tan', [unaryOps.tan]],\n  ['Tanh', [unaryOps.tanh]],\n  ['ThresholdedRelu', [unaryOps.thresholdedRelu, unaryOps.parseAlphaAttributes]],\n  ['Tile', [tile]],\n  ['Transpose', [transpose, parseTransposeAttributes]],\n  ['Where', [where]],\n]);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TRACE_FUNC_BEGIN, TRACE_FUNC_END} from 'onnxruntime-common';\n\nimport {tensorDataTypeEnumToString} from '../../wasm-common';\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\nimport {TensorView} from '../tensor-view';\n\nimport {createShaderHelper} from './ops/common';\nimport {Artifact, GpuData, ProgramInfo} from './types';\n\n/**\n * ProgramManager is the main class behind running computations\n * It builds ProgramInfo's into Artifacts\n * It compiles given ProgramInfo's into WebGL Prorams (cached as Artifacts)\n * Uses the artifact to run the computation by calling Draw on\n * the WebGL drawing buffer\n * ProgramManager automatically maps (binds) input variables to their\n * corresponding Location's in the binary program\n */\nexport class ProgramManager {\n  repo: Map<unknown, Artifact>;  // this should be per-session object\n  attributesBound: boolean;\n\n  constructor(private backend: WebGpuBackend) {\n    this.repo = new Map();\n    this.attributesBound = false;\n  }\n  getArtifact(key: unknown): Artifact|undefined {\n    return this.repo.get(key);\n  }\n  setArtifact(key: unknown, artifact: Artifact): void {\n    this.repo.set(key, artifact);\n  }\n  run(buildArtifact: Artifact, inputTensorViews: readonly TensorView[], outputTensorViews: readonly TensorView[],\n      inputs: GpuData[], outputs: GpuData[], dispatchGroup: [number, number, number],\n      uniformBufferBinding: GPUBindingResource|undefined): void {\n    TRACE_FUNC_BEGIN(buildArtifact.programInfo.name);\n    const device = this.backend.device;\n\n    const computePassEncoder = this.backend.getComputePassEncoder();\n    computePassEncoder.setPipeline(buildArtifact.computePipeline);\n    const entries = [];\n    for (const input of inputs) {\n      entries.push({binding: entries.length, resource: {buffer: input.buffer}});\n    }\n    for (const output of outputs) {\n      entries.push({binding: entries.length, resource: {buffer: output.buffer}});\n    }\n    if (uniformBufferBinding) {\n      entries.push({binding: entries.length, resource: uniformBufferBinding});\n    }\n    const bindGroup = device.createBindGroup(\n        {layout: buildArtifact.computePipeline.getBindGroupLayout(0), entries, label: buildArtifact.programInfo.name});\n    computePassEncoder.setBindGroup(0, bindGroup);\n\n    computePassEncoder.dispatchWorkgroups(...dispatchGroup);\n\n    this.backend.pendingDispatchNumber++;\n\n    if (this.backend.isQueryEnabled()) {\n      if (typeof this.backend.queryData === 'undefined') {\n        this.backend.queryData = this.backend.gpuDataManager.create(\n            // eslint-disable-next-line no-bitwise\n            this.backend.querySetCount * 8, GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);\n      }\n      const syncData = this.backend.gpuDataManager.create(\n          // eslint-disable-next-line no-bitwise\n          this.backend.querySetCount * 8, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n\n      this.backend.endComputePass();\n      this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet!, 0, 2, this.backend.queryData.buffer, 0);\n      this.backend.getCommandEncoder().copyBufferToBuffer(\n          this.backend.queryData.buffer, 0, syncData.buffer, 0, this.backend.querySetCount * 8);\n      this.backend.flush();\n\n      const kernelId = this.backend.currentKernelId!;\n      const kernelInfo = this.backend.kernels.get(kernelId)!;\n\n      void syncData.buffer.mapAsync(GPUMapMode.READ).then(() => {\n        const mappedData = new BigUint64Array(syncData.buffer.getMappedRange());\n        const [startTimeU64, endTimeU64] = mappedData;\n        const [kernelType, kernelName] = kernelInfo;\n\n        syncData.buffer.unmap();\n\n        if (typeof this.backend.queryTimeBase === 'undefined') {\n          this.backend.queryTimeBase = startTimeU64;\n        }\n\n        const startTime = Number(startTimeU64 - this.backend.queryTimeBase);\n        const endTime = Number(endTimeU64 - this.backend.queryTimeBase);\n\n        if (!Number.isSafeInteger(startTime) || !Number.isSafeInteger(endTime)) {\n          throw new RangeError('incorrect timestamp range');\n        }\n\n        this.backend.gpuDataManager.release(syncData.id);\n        if (this.backend.env.webgpu.profiling?.ondata) {\n          this.backend.env.webgpu.profiling.ondata({\n            version: 1,\n            inputsMetadata: inputTensorViews.map(\n                value => ({dims: value.dims, dataType: tensorDataTypeEnumToString(value.dataType)})),\n            outputsMetadata: outputTensorViews.map(\n                value => ({dims: value.dims, dataType: tensorDataTypeEnumToString(value.dataType)})),\n            kernelId,\n            kernelType,\n            kernelName,\n            startTime,\n            endTime,\n          });\n        } else {\n          // if no callback is provided, print the profiling message to console\n          let inputShapes = '';\n          inputTensorViews.forEach((value, i) => {\n            inputShapes += `input[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n          });\n          let outputShapes = '';\n          outputTensorViews.forEach((value, i) => {\n            outputShapes += `output[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n          });\n          // eslint-disable-next-line no-console\n          console.log(`[profiling] kernel \"${kernelId}|${kernelName}|${buildArtifact.programInfo.name}\" ${inputShapes}${\n              outputShapes}execution time: ${endTime - startTime} ns`);\n        }\n      });\n    }\n\n    if (this.backend.pendingDispatchNumber >= 16) {\n      this.backend.flush();\n    }\n    TRACE_FUNC_END(buildArtifact.programInfo.name);\n  }\n  dispose(): void {\n    // this.repo.forEach(a => this.glContext.deleteProgram(a.program));\n  }\n  build(programInfo: ProgramInfo, normalizedDispatchGroupSize: [number, number, number]): Artifact {\n    TRACE_FUNC_BEGIN(programInfo.name);\n    const device = this.backend.device;\n    const extensions: string[] = [];\n    if (device.features.has('shader-f16')) {\n      extensions.push('enable f16;');\n    }\n    const shaderHelper = createShaderHelper(normalizedDispatchGroupSize);\n    const userCode = programInfo.getShaderSource(shaderHelper);\n    const code = `${extensions.join('\\n')}\\n${shaderHelper.additionalImplementations}\\n${userCode}`;\n    const shaderModule = device.createShaderModule({code, label: programInfo.name});\n    LOG_DEBUG('verbose', () => `[WebGPU] ${programInfo.name} shader code: ${code}`);\n\n    const computePipeline = device.createComputePipeline(\n        {compute: {module: shaderModule, entryPoint: 'main'}, layout: 'auto', label: programInfo.name});\n\n    TRACE_FUNC_END(programInfo.name);\n    return {programInfo, computePipeline};\n  }\n\n  normalizeDispatchGroupSize(dispatchGroup: ReturnType<ProgramInfo['getRunData']>['dispatchGroup']):\n      [number, number, number] {\n    const x = typeof dispatchGroup === 'number' ? dispatchGroup : dispatchGroup.x;\n    const y = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.y || 1);\n    const z = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.z || 1);\n    const limitPerDimension = this.backend.device.limits.maxComputeWorkgroupsPerDimension;\n    if (x <= limitPerDimension && y <= limitPerDimension && z <= limitPerDimension) {\n      return [x, y, z];\n    }\n    const size = x * y * z;\n    let dispatchAverage = Math.ceil(Math.sqrt(size));\n    if (dispatchAverage > limitPerDimension) {\n      dispatchAverage = Math.ceil(Math.cbrt(size));\n      if (dispatchAverage > limitPerDimension) {\n        throw new Error('Total dispatch size exceeds WebGPU maximum.');\n      }\n      return [dispatchAverage, dispatchAverage, dispatchAverage];\n    } else {\n      return [dispatchAverage, dispatchAverage, 1];\n    }\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, Tensor, TRACE_FUNC_BEGIN, TRACE_FUNC_END} from 'onnxruntime-common';\n\nimport {configureLogger, LOG_DEBUG} from './log';\nimport {createView, TensorView} from './tensor-view';\nimport {createGpuDataManager, downloadGpuData, GpuDataManager} from './webgpu/gpu-data-manager';\nimport {RunFunction, WEBGPU_OP_RESOLVE_RULES} from './webgpu/op-resolve-rules';\nimport {ProgramManager} from './webgpu/program-manager';\nimport {ComputeContext, GpuData, ProgramInfo, ProgramInputTensorInfoDependency} from './webgpu/types';\n\nconst getProgramInputTensorInfoDependencyKey =\n    (inputTensors: readonly TensorView[], inputDependencies: readonly ProgramInputTensorInfoDependency[]): string => {\n      if (inputDependencies.length !== inputTensors.length) {\n        throw new Error(`inputDependencies length ${inputDependencies.length} is not equal to inputTensors length ${\n            inputTensors.length}.`);\n      }\n\n      const inputInfos: string[] = [];\n      for (let i = 0; i < inputTensors.length; ++i) {\n        const type = inputTensors[i].dataType;\n        switch (inputDependencies[i]) {\n          case 'none': {\n            inputInfos.push('');\n            break;\n          }\n          case 'type': {\n            inputInfos.push(`${type}`);\n            break;\n          }\n          case 'rank': {\n            const rank = inputTensors[i].dims.length;\n            inputInfos.push(`${type};${rank}`);\n            break;\n          }\n          case 'dims': {\n            const dims = inputTensors[i].dims.join(',');\n            inputInfos.push(`${type};${dims}`);\n            break;\n          }\n          default:\n            throw new Error(`unsupported input dependency: ${inputDependencies[i]}`);\n        }\n      }\n\n      return inputInfos.join('|');\n    };\n\n/**\n * get a unique key representing the program from the program info, input shapes and types.\n *\n * @returns a unique key is a shorter string than the shader source, which contains all the information to identify a\n * program. if the key is the same, the program shader source should be the same, so we can reuse the program.\n *\n */\nconst getProgramInfoUniqueKey =\n    (programInfo: ProgramInfo, inputTensors: readonly TensorView[], is1DimensionDispatch: boolean): string => {\n      // final key format:\n      // <PROGRAM_NAME>[<PROGRAM_CUSTOM_CACHE_HINT>]:is1DimensionDispatch:<INPUTS_INFO_0>|<INPUTS_INFO_1>|...\n      let key = programInfo.name;\n      if (programInfo.shaderCache?.hint) {\n        key += '[' + programInfo.shaderCache.hint + ']';\n      }\n      key += ':' + is1DimensionDispatch +\n          `:${\n                 getProgramInputTensorInfoDependencyKey(\n                     inputTensors,\n                     programInfo.shaderCache?.inputDependencies ??\n                         new Array<ProgramInputTensorInfoDependency>(inputTensors.length).fill('dims'))}`;\n      return key;\n    };\n\n/**\n * this class is designed to store status and being used as a singleton for JSEP. It will be passed to jsepInit() as\n * the first parameter so that it is stored for future use.\n */\nexport class WebGpuBackend {\n  device: GPUDevice;\n  /**\n   * an instance of GpuDataManager to manage a GpuDataId -> GpuBuffer mapping\n   */\n  gpuDataManager: GpuDataManager;\n  /**\n   * an instance of ProgramManager to build and run WebGPU compute shader program, and manage a ProgramKey -> Program\n   * artifacts mapping\n   */\n  programManager: ProgramManager;\n\n  /**\n   * representing the kernel ID of which is currently being computed (CPU code perspective).\n   * `null` means no kernel is being computed.\n   * only one kernel can be computed at a moment.\n   */\n  currentKernelId: number|null = null;\n  /**\n   * a list of temporary GPU data for the current kernel. should release when the kernel done computation.\n   */\n  private temporaryData: GpuData[];\n  /**\n   * a KernelID -> a GPU data list, which stores persistent GPU data owned by the specific kernel.\n   */\n  private kernelPersistentData: Map<number, GpuData[]>;\n  /**\n   * a KernelID -> a custom data, which stores custom data owned by the specific kernel.\n   */\n  private kernelCustomData: Map<number, {[key: string]: unknown}>;\n  /**\n   * get the custom data of the current kernel\n   */\n  get currentKernelCustomData(): {[key: string]: unknown} {\n    if (this.currentKernelId === null) {\n      throw new Error('currentKernelCustomData(): currentKernelId is null. (should not happen)');\n    }\n\n    let data = this.kernelCustomData.get(this.currentKernelId);\n    if (!data) {\n      data = {};\n      this.kernelCustomData.set(this.currentKernelId, data);\n    }\n\n    return data;\n  }\n\n  /**\n   * a KernelID -> kernel info mapping. value is\n   * [ op_type, name, run function, [optional] preprocess_attribute_once function ]\n   */\n  kernels: Map<number, [string, string, RunFunction, [((attribute: unknown) => unknown) | undefined, unknown]]>;\n\n  private commandEncoder: GPUCommandEncoder|null = null;\n  private computePassEncoder: GPUComputePassEncoder|null = null;\n  pendingDispatchNumber = 0;\n\n  queryData?: GpuData;\n  querySet?: GPUQuerySet;\n  querySetCount = 2;\n  queryTimeBase?: bigint;\n\n  env: Env;\n\n  /**\n   * a SessionID -> a Map of (InputOutputIndex -> [ID, GPUBuffer]) mapping.\n   */\n  sessionExternalDataMapping: Map<number, Map<number, [number, GPUBuffer]>> = new Map();\n\n  async initialize(env: Env, adapter: GPUAdapter): Promise<void> {\n    this.env = env;\n    const requiredFeatures: GPUFeatureName[] = [];\n    const deviceDescriptor: GPUDeviceDescriptor = {\n      requiredLimits: {\n        maxComputeWorkgroupStorageSize: adapter.limits.maxComputeWorkgroupStorageSize,\n        maxComputeWorkgroupsPerDimension: adapter.limits.maxComputeWorkgroupsPerDimension,\n        maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,\n        maxBufferSize: adapter.limits.maxBufferSize,\n        maxComputeInvocationsPerWorkgroup: adapter.limits.maxComputeInvocationsPerWorkgroup,\n        maxComputeWorkgroupSizeX: adapter.limits.maxComputeWorkgroupSizeX,\n        maxComputeWorkgroupSizeY: adapter.limits.maxComputeWorkgroupSizeY,\n        maxComputeWorkgroupSizeZ: adapter.limits.maxComputeWorkgroupSizeZ,\n      },\n      requiredFeatures,\n    };\n\n    if (adapter.features.has('timestamp-query')) {\n      requiredFeatures.push('timestamp-query');\n    }\n    if (adapter.features.has('shader-f16')) {\n      requiredFeatures.push('shader-f16');\n    }\n\n    this.device = await adapter.requestDevice(deviceDescriptor);\n    this.gpuDataManager = createGpuDataManager(this);\n    this.programManager = new ProgramManager(this);\n    this.kernels = new Map();\n    this.kernelPersistentData = new Map();\n    this.kernelCustomData = new Map();\n\n    // set up flags for logger\n    configureLogger(env.logLevel!, !!env.debug);\n\n    // TODO: set up flags\n\n    this.device.onuncapturederror = ev => {\n      if (ev.error instanceof GPUValidationError) {\n        // eslint-disable-next-line no-console\n        console.error(`An uncaught WebGPU validation error was raised: ${ev.error.message}`);\n      }\n    };\n\n    Object.defineProperty(this.env.webgpu, 'device', {value: this.device});\n  }\n\n  dispose(): void {\n    if (typeof this.querySet !== 'undefined') {\n      this.querySet.destroy();\n    }\n    this.gpuDataManager.dispose();\n  }\n\n  getCommandEncoder(): GPUCommandEncoder {\n    if (!this.commandEncoder) {\n      this.commandEncoder = this.device.createCommandEncoder();\n    }\n    return this.commandEncoder;\n  }\n\n  getComputePassEncoder(): GPUComputePassEncoder {\n    if (!this.computePassEncoder) {\n      const computePassDescriptor: GPUComputePassDescriptor = {};\n      if (this.isQueryEnabled()) {\n        if (typeof this.querySet === 'undefined') {\n          this.querySet = this.device.createQuerySet({\n            type: 'timestamp',\n            count: this.querySetCount,\n          });\n        }\n        computePassDescriptor.timestampWrites = {\n          querySet: this.querySet,\n          beginningOfPassWriteIndex: 0,\n          endOfPassWriteIndex: 1,\n        };\n      }\n\n      this.computePassEncoder = this.getCommandEncoder().beginComputePass(computePassDescriptor);\n    }\n    return this.computePassEncoder;\n  }\n\n  endComputePass(): void {\n    if (this.computePassEncoder) {\n      this.computePassEncoder.end();\n      this.computePassEncoder = null;\n    }\n  }\n\n  flush(): void {\n    if (this.commandEncoder) {\n      this.endComputePass();\n      this.device.queue.submit([this.getCommandEncoder().finish()]);\n      this.gpuDataManager.refreshPendingBuffers();\n      this.commandEncoder = null;\n      this.pendingDispatchNumber = 0;\n    }\n  }\n\n  isQueryEnabled(): boolean {\n    return this.device.features.has('timestamp-query') &&\n        (this.env.webgpu.profiling?.mode === 'default' ||\n         (!this.env.webgpu.profiling?.mode && this.env.webgpu.profilingMode === 'default'));\n  }\n\n  /**\n   * run a WebGPU program.\n   * @param program a ProgramInfo instance\n   * @param inputTensorViews a TensorView array. each element represents a value already exists in GPU.\n   * @param outputIndices an indices array. each element can be either -1 (temporary data), -2 (persistent data) or an\n   * index to the kernel's output.\n   * @param createKernelOutput a callback function that create a value to kernel's output with the given index\n   * @param createIntermediateOutput a callback function that create a value as a intermediate value, either temporary\n   * or persistent (owned by the current kernel)\n   * @returns a TensorView array representing the result.\n   */\n  run(program: ProgramInfo, inputTensorViews: readonly TensorView[], outputIndices: readonly number[],\n      createKernelOutput: (index: number, dataType: number, dims: readonly number[]) => TensorView,\n      createIntermediateOutput: (dataType: number, dims: readonly number[]) => TensorView): TensorView[] {\n    TRACE_FUNC_BEGIN(program.name);\n    // create info for inputs\n    const inputDatas: GpuData[] = [];\n    for (let i = 0; i < inputTensorViews.length; ++i) {\n      const gpuData = this.gpuDataManager.get(inputTensorViews[i].data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for input: ${inputTensorViews[i].data}`);\n      }\n      inputDatas[i] = gpuData;\n    }\n\n    const {outputs, dispatchGroup, programUniforms} = program.getRunData(inputTensorViews);\n\n    // check output indices\n    const validatedOutputIndices = outputIndices.length === 0 ? outputs.map((_, i) => i) : outputIndices;\n    if (validatedOutputIndices.length !== outputs.length) {\n      throw new Error(`Output size ${validatedOutputIndices.length} must be equal to ${outputs.length}.`);\n    }\n\n    // create info for outputs\n    const outputTensorViews: TensorView[] = [];\n    const outputDatas: GpuData[] = [];\n    for (let i = 0; i < outputs.length; ++i) {\n      // value -1 and -2 are used for creating temporary and persistent outputs.\n      // value -3 is used for placeholder output. So -3, -2, -1 and 0, 1, 2, ... are valid\n      // output indices. see type definition of ComputeContextInputsOutputsMapping for more details.\n      if (!Number.isInteger(validatedOutputIndices[i]) || validatedOutputIndices[i] < -3 ||\n          validatedOutputIndices[i] >= outputs.length) {\n        throw new Error(`Invalid output index: ${validatedOutputIndices[i]}`);\n      }\n      if (validatedOutputIndices[i] === -3) {\n        continue;\n      }\n      const isTemporary = validatedOutputIndices[i] === -1;\n      const isPersistent = validatedOutputIndices[i] === -2;\n      const tensorView = (isTemporary || isPersistent) ?\n          createIntermediateOutput(outputs[i].dataType, outputs[i].dims) :\n          createKernelOutput(validatedOutputIndices[i], outputs[i].dataType, outputs[i].dims);\n      const gpuData = this.gpuDataManager.get(tensorView.data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for output: ${tensorView.data}`);\n      }\n      if (isTemporary) {\n        this.temporaryData.push(gpuData);\n      }\n      if (isPersistent) {\n        let persistentData = this.kernelPersistentData.get(this.currentKernelId!);\n        if (!persistentData) {\n          persistentData = [];\n          this.kernelPersistentData.set(this.currentKernelId!, persistentData);\n        }\n        persistentData.push(gpuData);\n      }\n      outputTensorViews.push(tensorView);\n      outputDatas.push(gpuData);\n    }\n\n\n    // load uniforms\n    // TODO: add cache for uniform (is it necessary?)\n    //\n    let uniformBufferBinding: GPUBindingResource|undefined;\n    if (programUniforms) {\n      let currentOffset = 0;\n      const offsets: number[] = [];\n\n      programUniforms.forEach(v => {\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (data.length === 0) {\n          return;\n        }\n        // https://www.w3.org/TR/WGSL/#alignof\n        const baseAlignment = data.length <= 2 ? data.length * 4 : 16;\n        currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n        offsets.push(currentOffset);\n        // When data.length > 4, the uniform variable is of type array<vec4<i32|u32|f32>,N>, where N =\n        // Math.ceil(data.length / 4) and SizeOf(vec4<i32|u32|f32>) = 16. The total byte length is N *\n        // SizeOf(vec4<i32|u32|f32>).\n        currentOffset += data.length > 4 ? Math.ceil(data.length / 4) * 16 : data.length * 4;\n      });\n\n      // Meet alignment of struct here: https://www.w3.org/TR/WGSL/#alignment-and-size. For simplicity, set\n      // maxAlignmentOfField to 16 since the underlying buffer has been rounded up to 16.\n      const maxAlignmentOfField = 16;\n      currentOffset = Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;\n      const arrayBuffer = new ArrayBuffer(currentOffset);\n      programUniforms.forEach((v, i) => {\n        const offset = offsets[i];\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (v.type === 'int32') {\n          new Int32Array(arrayBuffer, offset, data.length).set(data);\n        } else if (v.type === 'uint32') {\n          new Uint32Array(arrayBuffer, offset, data.length).set(data);\n        } else {\n          new Float32Array(arrayBuffer, offset, data.length).set(data);\n        }\n      });\n\n      const uniformBufferData =\n          // eslint-disable-next-line no-bitwise\n          this.gpuDataManager.create(currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n      this.device.queue.writeBuffer(uniformBufferData.buffer, 0, arrayBuffer, 0, currentOffset);\n      this.gpuDataManager.release(uniformBufferData.id);\n      uniformBufferBinding = {offset: 0, size: currentOffset, buffer: uniformBufferData.buffer};\n    }\n\n    const normalizedDispatchGroup = this.programManager.normalizeDispatchGroupSize(dispatchGroup);\n    const is1DimensionDispatch = normalizedDispatchGroup[1] === 1 && normalizedDispatchGroup[2] === 1;\n    // get program info\n    const key = getProgramInfoUniqueKey(program, inputTensorViews, is1DimensionDispatch);\n    let artifact = this.programManager.getArtifact(key);\n    if (!artifact) {\n      artifact = this.programManager.build(program, normalizedDispatchGroup);\n      this.programManager.setArtifact(key, artifact);\n      LOG_DEBUG('info', () => `[artifact] key: ${key}, programName: ${program.name}`);\n    }\n\n    LOG_DEBUG(\n        'info',\n        () => `[ProgramManager] run \"${program.name}\" (key=${key}) with ${normalizedDispatchGroup[0]}x${\n            normalizedDispatchGroup[1]}x${normalizedDispatchGroup[2]}`);\n    this.programManager.run(\n        artifact, inputTensorViews, outputTensorViews, inputDatas, outputDatas, normalizedDispatchGroup,\n        uniformBufferBinding);\n\n    TRACE_FUNC_END(program.name);\n    return outputTensorViews;\n  }\n\n  upload(gpuDataId: number, data: Uint8Array): void {\n    this.gpuDataManager.upload(gpuDataId, data);\n  }\n\n  memcpy(src: number, dst: number): void {\n    this.gpuDataManager.memcpy(src, dst);\n  }\n\n  async download(gpuDataId: number, getTargetBuffer: () => Uint8Array): Promise<void> {\n    // the underlying buffer may be changed after the async function is called. so we use a getter function to make sure\n    // the buffer is up-to-date.\n    await this.gpuDataManager.download(gpuDataId, getTargetBuffer);\n  }\n\n  alloc(size: number): number {\n    return this.gpuDataManager.create(size).id;\n  }\n\n  free(ptr: number): number {\n    return this.gpuDataManager.release(ptr);\n  }\n\n  createKernel(opType: string, kernelId: number, attribute: unknown, nodeName: string): void {\n    const op = WEBGPU_OP_RESOLVE_RULES.get(opType);\n    if (!op) {\n      throw new Error(`kernel not implemented: ${opType}`);\n    }\n\n    this.kernels.set(kernelId, [opType, nodeName, op[0], [op[1], attribute]]);\n  }\n\n  releaseKernel(kernelId: number): void {\n    const persistentData = this.kernelPersistentData.get(kernelId);\n    if (persistentData) {\n      for (const data of persistentData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.kernelPersistentData.delete(kernelId);\n    }\n\n    this.kernelCustomData.delete(kernelId);\n    this.kernels.delete(kernelId);\n  }\n\n  computeKernel(kernelId: number, context: ComputeContext, errors: Array<Promise<string|null>>): number {\n    const kernel = this.kernels.get(kernelId);\n    if (!kernel) {\n      throw new Error(`kernel not created: ${kernelId}`);\n    }\n    const [opType, nodeName, kernelEntry, attributes] = kernel;\n    if (this.currentKernelId !== null) {\n      throw new Error(`kernel \"[${opType}] ${nodeName}\" is not allowed to be called recursively`);\n    }\n    this.currentKernelId = kernelId;\n\n    // parse attributes if necessary\n    if (attributes[0]) {\n      attributes[1] = attributes[0](attributes[1]);\n      attributes[0] = undefined;\n    }\n\n    LOG_DEBUG('info', () => `[WebGPU] Start to run kernel \"[${opType}] ${nodeName}\"...`);\n\n    const useErrorScope = this.env.debug;\n\n    this.temporaryData = [];\n    try {\n      if (useErrorScope) {\n        this.device.pushErrorScope('validation');\n      }\n\n      kernelEntry(context, attributes[1]);\n      return 0;  // ORT_OK\n    } catch (e) {\n      errors.push(Promise.resolve(`[WebGPU] Kernel \"[${opType}] ${nodeName}\" failed. ${e}`));\n      return 1;  // ORT_FAIL\n    } finally {\n      if (useErrorScope) {\n        errors.push(this.device.popErrorScope().then(\n            err => err ? `GPU validation error for kernel \"[${opType}] ${nodeName}\": ${err.message}` : null));\n      }\n\n      for (const data of this.temporaryData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.temporaryData = [];\n      this.currentKernelId = null;\n    }\n  }\n\n  // #region external buffer\n  registerBuffer(sessionId: number, index: number, buffer: GPUBuffer, size: number): number {\n    let sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (!sessionInputOutputMapping) {\n      sessionInputOutputMapping = new Map();\n      this.sessionExternalDataMapping.set(sessionId, sessionInputOutputMapping);\n    }\n\n    const previousBuffer = sessionInputOutputMapping.get(index);\n    const id = this.gpuDataManager.registerExternalBuffer(buffer, size, previousBuffer?.[1]);\n    sessionInputOutputMapping.set(index, [id, buffer]);\n    return id;\n  }\n  unregisterBuffers(sessionId: number): void {\n    const sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (sessionInputOutputMapping) {\n      sessionInputOutputMapping.forEach(bufferInfo => this.gpuDataManager.unregisterExternalBuffer(bufferInfo[1]));\n      this.sessionExternalDataMapping.delete(sessionId);\n    }\n  }\n  getBuffer(gpuDataId: number): GPUBuffer {\n    const gpuData = this.gpuDataManager.get(gpuDataId);\n    if (!gpuData) {\n      throw new Error(`no GPU data for buffer: ${gpuDataId}`);\n    }\n    return gpuData.buffer;\n  }\n  createDownloader(gpuBuffer: GPUBuffer, size: number, type: Tensor.GpuBufferDataTypes):\n      () => Promise<Tensor.DataType> {\n    return async () => {\n      const data = await downloadGpuData(this, gpuBuffer, size);\n      return createView(data.buffer, type);\n    };\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from '../binding/ort-wasm';\nimport {DataType, getTensorElementSize} from '../wasm-common';\n\nimport {WebGpuBackend} from './backend-webgpu';\nimport {LOG_DEBUG} from './log';\nimport {TensorView} from './tensor-view';\nimport {ShapeUtil} from './util';\nimport {ComputeContext, ComputeContextInputsOutputsMapping, ProgramInfo} from './webgpu/types';\n\n/* eslint-disable no-bitwise */\n\nclass TensorViewImpl implements TensorView {\n  constructor(\n      private module: OrtWasmModule, public readonly dataType: number, public readonly data: number,\n      public readonly dims: readonly number[]) {}\n\n  getFloat32Array(): Float32Array {\n    if (this.dataType !== DataType.float) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Float32Array() :\n                                new Float32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getBigInt64Array(): BigInt64Array {\n    if (this.dataType !== DataType.int64) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new BigInt64Array() :\n                                new BigInt64Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getInt32Array(): Int32Array {\n    if (this.dataType !== DataType.int32) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Int32Array() : new Int32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  reshape(newDims: readonly number[]): TensorView {\n    if (ShapeUtil.size(newDims) !== ShapeUtil.size(this.dims)) {\n      throw new Error('Invalid new shape');\n    }\n    return new TensorViewImpl(this.module, this.dataType, this.data, newDims);\n  }\n}\n\nclass ComputeContextImpl implements ComputeContext {\n  readonly opKernelContext: number;\n  readonly inputs: readonly TensorView[];\n  readonly outputCount: number;\n  get kernelCustomData(): {[key: string]: unknown} {\n    return this.backend.currentKernelCustomData;\n  }\n  get customDataBuffer(): Uint8Array {\n    return this.module.HEAPU8.subarray(this.customDataOffset, this.customDataOffset + this.customDataSize);\n  }\n  private customDataOffset = 0;\n  private customDataSize = 0;\n  constructor(private module: OrtWasmModule, private backend: WebGpuBackend, contextDataOffset: number) {\n    const heapU32 = module.HEAPU32;\n\n    // extract context data\n    let dataIndex = (contextDataOffset >>> 2);\n    this.opKernelContext = heapU32[dataIndex++];\n    const inputCount = heapU32[dataIndex++];\n    this.outputCount = heapU32[dataIndex++];\n    this.customDataOffset = heapU32[dataIndex++];\n    this.customDataSize = heapU32[dataIndex++];\n\n    const inputs: TensorView[] = [];\n    for (let i = 0; i < inputCount; i++) {\n      const dataType = heapU32[dataIndex++];\n      const data = heapU32[dataIndex++];\n      const dim = heapU32[dataIndex++];\n      const dims: number[] = [];\n      for (let d = 0; d < dim; d++) {\n        dims.push(heapU32[dataIndex++]);\n      }\n      inputs.push(new TensorViewImpl(module, dataType, data, dims));\n    }\n    this.inputs = inputs;\n  }\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[] {\n    // prepare inputs. inputs should always be valid data.\n    const mappedInputs =\n        inputsOutputsMapping?.inputs?.map(i => typeof i === 'number' ? this.inputs[i] : i) ?? this.inputs;\n    // prepare outputs.\n    const outputIndices = inputsOutputsMapping?.outputs ?? [];\n    const createKernelOutput = (index: number, dataType: number, dims: readonly number[]): TensorView =>\n        new TensorViewImpl(this.module, dataType, this.output(index, dims), dims);\n    const createTemporaryOutput = (dataType: number, dims: readonly number[]): TensorView => {\n      const elementSize = getTensorElementSize(dataType);\n      if (!elementSize) {\n        throw new Error(`Unsupported data type: ${dataType}`);\n      }\n      const bufferSize = elementSize * ShapeUtil.size(dims);\n      return new TensorViewImpl(this.module, dataType, this.backend.gpuDataManager.create(bufferSize).id, dims);\n    };\n    return this.backend.run(program, mappedInputs, outputIndices, createKernelOutput, createTemporaryOutput);\n  }\n\n  output(index: number, dims: readonly number[]): number {\n    const stack = this.module.stackSave();\n    try {\n      const data = this.module.stackAlloc((1 + dims.length) * 4 /* sizeof(size_t) */);\n      let offset = data >> 2;\n      this.module.HEAPU32[offset++] = dims.length;\n      for (let i = 0; i < dims.length; i++) {\n        this.module.HEAPU32[offset++] = dims[i];\n      }\n      return this.module._JsepOutput(this.opKernelContext, index, data);\n    } catch (e) {\n      throw new Error(\n          `Failed to generate kernel's output[${index}] with dims [${dims}]. ` +\n          'If you are running with pre-allocated output, please make sure the output type/dims are correct. ' +\n          `Error: ${e}`);\n    } finally {\n      this.module.stackRestore(stack);\n    }\n  }\n}\n\n/**\n * Initialize JSEP with WebGPU backend.\n *\n * This function will be called only once after the WebAssembly module is loaded and initialized (\"_OrtInit\" is called).\n * This function expects:\n *  - WebGPU is enabled in build (BUILD_DEFS.DISABLE_WEBGPU === false).\n *  - WebGPU is available in current environment. (a valid GPUAdapter is passed in)\n * If the WebAssembly module is not built with JSEP support, this function will throw an error. This will invalidate\n * 'webgpu' backend.\n *\n * @param module - the ORT WebAssembly module\n * @param env - the ORT environment variable (ort.env)\n * @param gpuAdapter - the pre-created GPU adapter\n */\nexport const init = async(module: OrtWasmModule, env: Env, gpuAdapter: GPUAdapter): Promise<void> => {\n  const jsepInit = module.jsepInit;\n  if (!jsepInit) {\n    throw new Error('Failed to initialize JSEP. The WebAssembly module is not built with JSEP support.');\n  }\n\n  const backend = new WebGpuBackend();\n  await backend.initialize(env, gpuAdapter);\n\n  jsepInit(\n      // backend\n      backend,\n\n      // jsepAlloc()\n      (size: number) => backend.alloc(size),\n\n      // jsepFree()\n      (ptr: number) => backend.free(ptr),\n\n      // jsepCopy(src, dst, size, isSourceGpu)\n      (src: number, dst: number, size: number, isSourceGpu = false) => {\n        if (isSourceGpu) {\n          LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyGpuToGpu: src=${src}, dst=${dst}, size=${size}`);\n          backend.memcpy(src, dst);\n        } else {\n          LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyCpuToGpu: dataOffset=${src}, gpuDataId=${dst}, size=${size}`);\n          const data = module.HEAPU8.subarray(src, src + size);\n          backend.upload(dst, data);\n        }\n      },\n\n      // jsepCopyAsync(src, dst, size)\n      async(gpuDataId: number, dataOffset: number, size: number):\n          Promise<void> => {\n            LOG_DEBUG(\n                'verbose',\n                () => `[WebGPU] jsepCopyGpuToCpu: gpuDataId=${gpuDataId}, dataOffset=${dataOffset}, size=${size}`);\n\n            await backend.download(gpuDataId, () => module.HEAPU8.subarray(dataOffset, dataOffset + size));\n          },\n\n      // jsepCreateKernel\n      (name: string, kernel: number, attribute: unknown) => backend.createKernel(\n          name, kernel, attribute,\n          env.debug || backend.isQueryEnabled() ? module.UTF8ToString(module._JsepGetNodeName(kernel)) : `${kernel}`),\n\n      // jsepReleaseKernel\n      (kernel: number) => backend.releaseKernel(kernel),\n\n      // jsepRun\n      (kernel: number, contextDataOffset: number, sessionHandle: number, errors: Array<Promise<string|null>>) => {\n        LOG_DEBUG(\n            'verbose',\n            () => `[WebGPU] jsepRun: sessionHandle=${sessionHandle}, kernel=${kernel}, contextDataOffset=${\n                contextDataOffset}`);\n        const context = new ComputeContextImpl(module, backend, contextDataOffset);\n        return backend.computeKernel(kernel, context, errors);\n      });\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, InferenceSession, Tensor} from 'onnxruntime-common';\n\nimport {SerializableInternalBuffer, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport {setRunOptions} from './run-options';\nimport {setSessionOptions} from './session-options';\nimport {dataLocationStringToEnum, getTensorElementSize, isGpuBufferSupportedType, logLevelStringToEnum, tensorDataTypeEnumToString, tensorDataTypeStringToEnum, tensorTypeToTypedArrayConstructor} from './wasm-common';\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError} from './wasm-utils';\n\n// #region Initializations\n\n/**\n * There are 4 different \"initialization\" steps for ORT. They happen in different places and different time.\n *\n * 1. JavaScript initialization for onnxruntime-common and onnxruntime-web.\n *    This is the first initialization step. In this step, onnxruntime-web calls onnxruntime-common's registerBackend()\n * function multiple times to register all the available backends. The backend registration is very fast. It only\n * registers the backend name with the uninitialized backend object. No heavy initialization is done in this step.\n *    Refer to web/lib/index.ts for the backend registration.\n *\n * 2. WebAssembly artifact initialization.\n *    This happens when any registered wasm backend is used for the first time (ie. `ort.InferenceSession.create()` or\n * `ort.TrainingSession.create()` is called). In this step, onnxruntime-web does the followings:\n *     - create a proxy worker and make sure the proxy worker is ready to receive messages, if proxy is enabled.\n *     - perform feature detection, locate correct WebAssembly artifact path and call the Emscripten generated\n * JavaScript code to initialize the WebAssembly runtime.\n *         - if proxy is enabled, this step happens in the proxy worker using message 'init-wasm'.\n *         - downloading the 'ort-wasm{...}.wasm' file is done in this step.\n *         - if multi-thread is enabled, one or more webworker will be created to initialize the PThread threadpool.\n *\n * 3. ORT environment initialization.\n *    This happens after step 2. In this step, onnxruntime-web performs ONNX Runtime environment initialization.\n * Function `_OrtInit()` is called in this step.\n *     - if proxy is enabled, this step happens in the proxy worker using message 'init-ort'.\n *     - logging level (ort.env.logLevel) and thread number (ort.env.wasm.numThreads) are set in this step.\n *\n * 4. Session initialization.\n *    This happens when `ort.InferenceSession.create()` or `ort.TrainingSession.create()` is called. Unlike the first 3\n * steps (they only called once), this step will be done for each session. In this step, onnxruntime-web does the\n * followings:\n *    If the parameter is a URL:\n *    - download the model data from the URL.\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\n *    - dereference the model buffer. This step allows the original ArrayBuffer to be garbage collected.\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\n *\n *    If the parameter is a Uint8Array object:\n *    - copy the model data to the WASM heap. (proxy: 'copy-from')\n *    - call `_OrtCreateSession()` to create the session. (proxy: 'create')\n *\n *\n */\n\n/**\n * initialize ORT environment.\n *\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\n */\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\n  if (errorCode !== 0) {\n    checkLastError('Can\\'t initialize onnxruntime.');\n  }\n};\n\n/**\n * intialize runtime environment.\n * @param env passed in the environment config object.\n */\nexport const initRuntime = async(env: Env): Promise<void> => {\n  // init ORT\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\n};\n\n/**\n * perform EP specific initialization.\n *\n * @param env\n * @param epName\n */\nexport const initEp = async(env: Env, epName: string): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WEBGPU && epName === 'webgpu') {\n    // perform WebGPU availability check\n    if (typeof navigator === 'undefined' || !navigator.gpu) {\n      throw new Error('WebGPU is not supported in current environment');\n    }\n    const adapter = await navigator.gpu.requestAdapter();\n    if (!adapter) {\n      throw new Error(\n          'Failed to get GPU adapter. You may need to enable flag \"--enable-unsafe-webgpu\" if you are using Chrome.');\n    }\n\n    if (!env.wasm.simd) {\n      throw new Error(\n          'Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using `webgpu` EP');\n    }\n\n    // init JSEP if available\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n    const initJsep = require('./jsep/init').init;\n    await initJsep(getInstance(), env, adapter);\n  }\n};\n\n// #endregion Initializations\n\n/**\n * valid data locations for input/output tensors.\n */\ntype SupportedTensorDataLocationForInputOutput = 'cpu'|'cpu-pinned'|'gpu-buffer';\n\ntype IOBindingState = {\n  /**\n   * the handle of IO binding.\n   */\n  readonly handle: number;\n\n  /**\n   * the preferred location for each output tensor.\n   *\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer'.\n   */\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\n\n  /**\n   * enum value of the preferred location for each output tensor.\n   */\n  readonly outputPreferredLocationsEncoded: readonly number[];\n};\n\n/**\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\n */\ntype SessionMetadata = [\n  inferenceSessionId: number, inputNamesUTF8Encoded: number[], outputNamesUTF8Encoded: number[],\n  bindingState: IOBindingState|null\n];\n\nconst activeSessions = new Map<number, SessionMetadata>();\n\n/**\n * get the input/output count of the session.\n * @param sessionHandle the handle representing the session. should be non-zero.\n * @returns a tuple including 2 numbers, representing the input count and output count.\n */\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\n  const wasm = getInstance();\n  const stack = wasm.stackSave();\n  try {\n    const dataOffset = wasm.stackAlloc(8);\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + 4);\n    if (errorCode !== 0) {\n      checkLastError('Can\\'t get session input/output count.');\n    }\n    return [wasm.HEAP32[dataOffset / 4], wasm.HEAP32[dataOffset / 4 + 1]];\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\n/**\n * allocate the memory and memcpy the external buffer.\n *\n * @param model - the external buffer containing the model data. Must not be the same buffer as the WASM heap.\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\n */\nexport const copyFromExternalBuffer = (model: Uint8Array): [number, number] => {\n  const wasm = getInstance();\n  const modelDataOffset = wasm._malloc(model.byteLength);\n  if (modelDataOffset === 0) {\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\n  }\n  wasm.HEAPU8.set(model, modelDataOffset);\n  return [modelDataOffset, model.byteLength];\n};\n\n/**\n * create an inference session from a model data buffer.\n *\n * @param modelData - either a Uint8Array object representing the model data, or a 2-elements tuple containing the\n *     pointer and size of the model data buffer.\n * @param options an optional session options object.\n * @returns a 3-elements tuple containing [session handle, input names, output names]\n */\nexport const createSession =\n    (modelData: Uint8Array|SerializableInternalBuffer,\n     options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      let modelDataOffset: number, modelDataLength: number;\n      const wasm = getInstance();\n\n      if (Array.isArray(modelData)) {\n        // if model data is an array, it must be a 2-elements tuple containing the pointer and size of the model data\n        [modelDataOffset, modelDataLength] = modelData;\n      } else if (modelData.buffer === wasm.HEAPU8.buffer) {\n        // if model data uses the same buffer as the WASM heap, we don't need to copy it.\n        [modelDataOffset, modelDataLength] = [modelData.byteOffset, modelData.byteLength];\n      } else {\n        // otherwise, copy the model data to the WASM heap.\n        [modelDataOffset, modelDataLength] = copyFromExternalBuffer(modelData);\n      }\n\n      let sessionHandle = 0;\n      let sessionOptionsHandle = 0;\n      let ioBindingHandle = 0;\n      let allocs: number[] = [];\n      const inputNamesUTF8Encoded = [];\n      const outputNamesUTF8Encoded = [];\n\n      try {\n        [sessionOptionsHandle, allocs] = setSessionOptions(options);\n\n        sessionHandle = wasm._OrtCreateSession(modelDataOffset, modelDataLength, sessionOptionsHandle);\n        if (sessionHandle === 0) {\n          checkLastError('Can\\'t create a session.');\n        }\n\n        const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\n\n        const inputNames = [];\n        const outputNames = [];\n        const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\n        for (let i = 0; i < inputCount; i++) {\n          const name = wasm._OrtGetInputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an input name.');\n          }\n          inputNamesUTF8Encoded.push(name);\n          inputNames.push(wasm.UTF8ToString(name));\n        }\n        for (let i = 0; i < outputCount; i++) {\n          const name = wasm._OrtGetOutputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an output name.');\n          }\n          outputNamesUTF8Encoded.push(name);\n          const nameString = wasm.UTF8ToString(name);\n          outputNames.push(nameString);\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            const location = typeof options?.preferredOutputLocation === 'string' ?\n                options.preferredOutputLocation :\n                options?.preferredOutputLocation?.[nameString] ?? 'cpu';\n            if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer') {\n              throw new Error(`Not supported preferred output location: ${location}.`);\n            }\n            outputPreferredLocations.push(location);\n          }\n        }\n\n        // use IO binding only when at least one output is preffered to be on GPU.\n        let bindingState: IOBindingState|null = null;\n        if (!BUILD_DEFS.DISABLE_WEBGPU && outputPreferredLocations.some(l => l === 'gpu-buffer')) {\n          ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\n          if (ioBindingHandle === 0) {\n            checkLastError('Can\\'t create IO binding.');\n          }\n\n          bindingState = {\n            handle: ioBindingHandle,\n            outputPreferredLocations,\n            outputPreferredLocationsEncoded: outputPreferredLocations.map(l => dataLocationStringToEnum(l)),\n          };\n        }\n\n        activeSessions.set(sessionHandle, [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, bindingState]);\n        return [sessionHandle, inputNames, outputNames];\n      } catch (e) {\n        inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n        outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n\n        if (ioBindingHandle !== 0) {\n          wasm._OrtReleaseBinding(ioBindingHandle);\n        }\n\n        if (sessionHandle !== 0) {\n          wasm._OrtReleaseSession(sessionHandle);\n        }\n        throw e;\n      } finally {\n        wasm._free(modelDataOffset);\n        if (sessionOptionsHandle !== 0) {\n          wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n        }\n        allocs.forEach(alloc => wasm._free(alloc));\n      }\n    };\n\nexport const releaseSession = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  if (ioBindingState) {\n    wasm._OrtReleaseBinding(ioBindingState.handle);\n  }\n\n  wasm.jsepUnregisterBuffers?.(sessionId);\n\n  inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  wasm._OrtReleaseSession(sessionHandle);\n  activeSessions.delete(sessionId);\n};\n\nexport const prepareInputOutputTensor =\n    (tensor: TensorMetadata|null, tensorHandles: number[], allocs: number[], sessionId: number, index: number):\n        void => {\n          if (!tensor) {\n            tensorHandles.push(0);\n            return;\n          }\n\n          const wasm = getInstance();\n\n          const dataType = tensor[0];\n          const dims = tensor[1];\n          const location = tensor[3];\n\n          let rawData: number;\n          let dataByteLength: number;\n\n          if (dataType === 'string' && location === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n\n          if (location === 'gpu-buffer') {\n            const gpuBuffer = tensor[2].gpuBuffer as GPUBuffer;\n            const elementSizeInBytes = getTensorElementSize(tensorDataTypeStringToEnum(dataType))!;\n            dataByteLength = dims.reduce((a, b) => a * b, 1) * elementSizeInBytes;\n            rawData = wasm.jsepRegisterBuffer(sessionId, index, gpuBuffer, dataByteLength);\n          } else {\n            const data = tensor[2];\n\n            if (Array.isArray(data)) {\n              // string tensor\n              dataByteLength = 4 * data.length;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              let dataIndex = rawData / 4;\n              for (let i = 0; i < data.length; i++) {\n                if (typeof data[i] !== 'string') {\n                  throw new TypeError(`tensor data at index ${i} is not a string`);\n                }\n                wasm.HEAPU32[dataIndex++] = allocWasmString(data[i], allocs);\n              }\n            } else {\n              dataByteLength = data.byteLength;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n            }\n          }\n\n          const stack = wasm.stackSave();\n          const dimsOffset = wasm.stackAlloc(4 * dims.length);\n          try {\n            let dimIndex = dimsOffset / 4;\n            dims.forEach(d => wasm.HEAP32[dimIndex++] = d);\n            const tensor = wasm._OrtCreateTensor(\n                tensorDataTypeStringToEnum(dataType), rawData, dataByteLength, dimsOffset, dims.length,\n                dataLocationStringToEnum(location));\n            if (tensor === 0) {\n              checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\n            }\n            tensorHandles.push(tensor);\n          } finally {\n            wasm.stackRestore(stack);\n          }\n        };\n\n/**\n * perform inference run\n */\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputTensors: TensorMetadata[], outputIndices: number[],\n    outputTensors: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  const inputCount = inputIndices.length;\n  const outputCount = outputIndices.length;\n\n  let runOptionsHandle = 0;\n  let runOptionsAllocs: number[] = [];\n\n  const inputTensorHandles: number[] = [];\n  const outputTensorHandles: number[] = [];\n  const inputOutputAllocs: number[] = [];\n\n  const beforeRunStack = wasm.stackSave();\n  const inputValuesOffset = wasm.stackAlloc(inputCount * 4);\n  const inputNamesOffset = wasm.stackAlloc(inputCount * 4);\n  const outputValuesOffset = wasm.stackAlloc(outputCount * 4);\n  const outputNamesOffset = wasm.stackAlloc(outputCount * 4);\n\n  try {\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\n\n    // create input tensors\n    for (let i = 0; i < inputCount; i++) {\n      prepareInputOutputTensor(inputTensors[i], inputTensorHandles, inputOutputAllocs, sessionId, inputIndices[i]);\n    }\n\n    // create output tensors\n    for (let i = 0; i < outputCount; i++) {\n      prepareInputOutputTensor(\n          outputTensors[i], outputTensorHandles, inputOutputAllocs, sessionId, inputCount + outputIndices[i]);\n    }\n\n    let inputValuesIndex = inputValuesOffset / 4;\n    let inputNamesIndex = inputNamesOffset / 4;\n    let outputValuesIndex = outputValuesOffset / 4;\n    let outputNamesIndex = outputNamesOffset / 4;\n    for (let i = 0; i < inputCount; i++) {\n      wasm.HEAPU32[inputValuesIndex++] = inputTensorHandles[i];\n      wasm.HEAPU32[inputNamesIndex++] = inputNamesUTF8Encoded[inputIndices[i]];\n    }\n    for (let i = 0; i < outputCount; i++) {\n      wasm.HEAPU32[outputValuesIndex++] = outputTensorHandles[i];\n      wasm.HEAPU32[outputNamesIndex++] = outputNamesUTF8Encoded[outputIndices[i]];\n    }\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      const {handle, outputPreferredLocations, outputPreferredLocationsEncoded} = ioBindingState;\n\n      if (inputNamesUTF8Encoded.length !== inputCount) {\n        throw new Error(`input count from feeds (${\n            inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`);\n      }\n\n      // process inputs\n      for (let i = 0; i < inputCount; i++) {\n        const index = inputIndices[i];\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\n        if (errorCode !== 0) {\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\n        }\n      }\n\n      // process pre-allocated outputs\n      for (let i = 0; i < outputCount; i++) {\n        const index = outputIndices[i];\n        const location = outputTensors[i]?.[3];  // undefined means output is not pre-allocated.\n\n        if (location) {\n          // output is pre-allocated. bind the tensor.\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\n          }\n        } else {\n          // output is not pre-allocated. reset preferred location.\n          const errorCode =\n              wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], 0, outputPreferredLocationsEncoded[index]);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\n          }\n        }\n      }\n    }\n\n    let errorCode: number;\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      errorCode = await wasm._OrtRunWithBinding(\n          sessionHandle, ioBindingState.handle, outputCount, outputValuesOffset, runOptionsHandle);\n    } else {\n      errorCode = await wasm._OrtRun(\n          sessionHandle, inputNamesOffset, inputValuesOffset, inputCount, outputNamesOffset, outputCount,\n          outputValuesOffset, runOptionsHandle);\n    }\n\n    if (errorCode !== 0) {\n      checkLastError('failed to call OrtRun().');\n    }\n\n    const output: TensorMetadata[] = [];\n\n    for (let i = 0; i < outputCount; i++) {\n      const tensor = wasm.HEAPU32[outputValuesOffset / 4 + i];\n      if (tensor === outputTensorHandles[i]) {\n        // output tensor is pre-allocated. no need to copy data.\n        output.push(outputTensors[i]!);\n        continue;\n      }\n\n      const beforeGetTensorDataStack = wasm.stackSave();\n      // stack allocate 4 pointer value\n      const tensorDataOffset = wasm.stackAlloc(4 * 4);\n\n      let keepOutputTensor = false;\n      let type: Tensor.Type|undefined, dataOffset = 0;\n      try {\n        const errorCode = wasm._OrtGetTensorData(\n            tensor, tensorDataOffset, tensorDataOffset + 4, tensorDataOffset + 8, tensorDataOffset + 12);\n        if (errorCode !== 0) {\n          checkLastError(`Can't access output tensor data on index ${i}.`);\n        }\n        let tensorDataIndex = tensorDataOffset / 4;\n        const dataType = wasm.HEAPU32[tensorDataIndex++];\n        dataOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsLength = wasm.HEAPU32[tensorDataIndex++];\n        const dims = [];\n        for (let i = 0; i < dimsLength; i++) {\n          dims.push(wasm.HEAPU32[dimsOffset / 4 + i]);\n        }\n        wasm._OrtFree(dimsOffset);\n\n        const size = dims.reduce((a, b) => a * b, 1);\n        type = tensorDataTypeEnumToString(dataType);\n\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\n\n        if (type === 'string') {\n          if (preferredLocation === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n          const stringData: string[] = [];\n          let dataIndex = dataOffset / 4;\n          for (let i = 0; i < size; i++) {\n            const offset = wasm.HEAPU32[dataIndex++];\n            const maxBytesToRead = i === size - 1 ? undefined : wasm.HEAPU32[dataIndex] - offset;\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\n          }\n          output.push([type, dims, stringData, 'cpu']);\n        } else {\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\n            const gpuBuffer = wasm.jsepGetBuffer(dataOffset);\n            const elementSize = getTensorElementSize(dataType);\n            if (elementSize === undefined || !isGpuBufferSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            output.push([\n              type, dims, {\n                gpuBuffer,\n                download: wasm.jsepCreateDownloader(gpuBuffer, size * elementSize, type),\n                dispose: () => {\n                  wasm._OrtReleaseTensor(tensor);\n                }\n              },\n              'gpu-buffer'\n            ]);\n          } else {\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\n            const data = new typedArrayConstructor(size);\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength)\n                .set(wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength));\n            output.push([type, dims, data, 'cpu']);\n          }\n        }\n      } finally {\n        wasm.stackRestore(beforeGetTensorDataStack);\n        if (type === 'string' && dataOffset) {\n          wasm._free(dataOffset);\n        }\n        if (!keepOutputTensor) {\n          wasm._OrtReleaseTensor(tensor);\n        }\n      }\n    }\n\n    if (ioBindingState) {\n      wasm._OrtClearBoundOutputs(ioBindingState.handle);\n    }\n\n    return output;\n  } finally {\n    wasm.stackRestore(beforeRunStack);\n\n    inputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    outputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    inputOutputAllocs.forEach(p => wasm._free(p));\n\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    runOptionsAllocs.forEach(p => wasm._free(p));\n  }\n};\n\n/**\n * end profiling\n */\nexport const endProfiling = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error('invalid session id');\n  }\n  const sessionHandle = session[0];\n\n  // profile file name is not used yet, but it must be freed.\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\n  if (profileFileName === 0) {\n    checkLastError('Can\\'t get an profile file name.');\n  }\n  wasm._OrtFree(profileFileName);\n};\n\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\n  const buffers: ArrayBufferLike[] = [];\n  for (const tensor of tensors) {\n    const data = tensor[2];\n    if (!Array.isArray(data) && 'buffer' in data) {\n      buffers.push(data.buffer);\n    }\n  }\n  return buffers;\n};\n", "/*!\n * ONNX Runtime Web v1.17.0\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License.\n */\n\"use strict\";(()=>{var gn=Object.defineProperty;var Wu=Object.getOwnPropertyDescriptor;var Nu=Object.getOwnPropertyNames;var Hu=Object.prototype.hasOwnProperty;var Y=(e,t)=>()=>(e&&(t=e(e=0)),t);var dr=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),Mr=(e,t)=>{for(var r in t)gn(e,r,{get:t[r],enumerable:!0})},Gu=(e,t,r,o)=>{if(t&&typeof t==\"object\"||typeof t==\"function\")for(let n of Nu(t))!Hu.call(e,n)&&n!==r&&gn(e,n,{get:()=>t[n],enumerable:!(o=Wu(t,n))||o.enumerable});return e};var Wt=e=>Gu(gn({},\"__esModule\",{value:!0}),e);var yn={};Mr(yn,{readFile:()=>Lu});var Lu,bn=Y(()=>{Lu=void 0});var wn={};Mr(wn,{join:()=>Fu});var Fu,vn=Y(()=>{Fu=void 0});var xo=dr((So,$n)=>{\"use strict\";var $o=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){var r=t,o,n;r.ready=new Promise((l,m)=>{o=l,n=m}),r.jsepInit=(l,m,v,C,P,F,H,le)=>{r.Za=l,r.Oa=m,r.Qa=v,r.Ja=C,r.Pa=P,r.ra=F,r.Ra=H,r.Sa=le,m=(Q,ae,te)=>(...ye)=>{let xe=et,k=ae?.();ye=Q(...ye);let se=ae?.();return k!==se&&(Q=se,te(k),ae=te=null),et!=xe?Ir():ye},v=Q=>async(...ae)=>{try{if(r.Da)throw Error(\"Session already started\");let te=r.Da={Ta:ae[0],errors:[]},ye=await Q(...ae);if(r.Da!==te)throw Error(\"Session mismatch\");l.flush();let xe=te.errors;if(0<xe.length){let k=await Promise.all(xe);if(k=k.filter(se=>se),0<k.length)throw Error(k.join(`\n`))}return ye}finally{r.Da=null}},r._OrtRun=v(m(r._OrtRun,()=>r._OrtRun,Q=>r._OrtRun=Q)),r._OrtRunWithBinding=v(m(r._OrtRunWithBinding,()=>r._OrtRunWithBinding,Q=>r._OrtRunWithBinding=Q)),r._OrtBindInput=m(r._OrtBindInput,()=>r._OrtBindInput,Q=>r._OrtBindInput=Q),r.jsepRegisterBuffer=(Q,ae,te,ye)=>l.registerBuffer(Q,ae,te,ye),r.jsepUnregisterBuffers=Q=>{l.unregisterBuffers(Q)},r.jsepGetBuffer=Q=>l.getBuffer(Q),r.jsepCreateDownloader=(Q,ae,te)=>l.createDownloader(Q,ae,te)};var s=Object.assign({},r),u=\"./this.program\",d=(l,m)=>{throw m},a=typeof window==\"object\",p=typeof importScripts==\"function\",h=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",g=\"\",y,w,b;if(h){var _=(bn(),Wt(yn)),I=(vn(),Wt(wn));g=p?I.dirname(g)+\"/\":__dirname+\"/\",y=(l,m)=>(l=l.startsWith(\"file://\")?new URL(l):I.normalize(l),_.readFileSync(l,m?void 0:\"utf8\")),b=l=>(l=y(l,!0),l.buffer||(l=new Uint8Array(l)),l),w=(l,m,v,C=!0)=>{l=l.startsWith(\"file://\")?new URL(l):I.normalize(l),_.readFile(l,C?void 0:\"utf8\",(P,F)=>{P?v(P):m(C?F.buffer:F)})},!r.thisProgram&&1<process.argv.length&&(u=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),d=(l,m)=>{throw process.exitCode=l,m},r.inspect=()=>\"[Emscripten Module object]\"}else(a||p)&&(p?g=self.location.href:typeof document<\"u\"&&document.currentScript&&(g=document.currentScript.src),e&&(g=e),g.indexOf(\"blob:\")!==0?g=g.substr(0,g.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):g=\"\",y=l=>{var m=new XMLHttpRequest;return m.open(\"GET\",l,!1),m.send(null),m.responseText},p&&(b=l=>{var m=new XMLHttpRequest;return m.open(\"GET\",l,!1),m.responseType=\"arraybuffer\",m.send(null),new Uint8Array(m.response)}),w=(l,m,v)=>{var C=new XMLHttpRequest;C.open(\"GET\",l,!0),C.responseType=\"arraybuffer\",C.onload=()=>{C.status==200||C.status==0&&C.response?m(C.response):v()},C.onerror=v,C.send(null)});var S=r.print||console.log.bind(console),x=r.printErr||console.error.bind(console);Object.assign(r,s),s=null,r.thisProgram&&(u=r.thisProgram),r.quit&&(d=r.quit);var O;r.wasmBinary&&(O=r.wasmBinary);var T=r.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&He(\"no native wasm support detected\");var M,A,W=!1,V,G,J,B,K,pe,ee;function ve(){var l=M.buffer;r.HEAP8=G=new Int8Array(l),r.HEAP16=new Int16Array(l),r.HEAP32=B=new Int32Array(l),r.HEAPU8=J=new Uint8Array(l),r.HEAPU16=new Uint16Array(l),r.HEAPU32=K=new Uint32Array(l),r.HEAPF32=pe=new Float32Array(l),r.HEAPF64=ee=new Float64Array(l)}var Z=[],be=[],Ce=[];function fe(){var l=r.preRun.shift();Z.unshift(l)}var ce=0,Ue=null,ke=null;function He(l){throw r.onAbort&&r.onAbort(l),l=\"Aborted(\"+l+\")\",x(l),W=!0,V=1,l=new WebAssembly.RuntimeError(l+\". Build with -sASSERTIONS for more info.\"),n(l),l}function L(l){return l.startsWith(\"data:application/octet-stream;base64,\")}var X;if(X=\"ort-wasm-simd.wasm\",!L(X)){var he=X;X=r.locateFile?r.locateFile(he,g):g+he}function Fe(l){if(l==X&&O)return new Uint8Array(O);if(b)return b(l);throw\"both async and sync fetching of the wasm failed\"}function Ze(l){if(!O&&(a||p)){if(typeof fetch==\"function\"&&!l.startsWith(\"file://\"))return fetch(l,{credentials:\"same-origin\"}).then(m=>{if(!m.ok)throw\"failed to load wasm binary file at '\"+l+\"'\";return m.arrayBuffer()}).catch(()=>Fe(l));if(w)return new Promise((m,v)=>{w(l,C=>m(new Uint8Array(C)),v)})}return Promise.resolve().then(()=>Fe(l))}function Re(l,m,v){return Ze(l).then(C=>WebAssembly.instantiate(C,m)).then(C=>C).then(v,C=>{x(\"failed to asynchronously prepare wasm: \"+C),He(C)})}function Ge(l,m){var v=X;return O||typeof WebAssembly.instantiateStreaming!=\"function\"||L(v)||v.startsWith(\"file://\")||h||typeof fetch!=\"function\"?Re(v,l,m):fetch(v,{credentials:\"same-origin\"}).then(C=>WebAssembly.instantiateStreaming(C,l).then(m,function(P){return x(\"wasm streaming compile failed: \"+P),x(\"falling back to ArrayBuffer instantiation\"),Re(v,l,m)}))}var Ke,ot={923216:l=>{r.ra(\"Abs\",l,void 0)},923267:l=>{r.ra(\"Neg\",l,void 0)},923318:l=>{r.ra(\"Floor\",l,void 0)},923371:l=>{r.ra(\"Ceil\",l,void 0)},923423:l=>{r.ra(\"Reciprocal\",l,void 0)},923481:l=>{r.ra(\"Sqrt\",l,void 0)},923533:l=>{r.ra(\"Exp\",l,void 0)},923584:l=>{r.ra(\"Erf\",l,void 0)},923635:l=>{r.ra(\"Sigmoid\",l,void 0)},923690:l=>{r.ra(\"Log\",l,void 0)},923741:l=>{r.ra(\"Sin\",l,void 0)},923792:l=>{r.ra(\"Cos\",l,void 0)},923843:l=>{r.ra(\"Tan\",l,void 0)},923894:l=>{r.ra(\"Asin\",l,void 0)},923946:l=>{r.ra(\"Acos\",l,void 0)},923998:l=>{r.ra(\"Atan\",l,void 0)},924050:l=>{r.ra(\"Sinh\",l,void 0)},924102:l=>{r.ra(\"Cosh\",l,void 0)},924154:l=>{r.ra(\"Asinh\",l,void 0)},924207:l=>{r.ra(\"Acosh\",l,void 0)},924260:l=>{r.ra(\"Atanh\",l,void 0)},924313:l=>{r.ra(\"Tanh\",l,void 0)},924365:l=>{r.ra(\"Not\",l,void 0)},924416:(l,m,v)=>{r.ra(\"Clip\",l,{min:m,max:v})},924485:l=>{r.ra(\"Clip\",l,void 0)},924537:(l,m)=>{r.ra(\"Elu\",l,{alpha:m})},924595:l=>{r.ra(\"Relu\",l,void 0)},924647:(l,m)=>{r.ra(\"LeakyRelu\",l,{alpha:m})},924711:(l,m)=>{r.ra(\"ThresholdedRelu\",l,{alpha:m})},924781:(l,m)=>{r.ra(\"Cast\",l,{to:m})},924839:l=>{r.ra(\"Add\",l,void 0)},924890:l=>{r.ra(\"Sub\",l,void 0)},924941:l=>{r.ra(\"Mul\",l,void 0)},924992:l=>{r.ra(\"Div\",l,void 0)},925043:l=>{r.ra(\"Pow\",l,void 0)},925094:l=>{r.ra(\"Equal\",l,void 0)},925147:l=>{r.ra(\"Greater\",l,void 0)},925202:l=>{r.ra(\"GreaterOrEqual\",l,void 0)},925264:l=>{r.ra(\"Less\",l,void 0)},925316:l=>{r.ra(\"LessOrEqual\",l,void 0)},925375:(l,m,v,C,P)=>{r.ra(\"ReduceMean\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},925539:(l,m,v,C,P)=>{r.ra(\"ReduceMax\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},925702:(l,m,v,C,P)=>{r.ra(\"ReduceMin\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},925865:(l,m,v,C,P)=>{r.ra(\"ReduceProd\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},926029:(l,m,v,C,P)=>{r.ra(\"ReduceSum\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},926192:(l,m,v,C,P)=>{r.ra(\"ReduceL1\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},926354:(l,m,v,C,P)=>{r.ra(\"ReduceL2\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},926516:(l,m,v,C,P)=>{r.ra(\"ReduceLogSum\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},926682:(l,m,v,C,P)=>{r.ra(\"ReduceSumSquare\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},926851:(l,m,v,C,P)=>{r.ra(\"ReduceLogSumExp\",l,{keepDims:!!m,noopWithEmptyAxes:!!v,axes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},927020:l=>{r.ra(\"Where\",l,void 0)},927073:(l,m,v)=>{r.ra(\"Transpose\",l,{perm:m?Array.from(B.subarray(v>>>0,v+m>>>0)):[]})},927186:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe,k,se)=>{r.ra(\"ConvTranspose\",l,{format:Q?\"NHWC\":\"NCHW\",autoPad:m,dilations:[v],group:C,kernel_shape:[P],pads:[F,H],strides:[le],wIsConst:()=>!!G[ae>>>0],outputPadding:te?Array.from(B.subarray(ye>>>0,ye+te>>>0)):[],outputShape:xe?Array.from(B.subarray(k>>>0,k+xe>>>0)):[],activation:Me(se)})},927600:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe,k)=>{r.ra(\"ConvTranspose\",l,{format:le?\"NHWC\":\"NCHW\",autoPad:m,dilations:Array.from(B.subarray(v>>>0,v+2>>>0)),group:C,kernelShape:Array.from(B.subarray(P>>>0,P+2>>>0)),pads:Array.from(B.subarray(F>>>0,F+4>>>0)),strides:Array.from(B.subarray(H>>>0,H+2>>>0)),wIsConst:()=>!!G[Q>>>0],outputPadding:0<ae?Array.from(B.subarray(te>>>0,te+ae>>>0)):[],outputShape:0<ye?Array.from(B.subarray(xe>>>0,xe+ye>>>0)):[],activation:Me(k)})},928157:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe,k,se)=>{r.ra(\"ConvTranspose\",l,{format:Q?\"NHWC\":\"NCHW\",autoPad:m,dilations:[v],group:C,kernel_shape:[P],pads:[F,H],strides:[le],wIsConst:()=>!!G[ae>>>0],outputPadding:te?Array.from(B.subarray(ye>>>0,ye+te>>>0)):[],outputShape:xe?Array.from(B.subarray(k>>>0,k+xe>>>0)):[],activation:Me(se)})},928571:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe,k)=>{r.ra(\"ConvTranspose\",l,{format:le?\"NHWC\":\"NCHW\",autoPad:m,dilations:Array.from(B.subarray(v>>>0,v+2>>>0)),group:C,kernelShape:Array.from(B.subarray(P>>>0,P+2>>>0)),pads:Array.from(B.subarray(F>>>0,F+4>>>0)),strides:Array.from(B.subarray(H>>>0,H+2>>>0)),wIsConst:()=>!!G[Q>>>0],outputPadding:0<ae?Array.from(B.subarray(te>>>0,te+ae>>>0)):[],outputShape:0<ye?Array.from(B.subarray(xe>>>0,xe+ye>>>0)):[],activation:Me(k)})},929128:(l,m)=>{r.ra(\"GlobalAveragePool\",l,{format:m?\"NHWC\":\"NCHW\"})},929219:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe,k,se,$e)=>{r.ra(\"AveragePool\",l,{format:$e?\"NHWC\":\"NCHW\",auto_pad:m,ceil_mode:v,count_include_pad:C,storage_order:P,dilations:[F,H],kernel_shape:[le,Q],pads:[ae,te,ye,xe],strides:[k,se]})},929503:(l,m)=>{r.ra(\"GlobalAveragePool\",l,{format:m?\"NHWC\":\"NCHW\"})},929594:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe,k,se,$e)=>{r.ra(\"AveragePool\",l,{format:$e?\"NHWC\":\"NCHW\",auto_pad:m,ceil_mode:v,count_include_pad:C,storage_order:P,dilations:[F,H],kernel_shape:[le,Q],pads:[ae,te,ye,xe],strides:[k,se]})},929878:(l,m)=>{r.ra(\"GlobalMaxPool\",l,{format:m?\"NHWC\":\"NCHW\"})},929965:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe,k,se,$e)=>{r.ra(\"MaxPool\",l,{format:$e?\"NHWC\":\"NCHW\",auto_pad:m,ceil_mode:v,count_include_pad:C,storage_order:P,dilations:[F,H],kernel_shape:[le,Q],pads:[ae,te,ye,xe],strides:[k,se]})},930245:(l,m)=>{r.ra(\"GlobalMaxPool\",l,{format:m?\"NHWC\":\"NCHW\"})},930332:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe,k,se,$e)=>{r.ra(\"MaxPool\",l,{format:$e?\"NHWC\":\"NCHW\",auto_pad:m,ceil_mode:v,count_include_pad:C,storage_order:P,dilations:[F,H],kernel_shape:[le,Q],pads:[ae,te,ye,xe],strides:[k,se]})},930612:(l,m,v,C,P)=>{r.ra(\"Gemm\",l,{alpha:m,beta:v,transA:C,transB:P})},930716:l=>{r.ra(\"MatMul\",l,void 0)},930770:(l,m,v,C)=>{r.ra(\"ArgMax\",l,{keepDims:!!m,selectLastIndex:!!v,axis:C})},930878:(l,m,v,C)=>{r.ra(\"ArgMin\",l,{keepDims:!!m,selectLastIndex:!!v,axis:C})},930986:(l,m)=>{r.ra(\"Softmax\",l,{axis:m})},931049:(l,m)=>{r.ra(\"Concat\",l,{axis:m})},931109:(l,m,v,C,P)=>{r.ra(\"Split\",l,{axis:m,numOutputs:v,splitSizes:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},931254:l=>{r.ra(\"Expand\",l,void 0)},931308:(l,m)=>{r.ra(\"Gather\",l,{axis:Number(m)})},931379:(l,m)=>{r.ra(\"GatherElements\",l,{axis:Number(m)})},931458:(l,m,v,C,P,F,H,le,Q,ae,te)=>{r.ra(\"Resize\",l,{antialias:m,axes:v?Array.from(B.subarray(C>>>0,C+v>>>0)):[],coordinateTransformMode:Me(P),cubicCoeffA:F,excludeOutside:H,extrapolationValue:le,keepAspectRatioPolicy:Me(Q),mode:Me(ae),nearestMode:Me(te)})},931809:(l,m,v,C,P,F,H)=>{r.ra(\"Slice\",l,{starts:m?Array.from(B.subarray(v>>>0,v+m>>>0)):[],ends:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[],axes:F?Array.from(B.subarray(H>>>0,H+F>>>0)):[]})},932040:l=>{r.ra(\"Tile\",l,void 0)},932092:(l,m,v)=>{r.ra(\"LayerNormalization\",l,{axis:Number(m),epsilon:Number(v)})},932199:(l,m,v)=>{r.ra(\"InstanceNormalization\",l,{epsilon:m,format:v?\"NHWC\":\"NCHW\"})},932313:(l,m,v)=>{r.ra(\"InstanceNormalization\",l,{epsilon:m,format:v?\"NHWC\":\"NCHW\"})},932427:l=>{r.ra(\"Range\",l,void 0)},932480:(l,m)=>{r.ra(\"Einsum\",l,{equation:Me(m)})},932561:(l,m,v,C,P)=>{r.ra(\"Pad\",l,{mode:m,value:v,pads:C?Array.from(B.subarray(P>>>0,P+C>>>0)):[]})},932693:(l,m,v,C,P,F)=>{r.ra(\"BatchNormalization\",l,{epsilon:m,momentum:v,spatial:!!P,trainingMode:!!C,format:F?\"NHWC\":\"NCHW\"})},932862:(l,m,v,C,P,F)=>{r.ra(\"BatchNormalization\",l,{epsilon:m,momentum:v,spatial:!!P,trainingMode:!!C,format:F?\"NHWC\":\"NCHW\"})},933031:(l,m,v)=>{r.ra(\"CumSum\",l,{exclusive:Number(m),reverse:Number(v)})},933128:(l,m,v,C,P,F,H,le,Q)=>{r.ra(\"Attention\",l,{numHeads:m,isUnidirectional:v,maskFilterValue:C,scale:P,doRotary:F,qkvHiddenSizes:H?Array.from(B.subarray(Number(le)>>>0,Number(le)+H>>>0)):[],pastPresentShareBuffer:!!Q})},933400:l=>{r.ra(\"Gelu\",l,void 0)},933452:(l,m,v,C,P,F)=>{r.ra(\"MultiHeadAttention\",l,{numHeads:m,isUnidirectional:v,maskFilterValue:C,scale:P,doRotary:F})},933611:l=>{r.ra(\"BiasAdd\",l,void 0)},933666:l=>{r.ra(\"BiasSplitGelu\",l,void 0)},933727:(l,m)=>{r.ra(\"SkipLayerNormalization\",l,{epsilon:m})},933808:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe)=>{r.ra(\"Conv\",l,{format:Q?\"NHWC\":\"NCHW\",auto_pad:m,dilations:[v],group:C,kernel_shape:[P],pads:F?Array.from(B.subarray(H>>>0,H+F>>>0)):[],strides:[le],w_is_const:()=>!!G[ae>>>0],activation:Me(te),activation_params:ye?Array.from(pe.subarray(xe>>>0,xe+ye>>>0)):[]})},934189:(l,m,v,C,P,F,H,le,Q,ae,te,ye,xe,k,se,$e)=>{r.ra(\"Conv\",l,{format:ye?\"NHWC\":\"NCHW\",auto_pad:m,dilations:[v,C],group:P,kernel_shape:[F,H],pads:le?Array.from(B.subarray(Q>>>0,Q+le>>>0)):[],strides:[ae,te],w_is_const:()=>!!G[xe>>>0],activation:Me(k),activation_params:se?Array.from(pe.subarray($e>>>0,$e+se>>>0)):[]})},934591:l=>{r.Ra(l)},934625:(l,m)=>r.Sa(l,m,r.Da.Ta,r.Da.errors),934737:l=>r.Oa(l),934770:l=>r.Qa(l),934802:(l,m,v)=>{r.Ja(l,m,v,!0)},934841:(l,m,v)=>{r.Ja(l,m,v)}};function Je(l){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${l})`,this.status=l}var _t=l=>{for(;0<l.length;)l.shift()(r)};function Ct(l){this.Ha=l-24,this.Ma=function(m){K[this.Ha+4>>2>>>0]=m},this.La=function(m){K[this.Ha+8>>2>>>0]=m},this.Ya=function(m,v){this.Ka(),this.Ma(m),this.La(v)},this.Ka=function(){K[this.Ha+16>>2>>>0]=0}}var jt=0,wr=0,tt=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,Kt=(l,m,v)=>{m>>>=0;var C=m+v;for(v=m;l[v]&&!(v>=C);)++v;if(16<v-m&&l.buffer&&tt)return tt.decode(l.subarray(m,v));for(C=\"\";m<v;){var P=l[m++];if(P&128){var F=l[m++]&63;if((P&224)==192)C+=String.fromCharCode((P&31)<<6|F);else{var H=l[m++]&63;P=(P&240)==224?(P&15)<<12|F<<6|H:(P&7)<<18|F<<12|H<<6|l[m++]&63,65536>P?C+=String.fromCharCode(P):(P-=65536,C+=String.fromCharCode(55296|P>>10,56320|P&1023))}}else C+=String.fromCharCode(P)}return C},Me=(l,m)=>(l>>>=0)?Kt(J,l,m):\"\",Rt=l=>{for(var m=0,v=0;v<l.length;++v){var C=l.charCodeAt(v);127>=C?m++:2047>=C?m+=2:55296<=C&&57343>=C?(m+=4,++v):m+=3}return m},Yt=(l,m,v,C)=>{if(v>>>=0,!(0<C))return 0;var P=v;C=v+C-1;for(var F=0;F<l.length;++F){var H=l.charCodeAt(F);if(55296<=H&&57343>=H){var le=l.charCodeAt(++F);H=65536+((H&1023)<<10)|le&1023}if(127>=H){if(v>=C)break;m[v++>>>0]=H}else{if(2047>=H){if(v+1>=C)break;m[v++>>>0]=192|H>>6}else{if(65535>=H){if(v+2>=C)break;m[v++>>>0]=224|H>>12}else{if(v+3>=C)break;m[v++>>>0]=240|H>>18,m[v++>>>0]=128|H>>12&63}m[v++>>>0]=128|H>>6&63}m[v++>>>0]=128|H&63}}return m[v>>>0]=0,v-P},ht=l=>l%4===0&&(l%100!==0||l%400===0),vr=[0,31,60,91,121,152,182,213,244,274,305,335],gt=[0,31,59,90,120,151,181,212,243,273,304,334],Bt=l=>{var m=Rt(l)+1,v=Ut(m);return v&&Yt(l,J,v,m),v},wt=[],Dt=(l,m)=>{wt.length=0;var v;for(m>>=2;v=J[l++>>>0];)m+=v!=105&m,wt.push(v==105?B[m>>>0]:ee[m++>>>1]),++m;return wt},Mt={},Zt=()=>{if(!zt){var l={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:u||\"./this.program\"},m;for(m in Mt)Mt[m]===void 0?delete l[m]:l[m]=Mt[m];var v=[];for(m in l)v.push(`${m}=${l[m]}`);zt=v}return zt},zt,$r=[null,[],[]],qe=[31,29,31,30,31,30,31,31,30,31,30,31],Xt=[31,28,31,30,31,30,31,31,30,31,30,31];function Qt(l){var m=Array(Rt(l)+1);return Yt(l,m,0,m.length),m}function oe(l,m,v,C){function P(k,se,$e){for(k=typeof k==\"number\"?k.toString():k||\"\";k.length<se;)k=$e[0]+k;return k}function F(k,se){return P(k,se,\"0\")}function H(k,se){function $e(lr){return 0>lr?-1:0<lr?1:0}var bt;return(bt=$e(k.getFullYear()-se.getFullYear()))===0&&(bt=$e(k.getMonth()-se.getMonth()))===0&&(bt=$e(k.getDate()-se.getDate())),bt}function le(k){switch(k.getDay()){case 0:return new Date(k.getFullYear()-1,11,29);case 1:return k;case 2:return new Date(k.getFullYear(),0,3);case 3:return new Date(k.getFullYear(),0,2);case 4:return new Date(k.getFullYear(),0,1);case 5:return new Date(k.getFullYear()-1,11,31);case 6:return new Date(k.getFullYear()-1,11,30)}}function Q(k){var se=k.Ba;for(k=new Date(new Date(k.Ca+1900,0,1).getTime());0<se;){var $e=k.getMonth(),bt=(ht(k.getFullYear())?qe:Xt)[$e];if(se>bt-k.getDate())se-=bt-k.getDate()+1,k.setDate(1),11>$e?k.setMonth($e+1):(k.setMonth(0),k.setFullYear(k.getFullYear()+1));else{k.setDate(k.getDate()+se);break}}return $e=new Date(k.getFullYear()+1,0,4),se=le(new Date(k.getFullYear(),0,4)),$e=le($e),0>=H(se,k)?0>=H($e,k)?k.getFullYear()+1:k.getFullYear():k.getFullYear()-1}l>>>=0,m>>>=0,v>>>=0,C>>>=0;var ae=B[C+40>>2>>>0];C={Wa:B[C>>2>>>0],Va:B[C+4>>2>>>0],Ea:B[C+8>>2>>>0],Ia:B[C+12>>2>>>0],Fa:B[C+16>>2>>>0],Ca:B[C+20>>2>>>0],wa:B[C+24>>2>>>0],Ba:B[C+28>>2>>>0],$a:B[C+32>>2>>>0],Ua:B[C+36>>2>>>0],Xa:ae?Me(ae):\"\"},v=Me(v),ae={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var te in ae)v=v.replace(new RegExp(te,\"g\"),ae[te]);var ye=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),xe=\"January February March April May June July August September October November December\".split(\" \");ae={\"%a\":k=>ye[k.wa].substring(0,3),\"%A\":k=>ye[k.wa],\"%b\":k=>xe[k.Fa].substring(0,3),\"%B\":k=>xe[k.Fa],\"%C\":k=>F((k.Ca+1900)/100|0,2),\"%d\":k=>F(k.Ia,2),\"%e\":k=>P(k.Ia,2,\" \"),\"%g\":k=>Q(k).toString().substring(2),\"%G\":k=>Q(k),\"%H\":k=>F(k.Ea,2),\"%I\":k=>(k=k.Ea,k==0?k=12:12<k&&(k-=12),F(k,2)),\"%j\":k=>{for(var se=0,$e=0;$e<=k.Fa-1;se+=(ht(k.Ca+1900)?qe:Xt)[$e++]);return F(k.Ia+se,3)},\"%m\":k=>F(k.Fa+1,2),\"%M\":k=>F(k.Va,2),\"%n\":()=>`\n`,\"%p\":k=>0<=k.Ea&&12>k.Ea?\"AM\":\"PM\",\"%S\":k=>F(k.Wa,2),\"%t\":()=>\"\t\",\"%u\":k=>k.wa||7,\"%U\":k=>F(Math.floor((k.Ba+7-k.wa)/7),2),\"%V\":k=>{var se=Math.floor((k.Ba+7-(k.wa+6)%7)/7);if(2>=(k.wa+371-k.Ba-2)%7&&se++,se)se==53&&($e=(k.wa+371-k.Ba)%7,$e==4||$e==3&&ht(k.Ca)||(se=1));else{se=52;var $e=(k.wa+7-k.Ba-1)%7;($e==4||$e==5&&ht(k.Ca%400-1))&&se++}return F(se,2)},\"%w\":k=>k.wa,\"%W\":k=>F(Math.floor((k.Ba+7-(k.wa+6)%7)/7),2),\"%y\":k=>(k.Ca+1900).toString().substring(2),\"%Y\":k=>k.Ca+1900,\"%z\":k=>{k=k.Ua;var se=0<=k;return k=Math.abs(k)/60,(se?\"+\":\"-\")+(\"0000\"+(k/60*100+k%60)).slice(-4)},\"%Z\":k=>k.Xa,\"%%\":()=>\"%\"},v=v.replace(/%%/g,\"\\0\\0\");for(te in ae)v.includes(te)&&(v=v.replace(new RegExp(te,\"g\"),ae[te](C)));return v=v.replace(/\\0\\0/g,\"%\"),te=Qt(v),te.length>m?0:(G.set(te,l>>>0),te.length-1)}function yt(l){try{l()}catch(m){He(m)}}function Sr(l){var m={},v;for(v in l)(function(C){var P=l[C];m[C]=typeof P==\"function\"?function(){It.push(C);try{return P.apply(null,arguments)}finally{W||(It.pop()===C||He(),et&&at===1&&It.length===0&&(at=0,yt(sr),typeof Fibers<\"u\"&&Fibers.ab()))}}:P})(v);return m}var at=0,et=null,xr=0,It=[],Jt={},er={},_r=0,At=null,Cr=[];function Ir(){return new Promise((l,m)=>{At={resolve:l,reject:m}})}function Ar(){var l=Ut(65548),m=l+12;K[l>>2>>>0]=m,K[l+4>>2>>>0]=m+65536,m=It[0];var v=Jt[m];return v===void 0&&(v=_r++,Jt[m]=v,er[v]=m),B[l+8>>2>>>0]=v,l}function Tr(l){if(!W){if(at===0){var m=!1,v=!1;l((C=0)=>{if(!W&&(xr=C,m=!0,v)){at=2,yt(()=>Vt(et)),typeof Browser<\"u\"&&Browser.Ga.Na&&Browser.Ga.resume(),C=!1;try{var P=(0,A[er[B[et+8>>2>>>0]]])()}catch(le){P=le,C=!0}var F=!1;if(!et){var H=At;H&&(At=null,(C?H.reject:H.resolve)(P),F=!0)}if(C&&!F)throw P}}),v=!0,m||(at=1,et=Ar(),typeof Browser<\"u\"&&Browser.Ga.Na&&Browser.Ga.pause(),yt(()=>ir(et)))}else at===2?(at=0,yt(Tt),tr(et),et=null,Cr.forEach(C=>{if(!W)try{if(C(),!T)try{V=V=C=V,T||(r.onExit&&r.onExit(C),W=!0),d(C,new Je(C))}catch(P){P instanceof Je||P==\"unwind\"||d(1,P)}}catch(P){P instanceof Je||P==\"unwind\"||d(1,P)}})):He(`invalid state: ${at}`);return xr}}function Er(l){return Tr(m=>{l().then(m)})}var Or={n:function(l,m,v){return Er(async()=>{await r.Pa(l,m,v)})},a:function(l,m,v){throw l>>>=0,new Ct(l).Ya(m>>>0,v>>>0),jt=l,wr++,jt},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},G:function(){},l:function(){},A:function(){},x:function(){},I:function(){},y:function(){},m:()=>!0,q:function(l,m,v){l=m+2097152>>>0<4194305-!!l?(l>>>0)+4294967296*m:NaN,v>>>=0,l=new Date(1e3*l),B[v>>2>>>0]=l.getUTCSeconds(),B[v+4>>2>>>0]=l.getUTCMinutes(),B[v+8>>2>>>0]=l.getUTCHours(),B[v+12>>2>>>0]=l.getUTCDate(),B[v+16>>2>>>0]=l.getUTCMonth(),B[v+20>>2>>>0]=l.getUTCFullYear()-1900,B[v+24>>2>>>0]=l.getUTCDay(),B[v+28>>2>>>0]=(l.getTime()-Date.UTC(l.getUTCFullYear(),0,1,0,0,0,0))/864e5|0},r:function(l,m,v){l=m+2097152>>>0<4194305-!!l?(l>>>0)+4294967296*m:NaN,v>>>=0,l=new Date(1e3*l),B[v>>2>>>0]=l.getSeconds(),B[v+4>>2>>>0]=l.getMinutes(),B[v+8>>2>>>0]=l.getHours(),B[v+12>>2>>>0]=l.getDate(),B[v+16>>2>>>0]=l.getMonth(),B[v+20>>2>>>0]=l.getFullYear()-1900,B[v+24>>2>>>0]=l.getDay(),B[v+28>>2>>>0]=(ht(l.getFullYear())?vr:gt)[l.getMonth()]+l.getDate()-1|0,B[v+36>>2>>>0]=-(60*l.getTimezoneOffset()),m=new Date(l.getFullYear(),6,1).getTimezoneOffset();var C=new Date(l.getFullYear(),0,1).getTimezoneOffset();B[v+32>>2>>>0]=(m!=C&&l.getTimezoneOffset()==Math.min(C,m))|0},s:function(l){l>>>=0;var m=new Date(B[l+20>>2>>>0]+1900,B[l+16>>2>>>0],B[l+12>>2>>>0],B[l+8>>2>>>0],B[l+4>>2>>>0],B[l>>2>>>0],0),v=B[l+32>>2>>>0],C=m.getTimezoneOffset(),P=new Date(m.getFullYear(),6,1).getTimezoneOffset(),F=new Date(m.getFullYear(),0,1).getTimezoneOffset(),H=Math.min(F,P);return 0>v?B[l+32>>2>>>0]=+(P!=F&&H==C):0<v!=(H==C)&&(P=Math.max(F,P),m.setTime(m.getTime()+6e4*((0<v?H:P)-C))),B[l+24>>2>>>0]=m.getDay(),B[l+28>>2>>>0]=(ht(m.getFullYear())?vr:gt)[m.getMonth()]+m.getDate()-1|0,B[l>>2>>>0]=m.getSeconds(),B[l+4>>2>>>0]=m.getMinutes(),B[l+8>>2>>>0]=m.getHours(),B[l+12>>2>>>0]=m.getDate(),B[l+16>>2>>>0]=m.getMonth(),B[l+20>>2>>>0]=m.getYear(),l=m.getTime()/1e3,rr((Ke=l,1<=+Math.abs(Ke)?0<Ke?+Math.floor(Ke/4294967296)>>>0:~~+Math.ceil((Ke-+(~~Ke>>>0))/4294967296)>>>0:0)),l>>>0},o:function(){return-52},p:function(){},v:function(l,m,v){function C(Q){return(Q=Q.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?Q[1]:\"GMT\"}v>>>=0;var P=new Date().getFullYear(),F=new Date(P,0,1),H=new Date(P,6,1);P=F.getTimezoneOffset();var le=H.getTimezoneOffset();K[l>>>0>>2>>>0]=60*Math.max(P,le),B[m>>>0>>2>>>0]=+(P!=le),l=C(F),m=C(H),l=Bt(l),m=Bt(m),le<P?(K[v>>2>>>0]=l,K[v+4>>2>>>0]=m):(K[v>>2>>>0]=m,K[v+4>>2>>>0]=l)},e:()=>{He(\"\")},b:function(l,m,v){return l>>>=0,m=Dt(m>>>0,v>>>0),ot[l].apply(null,m)},i:function(l,m,v){return l>>>=0,m=Dt(m>>>0,v>>>0),ot[l].apply(null,m)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(l,m,v){return m>>>=0,J.copyWithin(l>>>0>>>0,m>>>0,m+(v>>>0)>>>0)},u:function(l){l>>>=0;var m=J.length;if(4294901760<l)return!1;for(var v=1;4>=v;v*=2){var C=m*(1+.2/v);C=Math.min(C,l+100663296);var P=Math;C=Math.max(l,C);e:{P=P.min.call(P,4294901760,C+(65536-C%65536)%65536)-M.buffer.byteLength+65535>>>16;try{M.grow(P),ve();var F=1;break e}catch{}F=void 0}if(F)return!0}return!1},D:function(l,m){l>>>=0,m>>>=0;var v=0;return Zt().forEach(function(C,P){var F=m+v;for(P=K[l+4*P>>2>>>0]=F,F=0;F<C.length;++F)G[P++>>0>>>0]=C.charCodeAt(F);G[P>>0>>>0]=0,v+=C.length+1}),0},E:function(l,m){l>>>=0,m>>>=0;var v=Zt();K[l>>2>>>0]=v.length;var C=0;return v.forEach(function(P){C+=P.length+1}),K[m>>2>>>0]=C,0},f:()=>52,k:function(){return 52},t:function(){return 70},j:function(l,m,v,C){m>>>=0,v>>>=0,C>>>=0;for(var P=0,F=0;F<v;F++){var H=K[m>>2>>>0],le=K[m+4>>2>>>0];m+=8;for(var Q=0;Q<le;Q++){var ae=J[H+Q>>>0],te=$r[l];ae===0||ae===10?((l===1?S:x)(Kt(te,0)),te.length=0):te.push(ae)}P+=le}return K[C>>2>>>0]=P,0},F:oe,d:function(l,m,v,C){return oe(l>>>0,m>>>0,v>>>0,C>>>0)}};(function(){function l(v){if(v=v.exports,v=Sr(v),A=v=vt(v),M=A.M,ve(),be.unshift(A.N),ce--,r.monitorRunDependencies&&r.monitorRunDependencies(ce),ce==0&&(Ue!==null&&(clearInterval(Ue),Ue=null),ke)){var C=ke;ke=null,C()}return v}var m={a:Or};if(ce++,r.monitorRunDependencies&&r.monitorRunDependencies(ce),r.instantiateWasm)try{return r.instantiateWasm(m,l)}catch(v){x(\"Module.instantiateWasm callback failed with error: \"+v),n(v)}return Ge(m,function(v){l(v.instance)}).catch(n),{}})(),r._OrtInit=(l,m)=>(r._OrtInit=A.O)(l,m),r._OrtGetLastError=(l,m)=>(r._OrtGetLastError=A.P)(l,m),r._OrtCreateSessionOptions=(l,m,v,C,P,F,H,le,Q,ae)=>(r._OrtCreateSessionOptions=A.Q)(l,m,v,C,P,F,H,le,Q,ae),r._OrtAppendExecutionProvider=(l,m)=>(r._OrtAppendExecutionProvider=A.R)(l,m),r._OrtAddFreeDimensionOverride=(l,m,v)=>(r._OrtAddFreeDimensionOverride=A.S)(l,m,v),r._OrtAddSessionConfigEntry=(l,m,v)=>(r._OrtAddSessionConfigEntry=A.T)(l,m,v),r._OrtReleaseSessionOptions=l=>(r._OrtReleaseSessionOptions=A.U)(l),r._OrtCreateSession=(l,m,v)=>(r._OrtCreateSession=A.V)(l,m,v),r._OrtReleaseSession=l=>(r._OrtReleaseSession=A.W)(l),r._OrtGetInputOutputCount=(l,m,v)=>(r._OrtGetInputOutputCount=A.X)(l,m,v),r._OrtGetInputName=(l,m)=>(r._OrtGetInputName=A.Y)(l,m),r._OrtGetOutputName=(l,m)=>(r._OrtGetOutputName=A.Z)(l,m),r._OrtFree=l=>(r._OrtFree=A._)(l),r._OrtCreateTensor=(l,m,v,C,P,F)=>(r._OrtCreateTensor=A.$)(l,m,v,C,P,F),r._OrtGetTensorData=(l,m,v,C,P)=>(r._OrtGetTensorData=A.aa)(l,m,v,C,P),r._OrtReleaseTensor=l=>(r._OrtReleaseTensor=A.ba)(l),r._OrtCreateRunOptions=(l,m,v,C)=>(r._OrtCreateRunOptions=A.ca)(l,m,v,C),r._OrtAddRunConfigEntry=(l,m,v)=>(r._OrtAddRunConfigEntry=A.da)(l,m,v),r._OrtReleaseRunOptions=l=>(r._OrtReleaseRunOptions=A.ea)(l),r._OrtCreateBinding=l=>(r._OrtCreateBinding=A.fa)(l),r._OrtBindInput=(l,m,v)=>(r._OrtBindInput=A.ga)(l,m,v),r._OrtBindOutput=(l,m,v,C)=>(r._OrtBindOutput=A.ha)(l,m,v,C),r._OrtClearBoundOutputs=l=>(r._OrtClearBoundOutputs=A.ia)(l),r._OrtReleaseBinding=l=>(r._OrtReleaseBinding=A.ja)(l),r._OrtRunWithBinding=(l,m,v,C,P)=>(r._OrtRunWithBinding=A.ka)(l,m,v,C,P),r._OrtRun=(l,m,v,C,P,F,H,le)=>(r._OrtRun=A.la)(l,m,v,C,P,F,H,le),r._OrtEndProfiling=l=>(r._OrtEndProfiling=A.ma)(l),r._JsepOutput=(l,m,v)=>(r._JsepOutput=A.na)(l,m,v),r._JsepGetNodeName=l=>(r._JsepGetNodeName=A.oa)(l);var Ut=r._malloc=l=>(Ut=r._malloc=A.pa)(l),tr=r._free=l=>(tr=r._free=A.qa)(l),rr=l=>(rr=A.sa)(l),nr=()=>(nr=A.ta)(),or=l=>(or=A.ua)(l),ar=l=>(ar=A.va)(l),ir=l=>(ir=A.xa)(l),sr=()=>(sr=A.ya)(),Vt=l=>(Vt=A.za)(l),Tt=()=>(Tt=A.Aa)();r.___start_em_js=934874,r.___stop_em_js=935035;function vt(l){l=Object.assign({},l);var m=C=>()=>C()>>>0,v=C=>P=>C(P)>>>0;return l.__errno_location=m(l.__errno_location),l.malloc=v(l.malloc),l.stackSave=m(l.stackSave),l.stackAlloc=v(l.stackAlloc),l}r.stackAlloc=ar,r.stackSave=nr,r.stackRestore=or,r.UTF8ToString=Me,r.stringToUTF8=(l,m,v)=>Yt(l,J,m,v),r.lengthBytesUTF8=Rt;var Et;ke=function l(){Et||ur(),Et||(ke=l)};function ur(){function l(){if(!Et&&(Et=!0,r.calledRun=!0,!W)){if(_t(be),o(r),r.onRuntimeInitialized&&r.onRuntimeInitialized(),r.postRun)for(typeof r.postRun==\"function\"&&(r.postRun=[r.postRun]);r.postRun.length;){var m=r.postRun.shift();Ce.unshift(m)}_t(Ce)}}if(!(0<ce)){if(r.preRun)for(typeof r.preRun==\"function\"&&(r.preRun=[r.preRun]);r.preRun.length;)fe();_t(Z),0<ce||(r.setStatus?(r.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){r.setStatus(\"\")},1),l()},1)):l())}}if(r.preInit)for(typeof r.preInit==\"function\"&&(r.preInit=[r.preInit]);0<r.preInit.length;)r.preInit.pop()();return ur(),t.ready}})();typeof So==\"object\"&&typeof $n==\"object\"?$n.exports=$o:typeof define==\"function\"&&define.amd&&define([],()=>$o)});var _o=dr(()=>{});var Co=dr(()=>{});var Io={};Mr(Io,{cpus:()=>qu});var qu,Ao=Y(()=>{qu=void 0});var Oo=dr((Eo,Sn)=>{\"use strict\";var To=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){function r(){return ve.buffer!=ce.buffer&&he(),ce}function o(){return ve.buffer!=ce.buffer&&he(),Ue}function n(){return ve.buffer!=ce.buffer&&he(),ke}function s(){return ve.buffer!=ce.buffer&&he(),He}function u(){return ve.buffer!=ce.buffer&&he(),L}function d(){return ve.buffer!=ce.buffer&&he(),X}var a=t,p,h;a.ready=new Promise((i,c)=>{p=i,h=c}),a.jsepInit=(i,c,f,$,E,D,N,ie)=>{a.Qb=i,a.xb=c,a.zb=f,a.kb=$,a.yb=E,a.Ea=D,a.Ab=N,a.Bb=ie,c=(re,ne,ue)=>(..._e)=>{let Ae=it,R=ne?.();_e=re(..._e);let me=ne?.();return R!==me&&(re=me,ue(R),ne=ue=null),it!=Ae?ku():_e},f=re=>async(...ne)=>{try{if(a.bb)throw Error(\"Session already started\");let ue=a.bb={Fb:ne[0],errors:[]},_e=await re(...ne);if(a.bb!==ue)throw Error(\"Session mismatch\");i.flush();let Ae=ue.errors;if(0<Ae.length){let R=await Promise.all(Ae);if(R=R.filter(me=>me),0<R.length)throw Error(R.join(`\n`))}return _e}finally{a.bb=null}},a._OrtRun=f(c(a._OrtRun,()=>a._OrtRun,re=>a._OrtRun=re)),a._OrtRunWithBinding=f(c(a._OrtRunWithBinding,()=>a._OrtRunWithBinding,re=>a._OrtRunWithBinding=re)),a._OrtBindInput=c(a._OrtBindInput,()=>a._OrtBindInput,re=>a._OrtBindInput=re),a.jsepRegisterBuffer=(re,ne,ue,_e)=>i.registerBuffer(re,ne,ue,_e),a.jsepUnregisterBuffers=re=>{i.unregisterBuffers(re)},a.jsepGetBuffer=re=>i.getBuffer(re),a.jsepCreateDownloader=(re,ne,ue)=>i.createDownloader(re,ne,ue)};var g=Object.assign({},a),y=\"./this.program\",w=(i,c)=>{throw c},b=typeof window==\"object\",_=typeof importScripts==\"function\",I=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",S=a.ENVIRONMENT_IS_PTHREAD||!1,x=\"\";function O(i){return a.locateFile?a.locateFile(i,x):x+i}var T,M,A;if(I){var W=(bn(),Wt(yn)),V=(vn(),Wt(wn));x=_?V.dirname(x)+\"/\":__dirname+\"/\",T=(c,f)=>(c=c.startsWith(\"file://\")?new URL(c):V.normalize(c),W.readFileSync(c,f?void 0:\"utf8\")),A=c=>(c=T(c,!0),c.buffer||(c=new Uint8Array(c)),c),M=(c,f,$,E=!0)=>{c=c.startsWith(\"file://\")?new URL(c):V.normalize(c),W.readFile(c,E?void 0:\"utf8\",(D,N)=>{D?$(D):f(E?N.buffer:N)})},!a.thisProgram&&1<process.argv.length&&(y=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),w=(c,f)=>{throw process.exitCode=c,f},a.inspect=()=>\"[Emscripten Module object]\";let i;try{i=_o()}catch(c){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),c}global.Worker=i.Worker}else(b||_)&&(_?x=self.location.href:typeof document<\"u\"&&document.currentScript&&(x=document.currentScript.src),typeof e<\"u\"&&e&&(x=e),x.indexOf(\"blob:\")!==0?x=x.substr(0,x.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):x=\"\",I||(T=i=>{var c=new XMLHttpRequest;return c.open(\"GET\",i,!1),c.send(null),c.responseText},_&&(A=i=>{var c=new XMLHttpRequest;return c.open(\"GET\",i,!1),c.responseType=\"arraybuffer\",c.send(null),new Uint8Array(c.response)}),M=(i,c,f)=>{var $=new XMLHttpRequest;$.open(\"GET\",i,!0),$.responseType=\"arraybuffer\",$.onload=()=>{$.status==200||$.status==0&&$.response?c($.response):f()},$.onerror=f,$.send(null)}));I&&typeof performance>\"u\"&&(global.performance=Co().performance);var G=console.log.bind(console),J=console.error.bind(console);I&&(G=(...i)=>W.writeSync(1,i.join(\" \")+`\n`),J=(...i)=>W.writeSync(2,i.join(\" \")+`\n`));var B=a.print||G,K=a.printErr||J;Object.assign(a,g),g=null,a.thisProgram&&(y=a.thisProgram),a.quit&&(w=a.quit);var pe;a.wasmBinary&&(pe=a.wasmBinary);var ee=a.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&tt(\"no native wasm support detected\");var ve,Z,be,Ce=!1,fe,ce,Ue,ke,He,L,X;function he(){var i=ve.buffer;a.HEAP8=ce=new Int8Array(i),a.HEAP16=new Int16Array(i),a.HEAP32=ke=new Int32Array(i),a.HEAPU8=Ue=new Uint8Array(i),a.HEAPU16=new Uint16Array(i),a.HEAPU32=He=new Uint32Array(i),a.HEAPF32=L=new Float32Array(i),a.HEAPF64=X=new Float64Array(i)}var Fe=a.INITIAL_MEMORY||16777216;if(5242880<=Fe||tt(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+Fe+\"! (STACK_SIZE=5242880)\"),S)ve=a.wasmMemory;else if(a.wasmMemory)ve=a.wasmMemory;else if(ve=new WebAssembly.Memory({initial:Fe/65536,maximum:65536,shared:!0}),!(ve.buffer instanceof SharedArrayBuffer))throw K(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),I&&K(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),Error(\"bad memory\");he(),Fe=ve.buffer.byteLength;var Ze=[],Re=[],Ge=[],Ke=0;function ot(){return ee||0<Ke}var Je=0,_t=null,Ct=null;function jt(){Je++,a.monitorRunDependencies&&a.monitorRunDependencies(Je)}function wr(){if(Je--,a.monitorRunDependencies&&a.monitorRunDependencies(Je),Je==0&&(_t!==null&&(clearInterval(_t),_t=null),Ct)){var i=Ct;Ct=null,i()}}function tt(i){throw a.onAbort&&a.onAbort(i),i=\"Aborted(\"+i+\")\",K(i),Ce=!0,fe=1,i=new WebAssembly.RuntimeError(i+\". Build with -sASSERTIONS for more info.\"),h(i),i}function Kt(i){return i.startsWith(\"data:application/octet-stream;base64,\")}var Me;Me=\"ort-wasm-simd-threaded.wasm\",Kt(Me)||(Me=O(Me));function Rt(i){if(i==Me&&pe)return new Uint8Array(pe);if(A)return A(i);throw\"both async and sync fetching of the wasm failed\"}function Yt(i){if(!pe&&(b||_)){if(typeof fetch==\"function\"&&!i.startsWith(\"file://\"))return fetch(i,{credentials:\"same-origin\"}).then(c=>{if(!c.ok)throw\"failed to load wasm binary file at '\"+i+\"'\";return c.arrayBuffer()}).catch(()=>Rt(i));if(M)return new Promise((c,f)=>{M(i,$=>c(new Uint8Array($)),f)})}return Promise.resolve().then(()=>Rt(i))}function ht(i,c,f){return Yt(i).then($=>WebAssembly.instantiate($,c)).then($=>$).then(f,$=>{K(\"failed to asynchronously prepare wasm: \"+$),tt($)})}function vr(i,c){var f=Me;return pe||typeof WebAssembly.instantiateStreaming!=\"function\"||Kt(f)||f.startsWith(\"file://\")||I||typeof fetch!=\"function\"?ht(f,i,c):fetch(f,{credentials:\"same-origin\"}).then($=>WebAssembly.instantiateStreaming($,i).then(c,function(E){return K(\"wasm streaming compile failed: \"+E),K(\"falling back to ArrayBuffer instantiation\"),ht(f,i,c)}))}var gt,Bt={924476:i=>{a.Ea(\"Abs\",i,void 0)},924527:i=>{a.Ea(\"Neg\",i,void 0)},924578:i=>{a.Ea(\"Floor\",i,void 0)},924631:i=>{a.Ea(\"Ceil\",i,void 0)},924683:i=>{a.Ea(\"Reciprocal\",i,void 0)},924741:i=>{a.Ea(\"Sqrt\",i,void 0)},924793:i=>{a.Ea(\"Exp\",i,void 0)},924844:i=>{a.Ea(\"Erf\",i,void 0)},924895:i=>{a.Ea(\"Sigmoid\",i,void 0)},924950:i=>{a.Ea(\"Log\",i,void 0)},925001:i=>{a.Ea(\"Sin\",i,void 0)},925052:i=>{a.Ea(\"Cos\",i,void 0)},925103:i=>{a.Ea(\"Tan\",i,void 0)},925154:i=>{a.Ea(\"Asin\",i,void 0)},925206:i=>{a.Ea(\"Acos\",i,void 0)},925258:i=>{a.Ea(\"Atan\",i,void 0)},925310:i=>{a.Ea(\"Sinh\",i,void 0)},925362:i=>{a.Ea(\"Cosh\",i,void 0)},925414:i=>{a.Ea(\"Asinh\",i,void 0)},925467:i=>{a.Ea(\"Acosh\",i,void 0)},925520:i=>{a.Ea(\"Atanh\",i,void 0)},925573:i=>{a.Ea(\"Tanh\",i,void 0)},925625:i=>{a.Ea(\"Not\",i,void 0)},925676:(i,c,f)=>{a.Ea(\"Clip\",i,{min:c,max:f})},925745:i=>{a.Ea(\"Clip\",i,void 0)},925797:(i,c)=>{a.Ea(\"Elu\",i,{alpha:c})},925855:i=>{a.Ea(\"Relu\",i,void 0)},925907:(i,c)=>{a.Ea(\"LeakyRelu\",i,{alpha:c})},925971:(i,c)=>{a.Ea(\"ThresholdedRelu\",i,{alpha:c})},926041:(i,c)=>{a.Ea(\"Cast\",i,{to:c})},926099:i=>{a.Ea(\"Add\",i,void 0)},926150:i=>{a.Ea(\"Sub\",i,void 0)},926201:i=>{a.Ea(\"Mul\",i,void 0)},926252:i=>{a.Ea(\"Div\",i,void 0)},926303:i=>{a.Ea(\"Pow\",i,void 0)},926354:i=>{a.Ea(\"Equal\",i,void 0)},926407:i=>{a.Ea(\"Greater\",i,void 0)},926462:i=>{a.Ea(\"GreaterOrEqual\",i,void 0)},926524:i=>{a.Ea(\"Less\",i,void 0)},926576:i=>{a.Ea(\"LessOrEqual\",i,void 0)},926635:(i,c,f,$,E)=>{a.Ea(\"ReduceMean\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},926799:(i,c,f,$,E)=>{a.Ea(\"ReduceMax\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},926962:(i,c,f,$,E)=>{a.Ea(\"ReduceMin\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},927125:(i,c,f,$,E)=>{a.Ea(\"ReduceProd\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},927289:(i,c,f,$,E)=>{a.Ea(\"ReduceSum\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},927452:(i,c,f,$,E)=>{a.Ea(\"ReduceL1\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},927614:(i,c,f,$,E)=>{a.Ea(\"ReduceL2\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},927776:(i,c,f,$,E)=>{a.Ea(\"ReduceLogSum\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},927942:(i,c,f,$,E)=>{a.Ea(\"ReduceSumSquare\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},928111:(i,c,f,$,E)=>{a.Ea(\"ReduceLogSumExp\",i,{keepDims:!!c,noopWithEmptyAxes:!!f,axes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},928280:i=>{a.Ea(\"Where\",i,void 0)},928333:(i,c,f)=>{a.Ea(\"Transpose\",i,{perm:c?Array.from(n().subarray(f>>>0,f+c>>>0)):[]})},928446:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae,R,me)=>{a.Ea(\"ConvTranspose\",i,{format:re?\"NHWC\":\"NCHW\",autoPad:c,dilations:[f],group:$,kernel_shape:[E],pads:[D,N],strides:[ie],wIsConst:()=>!!r()[ne>>>0],outputPadding:ue?Array.from(n().subarray(_e>>>0,_e+ue>>>0)):[],outputShape:Ae?Array.from(n().subarray(R>>>0,R+Ae>>>0)):[],activation:qe(me)})},928860:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae,R)=>{a.Ea(\"ConvTranspose\",i,{format:ie?\"NHWC\":\"NCHW\",autoPad:c,dilations:Array.from(n().subarray(f>>>0,f+2>>>0)),group:$,kernelShape:Array.from(n().subarray(E>>>0,E+2>>>0)),pads:Array.from(n().subarray(D>>>0,D+4>>>0)),strides:Array.from(n().subarray(N>>>0,N+2>>>0)),wIsConst:()=>!!r()[re>>>0],outputPadding:0<ne?Array.from(n().subarray(ue>>>0,ue+ne>>>0)):[],outputShape:0<_e?Array.from(n().subarray(Ae>>>0,Ae+_e>>>0)):[],activation:qe(R)})},929417:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae,R,me)=>{a.Ea(\"ConvTranspose\",i,{format:re?\"NHWC\":\"NCHW\",autoPad:c,dilations:[f],group:$,kernel_shape:[E],pads:[D,N],strides:[ie],wIsConst:()=>!!r()[ne>>>0],outputPadding:ue?Array.from(n().subarray(_e>>>0,_e+ue>>>0)):[],outputShape:Ae?Array.from(n().subarray(R>>>0,R+Ae>>>0)):[],activation:qe(me)})},929831:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae,R)=>{a.Ea(\"ConvTranspose\",i,{format:ie?\"NHWC\":\"NCHW\",autoPad:c,dilations:Array.from(n().subarray(f>>>0,f+2>>>0)),group:$,kernelShape:Array.from(n().subarray(E>>>0,E+2>>>0)),pads:Array.from(n().subarray(D>>>0,D+4>>>0)),strides:Array.from(n().subarray(N>>>0,N+2>>>0)),wIsConst:()=>!!r()[re>>>0],outputPadding:0<ne?Array.from(n().subarray(ue>>>0,ue+ne>>>0)):[],outputShape:0<_e?Array.from(n().subarray(Ae>>>0,Ae+_e>>>0)):[],activation:qe(R)})},930388:(i,c)=>{a.Ea(\"GlobalAveragePool\",i,{format:c?\"NHWC\":\"NCHW\"})},930479:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae,R,me,Ie)=>{a.Ea(\"AveragePool\",i,{format:Ie?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:f,count_include_pad:$,storage_order:E,dilations:[D,N],kernel_shape:[ie,re],pads:[ne,ue,_e,Ae],strides:[R,me]})},930763:(i,c)=>{a.Ea(\"GlobalAveragePool\",i,{format:c?\"NHWC\":\"NCHW\"})},930854:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae,R,me,Ie)=>{a.Ea(\"AveragePool\",i,{format:Ie?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:f,count_include_pad:$,storage_order:E,dilations:[D,N],kernel_shape:[ie,re],pads:[ne,ue,_e,Ae],strides:[R,me]})},931138:(i,c)=>{a.Ea(\"GlobalMaxPool\",i,{format:c?\"NHWC\":\"NCHW\"})},931225:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae,R,me,Ie)=>{a.Ea(\"MaxPool\",i,{format:Ie?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:f,count_include_pad:$,storage_order:E,dilations:[D,N],kernel_shape:[ie,re],pads:[ne,ue,_e,Ae],strides:[R,me]})},931505:(i,c)=>{a.Ea(\"GlobalMaxPool\",i,{format:c?\"NHWC\":\"NCHW\"})},931592:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae,R,me,Ie)=>{a.Ea(\"MaxPool\",i,{format:Ie?\"NHWC\":\"NCHW\",auto_pad:c,ceil_mode:f,count_include_pad:$,storage_order:E,dilations:[D,N],kernel_shape:[ie,re],pads:[ne,ue,_e,Ae],strides:[R,me]})},931872:(i,c,f,$,E)=>{a.Ea(\"Gemm\",i,{alpha:c,beta:f,transA:$,transB:E})},931976:i=>{a.Ea(\"MatMul\",i,void 0)},932030:(i,c,f,$)=>{a.Ea(\"ArgMax\",i,{keepDims:!!c,selectLastIndex:!!f,axis:$})},932138:(i,c,f,$)=>{a.Ea(\"ArgMin\",i,{keepDims:!!c,selectLastIndex:!!f,axis:$})},932246:(i,c)=>{a.Ea(\"Softmax\",i,{axis:c})},932309:(i,c)=>{a.Ea(\"Concat\",i,{axis:c})},932369:(i,c,f,$,E)=>{a.Ea(\"Split\",i,{axis:c,numOutputs:f,splitSizes:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},932514:i=>{a.Ea(\"Expand\",i,void 0)},932568:(i,c)=>{a.Ea(\"Gather\",i,{axis:Number(c)})},932639:(i,c)=>{a.Ea(\"GatherElements\",i,{axis:Number(c)})},932718:(i,c,f,$,E,D,N,ie,re,ne,ue)=>{a.Ea(\"Resize\",i,{antialias:c,axes:f?Array.from(n().subarray($>>>0,$+f>>>0)):[],coordinateTransformMode:qe(E),cubicCoeffA:D,excludeOutside:N,extrapolationValue:ie,keepAspectRatioPolicy:qe(re),mode:qe(ne),nearestMode:qe(ue)})},933069:(i,c,f,$,E,D,N)=>{a.Ea(\"Slice\",i,{starts:c?Array.from(n().subarray(f>>>0,f+c>>>0)):[],ends:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[],axes:D?Array.from(n().subarray(N>>>0,N+D>>>0)):[]})},933300:i=>{a.Ea(\"Tile\",i,void 0)},933352:(i,c,f)=>{a.Ea(\"LayerNormalization\",i,{axis:Number(c),epsilon:Number(f)})},933459:(i,c,f)=>{a.Ea(\"InstanceNormalization\",i,{epsilon:c,format:f?\"NHWC\":\"NCHW\"})},933573:(i,c,f)=>{a.Ea(\"InstanceNormalization\",i,{epsilon:c,format:f?\"NHWC\":\"NCHW\"})},933687:i=>{a.Ea(\"Range\",i,void 0)},933740:(i,c)=>{a.Ea(\"Einsum\",i,{equation:qe(c)})},933821:(i,c,f,$,E)=>{a.Ea(\"Pad\",i,{mode:c,value:f,pads:$?Array.from(n().subarray(E>>>0,E+$>>>0)):[]})},933953:(i,c,f,$,E,D)=>{a.Ea(\"BatchNormalization\",i,{epsilon:c,momentum:f,spatial:!!E,trainingMode:!!$,format:D?\"NHWC\":\"NCHW\"})},934122:(i,c,f,$,E,D)=>{a.Ea(\"BatchNormalization\",i,{epsilon:c,momentum:f,spatial:!!E,trainingMode:!!$,format:D?\"NHWC\":\"NCHW\"})},934291:(i,c,f)=>{a.Ea(\"CumSum\",i,{exclusive:Number(c),reverse:Number(f)})},934388:(i,c,f,$,E,D,N,ie,re)=>{a.Ea(\"Attention\",i,{numHeads:c,isUnidirectional:f,maskFilterValue:$,scale:E,doRotary:D,qkvHiddenSizes:N?Array.from(n().subarray(Number(ie)>>>0,Number(ie)+N>>>0)):[],pastPresentShareBuffer:!!re})},934660:i=>{a.Ea(\"Gelu\",i,void 0)},934712:(i,c,f,$,E,D)=>{a.Ea(\"MultiHeadAttention\",i,{numHeads:c,isUnidirectional:f,maskFilterValue:$,scale:E,doRotary:D})},934871:i=>{a.Ea(\"BiasAdd\",i,void 0)},934926:i=>{a.Ea(\"BiasSplitGelu\",i,void 0)},934987:(i,c)=>{a.Ea(\"SkipLayerNormalization\",i,{epsilon:c})},935068:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae)=>{a.Ea(\"Conv\",i,{format:re?\"NHWC\":\"NCHW\",auto_pad:c,dilations:[f],group:$,kernel_shape:[E],pads:D?Array.from(n().subarray(N>>>0,N+D>>>0)):[],strides:[ie],w_is_const:()=>!!r()[ne>>>0],activation:qe(ue),activation_params:_e?Array.from(u().subarray(Ae>>>0,Ae+_e>>>0)):[]})},935449:(i,c,f,$,E,D,N,ie,re,ne,ue,_e,Ae,R,me,Ie)=>{a.Ea(\"Conv\",i,{format:_e?\"NHWC\":\"NCHW\",auto_pad:c,dilations:[f,$],group:E,kernel_shape:[D,N],pads:ie?Array.from(n().subarray(re>>>0,re+ie>>>0)):[],strides:[ne,ue],w_is_const:()=>!!r()[Ae>>>0],activation:qe(R),activation_params:me?Array.from(u().subarray(Ie>>>0,Ie+me>>>0)):[]})},935851:i=>{a.Ab(i)},935885:(i,c)=>a.Bb(i,c,a.bb.Fb,a.bb.errors),935997:i=>a.xb(i),936030:i=>a.zb(i),936062:(i,c,f)=>{a.kb(i,c,f,!0)},936101:(i,c,f)=>{a.kb(i,c,f)}};function wt(i){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${i})`,this.status=i}function Dt(i){i.terminate(),i.onmessage=()=>{}}function Mt(i){(i=oe.Qa[i])||tt(),oe.Eb(i)}function Zt(i){var c=oe.ub();if(!c)return 6;oe.Za.push(c),oe.Qa[i.Xa]=c,c.Xa=i.Xa;var f={cmd:\"run\",start_routine:i.Gb,arg:i.sb,pthread_ptr:i.Xa};return I&&c.unref(),c.postMessage(f,i.Mb),0}var zt=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,$r=(i,c,f)=>{c>>>=0;var $=c+f;for(f=c;i[f]&&!(f>=$);)++f;if(16<f-c&&i.buffer&&zt)return zt.decode(i.buffer instanceof SharedArrayBuffer?i.slice(c,f):i.subarray(c,f));for($=\"\";c<f;){var E=i[c++];if(E&128){var D=i[c++]&63;if((E&224)==192)$+=String.fromCharCode((E&31)<<6|D);else{var N=i[c++]&63;E=(E&240)==224?(E&15)<<12|D<<6|N:(E&7)<<18|D<<12|N<<6|i[c++]&63,65536>E?$+=String.fromCharCode(E):(E-=65536,$+=String.fromCharCode(55296|E>>10,56320|E&1023))}}else $+=String.fromCharCode(E)}return $},qe=(i,c)=>(i>>>=0)?$r(o(),i,c):\"\";function Xt(i){if(S)return H(1,1,i);fe=i,ot()||(oe.Hb(),a.onExit&&a.onExit(i),Ce=!0),w(i,new wt(i))}var Qt=i=>{if(fe=i,S)throw Sr(i),\"unwind\";Xt(i)},oe={Ya:[],Za:[],ob:[],Qa:{},gb:function(){S?oe.wb():oe.vb()},vb:function(){for(var i=a.numThreads;i--;)oe.jb();Ze.unshift(()=>{jt(),oe.Cb(()=>wr())})},wb:function(){oe.receiveObjectTransfer=oe.Db,oe.threadInitTLS=oe.nb,oe.setExitStatus=oe.mb,ee=!1},mb:function(i){fe=i},Sb:[\"$terminateWorker\"],Hb:function(){for(var i of oe.Za)Dt(i);for(i of oe.Ya)Dt(i);oe.Ya=[],oe.Za=[],oe.Qa=[]},Eb:function(i){var c=i.Xa;delete oe.Qa[c],oe.Ya.push(i),oe.Za.splice(oe.Za.indexOf(i),1),i.Xa=0,pn(c)},Db:function(){},nb:function(){oe.ob.forEach(i=>i())},lb:i=>new Promise(c=>{i.onmessage=D=>{D=D.data;var N=D.cmd;if(D.targetThread&&D.targetThread!=Rr()){var ie=oe.Qa[D.Rb];ie?ie.postMessage(D,D.transferList):K('Internal error! Worker sent a message \"'+N+'\" to target pthread '+D.targetThread+\", but that thread no longer exists!\")}else N===\"checkMailbox\"?Tt():N===\"spawnThread\"?Zt(D):N===\"cleanupThread\"?Mt(D.thread):N===\"killThread\"?(D=D.thread,N=oe.Qa[D],delete oe.Qa[D],Dt(N),pn(D),oe.Za.splice(oe.Za.indexOf(N),1),N.Xa=0):N===\"cancelThread\"?oe.Qa[D.thread].postMessage({cmd:\"cancel\"}):N===\"loaded\"?(i.loaded=!0,I&&!i.Xa&&i.unref(),c(i)):N===\"alert\"?alert(\"Thread \"+D.threadId+\": \"+D.text):D.target===\"setimmediate\"?i.postMessage(D):N===\"callHandler\"?a[D.handler](...D.args):N&&K(\"worker sent an unknown command \"+N)},i.onerror=D=>{throw K(\"worker sent an error! \"+D.filename+\":\"+D.lineno+\": \"+D.message),D},I&&(i.on(\"message\",function(D){i.onmessage({data:D})}),i.on(\"error\",function(D){i.onerror(D)}));var f=[],$=[\"onExit\",\"onAbort\",\"print\",\"printErr\"],E;for(E of $)a.hasOwnProperty(E)&&f.push(E);i.postMessage({cmd:\"load\",handlers:f,urlOrBlob:a.mainScriptUrlOrBlob||e,wasmMemory:ve,wasmModule:be})}),Cb:function(i){if(S)return i();Promise.all(oe.Ya.map(oe.lb)).then(i)},jb:function(){var i=O(\"ort-wasm-simd-threaded.worker.js\");i=new Worker(i),oe.Ya.push(i)},ub:function(){return oe.Ya.length==0&&(oe.jb(),oe.lb(oe.Ya[0])),oe.Ya.pop()}};a.PThread=oe;var yt=i=>{for(;0<i.length;)i.shift()(a)};a.establishStackSpace=function(){var i=Rr(),c=n()[i+52>>2>>>0];i=n()[i+56>>2>>>0],mo(c,c-i),Br(c)};function Sr(i){if(S)return H(2,0,i);Qt(i)}a.invokeEntryPoint=function(i,c){i=fo.apply(null,[i,c]),ot()?oe.mb(i):mn(i)};function at(i){this.fb=i-24,this.rb=function(c){s()[this.fb+4>>2>>>0]=c},this.qb=function(c){s()[this.fb+8>>2>>>0]=c},this.gb=function(c,f){this.pb(),this.rb(c),this.qb(f)},this.pb=function(){s()[this.fb+16>>2>>>0]=0}}var et=0,xr=0;function It(i,c,f,$){return S?H(3,1,i,c,f,$):Jt(i,c,f,$)}function Jt(i,c,f,$){if(i>>>=0,c>>>=0,f>>>=0,$>>>=0,typeof SharedArrayBuffer>\"u\")return K(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var E=[];return S&&E.length===0?It(i,c,f,$):(i={Gb:f,Xa:i,sb:$,Mb:E},S?(i.Ob=\"spawnThread\",postMessage(i,E),0):Zt(i))}function er(i,c,f){return S?H(4,1,i,c,f):0}function _r(i,c){if(S)return H(5,1,i,c)}var At=i=>{for(var c=0,f=0;f<i.length;++f){var $=i.charCodeAt(f);127>=$?c++:2047>=$?c+=2:55296<=$&&57343>=$?(c+=4,++f):c+=3}return c},Cr=(i,c,f,$)=>{if(f>>>=0,!(0<$))return 0;var E=f;$=f+$-1;for(var D=0;D<i.length;++D){var N=i.charCodeAt(D);if(55296<=N&&57343>=N){var ie=i.charCodeAt(++D);N=65536+((N&1023)<<10)|ie&1023}if(127>=N){if(f>=$)break;c[f++>>>0]=N}else{if(2047>=N){if(f+1>=$)break;c[f++>>>0]=192|N>>6}else{if(65535>=N){if(f+2>=$)break;c[f++>>>0]=224|N>>12}else{if(f+3>=$)break;c[f++>>>0]=240|N>>18,c[f++>>>0]=128|N>>12&63}c[f++>>>0]=128|N>>6&63}c[f++>>>0]=128|N&63}}return c[f>>>0]=0,f-E},Ir=(i,c,f)=>Cr(i,o(),c,f);function Ar(i,c){if(S)return H(6,1,i,c)}function Tr(i,c,f){if(S)return H(7,1,i,c,f)}function Er(i,c,f){return S?H(8,1,i,c,f):0}function Or(i,c){if(S)return H(9,1,i,c)}function Ut(i,c,f){if(S)return H(10,1,i,c,f)}function tr(i,c,f,$){if(S)return H(11,1,i,c,f,$)}function rr(i,c,f,$){if(S)return H(12,1,i,c,f,$)}function nr(i,c,f,$){if(S)return H(13,1,i,c,f,$)}function or(i){if(S)return H(14,1,i)}function ar(i,c){if(S)return H(15,1,i,c)}function ir(i,c,f){if(S)return H(16,1,i,c,f)}var sr=i=>{if(!Ce)try{if(i(),!ot())try{S?mn(fe):Qt(fe)}catch(c){c instanceof wt||c==\"unwind\"||w(1,c)}}catch(c){c instanceof wt||c==\"unwind\"||w(1,c)}};function Vt(i){i>>>=0,typeof Atomics.Nb==\"function\"&&(Atomics.Nb(n(),i>>2,i).value.then(Tt),i+=128,Atomics.store(n(),i>>2,1))}a.__emscripten_thread_mailbox_await=Vt;function Tt(){var i=Rr();i&&(Vt(i),sr(()=>co()))}a.checkMailbox=Tt;var vt=i=>i%4===0&&(i%100!==0||i%400===0),Et=[0,31,60,91,121,152,182,213,244,274,305,335],ur=[0,31,59,90,120,151,181,212,243,273,304,334];function l(i,c,f,$,E,D,N,ie){return S?H(17,1,i,c,f,$,E,D,N,ie):-52}function m(i,c,f,$,E,D,N){if(S)return H(18,1,i,c,f,$,E,D,N)}var v=i=>{var c=At(i)+1,f=cn(c);return f&&Ir(i,f,c),f},C=[],P=(i,c)=>{C.length=0;var f;for(c>>=2;f=o()[i++>>>0];)c+=f!=105&c,C.push(f==105?n()[c>>>0]:d()[c++>>>1]),++c;return C},F=i=>{var c=fn();return i=i(),Br(c),i};function H(i,c){var f=arguments.length-2,$=arguments;return F(()=>{for(var E=hn(8*f),D=E>>3,N=0;N<f;N++){var ie=$[2+N];d()[D+N>>>0]=ie}return lo(i,f,E,c)})}var le=[],Q={},ae=()=>{if(!te){var i={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:y||\"./this.program\"},c;for(c in Q)Q[c]===void 0?delete i[c]:i[c]=Q[c];var f=[];for(c in i)f.push(`${c}=${i[c]}`);te=f}return te},te;function ye(i,c){if(S)return H(19,1,i,c);i>>>=0,c>>>=0;var f=0;return ae().forEach(function($,E){var D=c+f;for(E=s()[i+4*E>>2>>>0]=D,D=0;D<$.length;++D)r()[E++>>0>>>0]=$.charCodeAt(D);r()[E>>0>>>0]=0,f+=$.length+1}),0}function xe(i,c){if(S)return H(20,1,i,c);i>>>=0,c>>>=0;var f=ae();s()[i>>2>>>0]=f.length;var $=0;return f.forEach(function(E){$+=E.length+1}),s()[c>>2>>>0]=$,0}function k(i){return S?H(21,1,i):52}function se(i,c,f,$){return S?H(22,1,i,c,f,$):52}function $e(i,c,f,$,E){return S?H(23,1,i,c,f,$,E):70}var bt=[null,[],[]];function lr(i,c,f,$){if(S)return H(24,1,i,c,f,$);c>>>=0,f>>>=0,$>>>=0;for(var E=0,D=0;D<f;D++){var N=s()[c>>2>>>0],ie=s()[c+4>>2>>>0];c+=8;for(var re=0;re<ie;re++){var ne=o()[N+re>>>0],ue=bt[i];ne===0||ne===10?((i===1?B:K)($r(ue,0)),ue.length=0):ue.push(ne)}E+=ie}return s()[$>>2>>>0]=E,0}var to=[31,29,31,30,31,30,31,31,30,31,30,31],ro=[31,28,31,30,31,30,31,31,30,31,30,31];function Au(i){var c=Array(At(i)+1);return Cr(i,c,0,c.length),c}var Tu=(i,c)=>{r().set(i,c>>>0)};function no(i,c,f,$){function E(R,me,Ie){for(R=typeof R==\"number\"?R.toString():R||\"\";R.length<me;)R=Ie[0]+R;return R}function D(R,me){return E(R,me,\"0\")}function N(R,me){function Ie(vo){return 0>vo?-1:0<vo?1:0}var Ot;return(Ot=Ie(R.getFullYear()-me.getFullYear()))===0&&(Ot=Ie(R.getMonth()-me.getMonth()))===0&&(Ot=Ie(R.getDate()-me.getDate())),Ot}function ie(R){switch(R.getDay()){case 0:return new Date(R.getFullYear()-1,11,29);case 1:return R;case 2:return new Date(R.getFullYear(),0,3);case 3:return new Date(R.getFullYear(),0,2);case 4:return new Date(R.getFullYear(),0,1);case 5:return new Date(R.getFullYear()-1,11,31);case 6:return new Date(R.getFullYear()-1,11,30)}}function re(R){var me=R.$a;for(R=new Date(new Date(R.ab+1900,0,1).getTime());0<me;){var Ie=R.getMonth(),Ot=(vt(R.getFullYear())?to:ro)[Ie];if(me>Ot-R.getDate())me-=Ot-R.getDate()+1,R.setDate(1),11>Ie?R.setMonth(Ie+1):(R.setMonth(0),R.setFullYear(R.getFullYear()+1));else{R.setDate(R.getDate()+me);break}}return Ie=new Date(R.getFullYear()+1,0,4),me=ie(new Date(R.getFullYear(),0,4)),Ie=ie(Ie),0>=N(me,R)?0>=N(Ie,R)?R.getFullYear()+1:R.getFullYear():R.getFullYear()-1}i>>>=0,c>>>=0,f>>>=0,$>>>=0;var ne=n()[$+40>>2>>>0];$={Kb:n()[$>>2>>>0],Jb:n()[$+4>>2>>>0],cb:n()[$+8>>2>>>0],ib:n()[$+12>>2>>>0],eb:n()[$+16>>2>>>0],ab:n()[$+20>>2>>>0],Wa:n()[$+24>>2>>>0],$a:n()[$+28>>2>>>0],Tb:n()[$+32>>2>>>0],Ib:n()[$+36>>2>>>0],Lb:ne?qe(ne):\"\"},f=qe(f),ne={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var ue in ne)f=f.replace(new RegExp(ue,\"g\"),ne[ue]);var _e=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),Ae=\"January February March April May June July August September October November December\".split(\" \");ne={\"%a\":R=>_e[R.Wa].substring(0,3),\"%A\":R=>_e[R.Wa],\"%b\":R=>Ae[R.eb].substring(0,3),\"%B\":R=>Ae[R.eb],\"%C\":R=>D((R.ab+1900)/100|0,2),\"%d\":R=>D(R.ib,2),\"%e\":R=>E(R.ib,2,\" \"),\"%g\":R=>re(R).toString().substring(2),\"%G\":R=>re(R),\"%H\":R=>D(R.cb,2),\"%I\":R=>(R=R.cb,R==0?R=12:12<R&&(R-=12),D(R,2)),\"%j\":R=>{for(var me=0,Ie=0;Ie<=R.eb-1;me+=(vt(R.ab+1900)?to:ro)[Ie++]);return D(R.ib+me,3)},\"%m\":R=>D(R.eb+1,2),\"%M\":R=>D(R.Jb,2),\"%n\":()=>`\n`,\"%p\":R=>0<=R.cb&&12>R.cb?\"AM\":\"PM\",\"%S\":R=>D(R.Kb,2),\"%t\":()=>\"\t\",\"%u\":R=>R.Wa||7,\"%U\":R=>D(Math.floor((R.$a+7-R.Wa)/7),2),\"%V\":R=>{var me=Math.floor((R.$a+7-(R.Wa+6)%7)/7);if(2>=(R.Wa+371-R.$a-2)%7&&me++,me)me==53&&(Ie=(R.Wa+371-R.$a)%7,Ie==4||Ie==3&&vt(R.ab)||(me=1));else{me=52;var Ie=(R.Wa+7-R.$a-1)%7;(Ie==4||Ie==5&&vt(R.ab%400-1))&&me++}return D(me,2)},\"%w\":R=>R.Wa,\"%W\":R=>D(Math.floor((R.$a+7-(R.Wa+6)%7)/7),2),\"%y\":R=>(R.ab+1900).toString().substring(2),\"%Y\":R=>R.ab+1900,\"%z\":R=>{R=R.Ib;var me=0<=R;return R=Math.abs(R)/60,(me?\"+\":\"-\")+(\"0000\"+(R/60*100+R%60)).slice(-4)},\"%Z\":R=>R.Lb,\"%%\":()=>\"%\"},f=f.replace(/%%/g,\"\\0\\0\");for(ue in ne)f.includes(ue)&&(f=f.replace(new RegExp(ue,\"g\"),ne[ue]($)));return f=f.replace(/\\0\\0/g,\"%\"),ue=Au(f),ue.length>c?0:(Tu(ue,i),ue.length-1)}function Pr(i){try{i()}catch(c){tt(c)}}function Eu(i){var c={},f;for(f in i)(function($){var E=i[$];c[$]=typeof E==\"function\"?function(){kr.push($);try{return E.apply(null,arguments)}finally{Ce||(kr.pop()===$||tt(),it&&$t===1&&kr.length===0&&($t=0,Ke+=1,Pr(go),typeof Fibers<\"u\"&&Fibers.Ub()))}}:E})(f);return c}var $t=0,it=null,oo=0,kr=[],ao={},io={},Ou=0,dn=null,Pu=[];function ku(){return new Promise((i,c)=>{dn={resolve:i,reject:c}})}function Ru(){var i=cn(65548),c=i+12;s()[i>>2>>>0]=c,s()[i+4>>2>>>0]=c+65536,c=kr[0];var f=ao[c];return f===void 0&&(f=Ou++,ao[c]=f,io[f]=c),c=f,n()[i+8>>2>>>0]=c,i}function Bu(){var i=n()[it+8>>2>>>0];return i=Z[io[i]],--Ke,i()}function Du(i){if(!Ce){if($t===0){var c=!1,f=!1;i(($=0)=>{if(!Ce&&(oo=$,c=!0,f)){$t=2,Pr(()=>yo(it)),typeof Browser<\"u\"&&Browser.hb.tb&&Browser.hb.resume(),$=!1;try{var E=Bu()}catch(ie){E=ie,$=!0}var D=!1;if(!it){var N=dn;N&&(dn=null,($?N.reject:N.resolve)(E),D=!0)}if($&&!D)throw E}}),f=!0,c||($t=1,it=Ru(),typeof Browser<\"u\"&&Browser.hb.tb&&Browser.hb.pause(),Pr(()=>ho(it)))}else $t===2?($t=0,Pr(bo),so(it),it=null,Pu.forEach($=>sr($))):tt(`invalid state: ${$t}`);return oo}}function Mu(i){return Du(c=>{i().then(c)})}oe.gb();var zu=[null,Xt,Sr,It,er,_r,Ar,Tr,Er,Or,Ut,tr,rr,nr,or,ar,ir,l,m,ye,xe,k,se,$e,lr],Uu={r:function(i,c,f){return Mu(async()=>{await a.yb(i,c,f)})},b:function(i,c,f){throw i>>>=0,new at(i).gb(c>>>0,f>>>0),et=i,xr++,et},O:function(i){uo(i>>>0,!_,1,!b,131072,!1),oe.nb()},l:function(i){i>>>=0,S?postMessage({cmd:\"cleanupThread\",thread:i}):Mt(i)},I:Jt,i:er,U:_r,E:Ar,G:Tr,V:Er,S:Or,K:Ut,R:tr,p:rr,F:nr,C:or,T:ar,D:ir,q:()=>!0,A:function(i,c){i>>>=0,i==c>>>0?setTimeout(()=>Tt()):S?postMessage({targetThread:i,cmd:\"checkMailbox\"}):(i=oe.Qa[i])&&i.postMessage({cmd:\"checkMailbox\"})},M:function(){return-1},N:Vt,X:function(i){I&&oe.Qa[i>>>0].ref()},u:function(i,c,f){i=c+2097152>>>0<4194305-!!i?(i>>>0)+4294967296*c:NaN,f>>>=0,i=new Date(1e3*i),n()[f>>2>>>0]=i.getUTCSeconds(),n()[f+4>>2>>>0]=i.getUTCMinutes(),n()[f+8>>2>>>0]=i.getUTCHours(),n()[f+12>>2>>>0]=i.getUTCDate(),n()[f+16>>2>>>0]=i.getUTCMonth(),n()[f+20>>2>>>0]=i.getUTCFullYear()-1900,n()[f+24>>2>>>0]=i.getUTCDay(),i=(i.getTime()-Date.UTC(i.getUTCFullYear(),0,1,0,0,0,0))/864e5|0,n()[f+28>>2>>>0]=i},v:function(i,c,f){i=c+2097152>>>0<4194305-!!i?(i>>>0)+4294967296*c:NaN,f>>>=0,i=new Date(1e3*i),n()[f>>2>>>0]=i.getSeconds(),n()[f+4>>2>>>0]=i.getMinutes(),n()[f+8>>2>>>0]=i.getHours(),n()[f+12>>2>>>0]=i.getDate(),n()[f+16>>2>>>0]=i.getMonth(),n()[f+20>>2>>>0]=i.getFullYear()-1900,n()[f+24>>2>>>0]=i.getDay(),c=(vt(i.getFullYear())?Et:ur)[i.getMonth()]+i.getDate()-1|0,n()[f+28>>2>>>0]=c,n()[f+36>>2>>>0]=-(60*i.getTimezoneOffset()),c=new Date(i.getFullYear(),6,1).getTimezoneOffset();var $=new Date(i.getFullYear(),0,1).getTimezoneOffset();i=(c!=$&&i.getTimezoneOffset()==Math.min($,c))|0,n()[f+32>>2>>>0]=i},w:function(i){i>>>=0;var c=new Date(n()[i+20>>2>>>0]+1900,n()[i+16>>2>>>0],n()[i+12>>2>>>0],n()[i+8>>2>>>0],n()[i+4>>2>>>0],n()[i>>2>>>0],0),f=n()[i+32>>2>>>0],$=c.getTimezoneOffset(),E=new Date(c.getFullYear(),6,1).getTimezoneOffset(),D=new Date(c.getFullYear(),0,1).getTimezoneOffset(),N=Math.min(D,E);return 0>f?n()[i+32>>2>>>0]=+(E!=D&&N==$):0<f!=(N==$)&&(E=Math.max(D,E),c.setTime(c.getTime()+6e4*((0<f?N:E)-$))),n()[i+24>>2>>>0]=c.getDay(),f=(vt(c.getFullYear())?Et:ur)[c.getMonth()]+c.getDate()-1|0,n()[i+28>>2>>>0]=f,n()[i>>2>>>0]=c.getSeconds(),n()[i+4>>2>>>0]=c.getMinutes(),n()[i+8>>2>>>0]=c.getHours(),n()[i+12>>2>>>0]=c.getDate(),n()[i+16>>2>>>0]=c.getMonth(),n()[i+20>>2>>>0]=c.getYear(),i=c.getTime()/1e3,po((gt=i,1<=+Math.abs(gt)?0<gt?+Math.floor(gt/4294967296)>>>0:~~+Math.ceil((gt-+(~~gt>>>0))/4294967296)>>>0:0)),i>>>0},s:l,t:m,z:function(i,c,f){function $(ne){return(ne=ne.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?ne[1]:\"GMT\"}i>>>=0,c>>>=0,f>>>=0;var E=new Date().getFullYear(),D=new Date(E,0,1),N=new Date(E,6,1);E=D.getTimezoneOffset();var ie=N.getTimezoneOffset(),re=Math.max(E,ie);s()[i>>2>>>0]=60*re,n()[c>>2>>>0]=+(E!=ie),i=$(D),c=$(N),i=v(i),c=v(c),ie<E?(s()[f>>2>>>0]=i,s()[f+4>>2>>>0]=c):(s()[f>>2>>>0]=c,s()[f+4>>2>>>0]=i)},d:()=>{tt(\"\")},c:function(i,c,f){return i>>>=0,c=P(c>>>0,f>>>0),Bt[i].apply(null,c)},k:function(i,c,f){return i>>>=0,c=P(c>>>0,f>>>0),Bt[i].apply(null,c)},m:function(){},j:function(){return Date.now()},W:()=>{throw Ke+=1,\"unwind\"},B:function(){return 4294901760},f:()=>performance.timeOrigin+performance.now(),g:function(){return I?(Ao(),Wt(Io)).cpus().length:navigator.hardwareConcurrency},L:function(i,c,f,$){for(oe.Pb=c>>>0,le.length=f,c=$>>>0>>3,$=0;$<f;$++)le[$]=d()[c+$>>>0];return(0>i?Bt[-i-1]:zu[i]).apply(null,le)},y:function(i){i>>>=0;var c=o().length;if(i<=c||4294901760<i)return!1;for(var f=1;4>=f;f*=2){var $=c*(1+.2/f);$=Math.min($,i+100663296);var E=Math;$=Math.max(i,$);e:{E=E.min.call(E,4294901760,$+(65536-$%65536)%65536)-ve.buffer.byteLength+65535>>>16;try{ve.grow(E),he();var D=1;break e}catch{}D=void 0}if(D)return!0}return!1},P:ye,Q:xe,H:Qt,h:k,o:se,x:$e,n:lr,a:ve||a.wasmMemory,J:no,e:function(i,c,f,$){return no(i>>>0,c>>>0,f>>>0,$>>>0)}};(function(){function i(f,$){return f=f.exports,f=Eu(f),Z=f=Vu(f),oe.ob.push(Z.Da),Re.unshift(Z.Y),be=$,wr(),f}var c={a:Uu};if(jt(),a.instantiateWasm)try{return a.instantiateWasm(c,i)}catch(f){K(\"Module.instantiateWasm callback failed with error: \"+f),h(f)}return vr(c,function(f){i(f.instance,f.module)}).catch(h),{}})(),a._OrtInit=(i,c)=>(a._OrtInit=Z.Z)(i,c),a._OrtGetLastError=(i,c)=>(a._OrtGetLastError=Z._)(i,c),a._OrtCreateSessionOptions=(i,c,f,$,E,D,N,ie,re,ne)=>(a._OrtCreateSessionOptions=Z.$)(i,c,f,$,E,D,N,ie,re,ne),a._OrtAppendExecutionProvider=(i,c)=>(a._OrtAppendExecutionProvider=Z.aa)(i,c),a._OrtAddFreeDimensionOverride=(i,c,f)=>(a._OrtAddFreeDimensionOverride=Z.ba)(i,c,f),a._OrtAddSessionConfigEntry=(i,c,f)=>(a._OrtAddSessionConfigEntry=Z.ca)(i,c,f),a._OrtReleaseSessionOptions=i=>(a._OrtReleaseSessionOptions=Z.da)(i),a._OrtCreateSession=(i,c,f)=>(a._OrtCreateSession=Z.ea)(i,c,f),a._OrtReleaseSession=i=>(a._OrtReleaseSession=Z.fa)(i),a._OrtGetInputOutputCount=(i,c,f)=>(a._OrtGetInputOutputCount=Z.ga)(i,c,f),a._OrtGetInputName=(i,c)=>(a._OrtGetInputName=Z.ha)(i,c),a._OrtGetOutputName=(i,c)=>(a._OrtGetOutputName=Z.ia)(i,c),a._OrtFree=i=>(a._OrtFree=Z.ja)(i),a._OrtCreateTensor=(i,c,f,$,E,D)=>(a._OrtCreateTensor=Z.ka)(i,c,f,$,E,D),a._OrtGetTensorData=(i,c,f,$,E)=>(a._OrtGetTensorData=Z.la)(i,c,f,$,E),a._OrtReleaseTensor=i=>(a._OrtReleaseTensor=Z.ma)(i),a._OrtCreateRunOptions=(i,c,f,$)=>(a._OrtCreateRunOptions=Z.na)(i,c,f,$),a._OrtAddRunConfigEntry=(i,c,f)=>(a._OrtAddRunConfigEntry=Z.oa)(i,c,f),a._OrtReleaseRunOptions=i=>(a._OrtReleaseRunOptions=Z.pa)(i),a._OrtCreateBinding=i=>(a._OrtCreateBinding=Z.qa)(i),a._OrtBindInput=(i,c,f)=>(a._OrtBindInput=Z.ra)(i,c,f),a._OrtBindOutput=(i,c,f,$)=>(a._OrtBindOutput=Z.sa)(i,c,f,$),a._OrtClearBoundOutputs=i=>(a._OrtClearBoundOutputs=Z.ta)(i),a._OrtReleaseBinding=i=>(a._OrtReleaseBinding=Z.ua)(i),a._OrtRunWithBinding=(i,c,f,$,E)=>(a._OrtRunWithBinding=Z.va)(i,c,f,$,E),a._OrtRun=(i,c,f,$,E,D,N,ie)=>(a._OrtRun=Z.wa)(i,c,f,$,E,D,N,ie),a._OrtEndProfiling=i=>(a._OrtEndProfiling=Z.xa)(i),a._JsepOutput=(i,c,f)=>(a._JsepOutput=Z.ya)(i,c,f),a._JsepGetNodeName=i=>(a._JsepGetNodeName=Z.za)(i);var Rr=a._pthread_self=()=>(Rr=a._pthread_self=Z.Aa)(),cn=a._malloc=i=>(cn=a._malloc=Z.Ba)(i),so=a._free=i=>(so=a._free=Z.Ca)(i);a.__emscripten_tls_init=()=>(a.__emscripten_tls_init=Z.Da)();var uo=a.__emscripten_thread_init=(i,c,f,$,E,D)=>(uo=a.__emscripten_thread_init=Z.Fa)(i,c,f,$,E,D);a.__emscripten_thread_crashed=()=>(a.__emscripten_thread_crashed=Z.Ga)();var lo=(i,c,f,$)=>(lo=Z.Ha)(i,c,f,$),pn=i=>(pn=Z.Ia)(i),mn=a.__emscripten_thread_exit=i=>(mn=a.__emscripten_thread_exit=Z.Ja)(i),co=a.__emscripten_check_mailbox=()=>(co=a.__emscripten_check_mailbox=Z.Ka)(),po=i=>(po=Z.La)(i),mo=(i,c)=>(mo=Z.Ma)(i,c),fn=()=>(fn=Z.Na)(),Br=i=>(Br=Z.Oa)(i),hn=i=>(hn=Z.Pa)(i),fo=a.dynCall_ii=(i,c)=>(fo=a.dynCall_ii=Z.Ra)(i,c),ho=i=>(ho=Z.Sa)(i),go=()=>(go=Z.Ta)(),yo=i=>(yo=Z.Ua)(i),bo=()=>(bo=Z.Va)();a.___start_em_js=936134,a.___stop_em_js=936295;function Vu(i){i=Object.assign({},i);var c=$=>()=>$()>>>0,f=$=>E=>$(E)>>>0;return i.__errno_location=c(i.__errno_location),i.pthread_self=c(i.pthread_self),i.malloc=f(i.malloc),i.stackSave=c(i.stackSave),i.stackAlloc=f(i.stackAlloc),i}a.keepRuntimeAlive=ot,a.wasmMemory=ve,a.stackAlloc=hn,a.stackSave=fn,a.stackRestore=Br,a.UTF8ToString=qe,a.stringToUTF8=Ir,a.lengthBytesUTF8=At,a.ExitStatus=wt,a.PThread=oe;var Dr;Ct=function i(){Dr||wo(),Dr||(Ct=i)};function wo(){function i(){if(!Dr&&(Dr=!0,a.calledRun=!0,!Ce)&&(S||yt(Re),p(a),a.onRuntimeInitialized&&a.onRuntimeInitialized(),!S)){if(a.postRun)for(typeof a.postRun==\"function\"&&(a.postRun=[a.postRun]);a.postRun.length;){var c=a.postRun.shift();Ge.unshift(c)}yt(Ge)}}if(!(0<Je))if(S)p(a),S||yt(Re),startWorker(a);else{if(a.preRun)for(typeof a.preRun==\"function\"&&(a.preRun=[a.preRun]);a.preRun.length;)Ze.unshift(a.preRun.shift());yt(Ze),0<Je||(a.setStatus?(a.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){a.setStatus(\"\")},1),i()},1)):i())}}if(a.preInit)for(typeof a.preInit==\"function\"&&(a.preInit=[a.preInit]);0<a.preInit.length;)a.preInit.pop()();return wo(),t.ready}})();typeof Eo==\"object\"&&typeof Sn==\"object\"?Sn.exports=To:typeof define==\"function\"&&define.amd&&define([],()=>To)});var Po=dr((Gc,ju)=>{ju.exports='\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason||e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(Module.__embind_initialize_bindings(),initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(`worker.js received unknown command ${e.data.cmd}`),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\\n'});var Cn,Xe,pr,Ur,mr,zo,In,De=Y(()=>{\"use strict\";Cn=e=>{switch(e){case\"int8\":return 3;case\"uint8\":return 2;case\"bool\":return 9;case\"int16\":return 5;case\"uint16\":return 4;case\"int32\":return 6;case\"uint32\":return 12;case\"float16\":return 10;case\"float32\":return 1;case\"float64\":return 11;case\"string\":return 8;case\"int64\":return 7;case\"uint64\":return 13;default:throw new Error(`unsupported data type: ${e}`)}},Xe=e=>{switch(e){case 3:return\"int8\";case 2:return\"uint8\";case 9:return\"bool\";case 5:return\"int16\";case 4:return\"uint16\";case 6:return\"int32\";case 12:return\"uint32\";case 10:return\"float16\";case 1:return\"float32\";case 11:return\"float64\";case 8:return\"string\";case 7:return\"int64\";case 13:return\"uint64\";default:throw new Error(`unsupported data type: ${e}`)}},pr=e=>[void 0,4,1,1,2,2,4,8,void 0,1,2,8,4,8,void 0,void 0,void 0][e],Ur=e=>{switch(e){case\"float16\":return Uint16Array;case\"float32\":return Float32Array;case\"uint8\":return Uint8Array;case\"int8\":return Int8Array;case\"uint16\":return Uint16Array;case\"int16\":return Int16Array;case\"int32\":return Int32Array;case\"bool\":return Uint8Array;case\"float64\":return Float64Array;case\"uint32\":return Uint32Array;case\"int64\":return BigInt64Array;case\"uint64\":return BigUint64Array;default:throw new Error(`unsupported type: ${e}`)}},mr=e=>{switch(e){case\"verbose\":return 0;case\"info\":return 1;case\"warning\":return 2;case\"error\":return 3;case\"fatal\":return 4;default:throw new Error(`unsupported logging level: ${e}`)}},zo=e=>e===\"float32\"||e===\"int32\"||e===\"int64\"||e===\"bool\"||e===\"float16\"||e===\"uint32\",In=e=>{switch(e){case\"none\":return 0;case\"cpu\":return 1;case\"cpu-pinned\":return 2;case\"texture\":return 3;case\"gpu-buffer\":return 4;default:throw new Error(`unsupported data location: ${e}`)}}});var Vr=Y(()=>{\"use strict\"});var Uo=Y(()=>{\"use strict\";Vr()});var Vo,Wo=Y(()=>{\"use strict\";Vo=\"1.17.0\"});var No,Pt,An=Y(()=>{\"use strict\";Wo();No=\"warning\",Pt={wasm:{},webgl:{},webgpu:{},versions:{common:Vo},set logLevel(e){if(e!==void 0){if(typeof e!=\"string\"||[\"verbose\",\"info\",\"warning\",\"error\",\"fatal\"].indexOf(e)===-1)throw new Error(`Unsupported logging level: ${e}`);No=e}},get logLevel(){return No}};Object.defineProperty(Pt,\"logLevel\",{enumerable:!0})});var Nt,Ho=Y(()=>{\"use strict\";An();Nt=Pt});var Go=Y(()=>{\"use strict\"});var Lo=Y(()=>{\"use strict\";Wr()});var qo=Y(()=>{\"use strict\"});var jo=Y(()=>{\"use strict\";Wr()});var Wr=Y(()=>{\"use strict\";Go();Lo();qo();jo()});var Nr=Y(()=>{\"use strict\";Wr()});var rl,Ko,Ht,Gt,Tn=Y(()=>{\"use strict\";An();rl=(e,t)=>{Pt.wasm.trace&&console.timeStamp(`${e}::ORT::${t}`)},Ko=(e,t)=>{let r=new Error().stack?.split(/\\r\\n|\\r|\\n/g)||[],o=!1;for(let n=0;n<r.length;n++){if(o&&!r[n].includes(\"TRACE_FUNC\")){let s=`FUNC_${e}::${r[n].trim().split(\" \")[1]}`;t&&(s+=`::${t}`),rl(\"CPU\",s);return}r[n].includes(\"TRACE_FUNC\")&&(o=!0)}},Ht=e=>{Pt.wasm.trace&&Ko(\"BEGIN\",e)},Gt=e=>{Pt.wasm.trace&&Ko(\"END\",e)}});var Yo=Y(()=>{\"use strict\";Vr();Nr();Tn()});var Zo=Y(()=>{\"use strict\";Yo()});var Xo=Y(()=>{\"use strict\"});var Qo=Y(()=>{\"use strict\";Vr();Nr()});var Jo=Y(()=>{\"use strict\";Qo()});var Lt=Y(()=>{\"use strict\";Uo();Ho();Zo();Nr();Tn();Xo();Jo()});var al,il,ea,ta,ra,sl,Pe,St=Y(()=>{\"use strict\";De();al=[\"V\",\"I\",\"W\",\"E\",\"F\"],il=(e,t)=>{console.log(`[${al[e]},${new Date().toISOString()}]${t}`)},ra=(e,t)=>{ea=e,ta=t},sl=(e,t)=>{let r=mr(e),o=mr(ea);r>=o&&il(r,typeof t==\"function\"?t():t)},Pe=(...e)=>{ta&&sl(...e)}});var na,oa=Y(()=>{\"use strict\";De();na=(e,t)=>new(Ur(t))(e)});var Hr=Y(()=>{\"use strict\"});var Gr,ul,aa,On,En,sa,ua=Y(()=>{\"use strict\";St();Hr();Gr=e=>Math.ceil(e/16)*16,ul=1,aa=()=>ul++,On=async(e,t,r,o)=>{let n=Gr(r),s=e.device.createBuffer({size:n,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ});try{let u=e.getCommandEncoder();e.endComputePass(),u.copyBufferToBuffer(t,0,s,0,n),e.flush(),await s.mapAsync(GPUMapMode.READ);let d=s.getMappedRange();if(o){let a=o();return a.set(new Uint8Array(d,0,r)),a}else return new Uint8Array(d.slice(0,r))}finally{s.destroy()}},En=class{constructor(t){this.backend=t;this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.buffersForUploadingPending=[],this.buffersPending=[],this.externalBuffers=new Map}upload(t,r){let o=r.buffer,n=r.byteOffset,s=r.byteLength,u=Gr(s),d=this.storageCache.get(t);if(!d)throw new Error(\"gpu data for uploading does not exist\");if(d.originalSize!==s)throw new Error(`inconsistent data size. gpu data size=${d.originalSize}, data size=${s}`);let a=this.backend.device.createBuffer({mappedAtCreation:!0,size:u,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC}),p=a.getMappedRange();new Uint8Array(p).set(new Uint8Array(o,n,s)),a.unmap();let h=this.backend.getCommandEncoder();this.backend.endComputePass(),h.copyBufferToBuffer(a,0,d.gpuData.buffer,0,u),Pe(\"verbose\",()=>`[WebGPU] GpuDataManager.upload(id=${t})`),this.buffersForUploadingPending.push(a)}memcpy(t,r){let o=this.storageCache.get(t);if(!o)throw new Error(\"source gpu data for memcpy does not exist\");let n=this.storageCache.get(r);if(!n)throw new Error(\"destination gpu data for memcpy does not exist\");if(o.originalSize!==n.originalSize)throw new Error(\"inconsistent source and destination gpu data size\");let s=Gr(o.originalSize),u=this.backend.getCommandEncoder();this.backend.endComputePass(),u.copyBufferToBuffer(o.gpuData.buffer,0,n.gpuData.buffer,0,s)}registerExternalBuffer(t,r,o){let n;if(o){if(n=this.externalBuffers.get(o),n===void 0)throw new Error(\"previous buffer is not registered\");if(t===o)return Pe(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${n}, buffer is the same, skip.`),n;this.externalBuffers.delete(o)}else n=aa();return this.storageCache.set(n,{gpuData:{id:n,type:0,buffer:t},originalSize:r}),this.externalBuffers.set(t,n),Pe(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${n}, registered.`),n}unregisterExternalBuffer(t){let r=this.externalBuffers.get(t);r!==void 0&&(this.storageCache.delete(r),this.externalBuffers.delete(t),Pe(\"verbose\",()=>`[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${r}`))}create(t,r=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){let o=Gr(t),n,s=(r&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE,u=(r&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM;if(s||u){let a=s?this.freeBuffers:this.freeUniformBuffers,p=a.get(o);p||(p=[],a.set(o,p)),p.length>0?n=p.pop():n=this.backend.device.createBuffer({size:o,usage:r})}else n=this.backend.device.createBuffer({size:o,usage:r});let d={id:aa(),type:0,buffer:n};return this.storageCache.set(d.id,{gpuData:d,originalSize:t}),Pe(\"verbose\",()=>`[WebGPU] GpuDataManager.create(size=${t}) => id=${d.id}`),d}get(t){return this.storageCache.get(t)?.gpuData}release(t){let r=this.storageCache.get(t);if(!r)throw new Error(\"releasing data does not exist\");return Pe(\"verbose\",()=>`[WebGPU] GpuDataManager.release(id=${t}), gpuDataId=${r.gpuData.id}`),this.storageCache.delete(t),this.buffersPending.push(r.gpuData.buffer),r.originalSize}async download(t,r){let o=this.storageCache.get(t);if(!o)throw new Error(\"data does not exist\");await On(this.backend,o.gpuData.buffer,o.originalSize,r)}refreshPendingBuffers(){for(let t of this.buffersForUploadingPending)t.destroy();this.buffersForUploadingPending=[];for(let t of this.buffersPending)(t.usage&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE?this.freeBuffers.get(t.size).push(t):(t.usage&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM?this.freeUniformBuffers.get(t.size).push(t):t.destroy();this.buffersPending=[]}dispose(){this.freeBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.freeUniformBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.storageCache.forEach(t=>{t.gpuData.buffer.destroy()}),this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map}},sa=(...e)=>new En(...e)});var Pn,ge,We=Y(()=>{\"use strict\";Pn=class{constructor(t){Object.assign(this,t)}get cacheKey(){return this.key||(this.key=Object.getOwnPropertyNames(this).sort().map(t=>`${this[t]}`).join(\";\")),this.key}},ge=e=>new Pn(e)});var kn,st,U,kt,Lr,Fr,qr,Se=Y(()=>{\"use strict\";kn=class{static calcMatMulShape(t,r){return t[1]!==r[0]?void 0:[t[0],r[1]]}},st=class{static calcShape(t,r,o=!1){let n=t.length,s=r.length;if(n===0)return r;if(s===0)return t;let u=Math.max(t.length,r.length),d=new Array(u);if(o){if(n<2||s<2)return;let a=kn.calcMatMulShape([t[n-2],t[n-1]],[r[s-2],r[s-1]]);if(a===void 0)return;[d[u-2],d[u-1]]=a}for(let a=o?3:1;a<=u;a++){let p=n-a<0?1:t[n-a],h=s-a<0?1:r[s-a];if(p!==h&&p>1&&h>1)return;d[u-a]=Math.max(p,h)}return d}static isValidBroadcast(t,r){let o=t.length,n=r.length;if(o>n)return!1;for(let s=1;s<=o;s++)if(t[o-s]!==1&&t[o-s]!==r[n-s])return!1;return!0}},U=class e{static size(t){return e.getSizeFromDimensionRange(t,0,t.length)}static sizeFromDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeFromDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,r,t.length)}static sizeToDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeToDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,0,r)}static getSizeFromDimensionRange(t,r,o){let n=1;for(let s=r;s<o;s++){if(t[s]<0)throw new Error(\"cannot get valid size from specified dimension range. Most likely the range contains negative values in them.\");n*=t[s]}return n}static computeStrides(t){let r=t.length;if(r===0)return[];if(r===1)return[1];let o=new Array(r);o[r-1]=1,o[r-2]=t[r-1];for(let n=r-3;n>=0;--n)o[n]=o[n+1]*t[n+1];return o}static normalizeAxis(t,r){if(t<-r&&t>=r)throw new Error(\"unsupported axis for this operation.\");return t<0?t+r:t}static normalizeAxes(t,r){return t.map(o=>this.normalizeAxis(o,r??t.length))}static sortBasedOnPerm(t,r){return r?r.map(o=>t[o]):t.slice().reverse()}static padShape(t,r){let o=t.length;return t.map((n,s)=>n+r[s]+r[s+o])}static areEqual(t,r){return t.length!==r.length?!1:t.every((o,n)=>o===r[n])}},kt=class e{static adjustPoolAttributes(t,r,o,n,s,u){if(!t&&o.length!==r.length-2)throw new Error(\"length of specified kernel shapes should be 2 less than length of input dimensions\");if(t)for(let d=0;d<r.length-2;d++)d>=o.length?o.push(r[d+2]):o[d]=r[d+2];for(let d=0;d<o.length;d++)if(d<n.length){if(n[d]<0)throw new Error(\"strides should be greater than or equal to 1\")}else n.push(1);for(let d=0;d<o.length;d++)if(d<s.length){if(s[d]<0)throw new Error(\"dilations should be greater than or equal to 1\")}else s.push(1);for(let d=0;d<o.length*2;d++)if(d<u.length){if(u[d]<0)throw new Error(\"pad should be greater than or equal to 1\")}else u.push(0);for(let d=0;d<o.length;d++){if(o[d]<=0)throw new Error(\"kernel shapes need to be greater than 0\");if(u[d]>=o[d]||u[d+o.length]>=o[d])throw new Error(\"pads should be smaller than kernel\")}}static adjustPadsBasedOnAutoPad(t,r,o,n,s,u,d){if(d){if(s.length!==2*(t.length-2))throw new Error(\"length of pads should be twice the length of data dimensions\");if(r.length!==t.length-2)throw new Error(\"length of strides should be the length of data dimensions\");if(n.length!==t.length-2)throw new Error(\"length of kernel shapes should be the length of data dimensions\");for(let a=0;a<t.length-2;a++)e.adjustPadAndReturnShape(t[a+(u?1:2)],r[a],o[a],n[a],s,a,a+t.length-2,d)}}static computePoolOutputShape(t,r,o,n,s,u,d){if(r.length<=0)throw new Error(\"input shape must be of size greater than 0\");let a=[r[0],r[1]];return e.computeShapeHelper(t,r,a,o,n,s,u,d),a}static computeConvOutputShape(t,r,o,n,s,u,d){if(t.length<=0||r.length<=0)throw new Error(\"invalid input tensor dims or invalid filter tensor dims\");let a=[t[0],r[0]];return e.computeShapeHelper(!1,t,a,o,n,s,u,d),a}static computeShapeHelper(t,r,o,n,s,u,d,a){if(t)for(let p=0;p<r.length-2;p++)o.push(1);else for(let p=0;p<r.length-2;p++)o.push(e.adjustPadAndReturnShape(r[p+2],n[p],s[p],u[p],d,p,p+r.length-2,a))}static adjustPadAndReturnShape(t,r,o,n,s,u,d,a){let p=o*(n-1)+1;if(a&&a!==\"NOTSET\")switch(a){case\"VALID\":return s[u]=0,s[d]=0,Math.floor((t-p)/r+1);case\"SAME_LOWER\":case\"SAME_UPPER\":if(o!==1)throw new Error(\"Dilation not supported for SAME_UPPER or SAME_LOWER\");{let g=((t+r-1)/r-1)*r+n-t;return s[u]=Math.floor(a===\"SAME_LOWER\"?(g+1)/2:g/2),s[d]=g-s[u],Math.floor((t+g-n)/r+1)}default:throw new Error(\"Unsupported AutoPad type\")}else return Math.floor((t+s[u]+s[d]-p)/r+1)}},Lr=class{static getShapeOfGemmResult(t,r,o,n,s){if(t.length!==2||o.length!==2)throw new Error(\"shape need to be of size 2\");let u,d,a;r?(u=t[1],d=t[0]):(u=t[0],d=t[1]);let p=-1;if(n?(a=o[0],p=1):(a=o[1],p=0),o[p]!==d)throw new Error(\"dimension mismatch\");if(u<=0||a<=0||d<=0)throw new Error(\"invalid shape specified\");if(s&&!st.isValidBroadcast(s,[u,a]))throw new Error(\"gemm: invalid bias shape for broadcast\");return[u,a,d]}},Fr=-34028234663852886e22,qr=34028234663852886e22});var ll,Bn,Ve,ut,q,Ne,je,rt,Qe,de,Dn,z,j,jr,Rn,la,Ft,Oe,we=Y(()=>{\"use strict\";De();Se();ll=64,Bn=(e,t)=>{if(t===3)throw new Error(\"vec3 has same alignment as vec4, use vec4 instead\");switch(e){case 10:return t>1?`vec${t}<f16>`:\"f16\";case 1:return t>1?`vec${t}<f32>`:\"f32\";case 6:return t>1?`vec${t}<i32>`:\"i32\";case 12:return t>1?`vec${t}<u32>`:\"u32\";case 7:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"i32\"];case 13:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"u32\"];case 9:if(t!==4)throw new Error(\"bool must be vec4\");return[\"u32\",\"vec4<bool>\"];default:throw new Error(`Unknown data type: ${e}`)}},Ve=(e,t=1)=>{let r=Bn(e,t);return typeof r==\"string\"?r:r[0]},ut=(e,t=1)=>{let r=Bn(e,t);return typeof r==\"string\"?r:r[1]},q=e=>e.length===0?[]:[{type:\"uint32\",data:e},{type:\"uint32\",data:U.computeStrides(e)}],Ne=e=>e%4===0?4:e%2===0?2:1,je=(e=\"f32\",t,r=\"0\")=>!t||t===1?`${e}(${r})`:`vec${t}<${e}>(${r})`,rt=(e,t,r)=>e===\"f32\"?r:t===1?`f32(${r})`:`vec${t}f(${r})`,Qe=(e,t)=>t===4?`(${e}.x + ${e}.y + ${e}.z + ${e}.w)`:t===2?`(${e}.x + ${e}.y)`:t===3?`(${e}.x + ${e}.y + ${e}.z)`:e,de=(e,t,r)=>e.startsWith(\"uniforms.\")&&r>4?typeof t==\"string\"?`${e}[(${t}) / 4][(${t}) % 4]`:`${e}[${Math.floor(t/4)}][${t%4}]`:r>1?`${e}[${t}]`:e,Dn=(e,t,r,o,n)=>{let s=typeof r==\"number\",u=s?r:r.length,d=[...new Array(u).keys()],a=u<2?\"u32\":u<=4?`vec${u}<u32>`:`array<u32, ${u}>`,p=Bn(t,n),h=typeof p==\"string\"?p:p[1],g=typeof p==\"string\"?p:p[0],y={indices:a,value:h,storage:g,tensor:t},w=L=>typeof L==\"string\"?L:`${L}u`,b={offsetToIndices:!1,indicesToOffset:!1,broadcastedIndicesToOffset:!1,set:!1,setByIndices:!1,get:!1,getByIndices:!1},_=s?\"uniforms.\":\"\",I=`${_}${e}_shape`,S=`${_}${e}_strides`,x=\"\";for(let L=0;L<u-1;L++)x+=`\n    let dim${L} = current / ${de(S,L,u)};\n    let rest${L} = current % ${de(S,L,u)};\n    indices[${L}] = dim${L};\n    current = rest${L};\n    `;x+=`indices[${u-1}] = current;`;let O=u<2?\"\":`\n  fn o2i_${e}(offset: u32) -> ${y.indices} {\n    var indices: ${y.indices};\n    var current = offset;\n    ${x}\n    return indices;\n  }`,T=L=>(b.offsetToIndices=!0,u<2?L:`o2i_${e}(${L})`),M=[];if(u>=2)for(let L=u-1;L>=0;L--)M.push(`${de(S,L,u)} * (indices[${L}])`);let A=u<2?\"\":`\n  fn i2o_${e}(indices: ${y.indices}) -> u32 {\n    return ${M.join(\"+\")};\n  }`,W=L=>(b.indicesToOffset=!0,u<2?L:`i2o_${e}(${L})`),V=(...L)=>u===0?\"0u\":`${y.indices}(${L.map(w).join(\",\")})`,G=(L,X)=>u<2?`${L}`:`${de(L,X,u)}`,J=(L,X,he)=>u<2?`${L}=${he};`:`${de(L,X,u)}=${he};`,B={},K=(L,X)=>{b.broadcastedIndicesToOffset=!0;let he=`${X.name}broadcastedIndicesTo${e}Offset`;if(he in B)return`${he}(${L})`;let Fe=[];for(let Ze=u-1;Ze>=0;Ze--){let Re=X.indicesGet(\"outputIndices\",Ze+X.rank-u);Fe.push(`${G(S,Ze)} * (${Re} % ${G(I,Ze)})`)}return B[he]=`fn ${he}(outputIndices: ${X.type.indices}) -> u32 {\n             return ${Fe.length>0?Fe.join(\"+\"):\"0u\"};\n           }`,`${he}(${L})`},pe=(L,X)=>(()=>{if(y.storage===y.value)return`${e}[${L}]=${X};`;if(y.storage===\"vec2<u32>\"&&y.value===\"i32\")return`${e}[${L}]=vec2<u32>(u32(${X}), select(0u, 0xFFFFFFFFu, ${X} < 0));`;if(y.storage===\"vec2<u32>\"&&y.value===\"u32\")return`${e}[${L}]=vec2<u32>(u32(${X}), 0u);`;if(y.storage===\"u32\"&&y.value===\"vec4<bool>\")return`${e}[${L}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${X}));`;throw new Error(`not supported combination of storage type ${y.storage} and value type ${y.value} yet`)})(),ee=L=>(()=>{if(y.storage===y.value)return`${e}[${L}]`;if(y.storage===\"vec2<u32>\"&&y.value===\"i32\")return`i32(${e}[${L}].x)`;if(y.storage===\"vec2<u32>\"&&y.value===\"u32\")return`u32(${e}[${L}].x)`;if(y.storage===\"u32\"&&y.value===\"vec4<bool>\")return`vec4<bool>(bool(${e}[${L}] & 0xFFu), bool(${e}[${L}] & 0xFF00u), bool(${e}[${L}] & 0xFF0000u), bool(${e}[${L}] & 0xFF000000u))`;throw new Error(`not supported combination of storage type ${y.storage} and value type ${y.value} yet`)})(),ve=u<2?\"\":`\n  fn get_${e}ByIndices(indices: ${y.indices}) -> ${h} {\n    return ${ee(`i2o_${e}(indices)`)};\n  }`,Z=u<2?\"\":(()=>{let L=d.map(he=>`d${he}: u32`).join(\", \"),X=d.map(he=>`d${he}`).join(\", \");return`\n  fn get_${e}(${L}) -> ${h} {\n    return get_${e}ByIndices(${V(X)});\n  }`})(),be=(...L)=>{if(L.length!==u)throw new Error(`indices length must be ${u}`);let X=L.map(w).join(\",\");return u===0?ee(\"0u\"):u===1?ee(X[0]):(b.get=!0,b.getByIndices=!0,b.indicesToOffset=!0,`get_${e}(${X})`)},Ce=L=>u<2?ee(L):(b.getByIndices=!0,b.indicesToOffset=!0,`get_${e}ByIndices(${L})`),fe=u<2?\"\":`\n  fn set_${e}ByIndices(indices: ${y.indices}, value: ${h}) {\n    ${pe(`i2o_${e}(indices)`,\"value\")}\n  }`,ce=u<2?\"\":(()=>{let L=d.map(he=>`d${he}: u32`).join(\", \"),X=d.map(he=>`d${he}`).join(\", \");return`\n  fn set_${e}(${L}, value: ${h}) {\n    set_${e}ByIndices(${V(X)}, value);\n  }`})();return{impl:()=>{let L=[],X=!1;return b.offsetToIndices&&(L.push(O),X=!0),b.indicesToOffset&&(L.push(A),X=!0),b.broadcastedIndicesToOffset&&(Object.values(B).forEach(he=>L.push(he)),X=!0),b.set&&(L.push(ce),X=!0),b.setByIndices&&(L.push(fe),X=!0),b.get&&(L.push(Z),X=!0),b.getByIndices&&(L.push(ve),X=!0),!s&&X&&L.unshift(`const ${I} = ${y.indices}(${r.join(\",\")});`,`const ${S} = ${y.indices}(${U.computeStrides(r).join(\",\")});`),L.join(`\n`)},type:y,offsetToIndices:T,indicesToOffset:W,broadcastedIndicesToOffset:K,indices:V,indicesGet:G,indicesSet:J,set:(...L)=>{if(L.length!==u+1)throw new Error(`indices length must be ${u}`);let X=L[u];if(typeof X!=\"string\")throw new Error(\"value must be string\");let he=L.slice(0,u).map(w).join(\",\");return u===0?pe(\"0u\",X):u===1?pe(he[0],X):(b.set=!0,b.setByIndices=!0,b.indicesToOffset=!0,`set_${e}(${he}, ${X})`)},setByOffset:pe,setByIndices:(L,X)=>u<2?pe(L,X):(b.setByIndices=!0,b.indicesToOffset=!0,`set_${e}ByIndices(${L}, ${X});`),get:be,getByOffset:ee,getByIndices:Ce,usage:o,name:e,strides:S,shape:I,rank:u}},z=(e,t,r,o=1)=>Dn(e,t,r,\"input\",o),j=(e,t,r,o=1)=>Dn(e,t,r,\"output\",o),jr=(e,t,r,o=1)=>Dn(e,t,r,\"internal\",o),Rn=class{constructor(t){this.normalizedDispatchGroup=t;this.internalVariables=[];this.variables=[];this.uniforms=[];this.variableIndex=0}guardAgainstOutOfBoundsWorkgroupSizes(t){return`if (global_idx >= ${typeof t==\"number\"?`${t}u`:t}) { return; }`}mainStart(t=ll){let r=typeof t==\"number\"?t:t[0],o=typeof t==\"number\"?1:t[1],n=typeof t==\"number\"?1:t[2],s=this.normalizedDispatchGroup[1]===1&&this.normalizedDispatchGroup[2]===1,u=s?`@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>`:`@builtin(local_invocation_id) local_id : vec3<u32>,\n    @builtin(local_invocation_index) local_idx : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>`,d=s?\"let global_idx = global_id.x; let local_idx = local_id.x;\":`let global_idx = (workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n          workgroup_id.y * num_workgroups[0] + workgroup_id.x) * ${r*o*n}u + local_idx;`;return`@compute @workgroup_size(${r}, ${o}, ${n})\n  fn main(${u}) {\n    ${d}\n  `}appendVariableUniforms(t){t.rank!==0&&(t.shape.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.shape.replace(\"uniforms.\",\"\"),type:\"u32\",length:t.rank}),t.strides.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.strides.replace(\"uniforms.\",\"\"),type:\"u32\",length:t.rank}))}declareVariable(t,r){if(t.usage===\"internal\")throw new Error(\"cannot use internal variable with declareVariable(). use registerInternalVariables() instead.\");this.variables.push(t),this.appendVariableUniforms(t);let o=t.usage===\"input\"?\"read\":\"read_write\",n=t.type.storage;return`@group(0) @binding(${r}) var<storage, ${o}> ${t.name}: array<${n}>;`}declareVariables(...t){return t.map(r=>this.declareVariable(r,this.variableIndex++)).join(`\n`)}registerInternalVariable(t){if(t.usage!==\"internal\")throw new Error(\"cannot use input or output variable with registerInternalVariable(). use declareVariables() instead.\");this.internalVariables.push(t),this.appendVariableUniforms(t)}registerInternalVariables(...t){return t.forEach(r=>this.registerInternalVariable(r)),this}registerUniform(t,r,o=1){return this.uniforms.push({name:t,type:r,length:o}),this}registerUniforms(t){return this.uniforms=this.uniforms.concat(t),this}uniformDeclaration(){if(this.uniforms.length===0)return\"\";let t=[];for(let{name:r,type:o,length:n}of this.uniforms)if(n&&n>4)t.push(`${r}:array<vec4<${o}>, ${Math.ceil(n/4)}>`);else{let s=n==null||n===1?o:`vec${n}<${o}>`;t.push(`${r}:${s}`)}return`\n      struct Uniforms { ${t.join(\", \")} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`}get additionalImplementations(){return this.uniformDeclaration()+this.variables.map(t=>t.impl()).join(`\n`)+this.internalVariables.map(t=>t.impl()).join(`\n`)}},la=e=>new Rn(e),Ft=(e,t)=>{let r=e.length,o=[];for(let n=0;n<r;n++){let s=r-1-n,u=e[s]||1;(t[t.length-1-n]||1)>1&&u===1&&o.unshift(s)}return o},Oe=e=>!0});var dl,da,cl,pl,nt,ca,pa,qt=Y(()=>{\"use strict\";Se();We();we();dl=e=>{if(!e||e.length!==1)throw new Error(\"Transpose requires 1 input.\")},da=(e,t)=>t&&t.length!==e?[...new Array(e).keys()].reverse():t,cl=(e,t)=>U.sortBasedOnPerm(e,da(e.length,t)),pl=(e,t,r,o)=>{let n=[];n.push(`fn perm(i: ${o.type.indices}) -> ${r.type.indices} {\n    var a: ${r.type.indices};`);for(let s=0;s<t;++s)n.push(r.indicesSet(\"a\",e[s],`i[${s}]`));return n.push(\"return a;}\"),n.join(`\n`)},nt=(e,t)=>{let r=e.dataType,o=e.dims.length,n=da(o,t),s=Oe(o),u=cl(e.dims,n),d=s?u.length:u,a=s?o:e.dims,p=j(\"output\",r,d),h=z(\"a\",r,a),g=y=>`\n  ${y.registerUniform(\"output_size\",\"u32\").declareVariables(h,p)}\n\n  ${pl(n,o,h,p)}\n\n  ${y.mainStart()}\n    ${y.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n\n    let indices = ${p.offsetToIndices(\"global_idx\")};\n    let aIndices = perm(indices);\n\n    ${p.setByOffset(\"global_idx\",h.getByIndices(\"aIndices\"))}\n  }`;return{name:\"Transpose\",shaderCache:{hint:`${t}`,inputDependencies:s?[\"rank\"]:[\"dims\"]},getRunData:y=>{let w=U.size(u);return{outputs:[{dims:u,dataType:y[0].dataType}],dispatchGroup:{x:Math.ceil(w/64)},programUniforms:s?[{type:\"uint32\",data:w},...q(y[0].dims),...q(u)]:[{type:\"uint32\",data:w}]}},getShaderSource:g}},ca=(e,t)=>{dl(e.inputs),e.compute(nt(e.inputs[0],t.perm))},pa=e=>ge({perm:e.perm})});var ml,fl,hl,gl,yl,bl,wl,vl,$l,Sl,lt,ma,fa,ha,ga,ya,ba,wa,va,$a,Sa,xa=Y(()=>{\"use strict\";Se();we();Kr();qt();ml={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate * candidate\",logSumExp:\"bestValue + exp(candidate)\",l1:\"bestValue + abs(candidate)\",l2:\"bestValue + candidate * candidate\",logSum:\"bestValue + candidate\"},fl={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate\",logSumExp:\"bestValue + candidate\",l1:\"bestValue + candidate\",l2:\"bestValue + candidate\",logSum:\"bestValue + candidate\"},hl={max:\"_A[offset]\",min:\"_A[offset]\",mean:\"0\",sum:\"0\",prod:\"1\",sumSquare:\"0\",logSumExp:\"0\",l1:\"0\",l2:\"0\",logSum:\"0\"},gl={max:\"bestValue\",min:\"bestValue\",sum:\"bestValue\",prod:\"bestValue\",sumSquare:\"bestValue\",logSumExp:\"log(bestValue)\",l1:\"bestValue\",l2:\"sqrt(bestValue)\",logSum:\"log(bestValue)\"},yl=(e,t)=>{let r=[];for(let o=t-e;o<t;++o)r.push(o);return r},bl=(e,t)=>{let r=[],o=e.length;for(let s=0;s<o;s++)t.indexOf(s)===-1&&r.push(e[s]);let n=t.map(s=>e[s]);return[r,n]},wl=(e,t)=>{let r=e.length+t.length,o=[],n=0;for(let s=0;s<r;s++)t.indexOf(s)===-1?o.push(e[n++]):o.push(1);return o},vl=(e,t)=>{for(let r=0;r<e.length;++r)if(e[e.length-r-1]!==t-1-r)return!1;return!0},$l=(e,t)=>{let r=[];if(!vl(e,t)){for(let o=0;o<t;++o)e.indexOf(o)===-1&&r.push(o);e.forEach(o=>r.push(o))}return r},Sl=(e,t,r,o,n,s,u)=>{let d=r[0].dims,a=U.size(s),p=U.size(u),h=z(\"_A\",r[0].dataType,d),g=j(\"output\",n,s),y=32,w=`\n          var<workgroup> aBestValues : array<${g.type.storage}, ${y}>;\n       `;return{name:e,shaderCache:t,getShaderSource:_=>`\n        ${_.registerUniform(\"reduceSize\",\"u32\").declareVariables(h,g)}\n        ${w}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${_.mainStart(y)}\n\n          let outputIndex = global_idx / ${y};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${g.type.storage}(${hl[o]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${y}) {\n           let candidate = ${g.type.storage}(${h.getByOffset(\"offset + k\")});\n           bestValue = ${ml[o]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${y}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${fl[o]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${g.setByOffset(\"outputIndex\",`${o===\"mean\"?`bestValue / ${g.type.storage}(uniforms.reduceSize)`:`${gl[o]}`}`)};\n         }\n        }`,getRunData:()=>({outputs:[{dims:s,dataType:n}],dispatchGroup:{x:a},programUniforms:[{type:\"uint32\",data:p}]})}},lt=(e,t,r,o)=>{let n=e.inputs.length===1?r:Mn(e.inputs,r),s=n.axes;s.length===0&&!n.noopWithEmptyAxes&&(s=e.inputs[0].dims.map((w,b)=>b));let u=U.normalizeAxes(s,e.inputs[0].dims.length),d=u,a=e.inputs[0],p=$l(d,e.inputs[0].dims.length);p.length>0&&(a=e.compute(nt(e.inputs[0],p),{inputs:[0],outputs:[-1]})[0],d=yl(d.length,a.dims.length));let[h,g]=bl(a.dims,d),y=h;n.keepDims&&(y=wl(h,u)),e.compute(Sl(t,{hint:n.cacheKey,inputDependencies:[\"type\"]},[a],o,e.inputs[0].dataType,y,g),{inputs:[a]})},ma=(e,t)=>{lt(e,\"ReduceMeanShared\",t,\"mean\")},fa=(e,t)=>{lt(e,\"ReduceL1Shared\",t,\"l1\")},ha=(e,t)=>{lt(e,\"ReduceL2Shared\",t,\"l2\")},ga=(e,t)=>{lt(e,\"ReduceLogSumExpShared\",t,\"logSumExp\")},ya=(e,t)=>{lt(e,\"ReduceMaxShared\",t,\"max\")},ba=(e,t)=>{lt(e,\"ReduceMinShared\",t,\"min\")},wa=(e,t)=>{lt(e,\"ReduceProdShared\",t,\"prod\")},va=(e,t)=>{lt(e,\"ReduceSumShared\",t,\"sum\")},$a=(e,t)=>{lt(e,\"ReduceSumSquareShared\",t,\"sumSquare\")},Sa=(e,t)=>{lt(e,\"ReduceLogSumShared\",t,\"logSum\")}});var dt,xl,Yr,Mn,ct,_l,Cl,Il,Al,Tl,El,Ol,Pl,kl,Rl,pt,_a,Ca,Ia,Aa,Ta,Ea,Oa,Pa,ka,Ra,Kr=Y(()=>{\"use strict\";Se();We();we();xa();dt=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"Reduce op requires 1 or 2 inputs.\");if(e.length===2&&e[1].dims.length!==1)throw new Error(\"Invalid axes input dims.\")},xl=e=>[\"\",\"\",`var value = ${e.getByIndices(\"input_indices\")};`,\"\"],Yr=(e,t,r,o,n,s,u=!1,d=!1)=>{let a=[],p=r[0].dims,h=p.length,g=U.normalizeAxes(n,h),y=!d&&g.length===0;p.forEach((I,S)=>{y||g.indexOf(S)>=0?u&&a.push(1):a.push(I)});let w=a.length,b=U.size(a);return{name:e,shaderCache:t,getShaderSource:I=>{let S=[],x=z(\"_A\",r[0].dataType,h),O=j(\"output\",s,w),T=o(x,O,g),M=T[2];for(let A=0,W=0;A<h;A++)y||g.indexOf(A)>=0?(u&&W++,M=`for(var j${A}: u32 = 0; j${A} < ${p[A]}; j${A}++) {\n                  ${T[2].includes(\"last_index\")?`let last_index = j${A};`:\"\"}\n                  ${x.indicesSet(\"input_indices\",A,`j${A}`)}\n                  ${M}\n                }`):(S.push(`${x.indicesSet(\"input_indices\",A,O.indicesGet(\"output_indices\",W))};`),W++);return`\n\n        ${I.registerUniform(\"output_size\",\"u32\").declareVariables(x,O)}\n\n        ${I.mainStart()}\n          ${I.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n          var input_indices: ${x.type.indices};\n          let output_indices = ${O.offsetToIndices(\"global_idx\")};\n\n          ${S.join(`\n`)}\n          ${T[0]}       // init ops for reduce max/min\n          ${T[1]}\n          ${M}\n          ${T[3]}\n          ${T.length===4?O.setByOffset(\"global_idx\",\"value\"):T.slice(4).join(`\n`)}\n        }`},getRunData:()=>({outputs:[{dims:a,dataType:s}],dispatchGroup:{x:Math.ceil(b/64)},programUniforms:[{type:\"uint32\",data:b},...q(p),...q(a)]})}},Mn=(e,t)=>{let r=[];return e[1].dims[0]>0&&e[1].getBigInt64Array().forEach(o=>r.push(Number(o))),ge({axes:r,keepDims:t.keepDims,noopWithEmptyAxes:t.noopWithEmptyAxes})},ct=(e,t,r,o)=>{let n=e.inputs,s=n.length===1?r:Mn(n,r);e.compute(Yr(t,{hint:s.cacheKey,inputDependencies:[\"rank\"]},[n[0]],s.noopWithEmptyAxes&&s.axes.length===0?xl:o,s.axes,n[0].dataType,s.keepDims,s.noopWithEmptyAxes),{inputs:[0]})},_l=(e,t)=>{dt(e.inputs),ct(e,\"ReduceLogSum\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += ${o.getByIndices(\"input_indices\")};`,\"value = log(value);\"])},Cl=(e,t)=>{dt(e.inputs),ct(e,\"ReduceL1\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += abs(${o.getByIndices(\"input_indices\")});`,\"\"])},Il=(e,t)=>{dt(e.inputs),ct(e,\"ReduceL2\",t,(o,n)=>[`var t = ${n.type.value}(0); var value = ${n.type.value}(0);`,\"\",`t = ${o.getByIndices(\"input_indices\")}; value += (t * t);`,\"value = sqrt(value);\"])},Al=(e,t)=>{dt(e.inputs),ct(e,\"ReduceLogSumExp\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += exp(${o.getByIndices(\"input_indices\")});`,\"value = log(value);\"])},Tl=(e,t)=>{dt(e.inputs),ct(e,\"ReduceMax\",t,(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(o.indicesSet(\"input_indices\",d,0));return[`${u.join(`\n`)}`,`var value = ${o.getByIndices(\"input_indices\")};`,`value = max(value, ${o.getByIndices(\"input_indices\")});`,\"\"]})},El=(e,t)=>{dt(e.inputs),ct(e,\"ReduceMean\",t,(o,n,s)=>{let u=1;for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&(u*=e.inputs[0].dims[d]);return[\"var sum = f32(0);\",\"\",`sum += f32(${o.getByIndices(\"input_indices\")});`,`let value = ${n.type.value}(sum / ${u});`]})},Ol=(e,t)=>{dt(e.inputs),ct(e,\"ReduceMin\",t,(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(`input_indices[${d}] = 0;`);return[`${u.join(`\n`)}`,`var value = ${o.getByIndices(\"input_indices\")};`,`value = min(value, ${o.getByIndices(\"input_indices\")});`,\"\"]})},Pl=(e,t)=>{dt(e.inputs),ct(e,\"ReduceProd\",t,(o,n)=>[`var value = ${n.type.storage}(1);`,\"\",`value *= ${o.getByIndices(\"input_indices\")};`,\"\"])},kl=(e,t)=>{dt(e.inputs),ct(e,\"ReduceSum\",t,(o,n)=>[`var value = ${n.type.storage}(0);`,\"\",`value += ${o.getByIndices(\"input_indices\")};`,\"\"])},Rl=(e,t)=>{dt(e.inputs),ct(e,\"ReduceSumSquare\",t,(o,n)=>[`var t = ${n.type.value}(0); var value = ${n.type.value}(0);`,\"\",`t = ${o.getByIndices(\"input_indices\")}; value += t * t;`,\"\"])},pt=(e,t,r)=>{if(t.length===0)return r;let o=1,n=1;for(let s=0;s<t.length;s++)t.indexOf(s)===-1?o*=e[s]:n*=e[s];return n<32&&o>1024},_a=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?El(e,t):ma(e,t)},Ca=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Cl(e,t):fa(e,t)},Ia=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Il(e,t):ha(e,t)},Aa=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Al(e,t):ga(e,t)},Ta=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Tl(e,t):ya(e,t)},Ea=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Ol(e,t):ba(e,t)},Oa=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Pl(e,t):wa(e,t)},Pa=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?kl(e,t):va(e,t)},ka=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Rl(e,t):$a(e,t)},Ra=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?_l(e,t):Sa(e,t)}});var Ba,Da,Ma,zn,za=Y(()=>{\"use strict\";De();We();Kr();Ba=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"ArgMinMaxOp op requires 1 or 2 inputs.\");if(e[0].dataType!==1)throw new Error(\"Invalid input type.\")},Da=(e,t)=>{Ba(e.inputs);let r=(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(`input_indices[${d}] = 0;`);return[`${u.join(`\n`)}`,`var value = ${o.getByIndices(\"input_indices\")};\nvar best_index : i32 = 0;`,`if (${o.getByIndices(\"input_indices\")} ${t.selectLastIndex>0?\"<=\":\"<\"} value) {\n         value = ${o.getByIndices(\"input_indices\")};\n         best_index = i32(last_index);\n       }`,\"\",n.setByOffset(\"global_idx\",\"best_index\")]};e.compute(Yr(\"ArgMin\",{hint:t.cacheKey,inputDependencies:[\"rank\"]},[e.inputs[0]],r,[t.axis],7,t.keepDims),{inputs:[0]})},Ma=(e,t)=>{Ba(e.inputs);let r=(o,n,s)=>{let u=[];for(let d=0;d<o.rank;d++)(s.indexOf(d)>=0||s.length===0)&&u.push(`input_indices[${d}] = 0;`);return[`${u.join(`\n`)}`,`var value = ${o.getByIndices(\"input_indices\")};\nvar best_index : i32 = 0;`,`if (${o.getByIndices(\"input_indices\")} ${t.selectLastIndex>0?\">=\":\">\"} value) {\n         value = ${o.getByIndices(\"input_indices\")};\n         best_index = i32(last_index);\n       }`,\"\",n.setByOffset(\"global_idx\",\"best_index\")]};e.compute(Yr(\"argMax\",{hint:t.cacheKey,inputDependencies:[\"rank\"]},[e.inputs[0]],r,[t.axis],7,t.keepDims),{inputs:[0]})},zn=e=>ge(e)});var Bl,Dl,Ml,zl,Zr,Ul,Ua,Un=Y(()=>{\"use strict\";De();Hr();we();Bl=(e,t)=>{let r=e[0],o=e[1],n=e[2],s=e[3],u=e[4],d=e[5];if(u&&d)throw new Error(\"Attention cannot have both past and relative_position_bias\");if(r.dims.length!==3)throw new Error('Input \"input\" must have 3 dimensions');let a=r.dims[0],p=r.dims[1],h=r.dims[2];if(n.dims.length!==1)throw new Error('Input \"bias\" is expected to have 1 dimensions');if(o.dims.length!==2)throw new Error('Input \"weights\" is expected to have 2 dimensions');if(o.dims[0]!==h)throw new Error(\"Input 1 dimension 0 should have same length as dimension 2 of input 0\");if(n.dims[0]!==o.dims[1])throw new Error('Input \"bias\" dimension 0 should have same length as dimension 1 of input \"weights\"');let g=n.dims[0]/3,y=g,w=y;if(t.qkvHiddenSizes.length>0){if(t.qkvHiddenSizes.length!==3)throw new Error(\"qkv_hidden_sizes attribute should have 3 elements\");for(let O of t.qkvHiddenSizes)if(O%t.numHeads!==0)throw new Error(\"qkv_hidden_sizes should be divisible by num_heads\");g=t.qkvHiddenSizes[0],y=t.qkvHiddenSizes[1],w=t.qkvHiddenSizes[2]}let b=p;if(g!==y)throw new Error(\"qkv_hidden_sizes first element should be same as the second\");if(n.dims[0]!==g+y+w)throw new Error('Input \"bias\" dimension 0 should have same length as sum of Q/K/V hidden sizes');let _=0;if(u){if(y!==w)throw new Error('Input \"past\" expect k_hidden_size == v_hidden_size');if(u.dims.length!==5)throw new Error('Input \"past\" must have 5 dimensions');if(u.dims[0]!==2)throw new Error('Input \"past\" first dimension must be 2');if(u.dims[1]!==a)throw new Error('Input \"past\" second dimension must be batch_size');if(u.dims[2]!==t.numHeads)throw new Error('Input \"past\" third dimension must be num_heads');if(u.dims[4]!==y/t.numHeads)throw new Error('Input \"past\" fifth dimension must be k_hidden_size / num_heads');t.pastPresentShareBuffer||(_=u.dims[3])}let I=b+_,S=-1,x=0;if(s)throw new Error(\"Mask not supported\");if(u)throw new Error(\"past is not supported\");if(d)throw new Error(\"relativePositionBias is not supported\");return{batchSize:a,sequenceLength:p,pastSequenceLength:_,kvSequenceLength:b,totalSequenceLength:I,maxSequenceLength:S,inputHiddenSize:h,hiddenSize:g,vHiddenSize:w,headSize:Math.floor(g/t.numHeads),vHeadSize:Math.floor(w/t.numHeads),numHeads:t.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:t.maskFilterValue,maskType:x,scale:t.scale,broadcastResPosBias:!1,passPastInKv:!1,qkvFormat:1}},Dl=(e,t,r,o)=>{let n=Ne(o),s=64,u=o/n;u<s?s=1:u/8<64&&(s=Math.ceil(u/8));let d=Math.ceil(o/n/s),p=[{type:Xe(t.dataType),data:1/o},{type:\"uint32\",data:u},{type:\"uint32\",data:d}],h=Ve(t.dataType,n),g=y=>{let w=j(\"x\",t.dataType,t.dims,n),b=\"thread_max_vector\";n===2?b=\"max(thread_max_vector.x, thread_max_vector.y)\":n===4&&(b=\"max(max(thread_max_vector.x, thread_max_vector.y), max(thread_max_vector.z, thread_max_vector.w))\");let _=ut(t.dataType),I=[{name:\"d_inv\",type:_},{name:\"d_comp\",type:\"u32\"},{name:\"elements_per_wg\",type:\"u32\"}];return`\n  var<workgroup> wgMax: array<f32, ${s}>;\n  var<workgroup> wgSum: array<f32, ${s}>;\n  ${y.registerUniforms(I).declareVariables(w)}\n  ${y.mainStart([s,1,1])}\n    let localOffset = local_idx * uniforms.elements_per_wg;\n    let offset: u32 = workgroup_id.x * uniforms.d_comp + localOffset;\n\n    var thread_max_vector = ${je(\"f32\",n,\"-3.402823e+38f\")};\n    for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n      thread_max_vector = max(${rt(_,n,\"x[offset + i]\")}, thread_max_vector);\n    }\n    wgMax[local_idx] = ${b};\n    workgroupBarrier();\n\n    var maxValue = -3.402823e+38f;\n    for (var i = 0u; i < ${s}; i++) {\n      maxValue = max(wgMax[i], maxValue);\n    }\n\n    var sumVector = ${je(\"f32\",n,\"0\")};\n    for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n      sumVector += exp(${rt(_,n,\"x[offset + i]\")} - maxValue);\n    }\n    wgSum[local_idx] = ${Qe(\"sumVector\",n)};\n    workgroupBarrier();\n\n    var sum: f32 = 0;\n    for (var i = 0u; i < ${s}; i++) {\n      sum += wgSum[i];\n    }\n\n    if (sum == 0) {\n      for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n        x[offset + i] = ${je(\"f32\",n,\"uniforms.d_inv\")};\n      }\n    } else {\n      for (var i: u32 = 0; i < uniforms.elements_per_wg && i + localOffset < uniforms.d_comp; i++) {\n        let f32input = ${rt(_,n,\"x[offset + i]\")};\n        x[offset + i] = ${w.type.value}(exp(f32input - maxValue) / sum);\n      }\n    }\n  }`};e.compute({name:\"AttentionProbsSoftmax\",shaderCache:{hint:`${s};${h};${n}`},getShaderSource:g,getRunData:()=>({outputs:[],dispatchGroup:{x:r},programUniforms:p})},{inputs:[t],outputs:[]})},Ml=(e,t,r,o,n,s)=>{let u=[n.batchSize,n.numHeads,n.sequenceLength,n.kvSequenceLength+n.pastSequenceLength],d=s.scale===0?1/Math.sqrt(n.headSize):s.scale,a=Ne(n.headSize),p=n.headSize/a,h=12,g={x:Math.ceil(n.totalSequenceLength/h),y:Math.ceil(n.sequenceLength/h),z:n.batchSize*n.numHeads},y=Xe(t.dataType),w=[{type:\"uint32\",data:n.sequenceLength},{type:\"uint32\",data:p},{type:\"uint32\",data:n.totalSequenceLength},{type:\"uint32\",data:n.kvSequenceLength},{type:y,data:d}],b=[t,r],_=S=>{let x=z(\"q\",t.dataType,t.dims,a),O=z(\"key\",r.dataType,r.dims,a),T=j(\"output\",t.dataType,u),M=Ve(t.dataType),A=[{name:\"M\",type:\"u32\"},{name:\"K\",type:\"u32\"},{name:\"N\",type:\"u32\"},{name:\"kv_sequence_length\",type:\"u32\"},{name:\"alpha\",type:M}];return`\n  const beta: ${M} = 1.0;\n  const TILE_SIZE = ${h}u;\n\n  var<workgroup> tileQ: array<${x.type.storage}, ${h*h}>;\n  var<workgroup> tileK: array<${x.type.storage}, ${h*h}>;\n  ${S.registerUniforms(A).declareVariables(x,O,T)}\n  ${S.mainStart([h,h,1])}\n    // x holds the N and y holds the M\n    let headIdx = workgroup_id.z;\n    let m = workgroup_id.y * TILE_SIZE;\n    let n = workgroup_id.x * TILE_SIZE;\n    let lm = m + local_id.y;\n    let ln = n + local_id.x;\n\n    let qOffset = uniforms.M * uniforms.K * headIdx + m * uniforms.K;\n    let kOffset = uniforms.kv_sequence_length * uniforms.K * headIdx + n * uniforms.K;\n\n    var value = ${je(M,a)};\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (m + local_id.y < uniforms.M && w + local_id.x < uniforms.K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * uniforms.K + w + local_id.x];\n      }\n      if (n + local_id.y < uniforms.N && w + local_id.x < uniforms.K) {\n        tileK[TILE_SIZE * local_id.y + local_id.x] = key[kOffset + local_id.y * uniforms.K + w + local_id.x];\n      }\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n        value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = headIdx * uniforms.M * uniforms.N;\n    if (lm < uniforms.M && ln < uniforms.N) {\n      let outputIdx = headOffset + lm * uniforms.N + ln;\n      output[outputIdx] = ${Qe(\"value\",a)} * uniforms.alpha;\n    }\n  }`},I=e.compute({name:\"AttentionProbs\",shaderCache:{hint:`${a}`,inputDependencies:[\"type\",\"type\"]},getRunData:()=>({outputs:[{dims:u,dataType:t.dataType,gpuDataType:0}],dispatchGroup:g,programUniforms:w}),getShaderSource:_},{inputs:b,outputs:[-1]})[0];return Dl(e,I,n.batchSize*n.numHeads*n.sequenceLength,n.totalSequenceLength),I},zl=(e,t,r,o)=>{let n=[o.batchSize,o.sequenceLength,o.vHiddenSize],s=12,u={x:Math.ceil(o.vHeadSize/s),y:Math.ceil(o.sequenceLength/s),z:o.batchSize*o.numHeads},d=[{type:\"uint32\",data:o.sequenceLength},{type:\"uint32\",data:o.totalSequenceLength},{type:\"uint32\",data:o.vHeadSize},{type:\"uint32\",data:o.numHeads},{type:\"uint32\",data:o.vHiddenSize}],a=p=>{let h=z(\"probs\",t.dataType,t.dims),g=z(\"v\",r.dataType,r.dims),y=j(\"output\",t.dataType,n),w=[{name:\"M\",type:\"u32\"},{name:\"K\",type:\"u32\"},{name:\"N\",type:\"u32\"},{name:\"num_heads\",type:\"u32\"},{name:\"v_hidden_size\",type:\"u32\"}];return`\n  const TILE_SIZE = ${s}u;\n  var<workgroup> tileQ: array<${h.type.value}, ${s*s}>;\n  var<workgroup> tileK: array<${h.type.value}, ${s*s}>;\n  ${p.registerUniforms(w).declareVariables(h,g,y)}\n  ${p.mainStart([s,s,1])}\n   let headIdx = workgroup_id.z;\n   let m = workgroup_id.y * TILE_SIZE + local_id.y;\n   let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n   let offsetA = headIdx * (uniforms.M * uniforms.K) + m * uniforms.K;\n   let offsetB = headIdx * (uniforms.N * uniforms.K) + n;\n\n   var value = ${h.type.storage}(0);\n   for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n     if (m < uniforms.M && w + local_id.x < uniforms.K) {\n       tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];\n     }\n     if (n < uniforms.N && w + local_id.y < uniforms.K) {\n       tileK[TILE_SIZE * local_id.y + local_id.x] = v[offsetB + (w + local_id.y) * uniforms.N];\n     }\n     workgroupBarrier();\n     for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n       value += tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * k + local_id.x];\n     }\n     workgroupBarrier();\n   }\n\n   // we need to transpose output from BNSH_v to BSND_v\n   let batchIdx = workgroup_id.z / uniforms.num_heads;\n   let currentBatchHeadNumber = workgroup_id.z % uniforms.num_heads;\n   let headOffset = (batchIdx * uniforms.M * uniforms.num_heads + currentBatchHeadNumber) * uniforms.N;\n   if (m < uniforms.M && n < uniforms.N) {\n     let outputIdx = batchIdx * uniforms.M *uniforms.v_hidden_size + m * uniforms.v_hidden_size\n       + currentBatchHeadNumber * uniforms.N + n;\n     output[outputIdx] = value;\n   }\n  }`};return e.compute({name:\"AttentionScore\",shaderCache:{inputDependencies:[\"type\",\"type\"]},getRunData:()=>({outputs:[{dims:n,dataType:t.dataType,gpuDataType:0}],dispatchGroup:u,programUniforms:d}),getShaderSource:a},{inputs:[t,r],outputs:[0]})[0]},Zr=(e,t,r,o,n,s,u,d,a,p,h)=>{let g=Ml(e,t,r,a,p,h);zl(e,g,o,p)},Ul=(e,t)=>{let r=[t.batchSize,t.numHeads,t.sequenceLength,t.headSize],o=t.sequenceLength,n=t.inputHiddenSize,s=t.headSize,u=12,d={x:Math.ceil(t.headSize/u),y:Math.ceil(t.sequenceLength/u),z:t.batchSize*t.numHeads},a=[e.inputs[0],e.inputs[1],e.inputs[2]],p=[{type:\"uint32\",data:o},{type:\"uint32\",data:n},{type:\"uint32\",data:s},{type:\"uint32\",data:t.numHeads},{type:\"uint32\",data:t.headSize},{type:\"uint32\",data:t.hiddenSize},{type:\"uint32\",data:t.hiddenSize+t.hiddenSize+t.vHiddenSize}],h=g=>{let y=j(\"output_q\",a[0].dataType,r),w=j(\"output_k\",a[0].dataType,r),b=j(\"output_v\",a[0].dataType,r),_=z(\"input\",a[0].dataType,a[0].dims),I=z(\"weight\",a[1].dataType,a[1].dims),S=z(\"bias\",a[2].dataType,a[2].dims),x=_.type.storage,O=[{name:\"M\",type:\"u32\"},{name:\"K\",type:\"u32\"},{name:\"N\",type:\"u32\"},{name:\"num_heads\",type:\"u32\"},{name:\"head_size\",type:\"u32\"},{name:\"hidden_size\",type:\"u32\"},{name:\"ldb\",type:\"u32\"}];return`\n  const TILE_SIZE = ${u}u;\n  var<workgroup> tileInput: array<${x}, ${u*u}>;\n  var<workgroup> tileWeightQ: array<${x}, ${u*u}>;\n  var<workgroup> tileWeightK: array<${x}, ${u*u}>;\n  var<workgroup> tileWeightV: array<${x}, ${u*u}>;\n  ${g.registerUniforms(O).declareVariables(_,I,S,y,w,b)}\n  ${g.mainStart([u,u,1])}\n    let batchIndex = workgroup_id.z / uniforms.num_heads;\n    let headNumber = workgroup_id.z % uniforms.num_heads;\n    let m = workgroup_id.y * TILE_SIZE + local_id.y;\n    let n = workgroup_id.x * TILE_SIZE + local_id.x;\n\n    let inputOffset = batchIndex * (uniforms.M * uniforms.K) + m * uniforms.K;\n    let biasOffsetQ = headNumber * uniforms.head_size;\n    let biasOffsetK = uniforms.hidden_size + biasOffsetQ;\n    let biasOffsetV = uniforms.hidden_size + biasOffsetK;\n\n    var valueQ = ${x}(0);\n    var valueK = ${x}(0);\n    var valueV = ${x}(0);\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (m < uniforms.M && w + local_id.x < uniforms.K) {\n        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];\n      }\n      if (n < uniforms.N && w + local_id.y < uniforms.K) {\n        let offset = n + (w + local_id.y) * uniforms.ldb;\n        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];\n        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];\n        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];\n      }\n      workgroupBarrier();\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n        let inputTileOffset = TILE_SIZE * local_id.y + k;\n        let weightTileOffset = TILE_SIZE * k + local_id.x;\n        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];\n        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];\n        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = (m * uniforms.N + n) % uniforms.head_size;\n    valueQ += bias[headOffset + biasOffsetQ];\n    valueK += bias[headOffset + biasOffsetK];\n    valueV += bias[headOffset + biasOffsetV];\n\n    let offset = workgroup_id.z * uniforms.M * uniforms.N;\n    if (m < uniforms.M && n < uniforms.N) {\n      let outputIdx = offset + m * uniforms.N + n;\n      output_q[outputIdx] = valueQ;\n      output_k[outputIdx] = valueK;\n      output_v[outputIdx] = valueV;\n    }\n  }`};return e.compute({name:\"AttentionPrepare\",shaderCache:{inputDependencies:[\"type\",\"type\",\"type\"]},getRunData:()=>({outputs:[{dims:r,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:r,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:r,dataType:e.inputs[0].dataType,gpuDataType:0}],dispatchGroup:d,programUniforms:p}),getShaderSource:h},{inputs:a,outputs:[-1,-1,-1]})},Ua=(e,t)=>{let r=Bl(e.inputs,t),[o,n,s]=Ul(e,r);return Zr(e,o,n,s,e.inputs[4],void 0,void 0,void 0,e.inputs[5],r,t)}});var Vl,Wl,Nl,Va,Wa=Y(()=>{\"use strict\";Lt();Se();We();we();Vl=(e,t)=>{if(!e||e.length!==5)throw new Error(\"BatchNormalization requires 5 inputs\");let r=(o,n,s)=>{let u=n.length;if(u!==o.length)throw new Error(`${s}: num dimensions != ${u}`);n.forEach((d,a)=>{if(d!==o[a])throw new Error(`${s}: dim[${a}] do not match`)})};if(e[0].dims.length>1){let o=t.format===\"NHWC\"?t.spatial?e[0].dims.slice(-1):e[0].dims.slice(-1).concat(e[0].dims.slice(1,e[0].dims.length-1)):e[0].dims.slice(1,t.spatial?2:void 0);r(e[1].dims,o,\"Invalid input scale\"),r(e[2].dims,o,\"Invalid input B\"),r(e[3].dims,o,\"Invalid input mean\"),r(e[4].dims,o,\"Invalid input var\")}else r(e[1].dims,[1],\"Invalid input scale\"),r(e[2].dims,[1],\"Invalid input B\"),r(e[3].dims,[1],\"Invalid input mean\"),r(e[4].dims,[1],\"Invalid input var\")},Wl=(e,t)=>{let{epsilon:r,spatial:o,format:n}=t,s=e[0].dims,u=o?Ne(s[s.length-1]):1,d=n===\"NHWC\"&&s.length>1?u:1,a=U.size(s)/u,p=Oe(s.length)&&o,h=p?s.length:s,g=z(\"x\",e[0].dataType,e[0].dims,u),y=z(\"scale\",e[1].dataType,e[1].dims,d),w=z(\"bias\",e[2].dataType,e[2].dims,d),b=z(\"inputMean\",e[3].dataType,e[3].dims,d),_=z(\"inputVar\",e[4].dataType,e[4].dims,d),I=j(\"y\",e[0].dataType,h,u),S=()=>{let O=\"\";if(o)O=`let cOffset = ${s.length===1?\"0u\":n===\"NHWC\"?`outputIndices[${s.length-1}] / ${u}`:\"outputIndices[1]\"};`;else if(n===\"NCHW\")O=`\n            ${I.indicesSet(\"outputIndices\",\"0\",\"0\")}\n            let cOffset = ${I.indicesToOffset(\"outputIndices\")};`;else{O=`var cIndices = ${y.type.indices}(0);\n                       cIndices[0] = outputIndices[${s.length-1}];`;for(let T=1;T<y.rank;T++)O+=`cIndices[${T}] = outputIndices[${T}];`;O+=`let cOffset = ${y.indicesToOffset(\"cIndices\")};`}return O},x=O=>`\n  const epsilon = ${r};\n  ${O.registerUniform(\"outputSize\",\"u32\").declareVariables(g,y,w,b,_,I)}\n  ${O.mainStart()}\n  ${O.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n    var outputIndices = ${I.offsetToIndices(`global_idx * ${u}`)};\n    ${S()}\n    let scale = ${y.getByOffset(\"cOffset\")};\n    let bias = ${w.getByOffset(\"cOffset\")};\n    let inputMean = ${b.getByOffset(\"cOffset\")};\n    let inputVar = ${_.getByOffset(\"cOffset\")};\n    let x = ${g.getByOffset(\"global_idx\")};\n    let value = (x - inputMean) / sqrt(inputVar + epsilon) * scale + bias;\n    ${I.setByOffset(\"global_idx\",\"value\")}\n  }`;return{name:\"BatchNormalization\",shaderCache:{hint:`${t.epsilon}_${t.format}_${o}_${u}`,inputDependencies:p?[\"rank\",\"type\",\"type\",\"type\",\"type\"]:void 0},getShaderSource:x,getRunData:()=>({outputs:[{dims:e[0].dims,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)},programUniforms:p?[{type:\"uint32\",data:a},...q(s)]:[{type:\"uint32\",data:a}]})}},Nl=e=>ge(e),Va=(e,t)=>{let{inputs:r,outputCount:o}=e,n=Nl({...t,outputCount:o});if(Nt.webgpu.validateInputContent&&Vl(r,n),t.trainingMode)throw new Error(\"BatchNormalization trainingMode is not supported yet.\");e.compute(Wl(r,n))}});var Hl,Gl,Na,Ha=Y(()=>{\"use strict\";Se();we();Hl=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![320,640,1280].includes(e[0].dims[2]))throw new Error(\"number of channels should be 320, 640 or 1280\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},Gl=e=>{let t=e[0].dims,r=e[0].dims[2],o=U.size(t)/4,n=e[0].dataType,s=z(\"input\",n,t,4),u=z(\"bias\",n,[r],4),d=z(\"residual\",n,t,4),a=j(\"output\",n,t,4);return{name:\"BiasAdd\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(o/64)}}),getShaderSource:h=>`\n  const channels = ${r}u / 4;\n  ${h.declareVariables(s,u,d,a)}\n\n  ${h.mainStart()}\n    ${h.guardAgainstOutOfBoundsWorkgroupSizes(o)}\n    let value = ${s.getByOffset(\"global_idx\")}\n      + ${u.getByOffset(\"global_idx % channels\")} + ${d.getByOffset(\"global_idx\")};\n    ${a.setByOffset(\"global_idx\",\"value\")}\n  }`}},Na=e=>{Hl(e.inputs),e.compute(Gl(e.inputs))}});var Ll,Te,Ga,La,Fa,qa,ja,Ka,Ya,Za,Xa,Fl,Qa,Ja,ei,ti,Xr,ri,Qr,ni,oi,ai,ii,si,ui,li,di,ci,pi,mi,fi,hi,gi,yi,bi,wi,Vn=Y(()=>{\"use strict\";De();Se();We();we();Ll=(e,t,r,o,n,s)=>{let u=Math.ceil(t/4),d=\"\";typeof n==\"string\"?d=`${n}(a)`:d=n(\"a\");let a=z(\"inputData\",r,[u],4),p=j(\"outputData\",o,[u],4);return`\n      ${e.registerUniform(\"vec_size\",\"u32\").declareVariables(a,p)}\n\n  ${s??\"\"}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n\n    let a = ${a.getByOffset(\"global_idx\")};\n    ${p.setByOffset(\"global_idx\",d)}\n  }`},Te=(e,t,r,o,n,s=e.dataType)=>({name:t,shaderCache:{hint:n,inputDependencies:[\"type\"]},getShaderSource:u=>Ll(u,U.size(e.dims),e.dataType,s,r,o),getRunData:u=>({outputs:[{dims:e.dims,dataType:s}],dispatchGroup:{x:Math.ceil(U.size(u[0].dims)/64/4)},programUniforms:[{type:\"uint32\",data:Math.ceil(U.size(e.dims)/4)}]})}),Ga=e=>{e.compute(Te(e.inputs[0],\"Abs\",\"abs\"))},La=e=>{e.compute(Te(e.inputs[0],\"Acos\",\"acos\"))},Fa=e=>{e.compute(Te(e.inputs[0],\"Acosh\",\"acosh\"))},qa=e=>{e.compute(Te(e.inputs[0],\"Asin\",\"asin\"))},ja=e=>{e.compute(Te(e.inputs[0],\"Asinh\",\"asinh\"))},Ka=e=>{e.compute(Te(e.inputs[0],\"Atan\",\"atan\"))},Ya=e=>{e.compute(Te(e.inputs[0],\"Atanh\",\"atanh\"))},Za=e=>ge(e),Xa=(e,t)=>{let r;switch(t.to){case 10:r=\"vec4<f16>\";break;case 1:r=\"vec4<f32>\";break;case 12:r=\"vec4<u32>\";break;case 6:r=\"vec4<i32>\";break;case 9:r=\"vec4<bool>\";break;default:throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${t.to}`)}e.compute(Te(e.inputs[0],\"Cast\",r,void 0,t.cacheKey,t.to))},Fl=e=>{let t=e.length>=2&&e[1].data!==0?e[1].getFloat32Array()[0]:Fr,r=e.length>=3&&e[2].data!==0?e[2].getFloat32Array()[0]:qr;return ge({min:t,max:r})},Qa=(e,t)=>{let r=e.inputs.length===1?t:Fl(e.inputs),o=ut(e.inputs[0].dataType);e.compute(Te(e.inputs[0],\"Clip\",n=>`clamp(${n}, clip_min_, clip_max_)`,`\n    const clip_min_: vec4<${o}> = vec4(${o}(${r.min}));\n    const clip_max_: vec4<${o}> = vec4(${o}(${r.max}));\n`,r.cacheKey),{inputs:[0]})},Ja=e=>{e.compute(Te(e.inputs[0],\"Ceil\",\"ceil\"))},ei=e=>{e.compute(Te(e.inputs[0],\"Cos\",\"cos\"))},ti=e=>{e.compute(Te(e.inputs[0],\"Cosh\",\"cosh\"))},Xr=e=>ge(e),ri=(e,t)=>{let r=ut(e.inputs[0].dataType);e.compute(Te(e.inputs[0],\"Elu\",o=>`elu_vf32(${o})`,`\n  const elu_alpha_ = ${r}(${t.alpha});\n\n  fn elu_f32(a: ${r}) -> ${r} {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<${r}>) -> vec4<${r}> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,t.cacheKey))},Qr=(e,t=\"f32\")=>`\nconst r0: ${t} = 0.3275911;\nconst r1: ${t} = 0.254829592;\nconst r2: ${t} = -0.284496736;\nconst r3: ${t} = 1.421413741;\nconst r4: ${t} = -1.453152027;\nconst r5: ${t} = 1.061405429;\n\nfn erf_vf32(v: ${e}) -> ${e} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`,ni=e=>{let t=ut(e.inputs[0].dataType);e.compute(Te(e.inputs[0],\"Erf\",r=>`erf_vf32(${r})`,Qr(`vec4<${t}>`,t)))},oi=e=>{e.compute(Te(e.inputs[0],\"Exp\",\"exp\"))},ai=e=>{e.compute(Te(e.inputs[0],\"Floor\",\"floor\"))},ii=e=>{let t=ut(e.inputs[0].dataType);e.compute(Te(e.inputs[0],\"Gelu\",r=>`0.5 * ${r} * (1.0 + erf_vf32(${r} * 0.7071067811865475))`,Qr(`vec4<${t}>`,t)))},si=(e,t)=>{let r=ut(e.inputs[0].dataType);e.compute(Te(e.inputs[0],\"LeakyRelu\",o=>`select(leaky_relu_alpha_ * ${o}, ${o}, ${o} >= vec4<${r}>(0.0))`,`const leaky_relu_alpha_ = ${r}(${t.alpha});`,t.cacheKey))},ui=e=>{e.compute(Te(e.inputs[0],\"Not\",t=>`!${t}`))},li=e=>{e.compute(Te(e.inputs[0],\"Neg\",t=>`-${t}`))},di=e=>{e.compute(Te(e.inputs[0],\"Reciprocal\",t=>`1.0/${t}`))},ci=e=>{let t=ut(e.inputs[0].dataType);e.compute(Te(e.inputs[0],\"Relu\",r=>`select(vec4<${t}>(0.0), ${r}, ${r} > vec4<${t}>(0.0))`))},pi=e=>{e.compute(Te(e.inputs[0],\"Sigmoid\",t=>`(1.0 / (1.0 + exp(-${t})))`))},mi=e=>{e.compute(Te(e.inputs[0],\"Sin\",\"sin\"))},fi=e=>{e.compute(Te(e.inputs[0],\"Sinh\",\"sinh\"))},hi=e=>{e.compute(Te(e.inputs[0],\"Sqrt\",\"sqrt\"))},gi=e=>{e.compute(Te(e.inputs[0],\"Tan\",\"tan\"))},yi=e=>{e.compute(Te(e.inputs[0],\"Tanh\",\"tanh\"))},bi=(e,t)=>{let r=ut(e.inputs[0].dataType);return e.compute(Te(e.inputs[0],\"ThresholdedRelu\",o=>`select(vec4<${r}>(0.0), ${o}, ${o} > thresholded_relu_alpha_)`,`const thresholded_relu_alpha_ = vec4<${r}>(${t.alpha});`,t.cacheKey)),0},wi=e=>{e.compute(Te(e.inputs[0],\"Log\",\"log\"))}});var jl,Kl,vi,$i=Y(()=>{\"use strict\";Se();we();Vn();jl=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![2560,5120,10240].includes(e[0].dims[2]))throw new Error(\"hidden state should be 2560, 5120 or 10240\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},Kl=e=>{let t=e[0].dims.slice();t[2]=t[2]/2;let r=z(\"input\",e[0].dataType,e[0].dims,4),o=z(\"bias\",e[0].dataType,[e[0].dims[2]],4),n=j(\"output\",e[0].dataType,t,4),s=U.size(t)/4,u=Ve(e[0].dataType);return{name:\"BiasSplitGelu\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:a=>`\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${e[0].dims[2]/4/2}u;\n\n  ${a.declareVariables(r,o,n)}\n\n  ${Qr(`vec4<${u}>`,u)}\n\n  ${a.mainStart()}\n    ${a.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${n.setByOffset(\"global_idx\",\"valueLeft * geluRight\")}\n  }`}},vi=e=>{jl(e.inputs),e.compute(Kl(e.inputs))}});var Yl,Zl,mt,Si,xi,_i,Ci,Ii,Ai,Ti,Ei,Oi,Pi,ki=Y(()=>{\"use strict\";De();Se();we();Yl=(e,t,r,o,n,s,u,d,a,p,h,g,y)=>{let w,b;typeof d==\"string\"?w=b=(A,W)=>`${d}((${A}),(${W}))`:typeof d==\"function\"?w=b=d:(w=d.scalar,b=d.vector);let _=g?t.length:t,I=g?r.length:r,S=g?o.length:o,x=j(\"outputData\",h,S,4),O=z(\"aData\",a,_,4),T=z(\"bData\",p,I,4),M;if(n)if(s){let A=U.size(t)===1,W=U.size(r)===1,V=t.length>0&&t[t.length-1]%4===0,G=r.length>0&&r[r.length-1]%4===0;A||W?M=x.setByOffset(\"global_idx\",b(A?`${O.type.value}(${O.getByOffset(\"0\")}.x)`:O.getByOffset(\"global_idx\"),W?`${T.type.value}(${T.getByOffset(\"0\")}.x)`:T.getByOffset(\"global_idx\"))):M=`\n            let outputIndices = ${x.offsetToIndices(\"global_idx * 4u\")};\n            let offsetA = ${O.broadcastedIndicesToOffset(\"outputIndices\",x)};\n            let offsetB = ${T.broadcastedIndicesToOffset(\"outputIndices\",x)};\n            ${x.setByOffset(\"global_idx\",b(u||V?O.getByOffset(\"offsetA / 4u\"):`${O.type.value}(${O.getByOffset(\"offsetA / 4u\")}[offsetA % 4u])`,u||G?T.getByOffset(\"offsetB / 4u\"):`${T.type.value}(${T.getByOffset(\"offsetB / 4u\")}[offsetB % 4u])`))}\n          `}else M=x.setByOffset(\"global_idx\",b(O.getByOffset(\"global_idx\"),T.getByOffset(\"global_idx\")));else{if(!s)throw new Error(\"no necessary to use scalar implementation for element-wise binary op implementation.\");let A=(W,V,G=\"\")=>{let J=`aData[indexA${V}][componentA${V}]`,B=`bData[indexB${V}][componentB${V}]`;return`\n            let outputIndices${V} = ${x.offsetToIndices(`global_idx * 4u + ${V}u`)};\n            let offsetA${V} = ${O.broadcastedIndicesToOffset(`outputIndices${V}`,x)};\n            let offsetB${V} = ${T.broadcastedIndicesToOffset(`outputIndices${V}`,x)};\n            let indexA${V} = offsetA${V} / 4u;\n            let indexB${V} = offsetB${V} / 4u;\n            let componentA${V} = offsetA${V} % 4u;\n            let componentB${V} = offsetB${V} % 4u;\n            ${W}[${V}] = ${G}(${w(J,B)});\n          `};h===9?M=`\n            var data = vec4<u32>(0);\n            ${A(\"data\",0,\"u32\")}\n            ${A(\"data\",1,\"u32\")}\n            ${A(\"data\",2,\"u32\")}\n            ${A(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:M=`\n            ${A(\"outputData[global_idx]\",0)}\n            ${A(\"outputData[global_idx]\",1)}\n            ${A(\"outputData[global_idx]\",2)}\n            ${A(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.registerUniform(\"vec_size\",\"u32\").declareVariables(O,T,x)}\n\n        ${y??\"\"}\n\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n        ${M}\n      }`},Zl=(e,t,r,o,n,s,u=r.dataType)=>{let d=!U.areEqual(r.dims,o.dims),a=r.dims,p=U.size(r.dims),h=!1,g=!1,y=[d];if(d){let b=st.calcShape(r.dims,o.dims,!1);if(!b)throw new Error(\"Can't perform binary op on the given tensors\");a=b,p=U.size(a);let _=U.size(r.dims)===1,I=U.size(o.dims)===1,S=r.dims.length>0&&r.dims[r.dims.length-1]%4===0,x=o.dims.length>0&&o.dims[o.dims.length-1]%4===0;y.push(_),y.push(I),y.push(S),y.push(x);let O=1;for(let T=1;T<a.length;T++){let M=r.dims[r.dims.length-T]??1,A=o.dims[o.dims.length-T]??1;if(M===A)O*=M;else break}O%4===0?(g=!0,h=!0):(_||I||S||x)&&(h=!0)}else h=!0;y.push(h);let w=Oe(r.dims.length)&&Oe(o.dims.length)&&Oe(a.length);return{name:e,shaderCache:{hint:t+y.map(b=>b.toString()).join(\"_\"),inputDependencies:w?[\"rank\",\"rank\"]:[\"dims\",\"dims\"]},getShaderSource:b=>Yl(b,r.dims,o.dims,a,h,d,g,n,r.dataType,o.dataType,u,w,s),getRunData:()=>({outputs:[{dims:a,dataType:u}],dispatchGroup:{x:Math.ceil(p/64/4)},programUniforms:w?[{type:\"uint32\",data:Math.ceil(U.size(a)/4)},...q(r.dims),...q(o.dims),...q(a)]:[{type:\"uint32\",data:Math.ceil(U.size(a)/4)}]})}},mt=(e,t,r,o,n,s)=>{e.compute(Zl(t,n??\"\",e.inputs[0],e.inputs[1],r,o,s))},Si=e=>{mt(e,\"Add\",(t,r)=>`${t}+${r}`)},xi=e=>{mt(e,\"Div\",(t,r)=>`${t}/${r}`)},_i=e=>{mt(e,\"Equal\",{scalar:(t,r)=>`u32(${t}==${r})`,vector:(t,r)=>`vec4<u32>(${t}==${r})`},void 0,void 0,9)},Ci=e=>{mt(e,\"Mul\",(t,r)=>`${t}*${r}`)},Ii=e=>{let t=z(\"input\",e.inputs[0].dataType,e.inputs[0].dims).type.value;mt(e,\"Pow\",{scalar:(o,n)=>`pow_custom(${o},${n})`,vector:(o,n)=>`pow_vector_custom(${o},${n})`},`\n    fn pow_custom(a : ${t}, b : ${t}) -> ${t} {\n      if (b == ${t}(0.0)) {\n        return ${t}(1.0);\n      } else if (a < ${t}(0.0) && f32(b) != floor(f32(b))) {\n        return ${t}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${t}(1.0), round(f32(abs(b) % ${t}(2.0))) != 1.0) * ${t}(${t===\"i32\"?\"round\":\"\"}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${t}>, b : vec4<${t}>) -> vec4<${t}> {\n      // TODO: implement vectorized pow\n      return vec4<${t}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `)},Ai=e=>{mt(e,\"Sub\",(t,r)=>`${t}-${r}`)},Ti=e=>{mt(e,\"Greater\",{scalar:(t,r)=>`u32(${t}>${r})`,vector:(t,r)=>`vec4<u32>(${t}>${r})`},void 0,void 0,9)},Ei=e=>{mt(e,\"Less\",{scalar:(t,r)=>`u32(${t}<${r})`,vector:(t,r)=>`vec4<u32>(${t}<${r})`},void 0,void 0,9)},Oi=e=>{mt(e,\"GreaterOrEqual\",{scalar:(t,r)=>`u32(${t}>=${r})`,vector:(t,r)=>`vec4<u32>(${t}>=${r})`},void 0,void 0,9)},Pi=e=>{mt(e,\"LessOrEqual\",{scalar:(t,r)=>`u32(${t}<=${r})`,vector:(t,r)=>`vec4<u32>(${t}<=${r})`},void 0,void 0,9)}});var Ql,Jl,ed,td,Ri,Bi,Di=Y(()=>{\"use strict\";Se();We();we();Ql=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\");let t=e[0].dataType,r=e[0].dims.length;for(let o of e){if(o.dataType!==t)throw new Error(\"input tensors should be one type\");if(o.dims.length!==r)throw new Error(\"input tensors should have the same shape\")}},Jl=(e,t)=>`\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${e}u>(${t});\n    for (var i: u32 = 0u; i < ${e}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${e}u;\n  }`,ed=(e,t)=>{let r=e.length,o=[];for(let n=0;n<r;++n){let s=t.setByOffset(\"global_idx\",e[n].getByIndices(\"indices\"));r===1?o.push(s):n===0?o.push(`if (inputIndex == ${n}u) { ${s} }`):n===r-1?o.push(`else { ${s} }`):o.push(`else if (inputIndex == ${n}) { ${s} }`)}return o.join(`\n`)},td=(e,t)=>{let r=e[0].dims.slice();if(t>=r.length||t<-1*r.length)throw new Error(\"axis specified for concat doesn't match input dimensionality\");let o=t<0?r.length+t:t,n=r.slice(0);for(let T=1;T<e.length;T++){let M=e[T].dims.slice();for(let A=0;A<r.length;A++)if(A===o)n[o]+=M[A];else if(r[A]!==M[A])throw new Error(\"non concat dimensions must match\")}let s=U.size(n),u=new Array(e.length),d=new Array(e.length),a=e[0].dataType,p=0,h=[],g=[],y=[],w=[{type:\"uint32\",data:s}];for(let T=0;T<e.length;++T)p+=e[T].dims[o],u[T]=p,y.push(Oe(e[T].dims.length)),g.push(y[T]?e[T].dims.length:e[T].dims),d[T]=z(`input${T}`,a,g[T]),h.push(y[T]?\"rank\":\"dims\"),w.push({type:\"uint32\",data:u[T]});for(let T=0;T<e.length;++T)y[T]&&w.push(...q(e[T].dims));let b=Oe(n.length);b&&w.push(...q(n));let _=b?n.length:n,I=j(\"output\",a,_),S=I.indicesGet(\"indices\",o),x=Array.from(Array(u.length).keys()).map(T=>`uniforms.sizeInConcatAxis${T}`).join(\",\"),O=T=>`\n\n  ${(()=>{T.registerUniform(\"outputSize\",\"u32\");for(let M=0;M<e.length;M++)T.registerUniform(`sizeInConcatAxis${M}`,\"u32\");return T.declareVariables(...d,I)})()}\n\n  ${Jl(u.length,x)}\n\n  ${T.mainStart()}\n    ${T.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n\n    var indices = ${I.offsetToIndices(\"global_idx\")};\n\n    let inputIndex = calculateInputIndex(${S});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${u.length}u>(${x});\n      ${S} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${ed(d,I)}\n  }`;return{name:\"Concat\",shaderCache:{hint:`${t}`,inputDependencies:h},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)},programUniforms:w}),getShaderSource:O}},Ri=(e,t)=>{Ql(e.inputs),e.compute(td(e.inputs,t.axis))},Bi=e=>ge({axis:e.axis})});var ft,Jr,xt=Y(()=>{\"use strict\";Se();ft=(e,t)=>{switch(e.activation){case\"Relu\":return{activationFunction:\"\",applyActivation:`value = max(value, ${t}(0.0));`};case\"Sigmoid\":return{activationFunction:\"\",applyActivation:`value = (${t}(1.0) / (${t}(1.0) + exp(-value)));`};case\"Clip\":return{activationFunction:`const clip_min_=${t}(${e.clipMin});const clip_max_=${t}(${e.clipMax});`,applyActivation:\"value = clamp(value, clip_min_, clip_max_);\"};default:return{activationFunction:\"\",applyActivation:\"\"}}},Jr=e=>{let t=e?.activation||\"\";if(t===\"Clip\"){let[r,o]=e?.activation_params||[Fr,qr];return{activation:t,clipMax:o,clipMin:r,activationCacheKey:`${t}:${r},${o}`}}return{activation:t,activationCacheKey:t}}});var Le,en,tn=Y(()=>{\"use strict\";Le=(e,t)=>{switch(e){case 1:return t;case 2:return`vec2<${t}>`;case 3:return`vec3<${t}>`;case 4:return`vec4<${t}>`;default:throw new Error(`${e}-component is not supported.`)}},en=e=>`\n      ${e?\"value = value + getBiasByOutputCoords(coords);\":\"\"}\n      `});var rn,Wn=Y(()=>{\"use strict\";rn=e=>`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    i32(${e}.x), i32(${e}.y), i32(${e}.z), 1));\n}\n`});var rd,nd,fr,Mi,od,hr,ad,nn,gr=Y(()=>{\"use strict\";Se();we();xt();tn();rd=(e,t)=>e?`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `:`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `,nd=(e,t)=>e?`\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${t===3?\"\":\"let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];\"}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached3[i] + acc[i];\"}\n        }`:`\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached.w + acc[i];\"}\n        }`,fr=(e,t,r=\"f32\",o,n=!1,s=32,u=!1,d=32)=>{let a=t[1]*e[1],p=t[0]*e[0],h=n?a:s,g=n?s:a,y=h/t[0],w=s/t[1];if(!((n&&y===4&&e[1]===4||!n&&(y===3||y===4))&&h%t[0]===0&&s%t[1]===0&&e[0]===4))throw new Error(`If transposeA ${n} is true, innerElementSize ${y} and workPerThread[1] ${e[1]} must be 4.\n      Otherwise, innerElementSize ${y} must be 3 or 4.\n  tileAWidth ${h} must be divisible by workgroupSize[0]${t[0]}. tileInner ${s} must be divisible by workgroupSize[1] ${t[1]}. colPerThread ${e[0]} must be 4.`);return`\nvar<workgroup> mm_Asub: array<array<vec${y}<${r}>, ${h/y}>, ${g}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${r}>, ${p/e[0]}>, ${s}>;\n\nconst rowPerThread = ${e[1]};\nconst colPerThread = ${e[0]};\nconst innerElementSize = ${y};\nconst tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${u?\"0\":\"i32(globalId.z)\"};\n  ${o?`let batchIndices = ${o.offsetToIndices(\"u32(batch)\")};`:\"\"}\n  let globalRowStart = i32(workgroupId.y) * ${a};\n\n  let numTiles = ${u?`${Math.ceil(d/s)}`:\"(uniforms.dimInner - 1) / tileInner + 1\"};\n  var kStart = ${u?`i32(globalId.z) * ${d}`:\"0\"};\n\n  var acc: array<vec4<${r}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${w};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${rd(n,o)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${w}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${o?\", batchIndices\":\"\"});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${y===3?\"\":\"let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];\"}\n\n          ${nd(n,y)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`},Mi=(e,t)=>e?`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${t?\", batchIndices\":\"\"});\n            `:`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${t?\", batchIndices\":\"\"});\n            `,od=e=>e?\"let ACached = mm_Asub[k][tileRow + innerRow];\":\"let ACached = mm_Asub[tileRow + innerRow][k];\",hr=(e,t,r=\"f32\",o,n=!1,s=32,u=!1,d=32,a=!1)=>{let p=e[1]*t[1],h=e[0]*t[0],g=n?p:s,y=n?s:p;if(!(y%t[1]===0&&g%t[0]===0&&s%t[1]===0))throw new Error(`tileAHight ${y} must be divisible by workgroupSize[1]${t[1]}, tileAWidth ${g} must be divisible by workgroupSize[0]${t[0]}, tileInner ${s} must be divisible by workgroupSize[1]${t[1]}`);let w=y/t[1],b=g/t[0],_=s/t[1],I=a?`\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${p};\n    let globalColStart = i32(workgroupId.x) * ${h};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${y}; inputRow = inputRow + ${t[1]}) {\n        for (var inputCol = localCol; inputCol < ${g}; inputCol = inputCol + ${t[0]}) {\n          ${Mi(n,o)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${s}; inputRow = inputRow + ${t[1]}) {\n            for (var inputCol = localCol; inputCol < ${h}; inputCol = inputCol + ${t[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${o?\", batchIndices\":\"\"});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${r}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${t[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${n?`mm_Asub[k][localRow + innerRow * ${t[1]}];`:`mm_Asub[localRow + innerRow * ${t[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${t[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${t[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    `:`\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${p};\n\nlet tileRowA = i32(localId.y) * ${w};\nlet tileColA = i32(localId.x) * ${b};\nlet tileRowB = i32(localId.y) * ${_};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${w}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${b}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${Mi(n,o)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${_}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${o?\", batchIndices\":\"\"});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${r}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${od(n)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;return`\n  var<workgroup> mm_Asub : array<array<${r}, ${g}>, ${y}>;\n  var<workgroup> mm_Bsub : array<array<${r}, ${h}>, ${s}>;\n  const rowPerThread = ${e[1]};\n  const colPerThread = ${e[0]};\n  const tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${u?\"0\":\"i32(globalId.z)\"};\n    ${o?`let batchIndices = ${o.offsetToIndices(\"u32(batch)\")};`:\"\"}\n    let numTiles = ${u?`${Math.ceil(d/s)}`:\"(uniforms.dimInner - 1) / tileInner + 1\"};\n    var kStart = ${u?`i32(globalId.z) * ${d}`:\"0\"};\n\n    var acc : array<array<${r}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${I}\n  }\n`},ad=(e,t,r,o,n,s=!1)=>{let[u,d,a]=n,[p,h,g,y]=o,w=Ft(u,a),b=Ft(d,a),_=Ve(o[0].type.tensor),I=()=>{let O=h.rank,T=p.rank,M=`var aIndices: ${h.type.indices};`;for(let A=O-2-1,W=T-1;A>=0;A--,W--)M+=`\naIndices[${A}] = ${T>1?`batchIndices[${W}]`:\"batchIndices\"};`;return w.forEach(A=>{M+=`\naIndices[${A}] = 0;`}),M+=`\naIndices[${O-2}] = u32(row);\n                   aIndices[${O-1}] = u32(colIn);`,M},S=()=>{let O=g.rank,T=p.rank,M=`var bIndices: ${g.type.indices};`;for(let A=O-2-1,W=T-1;A>=0;A--,W--)M+=`\nbIndices[${A}] = ${T>1?`batchIndices[${W}]`:\"batchIndices\"};`;return b.forEach(A=>{M+=`\nbIndices[${A}] = 0;`}),M+=`\nbIndices[${O-2}] = u32(row);\n                   bIndices[${O-1}] = u32(colIn);`,M};return`\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${p.type.indices}) -> ${Le(e,_)} {\n      var value = ${Le(e,_)}(0.0);\n      let col = colIn * ${e};\n      if(row < uniforms.dimAOuter && col < uniforms.dimInner)\n      {\n        ${I()}\n        value = ${h.getByIndices(\"aIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${p.type.indices}) -> ${Le(e,_)} {\n      var value = ${Le(e,_)}(0.0);\n      let col = colIn * ${e};\n      if(row < uniforms.dimInner && col < uniforms.dimBOuter)\n      {\n        ${S()}\n        value = ${g.getByIndices(\"bIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${Le(e,_)}) {\n      let col = colIn * ${e};\n      if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${t?`value = value + ${s?\"bias[colIn]\":`${Le(e,_)}(bias[row])`};`:\"\"}\n        ${r}\n        ${y.setByIndices(\"vec3<u32>(coords)\",\"value\")}\n      }\n    }\n    `},nn=(e,t,r,o,n=!1)=>{let s=e[0].dims,u=e[1].dims,d=s.slice(0,-2),a=u.slice(0,-2),p=o?o.slice(0,-2):r.slice(0,-2),h=Oe(p.length),g=h?p.length:p,y=jr(\"batchDims\",e[0].dataType,g,1),w=U.size(p),b=s[s.length-2],_=s[s.length-1],I=u[u.length-1],S=_%4===0&&I%4===0,x=b<=8?[4,1,1]:[4,4,1],O=[8,8,1],T=[Math.ceil(I/O[0]/x[0]),Math.ceil(b/O[1]/x[1]),Math.ceil(w/O[2]/x[2])],M=Ve(e[0].dataType),A=S?4:1,W=[...d,b,_/A],V=Oe(W.length),G=V?W.length:W,J=[...a,_,I/A],B=Oe(J.length),K=B?J.length:J,pe=[w,b,I/A],ee=z(\"a\",e[0].dataType,G,A),ve=z(\"b\",e[1].dataType,K,A),Z=j(\"result\",e[0].dataType,pe.length,A),be=[ee,ve],Ce=[{type:\"int32\",data:b},{type:\"int32\",data:I},{type:\"int32\",data:_}];h&&Ce.push(...q(p)),V&&Ce.push(...q(W)),B&&Ce.push(...q(J));let fe=[];fe.push(V?\"rank\":\"dims\"),fe.push(B?\"rank\":\"dims\");let ce=e.length>2,{activationFunction:Ue,applyActivation:ke}=ft(t,Z.type.value),He=ad(A,ce,ke,[y,ee,ve,Z],[d,a,p],n);if(ce){let X=n?A:1;be.push(z(\"bias\",e[2].dataType,e[2].dims.length,X)),Ce.push(...q(e[2].dims)),fe.push(\"rank\")}Ce.push(...q(pe));let L=X=>`\n  ${X.registerUniform(\"dimAOuter\",\"i32\").registerUniform(\"dimBOuter\",\"i32\").registerUniform(\"dimInner\",\"i32\").registerInternalVariables(y).declareVariables(...be,Z)}\n  ${Ue}\n  ${He}\n  ${S?fr(x,O,M,y):hr(x,O,M,y)}\n                   `;return{name:\"MatMul\",shaderCache:{hint:t.activationCacheKey+`${x}${S}${n}`,inputDependencies:fe},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:T[0],y:T[1],z:T[2]},programUniforms:Ce}),getShaderSource:L}}});var id,zi,Ui=Y(()=>{\"use strict\";St();we();xt();tn();Wn();gr();id=(e,t,r,o,n=!1,s,u=4,d=4,a=4,p=\"f32\")=>{let h=B=>{switch(B){case 1:return\"resData = x[xIndex];\";case 3:return`resData = vec3<${p}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;case 4:return\"resData = x[xIndex / 4];\";default:throw new Error(`innerElementSize ${B} is not supported.`)}},g=B=>{switch(B){case 1:return\"return w[row * i32(uniforms.w_shape[3]) + colIn];\";case 4:return\"return w[row * i32(uniforms.w_shape[3]) / 4 + colIn];\";default:throw new Error(`innerElementSize ${B} is not supported.`)}},y=e?`\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    `:`\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `,w=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,b=e?\"i32(uniforms.x_shape[1])\":\"i32(uniforms.x_shape[2])\",_=e?\"i32(uniforms.x_shape[2])\":\"i32(uniforms.x_shape[3])\",I=e?\"row\":\"col\",S=e?\"col\":\"row\",x=`\n    let inChannels = i32(uniforms.w_shape[2]);\n    let outWidth = ${e?\"i32(uniforms.result_shape[2])\":\"i32(uniforms.result_shape[3])\"};\n    let outRow = ${I} / outWidth;\n    let outCol = ${I} % outWidth;\n\n    let WRow = ${S} / (filterDims[1] * inChannels);\n    let WCol = ${S} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${S} % inChannels;\n    var resData = ${Le(u,p)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${b} && xCol >= 0 && xCol < ${_}) {\n      ${y}\n      let xIndex = getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape));\n      ${h(u)}\n    }\n    return resData;`,O=e?t&&o?`\n    let col = colIn * ${u};\n    ${x}`:`\n    let col = colIn * ${u};\n    if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n      ${x}\n    }\n    return ${Le(u,p)}(0.0);`:o&&r?`\n    let col = colIn * ${u};\n    ${x}`:`\n    let col = colIn * ${u};\n    if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n      ${x}\n    }\n    return ${Le(u,p)}(0.0);`,T=`${g(d)}`,M=Le(a,p),A=e?Le(u,p):Le(d,p),W=e?Le(d,p):Le(u,p),{activationFunction:V,applyActivation:G}=ft(s,M);return`\n    ${V}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${A} {\n      ${e?O:T}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${W} {\n      ${e?T:O}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${M}) {\n      let col = colIn * ${a};\n      if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${e?\"i32(uniforms.result_shape[2])\":\"i32(uniforms.result_shape[3])\"};\n      ${w}\n      ${en(n)}\n      ${G}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`},zi=(e,t,r,o,n,s,u,d)=>{let a=t.format===\"NHWC\",p=a?e[0].dims[3]:e[0].dims[1],h=r[0],g=a?r[2]:r[3],y=a?r[1]:r[2],w=a?r[3]:r[1],b=a&&(p%4===0||p%3===0)&&w%4===0,_=a?w:g*y,I=a?g*y:w,S=[8,8,1],x=o<=8?[4,1,1]:[4,4,1],O=[Math.ceil(_/S[0]/x[0]),Math.ceil(I/S[1]/x[1]),Math.ceil(h/S[2]/x[2])];Pe(\"verbose\",()=>`[conv2d_mm_webgpu] dispatch = ${O}`);let T=b?a&&p%4!==0?3:4:1,M=S[1]*x[1],A=S[0]*x[0],W=Math.max(S[0]*T,S[1]),V=o%M===0,G=n%A===0,J=s%W===0,B=b?[T,4,4]:[1,1,1],K=Ve(e[0].dataType),pe=b?4:1,ee=[{type:\"int32\",data:o},{type:\"int32\",data:n},{type:\"int32\",data:s}],ve=z(\"x\",e[0].dataType,e[0].dims.length,T===3?1:T),Z=z(\"w\",e[1].dataType,e[1].dims.length,pe),be=[ve,Z];ee.push(...q(e[0].dims)),ee.push(...q(e[1].dims));let Ce=`\n      fn setOutputAtIndex(flatIndex : i32, value : ${b?`vec4<${K}>`:K}) {\n        result[flatIndex] = ${b?`vec4<${K}>`:K}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${b?`vec4<${K}>`:K}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${b?\"/ 4\":\"\"}, value);\n      }`;if(u){let ce=z(\"bias\",e[2].dataType,e[2].dims.length,pe);be.push(ce),ee.push(...q(e[2].dims)),Ce+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${b?`vec4<${K}>`:K} {\n          return bias[coords.${a?\"w\":\"y\"}${b?\"/ 4\":\"\"}];\n        }`}let fe=j(\"result\",e[0].dataType,r.length,pe);return ee.push(...q(r)),{name:\"Conv2DMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:O[0],y:O[1],z:O[2]},programUniforms:ee}),getShaderSource:ce=>`\n        ${rn(\"uniforms.result_strides\")}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${ce.registerUniform(\"dimAOuter\",\"i32\").registerUniform(\"dimBOuter\",\"i32\").registerUniform(\"dimInner\",\"i32\").declareVariables(...be,fe)}\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[0]}, ${t.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${t.pads[0]}, ${t.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        ${Ce}\n        ${id(a,V,G,J,u,t,B[0],B[1],B[2],K)}\n            ${b?fr(x,S,K,void 0,!a,W):hr(x,S,K,void 0,!a,W,!1,void 0,d)}`}}});var Nn,Vi=Y(()=>{\"use strict\";Se();we();Gn();xt();Nn=(e,t,r)=>{let o=e.length>2,n=o?\"value += b[output_channel];\":\"\",s=e[0].dims,u=e[1].dims,d=u[0]/t.group,a=t.format===\"NHWC\",p=Hn(s,u,t.dilations,t.pads,t.strides,a),h=U.size(p),g=j(\"output\",e[0].dataType,p),{activationFunction:y,applyActivation:w}=ft(t,g.type.value),b=z(\"x\",e[0].dataType,s),_=z(\"w\",e[1].dataType,u),I=[b,_];o&&I.push(z(\"b\",e[2].dataType,e[2].dims));let S=x=>`\n  const strides: vec2<u32> = vec2(${t.strides[0]}u, ${t.strides[1]}u);\n  const pads: vec2<u32> = vec2(${t.pads[0]}u, ${t.pads[1]}u);\n\n  ${x.declareVariables(...I,g)}\n\n  ${y}\n\n  ${x.mainStart()}\n    ${x.guardAgainstOutOfBoundsWorkgroupSizes(h)}\n\n    let outputIndices = ${g.offsetToIndices(\"global_idx\")};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${a?3:1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${a?1:2}], outputIndices[${a?2:3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${d}u;\n\n    var value: ${g.type.value} = ${g.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${u[1]}u; wInChannel++) {\n      let input_channel = group_id * ${u[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${u[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${t.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${s[a?1:2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${u[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${t.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${s[a?2:3]}u) {\n            continue;\n          }\n\n          let xVal = ${a?b.get(\"batch\",\"xHeight\",\"xWidth\",\"input_channel\"):b.get(\"batch\",\"input_channel\",\"xHeight\",\"xWidth\")};\n          let wVal = ${_.get(\"output_channel\",\"wInChannel\",\"wHeight\",\"wWidth\")};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${n}\n    ${w}\n    ${g.setByOffset(\"global_idx\",\"value\")}\n  }`;return{name:\"GroupedConv\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r?r(p):p,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(h/64)}}),getShaderSource:S}}});var Ln,sd,Wi,Fn=Y(()=>{\"use strict\";Se();gr();we();xt();Ln=(e,t,r,o,n=!1)=>{let s=e[0].dims,u=e[1].dims,d=s[s.length-2],a=u[u.length-1],p=s[s.length-1],h=Ne(a),g=Ne(p),y=Ne(d),w=U.size(r)/h/y,b=e.length>2,_=o?o.slice(0,-2):r.slice(0,-2),S=[U.size(_),d,a],x=[{type:\"uint32\",data:w},{type:\"uint32\",data:d},{type:\"uint32\",data:a},{type:\"uint32\",data:p},...q(_),...q(s),...q(u)];b&&x.push(...q(e[2].dims)),x.push(...q(S));let O=T=>{let M=jr(\"batch_dims\",e[0].dataType,_.length),A=z(\"a\",e[0].dataType,s.length,g),W=z(\"b\",e[1].dataType,u.length,h),V=j(\"output\",e[0].dataType,S.length,h),{activationFunction:G,applyActivation:J}=ft(t,V.type.value),B=[A,W],K=\"\";if(b){let fe=n?h:1;B.push(z(\"bias\",e[2].dataType,e[2].dims.length,fe)),K=`${n?`value += bias[col / ${fe}];`:`value += ${V.type.value}(bias[row + i]);`}`}let pe=s.slice(0,-2),ee=u.slice(0,-2),ve=Ft(pe,_),Z=Ft(ee,_),be=(fe,ce)=>{let Ue=fe.rank,ke=fe.name;if(Ue===2)return`var ${ke}_indices = ${fe.type.indices}(0u, 0u);`;let He=M.rank,L=`var ${ke}_indices: ${fe.type.indices};`;for(let X=Ue-2-1,he=He-1;X>=0;X--,he--)L+=`\n${ke}_indices[${X}] = ${He>1?`batch_indices[${he}]`:\"batch_indices\"};`;return ce.forEach(X=>{L+=`\n${ke}_indices[${X}] = 0;`}),L+=`${ke}_indices[${Ue-2}] = 0u;\n                     ${ke}_indices[${Ue-1}] = 0u;`,L},Ce=()=>{let fe=`var a_data: ${A.type.value};`;for(let ce=0;ce<g;ce++)fe+=`\n              let b_data${ce} = b[(b_offset + (k + ${ce}) * uniforms.N + col) / ${h}];`;for(let ce=0;ce<y;ce++){fe+=`a_data = a[(a_offset + (row + ${ce}) * uniforms.K + k) / ${g}];`;for(let Ue=0;Ue<g;Ue++)fe+=`\n            values[${ce}] = fma(${W.type.value}(a_data${g===1?\"\":`[${Ue}]`}), b_data${Ue}, values[${ce}]);\n`}return fe};return`\n  ${T.registerUniform(\"outputSize\",\"u32\").registerUniform(\"M\",\"u32\").registerUniform(\"N\",\"u32\").registerUniform(\"K\",\"u32\").registerInternalVariables(M).declareVariables(...B,V)}\n  ${G}\n  ${T.mainStart()}\n    ${T.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n    let col = (global_idx % (uniforms.N / ${h})) * ${h};\n    var index1 = global_idx / (uniforms.N / ${h});\n    let stride1 = uniforms.M / ${y};\n    let row = (index1 % stride1) * ${y};\n    let batch = index1 / stride1;\n\n    ${r.length===2?\"\":`let batch_indices = ${M.offsetToIndices(\"batch\")};`}\n    ${be(A,ve)}\n    let a_offset = ${A.indicesToOffset(\"a_indices\")};\n    ${be(W,Z)}\n    let b_offset = ${W.indicesToOffset(\"b_indices\")};\n    var values: array<${V.type.value}, ${y}>;\n    for (var k: u32 = 0u; k < uniforms.K; k = k + ${g}) {\n      ${Ce()}\n    }\n    for (var i = 0u; i < ${y}u; i++) {\n      var value = values[i];\n      ${K}\n      ${J}\n      let cur_indices = ${V.type.indices}(batch, row + i, col);\n      let offset = ${V.indicesToOffset(\"cur_indices\")};\n      ${V.setByOffset(`offset / ${h}`,\"value\")};\n    }\n  }\n  `};return{name:\"MatMulNaive\",shaderCache:{hint:`${t.activationCacheKey}_${h}_${g}_${y}_${n}`,inputDependencies:b?[\"rank\",\"rank\",\"rank\"]:[\"rank\",\"rank\"]},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(w/64)},programUniforms:x}),getShaderSource:O}},sd=e=>{if(!e||e.length!==2)throw new Error(\"MatMul requires 2 inputs.\");if(e[0].dims[e[0].dims.length-1]!==e[1].dims[e[1].dims.length-2])throw new Error(\"shared dimension does not match.\")},Wi=e=>{sd(e.inputs);let t=st.calcShape(e.inputs[0].dims,e.inputs[1].dims,!0);if(!t)throw new Error(\"Can't use matmul on the given tensors\");let r=t[t.length-1],o=e.inputs[0].dims[e.inputs[0].dims.length-1];r<8&&o<8?e.compute(Ln(e.inputs,{activation:\"\",activationCacheKey:\"\"},t)):e.compute(nn(e.inputs,{activation:\"\",activationCacheKey:\"\"},t))}});var Hn,Ni,ud,Hi,qn,ld,dd,jn,Gn=Y(()=>{\"use strict\";Se();We();Ui();gr();Vi();xt();Fn();qt();Hn=(e,t,r,o,n,s)=>{let u=e[0],d=e.slice(s?1:2,s?3:4),a=d.length,p=t[0],g=t.slice(2).map((b,_)=>b+(b-1)*(r[_]-1)),w=d.map((b,_)=>b+o[_]+o[_+a]).map((b,_)=>Math.floor((b-g[_]+n[_])/n[_]));return w.splice(0,0,u),w.splice(s?3:1,0,p),w},Ni=[2,3,1,0],ud=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support conv 1D and 2D\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],o=e[1].dims[1]*t.group;if(r!==o)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");if(e.length===3&&(e[2].dims.length!==1||e[1].dims[0]!==e[2].dims[0]))throw new Error(\"invalid bias\");let n=e[0].dims.length-2;if(t.dilations.length!==n)throw new Error(`dilations should be ${n}D`);if(t.strides.length!==n)throw new Error(`strides should be ${n}D`);if(t.pads.length!==n*2)throw new Error(`pads should be ${n*2}D`);if(t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\")},Hi=(e,t)=>{let r=e.kernelShape.slice();for(let s=2;s<t[1].dims.length;++s)r[s-2]===0&&(r[s-2]=t[1].dims[s]);let o=e.pads.slice();kt.adjustPadsBasedOnAutoPad(t[0].dims,e.strides,e.dilations,r,o,e.format===\"NHWC\",e.autoPad);let n=Object.assign({},e);return Object.assign(n,{kernelShape:r,pads:o,cacheKey:e.cacheKey}),n},qn=e=>{let t=Jr(e),r=e.format,o=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],n=e.dilations,s=e.group,u=e.kernel_shape,d=e.pads,a=e.strides,p=e.w_is_const();return ge({autoPad:o,format:r,dilations:n,group:s,kernelShape:u,pads:d,strides:a,wIsConst:p,...t})},ld=(e,t,r)=>{let o=Hi(r,t);if(r.group!==1){e.compute(Nn(t,o));return}let n=r.format===\"NHWC\",s=t.length===3,u=t[0].dims[n?1:2],d=t[0].dims[n?2:3],a=t[0].dims[n?3:1],p=t[1].dims[2],h=t[1].dims[3],g=Hn(t[0].dims,t[1].dims,r.dilations,o.pads,r.strides,n),y=g[n?1:2],w=g[n?2:3],b=g[n?3:1],_=n&&p===u&&h===d&&r.pads[0]===0&&r.pads[1]===0;if(_||p===1&&h===1&&r.dilations[0]===1&&r.dilations[1]===1&&r.strides[0]===1&&r.strides[1]===1&&r.pads[0]===0&&r.pads[1]===0){let A=g[0],W,V,G,J=[];if(n){let pe=e.kernelCustomData.wT??e.compute(nt(t[1],Ni),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];if(r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=pe),_){let ee=u*d*a;W=t[0].reshape([1,A,ee]),V=pe.reshape([1,ee,b]),G=[1,A,b]}else W=t[0].reshape([A,u*d,a]),V=pe.reshape([1,a,b]),G=[A,y*w,b];J.push(W),J.push(V)}else W=t[0].reshape([A,a,u*d]),V=t[1].reshape([1,b,a]),G=[A,b,y*w],J.push(V),J.push(W);s&&J.push(t[2]);let B=G[2],K=J[0].dims[J[0].dims.length-1];B<8&&K<8?e.compute(Ln(J,o,g,G,n),{inputs:J}):e.compute(nn(J,o,g,G,n),{inputs:J});return}let I=!0,S=e.kernelCustomData.wT??e.compute(nt(t[1],Ni),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=S);let x=[t[0],S];s&&x.push(t[2]);let O=n?y*w:b,T=n?b:y*w,M=p*h*a;e.compute(zi(x,o,g,O,T,M,s,I),{inputs:x})},dd=(e,t)=>{let r=t.format===\"NHWC\",o=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];e.inputs.length===3&&o.push(e.inputs[2]);let n=[0,t.pads[0],0,t.pads[1]],s=[1].concat(t.strides),u=[1].concat(t.dilations),d=[1].concat(t.kernelShape),a=Hi({...t,pads:n,strides:s,dilations:u,kernelShape:d},o);e.compute(Nn(o,a,p=>r?[p[0],p[2],p[3]]:[]))},jn=(e,t)=>{ud(e.inputs,t),e.inputs[0].dims.length===3?dd(e,t):ld(e,e.inputs,t)}});var cd,Gi,Li=Y(()=>{\"use strict\";St();we();xt();tn();Wn();gr();cd=(e,t=!1,r,o=4)=>{let n=Le(o,\"f32\"),s=x=>{switch(x){case 1:return\"return w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];\";case 4:return`\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = w[getIndexFromCoords4D(coord, vec4<i32>(uniforms.w_shape))];\n            let v1 = w[getIndexFromCoords4D(coord1, vec4<i32>(uniforms.w_shape))];\n            let v2 = w[getIndexFromCoords4D(coord2, vec4<i32>(uniforms.w_shape))];\n            let v3 = w[getIndexFromCoords4D(coord3, vec4<i32>(uniforms.w_shape))];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;default:throw new Error(`innerElementSize ${x} is not supported.`)}},u=e?`\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      `:`\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `,d=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,a=e?\"outBackprop[1]\":\"outBackprop[2]\",p=e?\"outBackprop[2]\":\"outBackprop[3]\",h=e?\"row\":\"col\",g=e?\"col\":\"row\",y=`\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let outWidth = ${e?\"i32(uniforms.result_shape[2])\":\"i32(uniforms.result_shape[3])\"};\n      let outRow = ${h} / outWidth;\n      let outCol = ${h} % outWidth;\n\n      let WRow = ${g} / (filterDims[1] * inChannels);\n      let WCol = ${g} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${a}) || fract(xR) > 0.0) {\n        return ${n}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${p}) || fract(xC) > 0.0) {\n        return ${n}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${g} % inChannels;\n      ${u}\n      return x[getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape))/${o}];`,w=e?`\n      let col = colIn * ${o};\n      if (row < uniforms.dimAOuter && col < uniforms.dimInner) {\n        ${y}\n      }\n      return ${n}(0.0);`:`\n      let col = colIn * ${o};\n      if (row < uniforms.dimInner && col < uniforms.dimBOuter) {\n        ${y}\n      }\n      return ${n}(0.0);`,b=`\n      let col = colIn * ${o};\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${e?\"row < uniforms.dimInner && col < uniforms.dimBOuter\":\"row < uniforms.dimInner && col < uniforms.dimAOuter\"}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${s(o)}\n      }\n      return ${n}(0.0);\n      `,{activationFunction:_,applyActivation:I}=ft(r,n);return`\n      ${_}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${n} {\n    ${e?w:b}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${n} {\n    ${e?b:w}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${n}) {\n    let col = colIn * ${o};\n    if (row < uniforms.dimAOuter && col < uniforms.dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${e?\"i32(uniforms.result_shape[2])\":\"i32(uniforms.result_shape[3])\"};\n      ${d}\n      ${en(t)}\n      ${I}\n      result[getIndexFromCoords4D(coords, vec4<i32>(uniforms.result_shape))/${o}] = value;\n    }\n  }`},Gi=(e,t,r,o,n,s,u,d)=>{let a=t.format===\"NHWC\",p=a?e[0].dims[3]:e[0].dims[1],h=r[0],g=a?r[2]:r[3],y=a?r[1]:r[2],w=a?r[3]:r[1],b=a?p%4===0&&w%4===0:g%4===0&&w%4===0,_=a?w:g*y,I=a?g*y:w,S=b?[8,8,1]:[_<=4||I<=4?4:16,_>4&&I<=4?4:16,1],x=b?[4,4,1]:[_<=4?1:4,_>4&&I<=4?1:4,1],O=[Math.ceil(_/S[0]/x[0]),Math.ceil(I/S[1]/x[1]),Math.ceil(h/S[2]/x[2])];Pe(\"verbose\",()=>`[conv_backprop_mm_webgpu] dispatch = ${O}`);let T=b?4:1,M=Math.max(S[0]*T,S[1]),A=b?4:1,W=[{type:\"int32\",data:o},{type:\"int32\",data:n},{type:\"int32\",data:s}],V=z(\"x\",e[0].dataType,e[0].dims.length,A),G=z(\"w\",e[1].dataType,e[1].dims.length,1),J=j(\"result\",e[0].dataType,r.length,A),B=[V,G];W.push(...q(e[0].dims)),W.push(...q(e[1].dims));let K=\"\";if(u){let pe=z(\"bias\",e[2].dataType,e[2].dims.length,A);B.push(pe),W.push(...q(e[2].dims)),K+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${b?\"vec4<f32>\":\"f32\"} {\n          return bias[coords.${a?\"w\":\"y\"}${b?\"/ 4\":\"\"}];\n        }`}return W.push(...q(r)),{name:\"Conv2DTransposeMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:O[0],y:O[1],z:O[2]},programUniforms:W}),getShaderSource:pe=>`\n        ${rn(\"uniforms.result_strides\")}\n        ${pe.registerUniform(\"dimAOuter\",\"i32\").registerUniform(\"dimBOuter\",\"i32\").registerUniform(\"dimInner\",\"i32\").declareVariables(...B,J)};\n        const outBackprop : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[a?1:2]}, ${t.kernelShape[a?2:3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${t.dilations[0]<=1?0:(t.kernelShape[a?1:2]-1)*(t.dilations[0]-1)},\n              ${t.dilations[1]<=1?0:(t.kernelShape[a?2:3]-1)*(t.dilations[1]-1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${t.pads[0]+t.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${t.pads[1]+t.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        const dimAOuter : i32 = ${o};\n        const dimBOuter : i32 = ${n};\n        const dimInner : i32 = ${s};\n        ${K}\n        ${cd(a,u,t,T)}\n        ${b?fr(x,S,\"f32\",void 0,!a,M):hr(x,S,\"f32\",void 0,!a,M,!1,void 0,d)}`}}});var pd,Kn,Fi=Y(()=>{\"use strict\";St();Se();we();pd=(e,t,r,o,n,s,u=!1,d)=>{let a=r.format===\"NHWC\",p=a?1:2,h=a?2:3,g=a?3:1,y=U.size(o),w=u?2:1,b=r.group,_=t[1].dims,I=_[0]/b,S=_[1],x=`\n  fn setOutputAtIndex(flatIndex : u32, value : ${u?`vec4<${d}>`:d}) {\n    result[flatIndex] = ${u?`vec4<${d}>`:d}(value);\n  }`;n&&(x+=`\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${u?`vec4<${d}>`:d} {\n      return bias[coords.${a?\"w\":\"y\"}${u?\"/ 4\":\"\"}];\n    }`);let O=u?4:1,T=z(\"W\",t[1].dataType,t[1].dims,O),M=z(\"Dy\",t[0].dataType,t[0].dims,O),A=[M,T];n&&A.push(z(\"bias\",t[2].dataType,[o[g]],O));let W=j(\"result\",t[0].dataType,o,O),V=`{\n        let batch: u32 = ${s?\"global_id.z\":\"workgroup_id.z\"} / outShape[1];\n        let r = ${s?\"global_id.z\":\"workgroup_id.z\"} % outShape[1];\n        let c = ${s?\"global_id.y\":\"workgroup_id.y\"} * ${w};\n        let d1: u32 = ${s?\"global_id.x\":\"workgroup_id.x\"} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${d}>, ${w}>;\n        for (var i = 0; i < ${w}; i++) {\n          dotProd[i] = vec4<${d}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${d}(dyCorner.x) + ${d}(wR)) / ${d}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${d}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${d}(dyCorner.y) + ${d}(wC)) / ${d}(strides.y);\n            let dyC2 = (${d}(dyCorner.y) + 1.0 + ${d}(wC)) / ${d}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${d}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${d}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${M.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${M.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n\n                dotProd[1] = dotProd[1] + vec4<${d}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${g}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${M.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${T.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${M.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${w}; i = i + 1) {\n          let value = dotProd[i] + ${n?\"bias[c+i]\":`vec4<${d}>(0.0)`};\n          ${W.set(\"batch\",\"r\",\"c + i\",\"d1\",\"value\")};\n        }\n      }`,G=`\n          let outputIndices = ${W.offsetToIndices(\"global_idx\")};\n          let batch = ${W.indicesGet(\"outputIndices\",0)};\n          let d1 = ${W.indicesGet(\"outputIndices\",g)};\n          let r = ${W.indicesGet(\"outputIndices\",p)};\n          let c = ${W.indicesGet(\"outputIndices\",h)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${S};\n          let wOutChannel = d1 - groupId * ${S};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = ${d}(0.0);\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${d}(dyRCorner) + ${d}(wR)) / ${d}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${d}(outBackprop[${p}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${d}(dyCCorner) + ${d}(wC)) / ${d}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${d}(outBackprop[${h}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${I};\n              for (var d2: u32 = 0; d2 < ${I}; d2 = d2 + 1) {\n                let xValue = ${a?M.get(\"batch\",\"idyR\",\"idyC\",\"inputChannel\"):M.get(\"batch\",\"inputChannel\",\"idyR\",\"idyC\")};\n                let wValue = ${T.get(\"inputChannel\",\"wOutChannel\",\"u32(wRPerm)\",\"u32(wCPerm)\")};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${n?\"bias[d1]\":`${d}(0.0)`};\n          ${W.setByOffset(\"global_idx\",\"value\")};\n        `;return`\n  ${e.declareVariables(...A,W)}\n  ${x}\n  const outShape : vec4<u32> = vec4<u32>(${o.join(\",\")});\n  const outBackprop : vec4<u32> = vec4<u32>(${t[0].dims.join(\",\")});\n  const strides : vec2<u32> = vec2<u32>(${r.strides[0]}, ${r.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${r.kernelShape[a?1:2]}, ${r.kernelShape[a?2:3]});\n  const dilations : vec2<u32> = vec2<u32>(${r.dilations[0]}, ${r.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${r.dilations[0]<=1?0:(r.kernelShape[a?1:2]-1)*(r.dilations[0]-1)},\n          ${r.dilations[1]<=1?0:(r.kernelShape[a?2:3]-1)*(r.dilations[1]-1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${r.pads[0]+r.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${r.pads[1]+r.pads[3]})/2);\n    ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(y)};\n  ${u?V:G}}`},Kn=(e,t,r)=>{let o=e.length>2,n=t.outputShape,s=U.size(n),u=[Math.ceil(s/64),1,1];Pe(\"verbose\",()=>`[conv2d_backprop_webgpu] dispatch = ${u}`);let d=Ve(e[0].dataType);return{name:\"ConvTranspose2D\",shaderCache:{hint:t.cacheKey},getRunData:()=>({dispatchGroup:{x:u[0],y:u[1],z:u[2]},outputs:[{dims:r?r(n):n,dataType:e[0].dataType}]}),getShaderSource:a=>pd(a,e,t,n,o,u[1]===1&&u[2]===1,!1,d)}}});var md,fd,hd,qi,ji,gd,yd,bd,wd,Ki,Yi=Y(()=>{\"use strict\";We();Li();Fi();xt();qt();md=(e,t,r,o,n,s)=>(e-1)*t+r+(o-1)*n+1-s,fd=(e,t,r,o,n)=>{let s=Math.floor(e/2);t===\"SAME_UPPER\"?(r[o]=s,r[n]=e-s):t===\"SAME_LOWER\"&&(r[o]=e-s,r[n]=s)},hd=(e,t,r,o,n,s,u,d,a,p)=>{let h=e.length-2,g=p.length===0;if(a.length===0)for(let b=0;b<h;++b)a.push(0);let y=e[0],w=t[d?3:1]*n;for(let b=0,_=e.length-h-(d?1:0);b<h;++b,++_){let I=e[_],S=g?I*u[b]:p[b],x=md(I,u[b],s[b],t[_],r[b],S);fd(x,o,s,b,b+h),g&&p.push(u[b]*(I-1)+a[b]+(t[_]-1)*r[b]+1-s[b]-s[b+h])}p.splice(0,0,y),p.splice(d?3:1,0,w)},qi=(e,t)=>{let r=e.kernelShape.slice();if(e.kernelShape.length===0||e.kernelShape.reduce((y,w)=>y*w,1)===0){r.length=0;for(let y=2;y<t[1].dims.length;++y)r.push(t[1].dims[y])}let o=e.format===\"NHWC\";r.splice(0,0,t[1].dims[0]),r.splice(o?3:1,0,t[1].dims[1]);let n=e.pads.slice(),s=e.outputShape.slice(),u=e.outputPadding.slice(),d=t[0].dims,a=e.dilations.slice();if(a.reduce((y,w)=>y+w,0)===0){let y=t[0].dims.length-2;a=new Array(y).fill(1)}let p=e.strides.slice();if(p.reduce((y,w)=>y+w,0)===0){let y=t[0].dims.length-2;p=new Array(y).fill(1)}hd(d,r,a,e.autoPad,e.group,n,p,o,u,s);let h=Object.assign({},e),g=e.cacheKey+[r.join(\"n,\"),n.join(\",\"),p.join(\",\"),u.join(\",\"),s.join(\",\"),a.join(\",\")].join(\"_\");return Object.assign(h,{kernelShape:r,pads:n,outputPadding:u,outputShape:s,dilations:a,strides:p,cacheKey:g}),h},ji=e=>{let t=Jr(e),r=e.format,o=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][typeof e.autoPad>\"u\"?0:e.autoPad],n=e.dilations,s=e.group,u=e.kernelShape,d=e.pads,a=e.strides,p=e.wIsConst(),h=e.outputPadding,g=e.outputShape;return ge({autoPad:o,format:r,dilations:n,group:s,kernelShape:u,outputPadding:h,outputShape:g,pads:d,strides:a,wIsConst:p,...t})},gd=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support 2-dimensional conv\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],o=e[1].dims[0];if(r!==o)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");let n=e[1].dims[1]*t.group;if(e.length===3&&(e[2].dims.length!==1||e[2].dims[0]!==n))throw new Error(\"invalid bias\");let s=e[0].dims.length-2;if(t.dilations.reduce((h,g)=>h+g,0)>0&&t.dilations.length!==s)throw new Error(`dilations should be ${s}D`);if(t.strides.reduce((h,g)=>h+g,0)>0&&t.strides.length!==s)throw new Error(`strides should be ${s}D`);if(t.pads.reduce((h,g)=>h+g,0)>0&&t.pads.length!==s*2)throw new Error(`pads should be ${s*2}D`);if(t.outputPadding.length!==s&&t.outputPadding.length!==0)throw new Error(`output_padding should be ${s}D`);if(t.kernelShape.reduce((h,g)=>h+g,0)>0&&t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\");if(t.outputShape.length!==0&&t.outputShape.length!==e[0].dims.length-2)throw new Error(\"invalid output shape\")},yd=[2,3,1,0],bd=(e,t,r)=>{let o=qi(r,t),n=r.format===\"NHWC\",s=o.outputShape,u=s[n?3:1],d=t[0].dims[n?3:1];if(o.group!==1||u===1&&d===1){e.compute(Kn(t,o));return}let a=s[n?1:2],p=s[n?2:3],h=t[1].dims[2],g=t[1].dims[3],y=n?a*p:u,w=n?u:a*p,b=h*g*d,_=!0,I=e.kernelCustomData.wT??e.compute(nt(t[1],yd),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=I);let S=[t[0],I],x=t.length===3;x&&(!n&&t[2].dims.length===1?S.push(t[2].reshape([t[2].dims[0],1,1])):S.push(t[2])),e.compute(Gi(S,o,s,y,w,b,x,_),{inputs:S})},wd=(e,t)=>{let r=t.format===\"NHWC\",o=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];o.length===3&&o.push(e.inputs[2]);let n=t.kernelShape;(n.length===0||n[0]===0)&&(n=[e.inputs[1].dims[2]]);let s=t.dilations;(s.length===0||s[0]===0)&&(s=[1]);let u=t.strides;(u.length===0||u[0]===0)&&(u=[1]);let d=t.pads;d.length===0&&(d=[0,0]),d=[0,d[0],0,d[1]],u=[1].concat(u),s=[1].concat(s),n=[1].concat(n);let a=qi({...t,pads:d,strides:u,dilations:s,kernelShape:n},o);e.compute(Kn(o,a,p=>r?[p[0],p[2],p[3]]:[p[0],p[1],p[3]]))},Ki=(e,t)=>{gd(e.inputs,t),e.inputs[0].dims.length===3?wd(e,t):bd(e,e.inputs,t)}});var vd,Zi,Xi,Qi=Y(()=>{\"use strict\";De();Se();We();we();vd=(e,t,r,o)=>{let n=U.size(t),s=t.length,u=z(\"input\",e,s),d=j(\"output\",e,s),a=r.dataType===6?r.getInt32Array()[0]:Number(r.getBigInt64Array()[0]),p=U.normalizeAxis(a,s),h=g=>{let y=` i32(${u.indicesGet(\"inputIndices\",\"uniforms.axis\")}) `,w=de(\"uniforms.input_shape\",\"uniforms.axis\",s),b=o.reverse?y+(o.exclusive?\" + 1\":\"\"):\"0\",_=o.reverse?w:y+(o.exclusive?\"\":\" + 1\");return`\n                ${g.registerUniform(\"outputSize\",\"u32\").registerUniform(\"axis\",\"u32\").declareVariables(u,d)}\n                ${g.mainStart()}\n                  ${g.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n                  var inputIndices = ${d.offsetToIndices(\"global_idx\")};\n                  var sum = ${d.type.value}(0);\n                  let first : i32 = ${b};\n                  let last : i32 = ${_};\n                  for (var i : i32 = first; i < last; i++) {\n                    ${u.indicesSet(\"inputIndices\",\"uniforms.axis\",\"u32(i)\")};\n                    sum = sum + ${u.getByIndices(\"inputIndices\")};\n                  }\n                  ${d.setByOffset(\"global_idx\",\"sum\")};\n                }`};return{name:\"CumSum\",shaderCache:{hint:o.cacheKey,inputDependencies:[\"rank\"]},getRunData:()=>({outputs:[{dims:t,dataType:e}],dispatchGroup:{x:Math.ceil(n/64)},programUniforms:[{type:\"uint32\",data:n},{type:\"int32\",data:p},...q(t),...q(t)]}),getShaderSource:h}},Zi=(e,t)=>{let r=e.inputs[0].dims,o=e.inputs[0].dataType,n=e.inputs[1];e.compute(vd(o,r,n,t),{inputs:[0]})},Xi=e=>{let t=e.exclusive===1,r=e.reverse===1;return ge({exclusive:t,reverse:r})}});var Yn,on,Ji,$d,Sd,Zn,Xn,es,xd,ts,rs,ns=Y(()=>{\"use strict\";Se();We();we();Yn=\"[a-zA-Z]|\\\\.\\\\.\\\\.\",on=\"(\"+Yn+\")+\",Ji=\"^\"+on+\"$\",$d=\"(\"+on+\",)*\"+on,Sd=\"^\"+$d+\"$\",Zn=class{constructor(t=-1){this.symbolToIndices=new Map,this.inputIndex=t}addSymbol(t,r){let o=this.symbolToIndices.get(t);o===void 0?o=[r]:o.push(r),this.symbolToIndices.set(t,o)}},Xn=class{constructor(t,r){this.equation=r;this.hasEllipsis=!1,this.symbolToInfo=new Map,this.lhs=new Array,this.outputDims=[];let[o,n]=r.includes(\"->\")?r.split(\"->\",2):[r,\"\"];if(!o.match(RegExp(Sd)))throw new Error(\"Invalid LHS term\");if(o.split(\",\").forEach((d,a)=>{let p=t[a].dims.slice();if(!d.match(RegExp(Ji)))throw new Error(\"Invalid LHS term\");let h=this.processTerm(d,!0,p,a);this.lhs.push(h)}),n===\"\")n+=[...this.symbolToInfo.entries()].filter(([d,a])=>a.count===1||d===\"...\").map(([d])=>d).join(\"\");else if(!n.match(RegExp(on)))throw new Error(\"Invalid RHS\");n.match(RegExp(Yn,\"g\"))?.forEach(d=>{if(d===\"...\")this.outputDims=this.outputDims.concat(this.ellipsisDims);else{let a=this.symbolToInfo.get(d);if(a===void 0)throw new Error(\"Invalid RHS symbol\");this.outputDims.push(a.dimValue)}}),this.rhs=this.processTerm(n,!1,this.outputDims)}addSymbol(t,r,o){let n=this.symbolToInfo.get(t);if(n!==void 0){if(n.dimValue!==r&&n.count!==1)throw new Error(\"Dimension mismatch\");n.count++,n.inputIndices.push(o)}else n={count:1,dimValue:r,inputIndices:[o]};this.symbolToInfo.set(t,n)}processTerm(t,r,o,n=-1){let s=o.length,u=!1,d=[],a=0;if(!t.match(RegExp(Ji))&&!r&&t!==\"\")throw new Error(\"Invalid LHS term\");let p=t.match(RegExp(Yn,\"g\")),h=new Zn(n);return p?.forEach((g,y)=>{if(g===\"...\"){if(u)throw new Error(\"Only one ellipsis is allowed per input term\");u=!0;let w=s-p.length+1;if(w<0)throw new Error(\"Ellipsis out of bounds\");if(d=o.slice(a,a+w),this.hasEllipsis){if(this.ellipsisDims.length!==d.length||this.ellipsisDims.toString()!==d.toString())throw new Error(\"Ellipsis dimensions mismatch\")}else if(r)this.hasEllipsis=!0,this.ellipsisDims=d;else throw new Error(\"Ellipsis must be specified in the LHS\");for(let b=0;b<d.length;b++){let _=String.fromCharCode(\"0\".charCodeAt(0)+b);h.addSymbol(_,y+b),this.addSymbol(_,o[a++],n)}}else h.addSymbol(g,y+(this.hasEllipsis?this.ellipsisDims.length-1:0)),this.addSymbol(g,o[a++],n)}),h}},es=e=>e+\"_max\",xd=(e,t,r,o,n)=>{let u=t.map((w,b)=>e[b]?w.length:w).map((w,b)=>z(`input${b}`,r,w)),d=U.size(n),a=Oe(n.length),p=a?n.length:n,h=j(\"output\",r,p),g=[...o.symbolToInfo.keys()].filter(w=>!o.rhs.symbolToIndices.has(w)),y=w=>{let b=[],_=\"var prod = 1.0;\",I=\"var sum = 0.0;\",S=\"sum += prod;\",x=[],O=[],T=[],M=[],A=o.symbolToInfo.size===o.rhs.symbolToIndices.size;o.symbolToInfo.forEach((V,G)=>{if(o.rhs.symbolToIndices.has(G)){let J=o.rhs.symbolToIndices.get(G)?.[0];J!==void 0&&o.lhs.forEach((B,K)=>{if(V.inputIndices.includes(K)){let pe=B.symbolToIndices.get(G);if(pe===void 0)throw new Error(\"Invalid symbol error\");pe.forEach(ee=>{b.push(`${u[K].indicesSet(`input${K}Indices`,ee,h.indicesGet(\"outputIndices\",J))}`)})}})}else o.lhs.forEach((J,B)=>{if(V.inputIndices.includes(B)){let K=J.symbolToIndices.get(G);if(K===void 0)throw new Error(\"Invalid symbol error\");K.forEach(pe=>{x.push(`${u[B].indicesSet(`input${B}Indices`,pe,`${G}`)}`)}),M.push(`prod *= ${u[B].getByIndices(`input${B}Indices`)};`)}}),O.push(`for(var ${G}: u32 = 0; ${G} < uniforms.${es(G)}; ${G}++) {`),T.push(\"}\")});let W=A?[...b,`let sum = ${u.map((V,G)=>V.getByIndices(`input${G}Indices`)).join(\" * \")};`]:[...b,I,...O,...x,_,...M,S,...T];return`\n            ${w.registerUniforms(g.map(V=>({name:`${es(V)}`,type:\"u32\"}))).registerUniform(\"outputSize\",\"u32\").declareVariables(...u,h)}\n\n            ${w.mainStart()}\n            ${w.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n            var outputIndices = ${h.offsetToIndices(\"global_idx\")};\n            ${u.map((V,G)=>`var input${G}Indices: ${u[G].type.indices};`).join(`\n`)}\n            ${W.join(`\n`)};\n            ${h.setByOffset(\"global_idx\",\"sum\")};\n          }`};return{name:\"Einsum\",shaderCache:{hint:o.equation,inputDependencies:e.map(w=>w?\"rank\":\"dims\")},getRunData:()=>{let w=g.filter(_=>o.symbolToInfo.has(_)).map(_=>({type:\"uint32\",data:o.symbolToInfo.get(_)?.dimValue||0}));w.push({type:\"uint32\",data:d});let b=t.filter((_,I)=>e[I]).map((_,I)=>[...q(_)]).reduce((_,I)=>_.concat(I),w);return a&&b.push(...q(n)),{outputs:[{dims:n,dataType:r}],dispatchGroup:{x:Math.ceil(d/64)},programUniforms:b}},getShaderSource:y}},ts=(e,t)=>{let r=new Xn(e.inputs,t.equation),o=e.inputs.map((u,d)=>Oe(u.dims.length)),n=r.outputDims,s=e.inputs.map((u,d)=>u.dims);e.compute(xd(o,s,e.inputs[0].dataType,r,n))},rs=e=>{let t=e.equation.replace(/\\s+/g,\"\");return ge({equation:t})}});var _d,os,Cd,Id,as,is=Y(()=>{\"use strict\";De();Se();we();_d=e=>{if(!e||e.length!==2)throw new Error(\"Expand requires 2 input.\");let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),o=r.length<t.length?0:r.length-t.length,n=t.length<r.length?0:t.length-r.length;for(;o<r.length&&n<t.length;++o,++n)if(r[o]!==t[n]&&r[o]!==1&&t[n]!==1)throw new Error(\"Expand requires shape to be broadcastable to input\")},os=(e,t)=>{let r=e.length-t.length,o=[];for(let n=0;n<r;++n)o.push(e[n]);for(let n=0;n<t.length;++n)o.push(t[n]===1?e[n+r]:t[n]);return o},Cd=(e,t)=>e.length>t.length?os(e,t):os(t,e),Id=e=>{let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),o=Cd(t,r),n=e[0].dataType,s=n===9?4:1,u=Math.ceil(U.size(o)/s),d=Oe(t.length),a=Oe(o.length),p=g=>{let y=d?t.length:t,w=a?o.length:o,b=z(\"input\",n,y,s),_=j(\"output\",n,w,s),I;if(n===9){let S=(x,O,T=\"\")=>`\n          let outputIndices${O} = ${_.offsetToIndices(`outputOffset + ${O}u`)};\n          let offset${O} = ${b.broadcastedIndicesToOffset(`outputIndices${O}`,_)};\n          let index${O} = offset${O} / 4u;\n          let component${O} = offset${O} % 4u;\n          ${x}[${O}] = ${T}(${b.getByOffset(`index${O}`)}[component${O}]);\n        `;I=`\n        let outputOffset = global_idx * ${s};\n        var data = vec4<u32>(0);\n        ${S(\"data\",0,\"u32\")}\n        ${S(\"data\",1,\"u32\")}\n        ${S(\"data\",2,\"u32\")}\n        ${S(\"data\",3,\"u32\")}\n        ${_.setByOffset(\"global_idx\",\"data\")}\n      }`}else I=`\n        let outputIndices = ${_.offsetToIndices(\"global_idx\")};\n        let inputOffset = ${b.broadcastedIndicesToOffset(\"outputIndices\",_)};\n        ${_.setByOffset(\"global_idx\",b.getByOffset(\"inputOffset\"))}\n      }`;return`\n    ${g.registerUniform(\"vec_size\",\"u32\").declareVariables(b,_)}\n    ${g.mainStart()}\n    ${g.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n    ${I}`},h=[{type:\"uint32\",data:u}];return d&&h.push(...q(t)),a&&h.push(...q(o)),{name:\"Expand\",shaderCache:{hint:`${o.length}`,inputDependencies:[d?\"rank\":\"dims\"]},getShaderSource:p,getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:h})}},as=e=>{_d(e.inputs),e.compute(Id(e.inputs),{inputs:[0]})}});var Ad,Td,ss,us,ls=Y(()=>{\"use strict\";De();Se();We();we();Ad=e=>{if(!e||e.length!==2)throw new Error(\"Gather requires 2 inputs.\")},Td=(e,t)=>{let r=e[0].dims,o=e[1].dims,n=r.length,s=U.normalizeAxis(t.axis,n),u=r.slice(0);u.splice(s,1,...o);let d=r[s],a=e[0].dataType===9?4:1,p=Math.ceil(U.size(u)/a),h=Oe(e[0].dims.length),g=h?e[0].dims.length:e[0].dims,y=Oe(e[1].dims.length),w=y?e[1].dims.length:e[1].dims,b=Oe(u.length),_=b?u.length:u,I=[{type:\"uint32\",data:p},{type:\"int32\",data:d},{type:\"uint32\",data:s}];h&&I.push(...q(e[0].dims)),y&&I.push(...q(e[1].dims)),b&&I.push(...q(u));let S=[];S.push(h?\"rank\":\"dims\"),S.push(y?\"rank\":\"dims\");let x=O=>{let T=z(\"data\",e[0].dataType,g,a),M=z(\"inputIndices\",e[1].dataType,w),A=j(\"output\",e[0].dataType,_,a),W=G=>{let J=o.length,B=`var indicesIndices${G}  = ${M.type.indices}(0);`;for(let K=0;K<J;K++)B+=`${J>1?`indicesIndices${G}[${K}]`:`indicesIndices${G}`} = ${u.length>1?`outputIndices${G}[uniforms.axis + ${K}]`:`outputIndices${G}`};`;B+=`\n          var idx${G} = ${M.getByIndices(`indicesIndices${G}`)};\n          if (idx${G} < 0) {\n            idx${G} = idx${G} + uniforms.axisDimLimit;\n          }\n          var dataIndices${G} = ${T.type.indices}(0);\n        `;for(let K=0,pe=0;K<n;K++)K===s?(B+=`${n>1?`dataIndices${G}[${K}]`:`dataIndices${G}`} = u32(idx${G});`,pe+=J):(B+=`${n>1?`dataIndices${G}[${K}]`:`dataIndices${G}`} = ${u.length>1?`outputIndices${G}[${pe}]`:`outputIndices${G}`};`,pe++);return B},V;if(e[0].dataType===9){let G=(J,B,K=\"\")=>`\n          let outputIndices${B} = ${A.offsetToIndices(`outputOffset + ${B}u`)};\n          ${W(B)};\n          let offset${B} = ${T.indicesToOffset(`dataIndices${B}`)};\n          let index${B} = offset${B} / 4u;\n          let component${B} = offset${B} % 4u;\n          ${J}[${B}] = ${K}(${T.getByOffset(`index${B}`)}[component${B}]);\n        `;V=`\n        let outputOffset = global_idx * ${a};\n        var value = vec4<u32>(0);\n        ${G(\"value\",0,\"u32\")}\n        ${G(\"value\",1,\"u32\")}\n        ${G(\"value\",2,\"u32\")}\n        ${G(\"value\",3,\"u32\")}\n        ${A.setByOffset(\"global_idx\",\"value\")}\n      `}else V=`\n      let outputIndices = ${A.offsetToIndices(\"global_idx\")};\n      ${W(\"\")};\n      let value = ${T.getByIndices(\"dataIndices\")};\n      ${A.setByOffset(\"global_idx\",\"value\")};\n      `;return`\n      ${O.registerUniform(\"outputSize\",\"u32\").registerUniform(\"axisDimLimit\",\"i32\").registerUniform(\"axis\",\"u32\").declareVariables(T,M,A)}\n      ${O.mainStart()}\n        ${O.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n        ${V}\n      }`};return{name:\"Gather\",shaderCache:{hint:t.cacheKey,inputDependencies:S},getRunData:()=>({outputs:[{dims:u,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(p/64)},programUniforms:I}),getShaderSource:x}},ss=e=>ge({axis:e.axis}),us=(e,t)=>{let r=e.inputs;Ad(r),e.compute(Td(e.inputs,t))}});var Ed,Od,ds,cs,ps=Y(()=>{\"use strict\";Se();We();we();Ed=e=>{if(!e||e.length!==2)throw new Error(\"GatherElements requires 2 inputs.\");if(e[0].dims.length<1)throw new Error(\"GatherElements requires that the data input be rank >= 1.\");if(e[0].dims.length!==e[1].dims.length)throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`)},Od=(e,t)=>{let r=e[0].dims,o=e[0].dataType,n=r.length,s=e[1].dims,u=e[1].dataType,d=U.normalizeAxis(t.axis,n),a=r[d],p=s.slice(0),h=U.size(p),g=z(\"input\",o,n),y=z(\"indicesInput\",u,s.length),w=j(\"output\",o,p.length),b=[{type:\"uint32\",data:h},{type:\"int32\",data:a},{type:\"uint32\",data:d}];return b.push(...q(r)),b.push(...q(s)),b.push(...q(p)),{name:\"GatherElements\",shaderCache:{inputDependencies:[\"rank\",\"rank\"]},getRunData:()=>({outputs:[{dims:p,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(h/64)},programUniforms:b}),getShaderSource:S=>`\n      ${S.registerUniform(\"outputSize\",\"u32\").registerUniform(\"axisDimLimit\",\"i32\").registerUniform(\"axis\",\"u32\").declareVariables(g,y,w)}\n      ${S.mainStart()}\n      ${S.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n\n      let outputIndices = ${w.offsetToIndices(\"global_idx\")};\n\n      var idx = ${y.getByOffset(\"global_idx\")};\n      if (idx < 0) {\n        idx = idx + uniforms.axisDimLimit;\n      }\n      var inputIndices = ${g.type.indices}(outputIndices);\n      ${g.indicesSet(\"inputIndices\",\"uniforms.axis\",\"u32(idx)\")};\n      let value = ${g.getByIndices(\"inputIndices\")};\n\n      ${w.setByOffset(\"global_idx\",\"value\")};\n  }`}},ds=e=>ge({axis:e.axis}),cs=(e,t)=>{let r=e.inputs;Ed(r),e.compute(Od(e.inputs,t))}});var Pd,kd,ms,fs,hs=Y(()=>{\"use strict\";Se();we();Pd=e=>{if(!e)throw new Error(\"Input is missing\");if(e.length<2||e.length>3)throw new Error(\"Invaid input number.\");if(e.length===3&&e[2].dims.length>2)throw new Error(\"Invalid input shape of C\");if(e[0].dataType!==e[1].dataType||e.length===3&&e[0].dataType!==e[2].dataType)throw new Error(\"Input types are mismatched\")},kd=(e,t)=>{let r=e[0].dims.slice(),o=e[1].dims.slice(),[n,s,u]=Lr.getShapeOfGemmResult(r,t.transA,o,t.transB,e.length===3?e[2].dims:void 0),d=[n,s];if(!d)throw new Error(\"Can't use gemm on the given tensors\");let a=U.size(d),p=[{type:\"uint32\",data:a},{type:\"uint32\",data:n},{type:\"uint32\",data:s},{type:\"uint32\",data:u},{type:\"float32\",data:t.alpha},{type:\"float32\",data:t.beta}],h=[\"type\",\"type\"];e.length===3&&(p.push(...q(e[2].dims)),h.push(\"rank\")),p.push(...q(d));let g=y=>{let w=\"\";t.transA&&t.transB?w=\"value += a[k * uniforms.M + m] * b[n * uniforms.K + k];\":t.transA&&!t.transB?w=\"value += a[k * uniforms.M + m] * b[k * uniforms.N + n];\":!t.transA&&t.transB?w=\"value += a[m * uniforms.K + k] * b[n * uniforms.K + k];\":!t.transA&&!t.transB&&(w=\"value += a[m * uniforms.K + k] * b[k * uniforms.N + n];\");let b=t.alpha===1?\"\":\"value *= uniforms.alpha;\",_=z(\"a\",e[0].dataType,e[0].dims),I=z(\"b\",e[1].dataType,e[1].dims),S=_.type.value,x=null,O=[_,I];e.length===3&&(x=z(\"c\",e[2].dataType,e[2].dims.length),O.push(x));let T=j(\"output\",e[0].dataType,d.length);O.push(T);let M=[{name:\"output_size\",type:\"u32\"},{name:\"M\",type:\"u32\"},{name:\"N\",type:\"u32\"},{name:\"K\",type:\"u32\"},{name:\"alpha\",type:\"f32\"},{name:\"beta\",type:\"f32\"}];return`\n  ${y.registerUniforms(M).declareVariables(...O)}\n\n  ${y.mainStart()}\n    ${y.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n\n    let m = global_idx / uniforms.N;\n    let n = global_idx % uniforms.N;\n\n    var value = ${S}(0);\n    for (var k: u32 = 0u; k < uniforms.K; k++) {\n      ${w}\n    }\n\n    ${b}\n    ${(()=>x!=null?`let cOffset = ${x.broadcastedIndicesToOffset(\"vec2(m, n)\",T)}; value += uniforms.beta * ${x.getByOffset(\"cOffset\")};`:\"\")()}\n    output[global_idx] = value;\n  }`};return{name:\"Gemm\",shaderCache:{hint:`${t.cacheKey}`,inputDependencies:h},getRunData:()=>({outputs:[{dims:d,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)},programUniforms:p}),getShaderSource:g}},ms=e=>{let t=e.transA,r=e.transB,o=e.alpha,n=e.beta;return{transA:t,transB:r,alpha:o,beta:n,cacheKey:`${e.transA};${e.transB};${e.alpha===1}`}},fs=(e,t)=>{Pd(e.inputs),e.compute(kd(e.inputs,t))}});var Rd,Bd,Dd,gs,ys=Y(()=>{\"use strict\";De();Se();we();Rd=(e,t)=>{let r=e[0].dims,o=r,n=2,s=U.sizeToDimension(r,n),u=U.sizeFromDimension(r,n),d=Ne(u),a=u/d,p=[r[0],r[1],a],h=[\"rank\",\"type\",\"type\"],g=[{type:\"uint32\",data:u},{type:\"uint32\",data:a}];g.push(...q(p),...q(p));let y=w=>{let b=z(\"x\",e[0].dataType,p.length,d),_=z(\"scale\",e[1].dataType,e[1].dims),I=z(\"bias\",e[2].dataType,e[2].dims),S=j(\"output\",e[0].dataType,p.length,d),x=[b,_,I,S],O=b.type.value,T=d===1?\"f32\":`vec${d}<f32>`,M=64,A=[{name:\"normSize\",type:\"u32\"},{name:\"normPackedSize\",type:\"u32\"}];return`\n  var<workgroup> meanShared : f32;\n  var<workgroup> squaredNormShared : f32;\n  var<workgroup> workgroupShared : array<${T}, ${M}>;\n  const workgroupSize = ${M}u;\n  ${w.registerUniforms(A).declareVariables(...x)}\n  ${w.mainStart(M)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / uniforms.x_shape[1];\n    let channel = norm % uniforms.x_shape[1];\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial = ${T}(0);\n    for (var h = localIndex; h < uniforms.normPackedSize; h += workgroupSize) {\n      initial = initial + ${T}(${b.get(\"batch\",\"channel\",\"h\")});\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = ${Qe(\"workgroupShared[0]\",d)} / f32(uniforms.normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = ${T}(0);\n    for (var h = localIndex; h < uniforms.normPackedSize; h += workgroupSize) {\n      let deviation =  ${T}(${b.get(\"batch\",\"channel\",\"h\")}) - ${T}(meanShared);\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = ${Qe(\"workgroupShared[0]\",d)};\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / f32(uniforms.normSize) + f32(${t.epsilon}));\n    let channelScale = invStdDev * f32(${_.getByOffset(\"channel\")});\n    let channelShift = f32(${I.getByOffset(\"channel\")}) - meanShared * channelScale;\n    for (var h = localIndex; h < uniforms.normPackedSize; h += workgroupSize) {\n      let value = ${b.get(\"batch\",\"channel\",\"h\")} * ${O}(${T}(channelScale)) + ${O}(${T}(channelShift));\n      ${S.set(\"batch\",\"channel\",\"h\",\"value\")};\n    }\n  }`};return{name:\"InstanceNormalization\",shaderCache:{hint:`${t.epsilon};${d}`,inputDependencies:h},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:s},programUniforms:g}),getShaderSource:y}},Bd=(e,t,r,o,n,s,u,d)=>{let a=Ne(u),p=64,h=a===1?\"vec2f\":`mat2x${a}f`,g=a===1?\"f32\":`vec${a}f`,y=(A,W)=>`${h}(${A}, ${W})`,w=n*u/a,b=Math.ceil(s/p),_=[\"type\"],I=[{type:\"uint32\",data:b},{type:\"uint32\",data:s},{type:\"uint32\",data:Math.floor(u/a)},{type:\"uint32\",data:Math.floor(s*u/a)}],S=A=>{let W=z(\"input\",t.dataType,t.dims,a);return`\n  ${A.declareVariables(W)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${h}>;\n  struct Uniforms {wg_size:u32, H:u32, C:u32, image_size:u32};\n  @group(0) @binding(2) var<uniform> uniforms: Uniforms;\n\n  ${A.mainStart(p)}\n    let currentImageNumber = global_idx / ${p} / uniforms.C;\n    let currentChannelNumber = (global_idx / ${p}) % uniforms.C;\n    let wgId = global_idx % ${p};\n    let wgOffset = wgId * uniforms.wg_size;\n    if (wgOffset >= uniforms.H) {\n        return;\n    }\n    let wgMax = min(wgOffset + uniforms.wg_size, uniforms.H);\n\n    let offset = currentImageNumber * uniforms.image_size + currentChannelNumber;\n    var sum = ${je(\"f32\",a)};\n    var squaredSum = ${je(\"f32\",a)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${g}(input[offset + i * uniforms.C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${y(\"sum\",\"squaredSum\")};\n  }`},x=e.compute({name:\"InstanceNormComputeMean\",shaderCache:{hint:`${a}`,inputDependencies:_},getRunData:()=>({outputs:[{dims:[n,u,p,2],dataType:1}],dispatchGroup:{x:n*u/a},programUniforms:I}),getShaderSource:S},{inputs:[t],outputs:[-1]})[0],O=[{type:\"uint32\",data:w},{type:\"uint32\",data:s},{type:\"uint32\",data:Math.floor(u/a)},{type:\"uint32\",data:Math.floor(p*u/a)}],T=[\"type\",\"type\",\"type\"],M=A=>{let W=z(\"scale\",r.dataType,r.dims,a),V=z(\"bias\",o.dataType,o.dims,a);return`\n  @group(0) @binding(0) var<storage, read> input : array<${h}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${W.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${V.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${h}>;\n  struct Uniforms {units_of_work : u32, H: u32, C : u32, image_size : u32};\n  @group(0) @binding(4) var<uniform> uniforms: Uniforms;\n\n  ${A.mainStart()}\n    ${A.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.units_of_work\")}\n    let currentImageNumber = global_idx / uniforms.C;\n    let currentChannelNumber = global_idx % uniforms.C;\n\n    let offset = currentImageNumber * uniforms.image_size;\n    var sum = ${je(\"f32\",a)};\n    var squaredSum = ${je(\"f32\",a)};\n    for (var i: u32 = 0; i < ${p}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${p}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(uniforms.H);\n    squaredSum = squaredSum / f32(uniforms.H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + f32(${d}));\n    let channelScale = invStdDev * ${g}(scale[currentChannelNumber]);\n    let channelShift = ${g}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${y(\"channelScale\",\"channelShift\")};\n  }`};return e.compute({name:\"InstanceNormComputeChannelScaleShift\",shaderCache:{hint:`${a};${d}`,inputDependencies:T},getRunData:()=>({outputs:[{dims:[n,u,2],dataType:1}],dispatchGroup:{x:Math.ceil(w/64)},programUniforms:O}),getShaderSource:M},{inputs:[x,r,o],outputs:[-1]})[0]},Dd=(e,t,r)=>{let o=t[0].dims,n=o,s=o[0],u=o[o.length-1],d=U.sizeFromDimension(o,1)/u,a=Ne(u),p=U.size(n)/a,h=[{type:\"uint32\",data:d},{type:\"uint32\",data:Math.floor(u/a)}],g=[\"type\",\"type\"],y=Bd(e,t[0],t[1],t[2],s,d,u,r.epsilon),w=b=>{let _=Ve(t[0].dataType),I=a===1?\"vec2f\":`mat2x${a}f`,S=a===1?_:`vec${a}<${_}>`,x=z(\"input\",t[0].dataType,t[0].dims,a),O=j(\"output\",t[0].dataType,n,a);return`\n  @group(0) @binding(0) var<storage, read> input : array<${x.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${I}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${O.type.storage}>;\n  struct Uniforms {H: u32, C : u32};\n  @group(0) @binding(3) var<uniform> uniforms: Uniforms;\n\n  ${b.mainStart()}\n    let currentImageNumber = global_idx / (uniforms.C * uniforms.H);\n    let currentChannelNumber = global_idx % uniforms.C;\n\n    let scaleOffset = currentImageNumber * uniforms.C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${S}(scale[0]), ${S}(scale[1]));\n  }`};e.compute({name:\"InstanceNormalizationNHWC\",shaderCache:{hint:`${a}`,inputDependencies:g},getRunData:()=>({outputs:[{dims:n,dataType:t[0].dataType}],dispatchGroup:{x:Math.ceil(p/64)},programUniforms:h}),getShaderSource:w},{inputs:[t[0],y]})},gs=(e,t)=>{t.format===\"NHWC\"?Dd(e,e.inputs,t):e.compute(Rd(e.inputs,t))}});var Md,zd,bs,ws=Y(()=>{\"use strict\";De();Se();we();Md=e=>{if(!e||e.length<2)throw new Error(\"layerNorm requires at least 2 inputs.\")},zd=(e,t,r)=>{let o=e[0].dims,n=e[1],s=e[2],u=o,d=U.normalizeAxis(t.axis,o.length),a=U.sizeToDimension(o,d),p=U.sizeFromDimension(o,d),h=U.size(n.dims),g=s?U.size(s.dims):0;if(h!==p||s&&g!==p)throw new Error(`Size of X.shape()[axis:] == ${p}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${h} and bias size of ${g}`);let y=[];for(let T=0;T<o.length;++T)T<d?y.push(o[T]):y.push(1);let w=Ne(p),b=[\"type\",\"type\"],_=[{type:\"uint32\",data:a},{type:\"float32\",data:p},{type:\"uint32\",data:Math.floor(p/w)},{type:\"float32\",data:t.epsilon}];s&&b.push(\"type\");let I=r>1,S=r>2,x=T=>{let M=Ve(e[0].dataType),A=[z(\"x\",e[0].dataType,e[0].dims,w),z(\"scale\",n.dataType,n.dims,w)];s&&A.push(z(\"bias\",s.dataType,s.dims,w)),A.push(j(\"output\",e[0].dataType,u,w)),I&&A.push(j(\"mean_data_output\",1,y)),S&&A.push(j(\"inv_std_output\",1,y));let W=[{name:\"norm_count\",type:\"u32\"},{name:\"norm_size\",type:\"f32\"},{name:\"norm_size_vectorized\",type:\"u32\"},{name:\"epsilon\",type:\"f32\"}];return`\n  ${T.registerUniforms(W).declareVariables(...A)}\n  ${T.mainStart()}\n    ${T.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.norm_count\")}\n    let offset = global_idx * uniforms.norm_size_vectorized;\n    var meanVector = ${je(\"f32\",w)};\n    var meanSquareVector = ${je(\"f32\",w)};\n\n    for (var h: u32 = 0u; h < uniforms.norm_size_vectorized; h++) {\n      let value = ${rt(M,w,\"x[h + offset]\")};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${Qe(\"meanVector\",w)} / uniforms.norm_size;\n    let meanSquare = sqrt(${Qe(\"meanSquareVector\",w)}\n      / uniforms.norm_size - mean * mean + uniforms.epsilon);\n\n    for (var j: u32 = 0; j < uniforms.norm_size_vectorized; j++) {\n      let f32input = ${rt(M,w,\"x[j + offset]\")};\n      let f32scale = ${rt(M,w,\"scale[j]\")};\n      output[j + offset] = ${A[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${s?`+ ${rt(M,w,\"bias[j]\")}`:\"\"}\n      );\n    }\n\n    ${I?\"mean_data_output[global_idx] = mean\":\"\"};\n    ${S?\"inv_std_output[global_idx] = 1 / meanSquare\":\"\"};\n  }`},O=[{dims:u,dataType:e[0].dataType}];return I&&O.push({dims:y,dataType:1}),S&&O.push({dims:y,dataType:1}),{name:\"LayerNormalization\",shaderCache:{hint:`${w};${r}`,inputDependencies:b},getRunData:()=>({outputs:O,dispatchGroup:{x:Math.ceil(a/64)},programUniforms:_}),getShaderSource:x}},bs=(e,t)=>{Md(e.inputs),e.compute(zd(e.inputs,t,e.outputCount))}});var Ud,$s,vs,Vd,Qn,Ss,xs=Y(()=>{\"use strict\";Se();We();Hr();Un();we();qt();Ud=(e,t)=>{let r=e[0],o=e[1],n=e[2],s=e[3],u=e[4],d=e[5],a=e[6],p=e[7];if(r.dims.length!==3&&r.dims.length!==5)throw new Error(\"Input query is expected to have 3 or 5 dimensions\");let h=!1,g=r.dims[0],y=r.dims[1],w=r.dims.length===3?h?r.dims[2]/3:r.dims[2]:t.numHeads*r.dims[4],b=y,_=0,I=0,S=Math.floor(w/t.numHeads);if(a&&p){if(a.dims.length!==4)throw new Error('Input \"past_key\" is expected to have 4 dimensions');if(p.dims.length!==4)throw new Error('Input \"past_value\" is expected to have 4 dimensions');_=a.dims[2],I=a.dims[2]}else if(a||p)throw new Error('Input \"past_key\" and \"past_value\" shall be both present or both absent');let x;if(o){if(r.dims.length!==3)throw new Error('Input \"query\" is expected to have 3 dimensions when key is given');if(o.dims.length<3||o.dims.length>5)throw new Error('Input \"key\" is expected to have 3, 4, or 5 dimensions');if(r.dims[0]!==o.dims[0])throw new Error('Input \"query\" and \"key\" shall have same dim 0 (batch size)');if(o.dims.length===3){if(o.dims[2]!==r.dims[2])throw new Error('Input \"query\" and \"key\" shall have same dim 2 (hidden_size)');x=2,b=o.dims[1]}else if(o.dims.length===5){if(o.dims[2]!==t.numHeads||o.dims[3]!==2||o.dims[4]!==S)throw new Error('Expect \"key\" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');if(n)throw new Error('Expect \"value\" be none when \"key\" has packed kv format.');x=5,b=o.dims[1]}else{if(o.dims[1]!==t.numHeads||o.dims[3]!==S)throw new Error('Expect \"key\" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');x=0,b=o.dims[2]}}else{if(r.dims.length!==3&&r.dims.length!==5)throw new Error('Input \"query\" is expected to have 3 or 5 dimensions when key is empty');if(r.dims.length===5&&(r.dims[2]!==t.numHeads||r.dims[3]!==3))throw new Error('Expect \"query\" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');x=3}if(s){if(s.dims.length!==1)throw new Error('Input \"bias\" is expected to have 1 dimension');if(n&&r.dims.length===5&&r.dims[3]===2)throw new Error(\"bias is not allowed for packed kv.\")}let O=0;if(u){O=8;let V=u.dims;throw V.length===1?V[0]===g?O=1:V[0]===3*g+2&&(O=3):V.length===2&&V[0]===g&&V[1]===b&&(O=5),O===8?new Error('Input \"key_padding_mask\" shape shall be (batch_size) or (batch_size, kv_sequence_length)'):new Error(\"Mask not supported\")}let T=!1,M=w;if(n){if(n.dims.length!==3&&n.dims.length!==4)throw new Error('Input \"value\" is expected to have 3 or 4 dimensions');if(r.dims[0]!==n.dims[0])throw new Error('Input \"query\" and \"value\" shall have same dim 0 (batch_size)');if(n.dims.length===3){if(b!==n.dims[1])throw new Error('Input \"key\" and \"value\" shall have the same dim 1 (kv_sequence_length)');M=n.dims[2]}else{if(b!==n.dims[2])throw new Error('Input \"past_key\" and \"past_value\" shall have the same dim 2 (kv_sequence_length)');M=n.dims[1]*n.dims[3],T=!0}}let A=_+b,W=!1;if(u)throw new Error(\"Key padding mask is not supported\");if(d)throw new Error(\"extraAddQk is not supported\");if(a)throw new Error(\"pastKey is not supported\");if(p)throw new Error(\"pastValue is not supported\");return{batchSize:g,sequenceLength:y,pastSequenceLength:_,kvSequenceLength:b,totalSequenceLength:A,maxSequenceLength:I,inputHiddenSize:0,hiddenSize:w,vHiddenSize:M,headSize:S,vHeadSize:Math.floor(M/t.numHeads),numHeads:t.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:t.maskFilterValue,maskType:O,scale:t.scale,broadcastResPosBias:W,passPastInKv:T,qkvFormat:x}},$s=e=>ge({...e}),vs=ge({perm:[0,2,1,3]}),Vd=(e,t,r,o,n,s,u)=>{let d=[o,n,s],a=U.size(d),p=[{type:\"uint32\",data:a},{type:\"uint32\",data:u},{type:\"uint32\",data:s}],h=g=>{let y=j(\"qkv_with_bias\",t.dataType,d),w=z(\"qkv\",t.dataType,d),b=z(\"bias\",r.dataType,d),_=[{name:\"output_size\",type:\"u32\"},{name:\"bias_offset\",type:\"u32\"},{name:\"hidden_size\",type:\"u32\"}];return`\n  ${g.registerUniforms(_).declareVariables(w,b,y)}\n  ${g.mainStart()}\n    ${g.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n    let bias_offset_idx = (global_idx % uniforms.hidden_size) + uniforms.bias_offset;\n\n    qkv_with_bias[global_idx] = qkv[global_idx] + bias[bias_offset_idx];\n  }`};return e.compute({name:\"MultiHeadAttentionAddBias\",shaderCache:{inputDependencies:[\"type\",\"type\"]},getRunData:()=>({outputs:[{dims:d,dataType:t.dataType,gpuDataType:0}],dispatchGroup:{x:Math.ceil(a/64)},programUniforms:p}),getShaderSource:h},{inputs:[t,r],outputs:[-1]})[0]},Qn=(e,t,r,o,n,s,u,d)=>{let a=s;if(u){if(o===1)throw new Error(\"AddBiasReshape is not implemented. Please export your model with packed QKV or KV\");return a=Vd(e,s,u,t,o,r*n,d),a=a.reshape([t,o,r,n]),e.compute(nt(a,vs.perm),{inputs:[a],outputs:[-1]})[0]}else return s.dims.length===3&&(a=s.reshape([t,o,r,n])),e.compute(nt(a,vs.perm),{inputs:[a],outputs:[-1]})[0]},Ss=(e,t)=>{let r=Ud(e.inputs,t);if(e.inputs[0].dims.length===5)throw new Error(\"Packed QKV is not implemented\");if(e.inputs[1]?.dims.length===5)throw new Error(\"Packed KV is not implemented\");let o=e.inputs[1]&&e.inputs[2]&&e.inputs[1].dims.length===4&&e.inputs[2].dims.length===4,n=Qn(e,r.batchSize,r.numHeads,r.sequenceLength,r.headSize,e.inputs[0],e.inputs[3],0);if(o)return Zr(e,n,e.inputs[1],e.inputs[2],e.inputs[4],void 0,void 0,void 0,e.inputs[5],r,t);let s=Qn(e,r.batchSize,r.numHeads,r.kvSequenceLength,r.headSize,e.inputs[1],e.inputs[3],r.hiddenSize),u=Qn(e,r.batchSize,r.numHeads,r.kvSequenceLength,r.vHeadSize,e.inputs[2],e.inputs[3],2*r.hiddenSize);Zr(e,n,s,u,e.inputs[4],void 0,e.inputs[6],e.inputs[7],e.inputs[5],r,t)}});var Wd,Nd,Hd,Gd,Ld,Fd,qd,jd,_s,Cs=Y(()=>{\"use strict\";De();Se();we();Wd=e=>{if(!e||e.length<1)throw new Error(\"Too few inputs\");if(e[0].dataType!==1)throw new Error(\"Input type must be float.\");if(e.length>=2){let t=e[0].dims.length*2===e[1].dims[0];if(e.length===4&&(t=e[3].dims[0]*2===e[1].dims[0]),!t)throw new Error(\"The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].\")}},Nd=(e,t,r)=>{let o=\"\";for(let n=t-1;n>=0;--n)o+=`\n            k = i32(${e.indicesGet(\"indices\",n)}) - ${de(\"uniforms.pads\",n,r)};\n            if (k < 0) {\n              break;\n            }\n            if (k >= i32(${de(\"uniforms.x_shape\",n,t)})) {\n              break;\n            }\n            offset += k * i32(${de(\"uniforms.x_strides\",n,t)});\n        `;return`\n          value = ${e.type.value}(uniforms.constant_value);\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${o}\n            value = x[offset];\n          }\n      `},Hd=(e,t,r)=>{let o=\"\";for(let n=t-1;n>=0;--n)o+=`\n                k = i32(${e.indicesGet(\"indices\",n)}) - ${de(\"uniforms.pads\",n,r)};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = 2 * (i32(${de(\"uniforms.x_shape\",n,t)}) - 1);\n                  k = k % _2n_1;\n                  if(k >= i32(${de(\"uniforms.x_shape\",n,t)})) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * i32(${de(\"uniforms.x_strides\",n,t)});\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${o}\n              value = x[offset];\n          `},Gd=(e,t,r)=>{let o=\"\";for(let n=t-1;n>=0;--n)o+=`\n                k = i32(${e.indicesGet(\"indices\",n)}) - ${de(\"uniforms.pads\",n,r)};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= i32(${de(\"uniforms.x_shape\",n,t)})) {\n                  k = i32(${de(\"uniforms.x_shape\",n,t)}) - 1;\n                }\n                offset += k * i32(${de(\"uniforms.x_strides\",n,t)});\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${o}\n              value = x[offset];\n          `},Ld=(e,t,r)=>{let o=\"\";for(let n=t-1;n>=0;--n)o+=`\n                k = i32(${e.indicesGet(\"indices\",n)}) - ${de(\"uniforms.pads\",n,r)};\n                if (k < 0)  {\n                  k += i32(${de(\"uniforms.x_shape\",n,t)}]);\n                }\n                if (k >= i32(${de(\"uniforms.x_shape\",n,t)})) {\n                  k -= i32(${de(\"uniforms.x_shape\",n,t)});\n                }\n                offset += k * i32(${de(\"uniforms.x_strides\",n,t)});\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${o}\n              value = x[offset];\n          `},Fd=(e,t,r)=>{switch(r.mode){case 0:return Nd(e,t,r.pads.length);case 1:return Hd(e,t,r.pads.length);case 2:return Gd(e,t,r.pads.length);case 3:return Ld(e,t,r.pads.length);default:throw new Error(\"Invalid mode\")}},qd=(e,t)=>{let r=U.padShape(e[0].dims.slice(),t.pads),o=e[0].dims,s=[{type:\"uint32\",data:U.size(r)},{type:\"uint32\",data:t.pads}];if(t.mode===0){let a=Xe(e[0].dataType);s.push({type:a,data:t.value})}s.push(...q(e[0].dims),...q(r));let u=[\"rank\"],d=a=>{let p=j(\"output\",e[0].dataType,r.length),h=z(\"x\",e[0].dataType,o.length),g=h.type.value,y=Fd(p,o.length,t),w=[{name:\"output_size\",type:\"u32\"},{name:\"pads\",type:\"i32\",length:t.pads.length}];return t.mode===0&&w.push({name:\"constant_value\",type:g}),`\n            ${a.registerUniforms(w).declareVariables(h,p)}\n            ${a.mainStart()}\n            ${a.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n\n            let indices = ${p.offsetToIndices(\"global_idx\")};\n\n            var value = ${g}(0);\n            ${y}\n            output[global_idx] = value;\n        }`};return{name:\"Pad\",shaderCache:{hint:`${t.mode}`,inputDependencies:u},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(U.size(r)/64)},programUniforms:s}),getShaderSource:d}},jd=(e,t)=>{if(e.length>1){let r=e[1].getBigInt64Array(),o=e.length>=3&&e[2].data?e[2].getFloat32Array()[0]:0,n=e[0].dims.length,s=new Int32Array(2*n).fill(0);if(e.length>=4){let d=e[3].getBigInt64Array();for(let a=0;a<d.length;a++)s[Number(d[a])]=Number(r[a]),s[Number(d[a])+n]=Number(r[a+d.length])}else r.forEach((d,a)=>s[Number(a)]=Number(d));let u=[];return s.forEach(d=>u.push(d)),{mode:t.mode,value:o,pads:u}}else return t},_s=(e,t)=>{Wd(e.inputs);let r=jd(e.inputs,t);e.compute(qd(e.inputs,r),{inputs:[0]})}});var an,Is,As,Ts,Es,Kd,Yd,Os,Ps,ks,Rs,Bs,Ds,Ms,zs,Us,Vs,Ws,Ns,Hs=Y(()=>{\"use strict\";Lt();Se();we();an=e=>{if(Nt.webgpu.validateInputContent&&(!e||e.length!==1))throw new Error(\"Pool ops requires 1 input.\")},Is=(e,t,r)=>{let o=t.format===\"NHWC\",n=e.dims.slice();o&&n.splice(1,0,n.pop());let s=Object.hasOwnProperty.call(t,\"dilations\"),u=t.kernelShape.slice(),d=t.strides.slice(),a=s?t.dilations.slice():[],p=t.pads.slice();kt.adjustPoolAttributes(r,n,u,d,a,p);let h=kt.computePoolOutputShape(r,n,d,a,u,p,t.autoPad),g=Object.assign({},t);s?Object.assign(g,{kernelShape:u,strides:d,pads:p,dilations:a,cacheKey:t.cacheKey}):Object.assign(g,{kernelShape:u,strides:d,pads:p,cacheKey:t.cacheKey});let y=h.slice();return y.push(y.splice(1,1)[0]),[g,o?y:h]},As=(e,t)=>{let r=t.format===\"NHWC\",o=U.size(e),n=U.size(t.kernelShape),s=[{type:\"uint32\",data:o},{type:\"uint32\",data:n}],u=[{name:\"outputSize\",type:\"u32\"},{name:\"kernelSize\",type:\"u32\"}];if(t.kernelShape.length<=2){let d=t.kernelShape[t.kernelShape.length-1],a=t.strides[t.strides.length-1],p=t.pads[t.pads.length/2-1],h=t.pads[t.pads.length-1],g=!!(p+h);s.push({type:\"uint32\",data:d},{type:\"uint32\",data:a},{type:\"uint32\",data:p},{type:\"uint32\",data:h}),u.push({name:\"kw\",type:\"u32\"},{name:\"sw\",type:\"u32\"},{name:\"pwStart\",type:\"u32\"},{name:\"pwEnd\",type:\"u32\"});let y=!1;if(t.kernelShape.length===2){let w=t.kernelShape[t.kernelShape.length-2],b=t.strides[t.strides.length-2],_=t.pads[t.pads.length/2-2],I=t.pads[t.pads.length-2];y=!!(_+I),s.push({type:\"uint32\",data:w},{type:\"uint32\",data:b},{type:\"uint32\",data:_},{type:\"uint32\",data:I}),u.push({name:\"kh\",type:\"u32\"},{name:\"sh\",type:\"u32\"},{name:\"phStart\",type:\"u32\"},{name:\"phEnd\",type:\"u32\"})}return[s,u,!0,g,y]}else{if(r)throw new Error(\"Pooling with kernelShape.length > 2 is not supported for NHWC format.\");let d=U.computeStrides(t.kernelShape);s.push({type:\"uint32\",data:d},{type:\"uint32\",data:t.pads},{type:\"uint32\",data:t.strides}),u.push({name:\"kernelStrides\",type:\"u32\",length:d.length},{name:\"pads\",type:\"u32\",length:t.pads.length},{name:\"strides\",type:\"u32\",length:t.strides.length});let a=t.pads.reduce((p,h)=>p+h);return[s,u,!!a,!1,!1]}},Ts=(e,t,r,o,n,s,u,d,a,p,h,g)=>{let y=n.format===\"NHWC\",w=t.type.value,b=j(\"output\",t.type.tensor,o);if(n.kernelShape.length<=2){let _=\"\",I=\"\",S=\"\",x=r-(y?2:1);if(h?_=`\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${x}] = indices[${x}] * uniforms.sw - uniforms.pwStart + i;\n                  if (xIndices[${x}] < 0 || xIndices[${x}]\n                      >= uniforms.x_shape[${x}]) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                  ${s}\n                }`:_=`\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${x}] = indices[${x}] * uniforms.sw - uniforms.pwStart + i;\n                  let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                  ${s}\n                }`,n.kernelShape.length===2){let T=r-(y?3:2);g?I=`\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${T}] = indices[${T}] * uniforms.sh - uniforms.phStart + j;\n                  if (xIndices[${T}] < 0 || xIndices[${T}] >= uniforms.x_shape[${T}]) {\n                    pad += i32(uniforms.kw);\n                    continue;\n                  }\n              `:I=`\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${T}] = indices[${T}] * uniforms.sh - uniforms.phStart + j;\n                `,S=`\n              }\n            `}return`\n            ${e.registerUniforms(a).declareVariables(t,b)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n\n              let indices = ${b.offsetToIndices(\"global_idx\")};\n              var xIndices = ${b.offsetToIndices(\"global_idx\")};\n\n              var value = ${w}(${d});\n              var pad = 0;\n              ${I}\n              ${_}\n              ${S}\n              ${u}\n\n              output[global_idx] = value;\n            }`}else{if(y)throw new Error(\"Pooling with kernelShape.length > 2 is not supported for NHWC format.\");let _=n.kernelShape.length,I=n.pads.length,S=\"\";return p?S=`\n                if (xIndices[j] >= uniforms.x_shape[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                ${s}\n              }`:S=`\n              }\n              let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n              ${s}\n            `,`\n            ${e.registerUniforms(a).declareVariables(t,b)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n              let indices = ${b.offsetToIndices(\"global_idx\")};\n              var xIndices = ${b.offsetToIndices(\"global_idx\")};\n\n              var offsets: array<u32, ${_}>;\n\n              var value = ${w}(${d});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < uniforms.kernelSize; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${_-1}u; j++) {\n                  offsets[j] = offset / ${de(\"uniforms.kernelStrides\",\"j\",_)};\n                  offset -= offsets[j] * ${de(\"uniforms.kernelStrides\",\"j\",_)};\n                }\n                offsets[${_-1}] = offset;\n\n                isPad = false;\n                for (var j = ${r-_}u; j < ${r}u; j++) {\n                  xIndices[j] = indices[j] * ${de(\"uniforms.strides\",`j - ${r-_}u`,_)}\n                    + offsets[j - ${r-_}u] - ${de(\"uniforms.pads\",\"j - 2u\",I)};\n                  ${S}\n              }\n              ${u}\n\n              output[global_idx] = value;\n            }`}},Es=e=>`${e.format};${e.ceilMode};${e.autoPad};${e.kernelShape.length}`,Kd=e=>`${Es(e)};${e.countIncludePad}`,Yd=e=>`${Es(e)};${e.storageOrder};${e.dilations}`,Os=e=>({format:e.format,autoPad:[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],ceilMode:e.ceil_mode,kernelShape:e.kernel_shape,strides:e.strides,pads:e.pads}),Ps=(e,t,r,o)=>{let[n,s]=Is(t,o,r),u=z(\"x\",t.dataType,t.dims.length),d=u.type.value,a=\"value += x_val;\",p=\"\";n.countIncludePad?p+=`value /= ${d}(uniforms.kernelSize);`:p+=`value /= ${d}(i32(uniforms.kernelSize) - pad);`;let[h,g,y,w,b]=As(s,n);h.push(...q(t.dims),...q(s));let _=[\"rank\"];return{name:e,shaderCache:{hint:`${o.cacheKey};${y};${w};${b}`,inputDependencies:_},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(U.size(s)/64)},programUniforms:h}),getShaderSource:I=>Ts(I,u,t.dims.length,s.length,n,a,p,0,g,y,w,b)}},ks=e=>{let t=e.count_include_pad!==0,r=Os(e);if(r.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for AveragePool\");let o={countIncludePad:t,...r,cacheKey:\"\"};return{...o,cacheKey:Kd(o)}},Rs=(e,t)=>{an(e.inputs),e.compute(Ps(\"AveragePool\",e.inputs[0],!1,t))},Bs={autoPad:\"\",ceilMode:0,countIncludePad:!1,kernelShape:[],strides:[],pads:[],storageOrder:0,dilations:[]},Ds=e=>{let t=e.format;return{format:t,...Bs,cacheKey:t}},Ms=(e,t)=>{an(e.inputs),e.compute(Ps(\"GlobalAveragePool\",e.inputs[0],!0,t))},zs=(e,t,r,o)=>{let[n,s]=Is(t,o,r),u=`\n      value = max(x_val, value);\n    `,d=\"\",a=z(\"x\",t.dataType,t.dims.length),p=[\"rank\"],[h,g,y,w,b]=As(s,n);return h.push(...q(t.dims),...q(s)),{name:e,shaderCache:{hint:`${o.cacheKey};${y};${w};${b}`,inputDependencies:p},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(U.size(s)/64)},programUniforms:h}),getShaderSource:_=>Ts(_,a,t.dims.length,s.length,n,u,d,-1e5,g,y,w,b)}},Us=(e,t)=>{an(e.inputs),e.compute(zs(\"MaxPool\",e.inputs[0],!1,t))},Vs=e=>{let t=e.storage_order,r=e.dilations,o=Os(e);if(t!==0)throw new Error(\"column major storage order is not yet supported for MaxPool\");if(o.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for MaxPool\");let n={storageOrder:t,dilations:r,...o,cacheKey:\"\"};return{...n,cacheKey:Yd(n)}},Ws=e=>{let t=e.format;return{format:t,...Bs,cacheKey:t}},Ns=(e,t)=>{an(e.inputs),e.compute(zs(\"GlobalMaxPool\",e.inputs[0],!0,t))}});var Xd,Qd,Gs,Ls=Y(()=>{\"use strict\";Lt();De();we();Xd=(e,t,r)=>{let o=e===t,n=e<t&&r<0,s=e>t&&r>0;if(o||n||s)throw new Error(\"Range these inputs' contents are invalid.\")},Qd=(e,t,r,o)=>{let n=Math.abs(Math.ceil((t-e)/r)),s=[n],u=n,d=Xe(o),a=[{type:\"uint32\",data:u},{type:d,data:e},{type:d,data:r},...q(s)],p=h=>{let g=j(\"output\",o,s.length),y=g.type.value,w=[{name:\"outputSize\",type:\"u32\"},{name:\"start\",type:y},{name:\"delta\",type:y}];return`\n        ${h.registerUniforms(w).declareVariables(g)}\n        ${h.mainStart()}\n        ${h.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n        output[global_idx] = uniforms.start + ${y}(global_idx) * uniforms.delta;\n      }`};return{name:\"Range\",shaderCache:{hint:`${o}`},getShaderSource:p,getRunData:()=>({outputs:[{dims:s,dataType:o}],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:a})}},Gs=e=>{let t=0,r=0,o=0;e.inputs[0].dataType===6?(t=e.inputs[0].getInt32Array()[0],r=e.inputs[1].getInt32Array()[0],o=e.inputs[2].getInt32Array()[0]):e.inputs[0].dataType===1&&(t=e.inputs[0].getFloat32Array()[0],r=e.inputs[1].getFloat32Array()[0],o=e.inputs[2].getFloat32Array()[0]),Nt.webgpu.validateInputContent&&Xd(t,r,o),e.compute(Qd(t,r,o,e.inputs[0].dataType),{inputs:[]})}});var Jd,ec,tc,rc,nc,oc,ac,ic,sc,uc,lc,Fs,dc,cc,pc,mc,fc,qs,js,Ks=Y(()=>{\"use strict\";Se();We();we();Jd=(e,t)=>{if(e.every(r=>r>0||(()=>{throw new Error(\"Resize requires scales input values to be positive\")})),e.length>0){if(t.mode===\"linear\"){if(!(e.length===2||e.length===3||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1||e.length===5&&e[0]===1&&e[1]===1))throw new Error(`For linear mode, Resize requires scales to be 2D, 3D, 4D with either two outermost or one innermost and\n            one outermost scale values equal to 1, or 5D with two outermost scale values equal to 1`)}else if(t.mode===\"cubic\"&&!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for cubic mode\")}},ec=(e,t,r)=>{t.every(n=>n>=0&&n<r||(()=>{throw new Error(\"Resize requires axes input values to be positive and less than rank\")}));let o=new Array(r).fill(1);return t.forEach((n,s)=>o[n]=e[s]),o},tc=(e,t,r,o,n,s)=>{let[u,d,a]=r>10?[1,2,3]:[-1,e.length>1?1:-1,-1],p=e[0].dims.length;if(u>0&&e.length>u&&e[u].dims.length>0)e[u].getFloat32Array().forEach(h=>s.push(h));else if(t.coordinateTransformMode===\"tf_crop_and_resize\")throw new Error(\"Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize\");if(d>0&&e.length>d&&e[d].dims.length>0){if(e[d].getFloat32Array().forEach(h=>o.push(h)),o.length!==0&&o.length!==p&&r>=18&&o.length!==t.axes.length)throw new Error(\"Resize requires scales input size to be same as input rank or axes size for opset 18 and up\");Jd(o,t),t.axes.length>0&&ec(o,t.axes,p).forEach((h,g)=>o[g]=h)}if(a>0&&e.length>a&&(e[a].getBigInt64Array().forEach(h=>n.push(Number(h))),n.length!==p||r>=18&&n.length===t.axes.length))throw new Error(\"Resize requires sizes input size to be same as input rank or axes size for opset 18 and up\");if(t.axes.length>0){if(o.length!==t.axes.length)throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');if(n.length!==t.axes.length)throw new Error('Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified')}if(typeof o<\"u\"&&typeof n<\"u\"&&o.length>0&&n.length>p)throw new Error(\"Resize requires only of scales or sizes to be specified\")},rc=(e,t)=>`fn getOriginalCoordinateFromResizedCoordinate(xResized: u32, xScale: ${t}, lengthResized: u32,\n     lengthOriginal: u32, roiStart: ${t}, roiEnd: ${t}) -> ${t} { `+(()=>{switch(e){case\"asymmetric\":return`return ${t}(xResized) / xScale;`;case\"pytorch_half_pixel\":return`if (lengthResized > 1) {\n                    return (${t}(xResized) + 0.5) / xScale - 0.5;\n                  } else {\n                    return 0.0;\n                  }`;case\"tf_half_pixel_for_nn\":return`return (${t}(xResized) + 0.5) / xScale;`;case\"align_corners\":return`if (lengthResized == 1) {\n                    return 0.0;\n                  } else {\n                    // The whole part and the fractional part are calculated separately due to inaccuracy of floating\n                    // point division. As an example, f32(21) / f32(7) may evaluate to 2.99... instead of 3, causing an\n                    // offset-by-one error later in floor().\n                    let whole = ${t}(xResized * (lengthOriginal - 1) / (lengthResized - 1));\n                    let fract =\n                        ${t}(xResized * (lengthOriginal - 1) % (lengthResized - 1)) / ${t}(lengthResized - 1);\n                    return whole + fract;\n                  }`;case\"tf_crop_and_resize\":return`if (lengthResized > 1) {\n                    return roiStart * ${t}(lengthOriginal - 1) +\n                        (${t}(xResized) * (roiEnd - roiStart) * ${t}(lengthOriginal - 1)) /\n                        ${t}(lengthResized - 1);\n                  } else {\n                    return 0.5 * (roiStart + roiEnd) * ${t}(lengthOriginal - 1);\n                  }`;case\"half_pixel_symmetric\":return`const outputWidth = xScale * ${t}(lengthResized);\n                  const adjustment = ${t}(lengthResized) / outputWidth;\n                  const center = ${t}(lengthOriginal) / 2;\n                  const offset = center * (1 - adjustment);\n                  return offset + ((${t}(xResized) + 0.5) / xScale) - 0.5;`;case\"half_pixel\":return`return ((${t}(xResized) + 0.5) / xScale) - 0.5;`;default:throw new Error(`Coordinate transform mode ${e} is not supported`)}})()+\"}\",nc=(e,t,r)=>`fn getNearestPixelFromOriginal(xOriginal: ${r}, isDownSample: bool) -> ${r} {`+(()=>{switch(e){case\"round_prefer_ceil\":return\"if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }\";case\"floor\":return\"return floor(xOriginal);\";case\"ceil\":return\"return ceil(xOriginal);\";case\"round_prefer_floor\":return\"if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }\";case\"simple\":default:if(t<11)return\"if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }\";throw new Error(`Nearest mode ${e} is not supported`)}})()+\"}\",oc=(e,t,r)=>{let o=new Array(r).fill(0).concat(new Array(r).fill(1)),n=e.length===0?o:e.slice();return t.length>0?(t.forEach((s,u)=>{o[s]=n[u],o[u+r]=n[t.length+u]}),o):n},ac=(e,t,r,o)=>{let n=[];if(r.length>0)if(o.length>0){if(e.forEach(s=>n.push(s)),Math.max(...o)>e.length)throw new Error(\"axes is out of bound\");o.forEach((s,u)=>n[s]=r[u])}else r.forEach(s=>n.push(s));else{if(t.length===0)throw new Error(\"Resize requires either scales or sizes.\");n=e.map((s,u)=>Math.round(s*t[u]))}return n},ic=(e,t,r)=>{let o=(()=>{switch(r.keepAspectRatioPolicy){case\"not_larger\":return r.axes.length>0?Math.min(...r.axes.map(s=>t[s]),Number.MAX_VALUE):Math.min(...t,Number.MAX_VALUE);case\"not_smaller\":return r.axes.length>0?Math.max(...r.axes.map(s=>t[s]),Number.MIN_VALUE):Math.max(...t,Number.MIN_VALUE);default:throw new Error(`Keep aspect ratio policy ${r.keepAspectRatioPolicy} is not supported`)}})();t.fill(1,0,t.length);let n=e.slice();return r.axes.length>0?(r.axes.forEach(s=>t[s]=o),r.axes.forEach(s=>n[s]=Math.round(e[s]*t[s]))):(t.fill(o,0,t.length),n.forEach((s,u)=>n[u]=Math.round(s*t[u]))),n},sc=(e,t,r,o,n)=>`\n    fn calculateOriginalIndicesFromOutputIndices(output_indices: ${e.type.indices}) -> array<${e.type.value}, ${r.length}> {\n      var original_indices: array<${e.type.value}, ${r.length}>;\n      for (var i:u32 = 0; i < ${r.length}; i++) {\n        var output_index = ${e.indicesGet(\"output_indices\",\"i\")};\n        var scale = ${de(\"uniforms.scales\",\"i\",o)};\n        var roi_low = ${de(\"uniforms.roi\",\"i\",n)};\n        var roi_hi = ${de(\"uniforms.roi\",`i + ${t.length}`,n)};\n        if (scale == 1.0) {\n          original_indices[i] = ${e.type.value}(output_index);\n        } else {\n          var input_shape_i = ${de(\"uniforms.input_shape\",\"i\",t.length)};\n          var output_shape_i = ${de(\"uniforms.output_shape\",\"i\",r.length)};\n          original_indices[i] = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                           input_shape_i, roi_low, roi_hi);\n        }\n      }\n      return original_indices;\n    }`,uc=(e,t,r,o,n,s,u)=>`\n    fn calculateInputIndicesFromOutputIndices(output_indices: ${t.type.indices}) -> ${e.type.indices} {\n      var input_indices: ${e.type.indices};\n      for (var i:u32 = 0; i < ${o.length}; i++) {\n        var output_index = ${t.indicesGet(\"output_indices\",\"i\")};\n        var input_index: u32;\n        var scale = ${de(\"uniforms.scales\",\"i\",n)};\n        if (scale == 1.0) {\n          input_index = output_index;\n        } else {\n          var roi_low = ${de(\"uniforms.roi\",\"i\",s)};\n          var roi_hi = ${de(\"uniforms.roi\",`i + ${r.length}`,s)};\n          var input_shape_i = ${de(\"uniforms.input_shape\",\"i\",r.length)};\n          var output_shape_i = ${de(\"uniforms.output_shape\",\"i\",o.length)};\n          var original_idx = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                        input_shape_i, roi_low, roi_hi);\n          if (!${u} || (original_idx >= 0 && original_idx < ${t.type.value}(input_shape_i))) {\n            if (original_idx < 0) {\n              input_index = 0;\n            } else if (original_idx > ${t.type.value}(input_shape_i - 1)) {\n              input_index = input_shape_i - 1;\n            } else {\n              input_index = u32(getNearestPixelFromOriginal(original_idx, scale < 1));\n            }\n          } else {\n            input_index = u32(original_idx);\n          }\n        }\n        ${e.indicesSet(\"input_indices\",\"i\",\" input_index\")}\n      }\n      return input_indices;\n    }`,lc=(e,t)=>`\n    fn checkInputIndices(input_indices: ${e.type.indices}) -> bool {\n      for (var i:u32 = 0; i < ${t.length}; i++) {\n        var input_index = ${e.indicesGet(\"input_indices\",\"i\")};\n        if (input_index < 0 || input_index >= ${de(\"uniforms.input_shape\",\"i\",t.length)}) {\n          return false;\n        }\n      }\n      return true;\n    }`,Fs=(e,t,r,o)=>e.rank>o?`\n    ${e.indicesSet(\"input_indices\",t,\"channel\")};\n    ${e.indicesSet(\"input_indices\",r,\"batch\")};\n`:\"\",dc=(e,t,r,o,n)=>{let[u,d,a,p]=r.length===2?[-1,0,1,-1]:[0,2,3,1],h=e.type.value;return`\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> ${h} {\n      var input_indices: ${e.type.indices};\n      ${e.indicesSet(\"input_indices\",d,`max(0, min(row, ${r[d]} - 1))`)};\n      ${e.indicesSet(\"input_indices\",a,`max(0, min(col, ${r[a]} - 1))`)};\n      ${Fs(e,p,u,2)}\n      return ${e.getByIndices(\"input_indices\")};\n    }\n\n    fn bilinearInterpolation(output_indices: ${t.type.indices}) -> ${h} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var row:${h} = originalIndices[${d}];\n      var col:${h} = originalIndices[${a}];\n      ${o?`if (row < 0 || row > (${r[d]} - 1) || col < 0 || col > (${r[a]} - 1)) {\n        return ${n};\n      }`:\"\"};\n      row = max(0, min(row, ${r[d]} - 1));\n      col = max(0, min(col, ${r[a]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = ${r.length>2?`u32(originalIndices[${p}])`:\"0\"};\n      var batch: u32 =  ${r.length>2?`u32(originalIndices[${u}])`:\"0\"};\n      var x11: ${h} = getInputValue(batch, channel, row1, col1);\n      var x12: ${h} = getInputValue(batch, channel, row1, col2);\n      var x21: ${h} = getInputValue(batch, channel, row2, col1);\n      var x22: ${h} = getInputValue(batch, channel, row2, col2);\n      var dx1: ${h} = abs(row - ${h}(row1));\n      var dx2: ${h} = abs(${h}(row2) - row);\n      var dy1: ${h} = abs(col - ${h}(col1));\n      var dy2: ${h} = abs(${h}(col2) - col);\n      if (row1 == row2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (col1 == col2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`},cc=(e,t,r,o,n,s,u,d,a,p)=>{let h=r.length===2,g=!0,[y,w]=h?[0,1]:g?[2,3]:[1,2],b=e.type.value,_=I=>{let S=I===y?\"row\":\"col\";return`\n      fn ${S}CubicInterpolation(input_indices: ${e.type.indices}, output_indices: ${t.type.indices}) -> ${b} {\n        var output_index = ${t.indicesGet(\"output_indices\",I)};\n        var originalIdx: ${b} = getOriginalCoordinateFromResizedCoordinate(output_index, ${n[I]},\n        ${o[I]}, ${r[I]}, ${s[I]}, ${s[I]} + ${r.length});\n        var fractOriginalIdx: ${b} = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${d} && (originalIdx < 0 || originalIdx > (${r[I]} - 1))) {\n          return ${a};\n        }\n        var data: array<${b}, 4> = array<${b}, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${S}: ${b} = originalIdx + ${b}(i);\n          if (${S} < 0 || ${S} >= ${r[I]}) {\n            ${(()=>p?`coefs[i + 1] = 0.0;\n                        continue;`:d?`return ${a};`:`${S} = max(0, min(${S}, ${r[I]} - 1));`)()};\n          }\n        var input_indices_copy: ${e.type.indices} = input_indices;\n          ${e.indicesSet(\"input_indices_copy\",I,`u32(${S})`)};\n          data[i + 1] = ${I===y?e.getByIndices(\"input_indices_copy\"):\"rowCubicInterpolation(input_indices_copy, output_indices)\"};\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`};return`\n    ${_(y)};\n    ${_(w)};\n  fn getCubicInterpolationCoefs(s: ${b}) -> array<${b}, 4> {\n    var absS = abs(s);\n    var coeffs: array<${b}, 4> = array<${b}, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: ${b} = 1.0 - absS;\n    var twoMinusAbsS: ${b} = 2.0 - absS;\n    var onePlusAbsS: ${b} = 1.0 + absS;\n    coeffs[0] = ((${u} * onePlusAbsS - 5 * ${u}) * onePlusAbsS + 8 * ${u}) * onePlusAbsS - 4 * ${u};\n    coeffs[1] = ((${u} + 2) * absS - (${u} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${u} + 2) * oneMinusAbsS - (${u} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${u} * twoMinusAbsS - 5 * ${u}) * twoMinusAbsS + 8 * ${u}) * twoMinusAbsS - 4 * ${u};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<${b}, 4>, coefs: array<${b}, 4>) -> ${b} {\n    var coefsSum: ${b} = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(output_indices: ${t.type.indices}) -> ${b} {\n    var input_indices: ${e.type.indices} = output_indices;\n    return colCubicInterpolation(input_indices, output_indices);\n  }\n    `},pc=(e,t,r,o,n)=>{let[u,d,a,p,h]=r.length===3?[-1,0,1,2,-1]:[0,2,3,4,1],g=e.type.value;return`\n    fn getInputValue(batch: u32, channel: u32, depth:u32, height: u32, width: u32) -> ${g} {\n      var input_indices: ${e.type.indices};\n      ${e.indicesSet(\"input_indices\",d,`max(0, min(depth, ${r[d]} - 1))`)};\n      ${e.indicesSet(\"input_indices\",a,`max(0, min(height, ${r[a]} - 1))`)};\n      ${e.indicesSet(\"input_indices\",p,`max(0, min(width, ${r[p]} - 1))`)};\n      ${Fs(e,h,u,3)}\n      return ${e.getByIndices(\"input_indices\")};\n    }\n\n    fn trilinearInterpolation(output_indices: ${t.type.indices}) -> ${g} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var depth:${g} = originalIndices[${d}];\n      var height:${g} = originalIndices[${a}];\n      var width:${g} = originalIndices[${p}];\n      ${o?`if (depth < 0 || depth > (${r[d]} - 1) || height < 0 || height > (${r[a]} - 1) || width < 0 || (width > ${r[p]} - 1)) {\n      return ${n};\n        }`:\"\"};\n\n    depth = max(0, min(depth, ${r[d]} - 1));\n      height = max(0, min(height, ${r[a]} - 1));\n      width = max(0, min(width, ${r[p]} - 1));\n      var depth1: u32 = u32(depth);\n      var height1: u32 = u32(height);\n      var width1: u32 = u32(width);\n      var depth2: u32 = u32(depth + 1);\n      var height2: u32 = u32(height + 1);\n      var width2: u32 = u32(width + 1);\n      var channel: u32 = ${r.length>3?`u32(originalIndices[${h}])`:\"0\"};\n      var batch: u32 =  ${r.length>3?`u32(originalIndices[${u}])`:\"0\"};\n\n      var x111: ${g} = getInputValue(batch, channel, depth1, height1, width1);\n      var x112: ${g} = getInputValue(batch, channel, depth1, height1, width2);\n      var x121: ${g} = getInputValue(batch, channel, depth1, height2, width1);\n      var x122: ${g} = getInputValue(batch, channel, depth1, height2, width2);\n      var x211: ${g} = getInputValue(batch, channel, depth2, height1, width1);\n      var x212: ${g} = getInputValue(batch, channel, depth2, height1, width2);\n      var x221: ${g} = getInputValue(batch, channel, depth2, height2, width1);\n      var x222: ${g} = getInputValue(batch, channel, depth2, height2, width2);\n      var dx1: ${g} = abs(depth - ${g}(depth1));\n      var dx2: ${g} = abs(${g}(depth2) - depth);\n      var dy1: ${g} = abs(height - ${g}(height1));\n      var dy2: ${g} = abs(${g}(height2) - height);\n      var dz1: ${g} = abs(width - ${g}(width1));\n      var dz2: ${g} = abs(${g}(width2) - width);\n      if (depth1 == depth2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (height1 == height2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      if (width1 == width2) {\n        dz1 = 0.5;\n        dz2 = 0.5;\n      }\n      return (x111 * dx2 * dy2 * dz2 + x112 * dx2 * dy2 * dz1 + x121 * dx2 * dy1 *dz2 + x122 * dx2 * dy1 * dz1 +\n              x211 * dx1 * dy2 * dz2 + x212 * dx1 * dy2 * dz1 + x221 * dx1 * dy1 *dz2 + x222 * dx1 * dy1 * dz1);\n    }`},mc=(e,t,r,o,n,s)=>{let u=e.dims,d=oc(s,t.axes,u.length),a=ac(u,o,n,t.axes),p=o.slice();o.length===0&&(p=u.map((x,O)=>x===0?1:a[O]/x),t.keepAspectRatioPolicy!==\"stretch\"&&(a=ic(u,p,t)));let h=j(\"output\",e.dataType,a.length),g=z(\"input\",e.dataType,u.length),y=U.size(a),w=u.length===a.length&&u.every((x,O)=>x===a[O]),b=t.coordinateTransformMode===\"tf_crop_and_resize\",_=t.extrapolationValue,I=g.type.value,S=x=>`\n      ${w?\"\":`\n      ${rc(t.coordinateTransformMode,I)};\n      ${(()=>{switch(t.mode){case\"nearest\":return`\n              ${lc(g,u)};\n              ${nc(t.nearestMode,r,I)};\n              ${uc(g,h,u,a,p.length,d.length,b)};\n              `;case\"linear\":return`\n              ${sc(h,u,a,p.length,d.length)};\n              ${(()=>{if(u.length===2||u.length===4)return`${dc(g,h,u,b,_)}`;if(u.length===3||u.length===5)return`${pc(g,h,u,b,_)}`;throw Error(\"Linear mode only supports input dims 2, 3, 4 and 5 are supported in linear mode.\")})()};\n            `;case\"cubic\":return`\n            ${(()=>{if(u.length===2||u.length===4)return`${cc(g,h,u,a,p,d,t.cubicCoeffA,b,t.extrapolationValue,t.excludeOutside)}`;throw Error(\"Cubic mode only supports input dims 2 and 4 are supported in linear mode.\")})()};\n            `;default:throw Error(\"Invalid resize mode\")}})()};\n      `}\n      ${x.registerUniform(\"output_size\",\"u32\").registerUniform(\"scales\",\"f32\",p.length).registerUniform(\"roi\",\"f32\",d.length).declareVariables(g,h)}\n      ${x.mainStart()}\n        ${x.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n        ${w?\"output[global_idx] = input[global_idx];\":`\n        let output_indices = ${h.offsetToIndices(\"global_idx\")};\n        var input_indices: ${g.type.indices};\n        ${(()=>{switch(t.mode){case\"nearest\":return`input_indices = calculateInputIndicesFromOutputIndices(output_indices);\n                if (checkInputIndices(input_indices)) {\n                  output[global_idx] = ${g.getByIndices(\"input_indices\")};\n                } else {\n                  output[global_idx] = ${t.extrapolationValue};\n                }`;case\"linear\":return`output[global_idx] = ${u.length===2||u.length===4?\"bilinearInterpolation\":\"trilinearInterpolation\"}(output_indices);`;case\"cubic\":return\"output[global_idx] = bicubicInterpolation(output_indices);\";default:throw Error(`Unsupported resize mode: ${t.mode}`)}})()};\n`}\n      }`;return{name:\"Resize\",shaderCache:{hint:`${t.cacheKey}|${r}|${p.length>0?p:\"\"}|${n.length>0?n:\"\"}|${d.length>0?d:\"\"}|${w}|${u}`,inputDependencies:[\"rank\"]},getShaderSource:S,getRunData:()=>({outputs:[{dims:a,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(y/64)},programUniforms:[{type:\"uint32\",data:y},{type:\"float32\",data:p},{type:\"float32\",data:d},...q(u),...q(a)]})}},fc=e=>{let t=e.customDataBuffer;return new Uint32Array(t,t.byteOffset,1)[0]},qs=(e,t)=>{let r=[],o=[],n=[],s=fc(e);if(t.antialias!==0)throw Error(\"Only default value (0) for Antialias attribute is supported\");tc(e.inputs,t,s,r,o,n),e.compute(mc(e.inputs[0],t,s,r,o,n),{inputs:[0]})},js=e=>{let t=e.antialias,r=e.axes,o=e.coordinateTransformMode,n=e.cubicCoeffA,s=e.excludeOutside!==0,u=e.extrapolationValue,d=e.keepAspectRatioPolicy,a=e.mode,p=e.nearestMode===\"\"?\"simple\":e.nearestMode;return ge({antialias:t,axes:r,coordinateTransformMode:o,cubicCoeffA:n,excludeOutside:s,extrapolationValue:u,keepAspectRatioPolicy:d,mode:a,nearestMode:p})}});var hc,gc,Ys,Zs,Xs=Y(()=>{\"use strict\";De();Se();We();we();hc=e=>{if(!e||e.length<3)throw new Error(\"layerNorm requires at least 3 inputs.\");let t=e[0],r=e[1],o=e[2];if(t.dataType!==r.dataType||t.dataType!==o.dataType)throw new Error(\"All inputs must have the same data type\");if(t.dims.length!==3&&t.dims.length!==2)throw new Error(\"Input must be 2D or 3D\");if(r.dims.length!==3&&r.dims.length!==2)throw new Error(\"Skip must be 2D or 3D\");let n=t.dims[t.dims.length-1],s=t.dims[t.dims.length-2];if(r.dims[r.dims.length-1]!==n)throw new Error(\"Skip must have the same hidden size as input\");if(r.dims[r.dims.length-2]!==s)throw new Error(\"Skip must have the same sequence length as input\");if(o.dims.length!==1)throw new Error(\"Gamma must be 1D\");if(o.dims[o.dims.length-1]!==n)throw new Error(\"Gamma must have the same hidden size as input\");if(e.length>3){let u=e[3];if(u.dims.length!==1)throw new Error(\"Beta must be 1D\");if(u.dims[u.dims.length-1]!==n)throw new Error(\"Beta must have the same hidden size as input\")}if(e.length>4){let u=e[4];if(u.dims.length!==1)throw new Error(\"Bias must be 1D\");if(u.dims[u.dims.length-1]!==n)throw new Error(\"Bias must have the same hidden size as input\")}},gc=(e,t,r,o)=>{let n=e[0].dims,s=U.size(n),u=n,d=s,a=n.slice(-1)[0],p=o?n.slice(0,-1).concat(1):[],h=e.length>3,g=e.length>4,y=o&&r>1,w=o&&r>2,b=r>3,_=Ne(a),I=[z(\"x\",e[0].dataType,e[0].dims,_),z(\"skip\",e[1].dataType,e[1].dims,_),z(\"gamma\",e[2].dataType,e[2].dims,_)];h&&I.push(z(\"beta\",e[3].dataType,e[3].dims,_)),g&&I.push(z(\"bias\",e[4].dataType,e[4].dims,_)),I.push(j(\"output\",e[0].dataType,u,_)),y&&I.push(j(\"meanOutput\",1,p)),w&&I.push(j(\"invStdOutput\",1,p)),b&&I.push(j(\"inputSkipBiasSum\",e[0].dataType,u,_));let S=Ve(e[0].dataType),x=T=>`\n      const hiddenSize: f32 = ${a};\n      const hiddenSizeVectorized: u32 = ${a/_};\n      const epsilon: f32 = ${t.epsilon};\n\n      ${T.declareVariables(...I)}\n\n      ${T.mainStart()}\n        ${T.guardAgainstOutOfBoundsWorkgroupSizes(d/a)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${je(\"f32\",_)};\n        var squareSum = ${je(\"f32\",_)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${g?\"bias[i]\":\"0.0\"};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${b?\"inputSkipBiasSum[offset + i] = value;\":\"\"}\n          output[offset + i] = value;\n          let f32Value = ${rt(S,_,\"value\")};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${Qe(\"sum\",_)} / hiddenSize;\n        let variance = sqrt(${Qe(\"squareSum\",_)} / hiddenSize - mean * mean + epsilon);\n        ${y?\"meanOutput[global_idx] = mean;\":\"\"}\n        ${w?\"invStdOutput[global_idx] = 1.0 / variance;\":\"\"}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${S}(mean)) / ${S}(variance) * gamma[i]\n           + ${h?\"beta[i]\":\"0.0\"};\n        }\n      }`,O=[{dims:u,dataType:e[0].dataType}];return r>1&&O.push({dims:p,dataType:1}),r>2&&O.push({dims:p,dataType:1}),r>3&&O.push({dims:n,dataType:e[0].dataType}),{name:\"SkipLayerNormalization\",shaderCache:{hint:t.cacheKey},getShaderSource:x,getRunData:()=>({outputs:O,dispatchGroup:{x:Math.ceil(d/a/64)}})}},Ys=(e,t)=>{hc(e.inputs);let o=[0];e.outputCount>1&&o.push(-3),e.outputCount>2&&o.push(-3),e.outputCount>3&&o.push(3),e.compute(gc(e.inputs,t,e.outputCount,!1),{outputs:o})},Zs=e=>{let t=e.epsilon;return ge({epsilon:t})}});var yc,sn,bc,Qs,wc,vc,Js,eu,tu=Y(()=>{\"use strict\";De();Se();We();we();yc=(e,t)=>{if(!e||e.length<1)throw new Error(\"too few inputs\");if(t.axes.length!==0){if(t.axes.length!==t.starts.length||t.axes.length!==t.ends.length)throw new Error(\"axes, starts and ends must have the same length\")}else if(t.starts.length!==t.ends.length)throw new Error(\"starts and ends must have the same length\");e.slice(1).forEach((r,o)=>{if(e[o+1].dataType!==6&&e[o+1].dataType!==7)throw new Error(`Input ${o} must be an array of int32 or int64`)})},sn=(e,t)=>{let r=[];if(e.length>t)if(e[t].dataType===7)e[t].getBigInt64Array().forEach(o=>r.push(Number(o)));else if(e[t].dataType===6)e[t].getInt32Array().forEach(o=>r.push(Number(o)));else throw new Error(`Input ${t} must be an array of int32 or int64`);return r},bc=(e,t)=>{if(e.length>1){let r=sn(e,1),o=sn(e,2),n=sn(e,3);return n.length===0&&(n=[...Array(e[0].dims.length).keys()]),ge({starts:r,ends:o,axes:n})}else return t},Qs=(e,t,r,o,n)=>{let s=e;return e<0&&(s+=r[o[t]]),n[t]<0?Math.max(0,Math.min(s,r[o[t]]-1)):Math.max(0,Math.min(s,r[o[t]]))},wc=(e,t,r)=>`fn calculateInputIndices(output_indices: ${t.type.indices}) -> ${e.type.indices} {\n          var input_indices: ${e.type.indices};\n          var carry = 0u;\n          for (var i = ${r.length}; i >= 0; i--) {\n            let input_shape_i = ${de(\"uniforms.input_shape\",\"i\",r.length)};\n            let steps_i = ${de(\"uniforms.steps\",\"i\",r.length)};\n            let signs_i = ${de(\"uniforms.signs\",\"i\",r.length)};\n            let starts_i = ${de(\"uniforms.starts\",\"i\",r.length)};\n            var output_index = ${t.indicesGet(\"output_indices\",\"i\")};\n            var input_index = output_index * steps_i + starts_i + carry;\n            carry = input_index / input_shape_i;\n            input_index = input_index % input_shape_i;\n            if (signs_i < 0) {\n              input_index = input_shape_i - input_index - 1u + starts_i;\n            }\n            ${e.indicesSet(\"input_indices\",\"i\",\"input_index\")};\n          }\n          return input_indices;\n      }`,vc=(e,t)=>{let r=e[0].dims,o=U.size(r),n=t.axes.length>0?U.normalizeAxes(t.axes,r.length):[...Array(r.length).keys()],s=sn(e,4);s.forEach(S=>S!==0||(()=>{throw new Error(\"step cannot be 0\")})),s.length===0&&(s=Array(n.length).fill(1));let u=t.starts.map((S,x)=>Qs(S,x,r,n,s)),d=t.ends.map((S,x)=>Qs(S,x,r,n,s));if(n.length!==u.length||n.length!==d.length)throw new Error(\"start, ends and axes should have the same number of elements\");if(n.length!==r.length)for(let S=0;S<r.length;++S)n.includes(S)||(u.splice(S,0,0),d.splice(S,0,r[S]),s.splice(S,0,1));let a=s.map(S=>Math.sign(S));s.forEach((S,x,O)=>{if(S<0){let T=(d[x]-u[x])/S,M=u[x],A=M+T*s[x];u[x]=A,d[x]=M,O[x]=-S}});let p=r.slice(0);n.forEach((S,x)=>{p[S]=Math.ceil((d[S]-u[S])/s[S])});let h={dims:p,dataType:e[0].dataType},g=j(\"output\",e[0].dataType,p.length),y=z(\"input\",e[0].dataType,e[0].dims.length),w=U.size(p),b=[{name:\"outputSize\",type:\"u32\"},{name:\"starts\",type:\"u32\",length:u.length},{name:\"signs\",type:\"i32\",length:a.length},{name:\"steps\",type:\"u32\",length:s.length}],_=[{type:\"uint32\",data:w},{type:\"uint32\",data:u},{type:\"int32\",data:a},{type:\"uint32\",data:s},...q(e[0].dims),...q(p)],I=S=>`\n      ${S.registerUniforms(b).declareVariables(y,g)}\n        ${wc(y,g,r)}\n        ${S.mainStart()}\n          ${S.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n          let output_indices = ${g.offsetToIndices(\"global_idx\")};\n          let input_indices = calculateInputIndices(output_indices);\n          ${g.setByOffset(\"global_idx\",y.getByIndices(\"input_indices\"))}\n      }`;return{name:\"Slice\",shaderCache:{hint:`${a.length}_${u.length}_${s.length}`,inputDependencies:[\"rank\"]},getShaderSource:I,getRunData:()=>({outputs:[h],dispatchGroup:{x:Math.ceil(o/64)},programUniforms:_})}},Js=(e,t)=>{yc(e.inputs,t);let r=bc(e.inputs,t);e.compute(vc(e.inputs,r),{inputs:[0]})},eu=e=>{let t=e.starts,r=e.ends,o=e.axes;return ge({starts:t,ends:r,axes:o})}});var $c,Sc,ru,nu,ou=Y(()=>{\"use strict\";Se();We();we();$c=e=>{if(!e||e.length!==1)throw new Error(\"Softmax op requires 1 input.\")},Sc=(e,t)=>{let r=e.dims,o=U.size(r),n=64,s=t.axis;if(s<0&&(s=r.length+s),s<r.length-1)throw new Error(\"softmax only supports last axis for now.\");let u=r[s],d=o/u,a=Ne(u),p=u/a,h=(I,S)=>S===4?`max(max(${I}.x, ${I}.y), max(${I}.z, ${I}.w))`:S===2?`max(${I}.x, ${I}.y)`:S===3?`max(max(${I}.x, ${I}.y), ${I}.z)`:I,g=z(\"x\",e.dataType,e.dims,a),y=j(\"result\",e.dataType,e.dims,a),w=g.type.value,b=Ve(e.dataType)===\"f32\"?`var threadMax = ${w}(-3.402823e+38f);`:`var threadMax = ${w}(-65504.0h);`,_=I=>`\n      var<workgroup> rowMaxShared : ${w};\n      var<workgroup> rowSumShared : ${w};\n      var<workgroup> threadShared : array<${w}, ${n}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${w} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${w}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${I.registerUniform(\"packedCols\",\"i32\").declareVariables(g,y)}\n      ${I.mainStart()}\n        let gindex = i32(global_idx);\n        let lindex = i32(local_idx);\n        const wg = ${n};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${b}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${w}(${h(\"threadShared[0]\",a)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${w}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${w}(${Qe(\"threadShared[0]\",a)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;return{name:\"Softmax\",shaderCache:{hint:`${a}`,inputDependencies:[\"type\"]},getRunData:()=>({outputs:[{dims:r,dataType:e.dataType}],dispatchGroup:{x:d},programUniforms:[{type:\"uint32\",data:p}]}),getShaderSource:_}},ru=(e,t)=>{$c(e.inputs),e.compute(Sc(e.inputs[0],t))},nu=e=>ge({axis:e.axis})});var xc,_c,Cc,Ic,Ac,au,iu,su=Y(()=>{\"use strict\";Se();We();we();xc=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\")},_c=(e,t)=>{let r=[],o=t.numOutputs;return e[1].dims[0]>0&&(e[1].getBigInt64Array().forEach(n=>r.push(Number(n))),o=r.length),ge({numOutputs:o,axis:t.axis,splitSizes:r})},Cc=e=>`\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n    if (index < ${de(\"uniforms.size_in_split_axis\",\"i\",e)}) {\n        return i;\n    }\n    }\n    return ${e}u;\n}`,Ic=e=>{let t=e.length,r=[];for(let o=0;o<t;++o){let n=e[o].setByIndices(\"indices\",\"input[global_idx]\");t===1?r.push(n):o===0?r.push(`if (output_number == ${o}u) { ${n} }`):o===t-1?r.push(`else { ${n} }`):r.push(`else if (output_number == ${o}) { ${n} }`)}return`\n      fn writeBufferData(output_number: u32, indices: ${e[0].type.indices}, global_idx: u32) {\n        ${r.join(`\n`)}\n      }`},Ac=(e,t)=>{let r=e[0].dims,o=U.size(r),n=e[0].dataType,s=U.normalizeAxis(t.axis,r.length),u=new Array(t.numOutputs),d=z(\"input\",n,r),a=new Array(t.numOutputs),p=[],h=[],g=0,y=[{type:\"uint32\",data:o}];for(let b=0;b<t.numOutputs;b++){g+=t.splitSizes[b],a[b]=g;let _=r.slice();_[t.axis]=t.splitSizes[b],h.push(_),u[b]=j(`output${b}`,n,_),p.push({dims:h[b],dataType:e[0].dataType})}y.push({type:\"uint32\",data:a}),y.push(...q(r)),h.forEach(b=>y.push(...q(b)));let w=b=>`\n  ${b.registerUniform(\"input_size\",\"u32\").registerUniform(\"size_in_split_axis\",\"u32\",a.length).declareVariables(d,...u)}\n  ${Cc(a.length)}\n  ${Ic(u)}\n\n  ${b.mainStart()}\n    ${b.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.input_size\")}\n\n    var indices = ${d.offsetToIndices(\"global_idx\")};\n    var index = ${d.indicesGet(\"indices\",s)};\n    let output_number = calculateOutputIndex(index);\n    if (output_number != 0) {\n      index -= ${de(\"uniforms.size_in_split_axis\",\"output_number - 1u\",a.length)};\n      ${d.indicesSet(\"indices\",s,\"index\")};\n    }\n    writeBufferData(output_number, indices, global_idx);\n  }`;return{name:\"Split\",shaderCache:{hint:t.cacheKey,inputDependencies:[\"rank\"]},getShaderSource:w,getRunData:()=>({outputs:p,dispatchGroup:{x:Math.ceil(o/64)},programUniforms:y})}},au=(e,t)=>{xc(e.inputs);let r=e.inputs.length===1?t:_c(e.inputs,t);e.compute(Ac(e.inputs,r),{inputs:[0]})},iu=e=>{let t=e.axis,r=e.splitSizes,o=e.numOutputs<0?r.length:e.numOutputs;if(o!==r.length)throw new Error(\"numOutputs and splitSizes lengh must be equal\");return ge({axis:t,numOutputs:o,splitSizes:r})}});var uu,Tc,Ec,Oc,lu,du=Y(()=>{\"use strict\";De();Se();we();uu=e=>Array.from(e.getBigInt64Array(),Number),Tc=e=>{if(!e||e.length!==2)throw new Error(\"Tile requires 2 inputs.\");if(e[0].dataType!==1&&e[0].dataType!==6&&e[0].dataType!==12)throw new Error(\"Tile only support float, int32, and uint32 data types\");if(e[1].dataType!==7)throw new Error(\"Tile `repeats` input should be of int64 data type\");if(e[1].dims.length!==1)throw new Error(\"Tile `repeats` input should be 1-D\");if(uu(e[1]).length!==e[0].dims.length)throw new Error(\"Tile `repeats` input should have same number of elements as rank of input data tensor\")},Ec=(e,t)=>{let r=[];for(let o=0;o<e.length;++o)r.push(e[o]*t[o]);return r},Oc=e=>{let t=e[0].dims,r=uu(e[1]),o=Ec(t,r),n=U.size(o),s=e[0].dataType,u=z(\"input\",s,t.length),d=j(\"output\",s,o.length),a=p=>`\n      const inputShape = ${u.indices(...t)};\n      ${p.registerUniform(\"output_size\",\"u32\").declareVariables(u,d)}\n      ${p.mainStart()}\n      ${p.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n      let output_indices = ${d.offsetToIndices(\"global_idx\")};\n      var input_indices: ${u.type.indices};\n      for (var i = 0; i < ${t.length}; i++) {\n        let input_dim_i = ${u.indicesGet(\"uniforms.input_shape\",\"i\")};\n        let input_dim_value = ${d.indicesGet(\"output_indices\",\"i\")}  % input_dim_i;\n\n        ${u.indicesSet(\"input_indices\",\"i\",\"input_dim_value\")}\n      }\n      ${d.setByOffset(\"global_idx\",u.getByIndices(\"input_indices\"))}\n    }`;return{name:\"Tile\",shaderCache:{hint:`${r}`,inputDependencies:[\"rank\"]},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(n/64)},programUniforms:[{type:\"uint32\",data:n},...q(e[0].dims),...q(o)]}),getShaderSource:a}},lu=e=>{Tc(e.inputs),e.compute(Oc(e.inputs),{inputs:[0]})}});var Pc,kc,cu,pu=Y(()=>{\"use strict\";De();Se();we();Pc=(e,t,r,o,n)=>{let s=j(\"output_data\",n,r.length,4),u=z(\"a_data\",t[1].dataType,t[1].dims.length,4),d=z(\"b_data\",t[2].dataType,t[2].dims.length,4),a=z(\"c_data\",t[0].dataType,t[0].dims.length,4),p,h=(g,y,w)=>`select(${y}, ${g}, ${w})`;if(!o)p=s.setByOffset(\"global_idx\",h(u.getByOffset(\"global_idx\"),d.getByOffset(\"global_idx\"),a.getByOffset(\"global_idx\")));else{let g=(y,w,b=\"\")=>{let _=`a_data[index_a${w}][component_a${w}]`,I=`b_data[index_b${w}][component_b${w}]`,S=`bool(c_data[index_c${w}] & ${4278190080>>>(3-w)*8}u)`;return`\n            let output_indices${w} = ${s.offsetToIndices(`global_idx * 4u + ${w}u`)};\n            let offset_a${w} = ${u.broadcastedIndicesToOffset(`output_indices${w}`,s)};\n            let offset_b${w} = ${d.broadcastedIndicesToOffset(`output_indices${w}`,s)};\n            let offset_c${w} = ${a.broadcastedIndicesToOffset(`output_indices${w}`,s)};\n            let index_a${w} = offset_a${w} / 4u;\n            let index_b${w} = offset_b${w} / 4u;\n            let index_c${w} = offset_c${w} / 4u;\n            let component_a${w} = offset_a${w} % 4u;\n            let component_b${w} = offset_b${w} % 4u;\n            ${y}[${w}] = ${b}(${h(_,I,S)});\n          `};n===9?p=`\n            var data = vec4<u32>(0);\n            ${g(\"data\",0,\"u32\")}\n            ${g(\"data\",1,\"u32\")}\n            ${g(\"data\",2,\"u32\")}\n            ${g(\"data\",3,\"u32\")}\n            output_data[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:p=`\n            ${g(\"output_data[global_idx]\",0)}\n            ${g(\"output_data[global_idx]\",1)}\n            ${g(\"output_data[global_idx]\",2)}\n            ${g(\"output_data[global_idx]\",3)}\n          `}return`\n        ${e.registerUniform(\"vec_size\",\"u32\").declareVariables(a,u,d,s)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n        ${p}\n      }`},kc=e=>{let t=e[1].dims,r=e[2].dims,o=e[0].dims,n=e[1].dataType,s=!(U.areEqual(t,r)&&U.areEqual(r,o)),u=t,d=U.size(t),a=Math.ceil(d/4);if(s){let p=st.calcShape(st.calcShape(t,r,!1),o,!1);if(!p)throw new Error(\"Can't perform where op on the given tensors\");u=p,d=U.size(u)}return{name:\"Where\",shaderCache:{inputDependencies:[\"rank\",\"rank\",\"rank\"]},getShaderSource:p=>Pc(p,e,u,s,n),getRunData:()=>({outputs:[{dims:u,dataType:n}],dispatchGroup:{x:Math.ceil(d/64/4)},programUniforms:[{type:\"uint32\",data:a},...q(o),...q(t),...q(r),...q(u)]})}},cu=e=>{e.compute(kc(e.inputs))}});var mu,fu=Y(()=>{\"use strict\";za();Un();Wa();Ha();$i();ki();Di();Gn();Yi();Qi();ns();is();ls();ps();hs();ys();ws();Fn();xs();Cs();Hs();Ls();Kr();Ks();Xs();tu();ou();su();du();qt();Vn();pu();mu=new Map([[\"Abs\",[Ga]],[\"Acos\",[La]],[\"Acosh\",[Fa]],[\"Add\",[Si]],[\"ArgMax\",[Ma,zn]],[\"ArgMin\",[Da,zn]],[\"Asin\",[qa]],[\"Asinh\",[ja]],[\"Atan\",[Ka]],[\"Atanh\",[Ya]],[\"Attention\",[Ua]],[\"AveragePool\",[Rs,ks]],[\"BatchNormalization\",[Va]],[\"BiasAdd\",[Na]],[\"BiasSplitGelu\",[vi]],[\"Cast\",[Xa,Za]],[\"Ceil\",[Ja]],[\"Clip\",[Qa]],[\"Concat\",[Ri,Bi]],[\"Conv\",[jn,qn]],[\"ConvTranspose\",[Ki,ji]],[\"Cos\",[ei]],[\"Cosh\",[ti]],[\"CumSum\",[Zi,Xi]],[\"Div\",[xi]],[\"Einsum\",[ts,rs]],[\"Elu\",[ri,Xr]],[\"Equal\",[_i]],[\"Erf\",[ni]],[\"Exp\",[oi]],[\"Expand\",[as]],[\"Floor\",[ai]],[\"FusedConv\",[jn,qn]],[\"Gather\",[us,ss]],[\"GatherElements\",[cs,ds]],[\"Gelu\",[ii]],[\"Gemm\",[fs,ms]],[\"GlobalAveragePool\",[Ms,Ds]],[\"GlobalMaxPool\",[Ns,Ws]],[\"Greater\",[Ti]],[\"GreaterOrEqual\",[Oi]],[\"InstanceNormalization\",[gs]],[\"LayerNormalization\",[bs]],[\"LeakyRelu\",[si,Xr]],[\"Less\",[Ei]],[\"LessOrEqual\",[Pi]],[\"Log\",[wi]],[\"MatMul\",[Wi]],[\"MaxPool\",[Us,Vs]],[\"Mul\",[Ci]],[\"MultiHeadAttention\",[Ss,$s]],[\"Neg\",[li]],[\"Not\",[ui]],[\"Pad\",[_s]],[\"Pow\",[Ii]],[\"Range\",[Gs]],[\"Reciprocal\",[di]],[\"ReduceMin\",[Ea]],[\"ReduceMean\",[_a]],[\"ReduceMax\",[Ta]],[\"ReduceSum\",[Pa]],[\"ReduceProd\",[Oa]],[\"ReduceL1\",[Ca]],[\"ReduceL2\",[Ia]],[\"ReduceLogSum\",[Ra]],[\"ReduceLogSumExp\",[Aa]],[\"ReduceSumSquare\",[ka]],[\"Relu\",[ci]],[\"Resize\",[qs,js]],[\"Sigmoid\",[pi]],[\"Sin\",[mi]],[\"Sinh\",[fi]],[\"Slice\",[Js,eu]],[\"SkipLayerNormalization\",[Ys,Zs]],[\"Split\",[au,iu]],[\"Sqrt\",[hi]],[\"Softmax\",[ru,nu]],[\"Sub\",[Ai]],[\"Tan\",[gi]],[\"Tanh\",[yi]],[\"ThresholdedRelu\",[bi,Xr]],[\"Tile\",[lu]],[\"Transpose\",[ca,pa]],[\"Where\",[cu]]])});var un,hu=Y(()=>{\"use strict\";Lt();De();St();we();un=class{constructor(t){this.backend=t;this.repo=new Map,this.attributesBound=!1}getArtifact(t){return this.repo.get(t)}setArtifact(t,r){this.repo.set(t,r)}run(t,r,o,n,s,u,d){Ht(t.programInfo.name);let a=this.backend.device,p=this.backend.getComputePassEncoder();p.setPipeline(t.computePipeline);let h=[];for(let y of n)h.push({binding:h.length,resource:{buffer:y.buffer}});for(let y of s)h.push({binding:h.length,resource:{buffer:y.buffer}});d&&h.push({binding:h.length,resource:d});let g=a.createBindGroup({layout:t.computePipeline.getBindGroupLayout(0),entries:h,label:t.programInfo.name});if(p.setBindGroup(0,g),p.dispatchWorkgroups(...u),this.backend.pendingDispatchNumber++,this.backend.isQueryEnabled()){typeof this.backend.queryData>\"u\"&&(this.backend.queryData=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.COPY_SRC|GPUBufferUsage.QUERY_RESOLVE));let y=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST);this.backend.endComputePass(),this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet,0,2,this.backend.queryData.buffer,0),this.backend.getCommandEncoder().copyBufferToBuffer(this.backend.queryData.buffer,0,y.buffer,0,this.backend.querySetCount*8),this.backend.flush();let w=this.backend.currentKernelId,b=this.backend.kernels.get(w);y.buffer.mapAsync(GPUMapMode.READ).then(()=>{let _=new BigUint64Array(y.buffer.getMappedRange()),[I,S]=_,[x,O]=b;y.buffer.unmap(),typeof this.backend.queryTimeBase>\"u\"&&(this.backend.queryTimeBase=I);let T=Number(I-this.backend.queryTimeBase),M=Number(S-this.backend.queryTimeBase);if(!Number.isSafeInteger(T)||!Number.isSafeInteger(M))throw new RangeError(\"incorrect timestamp range\");if(this.backend.gpuDataManager.release(y.id),this.backend.env.webgpu.profiling?.ondata)this.backend.env.webgpu.profiling.ondata({version:1,inputsMetadata:r.map(A=>({dims:A.dims,dataType:Xe(A.dataType)})),outputsMetadata:o.map(A=>({dims:A.dims,dataType:Xe(A.dataType)})),kernelId:w,kernelType:x,kernelName:O,startTime:T,endTime:M});else{let A=\"\";r.forEach((V,G)=>{A+=`input[${G}]: [${V.dims}] | ${Xe(V.dataType)}, `});let W=\"\";o.forEach((V,G)=>{W+=`output[${G}]: [${V.dims}] | ${Xe(V.dataType)}, `}),console.log(`[profiling] kernel \"${w}|${O}|${t.programInfo.name}\" ${A}${W}execution time: ${M-T} ns`)}})}this.backend.pendingDispatchNumber>=16&&this.backend.flush(),Gt(t.programInfo.name)}dispose(){}build(t,r){Ht(t.name);let o=this.backend.device,n=[];o.features.has(\"shader-f16\")&&n.push(\"enable f16;\");let s=la(r),u=t.getShaderSource(s),d=`${n.join(`\n`)}\n${s.additionalImplementations}\n${u}`,a=o.createShaderModule({code:d,label:t.name});Pe(\"verbose\",()=>`[WebGPU] ${t.name} shader code: ${d}`);let p=o.createComputePipeline({compute:{module:a,entryPoint:\"main\"},layout:\"auto\",label:t.name});return Gt(t.name),{programInfo:t,computePipeline:p}}normalizeDispatchGroupSize(t){let r=typeof t==\"number\"?t:t.x,o=typeof t==\"number\"?1:t.y||1,n=typeof t==\"number\"?1:t.z||1,s=this.backend.device.limits.maxComputeWorkgroupsPerDimension;if(r<=s&&o<=s&&n<=s)return[r,o,n];let u=r*o*n,d=Math.ceil(Math.sqrt(u));if(d>s){if(d=Math.ceil(Math.cbrt(u)),d>s)throw new Error(\"Total dispatch size exceeds WebGPU maximum.\");return[d,d,d]}else return[d,d,1]}}});var Rc,Bc,ln,gu=Y(()=>{\"use strict\";Lt();St();oa();ua();fu();hu();Rc=(e,t)=>{if(t.length!==e.length)throw new Error(`inputDependencies length ${t.length} is not equal to inputTensors length ${e.length}.`);let r=[];for(let o=0;o<e.length;++o){let n=e[o].dataType;switch(t[o]){case\"none\":{r.push(\"\");break}case\"type\":{r.push(`${n}`);break}case\"rank\":{let s=e[o].dims.length;r.push(`${n};${s}`);break}case\"dims\":{let s=e[o].dims.join(\",\");r.push(`${n};${s}`);break}default:throw new Error(`unsupported input dependency: ${t[o]}`)}}return r.join(\"|\")},Bc=(e,t,r)=>{let o=e.name;return e.shaderCache?.hint&&(o+=\"[\"+e.shaderCache.hint+\"]\"),o+=\":\"+r+`:${Rc(t,e.shaderCache?.inputDependencies??new Array(t.length).fill(\"dims\"))}`,o},ln=class{constructor(){this.currentKernelId=null;this.commandEncoder=null;this.computePassEncoder=null;this.pendingDispatchNumber=0;this.querySetCount=2;this.sessionExternalDataMapping=new Map}get currentKernelCustomData(){if(this.currentKernelId===null)throw new Error(\"currentKernelCustomData(): currentKernelId is null. (should not happen)\");let t=this.kernelCustomData.get(this.currentKernelId);return t||(t={},this.kernelCustomData.set(this.currentKernelId,t)),t}async initialize(t,r){this.env=t;let o=[],n={requiredLimits:{maxComputeWorkgroupStorageSize:r.limits.maxComputeWorkgroupStorageSize,maxComputeWorkgroupsPerDimension:r.limits.maxComputeWorkgroupsPerDimension,maxStorageBufferBindingSize:r.limits.maxStorageBufferBindingSize,maxBufferSize:r.limits.maxBufferSize,maxComputeInvocationsPerWorkgroup:r.limits.maxComputeInvocationsPerWorkgroup,maxComputeWorkgroupSizeX:r.limits.maxComputeWorkgroupSizeX,maxComputeWorkgroupSizeY:r.limits.maxComputeWorkgroupSizeY,maxComputeWorkgroupSizeZ:r.limits.maxComputeWorkgroupSizeZ},requiredFeatures:o};r.features.has(\"timestamp-query\")&&o.push(\"timestamp-query\"),r.features.has(\"shader-f16\")&&o.push(\"shader-f16\"),this.device=await r.requestDevice(n),this.gpuDataManager=sa(this),this.programManager=new un(this),this.kernels=new Map,this.kernelPersistentData=new Map,this.kernelCustomData=new Map,ra(t.logLevel,!!t.debug),this.device.onuncapturederror=s=>{s.error instanceof GPUValidationError&&console.error(`An uncaught WebGPU validation error was raised: ${s.error.message}`)},Object.defineProperty(this.env.webgpu,\"device\",{value:this.device})}dispose(){typeof this.querySet<\"u\"&&this.querySet.destroy(),this.gpuDataManager.dispose()}getCommandEncoder(){return this.commandEncoder||(this.commandEncoder=this.device.createCommandEncoder()),this.commandEncoder}getComputePassEncoder(){if(!this.computePassEncoder){let t={};this.isQueryEnabled()&&(typeof this.querySet>\"u\"&&(this.querySet=this.device.createQuerySet({type:\"timestamp\",count:this.querySetCount})),t.timestampWrites={querySet:this.querySet,beginningOfPassWriteIndex:0,endOfPassWriteIndex:1}),this.computePassEncoder=this.getCommandEncoder().beginComputePass(t)}return this.computePassEncoder}endComputePass(){this.computePassEncoder&&(this.computePassEncoder.end(),this.computePassEncoder=null)}flush(){this.commandEncoder&&(this.endComputePass(),this.device.queue.submit([this.getCommandEncoder().finish()]),this.gpuDataManager.refreshPendingBuffers(),this.commandEncoder=null,this.pendingDispatchNumber=0)}isQueryEnabled(){return this.device.features.has(\"timestamp-query\")&&(this.env.webgpu.profiling?.mode===\"default\"||!this.env.webgpu.profiling?.mode&&this.env.webgpu.profilingMode===\"default\")}run(t,r,o,n,s){Ht(t.name);let u=[];for(let x=0;x<r.length;++x){let O=this.gpuDataManager.get(r[x].data);if(!O)throw new Error(`no GPU data for input: ${r[x].data}`);u[x]=O}let{outputs:d,dispatchGroup:a,programUniforms:p}=t.getRunData(r),h=o.length===0?d.map((x,O)=>O):o;if(h.length!==d.length)throw new Error(`Output size ${h.length} must be equal to ${d.length}.`);let g=[],y=[];for(let x=0;x<d.length;++x){if(!Number.isInteger(h[x])||h[x]<-3||h[x]>=d.length)throw new Error(`Invalid output index: ${h[x]}`);if(h[x]===-3)continue;let O=h[x]===-1,T=h[x]===-2,M=O||T?s(d[x].dataType,d[x].dims):n(h[x],d[x].dataType,d[x].dims),A=this.gpuDataManager.get(M.data);if(!A)throw new Error(`no GPU data for output: ${M.data}`);if(O&&this.temporaryData.push(A),T){let W=this.kernelPersistentData.get(this.currentKernelId);W||(W=[],this.kernelPersistentData.set(this.currentKernelId,W)),W.push(A)}g.push(M),y.push(A)}let w;if(p){let x=0,O=[];p.forEach(W=>{let V=typeof W.data==\"number\"?[W.data]:W.data;if(V.length===0)return;let G=V.length<=2?V.length*4:16;x=Math.ceil(x/G)*G,O.push(x),x+=V.length>4?Math.ceil(V.length/4)*16:V.length*4});let T=16;x=Math.ceil(x/T)*T;let M=new ArrayBuffer(x);p.forEach((W,V)=>{let G=O[V],J=typeof W.data==\"number\"?[W.data]:W.data;W.type===\"int32\"?new Int32Array(M,G,J.length).set(J):W.type===\"uint32\"?new Uint32Array(M,G,J.length).set(J):new Float32Array(M,G,J.length).set(J)});let A=this.gpuDataManager.create(x,GPUBufferUsage.COPY_DST|GPUBufferUsage.UNIFORM);this.device.queue.writeBuffer(A.buffer,0,M,0,x),this.gpuDataManager.release(A.id),w={offset:0,size:x,buffer:A.buffer}}let b=this.programManager.normalizeDispatchGroupSize(a),_=b[1]===1&&b[2]===1,I=Bc(t,r,_),S=this.programManager.getArtifact(I);return S||(S=this.programManager.build(t,b),this.programManager.setArtifact(I,S),Pe(\"info\",()=>`[artifact] key: ${I}, programName: ${t.name}`)),Pe(\"info\",()=>`[ProgramManager] run \"${t.name}\" (key=${I}) with ${b[0]}x${b[1]}x${b[2]}`),this.programManager.run(S,r,g,u,y,b,w),Gt(t.name),g}upload(t,r){this.gpuDataManager.upload(t,r)}memcpy(t,r){this.gpuDataManager.memcpy(t,r)}async download(t,r){await this.gpuDataManager.download(t,r)}alloc(t){return this.gpuDataManager.create(t).id}free(t){return this.gpuDataManager.release(t)}createKernel(t,r,o,n){let s=mu.get(t);if(!s)throw new Error(`kernel not implemented: ${t}`);this.kernels.set(r,[t,n,s[0],[s[1],o]])}releaseKernel(t){let r=this.kernelPersistentData.get(t);if(r){for(let o of r)this.gpuDataManager.release(o.id);this.kernelPersistentData.delete(t)}this.kernelCustomData.delete(t),this.kernels.delete(t)}computeKernel(t,r,o){let n=this.kernels.get(t);if(!n)throw new Error(`kernel not created: ${t}`);let[s,u,d,a]=n;if(this.currentKernelId!==null)throw new Error(`kernel \"[${s}] ${u}\" is not allowed to be called recursively`);this.currentKernelId=t,a[0]&&(a[1]=a[0](a[1]),a[0]=void 0),Pe(\"info\",()=>`[WebGPU] Start to run kernel \"[${s}] ${u}\"...`);let p=this.env.debug;this.temporaryData=[];try{return p&&this.device.pushErrorScope(\"validation\"),d(r,a[1]),0}catch(h){return o.push(Promise.resolve(`[WebGPU] Kernel \"[${s}] ${u}\" failed. ${h}`)),1}finally{p&&o.push(this.device.popErrorScope().then(h=>h?`GPU validation error for kernel \"[${s}] ${u}\": ${h.message}`:null));for(let h of this.temporaryData)this.gpuDataManager.release(h.id);this.temporaryData=[],this.currentKernelId=null}}registerBuffer(t,r,o,n){let s=this.sessionExternalDataMapping.get(t);s||(s=new Map,this.sessionExternalDataMapping.set(t,s));let u=s.get(r),d=this.gpuDataManager.registerExternalBuffer(o,n,u?.[1]);return s.set(r,[d,o]),d}unregisterBuffers(t){let r=this.sessionExternalDataMapping.get(t);r&&(r.forEach(o=>this.gpuDataManager.unregisterExternalBuffer(o[1])),this.sessionExternalDataMapping.delete(t))}getBuffer(t){let r=this.gpuDataManager.get(t);if(!r)throw new Error(`no GPU data for buffer: ${t}`);return r.buffer}createDownloader(t,r,o){return async()=>{let n=await On(this,t,r);return na(n.buffer,o)}}}});var yu={};Mr(yu,{init:()=>Dc});var yr,Jn,Dc,bu=Y(()=>{\"use strict\";De();gu();St();Se();yr=class e{constructor(t,r,o,n){this.module=t;this.dataType=r;this.data=o;this.dims=n}getFloat32Array(){if(this.dataType!==1)throw new Error(\"Invalid data type\");let t=U.size(this.dims);return t===0?new Float32Array:new Float32Array(this.module.HEAP8.buffer,this.data,t)}getBigInt64Array(){if(this.dataType!==7)throw new Error(\"Invalid data type\");let t=U.size(this.dims);return t===0?new BigInt64Array:new BigInt64Array(this.module.HEAP8.buffer,this.data,t)}getInt32Array(){if(this.dataType!==6)throw new Error(\"Invalid data type\");let t=U.size(this.dims);return t===0?new Int32Array:new Int32Array(this.module.HEAP8.buffer,this.data,t)}reshape(t){if(U.size(t)!==U.size(this.dims))throw new Error(\"Invalid new shape\");return new e(this.module,this.dataType,this.data,t)}},Jn=class{constructor(t,r,o){this.module=t;this.backend=r;this.customDataOffset=0;this.customDataSize=0;let n=t.HEAPU32,s=o>>>2;this.opKernelContext=n[s++];let u=n[s++];this.outputCount=n[s++],this.customDataOffset=n[s++],this.customDataSize=n[s++];let d=[];for(let a=0;a<u;a++){let p=n[s++],h=n[s++],g=n[s++],y=[];for(let w=0;w<g;w++)y.push(n[s++]);d.push(new yr(t,p,h,y))}this.inputs=d}get kernelCustomData(){return this.backend.currentKernelCustomData}get customDataBuffer(){return this.module.HEAPU8.subarray(this.customDataOffset,this.customDataOffset+this.customDataSize)}compute(t,r){let o=r?.inputs?.map(d=>typeof d==\"number\"?this.inputs[d]:d)??this.inputs,n=r?.outputs??[],s=(d,a,p)=>new yr(this.module,a,this.output(d,p),p),u=(d,a)=>{let p=pr(d);if(!p)throw new Error(`Unsupported data type: ${d}`);let h=p*U.size(a);return new yr(this.module,d,this.backend.gpuDataManager.create(h).id,a)};return this.backend.run(t,o,n,s,u)}output(t,r){let o=this.module.stackSave();try{let n=this.module.stackAlloc((1+r.length)*4),s=n>>2;this.module.HEAPU32[s++]=r.length;for(let u=0;u<r.length;u++)this.module.HEAPU32[s++]=r[u];return this.module._JsepOutput(this.opKernelContext,t,n)}catch(n){throw new Error(`Failed to generate kernel's output[${t}] with dims [${r}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${n}`)}finally{this.module.stackRestore(o)}}},Dc=async(e,t,r)=>{let o=e.jsepInit;if(!o)throw new Error(\"Failed to initialize JSEP. The WebAssembly module is not built with JSEP support.\");let n=new ln;await n.initialize(t,r),o(n,s=>n.alloc(s),s=>n.free(s),(s,u,d,a=!1)=>{if(a)Pe(\"verbose\",()=>`[WebGPU] jsepCopyGpuToGpu: src=${s}, dst=${u}, size=${d}`),n.memcpy(s,u);else{Pe(\"verbose\",()=>`[WebGPU] jsepCopyCpuToGpu: dataOffset=${s}, gpuDataId=${u}, size=${d}`);let p=e.HEAPU8.subarray(s,s+d);n.upload(u,p)}},async(s,u,d)=>{Pe(\"verbose\",()=>`[WebGPU] jsepCopyGpuToCpu: gpuDataId=${s}, dataOffset=${u}, size=${d}`),await n.download(s,()=>e.HEAPU8.subarray(u,u+d))},(s,u,d)=>n.createKernel(s,u,d,t.debug||n.isQueryEnabled()?e.UTF8ToString(e._JsepGetNodeName(u)):`${u}`),s=>n.releaseKernel(s),(s,u,d,a)=>{Pe(\"verbose\",()=>`[WebGPU] jsepRun: sessionHandle=${d}, kernel=${s}, contextDataOffset=${u}`);let p=new Jn(e,n,u);return n.computeKernel(s,p,a)})}});var Ro;Ro=xo();var Ku=Oo(),xn,_n=!1,zr=!1,ko=!1,Yu=()=>{try{return typeof SharedArrayBuffer>\"u\"?!1:(typeof MessageChannel<\"u\"&&new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11])))}catch{return!1}},Zu=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch{return!1}},Xu=(e,t)=>e?t?\"ort-wasm-simd-threaded.wasm\":\"ort-wasm-simd.wasm\":t?\"ort-wasm-threaded.wasm\":\"ort-wasm.wasm\",Bo=async e=>{if(_n)return Promise.resolve();if(zr)throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");if(ko)throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");zr=!0;let t=e.initTimeout,r=e.numThreads,o=e.simd,n=r>1&&Yu(),s=o&&Zu(),u=e.wasmPaths,d=typeof u==\"string\"?u:void 0,a=Xu(s,n),p=typeof u==\"object\"?u[a]:void 0,h=!1,g=[];if(t>0&&g.push(new Promise(y=>{setTimeout(()=>{h=!0,y()},t)})),g.push(new Promise((y,w)=>{let b=n?Ku:Ro,_={locateFile:(I,S)=>{if(n&&I.endsWith(\".worker.js\")&&typeof Blob<\"u\")return URL.createObjectURL(new Blob([Po()],{type:\"text/javascript\"}));if(I.endsWith(\".wasm\")){if(p)return p;let x=d??S;return a===\"ort-wasm-simd.wasm\"?x+\"ort-wasm-simd.jsep.wasm\":a===\"ort-wasm-simd-threaded.wasm\"?x+\"ort-wasm-simd-threaded.jsep.wasm\":x+a}return S+I}};if(n)if(_.numThreads=r,typeof Blob>\"u\")_.mainScriptUrlOrBlob=(void 0)(__dirname,\"ort-wasm-threaded.js\");else{let I=`var ortWasmThreaded=${b.toString()};`;_.mainScriptUrlOrBlob=new Blob([I],{type:\"text/javascript\"})}b(_).then(I=>{zr=!1,_n=!0,xn=I,y()},I=>{zr=!1,ko=!0,w(I)})})),await Promise.race(g),h)throw new Error(`WebAssembly backend initializing failed due to timeout: ${t}ms`)},Be=()=>{if(_n&&xn)return xn;throw new Error(\"WebAssembly is not initialized yet.\")};var ze=(e,t)=>{let r=Be(),o=r.lengthBytesUTF8(e)+1,n=r._malloc(o);return r.stringToUTF8(e,n,o),t.push(n),n},cr=(e,t,r,o)=>{if(typeof e==\"object\"&&e!==null){if(r.has(e))throw new Error(\"Circular reference in options\");r.add(e)}Object.entries(e).forEach(([n,s])=>{let u=t?t+n:n;if(typeof s==\"object\")cr(s,u+\".\",r,o);else if(typeof s==\"string\"||typeof s==\"number\")o(u,s.toString());else if(typeof s==\"boolean\")o(u,s?\"1\":\"0\");else throw new Error(`Can't handle extra config type: ${typeof s}`)})},Ee=e=>{let t=Be(),r=t.stackSave();try{let o=t.stackAlloc(8);t._OrtGetLastError(o,o+4);let n=t.HEAP32[o/4],s=t.HEAPU32[o/4+1],u=s?t.UTF8ToString(s):\"\";throw new Error(`${e} ERROR_CODE: ${n}, ERROR_MESSAGE: ${u}`)}finally{t.stackRestore(r)}};var Do=e=>{let t=Be(),r=0,o=[],n=e||{};try{if(e?.logSeverityLevel===void 0)n.logSeverityLevel=2;else if(typeof e.logSeverityLevel!=\"number\"||!Number.isInteger(e.logSeverityLevel)||e.logSeverityLevel<0||e.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${e.logSeverityLevel}`);if(e?.logVerbosityLevel===void 0)n.logVerbosityLevel=0;else if(typeof e.logVerbosityLevel!=\"number\"||!Number.isInteger(e.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${e.logVerbosityLevel}`);e?.terminate===void 0&&(n.terminate=!1);let s=0;return e?.tag!==void 0&&(s=ze(e.tag,o)),r=t._OrtCreateRunOptions(n.logSeverityLevel,n.logVerbosityLevel,!!n.terminate,s),r===0&&Ee(\"Can't create run options.\"),e?.extra!==void 0&&cr(e.extra,\"\",new WeakSet,(u,d)=>{let a=ze(u,o),p=ze(d,o);t._OrtAddRunConfigEntry(r,a,p)!==0&&Ee(`Can't set a run config entry: ${u} - ${d}.`)}),[r,o]}catch(s){throw r!==0&&t._OrtReleaseRunOptions(r),o.forEach(u=>t._free(u)),s}};var Qu=e=>{switch(e){case\"disabled\":return 0;case\"basic\":return 1;case\"extended\":return 2;case\"all\":return 99;default:throw new Error(`unsupported graph optimization level: ${e}`)}},Ju=e=>{switch(e){case\"sequential\":return 0;case\"parallel\":return 1;default:throw new Error(`unsupported execution mode: ${e}`)}},el=e=>{e.extra||(e.extra={}),e.extra.session||(e.extra.session={});let t=e.extra.session;t.use_ort_model_bytes_directly||(t.use_ort_model_bytes_directly=\"1\"),e.executionProviders&&e.executionProviders.some(r=>(typeof r==\"string\"?r:r.name)===\"webgpu\")&&(e.enableMemPattern=!1)},tl=(e,t,r)=>{for(let o of t){let n=typeof o==\"string\"?o:o.name;switch(n){case\"xnnpack\":n=\"XNNPACK\";break;case\"webnn\":if(n=\"WEBNN\",typeof o!=\"string\"){let u=o;if(u?.deviceType){let d=ze(\"deviceType\",r),a=ze(u.deviceType,r);Be()._OrtAddSessionConfigEntry(e,d,a)!==0&&Ee(`Can't set a session config entry: 'deviceType' - ${u.deviceType}.`)}if(u?.numThreads){let d=u.numThreads;(typeof d!=\"number\"||!Number.isInteger(d)||d<0)&&(d=0);let a=ze(\"numThreads\",r),p=ze(d.toString(),r);Be()._OrtAddSessionConfigEntry(e,a,p)!==0&&Ee(`Can't set a session config entry: 'numThreads' - ${u.numThreads}.`)}if(u?.powerPreference){let d=ze(\"powerPreference\",r),a=ze(u.powerPreference,r);Be()._OrtAddSessionConfigEntry(e,d,a)!==0&&Ee(`Can't set a session config entry: 'powerPreference' - ${u.powerPreference}.`)}}break;case\"webgpu\":if(n=\"JS\",typeof o!=\"string\"){let u=o;if(u?.preferredLayout){if(u.preferredLayout!==\"NCHW\"&&u.preferredLayout!==\"NHWC\")throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${u.preferredLayout}`);let d=ze(\"preferredLayout\",r),a=ze(u.preferredLayout,r);Be()._OrtAddSessionConfigEntry(e,d,a)!==0&&Ee(`Can't set a session config entry: 'preferredLayout' - ${u.preferredLayout}.`)}}break;case\"wasm\":case\"cpu\":continue;default:throw new Error(`not supported execution provider: ${n}`)}let s=ze(n,r);Be()._OrtAppendExecutionProvider(e,s)!==0&&Ee(`Can't append execution provider: ${n}.`)}},Mo=e=>{let t=Be(),r=0,o=[],n=e||{};el(n);try{let s=Qu(n.graphOptimizationLevel??\"all\"),u=Ju(n.executionMode??\"sequential\"),d=typeof n.logId==\"string\"?ze(n.logId,o):0,a=n.logSeverityLevel??2;if(!Number.isInteger(a)||a<0||a>4)throw new Error(`log serverity level is not valid: ${a}`);let p=n.logVerbosityLevel??0;if(!Number.isInteger(p)||p<0||p>4)throw new Error(`log verbosity level is not valid: ${p}`);let h=typeof n.optimizedModelFilePath==\"string\"?ze(n.optimizedModelFilePath,o):0;if(r=t._OrtCreateSessionOptions(s,!!n.enableCpuMemArena,!!n.enableMemPattern,u,!!n.enableProfiling,0,d,a,p,h),r===0&&Ee(\"Can't create session options.\"),n.executionProviders&&tl(r,n.executionProviders,o),n.freeDimensionOverrides)for(let[g,y]of Object.entries(n.freeDimensionOverrides)){if(typeof g!=\"string\")throw new Error(`free dimension override name must be a string: ${g}`);if(typeof y!=\"number\"||!Number.isInteger(y)||y<0)throw new Error(`free dimension override value must be a non-negative integer: ${y}`);let w=ze(g,o);t._OrtAddFreeDimensionOverride(r,w,y)!==0&&Ee(`Can't set a free dimension override: ${g} - ${y}.`)}return n.extra!==void 0&&cr(n.extra,\"\",new WeakSet,(g,y)=>{let w=ze(g,o),b=ze(y,o);t._OrtAddSessionConfigEntry(r,w,b)!==0&&Ee(`Can't set a session config entry: ${g} - ${y}.`)}),[r,o]}catch(s){throw r!==0&&t._OrtReleaseSessionOptions(r),o.forEach(u=>t._free(u)),s}};De();var Mc=(e,t)=>{Be()._OrtInit(e,t)!==0&&Ee(\"Can't initialize onnxruntime.\")},vu=async e=>{Mc(e.wasm.numThreads,mr(e.logLevel))},$u=async(e,t)=>{if(t===\"webgpu\"){if(typeof navigator>\"u\"||!navigator.gpu)throw new Error(\"WebGPU is not supported in current environment\");let r=await navigator.gpu.requestAdapter();if(!r)throw new Error('Failed to get GPU adapter. You may need to enable flag \"--enable-unsafe-webgpu\" if you are using Chrome.');if(!e.wasm.simd)throw new Error(\"Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using `webgpu` EP\");let o=(bu(),Wt(yu)).init;await o(Be(),e,r)}},br=new Map,zc=e=>{let t=Be(),r=t.stackSave();try{let o=t.stackAlloc(8);return t._OrtGetInputOutputCount(e,o,o+4)!==0&&Ee(\"Can't get session input/output count.\"),[t.HEAP32[o/4],t.HEAP32[o/4+1]]}finally{t.stackRestore(r)}},eo=e=>{let t=Be(),r=t._malloc(e.byteLength);if(r===0)throw new Error(`Can't create a session. failed to allocate a buffer of size ${e.byteLength}.`);return t.HEAPU8.set(e,r),[r,e.byteLength]},Su=(e,t)=>{let r,o,n=Be();Array.isArray(e)?[r,o]=e:e.buffer===n.HEAPU8.buffer?[r,o]=[e.byteOffset,e.byteLength]:[r,o]=eo(e);let s=0,u=0,d=0,a=[],p=[],h=[];try{[u,a]=Mo(t),s=n._OrtCreateSession(r,o,u),s===0&&Ee(\"Can't create a session.\");let[g,y]=zc(s),w=[],b=[],_=[];for(let S=0;S<g;S++){let x=n._OrtGetInputName(s,S);x===0&&Ee(\"Can't get an input name.\"),p.push(x),w.push(n.UTF8ToString(x))}for(let S=0;S<y;S++){let x=n._OrtGetOutputName(s,S);x===0&&Ee(\"Can't get an output name.\"),h.push(x);let O=n.UTF8ToString(x);b.push(O);{let T=typeof t?.preferredOutputLocation==\"string\"?t.preferredOutputLocation:t?.preferredOutputLocation?.[O]??\"cpu\";if(T!==\"cpu\"&&T!==\"cpu-pinned\"&&T!==\"gpu-buffer\")throw new Error(`Not supported preferred output location: ${T}.`);_.push(T)}}let I=null;return _.some(S=>S===\"gpu-buffer\")&&(d=n._OrtCreateBinding(s),d===0&&Ee(\"Can't create IO binding.\"),I={handle:d,outputPreferredLocations:_,outputPreferredLocationsEncoded:_.map(S=>In(S))}),br.set(s,[s,p,h,I]),[s,w,b]}catch(g){throw p.forEach(y=>n._OrtFree(y)),h.forEach(y=>n._OrtFree(y)),d!==0&&n._OrtReleaseBinding(d),s!==0&&n._OrtReleaseSession(s),g}finally{n._free(r),u!==0&&n._OrtReleaseSessionOptions(u),a.forEach(g=>n._free(g))}},xu=e=>{let t=Be(),r=br.get(e);if(!r)throw new Error(`cannot release session. invalid session id: ${e}`);let[o,n,s,u]=r;u&&t._OrtReleaseBinding(u.handle),t.jsepUnregisterBuffers?.(e),n.forEach(d=>t._OrtFree(d)),s.forEach(d=>t._OrtFree(d)),t._OrtReleaseSession(o),br.delete(e)},wu=(e,t,r,o,n)=>{if(!e){t.push(0);return}let s=Be(),u=e[0],d=e[1],a=e[3],p,h;if(u===\"string\"&&a===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");if(a===\"gpu-buffer\"){let w=e[2].gpuBuffer,b=pr(Cn(u));h=d.reduce((_,I)=>_*I,1)*b,p=s.jsepRegisterBuffer(o,n,w,h)}else{let w=e[2];if(Array.isArray(w)){h=4*w.length,p=s._malloc(h),r.push(p);let b=p/4;for(let _=0;_<w.length;_++){if(typeof w[_]!=\"string\")throw new TypeError(`tensor data at index ${_} is not a string`);s.HEAPU32[b++]=ze(w[_],r)}}else h=w.byteLength,p=s._malloc(h),r.push(p),s.HEAPU8.set(new Uint8Array(w.buffer,w.byteOffset,h),p)}let g=s.stackSave(),y=s.stackAlloc(4*d.length);try{let w=y/4;d.forEach(_=>s.HEAP32[w++]=_);let b=s._OrtCreateTensor(Cn(u),p,h,y,d.length,In(a));b===0&&Ee(`Can't create tensor for input/output. session=${o}, index=${n}.`),t.push(b)}finally{s.stackRestore(g)}},_u=async(e,t,r,o,n,s)=>{let u=Be(),d=br.get(e);if(!d)throw new Error(`cannot run inference. invalid session id: ${e}`);let[a,p,h,g]=d,y=t.length,w=o.length,b=0,_=[],I=[],S=[],x=[],O=u.stackSave(),T=u.stackAlloc(y*4),M=u.stackAlloc(y*4),A=u.stackAlloc(w*4),W=u.stackAlloc(w*4);try{[b,_]=Do(s);for(let ee=0;ee<y;ee++)wu(r[ee],I,x,e,t[ee]);for(let ee=0;ee<w;ee++)wu(n[ee],S,x,e,y+o[ee]);let V=T/4,G=M/4,J=A/4,B=W/4;for(let ee=0;ee<y;ee++)u.HEAPU32[V++]=I[ee],u.HEAPU32[G++]=p[t[ee]];for(let ee=0;ee<w;ee++)u.HEAPU32[J++]=S[ee],u.HEAPU32[B++]=h[o[ee]];if(g){let{handle:ee,outputPreferredLocations:ve,outputPreferredLocationsEncoded:Z}=g;if(p.length!==y)throw new Error(`input count from feeds (${y}) is expected to be always equal to model's input count (${p.length}).`);for(let be=0;be<y;be++){let Ce=t[be];await u._OrtBindInput(ee,p[Ce],I[be])!==0&&Ee(`Can't bind input[${be}] for session=${e}.`)}for(let be=0;be<w;be++){let Ce=o[be];n[be]?.[3]?u._OrtBindOutput(ee,h[Ce],S[be],0)!==0&&Ee(`Can't bind pre-allocated output[${be}] for session=${e}.`):u._OrtBindOutput(ee,h[Ce],0,Z[Ce])!==0&&Ee(`Can't bind output[${be}] to ${ve[be]} for session=${e}.`)}}let K;g?K=await u._OrtRunWithBinding(a,g.handle,w,A,b):K=await u._OrtRun(a,M,T,y,W,w,A,b),K!==0&&Ee(\"failed to call OrtRun().\");let pe=[];for(let ee=0;ee<w;ee++){let ve=u.HEAPU32[A/4+ee];if(ve===S[ee]){pe.push(n[ee]);continue}let Z=u.stackSave(),be=u.stackAlloc(4*4),Ce=!1,fe,ce=0;try{u._OrtGetTensorData(ve,be,be+4,be+8,be+12)!==0&&Ee(`Can't access output tensor data on index ${ee}.`);let ke=be/4,He=u.HEAPU32[ke++];ce=u.HEAPU32[ke++];let L=u.HEAPU32[ke++],X=u.HEAPU32[ke++],he=[];for(let Re=0;Re<X;Re++)he.push(u.HEAPU32[L/4+Re]);u._OrtFree(L);let Fe=he.reduce((Re,Ge)=>Re*Ge,1);fe=Xe(He);let Ze=g?.outputPreferredLocations[o[ee]];if(fe===\"string\"){if(Ze===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");let Re=[],Ge=ce/4;for(let Ke=0;Ke<Fe;Ke++){let ot=u.HEAPU32[Ge++],Je=Ke===Fe-1?void 0:u.HEAPU32[Ge]-ot;Re.push(u.UTF8ToString(ot,Je))}pe.push([fe,he,Re,\"cpu\"])}else if(Ze===\"gpu-buffer\"&&Fe>0){let Re=u.jsepGetBuffer(ce),Ge=pr(He);if(Ge===void 0||!zo(fe))throw new Error(`Unsupported data type: ${fe}`);Ce=!0,pe.push([fe,he,{gpuBuffer:Re,download:u.jsepCreateDownloader(Re,Fe*Ge,fe),dispose:()=>{u._OrtReleaseTensor(ve)}},\"gpu-buffer\"])}else{let Re=Ur(fe),Ge=new Re(Fe);new Uint8Array(Ge.buffer,Ge.byteOffset,Ge.byteLength).set(u.HEAPU8.subarray(ce,ce+Ge.byteLength)),pe.push([fe,he,Ge,\"cpu\"])}}finally{u.stackRestore(Z),fe===\"string\"&&ce&&u._free(ce),Ce||u._OrtReleaseTensor(ve)}}return g&&u._OrtClearBoundOutputs(g.handle),pe}finally{u.stackRestore(O),I.forEach(V=>u._OrtReleaseTensor(V)),S.forEach(V=>u._OrtReleaseTensor(V)),x.forEach(V=>u._free(V)),b!==0&&u._OrtReleaseRunOptions(b),_.forEach(V=>u._free(V))}},Cu=e=>{let t=Be(),r=br.get(e);if(!r)throw new Error(\"invalid session id\");let o=r[0],n=t._OrtEndProfiling(o);n===0&&Ee(\"Can't get an profile file name.\"),t._OrtFree(n)},Iu=e=>{let t=[];for(let r of e){let o=r[2];!Array.isArray(o)&&\"buffer\"in o&&t.push(o.buffer)}return t};self.onmessage=e=>{let{type:t,in:r}=e.data;try{switch(t){case\"init-wasm\":Bo(r.wasm).then(()=>{vu(r).then(()=>{postMessage({type:t})},o=>{postMessage({type:t,err:o})})},o=>{postMessage({type:t,err:o})});break;case\"init-ep\":{let{epName:o,env:n}=r;$u(n,o).then(()=>{postMessage({type:t})},s=>{postMessage({type:t,err:s})});break}case\"copy-from\":{let{buffer:o}=r,n=eo(o);postMessage({type:t,out:n});break}case\"create\":{let{model:o,options:n}=r,s=Su(o,n);postMessage({type:t,out:s});break}case\"release\":xu(r),postMessage({type:t});break;case\"run\":{let{sessionId:o,inputIndices:n,inputs:s,outputIndices:u,options:d}=r;_u(o,n,s,u,new Array(u.length).fill(null),d).then(a=>{a.some(p=>p[3]!==\"cpu\")?postMessage({type:t,err:\"Proxy does not support non-cpu tensor location.\"}):postMessage({type:t,out:a},Iu(a))},a=>{postMessage({type:t,err:a})});break}case\"end-profiling\":Cu(r),postMessage({type:t});break;default:}}catch(o){postMessage({type:t,err:o})}};})();\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env, InferenceSession} from 'onnxruntime-common';\n\nimport {OrtWasmMessage, SerializableInternalBuffer, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport * as core from './wasm-core-impl';\nimport {initializeWebAssembly} from './wasm-factory';\n\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\nlet proxyWorker: Worker|undefined;\nlet initializing = false;\nlet initialized = false;\nlet aborted = false;\n\ntype PromiseCallbacks<T = void> = [resolve: (result: T) => void, reject: (reason: unknown) => void];\nlet initWasmCallbacks: PromiseCallbacks;\nconst queuedCallbacks: Map<OrtWasmMessage['type'], Array<PromiseCallbacks<unknown>>> = new Map();\n\nconst enqueueCallbacks = (type: OrtWasmMessage['type'], callbacks: PromiseCallbacks<unknown>): void => {\n  const queue = queuedCallbacks.get(type);\n  if (queue) {\n    queue.push(callbacks);\n  } else {\n    queuedCallbacks.set(type, [callbacks]);\n  }\n};\n\nconst ensureWorker = (): void => {\n  if (initializing || !initialized || aborted || !proxyWorker) {\n    throw new Error('worker not ready');\n  }\n};\n\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\n  switch (ev.data.type) {\n    case 'init-wasm':\n      initializing = false;\n      if (ev.data.err) {\n        aborted = true;\n        initWasmCallbacks[1](ev.data.err);\n      } else {\n        initialized = true;\n        initWasmCallbacks[0]();\n      }\n      break;\n    case 'init-ep':\n    case 'copy-from':\n    case 'create':\n    case 'release':\n    case 'run':\n    case 'end-profiling': {\n      const callbacks = queuedCallbacks.get(ev.data.type)!;\n      if (ev.data.err) {\n        callbacks.shift()![1](ev.data.err);\n      } else {\n        callbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    }\n    default:\n  }\n};\n\nconst scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src : undefined;\n\nexport const initializeWebAssemblyAndOrtRuntime = async(): Promise<void> => {\n  if (initialized) {\n    return;\n  }\n  if (initializing) {\n    throw new Error('multiple calls to \\'initWasm()\\' detected.');\n  }\n  if (aborted) {\n    throw new Error('previous call to \\'initWasm()\\' failed.');\n  }\n\n  initializing = true;\n\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // overwrite wasm filepaths\n    if (env.wasm.wasmPaths === undefined) {\n      if (scriptSrc && scriptSrc.indexOf('blob:') !== 0) {\n        env.wasm.wasmPaths = scriptSrc.substr(0, +(scriptSrc).lastIndexOf('/') + 1);\n      }\n    }\n\n    return new Promise<void>((resolve, reject) => {\n      proxyWorker?.terminate();\n\n      const workerUrl = URL.createObjectURL(new Blob(\n          [\n            // This require() function is handled by esbuild plugin to load file content as string.\n            // eslint-disable-next-line @typescript-eslint/no-require-imports\n            require('./proxy-worker/main')\n          ],\n          {type: 'text/javascript'}));\n      proxyWorker = new Worker(workerUrl, {name: 'ort-wasm-proxy-worker'});\n      proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\n      proxyWorker.onmessage = onProxyWorkerMessage;\n      URL.revokeObjectURL(workerUrl);\n      initWasmCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-wasm', in : env};\n      proxyWorker.postMessage(message);\n    });\n\n  } else {\n    try {\n      await initializeWebAssembly(env.wasm);\n      await core.initRuntime(env);\n      initialized = true;\n    } catch (e) {\n      aborted = true;\n      throw e;\n    } finally {\n      initializing = false;\n    }\n  }\n};\n\nexport const initializeOrtEp = async(epName: string): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      enqueueCallbacks('init-ep', [resolve, reject]);\n      const message: OrtWasmMessage = {type: 'init-ep', in : {epName, env}};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    await core.initEp(env, epName);\n  }\n};\n\nexport const copyFromExternalBuffer = async(buffer: Uint8Array): Promise<SerializableInternalBuffer> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<SerializableInternalBuffer>((resolve, reject) => {\n      enqueueCallbacks('copy-from', [resolve, reject]);\n      const message: OrtWasmMessage = {type: 'copy-from', in : {buffer}};\n      proxyWorker!.postMessage(message, [buffer.buffer]);\n    });\n  } else {\n    return core.copyFromExternalBuffer(buffer);\n  }\n};\n\nexport const createSession =\n    async(model: SerializableInternalBuffer|Uint8Array, options?: InferenceSession.SessionOptions):\n        Promise<SerializableSessionMetadata> => {\n          if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n            // check unsupported options\n            if (options?.preferredOutputLocation) {\n              throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\n            }\n            ensureWorker();\n            return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n              enqueueCallbacks('create', [resolve, reject]);\n              const message: OrtWasmMessage = {type: 'create', in : {model, options}};\n              const transferable: Transferable[] = [];\n              if (model instanceof Uint8Array) {\n                transferable.push(model.buffer);\n              }\n              proxyWorker!.postMessage(message, transferable);\n            });\n          } else {\n            return core.createSession(model, options);\n          }\n        };\n\nexport const releaseSession = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      enqueueCallbacks('release', [resolve, reject]);\n      const message: OrtWasmMessage = {type: 'release', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.releaseSession(sessionId);\n  }\n};\n\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputs: TensorMetadata[], outputIndices: number[],\n    outputs: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check inputs location\n    if (inputs.some(t => t[3] !== 'cpu')) {\n      throw new Error('input tensor on GPU is not supported for proxy.');\n    }\n    // check outputs location\n    if (outputs.some(t => t)) {\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\n      enqueueCallbacks('run', [resolve, reject]);\n      const serializableInputs = inputs as SerializableTensorMetadata[];  // every input is on CPU.\n      const message: OrtWasmMessage =\n          {type: 'run', in : {sessionId, inputIndices, inputs: serializableInputs, outputIndices, options}};\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\n    });\n  } else {\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\n  }\n};\n\nexport const endProfiling = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      enqueueCallbacks('end-profiling', [resolve, reject]);\n      const message: OrtWasmMessage = {type: 'end-profiling', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.endProfiling(sessionId);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {readFile} from 'node:fs/promises';\nimport {InferenceSession, InferenceSessionHandler, SessionHandler, Tensor, TRACE_FUNC_BEGIN, TRACE_FUNC_END} from 'onnxruntime-common';\n\nimport {SerializableInternalBuffer, TensorMetadata} from './proxy-messages';\nimport {copyFromExternalBuffer, createSession, endProfiling, releaseSession, run} from './proxy-wrapper';\nimport {isGpuBufferSupportedType} from './wasm-common';\n\nexport const encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\n  switch (tensor.location) {\n    case 'cpu':\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\n    case 'gpu-buffer':\n      return [tensor.type, tensor.dims, {gpuBuffer: tensor.gpuBuffer}, 'gpu-buffer'];\n    default:\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\n  }\n};\n\nexport const decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\n  switch (tensor[3]) {\n    case 'cpu':\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\n    case 'gpu-buffer': {\n      const dataType = tensor[0];\n      if (!isGpuBufferSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\n      }\n      const {gpuBuffer, download, dispose} = tensor[2];\n      return Tensor.fromGpuBuffer(gpuBuffer, {dataType, dims: tensor[1], download, dispose});\n    }\n    default:\n      throw new Error(`invalid data location: ${tensor[3]}`);\n  }\n};\n\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\n  private sessionId: number;\n\n  inputNames: string[];\n  outputNames: string[];\n\n  async fetchModelAndCopyToWasmMemory(path: string): Promise<SerializableInternalBuffer> {\n    // fetch model from url and move to wasm heap. The arraybufffer that held the http\n    // response is freed once we return\n    const response = await fetch(path);\n    if (response.status !== 200) {\n      throw new Error(`failed to load model: ${path}`);\n    }\n    const arrayBuffer = await response.arrayBuffer();\n    return copyFromExternalBuffer(new Uint8Array(arrayBuffer));\n  }\n\n  async loadModel(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\n    TRACE_FUNC_BEGIN();\n    let model: Parameters<typeof createSession>[0];\n\n    if (typeof pathOrBuffer === 'string') {\n      if (typeof process !== 'undefined' && process.versions && process.versions.node) {\n        // node\n        model = await readFile(pathOrBuffer);\n      } else {\n        // browser\n        // fetch model and copy to wasm heap.\n        model = await this.fetchModelAndCopyToWasmMemory(pathOrBuffer);\n      }\n    } else {\n      model = pathOrBuffer;\n    }\n\n    [this.sessionId, this.inputNames, this.outputNames] = await createSession(model, options);\n    TRACE_FUNC_END();\n  }\n\n  async dispose(): Promise<void> {\n    return releaseSession(this.sessionId);\n  }\n\n  async run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType, options: InferenceSession.RunOptions):\n      Promise<SessionHandler.ReturnType> {\n    TRACE_FUNC_BEGIN();\n    const inputArray: Tensor[] = [];\n    const inputIndices: number[] = [];\n    Object.entries(feeds).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.inputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid input '${name}'`);\n      }\n      inputArray.push(tensor);\n      inputIndices.push(index);\n    });\n\n    const outputArray: Array<Tensor|null> = [];\n    const outputIndices: number[] = [];\n    Object.entries(fetches).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.outputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid output '${name}'`);\n      }\n      outputArray.push(tensor);\n      outputIndices.push(index);\n    });\n\n    const inputs =\n        inputArray.map((t, i) => encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`));\n    const outputs = outputArray.map(\n        (t, i) => t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null);\n\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\n\n    const resultMap: SessionHandler.ReturnType = {};\n    for (let i = 0; i < results.length; i++) {\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\n    }\n    TRACE_FUNC_END();\n    return resultMap;\n  }\n\n  startProfiling(): void {\n    // TODO: implement profiling\n  }\n\n  endProfiling(): void {\n    void endProfiling(this.sessionId);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {cpus} from 'node:os';\nimport {Backend, env, InferenceSession, InferenceSessionHandler} from 'onnxruntime-common';\n\nimport {initializeOrtEp, initializeWebAssemblyAndOrtRuntime} from './wasm/proxy-wrapper';\nimport {OnnxruntimeWebAssemblySessionHandler} from './wasm/session-handler-inference';\n\n/**\n * This function initializes all flags for WebAssembly.\n *\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\n * being created, to override default value.\n */\nexport const initializeFlags = (): void => {\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\n    env.wasm.initTimeout = 0;\n  }\n\n  if (typeof env.wasm.simd !== 'boolean') {\n    env.wasm.simd = true;\n  }\n\n  if (typeof env.wasm.proxy !== 'boolean') {\n    env.wasm.proxy = false;\n  }\n\n  if (typeof env.wasm.trace !== 'boolean') {\n    env.wasm.trace = false;\n  }\n\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\n    const numCpuLogicalCores = typeof navigator === 'undefined' ? cpus().length : navigator.hardwareConcurrency;\n    env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\n  }\n};\n\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\n  /**\n   * This function initializes the WebAssembly backend.\n   *\n   * This function will be called only once for each backend name. It will be called the first time when\n   * `ort.InferenceSession.create()` is called with a registered backend name.\n   *\n   * @param backendName - the registered backend name.\n   */\n  async init(backendName: string): Promise<void> {\n    // populate wasm flags\n    initializeFlags();\n\n    // init wasm\n    await initializeWebAssemblyAndOrtRuntime();\n\n    // performe EP specific initialization\n    await initializeOrtEp(backendName);\n  }\n  createInferenceSessionHandler(path: string, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  createInferenceSessionHandler(buffer: Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  async createInferenceSessionHandler(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler> {\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\n    await handler.loadModel(pathOrBuffer, options);\n    return Promise.resolve(handler);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OnnxruntimeWebAssemblyBackend} from './backend-wasm';\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\n// So we import code inside the if-clause to allow bundler remove the code safely.\n\nexport * from 'onnxruntime-common';\nimport * as ort from 'onnxruntime-common';\nexport default ort;\n\nimport {registerBackend, env} from 'onnxruntime-common';\nimport {version} from './version';\n\nif (!BUILD_DEFS.DISABLE_WEBGL) {\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\n  registerBackend('webgl', onnxjsBackend, -10);\n}\n\nif (!BUILD_DEFS.DISABLE_WASM) {\n  const wasmBackend = BUILD_DEFS.DISABLE_TRAINING ? require('./backend-wasm-inference').wasmBackend :\n                                                    require('./backend-wasm-training').wasmBackend;\n  if (!BUILD_DEFS.DISABLE_WEBGPU) {\n    registerBackend('webgpu', wasmBackend, 5);\n  }\n  registerBackend('cpu', wasmBackend, 10);\n  registerBackend('wasm', wasmBackend, 10);\n  if (BUILD_DEFS.DISABLE_TRAINING) {\n    registerBackend('xnnpack', wasmBackend, 9);\n    if (!BUILD_DEFS.DISABLE_WEBNN) {\n      registerBackend('webnn', wasmBackend, 9);\n    }\n  }\n}\n\nObject.defineProperty(env.versions, 'web', {value: version, enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n"],
  "mappings": ";;;;;wgBAAA,IAcMA,GACAC,GAYOC,GA0CAC,GArEbC,GAAAC,EAAA,kBAcML,GAAqC,IAAI,IACzCC,GAAqC,CAAA,EAY9BC,GAAkB,CAACI,EAAcC,EAAkBC,IAA0B,CACxF,GAAID,GAAW,OAAOA,EAAQ,MAAS,YAAc,OAAOA,EAAQ,+BAAkC,WAAY,CAChH,IAAME,EAAiBT,GAAS,IAAIM,CAAI,EACxC,GAAIG,IAAmB,OACrBT,GAAS,IAAIM,EAAM,CAAC,QAAAC,EAAS,SAAAC,CAAQ,CAAC,MACjC,IAAIC,EAAe,SAAWD,EAEnC,OACK,GAAIC,EAAe,WAAaD,GACjCC,EAAe,UAAYF,EAC7B,MAAM,IAAI,MAAM,4BAA4BD,CAAI,oBAAoBE,CAAQ,EAAE,EAIlF,GAAIA,GAAY,EAAG,CACjB,IAAME,EAAIT,GAAyB,QAAQK,CAAI,EAC3CI,IAAM,IACRT,GAAyB,OAAOS,EAAG,CAAC,EAGtC,QAASA,EAAI,EAAGA,EAAIT,GAAyB,OAAQS,IACnD,GAAIV,GAAS,IAAIC,GAAyBS,CAAC,CAAC,EAAG,UAAYF,EAAU,CACnEP,GAAyB,OAAOS,EAAG,EAAGJ,CAAI,EAC1C,OAGJL,GAAyB,KAAKK,CAAI,EAEpC,OAGF,MAAM,IAAI,UAAU,qBAAqB,CAC3C,EAUaH,GAAiB,MAAMQ,GAAqD,CACvF,IAAMC,EAAeD,EAAa,SAAW,EAAIV,GAA2BU,EACtEE,EAAS,CAAA,EACf,QAAWC,KAAeF,EAAc,CACtC,IAAMG,EAAcf,GAAS,IAAIc,CAAW,EAC5C,GAAIC,EAAa,CACf,GAAIA,EAAY,YACd,OAAOA,EAAY,QACd,GAAIA,EAAY,QACrB,SAGF,IAAMC,EAAiB,CAAC,CAACD,EAAY,YACrC,GAAI,CACF,OAAKC,IACHD,EAAY,YAAcA,EAAY,QAAQ,KAAKD,CAAW,GAEhE,MAAMC,EAAY,YAClBA,EAAY,YAAc,GACnBA,EAAY,cACZE,EAAG,CACLD,GACHH,EAAO,KAAK,CAAC,KAAMC,EAAa,IAAKG,CAAC,CAAC,EAEzCF,EAAY,QAAU,WAEtB,OAAOA,EAAY,cAKzB,MAAM,IAAI,MAAM,oCAAoCF,EAAO,IAAII,GAAK,IAAIA,EAAE,IAAI,KAAKA,EAAE,GAAG,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE,CAC1G,ICrGA,IAAAC,GAAAC,EAAA,kBAoFAC,OCpFA,IAMaC,GANbC,GAAAC,EAAA,kBAMaF,GAAU,WCNvB,IAQIG,GAESC,GAVbC,GAAAC,EAAA,kBAIAC,KAIIJ,GAAwC,UAE/BC,GAAW,CACtB,KAAM,CAAA,EACN,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,SAAU,CAAC,OAAQI,EAAO,EAE1B,IAAI,SAASC,EAAmB,CAC9B,GAAIA,IAAU,OAGd,IAAI,OAAOA,GAAU,UAAY,CAAC,UAAW,OAAQ,UAAW,QAAS,OAAO,EAAE,QAAQA,CAAK,IAAM,GACnG,MAAM,IAAI,MAAM,8BAA8BA,CAAK,EAAE,EAEvDN,GAAgBM,EAClB,EACA,IAAI,UAAQ,CACV,OAAON,EACT,GAIF,OAAO,eAAeC,GAAK,WAAY,CAAC,WAAY,EAAI,CAAC,IC/BzD,IA+MaM,GA/MbC,GAAAC,EAAA,kBAGAC,KA4MaH,GAAWA,KC/MxB,IASaI,GA0FAC,GAnGbC,GAAAC,EAAA,kBASaH,GAAkB,CAACI,EAAgBC,IAA4C,CAC1F,IAAMC,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQF,EAAO,KAAK,CAAC,EAC5BE,EAAO,OAASF,EAAO,KAAK,CAAC,EAC7B,IAAMG,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAJ,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,IAEtBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,GAGxB,IAAMM,EAAcL,GAAS,SAAW,OAAYA,EAAQ,OAAS,MAE/DM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EAEpBO,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5B,QAASK,EAAI,EAAGA,EAAIV,EAAQU,IAC1B,QAASC,EAAI,EAAGA,EAAIZ,EAAOY,IAAK,CAC9B,IAAMC,GAAMjB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EU,GAAMlB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EW,GAAMnB,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EY,EAAIN,IAAmB,GACzB,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,EAE1EL,EAAgB,UAAY,QAAUc,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxEjB,EAAgB,SAASa,EAAGD,EAAG,EAAG,CAAC,EAGvC,OAAOb,EAAO,UAAS,MAEvB,OAAM,IAAI,MAAM,2BAA2B,CAE/C,EAKaL,GAAoB,CAACG,EAAgBC,IAAiD,CACjG,IAAME,EAAkB,SAAS,cAAc,QAAQ,EAAE,WAAW,IAAI,EACpEkB,EACJ,GAAIlB,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAiB,EACArB,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBsB,EAAWtB,EAAO,KAAK,CAAC,IAExBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBsB,EAAWtB,EAAO,KAAK,CAAC,GAE1B,IAAMM,EAAcL,IAAY,QAAaA,EAAQ,SAAW,OAAYA,EAAQ,OAAkB,MAEhGM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,GAAG,EACrDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EACxB,GAAIH,IAAY,SACVA,EAAQ,SAAW,QAAcqB,IAAa,GAAKrB,EAAQ,SAAW,QACrEqB,IAAa,GAAMrB,EAAQ,SAAW,OAASA,EAAQ,SAAW,OACrE,MAAM,IAAI,MAAM,+CAAgD,EAKpE,IAAMsB,EAAO,EACTC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACzEhB,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5BW,EAAQlB,EAAgB,gBAAgBC,EAAOC,CAAM,EAErD,QAASU,EAAI,EAAGA,EAAIV,EAASD,EACxBoB,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAMR,IAC/FM,EAAM,KAAKG,CAAa,GAAMxB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKI,CAAa,GAAMzB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKK,CAAa,GAAM1B,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKM,CAAa,EAAIb,IAAmB,GAC3C,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,MAI5E,OAAM,IAAI,MAAM,2BAA2B,EAE7C,OAAOa,CACT,IC/LA,IAiBaO,GAkFAC,GA8IAC,GAWAC,GASAC,GArQbC,GAAAC,EAAA,kBAIAC,KAaaP,GAAiB,CAACQ,EAAqCC,IAA0C,CAC5G,GAAID,IAAW,OACb,MAAM,IAAI,MAAM,8BAA8B,EAEhD,GAAIC,EAAQ,SAAW,QAAaA,EAAQ,QAAU,OACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAM,CAAC,OAAAC,EAAQ,MAAAC,CAAK,EAAIF,EAElBG,EAAOH,EAAQ,MAAQ,CAAC,KAAM,IAAK,KAAM,CAAC,EAC5CI,EACAC,EAEA,OAAQF,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDC,EAAW,CAACD,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,GAAG,EAG3E,OAAQA,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDE,EAAW,CAACF,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,CAAC,EAG7E,IAAMG,EAAcN,EAAQ,SAAW,OAAYA,EAAQ,OAAS,OAG9DO,EACFP,EAAQ,eAAiB,QAAaA,EAAQ,eAAiB,OAAYA,EAAQ,aAAwB,MACzGQ,EAASP,EAASC,EAClBO,EAAcF,IAAiB,OAAS,IAAI,aAAaC,EAAS,CAAC,EAAI,IAAI,aAAaA,EAAS,CAAC,EAGpGE,EAAO,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACnFC,EAAiB,EAAGC,EAAiBR,EAAQS,EAAiBT,EAAS,EAAGU,EAAiB,GAG3FZ,IAAgB,QAClBI,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,IAIdP,IAAiB,OACnBW,EAAiBV,EAAS,EACjBD,IAAiB,OAC1BQ,EAAiB,EACjBE,EAAiBT,EACjBQ,EAAiBR,EAAS,GACjBD,IAAiB,QAC1BU,EAAiB,EACjBD,EAAiBR,EACjBO,EAAiBP,EAAS,GAG5B,QAASW,EAAI,EAAGA,EAAIX,EACfW,IAAKR,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAC9FD,EAAYM,GAAgB,GAAKhB,EAAOY,CAAa,EAAIN,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYO,GAAgB,GAAKjB,EAAOa,CAAa,EAAIP,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYQ,GAAgB,GAAKlB,EAAOc,CAAa,EAAIR,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC9Ec,IAAmB,IAAMJ,IAAkB,KAC7CL,EAAYS,GAAgB,GAAKnB,EAAOe,CAAa,EAAIT,EAAS,CAAC,GAAKD,EAAS,CAAC,GAOtF,OAFqBG,IAAiB,OAAS,IAAIa,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,EACxD,IAAIkB,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,CAEzG,EAKaV,GAAkB,MAC3B6B,EACArB,IACyC,CAE3C,IAAMsB,EAAiB,OAAQ,iBAAsB,KAAeD,aAAiB,iBAC/EE,EAAiB,OAAQ,UAAe,KAAeF,aAAiB,UACxEG,EAAgB,OAAQ,YAAiB,KAAeH,aAAiB,YACzEI,EAAW,OAAOJ,GAAU,SAE9BK,EACAC,EAA+C3B,GAAW,CAAA,EAG9D,GAAIsB,EAAgB,CAElB,IAAMM,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAI5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MAMlB,GALIrB,IAAY,QAAaA,EAAQ,gBAAkB,QAAaA,EAAQ,eAAiB,SAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,cAGdA,IAAY,OAAW,CAEzB,GADA2B,EAAwB3B,EACpBA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,6DAA6D,EAE7E2B,EAAsB,aAAe,OAEvCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,OAE9ByB,EAAsB,aAAe,OACrCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAGhC2B,EAAgB,UAAUR,EAAO,EAAG,CAAC,EACrCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,UAEpCsB,EAAgB,CACzB,IAAItB,EACAC,EAiBJ,GAfIF,IAAY,QAAaA,EAAQ,eAAiB,QAAaA,EAAQ,gBAAkB,QAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,eAEhBC,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,OAGZrB,IAAY,SACd2B,EAAwB3B,GAE1B2B,EAAsB,OAAS,OAC/BA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAE1BF,IAAY,OAAW,CACzB,IAAM8B,EAAa,SAAS,cAAc,QAAQ,EAElDA,EAAW,MAAQ5B,EACnB4B,EAAW,OAAS7B,EAEpB,IAAM4B,EAAkBC,EAAW,WAAW,IAAI,EAElD,GAAID,GAAmB,KACrBA,EAAgB,aAAaR,EAAO,EAAG,CAAC,EACxCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,OAG7CyB,EAAOL,EAAM,aAENG,EAAe,CAExB,GAAIxB,IAAY,OACd,MAAM,IAAI,MAAM,yDAAyD,EAG3E,IAAM4B,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAM5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MACpB,OAAAQ,EAAgB,UAAUR,EAAO,EAAG,EAAGnB,EAAOD,CAAM,EACpDyB,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,KACzD0B,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EACvBX,GAAemC,EAAMC,CAAqB,MAEjD,OAAM,IAAI,MAAM,2BAA2B,MAExC,IAAIF,EACT,OAAO,IAAI,QAAQ,CAACM,EAASC,IAAU,CACrC,IAAMJ,EAAS,SAAS,cAAc,QAAQ,EACxCK,EAAUL,EAAO,WAAW,IAAI,EACtC,GAAI,CAACP,GAAS,CAACY,EACb,OAAOD,EAAM,EAEf,IAAME,EAAW,IAAI,MACrBA,EAAS,YAAc,YACvBA,EAAS,IAAMb,EACfa,EAAS,OAAS,IAAK,CACrBN,EAAO,MAAQM,EAAS,MACxBN,EAAO,OAASM,EAAS,OACzBD,EAAQ,UAAUC,EAAU,EAAG,EAAGN,EAAO,MAAOA,EAAO,MAAM,EAC7D,IAAMO,EAAMF,EAAQ,aAAa,EAAG,EAAGL,EAAO,MAAOA,EAAO,MAAM,EAElED,EAAsB,OAASC,EAAO,OACtCD,EAAsB,MAAQC,EAAO,MACrCG,EAAQxC,GAAe4C,EAAI,KAAMR,CAAqB,CAAC,CACzD,CACF,CAAC,EAED,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAID,IAAS,OACX,OAAOnC,GAAemC,EAAMC,CAAqB,EAEjD,MAAM,IAAI,MAAM,gEAAgE,CAEpF,EAKalC,GAAoB,CAC7B2C,EAAsCpC,IAAgD,CACxF,GAAM,CAAC,MAAAE,EAAO,OAAAD,EAAQ,SAAAoC,EAAU,QAAAC,CAAO,EAAItC,EAErCuC,EAAO,CAAC,EAAGtC,EAAQC,EAAO,CAAC,EACjC,OAAO,IAAIkB,GAAO,CAAC,SAAU,UAAW,KAAM,UAAW,QAAAgB,EAAS,KAAAG,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC5F,EAKa5C,GAAsB,CAC/B8C,EAA0CxC,IAAkD,CAC9F,GAAM,CAAC,SAAAyC,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAItC,EAC5C,OAAO,IAAIoB,GAAO,CAAC,SAAU,aAAc,KAAMqB,GAAY,UAAW,UAAAD,EAAW,KAAAD,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC7G,EAKa3C,GAAyB,CAClC+C,EAAS3C,EAAwCwC,IACjD,IAAInB,GAAO,CAAC,SAAU,aAAc,KAAAsB,EAAM,KAAM3C,EAAQ,KAAMwC,GAAQ,CAACxC,EAAO,MAAM,CAAC,CAAC,ICvQ1F,IAWa4C,GAcAC,GAcTC,GACSC,GAxCbC,GAAAC,EAAA,kBAWaL,GAAwC,IAAI,IAA6C,CACpG,CAAC,UAAW,YAAY,EACxB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,SAAS,EAClB,CAAC,SAAU,WAAW,EACtB,CAAC,UAAW,WAAW,EACvB,CAAC,QAAS,UAAU,EACpB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,UAAU,EACnB,CAAC,UAAW,YAAY,EACxB,CAAC,SAAU,WAAW,EACvB,EAGYC,GAAwC,IAAI,IAAkD,CACzG,CAAC,aAAc,SAAS,EACxB,CAAC,WAAY,OAAO,EACpB,CAAC,UAAW,MAAM,EAClB,CAAC,YAAa,QAAQ,EACtB,CAAC,WAAY,OAAO,EACpB,CAAC,WAAY,OAAO,EACpB,CAAC,aAAc,SAAS,EACxB,CAAC,YAAa,QAAQ,EACvB,EAKGC,GAAkB,GACTC,GAAc,IAAK,CAC9B,GAAI,CAACD,GAAiB,CACpBA,GAAkB,GAClB,IAAMI,EAA2B,OAAO,cAAkB,KAAe,OAAO,cAAc,MAAS,WACjGC,EACF,OAAO,eAAmB,KAAe,OAAO,eAAe,MAAS,WAExED,IACFN,GAAsC,IAAI,QAAS,aAAa,EAChEC,GAAsC,IAAI,cAAe,OAAO,GAE9DM,IACFP,GAAsC,IAAI,SAAU,cAAc,EAClEC,GAAsC,IAAI,eAAgB,QAAQ,GAGxE,ICxDA,IAWaO,GAkBAC,GA7BbC,GAAAC,EAAA,kBAIAC,KAOaJ,GAAiBK,GAAoC,CAChE,IAAIC,EAAO,EACX,QAASC,EAAI,EAAGA,EAAIF,EAAK,OAAQE,IAAK,CACpC,IAAMC,EAAMH,EAAKE,CAAC,EAClB,GAAI,OAAOC,GAAQ,UAAY,CAAC,OAAO,cAAcA,CAAG,EACtD,MAAM,IAAI,UAAU,QAAQD,CAAC,8BAA8BC,CAAG,EAAE,EAElE,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,QAAQD,CAAC,0CAA0CC,CAAG,EAAE,EAE/EF,GAAQE,EAEV,OAAOF,CACT,EAKaL,GAAgB,CAACQ,EAAgBJ,IAAmC,CAC/E,OAAQI,EAAO,SAAU,CACvB,IAAK,MACH,OAAO,IAAIC,GAAOD,EAAO,KAAMA,EAAO,KAAMJ,CAAI,EAClD,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,KAAMD,EAAO,KACb,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,UACH,OAAO,IAAIK,GAAO,CAChB,SAAU,UACV,QAASD,EAAO,QAChB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,UAAWD,EAAO,UAClB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,QACE,MAAM,IAAI,MAAM,kCAAkCI,EAAO,QAAQ,mBAAmB,EAE1F,ICzDA,IAwBaE,GAxBbC,GAAAC,EAAA,kBAGAC,KAEAC,KAEAC,KACAC,KAgBaN,GAAP,KAAa,CAyCjB,YACIO,EAEAC,EAA8EC,EAAwB,CAExGC,GAAW,EAEX,IAAIC,EACAC,EAEJ,GAAI,OAAOL,GAAS,UAAY,aAAcA,EAO5C,OAHA,KAAK,aAAeA,EAAK,SACzBI,EAAOJ,EAAK,KACZK,EAAOL,EAAK,KACJA,EAAK,SAAU,CACrB,IAAK,aAAc,CACjB,IAAMM,EAAgCC,GAAsC,IAAIH,CAAI,EACpF,GAAI,CAACE,EACH,MAAM,IAAI,UAAU,qBAAqBF,CAAI,uCAAuC,EAEtF,GAAI,EAAEJ,EAAK,gBAAgBM,GACzB,MAAM,IAAI,UAAU,4BAA4BA,EAA8B,IAAI,EAAE,EAEtF,KAAK,QAAUN,EAAK,KACpB,MAEF,IAAK,UAAW,CACd,GAAII,IAAS,UACX,MAAM,IAAI,UAAU,qBAAqBA,CAAI,iCAAiC,EAEhF,KAAK,eAAiBJ,EAAK,QAC3B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,aAAc,CACjB,GAAKI,IAAS,WAAaA,IAAS,WAAaA,IAAS,SAAWA,IAAS,SAAWA,IAAS,UAC7FA,IAAS,OACZ,MAAM,IAAI,UAAU,qBAAqBA,CAAI,oCAAoC,EAEnF,KAAK,cAAgBJ,EAAK,UAC1B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,QACE,MAAM,IAAI,MAAM,6CAA6C,KAAK,YAAY,GAAG,MAEhF,CAIL,IAAIQ,EACAC,EAEJ,GAAI,OAAOT,GAAS,SAMlB,GAFAI,EAAOJ,EACPS,EAAYP,EACRF,IAAS,SAAU,CAErB,GAAI,CAAC,MAAM,QAAQC,CAAI,EACrB,MAAM,IAAI,UAAU,gDAAiD,EAIvEO,EAAOP,MACF,CAEL,IAAMS,EAAwBH,GAAsC,IAAIP,CAAI,EAC5E,GAAIU,IAA0B,OAC5B,MAAM,IAAI,UAAU,4BAA4BV,CAAI,GAAG,EAEzD,GAAI,MAAM,QAAQC,CAAI,EAAG,CACvB,GAAID,IAAS,UAIX,MAAM,IAAI,UACN,+FAA+F,EAC1FA,IAAS,UAAYA,IAAS,QAYvCQ,EAAQE,EAA8B,KAAKT,EAAM,MAAM,EAIvDO,EAAQE,EAA8B,KAAKT,CAAI,UAExCA,aAAgBS,EACzBF,EAAOP,MAEP,OAAM,IAAI,UAAU,KAAKG,CAAI,kCAAkCM,CAAqB,EAAE,UAO1FD,EAAYR,EACR,MAAM,QAAQD,CAAI,EAAG,CAEvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qDAAqD,EAE3E,IAAMW,EAAmB,OAAOX,EAAK,CAAC,EACtC,GAAIW,IAAqB,SACvBP,EAAO,SACPI,EAAOR,UACEW,IAAqB,UAC9BP,EAAO,OAIPI,EAAO,WAAW,KAAKR,CAAa,MAEpC,OAAM,IAAI,UAAU,uCAAuCW,CAAgB,GAAG,MAE3E,CAEL,IAAMC,EACFC,GAAsC,IAAIb,EAAK,WAA8C,EACjG,GAAIY,IAAe,OACjB,MAAM,IAAI,UAAU,qCAAqCZ,EAAK,WAAW,GAAG,EAE9EI,EAAOQ,EACPJ,EAAOR,EAKX,GAAIS,IAAc,OAEhBA,EAAY,CAACD,EAAK,MAAM,UACf,CAAC,MAAM,QAAQC,CAAS,EACjC,MAAM,IAAI,UAAU,wCAAyC,EAE/DJ,EAAOI,EAEP,KAAK,QAAUD,EACf,KAAK,aAAe,MAItB,IAAMM,EAAOC,GAAcV,CAAI,EAE/B,GAAI,KAAK,SAAWS,IAAS,KAAK,QAAQ,OACxC,MAAM,IAAI,MAAM,iBAAiBA,CAAI,gCAAgC,KAAK,QAAQ,MAAM,IAAI,EAG9F,KAAK,KAAOV,EACZ,KAAK,KAAOC,EACZ,KAAK,KAAOS,CACd,CAIA,aAAa,UACTE,EACAC,EACoB,CACtB,OAAOC,GAAgBF,EAAOC,CAAO,CACvC,CAEA,OAAO,YACHE,EAA4BF,EAAoC,CAClE,OAAOG,GAAkBD,EAASF,CAAO,CAC3C,CAEA,OAAO,cACHI,EAAgCJ,EAAsC,CACxE,OAAOK,GAAoBD,EAAWJ,CAAO,CAC/C,CAEA,OAAO,iBACHb,EAASmB,EAAwClB,EAAwB,CAC3E,OAAOmB,GAAuBpB,EAAMmB,EAAQlB,CAAI,CAClD,CAKA,UAAUY,EAAgC,CACxC,OAAOQ,GAAgB,KAAMR,CAAO,CACtC,CAEA,YAAYA,EAAkC,CAC5C,OAAOS,GAAkB,KAAMT,CAAO,CACxC,CAgDA,IAAI,MAAI,CAEN,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,QACR,MAAM,IAAI,MACN,gJAC2E,EAEjF,OAAO,KAAK,OACd,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,YACd,CAEA,IAAI,SAAO,CAET,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,eACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,cACd,CAEA,IAAI,WAAS,CAEX,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,cACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,aACd,CAKA,MAAM,QAAQU,EAAqB,CAEjC,OADA,KAAK,YAAW,EACR,KAAK,aAAc,CACzB,IAAK,MACL,IAAK,aACH,OAAO,KAAK,KACd,IAAK,UACL,IAAK,aAAc,CACjB,GAAI,CAAC,KAAK,WACR,MAAM,IAAI,MAAM,qEAAqE,EAEvF,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI,CACF,KAAK,cAAgB,GACrB,IAAMnB,EAAO,MAAM,KAAK,WAAU,EAClC,YAAK,WAAa,OAClB,KAAK,aAAe,MACpB,KAAK,QAAUA,EAEXmB,GAAe,KAAK,WACtB,KAAK,SAAQ,EACb,KAAK,SAAW,QAGXnB,UAGP,KAAK,cAAgB,IAGzB,QACE,MAAM,IAAI,MAAM,kCAAkC,KAAK,YAAY,EAAE,EAE3E,CAEA,SAAO,CACL,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAGvD,KAAK,WACP,KAAK,SAAQ,EACb,KAAK,SAAW,QAElB,KAAK,QAAU,OACf,KAAK,eAAiB,OACtB,KAAK,cAAgB,OACrB,KAAK,WAAa,OAClB,KAAK,cAAgB,OAErB,KAAK,aAAe,MACtB,CAKQ,aAAW,CACjB,GAAI,KAAK,eAAiB,OACxB,MAAM,IAAI,MAAM,yBAAyB,CAE7C,CAEA,QAAQH,EAAuB,CAE7B,GADA,KAAK,YAAW,EACZ,KAAK,YAAc,KAAK,SAC1B,MAAM,IAAI,MAAM,iDAAiD,EAEnE,OAAOuB,GAAc,KAAMvB,CAAI,CACjC,KClaF,IAwUawB,GAxUbC,GAAAC,EAAA,kBAIAC,KAoUaH,GAASA,KCxUtB,IAKaI,GAQPC,GAkBOC,GAOAC,GAtCbC,GAAAC,EAAA,kBAGAC,KAEaN,GAAQ,CAACO,EAAoBC,IAAiB,CACpDC,GAAI,KAAK,OAId,QAAQ,UAAU,GAAGF,CAAU,UAAUC,CAAK,EAAE,CAClD,EAEMP,GAAa,CAACS,EAAaC,IAAqB,CACpD,IAAMC,EAAQ,IAAI,MAAK,EAAG,OAAO,MAAM,aAAa,GAAK,CAAA,EACrDC,EAAe,GACnB,QAASC,EAAI,EAAGA,EAAIF,EAAM,OAAQE,IAAK,CACrC,GAAID,GAAgB,CAACD,EAAME,CAAC,EAAE,SAAS,YAAY,EAAG,CACpD,IAAIN,EAAQ,QAAQE,CAAG,KAAKE,EAAME,CAAC,EAAE,KAAI,EAAG,MAAM,GAAG,EAAE,CAAC,CAAC,GACrDH,IACFH,GAAS,KAAKG,CAAQ,IAExBX,GAAM,MAAOQ,CAAK,EAClB,OAEEI,EAAME,CAAC,EAAE,SAAS,YAAY,IAChCD,EAAe,IAGrB,EAEaX,GAAoBS,GAAqB,CAC/CF,GAAI,KAAK,OAGdR,GAAW,QAASU,CAAQ,CAC9B,EAEaR,GAAkBQ,GAAqB,CAC7CF,GAAI,KAAK,OAGdR,GAAW,MAAOU,CAAQ,CAC5B,IC3CA,IAgBaI,GAhBbC,GAAAC,EAAA,kBAGAC,KAIAC,KACAC,KAQaL,GAAP,MAAOM,CAAgB,CAC3B,YAAoBC,EAAgC,CAClD,KAAK,QAAUA,CACjB,CAGA,MAAM,IAAIC,EAAkBC,EAA+BC,EAAiB,CAC1EC,GAAgB,EAChB,IAAMC,EAA4C,CAAA,EAC9CC,EAAsB,CAAA,EAE1B,GAAI,OAAOL,GAAU,UAAYA,IAAU,MAAQA,aAAiBM,IAAU,MAAM,QAAQN,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIO,EAAiB,GAErB,GAAI,OAAON,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBK,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQL,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DM,EAAiB,GAEjB,QAAWC,KAAQP,EAAM,CACvB,GAAI,OAAOO,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEJ,EAAQI,CAAI,EAAI,KAGlB,GAAI,OAAON,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIO,EAAY,GACVC,EAAW,OAAO,oBAAoBT,CAAI,EAChD,QAAWO,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKV,EAA4DO,CAAI,GACvEG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBH,EAAQI,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAOP,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDG,EAAUJ,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWO,KAAQ,KAAK,WACtB,GAAI,OAAOR,EAAMQ,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBJ,EAAQI,CAAI,EAAI,KAMpB,IAAMI,EAAU,MAAM,KAAK,QAAQ,IAAIZ,EAAOI,EAASC,CAAO,EACxDQ,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAAC,GAAc,EACPH,CACT,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,CAOA,aAAa,OACTI,EAAyChB,EAA8BC,EACvEgB,EAAqB,CACvBf,GAAgB,EAEhB,IAAIgB,EACAd,EAA0B,CAAA,EAE9B,GAAI,OAAOY,GAAS,UAElB,GADAE,EAAuBF,EACnB,OAAOhB,GAAS,UAAYA,IAAS,KACvCI,EAAUJ,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7CgB,aAAgB,YAEzB,GADAE,EAAuBF,EACnB,OAAOhB,GAAS,UAAYA,IAAS,KACvCI,EAAUJ,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAGpDgB,aAAgB,aACf,OAAO,kBAAsB,KAAeA,aAAgB,kBAAoB,CACnF,IAAMG,EAASH,EACXI,EAAa,EACbC,EAAaL,EAAK,WACtB,GAAI,OAAOhB,GAAS,UAAYA,IAAS,KACvCI,EAAUJ,UACD,OAAOA,GAAS,SAAU,CAEnC,GADAoB,EAAapB,EACT,CAAC,OAAO,cAAcoB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,EAAa,GAAKA,GAAcD,EAAO,WACzC,MAAM,IAAI,WAAW,oCAAoCA,EAAO,UAAU,IAAI,EAGhF,GADAE,EAAaL,EAAK,WAAaI,EAC3B,OAAOnB,GAAS,SAAU,CAE5B,GADAoB,EAAapB,EACT,CAAC,OAAO,cAAcoB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,GAAc,GAAKD,EAAaC,EAAaF,EAAO,WACtD,MAAM,IAAI,WAAW,oCAAoCA,EAAO,WAAaC,CAAU,IAAI,EAE7F,GAAI,OAAOH,GAAS,UAAYA,IAAS,KACvCb,EAAUa,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7C,OAAOhB,EAAS,IACzB,MAAM,IAAI,UAAU,gCAAkC,UAE/C,OAAOD,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,EAEtDkB,EAAuB,IAAI,WAAWC,EAAQC,EAAYC,CAAU,MAEpE,OAAM,IAAI,UAAU,qDAAyD,EAK/E,IAAMC,GADMlB,EAAQ,oBAAsB,CAAA,GACjB,IAAImB,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAE9DzB,EAAU,MADA,MAAM0B,GAAeF,CAAY,GACnB,8BAA8BJ,EAAsBd,CAAO,EACzF,OAAAW,GAAc,EACP,IAAIlB,EAAiBC,CAAO,CACrC,CAEA,gBAAc,CACZ,KAAK,QAAQ,eAAc,CAC7B,CACA,cAAY,CACV,KAAK,QAAQ,aAAY,CAC3B,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,KC1NF,IAqca2B,GArcbC,GAAAC,EAAA,kBAGAC,KAkcaH,GAA4CA,KCrczD,IAAAI,GAAAC,EAAA,oBCAA,IAgBMC,GAGOC,GAnBbC,GAAAC,EAAA,kBAGAC,KAIAC,KASML,GAA0B,gHAGnBC,GAAP,MAAOK,CAAe,CAC1B,YAAoBC,EAAiCC,EAA4BC,EAAqB,CACpG,KAAK,QAAUF,EACf,KAAK,kBAAoBC,EACzB,KAAK,aAAeC,CACtB,CAKA,IAAI,oBAAkB,CACpB,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,qBAAmB,CACrB,OAAO,KAAK,QAAQ,WACtB,CAEA,IAAI,gBAAc,CAChB,GAAI,KAAK,aACP,OAAO,KAAK,QAAQ,eAEpB,MAAM,IAAI,MAAM,gDAAgD,CAEpE,CACA,IAAI,iBAAe,CACjB,GAAI,KAAK,aACP,OAAO,KAAK,QAAQ,gBAEpB,MAAM,IAAI,MAAM,gDAAgD,CAEpE,CAEA,aAAa,OAAOC,EAA+CC,EAA+B,CAEhG,IAAMC,EAA+BF,EAAgB,WAAa,GAC5DG,EAAoCH,EAAgB,gBAAkB,GACtEI,EAA0BH,GAAkB,CAAA,EAI5CI,GADMD,EAAQ,oBAAsB,CAAA,GACjB,IAAIE,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAC9DC,EAAU,MAAMC,GAAeH,CAAY,EACjD,GAAIE,EAAQ,6BAA8B,CACxC,IAAMV,EAAU,MAAMU,EAAQ,6BAC1BP,EAAgB,gBAAiBA,EAAgB,WAAYE,EAAWC,EAAgBC,CAAO,EACnG,OAAO,IAAIR,EAAgBC,EAAS,CAAC,CAACG,EAAgB,eAAgB,CAAC,CAACA,EAAgB,SAAS,MAEjG,OAAM,IAAI,MAAMV,EAAe,CAEnC,CAeA,wBACImB,EAA+BC,EAAgCC,EAAkBC,EACjFC,EAAiB,CACnB,IAAMC,EAA4C,CAAA,EAC9CV,EAAsB,CAAA,EAE1B,GAAI,OAAOO,GAAU,UAAYA,IAAU,MAAQA,aAAiBI,IAAU,MAAM,QAAQJ,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIK,EAAiB,GAErB,GAAI,OAAOJ,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBG,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQH,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DI,EAAiB,GAEjB,QAAWC,KAAQL,EAAM,CACvB,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAIP,EAAY,QAAQO,CAAI,IAAM,GAChC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEH,EAAQG,CAAI,EAAI,KAGlB,GAAI,OAAOJ,GAAS,UAAYA,IAAS,KACvCT,EAAUS,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIK,EAAY,GACVC,EAAW,OAAO,oBAAoBP,CAAI,EAChD,QAAWK,KAAQP,EACjB,GAAIS,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKR,EAAmDK,CAAI,GAC9DG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBF,EAAQG,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCT,EAAUS,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDT,EAAUQ,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWK,KAAQR,EACjB,GAAI,OAAOE,EAAMM,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQP,EACjBI,EAAQG,CAAI,EAAI,KAIpB,MAAO,CAACH,EAASV,CAAO,CAC1B,CASA,uCAAuCiB,EAAkC,CACvE,IAAMC,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAEA,MAAM,eAAa,CACjB,MAAM,KAAK,QAAQ,cAAa,CAClC,CAIA,MAAM,aAAaX,EAAkBC,EAA+BC,EAAiB,CACnF,GAAM,CAACC,EAASV,CAAO,EACnB,KAAK,wBAAwB,KAAK,mBAAoB,KAAK,oBAAqBO,EAAOC,EAAMC,CAAI,EAC/FQ,EAAU,MAAM,KAAK,QAAQ,aAAaV,EAAOG,EAASV,CAAO,EACvE,OAAO,KAAK,uCAAuCiB,CAAO,CAC5D,CAEA,MAAM,iBAAiBjB,EAA+C,CACpE,GAAI,KAAK,kBACP,MAAM,KAAK,QAAQ,iBAAiBA,GAAW,CAAA,CAAE,MAEjD,OAAM,IAAI,MAAM,oDAAoD,CAExE,CAIA,MAAM,YAAYO,EAAkBC,EAA+BC,EAAiB,CAClF,GAAI,KAAK,aAAc,CACrB,GAAM,CAACC,EAASV,CAAO,EACnB,KAAK,wBAAwB,KAAK,eAAgB,KAAK,gBAAiBO,EAAOC,EAAMC,CAAI,EACvFQ,EAAU,MAAM,KAAK,QAAQ,YAAYV,EAAOG,EAASV,CAAO,EACtE,OAAO,KAAK,uCAAuCiB,CAAO,MAE1D,OAAM,IAAI,MAAM,+CAA+C,CAEnE,CAEA,MAAM,kBAAkBI,EAAgB,GAAI,CAC1C,OAAO,KAAK,QAAQ,kBAAkBA,CAAa,CACrD,CAEA,MAAM,qBAAqBC,EAAmBD,EAAgB,GAAI,CAChE,IAAME,EAAa,MAAM,KAAK,kBAAkBF,CAAa,EAG7D,GAAIC,EAAM,SAAW,EAAIC,EACvB,MAAM,IAAI,MACN,qJAC0D,EAEhE,OAAO,KAAK,QAAQ,qBAAqBD,EAAOD,CAAa,CAC/D,CAEA,MAAM,wBAAwBA,EAAgB,GAAI,CAChD,OAAO,KAAK,QAAQ,wBAAwBA,CAAa,CAC3D,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,KC1PF,IAmMaG,GAnMbC,GAAAC,EAAA,kBAKAC,KA8LaH,GAA0CA,KCnMvD,IAAAI,GAAA,GAAAC,GAAAD,GAAA,sBAAAE,GAAA,UAAAC,GAAA,qBAAAC,GAAA,mBAAAC,GAAA,WAAAC,GAAA,oBAAAC,GAAA,QAAAC,GAAA,oBAAAC,KAAA,IAAAC,GAAAC,EAAA,kBAmBAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,OCzBA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,cAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAW,SCAxB,IAAAG,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAW,IAAM,CACnB,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,IAAIC,EAAED,EAAUE,EAAGC,EAAEF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAEE,CAAC,CAAC,EAC1DJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,GAAEN,EAAE,CAACO,EAAEC,GAAEC,KAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,KAAI,EAAEE,GAAEH,EAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,KAAI,EAAE,OAAAK,IAAIC,KAAIP,EAAEO,GAAEL,GAAEI,CAAC,EAAEL,GAAEC,GAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,GAAG,SAASC,KAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,GAAEb,EAAE,GAAG,CAAC,GAAGY,GAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,EAAE,GAAGC,EAAC,EAAE,GAAGZ,EAAE,KAAKa,GAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,GAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,GAAGX,EAAE,QAAQW,CAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,GAAGX,EAAE,mBAAmBW,CAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,GAAGX,EAAE,cAAcW,CAAC,EAAEX,EAAE,mBAAmB,CAACW,EAAEC,GAAEC,GAAEC,KAAIX,EAAE,eAAeQ,EAAEC,GAAEC,GAAEC,EAAC,EAAEd,EAAE,sBAAsBW,GAAG,CAACR,EAAE,kBAAkBQ,CAAC,CAAC,EAAEX,EAAE,cAAcW,GAAGR,EAAE,UAAUQ,CAAC,EAAEX,EAAE,qBAAqB,CAACW,EAAEC,GAAEC,KAAIV,EAAE,iBAAiBQ,EAAEC,GAAEC,EAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAE,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAa,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE,GAAGC,EAAEC,EAAEC,EAChP,GAAGJ,EAAG,CAAC,IAAIK,EAAG,cAAcC,EAAG,cAAgBL,EAAEF,EAAEO,EAAG,QAAQL,CAAC,EAAE,IAAI,UAAU,IAAIC,EAAE,CAACxB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAS2B,EAAG,aAAa3B,EAAEC,EAAE,OAAO,MAAM,GAAGyB,EAAE1B,IAAIA,EAAEwB,EAAExB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAGyB,EAAE,CAACzB,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAE2B,EAAG,SAAS3B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACR,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAE,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAACnB,EAAEC,IAAI,CAAC,cAAQ,SACnfD,EAAQC,CAAE,EAAEJ,EAAE,QAAQ,IAAI,4BAA4B,MAASuB,GAAIC,KAAEA,EAAEE,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAK5B,IAAa4B,EAAE5B,GAAgB4B,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGC,EAAExB,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIK,EAAE1B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GACvfwB,EAAE,CAACzB,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,GAAE,IAAI0B,EAAGhC,EAAE,OAAO,QAAQ,IAAI,KAAK,OAAO,EAAEiC,EAAEjC,EAAE,UAAU,QAAQ,MAAM,KAAK,OAAO,EAAE,OAAO,OAAOA,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAErB,EAAE,aAAaA,EAAE,OAAOsB,EAAEtB,EAAE,MAAM,IAAIkC,EAAElC,EAAE,aAAakC,EAAElC,EAAE,YAAY,IAAImC,EAAcnC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BoC,GAAE,iCAAiC,EACve,IAAIC,EAAEC,EAAEC,EAAE,GAAGC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAGC,GAAG,SAASC,IAAI,CAAC,IAAI5C,EAAEkC,EAAE,OAAOrC,EAAE,MAAMyC,EAAE,IAAI,UAAUtC,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAO2C,EAAE,IAAI,WAAWxC,CAAC,EAAEH,EAAE,OAAO0C,EAAE,IAAI,WAAWvC,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQ4C,EAAE,IAAI,YAAYzC,CAAC,EAAEH,EAAE,QAAQ6C,GAAG,IAAI,aAAa1C,CAAC,EAAEH,EAAE,QAAQ8C,GAAG,IAAI,aAAa3C,CAAC,CAAC,CAAC,IAAI6C,EAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAE,SAASC,IAAI,CAAC,IAAIhD,EAAEH,EAAE,OAAO,MAAM,EAAEgD,EAAG,QAAQ7C,CAAC,CAAC,CAAC,IAAIiD,GAAE,EAAEC,GAAG,KAAKC,GAAE,KACnY,SAASlB,GAAEjC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAI8B,EAAE9B,CAAC,EAAEoC,EAAE,GAAGC,EAAE,EAAErC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAEC,CAAC,EAAQA,CAAE,CAAC,SAASoD,EAAGpD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIqD,EAAyB,GAAvBA,EAAE,qBAAwB,CAACD,EAAGC,CAAC,EAAE,CAAC,IAAIC,GAAGD,EAAEA,EAAExD,EAAE,WAAWA,EAAE,WAAWyD,GAAG/B,CAAC,EAAEA,EAAE+B,EAAE,CAAC,SAASC,GAAGvD,EAAE,CAAC,GAAGA,GAAGqD,GAAGtB,EAAE,OAAO,IAAI,WAAWA,CAAC,EAAE,GAAGL,EAAE,OAAOA,EAAE1B,CAAC,EAAE,KAAK,iDAAkD,CACnc,SAASwD,GAAGxD,EAAE,CAAC,GAAG,CAAC+B,IAAIX,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIsD,GAAGvD,CAAC,CAAC,EAAE,GAAGyB,EAAE,OAAO,IAAI,QAAQ,CAACxB,EAAEC,IAAI,CAACuB,EAAEzB,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIqD,GAAGvD,CAAC,CAAC,CAAC,CAAC,SAASyD,GAAGzD,EAAEC,EAAEC,EAAE,CAAC,OAAOsD,GAAGxD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC2B,EAAE,0CAA0C3B,CAAC,EAAE8B,GAAE9B,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASuD,GAAG1D,EAAEC,EAAE,CAAC,IAAIC,EAAEmD,EAAE,OAAOtB,GAAe,OAAO,YAAY,sBAA/B,YAAqDqB,EAAGlD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAgB,OAAO,OAAnB,WAAyBmC,GAAGvD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA0B,EAAE,kCAAkC1B,CAAC,EAAE0B,EAAE,2CAA2C,EAAS2B,GAAGvD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC9W,IAAI0D,GAAEC,GAAG,CAAC,OAAO5D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OACxfG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,OAAOG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YAAYG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,kBAC1fG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAClgB,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IACzf,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAC/f,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,EAAE7B,KAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EACpfA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,EAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAK+B,EAAE,SAAS9B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KACnf,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,EAAE7B,KAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EACnf,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,EAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAK+B,EAAE,SAAS9B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAChgB,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAC5f,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAAOG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,OAAOJ,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAC1fC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAAUG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EACnfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,KAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKsC,EAAE,SAASrC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB2D,GAAEzD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,GAAE,sBAAsBsD,GAAErD,CAAC,EAAE,KAAKqD,GAAEpD,EAAC,EAAE,YAAYoD,GAAEnD,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBACpeG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS6D,GAAE5D,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBAAqBG,EAAE,CAAC,QAAQC,EAAE,SAASC,EAAE,QAAQ,CAAC,CAACE,EAAE,aAAa,CAAC,CAACD,EAAE,OAAOE,EACvf,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACL,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBAAqBG,EAAE,CAAC,QAAQC,EAAE,SAASC,EAAE,QAAQ,CAAC,CAACE,EAAE,aAAa,CAAC,CAACD,EAAE,OAAOE,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACL,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,SAASG,EAAE,CAAC,UAAU,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,IAAI,CAACX,EAAE,GAAG,YAAYG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,EAAE,eAAeC,EAAE,MAAM,KAAKkC,EAAE,SAAS,OAAOjC,EAAC,IAAI,EAAE,OAAOA,EAAC,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,uBAAuB,CAAC,CAACE,CAAC,CAAC,CAAC,EAAE,OAAOR,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBACtfG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC+B,EAAE7B,KAAI,CAAC,EAAE,WAAWoD,GAAEnD,EAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAK+B,GAAG,SAAS9B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EACxf,OAAO,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOW,GAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAKC,GAAE,MAAM,KAAKiC,EAAE,SAAShC,IAAI,EAAEA,EAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,GAAEC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC4B,EAAE1B,KAAI,CAAC,EAAE,WAAWiD,GAAE/C,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAK2B,GAAG,SAASoB,KAAI,EAAEA,GAAE/C,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOf,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,OAAOG,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAOA,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EACld,SAAS6D,GAAG/D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,IAAIgE,GAAGhE,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EAAE,SAASoE,GAAGjE,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACwC,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACwC,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACuC,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CACnW,IAAIyB,GAAG,EAAEC,GAAG,EAAEC,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACrE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQoE,GAAG,OAAOA,GAAG,OAAOpE,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GAAG,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EACxgB0D,GAAE,CAAC7D,EAAEC,KAAKD,KAAK,GAAGqE,GAAG9B,EAAEvC,EAAEC,CAAC,EAAE,GAAGqE,GAAGtE,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEsE,GAAG,CAACvE,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EACnf,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEoE,GAAExE,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAWyE,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG3E,GAAG,CAAC,IAAIC,EAAEqE,GAAGtE,CAAC,EAAE,EAAEE,EAAE0E,GAAG3E,CAAC,EAAE,OAAAC,GAAGqE,GAAGvE,EAAEuC,EAAErC,EAAED,CAAC,EAASC,CAAC,EAAE2E,GAAG,CAAC,EAAEC,GAAG,CAAC9E,EAAEC,IAAI,CAAC4E,GAAG,OAAO,EAAE,IAAI3E,EAAE,IAAID,IAAI,EAAEC,EAAEqC,EAAEvC,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAE4E,GAAG,KAAU3E,GAAL,IAAOsC,EAAEvC,IAAI,CAAC,EAAE0C,GAAG1C,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAO4E,EAAE,EAAEE,GAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,GAAG,CAAC,IAAIjF,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IACtf,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAG,gBAAgB,EAAEjB,EAAE,IAAIA,KAAK8E,GAAYA,GAAG9E,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAE8E,GAAG9E,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEgF,GAAG/E,CAAC,CAAC,OAAO+E,EAAE,EAAEA,GAAGC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGrF,EAAE,CAAC,IAAIC,EAAE,MAAMqE,GAAGtE,CAAC,EAAE,CAAC,EAAE,OAAAuE,GAAGvE,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACtb,SAASqF,GAAGtF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE+C,GAAE,CAAC,IAAIhD,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAEgD,GAAE,CAAC,EAAEhD,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAAS+C,GAAEyB,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE1B,GAAEhD,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiDyE,GAAE1B,GAAEhD,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuCyE,GAAE1B,GAAEhD,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAUyE,EAAC,CAAC,SAASjF,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,EAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI+C,GAAEhD,EAAE,SAAS,EAAE0E,IAAGhB,GAAE1D,EAAE,YAAY,CAAC,EAAEqE,GAAGC,IAAItB,EAAC,EAAE,GAAG/C,GAAEyE,GAAE1E,EAAE,QAAQ,EAAEC,IAAGyE,GAAE1E,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAGgD,GAAEhD,EAAE,SAASgD,GAAE,CAAC,GAAGhD,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA+C,GAAE,IAAI,KAAKhD,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAEgD,GAAEvD,GAAEuD,EAAC,EAAS,GAAGxD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEwD,GAAEhD,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,GAAE+B,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGqC,EAAErC,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,GAAEoD,GAAEpD,EAAC,EAAE,EAAE,EAAEP,EAAE2D,GAAE3D,CAAC,EAAEO,GAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WAAW,MAAM,KACnf,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,MAAKD,GAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,GAAEC,EAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,GAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,UAAU,EACngB,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE+C,GAAE,EAAEA,IAAGhD,EAAE,GAAG,EAAEC,KAAIyD,GAAE1D,EAAE,GAAG,IAAI,EAAEqE,GAAGC,IAAItB,IAAG,EAAE,CAAC,OAAOzD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GAAG,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GACvf,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ+C,IAAGhD,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAKgD,IAAH,GAASA,IAAH,GAAMU,GAAE1D,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI+C,IAAGhD,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAMgD,IAAH,GAASA,IAAH,GAAMU,GAAE1D,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,MAAKD,GAAEP,EAAE,SAASQ,EAAC,IAAIR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GACzgB,GAAG,EAAED,GAAEC,EAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,GAAE2E,GAAGnF,CAAC,EAAKQ,GAAE,OAAOT,EAAS,GAAEqC,EAAE,IAAI5B,GAAEV,IAAI,CAAC,EAASU,GAAE,OAAO,EAAC,CAAC,SAAS+E,GAAEzF,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACgC,GAAEhC,CAAC,CAAC,CAAC,CAAC,SAASyF,GAAG1F,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACuF,GAAE,KAAKxF,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQgC,IAAIuD,GAAE,IAAI,IAAIxF,GAAG8B,GAAE,EAAEpB,IAAO+E,KAAJ,GAAWD,GAAE,SAAN,IAAeC,GAAE,EAAEH,GAAEI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAEzF,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI2F,GAAE,EAAE/E,GAAE,KAAKiF,GAAG,EAAEH,GAAE,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC9c,SAASnF,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACiG,GAAG,CAAC,QAAQlG,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASmG,IAAI,CAAC,IAAIpG,EAAE4E,GAAG,KAAK,EAAE3E,EAAED,EAAE,GAAGyC,EAAEzC,GAAG,IAAI,CAAC,EAAEC,EAAEwC,EAAEzC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAE0F,GAAE,CAAC,EAAE,IAAIzF,EAAE6F,GAAG9F,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAE+F,KAAKF,GAAG9F,CAAC,EAAEC,EAAE8F,GAAG9F,CAAC,EAAED,GAAGuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEE,EAASF,CAAC,CAC5N,SAASqG,GAAGrG,EAAE,CAAC,GAAG,CAACoC,EAAE,CAAC,GAAOwD,KAAJ,EAAM,CAAC,IAAI3F,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACiC,IAAI0D,GAAG3F,EAAEF,EAAE,GAAGC,GAAG,CAAC0F,GAAE,EAAEH,GAAE,IAAIa,GAAGzF,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,KAAK+B,EAAE6D,GAAGxD,EAAE3B,GAAE,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,OAAON,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAE4F,GAAG5F,IAAI4F,GAAG,MAAM/F,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI2F,GAAE,EAAE/E,GAAEuF,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAE,IAAIc,GAAG1F,EAAC,CAAC,EAAE,MAAU+E,KAAJ,GAAOA,GAAE,EAAEH,GAAEe,EAAE,EAAEC,GAAG5F,EAAC,EAAEA,GAAE,KAAKsF,GAAG,QAAQhG,GAAG,CAAC,GAAG,CAACiC,EAAE,GAAG,CAAC,GAAGjC,EAAE,EAAE,CAAC6B,EAAc,GAAG,CAACK,EAAEA,EAAElC,EAAEkC,EAAML,IAAkBnC,EAAE,QAAOA,EAAE,OAAOM,CAAC,EAC7hBiC,EAAE,IAAGjB,EAAEhB,EAAE,IAAI4D,GAAG5D,CAAC,CAAC,CAAC,OAAOC,EAAE,CAACA,aAAa2D,IAAc3D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa2D,IAAc3D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,CAAC,GAAG6B,GAAE,kBAAkB2D,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAAC,SAASY,GAAG1G,EAAE,CAAC,OAAOqG,GAAGpG,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CACnM,IAAI0G,GAAG,CAAC,EAAE,SAAS3G,EAAEC,EAAEC,EAAE,CAAC,OAAOwG,GAAG,SAAS,CAAC,MAAM7G,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIiE,GAAGjE,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEgE,GAAGlE,EAAEmE,KAAWD,EAAG,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,IAAI,GAAG,EAAE,SAASlE,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EACnfF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGF,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAClf,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGsE,GAAExE,EAAE,YAAY,CAAC,EAAEyE,GAAGC,IAAI1E,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGD,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,CAAC,EAAE,EAAE,SAASD,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAC5fG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAAG,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGqC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,GAAGwE,GAAEvE,EAAE,YAAY,CAAC,EAAEwE,GAAGC,IAAIzE,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEuC,EAAExC,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAC7f,IAAW2G,IAAIjD,GAAE3D,EAAE,GAAG,CAAC,KAAK,IAAI2D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE3D,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,GAAG,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEK,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACN,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,EAAE,kBAAkB,EAAEmC,EAAEzC,IAAI,GAAG,IAAI,CAAC,EAAE,GAAG,KAAK,IAAII,EAAEG,EAAC,EAAEiC,EAAEvC,IAAI,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAE2E,GAAG3E,CAAC,EAAEC,EAAE0E,GAAG1E,CAAC,EAAEM,GAAEH,GAAGqC,EAAEvC,GAAG,IAAI,CAAC,EAAEF,EAAEyC,EAAEvC,EACnf,GAAG,IAAI,CAAC,EAAED,IAAIwC,EAAEvC,GAAG,IAAI,CAAC,EAAED,EAAEwC,EAAEvC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACiC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASjC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE6E,GAAG7E,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE6E,GAAG7E,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,IAAI,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAD,KAAK,EAASsC,EAAE,WAAWvC,IAAI,IAAI,EAAEC,IAAI,EAAEA,GAAGC,IAAI,KAAK,CAAC,CAAC,EAAE,EAAE,SAASF,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEsC,EAAE,OAAO,GAAG,WAAWvC,EAAE,MAAM,GAAG,QAAQE,EAAE,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KACpfD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAE+B,EAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,EAAE,KAAK9B,CAAC,EAAEwC,GAAG,EAAE,IAAIvC,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAE,SAASL,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAA8E,GAAG,EAAE,QAAQ,SAAS7E,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAsB,IAApBE,EAAEqC,EAAEzC,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEiC,EAAElC,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEiC,EAAElC,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,EAAE,EAAE,SAASH,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE8E,GAAG,EAAEvC,EAAEzC,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEqC,EAAExC,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,EAAE,EAAE,IACrf,GAAG,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,SAASH,EAAEC,EAAEC,EAAEC,EAAE,CAACF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEmC,EAAExC,GAAG,IAAI,CAAC,EAAEM,GAAEkC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,EAAE,EAAEA,EAAED,GAAEC,IAAI,CAAC,IAAIC,GAAE8B,EAAEjC,EAAEE,IAAI,CAAC,EAAEE,GAAEwE,GAAGlF,CAAC,EAAMS,KAAJ,GAAYA,KAAL,KAAaT,IAAJ,EAAM6B,EAAGC,GAAGuC,GAAG3D,GAAE,CAAC,CAAC,EAAEA,GAAE,OAAO,GAAGA,GAAE,KAAKD,EAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAkC,EAAEtC,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,EAAE,EAAEkF,GAAG,EAAE,SAAStF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmF,GAAGtF,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GAC7V,UAAU,CAAC,SAASH,EAAEE,EAAE,CAAoH,GAAnHA,EAAEA,EAAE,QAAQA,EAAEwF,GAAGxF,CAAC,EAAEiC,EAAEjC,EAAE2G,GAAG3G,CAAC,EAAEgC,EAAEC,EAAE,EAAES,GAAG,EAAEE,GAAG,QAAQX,EAAE,CAAC,EAAEc,KAAIpD,EAAE,wBAAwBA,EAAE,uBAAuBoD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAIhD,EAAEgD,GAAEA,GAAE,KAAKhD,EAAE,CAAC,CAAC,OAAOD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE0G,EAAE,EAA4D,GAA1D1D,KAAIpD,EAAE,wBAAwBA,EAAE,uBAAuBoD,EAAC,EAAKpD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAAC4B,EAAE,sDAAsD5B,CAAC,EAAEH,EAAEG,CAAC,CAAC,CAAC,OAAAwD,GAAGzD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,QAAQ,CAAC,CAAC,EAAE,MAAMH,CAAC,EAAQ,CAAC,CAAC,GAAG,EAC1dF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,MAAKZ,EAAE,yBAAyBsC,EAAE,GAAGnC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4BsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0BsC,EAAE,GAAGnC,CAAC,EAC1fH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAC/dP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EACteH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,MAAKV,EAAE,QAAQsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EACtV,IAAI4E,GAAG/E,EAAE,QAAQG,IAAI4E,GAAG/E,EAAE,QAAQsC,EAAE,IAAInC,CAAC,EAAEyG,GAAG5G,EAAE,MAAMG,IAAIyG,GAAG5G,EAAE,MAAMsC,EAAE,IAAInC,CAAC,EAAE4G,GAAG5G,IAAI4G,GAAGzE,EAAE,IAAInC,CAAC,EAAE8G,GAAG,KAAKA,GAAG3E,EAAE,IAAI,EAAE4E,GAAG/G,IAAI+G,GAAG5E,EAAE,IAAInC,CAAC,EAAEgH,GAAGhH,IAAIgH,GAAG7E,EAAE,IAAInC,CAAC,EAAEuG,GAAGvG,IAAIuG,GAAGpE,EAAE,IAAInC,CAAC,EAAE6F,GAAG,KAAKA,GAAG1D,EAAE,IAAI,EAAEmE,GAAGtG,IAAIsG,GAAGnE,EAAE,IAAInC,CAAC,EAAEwG,GAAG,KAAKA,GAAGrE,EAAE,IAAI,EAAEtC,EAAE,eAAe,OAAOA,EAAE,cAAc,OAAO,SAASgH,GAAG7G,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,WAAWmH,GAC5enH,EAAE,UAAUiH,GAAGjH,EAAE,aAAakH,GAAGlH,EAAE,aAAagE,GAAEhE,EAAE,aAAa,CAACG,EAAEC,EAAEC,IAAIqE,GAAGvE,EAAEuC,EAAEtC,EAAEC,CAAC,EAAEL,EAAE,gBAAgByE,GAAG,IAAI2C,GAAE9D,GAAE,SAAS+D,GAAI,CAACD,IAAGE,GAAG,EAAEF,KAAI9D,GAAE+D,EAAG,EAClJ,SAASC,IAAI,CAAC,SAASnH,GAAG,CAAC,GAAG,CAACiH,KAAIA,GAAE,GAAGpH,EAAE,UAAU,GAAG,CAACuC,GAAG,CAAiE,GAAhE4B,GAAGlB,EAAE,EAAEhD,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAKA,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAEkD,GAAG,QAAQ9C,CAAC,CAAC,CAAC+D,GAAGjB,EAAE,CAAC,CAAC,CAAC,GAAG,EAAE,EAAEE,IAAG,CAAC,GAAGpD,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQmD,GAAG,EAAEgB,GAAGnB,CAAE,EAAE,EAAEI,KAAIpD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EAAE,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAC1e,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAAsH,GAAG,EAGvGvH,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAO,IC7E1B,IAAA0H,GAAAC,GAAA,QCAA,IAAAC,GAAAC,GAAA,QCAA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAmB,IAAM,CAC3B,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,SAASC,GAAG,CAAC,OAAAC,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASD,EAAC,CAAC,SAASE,GAAG,CAAC,OAAAH,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASE,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAL,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASI,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAP,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASM,EAAE,CAAC,SAASC,GAAI,CAAC,OAAAT,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASQ,CAAE,CAAC,SAASC,GAAI,CAAC,OAAAX,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASU,CAAE,CAAC,IAAIC,EAAEf,EAAUgB,EAAGC,EAAEF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAEE,CAAC,CAAC,EACrVJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,GAAEN,EAAE,CAACO,GAAEC,GAAEC,KAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,KAAI,EAAEE,GAAEH,GAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,KAAI,EAAE,OAAAK,IAAIC,KAAIP,GAAEO,GAAEL,GAAEI,CAAC,EAAEL,GAAEC,GAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,IAAG,SAASC,KAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,GAAEb,EAAE,GAAG,CAAC,GAAGY,GAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,GAAE,GAAGC,EAAC,EAAE,GAAGZ,EAAE,KAAKa,GAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,GAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,IAAGX,EAAE,QAAQW,EAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,IAAGX,EAAE,mBAAmBW,EAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,IAAGX,EAAE,cAAcW,EAAC,EAAEX,EAAE,mBAAmB,CAACW,GAAEC,GAAEC,GAAEC,KAAIX,EAAE,eAAeQ,GAAEC,GAAEC,GAAEC,EAAC,EAAEd,EAAE,sBAAsBW,IAAG,CAACR,EAAE,kBAAkBQ,EAAC,CAAC,EAAEX,EAAE,cAAcW,IAAGR,EAAE,UAAUQ,EAAC,EAAEX,EAAE,qBAAqB,CAACW,GAAEC,GAAEC,KAAIV,EAAE,iBAAiBQ,GAAEC,GAAEC,EAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAG,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAY,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE1B,EAAE,wBAAwB,GAAG2B,EAAE,GAAG,SAASC,EAAGzB,EAAE,CAAC,OAAOH,EAAE,WAAWA,EAAE,WAAWG,EAAEwB,CAAC,EAAEA,EAAExB,CAAC,CAAC,IAAI0B,EAAGC,EAAEC,EAC7U,GAAGN,EAAE,CAAC,IAAIO,EAAG,cAAcC,EAAG,cAAgBN,EAAEH,EAAES,EAAG,QAAQN,CAAC,EAAE,IAAI,UAAU,IAAIE,EAAG,CAACzB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE6B,EAAG,UAAU7B,CAAC,EAAS4B,EAAG,aAAa5B,EAAEC,EAAE,OAAO,MAAM,GAAG0B,EAAG3B,IAAIA,EAAEyB,EAAGzB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAG0B,EAAE,CAAC1B,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE6B,EAAG,UAAU7B,CAAC,EAAE4B,EAAG,SAAS5B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACT,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAG,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAAClB,EAAEC,IAAI,CAAC,cAAQ,SACtfD,EAAQC,CAAE,EAAEL,EAAE,QAAQ,IAAI,6BAA6B,IAAIG,EAAE,GAAG,CAACA,EAAE,IAAyB,OAAOC,EAAE,CAAC,MAAM,QAAQ,MAAM,yGAAyG,EAAEA,CAAE,CAAC,OAAO,OAAOD,EAAE,MAAM,MAASoB,GAAIC,KAAEA,EAAEG,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAM,OAAO3C,EAAe,KAAeA,IAAc2C,EAAE3C,GAAgB2C,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGF,IAAII,EAAG1B,GAAG,CAAC,IAAIC,EAC9hB,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIO,EAAG5B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GAAG0B,EAAE,CAAC3B,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,IAAGmB,GAAgB,OAAO,YAApB,MAAkC,OAAO,YAAY,KAAsB,aACrd,IAAIS,EAAG,QAAQ,IAAI,KAAK,OAAO,EAAEC,EAAG,QAAQ,MAAM,KAAK,OAAO,EAAEV,IAAIS,EAAG,IAAI/B,IAAI6B,EAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,EAAEgC,EAAG,IAAIhC,IAAI6B,EAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,GAAG,IAAIiC,EAAGpC,EAAE,OAAOkC,EAAGG,EAAErC,EAAE,UAAUmC,EAAG,OAAO,OAAOnC,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAGrB,EAAE,aAAaA,EAAE,OAAOsB,EAAEtB,EAAE,MAAM,IAAIsC,GAAEtC,EAAE,aAAasC,GAAEtC,EAAE,YAAY,IAAIuC,GAAcvC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BwC,GAAE,iCAAiC,EAAE,IAAIrD,GAAEsD,EAAEC,GAAGC,GAAE,GAAGC,GAAExD,GAAEG,GAAGE,GAAGE,GAAGE,EAAGE,EAChc,SAASV,IAAG,CAAC,IAAIc,EAAEhB,GAAE,OAAOa,EAAE,MAAMZ,GAAE,IAAI,UAAUe,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAOP,GAAG,IAAI,WAAWU,CAAC,EAAEH,EAAE,OAAOT,GAAG,IAAI,WAAWY,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQL,GAAG,IAAI,YAAYQ,CAAC,EAAEH,EAAE,QAAQH,EAAG,IAAI,aAAaM,CAAC,EAAEH,EAAE,QAAQD,EAAG,IAAI,aAAaI,CAAC,CAAC,CAAC,IAAI0C,GAAG7C,EAAE,gBAAgB,SACtS,GAD+S,SAAS6C,IAAIL,GAAE,wDAAwDK,GAAG,wBAAwB,EAC9YnB,EAAEvC,GAAEa,EAAE,mBAAmBA,EAAE,WAAWb,GAAEa,EAAE,mBAAmBb,GAAE,IAAI,YAAY,OAAO,CAAC,QAAQ0D,GAAG,MAAM,QAAQ,MAAM,OAAO,EAAE,CAAC,EAAE,EAAE1D,GAAE,kBAAkB,mBAAmB,MAAMkD,EAAE,6NAA6N,EAAEZ,GAAGY,EAAE,2GAA2G,EACrgB,MAAM,YAAY,EAAEhD,GAAE,EAAEwD,GAAG1D,GAAE,OAAO,WAAW,IAAI2D,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAE,SAASC,IAAI,CAAC,OAAOX,IAAe,EAAEU,EAAE,CAAC,IAAIE,GAAE,EAAEC,GAAG,KAAKC,GAAE,KAAK,SAASC,IAAI,CAACH,KAAInD,EAAE,wBAAwBA,EAAE,uBAAuBmD,EAAC,CAAC,CAAC,SAASI,IAAI,CAA2D,GAA1DJ,KAAInD,EAAE,wBAAwBA,EAAE,uBAAuBmD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAIlD,EAAEkD,GAAEA,GAAE,KAAKlD,EAAE,CAAC,CAAC,CAClW,SAASqC,GAAErC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAIkC,EAAElC,CAAC,EAAEwC,GAAE,GAAGC,GAAE,EAAEzC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAEC,CAAC,EAAQA,CAAE,CAAC,SAASqD,GAAGrD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIsD,GAAEA,GAAE,8BAA8BD,GAAGC,EAAC,IAAIA,GAAE7B,EAAG6B,EAAC,GAAG,SAASC,GAAGvD,EAAE,CAAC,GAAGA,GAAGsD,IAAGnB,GAAE,OAAO,IAAI,WAAWA,EAAC,EAAE,GAAGP,EAAG,OAAOA,EAAG5B,CAAC,EAAE,KAAK,iDAAkD,CACpa,SAASwD,GAAGxD,EAAE,CAAC,GAAG,CAACmC,KAAIf,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIsD,GAAGvD,CAAC,CAAC,EAAE,GAAG2B,EAAE,OAAO,IAAI,QAAQ,CAAC1B,EAAEC,IAAI,CAACyB,EAAE3B,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIqD,GAAGvD,CAAC,CAAC,CAAC,CAAC,SAASyD,GAAGzD,EAAEC,EAAEC,EAAE,CAAC,OAAOsD,GAAGxD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC+B,EAAE,0CAA0C/B,CAAC,EAAEkC,GAAElC,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASuD,GAAG1D,EAAEC,EAAE,CAAC,IAAIC,EAAEoD,GAAE,OAAOnB,IAAe,OAAO,YAAY,sBAA/B,YAAqDkB,GAAGnD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAe,OAAO,OAAnB,WAAyBmC,GAAGvD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA8B,EAAE,kCAAkC9B,CAAC,EAAE8B,EAAE,2CAA2C,EAASuB,GAAGvD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC7W,IAAI0D,GAAEC,GAAG,CAAC,OAAO5D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OACxfG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,OAAOG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YAAYG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,kBAC1fG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IACpgB,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IACjgB,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IACvgB,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,GAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAACxB,EAAE,EAAE0B,KAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KACxf,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKvB,EAAE,EAAE,SAASyB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKf,EAAE,EAAE,SAASgB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACvB,EAAE,EAAEyB,KAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASuB,KACrgB,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,GAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAACxB,EAAE,EAAE0B,KAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKvB,EAAE,EAAE,SAASyB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWiD,GAAE9C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EACnf,MAAMC,EAAE,YAAY,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKf,EAAE,EAAE,SAASgB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACvB,EAAE,EAAEyB,KAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASuB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EACpgB,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GACnf,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO8D,GAAE,OAAO,OAAO,SAAS7D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,EAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAAOG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,OAAOJ,GAAG,CAACH,EAAE,GAAG,SACvfG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAAUG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAChgB,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,KAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB2D,GAAEzD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,GAAE,sBAAsBsD,GAAErD,EAAC,EAAE,KAAKqD,GAAEpD,EAAC,EAAE,YAAYoD,GAAEnD,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBACtfG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS6D,GAAE5D,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBAAqBG,EAAE,CAAC,QAAQC,EAAE,SAASC,EAAE,QAAQ,CAAC,CAACE,EAAE,aAAa,CAAC,CAACD,EAAE,OAAOE,EACzf,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACL,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBAAqBG,EAAE,CAAC,QAAQC,EAAE,SAASC,EAAE,QAAQ,CAAC,CAACE,EAAE,aAAa,CAAC,CAACD,EAAE,OAAOE,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACL,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,SAASG,EAAE,CAAC,UAAU,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,KAAI,CAACX,EAAE,GAAG,YAAYG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,EAAE,eAAeC,EAAE,MAAM,KAAKjB,EAAE,EAAE,SAAS,OAAOkB,EAAC,IAAI,EAAE,OAAOA,EAAC,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,uBAAuB,CAAC,CAACE,EAAC,CAAC,CAAC,EAAE,OAAOR,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACR,EAAE,GAAG,qBACxfG,EAAE,CAAC,SAASC,EAAE,iBAAiBC,EAAE,gBAAgBC,EAAE,MAAMC,EAAE,SAASC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,GAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAC,EAAE,WAAW,IAAI,CAAC,CAACxB,EAAE,EAAE0B,KAAI,CAAC,EAAE,WAAWoD,GAAEnD,EAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAKlB,EAAG,EAAE,SAASmB,KAAI,EAAEA,GAAED,KAClf,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAE+C,KAAI,CAACjE,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOW,GAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAKC,GAAE,MAAM,KAAKlB,EAAE,EAAE,SAASmB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,GAAEC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC3B,EAAE,EAAE6B,KAAI,CAAC,EAAE,WAAWiD,GAAE/C,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAKtB,EAAG,EAAE,SAASqE,KAAI,EAAEA,GAAE/C,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOf,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,OAAOG,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAOA,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EACle,SAAS6D,GAAG/D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,SAASgE,GAAGhE,EAAE,CAACA,EAAE,UAAU,EAAEA,EAAE,UAAU,IAAI,CAAC,CAAC,CAAC,SAASiE,GAAGjE,EAAE,EAAEA,EAAEkE,GAAE,GAAGlE,CAAC,IAAIqC,GAAE,EAAE6B,GAAE,GAAGlE,CAAC,CAAC,CAAC,SAASmE,GAAGnE,EAAE,CAAC,IAAIC,EAAEiE,GAAE,GAAG,EAAE,GAAG,CAACjE,EAAE,MAAO,GAAEiE,GAAE,GAAG,KAAKjE,CAAC,EAAEiE,GAAE,GAAGlE,EAAE,EAAE,EAAEC,EAAEA,EAAE,GAAGD,EAAE,GAAG,IAAIE,EAAE,CAAC,IAAI,MAAM,cAAcF,EAAE,GAAG,IAAIA,EAAE,GAAG,YAAYA,EAAE,EAAE,EAAE,OAAAsB,GAAGrB,EAAE,MAAM,EAAEA,EAAE,YAAYC,EAAEF,EAAE,EAAE,EAAS,CAAC,CACvX,IAAIoE,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACrE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQoE,GAAG,OAAOA,GAAG,OAAOpE,EAAE,kBAAkB,kBAAkBA,EAAE,MAAMC,EAAEC,CAAC,EAAEF,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GACpf,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EAAE0D,GAAE,CAAC7D,EAAEC,KAAKD,KAAK,GAAGqE,GAAGlF,EAAE,EAAEa,EAAEC,CAAC,EAAE,GAAG,SAASqE,GAAGtE,EAAE,CAAC,GAAGuB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,CAAC,EAAEyC,GAAEzC,EAAM+C,GAAG,IAAGmB,GAAE,GAAG,EAAKrE,EAAE,QAAOA,EAAE,OAAOG,CAAC,EAAEwC,GAAE,IAAGrB,EAAEnB,EAAE,IAAI+D,GAAG/D,CAAC,CAAC,CAAC,CACjM,IAAIwE,GAAGxE,GAAG,CAAK,GAAJyC,GAAEzC,EAAKuB,EAAE,MAAMkD,GAAGzE,CAAC,EAAE,SAASsE,GAAGtE,CAAC,CAAC,EAAEkE,GAAE,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAAC3C,EAAE2C,GAAE,GAAG,EAAEA,GAAE,GAAG,CAAC,EAAE,GAAG,UAAU,CAAC,QAAQlE,EAAEH,EAAE,WAAWG,KAAKkE,GAAE,GAAG,EAAEvB,GAAG,QAAQ,IAAI,CAACQ,GAAG,EAAEe,GAAE,GAAG,IAAId,GAAG,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,UAAU,CAACc,GAAE,sBAAsBA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAG9B,GAAc,EAAE,EAAE,GAAG,SAASpC,EAAE,CAACyC,GAAEzC,CAAC,EAAE,GAAG,CAAC,kBAAkB,EAAE,GAAG,UAAU,CAAC,QAAQA,KAAKkE,GAAE,GAAGF,GAAGhE,CAAC,EAAE,IAAIA,KAAKkE,GAAE,GAAGF,GAAGhE,CAAC,EAAEkE,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,CAAC,EAAE,GAAG,SAASlE,EAAE,CAAC,IAAIC,EAAED,EAAE,GAAG,OAAOkE,GAAE,GAAGjE,CAAC,EAAEiE,GAAE,GAAG,KAAKlE,CAAC,EAAEkE,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQlE,CAAC,EACxf,CAAC,EAAEA,EAAE,GAAG,EAAE0E,GAAGzE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,EAAE,GAAG,UAAU,CAACiE,GAAE,GAAG,QAAQlE,GAAGA,EAAE,CAAC,CAAC,EAAE,GAAGA,GAAG,IAAI,QAAQC,GAAG,CAACD,EAAE,UAAUK,GAAG,CAACA,EAAEA,EAAE,KAAK,IAAIC,EAAED,EAAE,IAAI,GAAGA,EAAE,cAAcA,EAAE,cAAcsE,GAAG,EAAE,CAAC,IAAIpE,GAAE2D,GAAE,GAAG7D,EAAE,EAAE,EAAEE,GAAEA,GAAE,YAAYF,EAAEA,EAAE,YAAY,EAAE6B,EAAE,0CAA0C5B,EAAE,uBAAuBD,EAAE,aAAa,qCAAqC,CAAC,MAA0BC,IAAjB,eAAmBsE,GAAG,EAA0BtE,IAAhB,cAAkB6D,GAAG9D,CAAC,EAA4BC,IAAlB,gBAAoB2D,GAAG5D,EAAE,MAAM,EAAyBC,IAAf,cAAiBD,EAAEA,EAAE,OAAOC,EAAE4D,GAAE,GAAG7D,CAAC,EAAE,OAAO6D,GAAE,GAAG7D,CAAC,EAC3f2D,GAAG1D,CAAC,EAAEoE,GAAGrE,CAAC,EAAE6D,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQ5D,CAAC,EAAE,CAAC,EAAEA,EAAE,GAAG,GAA2BA,IAAjB,eAAmB4D,GAAE,GAAG7D,EAAE,MAAM,EAAE,YAAY,CAAC,IAAI,QAAQ,CAAC,EAAqBC,IAAX,UAAaN,EAAE,OAAO,GAAGsB,GAAG,CAACtB,EAAE,IAAIA,EAAE,MAAM,EAAEC,EAAED,CAAC,GAAoBM,IAAV,QAAY,MAAM,UAAUD,EAAE,SAAS,KAAKA,EAAE,IAAI,EAA2BA,EAAE,SAAnB,eAA0BL,EAAE,YAAYK,CAAC,EAA0BC,IAAhB,cAAkBT,EAAEQ,EAAE,OAAO,EAAE,GAAGA,EAAE,IAAI,EAAOC,GAAG4B,EAAE,kCAAkC5B,CAAC,CAAC,EAAEN,EAAE,QAAQK,GAAG,CAAC,MAAA6B,EAAE,yBAAyB7B,EAAE,SAAS,IAAIA,EAAE,OAAO,KAAKA,EAAE,OAAO,EAAQA,CAAE,EAAEiB,IAAItB,EAAE,GAAG,UAAU,SAASK,EAAE,CAACL,EAAE,UAAU,CAAC,KAAKK,CAAC,CAAC,CAAC,CAAC,EACnhBL,EAAE,GAAG,QAAQ,SAASK,EAAE,CAACL,EAAE,QAAQK,CAAC,CAAC,CAAC,GAAG,IAAIH,EAAE,CAAC,EAAEC,EAAE,CAAC,SAAS,UAAU,QAAQ,UAAU,EAAEC,EAAE,IAAIA,KAAKD,EAAEN,EAAE,eAAeO,CAAC,GAAGF,EAAE,KAAKE,CAAC,EAAEJ,EAAE,YAAY,CAAC,IAAI,OAAO,SAASE,EAAE,UAAUL,EAAE,qBAAqBhB,EAAW,WAAWG,GAAE,WAAWuD,EAAE,CAAC,CAAC,CAAC,EAAE,GAAG,SAASvC,EAAE,CAAC,GAAGuB,EAAE,OAAOvB,EAAE,EAAE,QAAQ,IAAIkE,GAAE,GAAG,IAAIA,GAAE,EAAE,CAAC,EAAE,KAAKlE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,IAAIA,EAAEyB,EAAG,kCAAkC,EAAEzB,EAAE,IAAI,OAAOA,CAAC,EAAEkE,GAAE,GAAG,KAAKlE,CAAC,CAAC,EAAE,GAAG,UAAU,CAAC,OAAGkE,GAAE,GAAG,QAAR,IAAiBA,GAAE,GAAG,EAAEA,GAAE,GAAGA,GAAE,GAAG,CAAC,CAAC,GAAUA,GAAE,GAAG,IAAI,CAAC,CAAC,EAAErE,EAAE,QAAQqE,GACxe,IAAIW,GAAG7E,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EAAEA,EAAE,oBAAoB,UAAU,CAAC,IAAIG,EAAE2E,GAAG,EAAE1E,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAEX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE8E,GAAG7E,EAAEA,EAAED,CAAC,EAAE+E,GAAG9E,CAAC,CAAC,EAAE,SAASwE,GAAGzE,EAAE,CAAC,GAAGuB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,CAAC,EAAEwE,GAAGxE,CAAC,CAAC,CAACH,EAAE,iBAAiB,SAASG,EAAEC,EAAE,CAACD,EAAEgF,GAAG,MAAM,KAAK,CAAChF,EAAEC,CAAC,CAAC,EAAE8C,GAAG,EAAEmB,GAAE,GAAGlE,CAAC,EAAEiF,GAAGjF,CAAC,CAAC,EAAE,SAASkF,GAAGlF,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACV,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAEU,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACV,EAAE,EAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAEU,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACX,EAAE,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,IAAI4F,GAAG,EAAEC,GAAG,EACze,SAASC,GAAGrF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAEgD,EAAE,EAAE,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,EAAEmF,GAAGtF,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASmF,GAAGtF,EAAEC,EAAEC,EAAEC,EAAE,CAA6B,GAA5BH,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAkB,OAAO,kBAApB,IAAsC,OAAO+B,EAAE,qFAAqF,EAAE,EAAE,IAAI9B,EAAE,CAAC,EAAE,OAAGmB,GAAOnB,EAAE,SAAN,EAAoBiF,GAAGrF,EAAEC,EAAEC,EAAEC,CAAC,GAAEH,EAAE,CAAC,GAAGE,EAAE,GAAGF,EAAE,GAAGG,EAAE,GAAGC,CAAC,EAASmB,GAAGvB,EAAE,GAAG,cAAc,YAAYA,EAAEI,CAAC,EAAE,GAAG+D,GAAGnE,CAAC,EAAC,CAAC,SAASuF,GAAGvF,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAEgD,EAAE,EAAE,EAAEvE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAASsF,GAAGxF,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,EAAEC,CAAC,CAAC,CACrc,IAAIwF,GAAGzF,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEyF,GAAG,CAAC1F,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GACpf,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEuF,GAAG,CAAC3F,EAAEC,EAAEC,IAAIwF,GAAG1F,EAAEb,EAAE,EAAEc,EAAEC,CAAC,EAAE,SAAS0F,GAAG5F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,EAAEC,CAAC,CAAC,CAAC,SAAS4F,GAAG7F,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS4F,GAAG9F,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAEgD,EAAE,EAAE,EAAEvE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAAS6F,GAAG/F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,EAAE,EAAEvE,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGhG,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGjG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS+F,GAAGlG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASgG,GAAGnG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAC9d,SAASiG,GAAGpG,EAAE,CAAC,GAAGuB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,CAAC,CAAC,CAAC,SAASqG,GAAGrG,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,CAAC,CAAC,CAAC,SAASqG,GAAGtG,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIqG,GAAGvG,GAAG,CAAC,GAAG,CAACwC,GAAE,GAAG,CAAC,GAAGxC,EAAE,EAAE,CAAC+C,GAAG,EAAE,GAAG,CAACxB,EAAE0D,GAAGxC,EAAC,EAAE+B,GAAG/B,EAAC,CAAC,OAAOxC,EAAE,CAACA,aAAa8D,IAAc9D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa8D,IAAc9D,GAAV,UAAakB,EAAE,EAAElB,CAAC,CAAC,CAAC,EAAE,SAASuG,GAAGxG,EAAE,CAACA,KAAK,EAAe,OAAO,QAAQ,IAA5B,aAAiC,QAAQ,GAAGX,EAAE,EAAEW,GAAG,EAAEA,CAAC,EAAE,MAAM,KAAK4E,EAAE,EAAE5E,GAAG,IAAI,QAAQ,MAAMX,EAAE,EAAEW,GAAG,EAAE,CAAC,EAAE,CAACH,EAAE,kCAAkC2G,GAAG,SAAS5B,IAAI,CAAC,IAAI5E,EAAE2E,GAAG,EAAE3E,IAAIwG,GAAGxG,CAAC,EAAEuG,GAAG,IAAIE,GAAG,CAAC,EAAE,CAAC5G,EAAE,aAAa+E,GACpf,IAAI8B,GAAE1G,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAW2G,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAE,SAASC,EAAG7G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAE,CAAC,OAAOgB,EAAEgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAE,GAAG,CAAC,SAASuG,EAAG9G,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGiB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIyG,EAAG/G,GAAG,CAAC,IAAIC,EAAEwF,GAAGzF,CAAC,EAAE,EAAEE,EAAE8G,GAAG/G,CAAC,EAAE,OAAAC,GAAGyF,GAAG3F,EAAEE,EAAED,CAAC,EAASC,CAAC,EAAE+G,EAAG,CAAC,EAAEC,EAAG,CAAClH,EAAEC,IAAI,CAACgH,EAAG,OAAO,EAAE,IAAI/G,EAAE,IAAID,IAAI,EAAEC,EAAEf,EAAE,EAAEa,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAEgH,EAAG,KAAU/G,GAAL,IAAOb,EAAE,EAAEY,IAAI,CAAC,EAAEN,EAAG,EAAEM,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAOgH,CAAE,EAAEE,EAAGnH,GAAG,CAAC,IAAIC,EAAEmH,GAAG,EAAE,OAAApH,EAAEA,EAAE,EAAE+E,GAAG9E,CAAC,EAASD,CAAC,EACve,SAASuE,EAAEvE,EAAEC,EAAE,CAAC,IAAIC,EAAE,UAAU,OAAO,EAAEC,EAAE,UAAU,OAAOgH,EAAG,IAAI,CAAC,QAAQ/G,EAAEiH,GAAG,EAAEnH,CAAC,EAAEG,EAAED,GAAG,EAAEE,EAAE,EAAEA,EAAEJ,EAAEI,IAAI,CAAC,IAAIC,GAAEJ,EAAE,EAAEG,CAAC,EAAEX,EAAG,EAAEU,EAAEC,IAAI,CAAC,EAAEC,EAAC,CAAC,OAAO+G,GAAGtH,EAAEE,EAAEE,EAAEH,CAAC,CAAC,CAAC,CAAC,CAC3J,IAAIsH,GAAG,CAAC,EAAEC,EAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,GAAG,CAAC,IAAI1H,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IAAI,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAI,gBAAgB,EAAEjB,EAAE,IAAIA,KAAKuH,EAAYA,EAAGvH,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAEuH,EAAGvH,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEyH,GAAGxH,CAAC,CAAC,OAAOwH,EAAE,EAAEA,GACtW,SAASC,GAAG3H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAAuH,GAAG,EAAE,QAAQ,SAAStH,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAwB,IAAtBE,EAAEb,EAAE,EAAES,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEtB,EAAE,EAAEqB,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEtB,EAAE,EAAEqB,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,CAAC,SAASyH,GAAG5H,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAEuH,GAAG,EAAElI,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEb,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,CAAC,SAAS0H,EAAG7H,EAAE,CAAC,OAAOuB,EAAEgD,EAAE,GAAG,EAAEvE,CAAC,EAAE,EAAE,CAAC,SAAS8H,GAAG9H,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAEgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAC/c,SAAS4H,GAAG/H,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmB,EAAEgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAAC,IAAI4H,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,SAASC,GAAGjI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAOgD,EAAE,GAAG,EAAEvE,EAAEC,EAAEC,EAAEC,CAAC,EAAEF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEf,EAAE,EAAEU,GAAG,IAAI,CAAC,EAAEM,GAAEhB,EAAE,EAAEU,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,GAAE,EAAEA,GAAED,GAAEC,KAAI,CAAC,IAAIC,GAAEtB,EAAE,EAAEmB,EAAEE,KAAI,CAAC,EAAEE,GAAEsH,GAAGhI,CAAC,EAAMS,KAAJ,GAAYA,KAAL,KAAaT,IAAJ,EAAMiC,EAAGC,GAAGmC,GAAG3D,GAAE,CAAC,CAAC,EAAEA,GAAE,OAAO,GAAGA,GAAE,KAAKD,EAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAhB,EAAE,EAAEY,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,CAAC,IAAI8H,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGpI,EAAE,CAAC,IAAIC,EAAE,MAAMwF,GAAGzF,CAAC,EAAE,CAAC,EAAE,OAAA0F,GAAG1F,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACjf,IAAIoI,GAAG,CAACrI,EAAEC,IAAI,CAAClB,EAAE,EAAE,IAAIiB,EAAEC,IAAI,CAAC,CAAC,EAC/B,SAASqI,GAAGtI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE+C,GAAE,CAAC,IAAIhD,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAEgD,GAAE,CAAC,EAAEhD,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAAS+C,GAAEyE,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE1E,GAAEhD,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiDyH,GAAE1E,GAAEhD,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuCyH,GAAE1E,GAAEhD,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAUyH,EAAC,CAAC,SAASjI,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,GAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI+C,GAAEhD,EAAE,SAAS,EAAE0H,IAAG9B,GAAE5F,EAAE,YAAY,CAAC,EAAEoH,GAAGC,IAAIrE,EAAC,EAAE,GAAG/C,GAAEyH,GAAE1H,EAAE,QAAQ,EAAEC,IAAGyH,GAAE1H,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAGgD,GAAEhD,EAAE,SAASgD,GAAE,CAAC,GAAGhD,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA+C,GAAE,IAAI,KAAKhD,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAEgD,GAAEvD,GAAEuD,EAAC,EAAS,GAAGxD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEwD,GAAEhD,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,GAAEpB,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGd,EAAE,EAAEc,GAAG,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,GAAEoD,GAAEpD,EAAC,EAAE,EAAE,EAAEP,EAAE2D,GAAE3D,CAAC,EAAEO,GAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WACxf,MAAM,KAAK,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,MAAKD,GAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,GAAEC,EAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,GAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GACzfF,GAAEE,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,GAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,GAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE+C,GAAE,EAAEA,IAAGhD,EAAE,GAAG,EAAEC,KAAI2F,GAAE5F,EAAE,GAAG,IAAI,EAAEoH,GAAGC,IAAIrE,IAAG,EAAE,CAAC,OAAOzD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GACnf,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ+C,IAAGhD,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAKgD,IAAH,GAASA,IAAH,GAAM4C,GAAE5F,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI+C,IAAGhD,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAMgD,IAAH,GAASA,IAAH,GAAM4C,GAAE5F,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,MAAKD,GAAEP,EAAE,SAASQ,EAAC,IACrgBR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,GAAEC,EAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,GAAE0H,GAAGlI,CAAC,EAAKQ,GAAE,OAAOT,EAAS,GAAEoI,GAAG3H,GAAEV,CAAC,EAASU,GAAE,OAAO,EAAC,CAAC,SAAS+H,GAAGzI,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACoC,GAAEpC,CAAC,CAAC,CAAC,CAAC,SAASyI,GAAG1I,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACuI,GAAG,KAAKxI,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQoC,KAAImG,GAAG,IAAI,IAAIxI,GAAGkC,GAAE,EAAExB,IAAO+H,KAAJ,GAAWD,GAAG,SAAP,IAAgBC,GAAE,EAAE9F,IAAI,EAAE2F,GAAGI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAEzI,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI2I,GAAE,EAAE/H,GAAE,KAAKiI,GAAG,EAAEH,GAAG,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC7e,SAASnI,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACiJ,GAAG,CAAC,QAAQlJ,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASmJ,IAAI,CAAC,IAAIpJ,EAAEgH,GAAG,KAAK,EAAE/G,EAAED,EAAE,GAAGT,EAAE,EAAES,GAAG,IAAI,CAAC,EAAEC,EAAEV,EAAE,EAAES,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAE0I,GAAG,CAAC,EAAE,IAAIzI,EAAE6I,GAAG9I,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAE+I,KAAKF,GAAG9I,CAAC,EAAEC,EAAE8I,GAAG9I,CAAC,EAAED,GAAGA,EAAEC,EAAEb,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEC,EAASD,CAAC,CAAC,SAASqJ,IAAI,CAAC,IAAIrJ,EAAEX,EAAE,EAAEwB,GAAE,GAAG,IAAI,CAAC,EAAE,OAAAb,EAAEsC,EAAE0G,GAAGhJ,CAAC,CAAC,EAAE,EAAE8C,GAAU9C,EAAE,CAAC,CACtS,SAASsJ,GAAGtJ,EAAE,CAAC,GAAG,CAACwC,GAAE,CAAC,GAAOoG,KAAJ,EAAM,CAAC,IAAI3I,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACqC,KAAIsG,GAAG3I,EAAEF,EAAE,GAAGC,GAAG,CAAC0I,GAAE,EAAEH,GAAG,IAAIc,GAAG1I,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,EAAEiJ,GAAG,CAAC,OAAO9I,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAE4I,GAAG5I,IAAI4I,GAAG,MAAM/I,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI2I,GAAE,EAAE/H,GAAEuI,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAG,IAAIe,GAAG3I,EAAC,CAAC,EAAE,MAAU+H,KAAJ,GAAOA,GAAE,EAAEH,GAAGgB,EAAE,EAAEC,GAAG7I,EAAC,EAAEA,GAAE,KAAKsI,GAAG,QAAQhJ,GAAGoG,GAAGpG,CAAC,CAAC,GAAGkC,GAAE,kBAAkBuG,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAC/d,SAASa,GAAG3J,EAAE,CAAC,OAAOsJ,GAAGrJ,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CAACiE,GAAE,GAAG,EAChD,IAAI0F,GAAG,CAAC,KAAKtF,GAAGG,GAAGY,GAAGE,GAAGC,GAAGI,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGO,EAAGC,EAAGa,GAAGC,GAAGC,EAAGC,GAAGC,GAAGE,EAAE,EAAE4B,GAAG,CAAC,EAAE,SAAS7J,EAAEC,EAAEC,EAAE,CAAC,OAAOyJ,GAAG,SAAS,CAAC,MAAM9J,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIkF,GAAGlF,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEiF,GAAGnF,EAAEoF,KAAWD,EAAG,EAAE,EAAE,SAASnF,EAAE,CAAC8J,GAAG9J,IAAI,EAAE,CAACqB,EAAE,EAAE,CAACD,EAAG,OAAO,EAAE,EAAE8C,GAAE,GAAG,CAAC,EAAE,EAAE,SAASlE,EAAE,CAACA,KAAK,EAAEuB,EAAE,YAAY,CAAC,IAAI,gBAAgB,OAAOvB,CAAC,CAAC,EAAEiE,GAAGjE,CAAC,CAAC,EAAE,EAAEsF,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEI,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAE,IAAI,GAAG,EAAE,SAAStG,EAAEC,EAAE,CAACD,KAAK,EAAEA,GAAGC,IAAI,EAAE,WAAW,IAAI2E,GAAG,CAAC,EAAErD,EAAE,YAAY,CAAC,aAAavB,EAC5f,IAAI,cAAc,CAAC,GAAGA,EAAEkE,GAAE,GAAGlE,CAAC,IAAIA,EAAE,YAAY,CAAC,IAAI,cAAc,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,EAAE,EAAE,EAAEwG,GAAG,EAAE,SAASxG,EAAE,CAACsB,GAAG4C,GAAE,GAAGlE,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEX,EAAE,EAAEa,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEA,GAAGA,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAC3f,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEX,EAAE,EAAEa,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEX,EAAE,EAAEa,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEC,GAAGyG,GAAE1G,EAAE,YAAY,CAAC,EAAE2G,GAAGC,IAAI5G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEX,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAED,EAAEZ,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EACrf,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEA,GAAGC,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,EAAEZ,EAAE,EAAEa,EAAE,IAAI,IAAI,CAAC,EAAEF,CAAC,EAAE,EAAE,SAASA,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEX,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEb,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAAEG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEb,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAClf,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGd,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEC,GAAGwG,GAAEzG,EAAE,YAAY,CAAC,EAAE0G,GAAGC,IAAI3G,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEE,EAAEb,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEZ,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEZ,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAAE,IAAW8J,IAAIpG,GAAE3D,EAAE,GAAG,CAAC,KAAK,IAAI2D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE3D,IAAI,CAAC,EAAE,EAAE6G,EAAG,EAAEC,EACpf,EAAE,SAAS9G,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEM,GAAE,CAAC,OAAOA,GAAEA,GAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,GAAE,CAAC,EAAE,KAAK,CAACT,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,EAAE,kBAAkB,EAAEE,GAAE,KAAK,IAAIJ,EAAEG,EAAC,EAAEhB,EAAE,EAAES,GAAG,IAAI,CAAC,EAAE,GAAGQ,GAAEnB,EAAE,EAAEY,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAE+G,EAAG/G,CAAC,EAAEC,EAAE8G,EAAG9G,CAAC,EAAEM,GAAEH,GAAGb,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAEF,EAAET,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAED,IAAIV,EAAE,EAAEW,GAAG,IAAI,CAAC,EAAED,EAAEV,EAAE,EAAEW,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACqC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASrC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEiH,EAAGjH,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EACtfC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAEiH,EAAGjH,IAAI,EAAEC,IAAI,CAAC,EAAS0D,GAAG5D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,IAAI,CAAC,MAAA6C,IAAI,EAAO,QAAS,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,WAAW,YAAY,IAAI,EAAE,EAAE,UAAU,CAAC,OAAOxB,EAAE,cAAc,KAAK,EAAE,OAAO,UAAU,mBAAmB,EAAE,EAAE,SAAStB,EAAEC,EAAEC,EAAEC,EAAE,CAAmC,IAAlC+D,GAAE,GAAGjE,IAAI,EAAEsH,GAAG,OAAOrH,EAAED,EAAEE,IAAI,GAAG,EAAMA,EAAE,EAAEA,EAAED,EAAEC,IAAIoH,GAAGpH,CAAC,EAAER,EAAG,EAAEM,EAAEE,IAAI,CAAC,EAAE,OAAO,EAAEH,EAAE4D,GAAG,CAAC5D,EAAE,CAAC,EAAE4J,GAAG5J,CAAC,GAAG,MAAM,KAAKuH,EAAE,CAAC,EAAE,EAAE,SAASvH,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEd,EAAE,EAAE,OAAO,GAAGa,GAAGC,GAAG,WAAWD,EAAE,MAAM,GAAG,QAAQE,EACxf,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KAAKD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAEnB,GAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,GAAE,KAAKoB,CAAC,EAAElB,GAAE,EAAE,IAAImB,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAEsH,GAAG,EAAEC,GAAG,EAAEpD,GAAG,EAAEqD,EAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEE,GAAG,EAAEjJ,IAAGa,EAAE,WAAW,EAAEyI,GAAG,EAAE,SAAStI,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOmI,GAAGtI,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,GACrW,UAAU,CAAC,SAASH,EAAEE,EAAEC,EAAE,CAAC,OAAAD,EAAEA,EAAE,QAAQA,EAAEwI,GAAGxI,CAAC,EAAEoC,EAAEpC,EAAE8J,GAAG9J,CAAC,EAAEgE,GAAE,GAAG,KAAK5B,EAAE,EAAE,EAAEM,GAAG,QAAQN,EAAE,CAAC,EAAEC,GAAGpC,EAAEiD,GAAG,EAASlD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE4J,EAAE,EAAO,GAAL1G,GAAG,EAAKtD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAACgC,EAAE,sDAAsDhC,CAAC,EAAEH,EAAEG,CAAC,CAAC,CAAC,OAAAwD,GAAGzD,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,SAASA,EAAE,MAAM,CAAC,CAAC,EAAE,MAAMH,CAAC,EAAQ,CAAC,CAAC,GAAG,EAAEF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASyC,EAAE,GAAGtC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiByC,EAAE,GAAGtC,EAAEC,CAAC,EAC7ZJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,MAAKZ,EAAE,yBAAyByC,EAAE,GAAGtC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEC,EAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4ByC,EAAE,IAAItC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6ByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0ByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0ByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAC7dL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiByC,EAAE,IAAItC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkByC,EAAE,IAAItC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASyC,EAAE,IAAItC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkByC,EAAE,IAAItC,CAAC,EAC5dH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsByC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcyC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAeyC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmByC,EAAE,IAAItC,CAAC,EACxeH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,MAAKV,EAAE,QAAQyC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiByC,EAAE,IAAItC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYyC,EAAE,IAAItC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiByC,EAAE,IAAItC,CAAC,EAAE,IAAI2E,GAAG9E,EAAE,cAAc,KAAK8E,GAAG9E,EAAE,cAAcyC,EAAE,IAAI,EAAE0E,GAAGnH,EAAE,QAAQG,IAAIgH,GAAGnH,EAAE,QAAQyC,EAAE,IAAItC,CAAC,EAAE0J,GAAG7J,EAAE,MAAMG,IAAI0J,GAAG7J,EAAE,MAAMyC,EAAE,IAAItC,CAAC,EAAEH,EAAE,sBAAsB,KAAKA,EAAE,sBAAsByC,EAAE,IAAI,EAC7d,IAAIwH,GAAGjK,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKyJ,GAAGjK,EAAE,yBAAyByC,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,4BAA4B,KAAKA,EAAE,4BAA4ByC,EAAE,IAAI,EAC1K,IAAIgF,GAAG,CAACtH,EAAEC,EAAEC,EAAEC,KAAKmH,GAAGhF,EAAE,IAAItC,EAAEC,EAAEC,EAAEC,CAAC,EAAEuE,GAAG1E,IAAI0E,GAAGpC,EAAE,IAAItC,CAAC,EAAEiF,GAAGpF,EAAE,yBAAyBG,IAAIiF,GAAGpF,EAAE,yBAAyByC,EAAE,IAAItC,CAAC,EAAEyG,GAAG5G,EAAE,2BAA2B,KAAK4G,GAAG5G,EAAE,2BAA2ByC,EAAE,IAAI,EAAEyH,GAAG/J,IAAI+J,GAAGzH,EAAE,IAAItC,CAAC,EAAE8E,GAAG,CAAC9E,EAAEC,KAAK6E,GAAGxC,EAAE,IAAItC,EAAEC,CAAC,EAAEmH,GAAG,KAAKA,GAAG9E,EAAE,IAAI,EAAEyC,GAAG/E,IAAI+E,GAAGzC,EAAE,IAAItC,CAAC,EAAEqH,GAAGrH,IAAIqH,GAAG/E,EAAE,IAAItC,CAAC,EAAEgF,GAAGnF,EAAE,WAAW,CAACG,EAAEC,KAAK+E,GAAGnF,EAAE,WAAWyC,EAAE,IAAItC,EAAEC,CAAC,EAAEuJ,GAAGxJ,IAAIwJ,GAAGlH,EAAE,IAAItC,CAAC,EAAE6I,GAAG,KAAKA,GAAGvG,EAAE,IAAI,EAAEiH,GAAGvJ,IAAIuJ,GAAGjH,EAAE,IAAItC,CAAC,EAAEyJ,GAAG,KAAKA,GAAGnH,EAAE,IAAI,EAAEzC,EAAE,eAAe,OAAOA,EAAE,cAAc,OAC1d,SAASmK,GAAGhK,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,aAAaC,EAAED,EAAE,YAAY,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,iBAAiBkD,GAAGlD,EAAE,WAAWb,GAAEa,EAAE,WAAWwH,GAAGxH,EAAE,UAAUuH,GAAGvH,EAAE,aAAakF,GAAGlF,EAAE,aAAagE,GAAEhE,EAAE,aAAa8F,GAAG9F,EAAE,gBAAgB4F,GAAG5F,EAAE,WAAWkE,GAAGlE,EAAE,QAAQqE,GAAE,IAAI+F,GAAG/G,GAAE,SAASgH,GAAI,CAACD,IAAIE,GAAG,EAAEF,KAAK/G,GAAEgH,EAAG,EAC/b,SAASC,IAAI,CAAC,SAASnK,GAAG,CAAC,GAAG,CAACiK,KAAKA,GAAG,GAAGpK,EAAE,UAAU,GAAG,CAAC2C,MAAIjB,GAAGsD,GAAGjC,EAAE,EAAE9C,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAK,CAAC0B,GAAE,CAAC,GAAG1B,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAEgD,GAAG,QAAQ5C,CAAC,CAAC,CAAC4E,GAAGhC,EAAE,CAAC,CAAE,CAAC,GAAG,EAAE,EAAEG,IAAG,GAAGzB,EAAEzB,EAAGD,CAAC,EAAE0B,GAAGsD,GAAGjC,EAAE,EAAE,YAAY/C,CAAC,MAAM,CAAC,GAAGA,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQ8C,GAAG,QAAQ9C,EAAE,OAAO,MAAM,CAAC,EAAEgF,GAAGlC,EAAE,EAAE,EAAEK,KAAInD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EACpiB,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAAC,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAAsK,GAAG,EAGzHrL,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAe,IC9FlC,IAAAwL,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,kiFCAA,IAUIC,GASEC,GAMFC,GACAC,GACAC,GACAC,GAEEC,GAwBAC,GAyBAC,GAWOC,GA+GAC,GAzMbC,GAAAC,EAAA,kBAeEZ,GACmE,KAG/DC,GAE2B,KAK7BE,GAAc,GACdC,GAAe,GACfC,GAAU,GAERC,GAAyB,IAAe,CAC5C,GAAI,CAEF,OAAI,OAAO,kBAAsB,IACxB,IAKL,OAAO,eAAmB,KAC5B,IAAI,eAAe,EAAE,MAAM,YAAY,IAAI,kBAAkB,CAAC,CAAC,EAK1D,YAAY,SAAS,IAAI,WAAW,CACzC,EAAG,GAAI,IAAK,IAAK,EAAG,EAAI,EAAI,EAAG,EAAG,EAAG,EAAI,GAAI,EAAK,EAAI,EAAG,EAAG,EAAI,EAAG,EACnE,EAAG,EAAI,EAAK,EAAK,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAI,IAAK,GAAI,EAAG,EAAG,GAAI,EAClE,CAAC,CAAC,EACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,IAAe,CACrC,GAAI,CAeF,OAAO,YAAY,SAAS,IAAI,WAAW,CACzC,EAAK,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAK,GAAK,EAAG,GAAI,EACvF,IAAK,GAAI,IAAK,GAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAI,IAAK,IAAK,EAAG,GAAI,EACzF,CAAC,CAAC,CACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,CAACK,EAAkBC,IACrCD,EAIKC,EAAa,8BAAgC,qBAE7CA,EAAa,yBAA2B,gBAItCL,GAAwB,MAAMM,GAA+C,CACxF,GAAIZ,GACF,OAAO,QAAQ,QAAQ,EAEzB,GAAIC,GACF,MAAM,IAAI,MAAM,uDAAyD,EAE3E,GAAIC,GACF,MAAM,IAAI,MAAM,oDAAsD,EAGxED,GAAe,GAGf,IAAMY,EAAUD,EAAM,YAChBE,EAAaF,EAAM,WACnBG,EAAOH,EAAM,KAEbD,EAAaG,EAAa,GAAKX,GAAuB,EACtDO,EAAUK,GAAQX,GAAgB,EAElCY,EAAYJ,EAAM,UAClBK,EAAqB,OAAOD,GAAc,SAAWA,EAAY,OACjEE,EAAeb,GAAgBK,EAASC,CAAU,EAClDQ,EAAmB,OAAOH,GAAc,SAAWA,EAAUE,CAAY,EAAI,OAE/EE,EAAY,GAEVC,EAA8B,CAAC,EA8ErC,GA3EIR,EAAU,GACZQ,EAAM,KAAK,IAAI,QAASC,GAAY,CAClC,WAAW,IAAM,CACfF,EAAY,GACZE,EAAQ,CACV,EAAGT,CAAO,CACZ,CAAC,CAAC,EAIJQ,EAAM,KAAK,IAAI,QAAQ,CAACC,EAASC,IAAW,CAC1C,IAAMC,EAAUb,EAAab,GAAyBD,GAChD4B,EAAiC,CACrC,WAAY,CAACC,EAAkBC,IAA4B,CACzD,GAAuChB,GAAce,EAAS,SAAS,YAAY,GAC/E,OAAO,KAAS,IAClB,OAAO,IAAI,gBAAgB,IAAI,KAC3B,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAGhC,GAAIA,EAAS,SAAS,OAAO,EAAG,CAC9B,GAAIP,EACF,OAAOA,EAGT,IAAMS,EAASX,GAAsBU,EAGnC,OAAIT,IAAiB,qBACZU,EAAS,0BACPV,IAAiB,8BACnBU,EAAS,mCAIbA,EAASV,CAClB,CAEA,OAAOS,EAAkBD,CAC3B,CACF,EAEA,GAAuCf,EAErC,GADAc,EAAO,WAAaX,EAChB,OAAO,KAAS,IAClBW,EAAO,oBAA2B,SAAK,UAAW,sBAAsB,MACnE,CACL,IAAMI,EAAmB,uBAAuBL,EAAQ,SAAS,CAAC,IAClEC,EAAO,oBAAsB,IAAI,KAAK,CAACI,CAAgB,EAAG,CAAC,KAAM,iBAAiB,CAAC,CACrF,CAGFL,EAAQC,CAAM,EAAE,KAEZK,GAAU,CACR7B,GAAe,GACfD,GAAc,GACdD,GAAO+B,EACPR,EAAQ,CACV,EAECS,GAAS,CACR9B,GAAe,GACfC,GAAU,GACVqB,EAAOQ,CAAI,CACb,CAAC,CACP,CAAC,CAAC,EAEF,MAAM,QAAQ,KAAKV,CAAK,EAEpBD,EACF,MAAM,IAAI,MAAM,2DAA2DP,CAAO,IAAI,CAE1F,EAEaN,GAAc,IAAqB,CAC9C,GAAIP,IAAeD,GACjB,OAAOA,GAGT,MAAM,IAAI,MAAM,qCAAqC,CACvD,IC/MA,IAKaiC,GAeAC,GA6BAC,GAjDbC,GAAAC,EAAA,kBAGAC,KAEaL,GAAkB,CAACM,EAAcC,IAA6B,CACzE,IAAMC,EAAOC,GAAY,EAEnBC,EAAaF,EAAK,gBAAgBF,CAAI,EAAI,EAC1CK,EAAaH,EAAK,QAAQE,CAAU,EAC1C,OAAAF,EAAK,aAAaF,EAAMK,EAAYD,CAAU,EAC9CH,EAAO,KAAKI,CAAU,EAEfA,CACT,EAMaV,GACT,CAACW,EAAkCC,EAAgBC,EAClDC,IAAuC,CACtC,GAAI,OAAOH,GAAW,UAAYA,IAAY,KAAM,CAClD,GAAIE,EAAK,IAAIF,CAAO,EAClB,MAAM,IAAI,MAAM,+BAA+B,EAE/CE,EAAK,IAAIF,CAAO,CAEpB,CAEA,OAAO,QAAQA,CAAO,EAAE,QAAQ,CAAC,CAACI,EAAKC,CAAK,IAAM,CAChD,IAAMC,EAAQL,EAAUA,EAASG,EAAMA,EACvC,GAAI,OAAOC,GAAU,SACnBhB,GAAoBgB,EAAkCC,EAAO,IAAKJ,EAAMC,CAAO,UACtE,OAAOE,GAAU,UAAY,OAAOA,GAAU,SACvDF,EAAQG,EAAMD,EAAM,SAAS,CAAC,UACrB,OAAOA,GAAU,UAC1BF,EAAQG,EAAOD,EAAS,IAAM,GAAG,MAEjC,OAAM,IAAI,MAAM,mCAAmC,OAAOA,CAAK,EAAE,CAErE,CAAC,CACH,EAMSf,GAAkBiB,GAA0B,CACvD,IAAMX,EAAOC,GAAY,EAEnBW,EAAQZ,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMa,EAAeb,EAAK,WAAW,CAAC,EACtCA,EAAK,iBAAiBa,EAAcA,EAAe,CAAC,EACpD,IAAMC,EAAYd,EAAK,OAAOa,EAAe,CAAC,EACxCE,EAAsBf,EAAK,QAAQa,EAAe,EAAI,CAAC,EACvDG,EAAeD,EAAsBf,EAAK,aAAae,CAAmB,EAAI,GACpF,MAAM,IAAI,MAAM,GAAGJ,CAAO,gBAAgBG,CAAS,oBAAoBE,CAAY,EAAE,CACvF,QAAE,CACAhB,EAAK,aAAaY,CAAK,CACzB,CACF,IC/DA,IAQaK,GARbC,GAAAC,EAAA,kBAKAC,KACAC,KAEaJ,GAAiBK,GAA6D,CACzF,IAAMC,EAAOC,GAAY,EACrBC,EAAmB,EACjBC,EAAmB,CAAC,EAEpBC,EAA0CL,GAAW,CAAC,EAE5D,GAAI,CACF,GAAIA,GAAS,mBAAqB,OAChCK,EAAW,iBAAmB,UAE5B,OAAOL,EAAQ,kBAAqB,UAAY,CAAC,OAAO,UAAUA,EAAQ,gBAAgB,GAC1FA,EAAQ,iBAAmB,GAAKA,EAAQ,iBAAmB,EAC7D,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,gBAAgB,EAAE,EAGjF,GAAIA,GAAS,oBAAsB,OACjCK,EAAW,kBAAoB,UACtB,OAAOL,EAAQ,mBAAsB,UAAY,CAAC,OAAO,UAAUA,EAAQ,iBAAiB,EACrG,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,iBAAiB,EAAE,EAG9EA,GAAS,YAAc,SACzBK,EAAW,UAAY,IAGzB,IAAIC,EAAgB,EACpB,OAAIN,GAAS,MAAQ,SACnBM,EAAgBC,GAAgBP,EAAQ,IAAKI,CAAM,GAGrDD,EAAmBF,EAAK,qBACpBI,EAAW,iBAAmBA,EAAW,kBAAoB,CAAC,CAACA,EAAW,UAAYC,CAAa,EACnGH,IAAqB,GACvBK,GAAe,2BAA4B,EAGzCR,GAAS,QAAU,QACrBS,GAAoBT,EAAQ,MAAO,GAAI,IAAI,QAAoC,CAACU,EAAKC,IAAU,CAC7F,IAAMC,EAAgBL,GAAgBG,EAAKN,CAAM,EAC3CS,EAAkBN,GAAgBI,EAAOP,CAAM,EAEjDH,EAAK,sBAAsBE,EAAkBS,EAAeC,CAAe,IAAM,GACnFL,GAAe,iCAAiCE,CAAG,MAAMC,CAAK,GAAG,CAErE,CAAC,EAGI,CAACR,EAAkBC,CAAM,CAClC,OAASU,EAAG,CACV,MAAIX,IAAqB,GACvBF,EAAK,sBAAsBE,CAAgB,EAE7CC,EAAO,QAAQW,GAASd,EAAK,MAAMc,CAAK,CAAC,EACnCD,CACR,CACF,IChEA,IAQME,GAeAC,GAWAC,GAoBAC,GA+EOC,GArIbC,GAAAC,EAAA,kBAKAC,KACAC,KAEMR,GAA4BS,GAAmD,CACnF,OAAQA,EAAwB,CAC9B,IAAK,WACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,IAAK,MACH,MAAO,IACT,QACE,MAAM,IAAI,MAAM,yCAAyCA,CAAsB,EAAE,CACrF,CACF,EAEMR,GAAoBS,GAAmD,CAC3E,OAAQA,EAAe,CACrB,IAAK,aACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,+BAA+BA,CAAa,EAAE,CAClE,CACF,EAEMR,GAAwBS,GAAmD,CAC1EA,EAAQ,QACXA,EAAQ,MAAQ,CAAC,GAEdA,EAAQ,MAAM,UACjBA,EAAQ,MAAM,QAAU,CAAC,GAE3B,IAAMC,EAAUD,EAAQ,MAAM,QACzBC,EAAQ,+BAEXA,EAAQ,6BAA+B,KAIrCD,EAAQ,oBACRA,EAAQ,mBAAmB,KAAKE,IAAO,OAAOA,GAAO,SAAWA,EAAKA,EAAG,QAAU,QAAQ,IAC5FF,EAAQ,iBAAmB,GAE/B,EAEMR,GACF,CAACW,EAA8BC,EAC9BC,IAA2B,CAC1B,QAAWH,KAAME,EAAoB,CACnC,IAAIE,EAAS,OAAOJ,GAAO,SAAWA,EAAKA,EAAG,KAG9C,OAAQI,EAAQ,CACd,IAAK,UACHA,EAAS,UACT,MACF,IAAK,QAEH,GADAA,EAAS,QACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMK,EAAeL,EACrB,GAAIK,GAAc,WAAY,CAC5B,IAAMC,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBF,EAAa,WAAYF,CAAM,EACnEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,WAAY,CAC5B,IAAIM,EAAaN,EAAa,YAE1B,OAAOM,GAAc,UAAY,CAAC,OAAO,UAAUA,CAAU,GAAKA,EAAa,KACjFA,EAAa,GAEf,IAAML,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBI,EAAW,SAAS,EAAGR,CAAM,EACjEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,gBAAiB,CACjC,IAAMC,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBF,EAAa,gBAAiBF,CAAM,EACxEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDL,EAAa,eAAe,GAAG,CAEhG,CACF,CACA,MACF,IAAK,SAEH,GADAD,EAAS,KACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMY,EAAgBZ,EACtB,GAAIY,GAAe,gBAAiB,CAClC,GAAIA,EAAc,kBAAoB,QAAUA,EAAc,kBAAoB,OAChF,MAAM,IAAI,MAAM,oDAAoDA,EAAc,eAAe,EAAE,EAErG,IAAMN,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBK,EAAc,gBAAiBT,CAAM,EACzEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDE,EAAc,eAAe,GAAG,CAEjG,CACF,CACA,MACF,IAAK,OACL,IAAK,MACH,SACF,QACE,MAAM,IAAI,MAAM,qCAAqCR,CAAM,EAAE,CACjE,CAEA,IAAMS,EAAmBN,GAAgBH,EAAQD,CAAM,EACnDM,GAAY,EAAE,4BAA4BR,EAAsBY,CAAgB,IAAM,GACxFH,GAAe,oCAAoCN,CAAM,GAAG,CAEhE,CACF,EAESb,GAAqBO,GAAkE,CAClG,IAAMgB,EAAOL,GAAY,EACrBR,EAAuB,EACrBE,EAAmB,CAAC,EAEpBY,EAAkDjB,GAAW,CAAC,EACpET,GAAqB0B,CAAc,EAEnC,GAAI,CACF,IAAMnB,EAAyBT,GAAyB4B,EAAe,wBAA0B,KAAK,EAChGlB,EAAgBT,GAAiB2B,EAAe,eAAiB,YAAY,EAC7EC,EACF,OAAOD,EAAe,OAAU,SAAWR,GAAgBQ,EAAe,MAAOZ,CAAM,EAAI,EAEzFc,EAAmBF,EAAe,kBAAoB,EAC5D,GAAI,CAAC,OAAO,UAAUE,CAAgB,GAAKA,EAAmB,GAAKA,EAAmB,EACpF,MAAM,IAAI,MAAM,qCAAqCA,CAAgB,EAAE,EAGzE,IAAMC,EAAoBH,EAAe,mBAAqB,EAC9D,GAAI,CAAC,OAAO,UAAUG,CAAiB,GAAKA,EAAoB,GAAKA,EAAoB,EACvF,MAAM,IAAI,MAAM,qCAAqCA,CAAiB,EAAE,EAG1E,IAAMC,EAA+B,OAAOJ,EAAe,wBAA2B,SAClFR,GAAgBQ,EAAe,uBAAwBZ,CAAM,EAC7D,EAcJ,GAZAF,EAAuBa,EAAK,yBACxBlB,EAAwB,CAAC,CAACmB,EAAe,kBAAmB,CAAC,CAACA,EAAe,iBAAkBlB,EAC/F,CAAC,CAACkB,EAAe,gBAAiB,EAAGC,EAAiBC,EAAkBC,EACxEC,CAA4B,EAC5BlB,IAAyB,GAC3BS,GAAe,+BAAgC,EAG7CK,EAAe,oBACjBzB,GAAsBW,EAAsBc,EAAe,mBAAoBZ,CAAM,EAGnFY,EAAe,uBACjB,OAAW,CAACK,EAAMC,CAAK,IAAK,OAAO,QAAQN,EAAe,sBAAsB,EAAG,CACjF,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,MAAM,kDAAkDA,CAAI,EAAE,EAE1E,GAAI,OAAOC,GAAU,UAAY,CAAC,OAAO,UAAUA,CAAK,GAAKA,EAAQ,EACnE,MAAM,IAAI,MAAM,iEAAiEA,CAAK,EAAE,EAE1F,IAAMC,EAAaf,GAAgBa,EAAMjB,CAAM,EAC3CW,EAAK,6BAA6Bb,EAAsBqB,EAAYD,CAAK,IAAM,GACjFX,GAAe,wCAAwCU,CAAI,MAAMC,CAAK,GAAG,CAE7E,CAGF,OAAIN,EAAe,QAAU,QAC3BQ,GAAoBR,EAAe,MAAO,GAAI,IAAI,QAAoC,CAACS,EAAKH,IAAU,CACpG,IAAMf,EAAgBC,GAAgBiB,EAAKrB,CAAM,EAC3CK,EAAkBD,GAAgBc,EAAOlB,CAAM,EAEjDW,EAAK,0BAA0Bb,EAAsBK,EAAeE,CAAe,IAAM,GAC3FE,GAAe,qCAAqCc,CAAG,MAAMH,CAAK,GAAG,CAEzE,CAAC,EAGI,CAACpB,EAAsBE,CAAM,CACtC,OAASsB,EAAG,CACV,MAAIxB,IAAyB,GAC3Ba,EAAK,0BAA0Bb,CAAoB,EAErDE,EAAO,QAAQuB,GAASZ,EAAK,MAAMY,CAAK,CAAC,EACnCD,CACR,CACF,IC/MA,IAiCaE,GAqCAC,GAsCAC,GAMAC,GAoCAC,GAoBAC,GAMAC,GAhLbC,GAAAC,EAAA,kBAiCaR,GAA8BS,GAA2B,CACpE,OAAQA,EAAM,CACZ,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,UACH,MAAO,IACT,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,IACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,CACpD,CACF,EAKaR,GAA8BS,GAAqC,CAC9E,OAAQA,EAAW,CACjB,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,UACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAS,EAAE,CACzD,CACF,EAMaR,GAAwBS,GACpB,CAAC,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,OAAW,MAAS,EAAEA,CAAQ,EAKxGR,GAAqCM,GAEoD,CAChG,OAAQA,EAAM,CACZ,IAAK,UACH,OAAO,YACT,IAAK,UACH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,WACT,IAAK,UACH,OAAO,aACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,cACT,IAAK,SACH,OAAO,eACT,QACE,MAAM,IAAI,MAAM,qBAAqBA,CAAI,EAAE,CAC/C,CACF,EAKSL,GAAwBQ,GAAkE,CACrG,OAAQA,EAAU,CAChB,IAAK,UACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,EAKaP,GAA4BI,GAAyDA,IAAS,WACvGA,IAAS,SAAWA,IAAS,SAAWA,IAAS,QAAUA,IAAS,WAAaA,IAAS,SAKjFH,GAA4BO,GAA0C,CACjF,OAAQA,EAAU,CAChB,IAAK,OACH,MAAO,GACT,IAAK,MACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,IC/LA,IAYMC,GAEAC,GAKFC,GACAC,GAESC,GAQAC,GAWAC,GAzCbC,GAAAC,EAAA,kBAKAC,KAOMT,GAAiB,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAEzCC,GAAQ,CAACS,EAAeC,IAA0B,CAEtD,QAAQ,IAAI,IAAIX,GAAeU,CAAK,CAAC,IAAI,IAAI,KAAK,EAAE,YAAY,CAAC,IAAIC,CAAO,EAAE,CAChF,EAKaP,GAAkB,CAACQ,EAA2BC,IAA0B,CACnFX,GAAiBU,EACjBT,GAAQU,CACV,EAKaR,GAAM,CAACS,EAAoBC,IAAuB,CAC7D,IAAMC,EAAeC,GAAqBH,CAAQ,EAC5CI,EAAcD,GAAqBf,EAAc,EACnDc,GAAgBE,GAClBjB,GAAMe,EAAc,OAAOD,GAAQ,WAAaA,EAAI,EAAIA,CAAG,CAE/D,EAKaT,GAAwB,IAAIa,IAAiC,CACpEhB,IACFE,GAAI,GAAGc,CAAI,CAEf,IC7CA,IAOaC,GAPbC,GAAAC,EAAA,kBAKAC,KAEaH,GAAa,CAACI,EAAyBC,IAE5C,IAAKC,GAAkCD,CAAI,GAAGD,CAAU,ICThE,IAAAG,GAAAC,EAAA,oBCAA,IA2EMC,GAEFC,GACEC,GAYOC,GAkCPC,GAoOOC,GAhWbC,GAAAC,EAAA,kBAIAC,KAEAC,KAqEMT,GAA4BU,GAAiB,KAAK,KAAKA,EAAO,EAAE,EAAI,GAEtET,GAAO,EACLC,GAAqB,IAAMD,KAYpBE,GACT,MAAMQ,EAAwBC,EAAsBC,EAAsBC,IAC/C,CACrB,IAAMC,EAAaf,GAAyBa,CAAY,EAClDG,EAAgBL,EAAQ,OAAO,aAEjC,CAAC,KAAMI,EAAY,MAAO,eAAe,SAAW,eAAe,QAAQ,CAAC,EAChF,GAAI,CACF,IAAME,EAAiBN,EAAQ,kBAAkB,EACjDA,EAAQ,eAAe,EACvBM,EAAe,mBACXL,EAA+B,EAAuBI,EACtD,EAA4BD,CAChC,EACAJ,EAAQ,MAAM,EAEd,MAAMK,EAAc,SAAS,WAAW,IAAI,EAE5C,IAAME,EAAcF,EAAc,eAAe,EACjD,GAAIF,EAAiB,CAEnB,IAAMK,EAAeL,EAAgB,EACrC,OAAAK,EAAa,IAAI,IAAI,WAAWD,EAAa,EAAGL,CAAY,CAAC,EACtDM,CACT,KAGE,QAAO,IAAI,WAAWD,EAAY,MAAM,EAAGL,CAAY,CAAC,CAE5D,QAAE,CACAG,EAAc,QAAQ,CACxB,CACF,EAEFZ,GAAN,KAAmD,CAiBjD,YAAoBO,EAAwB,CAAxB,aAAAA,EAClB,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,IAC9B,KAAK,2BAA6B,CAAC,EACnC,KAAK,eAAiB,CAAC,EACvB,KAAK,gBAAkB,IAAI,GAC7B,CAEA,OAAOS,EAAeC,EAAwB,CAC5C,IAAMC,EAAiBD,EAAK,OACtBE,EAAYF,EAAK,WACjBG,EAAYH,EAAK,WACjBX,EAAOV,GAAyBwB,CAAS,EAGzCC,EAAe,KAAK,aAAa,IAAIL,CAAE,EAC7C,GAAI,CAACK,EACH,MAAM,IAAI,MAAM,uCAAuC,EAEzD,GAAIA,EAAa,eAAiBD,EAChC,MAAM,IAAI,MAAM,yCAAyCC,EAAa,YAAY,eAAeD,CAAS,EAAE,EAI9G,IAAME,EAAwB,KAAK,QAAQ,OAAO,aAE9C,CAAC,iBAAkB,GAAM,KAAAhB,EAAM,MAAO,eAAe,UAAY,eAAe,QAAQ,CAAC,EAGvFQ,EAAcQ,EAAsB,eAAe,EACzD,IAAI,WAAWR,CAAW,EAAE,IAAI,IAAI,WAAWI,EAAgBC,EAAWC,CAAS,CAAC,EACpFE,EAAsB,MAAM,EAI5B,IAAMT,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBAAmBS,EAAuB,EAAGD,EAAa,QAAQ,OAAQ,EAAGf,CAAI,EAEhGiB,GAAU,UAAW,IAAM,qCAAqCP,CAAE,GAAG,EAErE,KAAK,2BAA2B,KAAKM,CAAqB,CAC5D,CAEA,OAAOE,EAAqBC,EAAgC,CAE1D,IAAMC,EAAqB,KAAK,aAAa,IAAIF,CAAQ,EACzD,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,IAAMC,EAA0B,KAAK,aAAa,IAAIF,CAAa,EACnE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAID,EAAmB,eAAiBC,EAAwB,aAC9D,MAAM,IAAI,MAAM,mDAAmD,EAErE,IAAMrB,EAAOV,GAAyB8B,EAAmB,YAAY,EAG/Db,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBACXa,EAAmB,QAAQ,OAAQ,EAAGC,EAAwB,QAAQ,OAAQ,EAAGrB,CAAI,CAC3F,CAEA,uBAAuBsB,EAAmBnB,EAAsBoB,EAAoC,CAClG,IAAIb,EACJ,GAAIa,EAAgB,CAElB,GADAb,EAAK,KAAK,gBAAgB,IAAIa,CAAc,EACxCb,IAAO,OACT,MAAM,IAAI,MAAM,mCAAmC,EAErD,GAAIY,IAAWC,EACb,OAAAN,GACI,UACA,IAAM,uDAAuDd,CAAY,WACrEO,CAAE,6BAA6B,EAChCA,EAET,KAAK,gBAAgB,OAAOa,CAAc,CAC5C,MACEb,EAAKlB,GAAmB,EAG1B,YAAK,aAAa,IAAIkB,EAAI,CAAC,QAAS,CAAC,GAAAA,EAAI,OAA2B,OAAAY,CAAM,EAAG,aAAAnB,CAAY,CAAC,EAC1F,KAAK,gBAAgB,IAAImB,EAAQZ,CAAE,EACnCO,GACI,UACA,IAAM,uDAAuDd,CAAY,WAAWO,CAAE,eAAe,EAClGA,CACT,CAEA,yBAAyBY,EAAyB,CAChD,IAAMZ,EAAK,KAAK,gBAAgB,IAAIY,CAAM,EACtCZ,IAAO,SACT,KAAK,aAAa,OAAOA,CAAE,EAC3B,KAAK,gBAAgB,OAAOY,CAAM,EAClCL,GAAU,UAAW,IAAM,4DAA4DP,CAAE,EAAE,EAE/F,CAGA,OAAOV,EAAcwB,EAAQ,eAAe,QAAU,eAAe,SAAW,eAAe,SAAmB,CAChH,IAAMnB,EAAaf,GAAyBU,CAAI,EAE5CE,EAGEuB,GAAaD,EAAQ,eAAe,WAAa,eAAe,QAEhEE,GAAaF,EAAQ,eAAe,WAAa,eAAe,QACtE,GAAIC,GAAaC,EAAW,CAC1B,IAAMC,EAAcF,EAAY,KAAK,YAAc,KAAK,mBACpDG,EAAUD,EAAY,IAAItB,CAAU,EACnCuB,IACHA,EAAU,CAAC,EACXD,EAAY,IAAItB,EAAYuB,CAAO,GAEjCA,EAAQ,OAAS,EACnB1B,EAAY0B,EAAQ,IAAI,EAGxB1B,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,CAE1E,MAEEtB,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,EAGxE,IAAMK,EAAU,CAAC,GAAIrC,GAAmB,EAAG,OAA2B,OAAQU,CAAS,EACvF,YAAK,aAAa,IAAI2B,EAAQ,GAAI,CAAC,QAAAA,EAAS,aAAc7B,CAAI,CAAC,EAE/DiB,GAAU,UAAW,IAAM,uCAAuCjB,CAAI,WAAW6B,EAAQ,EAAE,EAAE,EACtFA,CACT,CAEA,IAAInB,EAAkC,CACpC,OAAO,KAAK,aAAa,IAAIA,CAAE,GAAG,OACpC,CAEA,QAAQA,EAAuB,CAC7B,IAAMoB,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,+BAA+B,EAGjD,OAAAb,GAAU,UAAW,IAAM,sCAAsCP,CAAE,gBAAgBoB,EAAW,QAAQ,EAAE,EAAE,EAE1G,KAAK,aAAa,OAAOpB,CAAE,EAC3B,KAAK,eAAe,KAAKoB,EAAW,QAAQ,MAAM,EAG3CA,EAAW,YACpB,CAEA,MAAM,SAASpB,EAAeN,EAAkD,CAC9E,IAAM0B,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,qBAAqB,EAGvC,MAAMrC,GAAgB,KAAK,QAASqC,EAAW,QAAQ,OAAQA,EAAW,aAAc1B,CAAe,CACzG,CAEA,uBAA8B,CAC5B,QAAWkB,KAAU,KAAK,2BAExBA,EAAO,QAAQ,EAEjB,KAAK,2BAA6B,CAAC,EACnC,QAAWA,KAAU,KAAK,gBAEnBA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAE7D,KAAK,YAAY,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,GAEpCA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAEpE,KAAK,mBAAmB,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,EAErDA,EAAO,QAAQ,EAGnB,KAAK,eAAiB,CAAC,CACzB,CAEA,SAAU,CACR,KAAK,YAAY,QAASM,GAAY,CACpCA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EACD,KAAK,mBAAmB,QAASM,GAAY,CAC3CA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EAED,KAAK,aAAa,QAASS,GAAY,CACrCA,EAAQ,QAAQ,OAAO,QAAQ,CACjC,CAAC,EAED,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,GAChC,CACF,EAEapC,GAAuB,IAAIqC,IACpC,IAAItC,GAAmB,GAAGsC,CAAI,ICjWlC,IAGMC,GAsBOC,GAzBbC,GAAAC,EAAA,kBAGMH,GAAN,KAAgC,CAC9B,YAAYI,EAAoC,CAC9C,OAAO,OAAO,KAAMA,CAAS,CAC/B,CAGA,IAAW,UAAmB,CAC5B,OAAK,KAAK,MACR,KAAK,IACD,OAAO,oBAAoB,IAAI,EAAE,KAAK,EAAE,IAAIC,GAAQ,GAAI,KAAiCA,CAAI,CAAC,EAAE,EAAE,KAAK,GAAG,GAEzG,KAAK,GACd,CACF,EASaJ,GAAkEG,GAC3E,IAAIJ,GAA0BI,CAAS,IC1B3C,IAKaE,GAaAC,GAoEAC,EAiHAC,GA0MAC,GAkDAC,GACAC,GApcbC,GAAAC,EAAA,kBAKaR,GAAN,KAAiB,CAOtB,OAAO,gBAAgBS,EAAqBC,EAAiD,CAC3F,OAAQD,EAAE,CAAC,IAAMC,EAAE,CAAC,EAAK,OAAY,CAACD,EAAE,CAAC,EAAGC,EAAE,CAAC,CAAC,CAClD,CACF,EAGaT,GAAN,KAAoB,CAQzB,OAAO,UAAUU,EAA0BC,EAA0BC,EAAW,GAAoC,CAClH,IAAMC,EAAQH,EAAM,OACdI,EAAQH,EAAM,OACpB,GAAIE,IAAU,EACZ,OAAOF,EAET,GAAIG,IAAU,EACZ,OAAOJ,EAET,IAAMK,EAAQ,KAAK,IAAIL,EAAM,OAAQC,EAAM,MAAM,EAC3CK,EAAQ,IAAI,MAAcD,CAAK,EAGrC,GAAIH,EAAU,CACZ,GAAIC,EAAQ,GAAKC,EAAQ,EACvB,OAEF,IAAMG,EACFlB,GAAW,gBAAgB,CAACW,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,EAAG,CAACF,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,CAAC,EACzG,GAAIG,IAAiB,OACnB,OAEF,CAACD,EAAMD,EAAQ,CAAC,EAAGC,EAAMD,EAAQ,CAAC,CAAC,EAAIE,CACzC,CAEA,QAAS,EAAIL,EAAW,EAAI,EAAG,GAAKG,EAAO,IAAK,CAC9C,IAAMG,EAAOL,EAAQ,EAAI,EAAI,EAAIH,EAAMG,EAAQ,CAAC,EAC1CM,EAAOL,EAAQ,EAAI,EAAI,EAAIH,EAAMG,EAAQ,CAAC,EAEhD,GAAII,IAASC,GAAQD,EAAO,GAAKC,EAAO,EACtC,OAEFH,EAAMD,EAAQ,CAAC,EAAI,KAAK,IAAIG,EAAMC,CAAI,CACxC,CAEA,OAAOH,CACT,CAOA,OAAO,iBAAiBI,EAA0BC,EAAwC,CAExF,IAAMC,EAAYF,EAAM,OAClBG,EAAYF,EAAW,OAC7B,GAAIC,EAAYC,EACd,MAAO,GAET,QAASC,EAAI,EAAGA,GAAKF,EAAWE,IAC9B,GAAIJ,EAAME,EAAYE,CAAC,IAAM,GAAKJ,EAAME,EAAYE,CAAC,IAAMH,EAAWE,EAAYC,CAAC,EACjF,MAAO,GAGX,MAAO,EACT,CACF,EAGavB,EAAN,MAAMwB,CAAU,CAIrB,OAAO,KAAKC,EAAiC,CAC3C,OAAOD,EAAU,0BAA0BC,EAAM,EAAGA,EAAK,MAAM,CACjE,CAKA,OAAO,kBAAkBA,EAAyBC,EAAsB,CACtE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,wCAAwCD,EAAK,MAAM,cAAc,EAE/G,OAAOD,EAAU,0BAA0BC,EAAMC,EAAMD,EAAK,MAAM,CACpE,CAKA,OAAO,gBAAgBA,EAAyBC,EAAsB,CACpE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,sCAAsCD,EAAK,MAAM,cAAc,EAE7G,OAAOD,EAAU,0BAA0BC,EAAM,EAAGC,CAAI,CAC1D,CAKA,OAAO,0BAA0BD,EAAyBE,EAAeC,EAAqB,CAC5F,IAAIC,EAAO,EACX,QAASN,EAAII,EAAOJ,EAAIK,EAAKL,IAAK,CAGhC,GAAIE,EAAKF,CAAC,EAAI,EACZ,MAAM,IAAI,MAEN,+GAA+G,EAErHM,GAAQJ,EAAKF,CAAC,CAChB,CACA,OAAOM,CACT,CAEA,OAAO,eAAeJ,EAA4C,CAChE,IAAMK,EAAOL,EAAK,OAClB,GAAIK,IAAS,EACX,MAAO,CAAC,EACH,GAAIA,IAAS,EAClB,MAAO,CAAC,CAAC,EAEX,IAAMC,EAAU,IAAI,MAAMD,CAAI,EAC9BC,EAAQD,EAAO,CAAC,EAAI,EACpBC,EAAQD,EAAO,CAAC,EAAIL,EAAKK,EAAO,CAAC,EACjC,QAASP,EAAIO,EAAO,EAAGP,GAAK,EAAG,EAAEA,EAC/BQ,EAAQR,CAAC,EAAIQ,EAAQR,EAAI,CAAC,EAAIE,EAAKF,EAAI,CAAC,EAE1C,OAAOQ,CACT,CAKA,OAAO,cAAcL,EAAcM,EAA4B,CAC7D,GAAIN,EAAO,CAACM,GAAcN,GAAQM,EAChC,MAAM,IAAI,MAAM,sCAAsC,EAExD,OAAON,EAAO,EAAIA,EAAOM,EAAaN,CACxC,CAEA,OAAO,cAAcO,EAAyBD,EAA+B,CAC3E,OAAOC,EAAK,IAAIC,GAAK,KAAK,cAAcA,EAAGF,GAAcC,EAAK,MAAM,CAAC,CACvE,CAQA,OAAO,gBAAgB1B,EAAsB4B,EAA6C,CACxF,OAAIA,EACKA,EAAK,IAAKC,GAAM7B,EAAE6B,CAAC,CAAC,EAEpB7B,EAAE,MAAM,EAAE,QAAQ,CAE7B,CAOA,OAAO,SAASkB,EAAyBY,EAA2C,CAClF,IAAMP,EAAOL,EAAK,OAClB,OAAOA,EAAK,IAAI,CAACW,EAAGb,IAAMa,EAAIC,EAAId,CAAC,EAAIc,EAAId,EAAIO,CAAI,CAAC,CACtD,CAOA,OAAO,SAASQ,EAA2BC,EAAoC,CAC7E,OAAID,EAAO,SAAWC,EAAO,OACpB,GAEFD,EAAO,MAAM,CAACF,EAAGb,IAAMa,IAAMG,EAAOhB,CAAC,CAAC,CAC/C,CACF,EAEatB,GAAN,MAAMuC,CAAa,CAUxB,OAAO,qBACHC,EAA2BC,EAA8BC,EAAuBZ,EAChFa,EAAqBC,EAAsB,CAC7C,GAAI,CAACJ,GAAoBE,EAAY,SAAWD,EAAU,OAAS,EACjE,MAAM,IAAI,MAAM,oFAAoF,EAGtG,GAAID,EAEF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IACxCA,GAAOH,EAAY,OACrBA,EAAY,KAAKD,EAAUI,EAAM,CAAC,CAAC,EAEnCH,EAAYG,CAAG,EAAIJ,EAAUI,EAAM,CAAC,EAM1C,QAASA,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMf,EAAQ,QAChB,GAAIA,EAAQe,CAAG,EAAI,EACjB,MAAM,IAAI,MAAM,8CAA8C,OAGhEf,EAAQ,KAAK,CAAC,EAKlB,QAASe,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMF,EAAU,QAClB,GAAIA,EAAUE,CAAG,EAAI,EACnB,MAAM,IAAI,MAAM,gDAAgD,OAGlEF,EAAU,KAAK,CAAC,EAKpB,QAASE,EAAM,EAAGA,EAAMH,EAAY,OAAS,EAAGG,IAC9C,GAAIA,EAAMD,EAAK,QACb,GAAIA,EAAKC,CAAG,EAAI,EACd,MAAM,IAAI,MAAM,0CAA0C,OAG5DD,EAAK,KAAK,CAAC,EAKf,QAASC,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAAO,CACjD,GAAIH,EAAYG,CAAG,GAAK,EACtB,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAID,EAAKC,CAAG,GAAKH,EAAYG,CAAG,GAAKD,EAAKC,EAAMH,EAAY,MAAM,GAAKA,EAAYG,CAAG,EACpF,MAAM,IAAI,MAAM,oCAAoC,CAExD,CACF,CAGA,OAAO,yBACHJ,EAA8BX,EAA4Ba,EAC1DD,EAAgCE,EAAgBE,EAAwBC,EAAwB,CAClG,GAAKA,EAIL,IAAIH,EAAK,SAAW,GAAKH,EAAU,OAAS,GAC1C,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIX,EAAQ,SAAYW,EAAU,OAAS,EACzC,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIC,EAAY,SAAYD,EAAU,OAAS,EAC7C,MAAM,IAAI,MAAM,iEAAiE,EAGnF,QAASI,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CN,EAAa,wBACTE,EAAUI,GAAOC,EAAgB,EAAI,EAAE,EAAGhB,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAChGA,EAAMJ,EAAU,OAAS,EAAGM,CAAO,EAE3C,CAaA,OAAO,uBACHP,EAA2BC,EAA8BX,EAAmBa,EAC5ED,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,EACtB,MAAM,IAAI,MAAM,4CAA4C,EAI9D,IAAMO,EAAa,CAACP,EAAU,CAAC,EAAGA,EAAU,CAAC,CAAC,EAE9C,OAAAF,EAAa,mBACTC,EAAkBC,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACpFC,CACT,CAYA,OAAO,uBACHP,EAA8BQ,EAA+BnB,EAAmBa,EAChFD,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,GAAKQ,EAAW,QAAU,EAChD,MAAM,IAAI,MAAM,yDAAyD,EAI3E,IAAMD,EAAa,CAACP,EAAU,CAAC,EAAGQ,EAAW,CAAC,CAAC,EAE/C,OAAAV,EAAa,mBAAmB,GAAOE,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACrGC,CACT,CAKA,OAAe,mBACXR,EAA2BC,EAA8BO,EAAsBlB,EAC/Ea,EAA8BD,EAAgCE,EAAgBG,EAAkB,CAClG,GAAIP,EACF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAK,CAAC,MAGnB,SAASH,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAKT,EAAa,wBACzBE,EAAUI,EAAM,CAAC,EAAGf,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAAKA,EAAMJ,EAAU,OAAS,EACxGM,CAAO,CAAC,CAGlB,CAIA,OAAe,wBACXG,EAAgBC,EAAgBC,EAAkBC,EAAgBT,EAAgBU,EAClFC,EAAsBR,EAA0B,CAClD,IAAMS,EAAUJ,GAAYC,EAAS,GAAK,EAC1C,GAAIN,GAAWA,IAAY,SACzB,OAAQA,EAAS,CACf,IAAK,QACH,OAAAH,EAAKU,CAAY,EAAI,EACrBV,EAAKW,CAAY,EAAI,EACd,KAAK,OAAQL,EAASM,GAAWL,EAAU,CAAC,EACrD,IAAK,aACL,IAAK,aACH,GAAIC,IAAa,EACf,MAAM,IAAI,MAAM,qDAAqD,EAChE,CAEL,IAAMK,IADoBP,EAASC,EAAS,GAAKA,EACX,GAAKA,EAASE,EAASH,EAC7D,OAAAN,EAAKU,CAAY,EACgB,KAAK,MAAjCP,IAAY,cAA4BU,EAAY,GAAK,EAAgBA,EAAY,CAA3B,EAC/Db,EAAKW,CAAY,EAAIE,EAAYb,EAAKU,CAAY,EAC3C,KAAK,OAAQJ,EAASO,EAAYJ,GAAUF,EAAU,CAAC,CAChE,CACF,QACE,MAAM,IAAI,MAAM,0BAA0B,CAC9C,KAEA,QAAO,KAAK,OAAQD,EAASN,EAAKU,CAAY,EAAIV,EAAKW,CAAY,EAAIC,GAAWL,EAAU,CAAC,CAEjG,CACF,EAEalD,GAAN,KAAe,CAIpB,OAAO,qBACHyD,EAA8BC,EAAoBC,EAA+BC,EACjFC,EAAkD,CACpD,GAAIJ,EAAU,SAAW,GAAKE,EAAW,SAAW,EAClD,MAAM,IAAI,MAAM,4BAA4B,EAG9C,IAAIG,EACAC,EACAC,EAEAN,GACFI,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,IAEfK,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,GAGjB,IAAIQ,EAAO,GAUX,GARIL,GACFI,EAAIL,EAAW,CAAC,EAChBM,EAAO,IAEPD,EAAIL,EAAW,CAAC,EAChBM,EAAO,GAGLN,EAAWM,CAAI,IAAMF,EACvB,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAID,GAAK,GAAKE,GAAK,GAAKD,GAAK,EAC3B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIF,GAAa,CAAChE,GAAc,iBAAiBgE,EAAW,CAACC,EAAGE,CAAC,CAAC,EAChE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,MAAO,CAACF,EAAGE,EAAGD,CAAC,CACjB,CACF,EAGa9D,GAAW,sBACXC,GAAW,uBCpcxB,IAiBagE,GAsMPC,GAoCOC,GAKAC,GAKAC,EAOAC,GAiBAC,GAcAC,GAgBAC,GAkBAC,GAsBPC,GAiTOC,EAaAC,EAaAC,GAgFPC,GAuHOC,GAYAC,GAeAC,GAh5BbC,GAAAC,EAAA,kBAGAC,KACAC,KAaarB,GAAiB,GAsMxBC,GAAoB,CAACqB,EAAcC,IAAiD,CACxF,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,OAAQD,EAAM,CACZ,QACE,OAAOC,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,QACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,QACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,OACE,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mBAAmB,EAErC,MAAO,CAAC,MAAO,YAAY,EAE7B,QACE,MAAM,IAAI,MAAM,sBAAsBD,CAAI,EAAE,CAChD,CACF,EAEapB,GAA8B,CAACoB,EAAgBC,EAAsB,IAAM,CACtF,IAAMC,EAAavB,GAAkBqB,EAAMC,CAAU,EACrD,OAAO,OAAOC,GAAe,SAAWA,EAAaA,EAAW,CAAC,CACnE,EAEarB,GAA4B,CAACmB,EAAgBC,EAAsB,IAAM,CACpF,IAAMC,EAAavB,GAAkBqB,EAAMC,CAAU,EACrD,OAAO,OAAOC,GAAe,SAAWA,EAAaA,EAAW,CAAC,CACnE,EAEapB,EAA8BqB,GACvCA,EAAK,SAAW,EAAI,CAAC,EAAI,CAAC,CAAC,KAAM,SAAU,KAAMA,CAAI,EAAG,CAAC,KAAM,SAAU,KAAMC,EAAU,eAAeD,CAAI,CAAC,CAAC,EAMrGpB,GAAoBsB,GAE3BA,EAAO,IAAM,EACR,EACEA,EAAO,IAAM,EACf,EAGF,EASIrB,GAAa,CAACsB,EAAW,MAAOL,EAAqBM,EAAQ,MACpE,CAACN,GAAcA,IAAe,EACzB,GAAGK,CAAQ,IAAIC,CAAK,IAGtB,MAAMN,CAAU,IAAIK,CAAQ,KAAKC,CAAK,IASlCtB,GAAY,CAACqB,EAAkBL,EAAoBM,IAC1DD,IAAa,MACRC,EAELN,IAAe,EACV,OAAOM,CAAK,IAGd,MAAMN,CAAU,KAAKM,CAAK,IAQtBrB,GAAY,CAACsB,EAAcP,IAClCA,IAAe,EACV,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAC1CP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,MAClBP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAGlCA,EASIrB,GAAe,CAACqB,EAAcC,EAAsBC,IAC3DF,EAAK,WAAW,WAAW,GAAKE,EAAS,EACvC,OAAQD,GAAW,SACd,GAAGD,CAAI,KAAKC,CAAK,WAAWA,CAAK,SAEjC,GAAGD,CAAI,IAAI,KAAK,MAAMC,EAAQ,CAAC,CAAC,KAAKA,EAAQ,CAAC,IAGhDC,EAAS,EAAI,GAAGF,CAAI,IAAIC,CAAK,IAAMD,EAcxCpB,GACF,CAACoB,EAAcG,EAAoBC,EAAuCC,EACzEZ,IAAuC,CACtC,IAAMa,EAAa,OAAOF,GAAgB,SACpCG,EAAOD,EAAaF,EAAcA,EAAY,OAC9CI,EAAe,CAAC,GAAG,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAC,EACzCE,EAAcF,EAAO,EAAI,MAAQA,GAAQ,EAAI,MAAMA,CAAI,QAAU,cAAcA,CAAI,IACnFb,EAAavB,GAAkBgC,EAAYV,CAAU,EACrDiB,EAAY,OAAOhB,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACtEiB,EAAc,OAAOjB,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACxEF,EAAO,CAAC,QAASiB,EAAa,MAAOC,EAAW,QAASC,EAAa,OAAQR,CAAU,EAExFS,EAAgBC,GAA+B,OAAOA,GAAQ,SAAWA,EAAM,GAAGA,CAAG,IAErFC,EAAqB,CACzB,gBAAiB,GACjB,gBAAiB,GACjB,2BAA4B,GAC5B,IAAK,GACL,aAAc,GACd,IAAK,GACL,aAAc,EAChB,EAEMC,EAAgBT,EAAa,YAAc,GAC3CU,EAAQ,GAAGD,CAAa,GAAGf,CAAI,SAC/BiB,EAAU,GAAGF,CAAa,GAAGf,CAAI,WAEnCkB,EAAa,GACjB,QAASC,EAAI,EAAGA,EAAIZ,EAAO,EAAGY,IAC5BD,GAAc;AAAA,aACTC,CAAC,gBAAgBxC,GAAasC,EAASE,EAAGZ,CAAI,CAAC;AAAA,cAC9CY,CAAC,gBAAgBxC,GAAasC,EAASE,EAAGZ,CAAI,CAAC;AAAA,cAC/CY,CAAC,UAAUA,CAAC;AAAA,oBACNA,CAAC;AAAA,MAGfD,GAAc,WAAWX,EAAO,CAAC,eAEjC,IAAMa,EAAgCb,EAAO,EAAI,GAAK;AAAA,WACjDP,CAAI,oBAAoBR,EAAK,OAAO;AAAA,mBAC5BA,EAAK,OAAO;AAAA;AAAA,MAEzB0B,CAAU;AAAA;AAAA,KAIJG,EAAmBC,IACvBR,EAAmB,gBAAkB,GAC9BP,EAAO,EAAIe,EAAY,OAAOtB,CAAI,IAAIsB,CAAS,KAGlDC,EAAoB,CAAC,EAC3B,GAAIhB,GAAQ,EACV,QAASY,EAAIZ,EAAO,EAAGY,GAAK,EAAGA,IAC7BI,EAAQ,KAAK,GAAG5C,GAAasC,EAASE,EAAGZ,CAAI,CAAC,eAAeY,CAAC,IAAI,EAItE,IAAMK,EAAgCjB,EAAO,EAAI,GAAK;AAAA,WACjDP,CAAI,aAAaR,EAAK,OAAO;AAAA,aAC3B+B,EAAQ,KAAK,GAAG,CAAC;AAAA,KAGlBE,EAAmBC,IACvBZ,EAAmB,gBAAkB,GAC9BP,EAAO,EAAImB,EAAa,OAAO1B,CAAI,IAAI0B,CAAU,KAGpDC,EAAU,IAAIC,IAChBrB,IAAS,EAAI,KAAO,GAAGf,EAAK,OAAO,IAAIoC,EAAK,IAAIhB,CAAY,EAAE,KAAK,GAAG,CAAC,IAErEiB,EAAa,CAACH,EAAoBI,IAClCvB,EAAO,EACF,GAAGmB,CAAU,GAEb,GAAG/C,GAAa+C,EAAYI,EAAKvB,CAAI,CAAC,GAI3CwB,EAAa,CAACL,EAAoBI,EAAoB/B,KACtDQ,EAAO,EACF,GAAGmB,CAAU,IAAI3B,EAAK,IAEtB,GAAGpB,GAAa+C,EAAYI,EAAKvB,CAAI,CAAC,IAAIR,EAAK,IAIpDiC,EAAoE,CAAC,EACrEC,EAA6B,CAACP,EAAoBQ,IAA0B,CAChFpB,EAAmB,2BAA6B,GAChD,IAAMqB,GAAU,GAAGD,EAAO,IAAI,uBAAuBlC,CAAI,SACzD,GAAImC,MAAWH,EACb,MAAO,GAAGG,EAAO,IAAIT,CAAU,IAEjC,IAAMH,GAAU,CAAC,EACjB,QAASJ,GAAIZ,EAAO,EAAGY,IAAK,EAAGA,KAAK,CAClC,IAAMW,GAAMI,EAAO,WAAW,gBAAiBf,GAAIe,EAAO,KAAO3B,CAAI,EACrEgB,GAAQ,KAAK,GAAGM,EAAWZ,EAASE,EAAC,CAAC,OAAOW,EAAG,MAAMD,EAAWb,EAAOG,EAAC,CAAC,GAAG,CAC/E,CACA,OAAAa,EAAyCG,EAAO,EAC5C,MAAMA,EAAO,mBAAmBD,EAAO,KAAK,OAAO;AAAA,sBACzCX,GAAQ,OAAS,EAAIA,GAAQ,KAAK,GAAG,EAAI,IAAI;AAAA,cAGpD,GAAGY,EAAO,IAAIT,CAAU,GACjC,EAEMU,GAAc,CAACC,EAAuBtC,KAAmB,IAAM,CACnE,GAAIP,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAIqC,CAAM,KAAKtC,CAAK,IAC7B,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAIqC,CAAM,mBAAmBtC,CAAK,8BAA8BA,CAAK,UAC9E,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAIqC,CAAM,mBAAmBtC,CAAK,UAC3C,GAAIP,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,GAAGQ,CAAI,IAAIqC,CAAM,8DAA8DtC,CAAK,MAE3F,MAAM,IAAI,MAAM,6CAA6CP,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG8C,GAAeD,IAA2B,IAAM,CACpD,GAAI7C,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAIqC,CAAM,IACnB,GAAI7C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAIqC,CAAM,OACvB,GAAI7C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAIqC,CAAM,OACvB,GAAI7C,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,mBAAmBQ,CAAI,IAAIqC,CAAM,oBAAoBrC,CAAI,IAAIqC,CAAM,sBAAsBrC,CAAI,IAChGqC,CAAM,wBAAwBrC,CAAI,IAAIqC,CAAM,oBAEhD,MAAM,IAAI,MAAM,6CAA6C7C,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG+C,GAA6BhC,EAAO,EAAI,GAAK;AAAA,WAC9CP,CAAI,sBAAsBR,EAAK,OAAO,QAAQkB,CAAS;AAAA,aACrD4B,GAAY,OAAOtC,CAAI,WAAW,CAAC;AAAA,KAGpCwC,EAAoBjC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,EAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,EAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJnB,CAAI,IAAIyC,CAAc,QAAQ/B,CAAS;AAAA,iBACjCV,CAAI,aAAa2B,EAAQe,CAAU,CAAC;AAAA,IAE/C,GAAG,EAEGC,GAAM,IAAIhB,IAA0C,CACxD,GAAIA,EAAQ,SAAWpB,EACrB,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAGlD,IAAMqC,EAAoBjB,EAAQ,IAAIf,CAAY,EAAE,KAAK,GAAG,EAE5D,OAAIL,IAAS,EACJ+B,GAAY,IAAI,EACd/B,IAAS,EACX+B,GAAYM,EAAkB,CAAC,CAAC,GAEvC9B,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOd,CAAI,IAAI4C,CAAiB,IAE3C,EAEMC,GAAgBnB,GAChBnB,EAAO,EACF+B,GAAYZ,CAAU,GAE7BZ,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOd,CAAI,aAAa0B,CAAU,KAIvCoB,GAA6BvC,EAAO,EAAI,GAAK;AAAA,WAC9CP,CAAI,sBAAsBR,EAAK,OAAO,YAAYkB,CAAS;AAAA,MAChE0B,GAAY,OAAOpC,CAAI,YAAa,OAAO,CAAC;AAAA,KAGtC+C,GAAoBxC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,EAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,EAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJnB,CAAI,IAAIyC,CAAc,YAAY/B,CAAS;AAAA,UAC5CV,CAAI,aAAa2B,EAAQe,CAAU,CAAC;AAAA,IAExC,GAAG,EA0EH,MAAO,CACL,KAxCW,IAAM,CACjB,IAAMM,EAAQ,CAAC,EACXC,EAAmB,GACvB,OAAInC,EAAmB,kBACrBkC,EAAM,KAAK5B,CAA6B,EACxC6B,EAAmB,IAEjBnC,EAAmB,kBACrBkC,EAAM,KAAKxB,CAA6B,EACxCyB,EAAmB,IAEjBnC,EAAmB,6BACrB,OAAO,OAAOkB,CAAwC,EAAE,QAAQkB,IAAQF,EAAM,KAAKE,EAAI,CAAC,EACxFD,EAAmB,IAEjBnC,EAAmB,MACrBkC,EAAM,KAAKD,EAAiB,EAC5BE,EAAmB,IAEjBnC,EAAmB,eACrBkC,EAAM,KAAKF,EAA0B,EACrCG,EAAmB,IAEjBnC,EAAmB,MACrBkC,EAAM,KAAKR,CAAiB,EAC5BS,EAAmB,IAEjBnC,EAAmB,eACrBkC,EAAM,KAAKT,EAA0B,EACrCU,EAAmB,IAEjB,CAAC3C,GAAc2C,GACjBD,EAAM,QACF,SAAShC,CAAK,MAAMxB,EAAK,OAAO,IAAIY,EAAY,KAAK,GAAG,CAAC,KACzD,SAASa,CAAO,MAAMzB,EAAK,OAAO,IAAII,EAAU,eAAeQ,CAAW,EAAE,KAAK,GAAG,CAAC,IAAI,EAExF4C,EAAM,KAAK;AAAA,CAAI,CACxB,EAIE,KAAAxD,EACA,gBAAA6B,EACA,gBAAAI,EACA,2BAAAQ,EACA,QAAAN,EACA,WAAAE,EACA,WAAAE,EACA,IAjFU,IAAIoB,IAAkD,CAChE,GAAIA,EAAgB,SAAW5C,EAAO,EACpC,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,IAAMR,EAAQoD,EAAgB5C,CAAI,EAClC,GAAI,OAAOR,GAAU,SACnB,MAAM,IAAI,MAAM,sBAAsB,EAGxC,IAAM6C,GAAoBO,EAAgB,MAAM,EAAG5C,CAAI,EAAE,IAAIK,CAAY,EAAE,KAAK,GAAG,EAEnF,OAAIL,IAAS,EACJ6B,GAAY,KAAMrC,CAAK,EACrBQ,IAAS,EACX6B,GAAYQ,GAAkB,CAAC,EAAG7C,CAAK,GAE9Ce,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOd,CAAI,IAAI4C,EAAiB,KAAK7C,CAAK,IAErD,EA6DE,YAAAqC,GACA,aA5DmB,CAACV,EAAoB3B,IACpCQ,EAAO,EACF6B,GAAYV,EAAY3B,CAAK,GAEpCe,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOd,CAAI,aAAa0B,CAAU,KAAK3B,CAAK,MAuDrD,IAAA4C,GACA,YAAAL,GACA,aAAAO,GAEA,MAAAxC,EACA,KAAAL,EACA,QAAAiB,EACA,MAAAD,EACA,KAAAT,CACF,CACF,EAWS1B,EACT,CAACmB,EAAcR,EAAcY,EAAuCX,EAAsB,IACtFb,GAAoBoB,EAAMR,EAAMY,EAAa,QAASX,CAAU,EAW3DX,EACT,CAACkB,EAAcR,EAAcY,EAAuCX,EAAsB,IACtFb,GAAoBoB,EAAMR,EAAMY,EAAa,SAAUX,CAAU,EAW5DV,GACT,CAACiB,EAAcR,EAAcY,EAAuCX,EAAsB,IACtFb,GAAoBoB,EAAMR,EAAMY,EAAa,WAAYX,CAAU,EA8ErET,GAAN,KAA+C,CAC7C,YAAoBoE,EAAmD,CAAnD,6BAAAA,EAqFpB,KAAQ,kBAAqC,CAAC,EAC9C,KAAQ,UAA6B,CAAC,EACtC,KAAQ,SAA8B,CAAC,EAoBvC,KAAQ,cAAgB,CA3GgD,CAExE,sCAAsCvD,EAA6B,CAGjE,MAAO,qBADY,OAAOA,GAAS,SAAW,GAAGA,CAAI,IAAMA,CACrB,eACxC,CAEA,UAAUwD,EAAiDnF,GAAgB,CACzE,IAAMoF,EAAiB,OAAOD,GAAkB,SAAWA,EAAgBA,EAAc,CAAC,EACpFE,EAAiB,OAAOF,GAAkB,SAAW,EAAIA,EAAc,CAAC,EACxEG,EAAiB,OAAOH,GAAkB,SAAW,EAAIA,EAAc,CAAC,EAExEI,EAAuB,KAAK,wBAAwB,CAAC,IAAM,GAAK,KAAK,wBAAwB,CAAC,IAAM,EACpGC,EAAYD,EAAuB;AAAA;AAAA,wDAGA;AAAA;AAAA;AAAA,yDAInCE,EAAsBF,EACxB,4DACA;AAAA,mEAEIH,EAAiBC,EAAiBC,CAAc,iBAExD,MAAO,4BAA4BF,CAAc,KAAKC,CAAc,KAAKC,CAAc;AAAA,YAC/EE,CAAS;AAAA,MACfC,CAAmB;AAAA,GAEvB,CAEQ,uBAAuBC,EAA+B,CACxDA,EAAS,OAAS,IAChBA,EAAS,MAAM,WAAW,WAAW,GACvC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,MAAM,QAAQ,YAAa,EAAE,EAAG,KAAM,MAAO,OAAQA,EAAS,IAAI,CAAC,EAEpGA,EAAS,QAAQ,WAAW,WAAW,GACzC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,QAAQ,QAAQ,YAAa,EAAE,EAAG,KAAM,MAAO,OAAQA,EAAS,IAAI,CAAC,EAG9G,CAEQ,gBAAgBA,EAAyBC,EAA8B,CAC7E,GAAID,EAAS,QAAU,WACrB,MAAM,IAAI,MAAM,+FAA+F,EAEjH,KAAK,UAAU,KAAKA,CAAQ,EAC5B,KAAK,uBAAuBA,CAAQ,EAEpC,IAAME,EAASF,EAAS,QAAU,QAAU,OAAS,aAC/CjD,EAAciD,EAAS,KAAK,QAClC,MAAO,sBAAsBC,CAAY,kBAAkBC,CAAM,KAAKF,EAAS,IAAI,WAAWjD,CAAW,IAC3G,CAEA,oBAAoBoD,EAAoC,CACtD,OAAOA,EAAU,IAAIC,GAAK,KAAK,gBAAgBA,EAAG,KAAK,eAAe,CAAC,EAAE,KAAK;AAAA,CAAI,CACpF,CAEQ,yBAAyBJ,EAA+B,CAC9D,GAAIA,EAAS,QAAU,WACrB,MAAM,IAAI,MACN,sGAAsG,EAG5G,KAAK,kBAAkB,KAAKA,CAAQ,EACpC,KAAK,uBAAuBA,CAAQ,CACtC,CAEA,6BAA6BG,EAA0C,CACrE,OAAAA,EAAU,QAAQC,GAAK,KAAK,yBAAyBA,CAAC,CAAC,EAChD,IACT,CAEA,gBAAgBhE,EAAcR,EAA8BU,EAAS,EAAiB,CACpF,YAAK,SAAS,KAAK,CAAC,KAAAF,EAAM,KAAAR,EAAM,OAAAU,CAAM,CAAC,EAChC,IACT,CAEA,iBAAiB+D,EAAqD,CACpE,YAAK,SAAW,KAAK,SAAS,OAAOA,CAAkB,EAChD,IACT,CAKQ,oBAA6B,CACnC,GAAI,KAAK,SAAS,SAAW,EAC3B,MAAO,GAGT,IAAMC,EAA4B,CAAC,EACnC,OAAW,CAAC,KAAAlE,EAAM,KAAAR,EAAM,OAAAU,CAAM,IAAK,KAAK,SACtC,GAAIA,GAAUA,EAAS,EACrBgE,EAAgB,KAAK,GAAGlE,CAAI,eAAeR,CAAI,MAAM,KAAK,KAAKU,EAAS,CAAC,CAAC,GAAG,MACxE,CACL,IAAMiE,EAAWjE,GAAU,MAAQA,IAAW,EAAIV,EAAO,MAAMU,CAAM,IAAIV,CAAI,IAC7E0E,EAAgB,KAAK,GAAGlE,CAAI,IAAImE,CAAQ,EAAE,CAC5C,CAGF,MAAO;AAAA,0BACeD,EAAgB,KAAK,IAAI,CAAC;AAAA,2BACzB,KAAK,aAAa,oCAC3C,CAMA,IAAI,2BAAoC,CACtC,OAAO,KAAK,mBAAmB,EAAI,KAAK,UAAU,IAAI/C,GAAKA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,EAC1E,KAAK,kBAAkB,IAAIA,GAAKA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,CACzD,CACF,EAEalC,GAAsBmF,GAA4C,IAAIpF,GAAiBoF,CAAa,EAYpGlF,GAAmB,CAACmF,EAA4BC,IAA0C,CACrG,IAAMC,EAASF,EAAQ,OACjB1E,EAAiB,CAAC,EACxB,QAASwB,EAAI,EAAGA,EAAIoD,EAAQpD,IAAK,CAC/B,IAAMN,EAAM0D,EAAS,EAAIpD,EACnBqD,EAAIH,EAAQxD,CAAG,GAAK,GAChByD,EAASA,EAAS,OAAS,EAAInD,CAAC,GAAK,GACvC,GAAKqD,IAAM,GACjB7E,EAAK,QAAQkB,CAAG,CAEpB,CACA,OAAOlB,CACT,EAGaR,GAAwBsF,GAA2B,KCh5BhE,IAcMC,GAMAC,GAGAC,GAGAC,GAWOC,GA+CAC,GAKAC,GAzFbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,6BAA6B,CAEjD,EAEMX,GAAkB,CAACY,EAAmBC,IACvCA,GAAQA,EAAK,SAAWD,EAAa,CAAC,GAAI,IAAI,MAAMA,CAAS,EAAE,KAAK,CAAE,EAAE,QAAQ,EAAIC,EAEnFZ,GAAiB,CAACa,EAA+BD,IACnDE,EAAU,gBAAgBD,EAAYd,GAAgBc,EAAW,OAAQD,CAAI,CAAC,EAE5EX,GAAmB,CAACW,EAAgBG,EAAcC,EAAsBC,IAAkC,CAC9G,IAAMC,EAAc,CAAC,EACrBA,EAAY,KAAK,cAAcD,EAAO,KAAK,OAAO,QAAQD,EAAM,KAAK,OAAO;AAAA,aACjEA,EAAM,KAAK,OAAO,GAAG,EAChC,QAASG,EAAI,EAAGA,EAAIJ,EAAM,EAAEI,EAC1BD,EAAY,KAAKF,EAAM,WAAW,IAAKJ,EAAKO,CAAC,EAAG,KAAKA,CAAC,GAAG,CAAC,EAE5D,OAAAD,EAAY,KAAK,YAAY,EACtBA,EAAY,KAAK;AAAA,CAAI,CAC9B,EAEahB,GAA6B,CAACkB,EAAyBC,IAAoC,CACtG,IAAMC,EAAgBF,EAAY,SAC5BT,EAAYS,EAAY,KAAK,OAC7BR,EAAOb,GAAgBY,EAAWU,CAAQ,EAC1CE,EAAoBC,GAAqBb,CAAS,EAClDc,EAAczB,GAAeoB,EAAY,KAAMR,CAAI,EACnDc,EAAiBH,EAAoBE,EAAY,OAASA,EAC1DE,EAAgBJ,EAAoBZ,EAAYS,EAAY,KAC5DH,EAASW,EAAe,SAAUN,EAAeI,CAAc,EAC/DV,EAAQa,EAAc,IAAKP,EAAeK,CAAa,EAEvDG,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBf,EAAOC,CAAM,CAAC;AAAA;AAAA,IAElFhB,GAAiBW,EAAMD,EAAWK,EAAOC,CAAM,CAAC;AAAA;AAAA,IAEhDc,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,oBAE5Dd,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,MAGlDA,EAAO,YAAY,aAAcD,EAAM,aAAa,UAAU,CAAC,CAAC;AAAA,KAEpE,MAAO,CACL,KAAM,YACN,YAAa,CAAC,KAAM,GAAGK,CAAQ,GAAI,kBAAmBE,EAAoB,CAAC,MAAM,EAAI,CAAC,MAAM,CAAC,EAC7F,WAAab,GAAW,CACtB,IAAMsB,EAAalB,EAAU,KAAKW,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUf,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,EAClE,gBAAiBT,EACb,CACE,CAAC,KAAM,SAAU,KAAMS,CAAU,EACjC,GAAGC,EAA2BvB,EAAO,CAAC,EAAE,IAAI,EAC5C,GAAGuB,EAA2BR,CAAW,CAC3C,EACA,CACE,CAAC,KAAM,SAAU,KAAMO,CAAU,CACnC,CACN,CACF,EACA,gBAAAF,CACF,CACF,EAEa3B,GAAY,CAAC+B,EAAyBC,IAA0C,CAC3FrC,GAAeoC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQhC,GAA2BgC,EAAQ,OAAO,CAAC,EAAGC,EAAW,IAAI,CAAC,CAChF,EAEa/B,GAA4B+B,GACrCC,GAA4B,CAAC,KAAMD,EAAW,IAAgB,CAAC,IC1FnE,IAYME,GAaAC,GAaAC,GAaAC,GAYAC,GAQAC,GAYAC,GAcAC,GASAC,GAaOC,GAyEPC,GAkCOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAtQbC,GAAAC,EAAA,kBAKAC,KAGAC,KACAC,KACAC,KAEM1B,GAAqC,CACzC,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,oCACX,UAAW,6BACX,GAAI,6BACJ,GAAI,oCACJ,OAAQ,uBACV,EAEMC,GAA2C,CAC/C,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,wBACX,UAAW,wBACX,GAAI,wBACJ,GAAI,wBACJ,OAAQ,uBACV,EAEMC,GAA4C,CAChD,IAAK,aACL,IAAK,aACL,KAAM,IACN,IAAK,IACL,KAAM,IACN,UAAW,IACX,UAAW,IACX,GAAI,IACJ,GAAI,IACJ,OAAQ,GACV,EAEMC,GAA8C,CAClD,IAAK,YACL,IAAK,YACL,IAAK,YACL,KAAM,YACN,UAAW,YACX,UAAW,iBACX,GAAI,YACJ,GAAI,kBACJ,OAAQ,gBACV,EAEMC,GAAmB,CAACuB,EAAsBC,IAA2B,CACzE,IAAMC,EAAM,CAAC,EACb,QAASC,EAAIF,EAAOD,EAAcG,EAAIF,EAAM,EAAEE,EAC5CD,EAAI,KAAKC,CAAC,EAEZ,OAAOD,CACT,EAEMxB,GAA4B,CAAC0B,EAA0BC,IAAkD,CAC7G,IAAMC,EAAc,CAAC,EACfL,EAAOG,EAAM,OACnB,QAASG,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,IACxBD,EAAY,KAAKF,EAAMG,CAAG,CAAC,EAG/B,IAAMC,EAAcH,EAAK,IAAIE,GAAOH,EAAMG,CAAG,CAAC,EAC9C,MAAO,CAACD,EAAaE,CAAW,CAClC,EAEM7B,GAAuB,CAACyB,EAAiBC,IAA6B,CAC1E,IAAMJ,EAAOG,EAAM,OAASC,EAAK,OAC3BI,EAAc,CAAC,EACjBC,EAAW,EACf,QAASH,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,GACxBE,EAAY,KAAKL,EAAMM,GAAU,CAAC,EAElCD,EAAY,KAAK,CAAC,EAGtB,OAAOA,CACT,EAEM7B,GAAuB,CAACyB,EAAgBJ,IAA0B,CACtE,QAASE,EAAI,EAAGA,EAAIE,EAAK,OAAQ,EAAEF,EACjC,GAAIE,EAAKA,EAAK,OAASF,EAAI,CAAC,IAAMF,EAAO,EAAIE,EAC3C,MAAO,GAGX,MAAO,EACT,EAEMtB,GAAqB,CAACwB,EAAgBJ,IAA2B,CACrE,IAAMC,EAAM,CAAC,EACb,GAAI,CAACtB,GAAqByB,EAAMJ,CAAI,EAAG,CACrC,QAASE,EAAI,EAAGA,EAAIF,EAAM,EAAEE,EACtBE,EAAK,QAAQF,CAAC,IAAM,IACtBD,EAAI,KAAKC,CAAC,EAGdE,EAAK,QAAQM,GAAQT,EAAI,KAAKS,CAAI,CAAC,CACrC,CACA,OAAOT,CACT,EAEapB,GACT,CAAC8B,EAAcC,EAAqCC,EAA+BC,EAClFC,EAA0BV,EAAuBE,IAAuC,CACvF,IAAMS,EAAaH,EAAO,CAAC,EAAE,KAEvBI,EAAaC,EAAU,KAAKb,CAAW,EACvCc,EAAaD,EAAU,KAAKX,CAAW,EAEvCa,EAAQC,EAAc,KAAMR,EAAO,CAAC,EAAE,SAAUG,CAAU,EAC1DM,EAASC,EAAe,SAAUR,EAAgBV,CAAW,EAE7DmB,EAAgB,GAEhBC,EAAsB;AAAA,+CACaH,EAAO,KAAK,OAAO,KAAKE,CAAa;AAAA,SA+C9E,MAAO,CACL,KAAAb,EACA,YAAAC,EACA,gBA/CuBc,GAA+B;AAAA,UACpDA,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBN,EAAOE,CAAM,CAAC;AAAA,UACjFG,CAAmB;AAAA;AAAA;AAAA;AAAA,WAIlBC,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA,2CAELA,CAAa;AAAA;AAAA;AAAA,4BAG5BF,EAAO,KAAK,OAAO,IAAIhD,GAAiBwC,CAAU,CAAC;AAAA;AAAA,wDAEvBU,CAAa;AAAA,6BACxCF,EAAO,KAAK,OAAO,IAAIF,EAAM,YAAY,YAAY,CAAC;AAAA,yBAC1DhD,GAAU0C,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,wCAKNU,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAM3BnD,GAAgByC,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAS3CQ,EAAO,YACH,cACA,GACIR,IAAe,OAAS,eAAeQ,EAAO,KAAK,OAAO,wBAClC,GAAG/C,GAAmBuC,CAAU,CAAC,EAAE,EAAE,CAAC;AAAA;AAAA,WASxE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUU,CAAc,CAAC,EACvD,cAAe,CAAC,EAAGE,CAAU,EAC7B,gBAAiB,CAAC,CAAC,KAAM,SAAU,KAAME,CAAU,CAAC,CACtD,EACF,CACF,EAEErC,GACF,CAAC6C,EAAyBhB,EAAciB,EACvCd,IAAiG,CAChG,IAAMe,EACFF,EAAQ,OAAO,SAAW,EAAIC,EAAaE,GAAiCH,EAAQ,OAAQC,CAAU,EAEtGG,EAAcF,EAAkB,KAChCE,EAAY,SAAW,GAAK,CAACF,EAAkB,oBACjDE,EAAcJ,EAAQ,OAAO,CAAC,EAAE,KAAK,IAAI,CAACK,EAAM9B,IAAMA,CAAC,GAEzD,IAAM+B,EAAgBf,EAAU,cAAca,EAAaJ,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EAEpFvB,EAAO6B,EACPb,EAAQO,EAAQ,OAAO,CAAC,EACtBO,EAAetD,GAAmBwB,EAAMuB,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EACvEO,EAAa,OAAS,IACxBd,EAAQO,EAAQ,QACZQ,GAA2BR,EAAQ,OAAO,CAAC,EAAGO,CAAY,EAAG,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAChG9B,EAAO5B,GAAiB4B,EAAK,OAAQgB,EAAM,KAAK,MAAM,GAGxD,GAAM,CAACf,EAAaE,CAAW,EAAI9B,GAA0B2C,EAAM,KAAMhB,CAAI,EACzEgC,EAAmB/B,EACnBwB,EAAkB,WACpBO,EAAmB1D,GAAqB2B,EAAa4B,CAAa,GAGpEN,EAAQ,QACJ9C,GACI8B,EAAM,CAAC,KAAMkB,EAAkB,SAAU,kBAAmB,CAAC,MAAM,CAAC,EAAG,CAACT,CAAK,EAAGN,EAChFa,EAAQ,OAAO,CAAC,EAAE,SAAUS,EAAkB7B,CAAW,EAC7D,CAAC,OAAQ,CAACa,CAAK,CAAC,CAAC,CACvB,EAESrC,GAAmB,CAAC4C,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEa5C,GAAiB,CAAC2C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa3C,GAAiB,CAAC0C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa1C,GAAwB,CAACyC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEazC,GAAkB,CAACwC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEaxC,GAAkB,CAACuC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEavC,GAAmB,CAACsC,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEatC,GAAkB,CAACqC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEarC,GAAwB,CAACoC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEapC,GAAqB,CAACmC,EAAyBC,IAAuC,CACjG9C,GAAa6C,EAAS,qBAAsBC,EAAY,QAAQ,CAClE,ICxQA,IAYMS,GAoBAC,GACOC,GA6EAC,GAUPC,GAeAC,GAWAC,GAWAC,GAWAC,GAWAC,GAoBAC,GAqBAC,GAoBAC,GAWAC,GAWAC,GAWAC,GAsBOC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GA/WbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KACAC,KAEM/B,GAAkBgC,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,0BAA0B,CAE9C,EAYM/B,GAAkBgC,GAAU,CAAC,GAAI,GAAI,eAAeA,EAAM,aAAa,eAAe,CAAC,IAAK,EAAE,EACvF/B,GACT,CAACgC,EAAcC,EAAqCH,EAA+BI,EAClFC,EAAqBC,EAA0BC,EAAW,GAAOC,EAAoB,KAAuB,CAC3G,IAAMC,EAAwB,CAAC,EACzBC,EAAaV,EAAO,CAAC,EAAE,KACvBW,EAAYD,EAAW,OACvBE,EAAOC,EAAU,cAAcR,EAAWM,CAAS,EACnDG,EAAkB,CAACN,GAAqBI,EAAK,SAAW,EAC9DF,EAAW,QAAQ,CAACK,EAAGC,IAAM,CACvBF,GAAmBF,EAAK,QAAQI,CAAC,GAAK,EACpCT,GACFE,EAAY,KAAK,CAAC,EAGpBA,EAAY,KAAKM,CAAC,CAEtB,CAAC,EACD,IAAME,EAAaR,EAAY,OACzBS,EAAaL,EAAU,KAAKJ,CAAW,EA4C7C,MAAO,CACL,KAAAP,EACA,YAAAC,EACA,gBA9CuBgB,GAA+B,CACtD,IAAMC,EAAoB,CAAC,EAErBnB,EAAQoB,EAAc,KAAMrB,EAAO,CAAC,EAAE,SAAUW,CAAS,EACzDW,EAASC,EAAe,SAAUjB,EAAgBW,CAAU,EAC5DO,EAAMpB,EAASH,EAAOqB,EAAQV,CAAI,EACpCa,EAAYD,EAAI,CAAC,EAErB,QAASE,EAAI,EAAGC,EAAI,EAAGD,EAAIf,EAAWe,IAEhCZ,GAAmBF,EAAK,QAAQc,CAAC,GAAK,GACpCnB,GACFoB,IAGFF,EAAY,YAAYC,CAAC,eAAeA,CAAC,MAAMhB,EAAWgB,CAAC,CAAC,MAAMA,CAAC;AAAA,oBAC3DF,EAAI,CAAC,EAAE,SAAS,YAAY,EAAI,qBAAqBE,CAAC,IAAM,EAAE;AAAA,oBAC9DzB,EAAM,WAAW,gBAAiByB,EAAG,IAAIA,CAAC,EAAE,CAAC;AAAA,oBAC7CD,CAAS;AAAA,qBAGjBL,EAAQ,KAAK,GAAGnB,EAAM,WAAW,gBAAiByB,EAAGJ,EAAO,WAAW,iBAAkBK,CAAC,CAAC,CAAC,GAAG,EAC/FA,KAGJ,MAAO;AAAA;AAAA,UAELR,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBlB,EAAOqB,CAAM,CAAC;AAAA;AAAA,UAElFH,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,+BACvDlB,EAAM,KAAK,OAAO;AAAA,iCAChBqB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAEzDF,EAAQ,KAAK;AAAA,CAAI,CAAC;AAAA,YAClBI,EAAI,CAAC,CAAC;AAAA,YACNA,EAAI,CAAC,CAAC;AAAA,YACNC,CAAS;AAAA,YACTD,EAAI,CAAC,CAAC;AAAA,YACNA,EAAI,SAAW,EAAIF,EAAO,YAAY,aAAc,OAAO,EAAIE,EAAI,MAAM,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,UAE5F,EAME,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMf,EAAa,SAAUH,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKY,EAAa,EAAuB,CAAC,EAClE,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAMA,CAAU,EAAG,GAAGU,EAA2BlB,CAAU,EAC5E,GAAGkB,EAA2BnB,CAAW,CAC3C,CACF,EACF,CACF,EAEStC,GACT,CAAC6B,EAA+B6B,IAAmD,CACjF,IAAMjB,EAAiB,CAAC,EACxB,OAAIZ,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,GACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQ8B,GAAKlB,EAAK,KAAK,OAAOkB,CAAC,CAAC,CAAC,EAEzDC,GACH,CAAC,KAAAnB,EAAM,SAAUiB,EAAW,SAAU,kBAAmBA,EAAW,iBAAiB,CAAC,CAC5F,EAEEzD,GACF,CAAC4D,EAAyB9B,EAAc2B,EAA8BzB,IAA6B,CACjG,IAAMJ,EAASgC,EAAQ,OACjBC,EACFjC,EAAO,SAAW,EAAI6B,EAAa1D,GAAiC6B,EAAQ6B,CAAU,EAE1FG,EAAQ,QACJ9D,GACIgC,EAAM,CAAC,KAAM+B,EAAkB,SAAU,kBAAmB,CAAC,MAAM,CAAC,EAAG,CAACjC,EAAO,CAAC,CAAC,EACjFiC,EAAkB,mBAAqBA,EAAkB,KAAK,SAAW,EAAIhE,GAAOmC,EACpF6B,EAAkB,KAAMjC,EAAO,CAAC,EAAE,SAAUiC,EAAkB,SAC9DA,EAAkB,iBAAiB,EACvC,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEE5D,GAAoB,CAAC2D,EAAyBH,IAAuC,CACzF7D,GAAegE,EAAQ,MAAM,EAO7B5D,GAAiB4D,EAAS,eAAgBH,EANf,CAAC5B,EAAOqB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYrB,EAAM,aAAa,eAAe,CAAC,IAC/C,qBACL,CAC8D,CAChE,EAEM3B,GAAgB,CAAC0D,EAAyBH,IAAuC,CACrF7D,GAAegE,EAAQ,MAAM,EAO7B5D,GAAiB4D,EAAS,WAAYH,EANX,CAAC5B,EAAOqB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBrB,EAAM,aAAa,eAAe,CAAC,KACnD,EACL,CAC0D,CAC5D,EAEM1B,GAAgB,CAACyD,EAAyBH,IAAuC,CACrF7D,GAAegE,EAAQ,MAAM,EAO7B5D,GAAiB4D,EAAS,WAAYH,EANX,CAAC5B,EAAOqB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOrB,EAAM,aAAa,eAAe,CAAC,sBAC1C,sBACL,CAC0D,CAC5D,EAEMzB,GAAuB,CAACwD,EAAyBH,IAAuC,CAC5F7D,GAAegE,EAAQ,MAAM,EAO7B5D,GAAiB4D,EAAS,kBAAmBH,EANlB,CAAC5B,EAAOqB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBrB,EAAM,aAAa,eAAe,CAAC,KACnD,qBACL,CACiE,CACnE,EAEMxB,GAAiB,CAACuD,EAAyBH,IAAuC,CACtF7D,GAAegE,EAAQ,MAAM,EAgB7B5D,GAAiB4D,EAAS,YAAaH,EAfZ,CAAC5B,EAAOiC,EAAStB,IAAS,CACnD,IAAMuB,EAAU,CAAC,EACjB,QAAST,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bd,EAAK,QAAQc,CAAC,GAAK,GAAKd,EAAK,SAAW,IAC1CuB,EAAQ,KAAKlC,EAAM,WAAW,gBAAiByB,EAAG,CAAC,CAAC,EAIxD,MAAO,CACL,GAAGS,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAelC,EAAM,aAAa,eAAe,CAAC,IAClD,sBAAsBA,EAAM,aAAa,eAAe,CAAC,KACzD,EACF,CACF,CAC2D,CAC7D,EAEMvB,GAAkB,CAACsD,EAAyBH,IAAuC,CACvF7D,GAAegE,EAAQ,MAAM,EAiB7B5D,GAAiB4D,EAAS,aAAcH,EAhBb,CAAC5B,EAAOqB,EAAQV,IAAS,CAClD,IAAIwB,EAAO,EACX,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bd,EAAK,QAAQc,CAAC,GAAK,GAAKd,EAAK,SAAW,KAE1CwB,GAAQJ,EAAQ,OAAO,CAAC,EAAE,KAAKN,CAAC,GAIpC,MAAO,CACL,oBACA,GACA,cAAczB,EAAM,aAAa,eAAe,CAAC,KACjD,eAAeqB,EAAO,KAAK,KAAK,UAAUc,CAAI,IAChD,CACF,CAC4D,CAC9D,EAEMzD,GAAiB,CAACqD,EAAyBH,IAAuC,CACtF7D,GAAegE,EAAQ,MAAM,EAgB7B5D,GAAiB4D,EAAS,YAAaH,EAfZ,CAAC5B,EAAOiC,EAAStB,IAAS,CACnD,IAAMuB,EAAU,CAAC,EACjB,QAAST,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bd,EAAK,QAAQc,CAAC,GAAK,GAAKd,EAAK,SAAW,IAC1CuB,EAAQ,KAAK,iBAAiBT,CAAC,QAAQ,EAI3C,MAAO,CACL,GAAGS,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAelC,EAAM,aAAa,eAAe,CAAC,IAClD,sBAAsBA,EAAM,aAAa,eAAe,CAAC,KACzD,EACF,CACF,CAC2D,CAC7D,EAEMrB,GAAkB,CAACoD,EAAyBH,IAAuC,CACvF7D,GAAegE,EAAQ,MAAM,EAO7B5D,GAAiB4D,EAAS,aAAcH,EANb,CAAC5B,EAAOqB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYrB,EAAM,aAAa,eAAe,CAAC,IAC/C,EACL,CAC4D,CAC9D,EAEMpB,GAAiB,CAACmD,EAAyBH,IAAuC,CACtF7D,GAAegE,EAAQ,MAAM,EAO7B5D,GAAiB4D,EAAS,YAAaH,EANZ,CAAC5B,EAAOqB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYrB,EAAM,aAAa,eAAe,CAAC,IAC/C,EACL,CAC2D,CAC7D,EAEMnB,GAAuB,CAACkD,EAAyBH,IAAuC,CAC5F7D,GAAegE,EAAQ,MAAM,EAO7B5D,GAAiB4D,EAAS,kBAAmBH,EANlB,CAAC5B,EAAOqB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOrB,EAAM,aAAa,eAAe,CAAC,oBAC1C,EACL,CACiE,CACnE,EAEMlB,GACF,CAACsD,EAA0BzB,EAAyBJ,IAAwC,CAC1F,GAAII,EAAK,SAAW,EAClB,OAAOJ,EAGT,IAAIU,EAAa,EACboB,EAAa,EACjB,QAASC,EAAM,EAAGA,EAAM3B,EAAK,OAAQ2B,IAC/B3B,EAAK,QAAQ2B,CAAG,IAAM,GACxBrB,GAAcmB,EAAME,CAAG,EAEvBD,GAAcD,EAAME,CAAG,EAO3B,OAAOD,EAAa,IAAMpB,EAAa,IACzC,EAESlC,GAAa,CAACgD,EAAyBH,IAAuC,CACrF9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FnD,GAAgBsD,EAASH,CAAU,EAEnCW,GAAiBR,EAASH,CAAU,CAExC,EAEa5C,GAAW,CAAC+C,EAAyBH,IAAuC,CACnF9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FvD,GAAc0D,EAASH,CAAU,EAEjCY,GAAeT,EAASH,CAAU,CAEtC,EAEa3C,GAAW,CAAC8C,EAAyBH,IAAuC,CACnF9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FtD,GAAcyD,EAASH,CAAU,EAEjCa,GAAeV,EAASH,CAAU,CAEtC,EAEa1C,GAAkB,CAAC6C,EAAyBH,IAAuC,CAC1F9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FrD,GAAqBwD,EAASH,CAAU,EAExCc,GAAsBX,EAASH,CAAU,CAE7C,EAEazC,GAAY,CAAC4C,EAAyBH,IAAuC,CACpF9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FpD,GAAeuD,EAASH,CAAU,EAElCe,GAAgBZ,EAASH,CAAU,CAEvC,EAEaxC,GAAY,CAAC2C,EAAyBH,IAAuC,CACpF9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FlD,GAAeqD,EAASH,CAAU,EAElCgB,GAAgBb,EAASH,CAAU,CAEvC,EAEavC,GAAa,CAAC0C,EAAyBH,IAAuC,CACrF9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FjD,GAAgBoD,EAASH,CAAU,EAEnCiB,GAAiBd,EAASH,CAAU,CAExC,EAEatC,GAAY,CAACyC,EAAyBH,IAAuC,CACpF9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FhD,GAAemD,EAASH,CAAU,EAElCkB,GAAgBf,EAASH,CAAU,CAEvC,EAEarC,GAAkB,CAACwC,EAAyBH,IAAuC,CAC1F9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5F/C,GAAqBkD,EAASH,CAAU,EAExCmB,GAAsBhB,EAASH,CAAU,CAE7C,EAEapC,GAAe,CAACuC,EAAyBH,IAAuC,CACvF9C,GAAqBiD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FxD,GAAkB2D,EAASH,CAAU,EAErCoB,GAAmBjB,EAASH,CAAU,CAE1C,ICrXA,IAcMqB,GAeOC,GA0BAC,GA0BAC,GAjFbC,GAAAC,EAAA,kBAOAC,KAEAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,qBAAqB,CAEzC,EAQaR,GAAS,CAACS,EAAyBC,IAA0C,CACxFX,GAAeU,EAAQ,MAAM,EAC7B,IAAME,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,iBAAiBC,CAAC,QAAQ,EAG3C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,aAAa,eAAe,CAAC;AAAA,2BAC3E,OAAOA,EAAM,aAAa,eAAe,CAAC,IAAIF,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBAC5EE,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA,UAGhD,GAAIC,EAAO,YAAY,aAAc,YAAY,CACnD,CACF,EAEAJ,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMP,EAAW,SAAU,kBAAmB,CAAC,MAAM,CAAC,EAAG,CAACD,EAAQ,OAAO,CAAC,CAAC,EAAGE,EACzF,CAACD,EAAW,IAAI,IAAmBA,EAAW,QAAQ,EAC1D,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEaT,GAAS,CAACQ,EAAyBC,IAA0C,CACxFX,GAAeU,EAAQ,MAAM,EAC7B,IAAME,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,iBAAiBC,CAAC,QAAQ,EAG3C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,aAAa,eAAe,CAAC;AAAA,2BAC3E,OAAOA,EAAM,aAAa,eAAe,CAAC,IAAIF,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBAC5EE,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA,UAGhD,GAAIC,EAAO,YAAY,aAAc,YAAY,CACnD,CACF,EAEAJ,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMP,EAAW,SAAU,kBAAmB,CAAC,MAAM,CAAC,EAAG,CAACD,EAAQ,OAAO,CAAC,CAAC,EAAGE,EACzF,CAACD,EAAW,IAAI,IAAmBA,EAAW,QAAQ,EAC1D,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEaR,GAA4BQ,GACrCQ,GAA4BR,CAAoE,IClFpG,IAmEMS,GAsKOC,GAuFPC,GAsGAC,GA+EOC,GASPC,GAmHOC,GAjnBbC,GAAAC,EAAA,kBAGAC,KAEAC,KAEAC,KA4DMX,GAA0B,CAACY,EAA+BC,IAAoD,CAmClH,IAAMC,EAAQF,EAAO,CAAC,EAChBG,EAAUH,EAAO,CAAC,EAClBI,EAAOJ,EAAO,CAAC,EACfK,EAAYL,EAAO,CAAC,EACpBM,EAAON,EAAO,CAAC,EACfO,EAAuBP,EAAO,CAAC,EAErC,GAAIM,GAAQC,EACV,MAAM,IAAI,MAAM,4DAA4D,EAG9E,GAAIL,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,sCAAsC,EAGxD,IAAMM,EAAYN,EAAM,KAAK,CAAC,EACxBO,EAAiBP,EAAM,KAAK,CAAC,EAC7BQ,EAAkBR,EAAM,KAAK,CAAC,EAEpC,GAAIE,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAID,EAAQ,KAAK,SAAW,EAC1B,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIA,EAAQ,KAAK,CAAC,IAAMO,EACtB,MAAM,IAAI,MAAM,uEAAuE,EAGzF,GAAIN,EAAK,KAAK,CAAC,IAAMD,EAAQ,KAAK,CAAC,EACjC,MAAM,IAAI,MAAM,oFAAoF,EAGtG,IAAIQ,EAAcP,EAAK,KAAK,CAAC,EAAI,EAC7BQ,EAAcD,EACdE,EAAcD,EAClB,GAAIX,EAAW,eAAe,OAAS,EAAG,CACxC,GAAIA,EAAW,eAAe,SAAW,EACvC,MAAM,IAAI,MAAM,mDAAmD,EAErE,QAAWa,KAAMb,EAAW,eAC1B,GAAIa,EAAKb,EAAW,WAAa,EAC/B,MAAM,IAAI,MAAM,mDAAmD,EAIvEU,EAAcV,EAAW,eAAe,CAAC,EACzCW,EAAcX,EAAW,eAAe,CAAC,EACzCY,EAAcZ,EAAW,eAAe,CAAC,CAC3C,CAEA,IAAMc,EAAmBN,EAEzB,GAAIE,IAAgBC,EAClB,MAAM,IAAI,MAAM,6DAA6D,EAG/E,GAAIR,EAAK,KAAK,CAAC,IAAMO,EAAcC,EAAcC,EAC/C,MAAM,IAAI,MAAM,+EAA+E,EAGjG,IAAIG,EAAqB,EACzB,GAAIV,EAAM,CACR,GAAIM,IAAgBC,EAClB,MAAM,IAAI,MAAM,oDAAoD,EAEtE,GAAIP,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,qCAAqC,EAEvD,GAAIA,EAAK,KAAK,CAAC,IAAM,EACnB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAK,KAAK,CAAC,IAAME,EACnB,MAAM,IAAI,MAAM,kDAAkD,EAEpE,GAAIF,EAAK,KAAK,CAAC,IAAML,EAAW,SAC9B,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAIK,EAAK,KAAK,CAAC,IAAMM,EAAcX,EAAW,SAC5C,MAAM,IAAI,MAAM,gEAAgE,EAG7EA,EAAW,yBACde,EAAqBV,EAAK,KAAK,CAAC,EAGpC,CAEA,IAAMW,EAAsBF,EAAmBC,EACzCE,EAAoB,GAEpBC,EAAW,EACjB,GAAId,EAGF,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAIC,EACF,MAAM,IAAI,MAAM,uBAAuB,EAEzC,GAAIC,EACF,MAAM,IAAI,MAAM,uCAAuC,EAGzD,MAAO,CACL,UAAAC,EACA,eAAAC,EACA,mBAAAO,EACA,iBAAAD,EACA,oBAAAE,EACA,kBAAAC,EACA,gBAAAR,EACA,WAAYC,EACZ,YAAAE,EACA,SAAU,KAAK,MAAMF,EAAcV,EAAW,QAAQ,EACtD,UAAW,KAAK,MAAMY,EAAcZ,EAAW,QAAQ,EACvD,SAAUA,EAAW,SACrB,iBAAkB,GAClB,uBAAwB,GACxB,gBAAiBA,EAAW,gBAC5B,SAAAkB,EACA,MAAOlB,EAAW,MAClB,oBAAqB,GACrB,aAAc,GACd,UAAW,CACb,CACF,EAEaZ,GAAwB,CAAC+B,EAAyBlB,EAAmBmB,EAAWC,IAAc,CACzG,IAAMC,EAAaC,GAAiBF,CAAC,EACjCG,EAAK,GACHC,EAAQJ,EAAIC,EACdG,EAAQD,EACVA,EAAK,EACIC,EAAQ,EAAI,KACrBD,EAAK,KAAK,KAAKC,EAAQ,CAAC,GAE1B,IAAMC,EAAgB,KAAK,KAAKL,EAAIC,EAAaE,CAAE,EAE7CG,EACF,CAAC,CAAC,KAFiBC,GAA2B3B,EAAM,QAAQ,EAEpC,KAAM,EAAIoB,CAAC,EAAG,CAAC,KAAM,SAAU,KAAMI,CAAK,EAAG,CAAC,KAAM,SAAU,KAAMC,CAAa,CAAC,EACxGG,EAAWC,GAA4B7B,EAAM,SAAUqB,CAAU,EAEjES,EAAmBC,GAA+B,CACtD,IAAMC,EAAcC,EAAe,IAAKjC,EAAM,SAAUA,EAAM,KAAMqB,CAAU,EAC1Ea,EAAiB,oBACjBb,IAAe,EACjBa,EAAiB,gDACRb,IAAe,IACxBa,EACI,qGAEN,IAAMC,EAAgBC,GAA0BpC,EAAM,QAAQ,EACxDqC,EAA8B,CAClC,CAAC,KAAM,QAAS,KAAMF,CAAuC,EAAG,CAAC,KAAM,SAAU,KAAM,KAAK,EAC5F,CAAC,KAAM,kBAAmB,KAAM,KAAK,CACvC,EAEA,MAAO;AAAA,qCAC0BZ,CAAE;AAAA,qCACFA,CAAE;AAAA,IACnCQ,EAAa,iBAAiBM,CAAQ,EAAE,iBAAiBL,CAAW,CAAC;AAAA,IACrED,EAAa,UAAU,CACrBR,EAAI,EAAG,CACT,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,8BAIwBe,GAAW,MAAOjB,EAAY,gBAAgB,CAAC;AAAA;AAAA,gCAE7CkB,GAAUJ,EAAed,EAAY,eAAe,CAAC;AAAA;AAAA,yBAE5Da,CAAc;AAAA;AAAA;AAAA;AAAA,2BAIZX,CAAE;AAAA;AAAA;AAAA;AAAA,sBAIPe,GAAW,MAAOjB,EAAY,GAAG,CAAC;AAAA;AAAA,yBAE/BkB,GAAUJ,EAAed,EAAY,eAAe,CAAC;AAAA;AAAA,yBAErDmB,GAAU,YAAanB,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,2BAIhCE,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAMHe,GAAW,MAAOjB,EAAY,gBAAgB,CAAC;AAAA;AAAA;AAAA;AAAA,yBAIhDkB,GAAUJ,EAAed,EAAY,eAAe,CAAC;AAAA,0BACpDW,EAAY,KAAK,KAAK;AAAA;AAAA;AAAA,IAI9C,EAEAd,EAAQ,QACJ,CACE,KAAM,wBACN,YAAa,CAAC,KAAM,GAAGK,CAAE,IAAIK,CAAQ,IAAIP,CAAU,EAAE,EACrD,gBAAAS,EACA,WAAY,KAAO,CAAC,QAAS,CAAC,EAAG,cAAe,CAAC,EAAGX,CAAC,EAAG,gBAAAO,CAAe,EACzE,EACA,CAAC,OAAQ,CAAC1B,CAAK,EAAG,QAAS,CAAC,CAAC,CAAC,CACpC,EAEMZ,GACF,CAAC8B,EAAyBuB,EAAeC,EAAiBC,EACzDC,EAAiC7C,IAA+B,CAC/D,IAAM8C,EAAa,CACjBD,EAAW,UAAWA,EAAW,SAAUA,EAAW,eACtDA,EAAW,iBAAmBA,EAAW,kBAC3C,EAGME,EAAQ/C,EAAW,QAAU,EAAI,EAAM,KAAK,KAAK6C,EAAW,QAAQ,EAAI7C,EAAW,MACnFsB,EAAaC,GAAiBsB,EAAW,QAAQ,EACjDG,EAAqBH,EAAW,SAAWvB,EAC3C2B,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAKL,EAAW,oBAAsBI,CAAS,EACvD,EAAG,KAAK,KAAKJ,EAAW,eAAiBI,CAAS,EAClD,EAAGJ,EAAW,UAAYA,EAAW,QACvC,EACMM,EAAiBvB,GAA2Bc,EAAE,QAAQ,EACtDf,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAMkB,EAAW,cAAc,EAAG,CAAC,KAAM,SAAU,KAAMG,CAAkB,EAC5F,CAAC,KAAM,SAAU,KAAMH,EAAW,mBAAmB,EAAG,CAAC,KAAM,SAAU,KAAMA,EAAW,gBAAgB,EAC1G,CAAC,KAAMM,EAAgB,KAAMJ,CAAK,CACpC,EAEMhD,EAAS,CAAC2C,EAAGC,CAAG,EAEhBZ,EAAmBC,GAA+B,CACtD,IAAMoB,EAASC,EAAc,IAAKX,EAAE,SAAUA,EAAE,KAAMpB,CAAU,EAC1DgC,EAASD,EAAc,MAAOV,EAAI,SAAUA,EAAI,KAAMrB,CAAU,EAChEiC,EAASrB,EAAe,SAAUQ,EAAE,SAAUI,CAAU,EACxDjB,EAAWC,GAA4BY,EAAE,QAAQ,EAEjDJ,EAA8B,CAClC,CAAC,KAAM,IAAK,KAAM,KAAK,EAAG,CAAC,KAAM,IAAK,KAAM,KAAK,EAAG,CAAC,KAAM,IAAK,KAAM,KAAK,EAC3E,CAAC,KAAM,qBAAsB,KAAM,KAAK,EAAG,CAAC,KAAM,QAAS,KAAMT,CAAkC,CACrG,EACA,MAAO;AAAA,gBACCA,CAAQ;AAAA,sBACFoB,CAAS;AAAA;AAAA,gCAECG,EAAO,KAAK,OAAO,KAAKH,EAAYA,CAAS;AAAA,gCAC7CG,EAAO,KAAK,OAAO,KAAKH,EAAYA,CAAS;AAAA,IACzEjB,EAAa,iBAAiBM,CAAQ,EAAE,iBAAiBc,EAAQE,EAAQC,CAAM,CAAC;AAAA,IAChFvB,EAAa,UAAU,CACjBiB,EAAWA,EAAW,CACxB,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAWQV,GAAWV,EAAUP,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAoBtBmB,GAAU,QAASnB,CAAU,CAAC;AAAA;AAAA,IAGpD,EAEMkC,EAAQrC,EAAQ,QAClB,CACE,KAAM,iBACN,YAAa,CAAC,KAAM,GAAGG,CAAU,GAAI,kBAAmB,CAAC,OAAQ,MAAM,CAAC,EACxE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMwB,EAAY,SAAUJ,EAAE,SAAU,aAAgC,CAAC,EACpF,cAAeQ,EACf,gBAAAvB,CACF,GACA,gBAAAI,CACF,EACA,CAAC,OAAAhC,EAAQ,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAE9B,OAAAX,GACI+B,EAASqC,EAAOX,EAAW,UAAYA,EAAW,SAAWA,EAAW,eACxEA,EAAW,mBAAmB,EAE3BW,CACT,EAEElE,GACF,CAAC6B,EAAyBqC,EAAmBC,EAAeC,IAAgC,CAC1F,IAAMC,EAAc,CAACD,EAAO,UAAWA,EAAO,eAAgBA,EAAO,WAAW,EAC1ET,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAKQ,EAAO,UAAYT,CAAS,EACzC,EAAG,KAAK,KAAKS,EAAO,eAAiBT,CAAS,EAC9C,EAAGS,EAAO,UAAYA,EAAO,QAC/B,EACM/B,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAM+B,EAAO,cAAc,EAAG,CAAC,KAAM,SAAU,KAAMA,EAAO,mBAAmB,EAChG,CAAC,KAAM,SAAU,KAAMA,EAAO,SAAS,EAAG,CAAC,KAAM,SAAU,KAAMA,EAAO,QAAQ,EAChF,CAAC,KAAM,SAAU,KAAMA,EAAO,WAAW,CAC3C,EAEM3B,EAAmBC,GAA+B,CACtD,IAAM4B,EAAcP,EAAc,QAASG,EAAM,SAAUA,EAAM,IAAI,EAC/DK,EAAUR,EAAc,IAAKI,EAAE,SAAUA,EAAE,IAAI,EAC/CF,EAASrB,EAAe,SAAUsB,EAAM,SAAUG,CAAW,EAC7DrB,EAA8B,CAClC,CAAC,KAAM,IAAK,KAAM,KAAK,EAAG,CAAC,KAAM,IAAK,KAAM,KAAK,EAAG,CAAC,KAAM,IAAK,KAAM,KAAK,EAC3E,CAAC,KAAM,YAAa,KAAM,KAAK,EAAG,CAAC,KAAM,gBAAiB,KAAM,KAAK,CACvE,EACA,MAAO;AAAA,sBACOW,CAAS;AAAA,gCACCW,EAAY,KAAK,KAAK,KAAKX,EAAYA,CAAS;AAAA,gCAChDW,EAAY,KAAK,KAAK,KAAKX,EAAYA,CAAS;AAAA,IAC5EjB,EAAa,iBAAiBM,CAAQ,EAAE,iBAAiBsB,EAAaC,EAASN,CAAM,CAAC;AAAA,IACtFvB,EAAa,UAAU,CACjBiB,EAAWA,EAAW,CACxB,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBAQOW,EAAY,KAAK,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAyBnC,EAEA,OAAOzC,EAAQ,QACX,CACE,KAAM,iBACN,YAAa,CAAC,kBAAmB,CAAC,OAAQ,MAAM,CAAC,EACjD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMwC,EAAa,SAAUH,EAAM,SAAU,aAAgC,CAAC,EACzF,cAAeN,EACf,gBAAAvB,CACF,GACA,gBAAAI,CACF,EACA,CAAC,OAAQ,CAACyB,EAAOC,CAAC,EAAG,QAAS,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAC3C,EAESlE,GACT,CAAC4B,EAAyBuB,EAAeoB,EAAeL,EAAeM,EACtEC,EAA6BC,EAAgCC,EAC7D5D,EAA4CuC,EAAiC7C,IAA+B,CAC3G,IAAMwD,EAAQnE,GAAsB8B,EAASuB,EAAGoB,EAAGxD,EAAsBuC,EAAY7C,CAAU,EAE/FV,GAAwB6B,EAASqC,EAAOC,EAAGZ,CAAU,CACvD,EAEErD,GAAU,CAAC2B,EAAyB0B,IAAoC,CAC5E,IAAMc,EAAc,CAClBd,EAAW,UACXA,EAAW,SACXA,EAAW,eACXA,EAAW,QACb,EACMsB,EAAItB,EAAW,eACfuB,EAAIvB,EAAW,gBACfwB,EAAIxB,EAAW,SACfI,EAAY,GACZC,EAAW,CACf,EAAG,KAAK,KAAKL,EAAW,SAAWI,CAAS,EAC5C,EAAG,KAAK,KAAKJ,EAAW,eAAiBI,CAAS,EAClD,EAAGJ,EAAW,UAAYA,EAAW,QACvC,EACM9C,EAAS,CAACoB,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,CAAC,EACjEQ,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAMwC,CAAC,EAAG,CAAC,KAAM,SAAU,KAAMC,CAAC,EAAG,CAAC,KAAM,SAAU,KAAMC,CAAC,EAC9E,CAAC,KAAM,SAAU,KAAMxB,EAAW,QAAQ,EAAG,CAAC,KAAM,SAAU,KAAMA,EAAW,QAAQ,EACvF,CAAC,KAAM,SAAU,KAAMA,EAAW,UAAU,EAC5C,CAAC,KAAM,SAAU,KAAMA,EAAW,WAAaA,EAAW,WAAaA,EAAW,WAAW,CAC/F,EAEMd,EAAmBC,GAA+B,CACtD,IAAMsC,EAAUpC,EAAe,WAAYnC,EAAO,CAAC,EAAE,SAAU4D,CAAW,EACpEY,EAAUrC,EAAe,WAAYnC,EAAO,CAAC,EAAE,SAAU4D,CAAW,EACpEa,EAAUtC,EAAe,WAAYnC,EAAO,CAAC,EAAE,SAAU4D,CAAW,EACpE1D,EAAQoD,EAAc,QAAStD,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACjE0E,EAASpB,EAAc,SAAUtD,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACnEI,EAAOkD,EAAc,OAAQtD,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/D8B,EAAW5B,EAAM,KAAK,QAEtBqC,EAA8B,CAClC,CAAC,KAAM,IAAK,KAAM,KAAK,EAAG,CAAC,KAAM,IAAK,KAAM,KAAK,EAAG,CAAC,KAAM,IAAK,KAAM,KAAK,EAAG,CAAC,KAAM,YAAa,KAAM,KAAK,EAC7G,CAAC,KAAM,YAAa,KAAM,KAAK,EAAG,CAAC,KAAM,cAAe,KAAM,KAAK,EAAG,CAAC,KAAM,MAAO,KAAM,KAAK,CACjG,EACA,MAAO;AAAA,sBACWW,CAAS;AAAA,oCACKpB,CAAQ,KAAKoB,EAAYA,CAAS;AAAA,sCAChCpB,CAAQ,KAAKoB,EAAYA,CAAS;AAAA,sCAClCpB,CAAQ,KAAKoB,EAAYA,CAAS;AAAA,sCAClCpB,CAAQ,KAAKoB,EAAYA,CAAS;AAAA,IACpEjB,EAAa,iBAAiBM,CAAQ,EAAE,iBAAiBrC,EAAOwE,EAAQtE,EAAMmE,EAASC,EAASC,CAAO,CAAC;AAAA,IACxGxC,EAAa,UAAU,CACrBiB,EAAWA,EAAW,CACxB,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAWapB,CAAQ;AAAA,mBACRA,CAAQ;AAAA,mBACRA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAoCzB,EAEA,OAAOV,EAAQ,QACX,CACE,KAAM,mBACN,YAAa,CAAC,kBAAmB,CAAC,OAAQ,OAAQ,MAAM,CAAC,EACzD,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMwC,EAAa,SAAUxC,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAgC,EAC1F,CAAC,KAAMwC,EAAa,SAAUxC,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAgC,EAC1F,CAAC,KAAMwC,EAAa,SAAUxC,EAAQ,OAAO,CAAC,EAAE,SAAU,aAAgC,CAC5F,EACA,cAAe+B,EACf,gBAAAvB,CACF,GACA,gBAAAI,CACF,EACA,CAAC,OAAAhC,EAAQ,QAAS,CAAC,GAAI,GAAI,EAAE,CAAC,CAAC,CACrC,EAEaN,GAAY,CAAC0B,EAAyBnB,IAAqC,CACtF,IAAM0D,EAASvE,GAAwBgC,EAAQ,OAAQnB,CAAU,EAE3D,CAAC0C,EAAGoB,EAAGL,CAAC,EAAIjE,GAAQ2B,EAASuC,CAAM,EAEzC,OAAOnE,GACH4B,EAASuB,EAAGoB,EAAGL,EAAGtC,EAAQ,OAAO,CAAC,EAAG,OAAW,OAAW,OAAWA,EAAQ,OAAO,CAAC,EAAGuC,EAAQ1D,CAAU,CACjH,ICxnBA,IAqBM0E,GAkCAC,GAgFOC,GAGAC,GA1IbC,GAAAC,EAAA,kBAGAC,KAGAC,KACAC,KAGAC,KAWMT,GAAiB,CAACU,EAA+BC,IAA0C,CAC/F,GAAI,CAACD,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,sCAAsC,EAGxD,IAAME,EAAkB,CAACC,EAA2BC,EAA6BC,IAAoB,CACnG,IAAMC,EAAIF,EAAS,OACnB,GAAIE,IAAMH,EAAO,OACf,MAAM,IAAI,MAAM,GAAGE,CAAO,uBAAuBC,CAAC,EAAE,EAEtDF,EAAS,QAAQ,CAACG,EAAG,IAAM,CACzB,GAAIA,IAAMJ,EAAO,CAAC,EAChB,MAAM,IAAI,MAAM,GAAGE,CAAO,SAAS,CAAC,gBAAgB,CAExD,CAAC,CACH,EAEA,GAAIL,EAAO,CAAC,EAAE,KAAK,OAAS,EAAG,CAC7B,IAAMQ,EAAQP,EAAW,SAAW,OAC/BA,EAAW,QAAUD,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,EACvBA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,EAAE,OAAOA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,CAAC,EACxGA,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGC,EAAW,QAAU,EAAI,MAAS,EAC9DC,EAAgBF,EAAO,CAAC,EAAE,KAAMQ,EAAO,qBAAqB,EAC5DN,EAAgBF,EAAO,CAAC,EAAE,KAAMQ,EAAO,iBAAiB,EACxDN,EAAgBF,EAAO,CAAC,EAAE,KAAMQ,EAAO,oBAAoB,EAC3DN,EAAgBF,EAAO,CAAC,EAAE,KAAMQ,EAAO,mBAAmB,CAC5D,MACEN,EAAgBF,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,qBAAqB,EAC1DE,EAAgBF,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,iBAAiB,EACtDE,EAAgBF,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,oBAAoB,EACzDE,EAAgBF,EAAO,CAAC,EAAE,KAAM,CAAC,CAAC,EAAG,mBAAmB,CAE5D,EAEMT,GACF,CAACS,EAA+BC,IAAiD,CAC/E,GAAM,CAAC,QAAAQ,EAAS,QAAAC,EAAS,OAAAC,CAAM,EAAIV,EAC7BW,EAASZ,EAAO,CAAC,EAAE,KACnBa,EAAaH,EAAUI,GAAiBF,EAAOA,EAAO,OAAS,CAAC,CAAC,EAAI,EACrEG,EAAcJ,IAAW,QAAUC,EAAO,OAAS,EAAIC,EAAa,EACpEG,EAAaC,EAAU,KAAKL,CAAM,EAAIC,EAEtCK,EAAoBC,GAAqBP,EAAO,MAAM,GAAKF,EAC3DU,EAAcF,EAAoBN,EAAO,OAASA,EAClDS,EAAIC,EAAc,IAAKtB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMa,CAAU,EACrEU,EAAQD,EAAc,QAAStB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMe,CAAW,EAC9ES,EAAOF,EAAc,OAAQtB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMe,CAAW,EAC5EU,EAAYH,EAAc,YAAatB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMe,CAAW,EACtFW,EAAWJ,EAAc,WAAYtB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMe,CAAW,EACpFY,EAAIC,EAAe,IAAK5B,EAAO,CAAC,EAAE,SAAUoB,EAAaP,CAAU,EAGnEgB,EAAc,IAAc,CAChC,IAAIC,EAAU,GACd,GAAIpB,EACFoB,EAAU,iBACNlB,EAAO,SAAW,EAAM,KACpBD,IAAW,OAAS,iBAAiBC,EAAO,OAAS,CAAC,OAAOC,CAAU,GACnD,kBAAkB,YAE1CF,IAAW,OACbmB,EAAU;AAAA,cACRH,EAAE,WAAW,gBAAiB,IAAK,GAAG,CAAC;AAAA,4BACzBA,EAAE,gBAAgB,eAAe,CAAC,QAC7C,CAELG,EAAU,kBAAkBP,EAAM,KAAK,OAAO;AAAA,qDACLX,EAAO,OAAS,CAAC,KAE1D,QAASmB,EAAI,EAAGA,EAAIR,EAAM,KAAMQ,IAC9BD,GAAW,YAAYC,CAAC,qBAAqBA,CAAC,KAEhDD,GAAW,iBAAiBP,EAAM,gBAAgB,UAAU,CAAC,GAC/D,CAEF,OAAOO,CACT,EACME,EAAgCC,GAAyB;AAAA,oBACjDxB,CAAO;AAAA,IACvBwB,EAAO,gBAAgB,aAAc,KAAK,EAAE,iBAAiBZ,EAAGE,EAAOC,EAAMC,EAAWC,EAAUC,CAAC,CAAC;AAAA,IACpGM,EAAO,UAAU,CAAC;AAAA,IAClBA,EAAO,sCAAsC,qBAAqB,CAAC;AAAA,0BAC7CN,EAAE,gBAAgB,gBAAgBd,CAAU,EAAE,CAAC;AAAA,MACnEgB,EAAY,CAAC;AAAA,kBACDN,EAAM,YAAY,SAAS,CAAC;AAAA,iBAC7BC,EAAK,YAAY,SAAS,CAAC;AAAA,sBACtBC,EAAU,YAAY,SAAS,CAAC;AAAA,qBACjCC,EAAS,YAAY,SAAS,CAAC;AAAA,cACtCL,EAAE,YAAY,YAAY,CAAC;AAAA;AAAA,MAEnCM,EAAE,YAAY,aAAc,OAAO,CAAC;AAAA,KAEpC,MAAO,CACL,KAAM,qBACN,YAAa,CACX,KAAM,GAAG1B,EAAW,OAAO,IAAIA,EAAW,MAAM,IAAIS,CAAO,IAAIG,CAAU,GACzE,kBAAmBK,EAAoB,CAAC,OAAQ,OAAQ,OAAQ,OAAQ,MAAM,EAAI,MACpF,EACA,gBAAiBc,EACjB,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMhC,EAAO,CAAC,EAAE,KAAM,SAAUA,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC9D,cAAe,CAAC,EAAG,KAAK,KAAKgB,EAAa,EAAuB,CAAC,EAClE,gBAAiBE,EACb,CACE,CAAC,KAAM,SAAU,KAAMF,CAAU,EACjC,GAAGkB,EAA2BtB,CAAM,CACtC,EACA,CACE,CAAC,KAAM,SAAU,KAAMI,CAAU,CACnC,CACN,EACF,CACF,EAESxB,GAA4BS,GACrCkC,GAA4BlC,CAAoE,EAEvFR,GAAY,CAAC2C,EAAyBnC,IAA8C,CAC/F,GAAM,CAAC,OAAAD,EAAQ,YAAAqC,CAAW,EAAID,EACxBE,EAAoB9C,GAAyB,CAAC,GAAGS,EAAY,YAAAoC,CAAW,CAAC,EAI/E,GAHIE,GAAI,OAAO,sBACbjD,GAAeU,EAAQsC,CAAiB,EAEtCrC,EAAW,aACb,MAAM,IAAI,MAAM,uDAAuD,EAEvEmC,EAAQ,QAAQ7C,GAAoCS,EAAQsC,CAAiB,CAAC,CAElF,ICrJA,IASME,GAkBAC,GAkCOC,GA7DbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEMN,GAAkBO,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,IAAK,IAAK,IAAI,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC9C,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMN,GAA4BM,GAA+C,CAC/E,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAExBE,EAAWF,EAAO,CAAC,EAAE,KAAK,CAAC,EAE3BG,EAAaC,EAAU,KAAKH,CAAW,EAAI,EAE3CI,EAAWL,EAAO,CAAC,EAAE,SACrBM,EAAQC,EAAc,QAASF,EAAUJ,EAAa,CAAC,EACvDO,EAAOD,EAAc,OAAQF,EAAU,CAACH,CAAQ,EAAG,CAAC,EACpDO,EAAWF,EAAc,WAAYF,EAAUJ,EAAa,CAAC,EAC7DS,EAASC,EAAe,SAAUN,EAAUJ,EAAa,CAAC,EAahE,MAAO,CACL,KAAM,UACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CACpE,GACA,gBAjBuBS,GAA+B;AAAA,qBACrCV,CAAQ;AAAA,IACzBU,EAAa,iBAAiBN,EAAOE,EAAMC,EAAUC,CAAM,CAAC;AAAA;AAAA,IAE5DE,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA,kBAClDG,EAAM,YAAY,YAAY,CAAC;AAAA,UACvCE,EAAK,YAAY,uBAAuB,CAAC,MAAMC,EAAS,YAAY,YAAY,CAAC;AAAA,MACrFC,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAU7C,CACF,EAEaf,GAAWkB,GAAkC,CACxDpB,GAAeoB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQnB,GAAyBmB,EAAQ,MAAM,CAAC,CAC1D,IChEA,IAeMC,GA4BAC,GAiBOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAGAC,GASAC,GAIAC,GA8BPC,GAMOC,GAaAC,GAIAC,GAIAC,GAQAC,GAGAC,GAgBAC,GAcAC,GAMAC,GAIAC,GAIAC,GAOAC,GAOAC,GAIAC,GAIAC,GAIAC,GAMAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAQAC,GAhRbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMzC,GACF,CAAC0C,EAA4BC,EAAkBC,EAAuBC,EACrEC,EAAmCC,IAA8C,CAChF,IAAMC,EAAU,KAAK,KAAKL,EAAW,CAAC,EAElCM,EAAa,GACb,OAAOH,GAAa,SACtBG,EAAa,GAAGH,CAAQ,MAExBG,EAAaH,EAAS,GAAG,EAG3B,IAAMI,EAAQC,EAAc,YAAaP,EAAe,CAACI,CAAO,EAAG,CAAC,EAC9DI,EAASC,EAAe,aAAcR,EAAgB,CAACG,CAAO,EAAG,CAAC,EAExE,MAAO;AAAA,QACLN,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBQ,EAAOE,CAAM,CAAC;AAAA;AAAA,IAEnFL,GAA4B,EAAE;AAAA;AAAA,IAE9BL,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA;AAAA,cAE/DQ,EAAM,YAAY,YAAY,CAAC;AAAA,MACvCE,EAAO,YAAY,aAAcH,CAAU,CAAC;AAAA,IAE9C,EAEEhD,GACF,CAACiD,EAAmBI,EAAcR,EAAmCC,EACpEQ,EAAmBV,EAAyBK,EAAM,YAA2B,CAC5E,KAAAI,EACA,YAAa,CAAC,KAAMC,EAAU,kBAAmB,CAAC,MAAM,CAAC,EACzD,gBAAiBb,GAAgB1C,GAC7B0C,EAAcc,EAAU,KAAKN,EAAM,IAAI,EAAGA,EAAM,SAAUL,EAAgBC,EAAUC,CAAwB,EAChH,WAAaU,IAAkB,CAC7B,QAAS,CAAC,CAAC,KAAMP,EAAM,KAAM,SAAUL,CAAc,CAAC,EACtD,cACI,CAAC,EAAG,KAAK,KAAKW,EAAU,KAAKC,EAAa,CAAC,EAAE,IAAI,EAAI,GAA0B,CAAgB,CAAC,EACpG,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKD,EAAU,KAAKN,EAAM,IAAI,EAAI,CAAC,CAAC,CAClE,CACF,EACF,GAEShD,GAAOwD,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEavD,GAAQuD,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEatD,GAASsD,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEarD,GAAQqD,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEapD,GAASoD,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEanD,GAAQmD,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EACalD,GAASkD,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAOajD,GAAuBkD,GAChCC,GAA4BD,CAA0B,EAG7CjD,GAAO,CAACgD,EAAyBC,IAAqC,CACjF,IAAIE,EACJ,OAAQF,EAAW,GAAI,CACrB,QACEE,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,QACEA,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,OACEA,EAAO,aACP,MACF,QACE,MAAM,IAAI,WAAW,0EAA0EF,EAAW,EAAE,EAAE,CAClH,CACAD,EAAQ,QACJzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQG,EAAM,OAAWF,EAAW,SAAUA,EAAW,EAAE,CAAC,CAClH,EAOMhD,GAAoCmD,GAAkD,CAC1F,IAAMC,EAAOD,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,OAAS,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAIE,GACtFC,EAAOH,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,OAAS,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAII,GAC5F,OAAON,GAA4B,CAAC,IAAAG,EAAK,IAAAE,CAAG,CAAC,CAC/C,EAEarD,GAAO,CAAC8C,EAAyBS,IAAyC,CACrF,IAAMR,EAAaD,EAAQ,OAAO,SAAW,EAAIS,EAAiBxD,GAAiC+C,EAAQ,MAAM,EAC3GU,EAAWC,GAA0BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QACJzD,GACIyD,EAAQ,OAAO,CAAC,EAAG,OAAQY,GAAK,SAASA,CAAC,0BAA2B;AAAA,4BACnDF,CAAQ,YAAYA,CAAQ,IAAIT,EAAW,GAAG;AAAA,4BAC9CS,CAAQ,YAAYA,CAAQ,IAAIT,EAAW,GAAG;AAAA,EAEhEA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEa9C,GAAQ6C,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa5C,GAAO4C,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa3C,GAAQ2C,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAMa1C,GAAwB2C,GACjCC,GAA4BD,CAA6B,EAEhD1C,GAAM,CAACyC,EAAyBC,IAAsC,CACjF,IAAMS,EAAWC,GAA0BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,MAAO,GAAK,YAAY,CAAC,IAAK;AAAA,uBAChCU,CAAQ,IAAIT,EAAW,KAAK;AAAA;AAAA,kBAEjCS,CAAQ,QAAQA,CAAQ;AAAA;AAAA;AAAA;AAAA,wBAIlBA,CAAQ,cAAcA,CAAQ;AAAA;AAAA,KAGhDT,EAAW,QAAQ,CAAC,CAC1B,EAEazC,GAAU,CAACkD,EAAkBG,EAAU,QAAU;AAAA,YAClDA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA;AAAA,iBAEFH,CAAQ,QAAQA,CAAQ;AAAA;AAAA;AAAA;AAAA,GAM5BjD,GAAOuC,GAAkC,CACpD,IAAMU,EAAWC,GAA0BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,YAAYA,CAAC,IAAKpD,GAAQ,QAAQkD,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC9F,EAEahD,GAAOsC,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEarC,GAASqC,GAAkC,CACtDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEapC,GAAQoC,GAAkC,CACrD,IAAMU,EAAWC,GAA0BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,OAAQY,GAAK,SAASA,CAAC,sBAAsBA,CAAC,0BACjEpD,GAAQ,QAAQkD,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC7C,EAEa7C,GAAY,CAACmC,EAAyBC,IAAsC,CACvF,IAAMS,EAAWC,GAA0BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,YAAa,GAAK,8BAA8B,CAAC,KAAK,CAAC,KAAK,CAAC,YAAYU,CAAQ,UACpG,6BAA6BA,CAAQ,IAAIT,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,CACzF,EAEanC,GAAOkC,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa7C,GAAOiC,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAOY,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa5C,GAAcgC,GAAkC,CAC3DA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,aAAcY,GAAK,OAAOA,CAAC,EAAE,CAAC,CAChG,EAEa3C,GAAQ+B,GAAkC,CACrD,IAAMU,EAAWC,GAA0BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrEA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,OAAQY,GAAK,eAAeF,CAAQ,WAAWE,CAAC,KAAKA,CAAC,WAAWF,CAAQ,SAAS,CAAC,CAC5G,EAEaxC,GAAW8B,GAAkC,CACxDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,UAAWY,GAAK,sBAAsBA,CAAC,KAAK,CAAC,CAC/G,EAEazC,GAAO6B,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa5B,GAAQ4B,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa3B,GAAQ2B,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa1B,GAAO0B,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEazB,GAAQyB,GAAkC,CACrDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEaxB,GAAkB,CAACwB,EAAyBC,IAAwC,CAC/F,IAAMS,EAAWC,GAA0BX,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACrE,OAAAA,EAAQ,QAAQzD,GACZyD,EAAQ,OAAO,CAAC,EAAG,kBAAmB,GAAK,eAAeU,CAAQ,WAAW,CAAC,KAAK,CAAC,8BACpF,wCAAwCA,CAAQ,KAAKT,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,EAC5F,CACT,EAEaxB,GAAOuB,GAAkC,CACpDA,EAAQ,QAAQzD,GAA6ByD,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,IClRA,IAUMc,GAkBAC,GAyCOC,GArEbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEMP,GAAkBQ,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,KAAM,KAAM,KAAK,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACjD,MAAM,IAAI,MAAM,4CAA4C,EAG9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMP,GAAkCO,GAA+C,CACrF,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAAK,MAAM,EACzCC,EAAY,CAAC,EAAIA,EAAY,CAAC,EAAI,EAElC,IAAMC,EAAQC,EAAc,QAASH,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EACpEI,EAAOD,EAAc,OAAQH,EAAO,CAAC,EAAE,SAAU,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAAG,CAAC,EACvEK,EAASC,EAAe,SAAUN,EAAO,CAAC,EAAE,SAAUC,EAAa,CAAC,EAEpEM,EAAaC,EAAU,KAAKP,CAAW,EAAI,EAC3CQ,EAAWC,GAA4BV,EAAO,CAAC,EAAE,QAAQ,EAsB/D,MAAO,CACL,KAAM,gBACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKO,EAAa,EAAuB,CAAC,CACpE,GACA,gBA1BuBI,GAA+B;AAAA;AAAA,yBAEjCX,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,EAAI,CAAC;AAAA;AAAA,IAE9CW,EAAa,iBAAiBT,EAAOE,EAAMC,CAAM,CAAC;AAAA;AAAA,IAElDO,GAAQ,QAAQH,CAAQ,IAAKA,CAAQ,CAAC;AAAA;AAAA,IAEtCE,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCJ,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ9DF,EAAO,YAAY,aAAc,uBAAuB,CAAC;AAAA,IAU7D,CACF,EAEaX,GAAiBmB,GAAkC,CAC9DrB,GAAeqB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpB,GAA+BoB,EAAQ,MAAM,CAAC,CAChE,ICxEA,IAiBMC,GAyGAC,GA6EAC,GAQOC,GAIAC,GAIAC,GAMAC,GAIAC,GAsBAC,GAIAC,GAMAC,GAMAC,GAMAC,GA7QbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KASMjB,GACF,CAACkB,EAA4BC,EAA0BC,EAA0BC,EAChFC,EAAoBC,EAAsBC,EAAsCC,EAChFC,EAAeC,EAAeC,EAAoBC,EAClDC,IAAsC,CACrC,IAAIC,EACAC,EACA,OAAOP,GAAa,SACtBM,EAAmBC,EAAmB,CAACC,EAAGC,IAAM,GAAGT,CAAQ,KAAKQ,CAAC,MAAMC,CAAC,KAC/D,OAAOT,GAAa,WAC7BM,EAAmBC,EAAmBP,GAEtCM,EAAmBN,EAAS,OAC5BO,EAAmBP,EAAS,QAG9B,IAAMU,EAAoBN,EAAoBV,EAAM,OAASA,EACvDiB,EAAoBP,EAAoBT,EAAM,OAASA,EACvDiB,EAAoBR,EAAoBR,EAAW,OAASA,EAC5DiB,EAASC,EAAe,aAAcX,EAAYS,EAAmB,CAAC,EACtEJ,EAAIO,EAAc,QAASd,EAAOS,EAAmB,CAAC,EACtDD,EAAIM,EAAc,QAASb,EAAOS,EAAmB,CAAC,EAExDK,EACJ,GAAInB,EACF,GAAIC,EAAa,CACf,IAAMmB,EAAgBC,EAAU,KAAKxB,CAAK,IAAM,EAC1CyB,EAAgBD,EAAU,KAAKvB,CAAK,IAAM,EAC1CyB,EAAuB1B,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EAC3E2B,EAAuB1B,EAAM,OAAS,GAAKA,EAAMA,EAAM,OAAS,CAAC,EAAI,IAAM,EAC7EsB,GAAiBE,EACnBH,EAAaH,EAAO,YAChB,aACAN,EACIU,EAAgB,GAAGT,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,EACvFW,EAAgB,GAAGV,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,CAAC,CAAC,EAEjGO,EAAa;AAAA,kCACSH,EAAO,gBAAgB,iBAAiB,CAAC;AAAA,4BAC/CL,EAAE,2BAA2B,gBAAiBK,CAAM,CAAC;AAAA,4BACrDJ,EAAE,2BAA2B,gBAAiBI,CAAM,CAAC;AAAA,cAEjEA,EAAO,YACH,aACAN,EACIR,GAA+BqB,EAC3BZ,EAAE,YAAY,cAAc,EAC5B,GAAGA,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,cAAc,CAAC,kBACpDT,GAA+BsB,EAC3BZ,EAAE,YAAY,cAAc,EAC5B,GAAGA,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,cAAc,CAAC,iBAAiB,CAAC,CAAC;AAAA,WAGvF,MACEO,EAAaH,EAAO,YAChB,aAAcN,EAAiBC,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAEzF,CACL,GAAI,CAACX,EACH,MAAM,IAAI,MAAM,sFAAsF,EAGxG,IAAMwB,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,EAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IACpD,MAAO;AAAA,+BACcA,CAAC,MAAMX,EAAO,gBAAgB,qBAAqBW,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMhB,EAAE,2BAA2B,gBAAgBgB,CAAC,GAAIX,CAAM,CAAC;AAAA,yBAChEW,CAAC,MAAMf,EAAE,2BAA2B,gBAAgBe,CAAC,GAAIX,CAAM,CAAC;AAAA,wBACjEW,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAInB,EAAiBoB,EAAaC,CAAW,CAAC;AAAA,WAE9E,EACIxB,IAAe,EACjBa,EAAa;AAAA;AAAA,cAETM,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCN,EAAa;AAAA,cACTM,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACH7B,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBe,EAAGC,EAAGI,CAAM,CAAC;AAAA;AAAA,UAE9ER,GAA4B,EAAE;AAAA;AAAA,UAE9BZ,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,UACvEuB,CAAU;AAAA,QAEhB,EAEExC,GACF,CAACoD,EAAcC,EAAkBrB,EAAeC,EAAeT,EAC9DK,EAAmCyB,EAAyBtB,EAAE,WAA0B,CACvF,IAAMuB,EAAc,CAACb,EAAU,SAASV,EAAE,KAAMC,EAAE,IAAI,EAClDuB,EAAcxB,EAAE,KAChByB,EAAaf,EAAU,KAAKV,EAAE,IAAI,EAElCX,EAAY,GACZE,EAA8B,GAG5BmC,EAAc,CAACH,CAAW,EAChC,GAAIA,EAAa,CACf,IAAMI,EAAkBC,GAAc,UAAU5B,EAAE,KAAMC,EAAE,KAAM,EAAK,EACrE,GAAI,CAAC0B,EACH,MAAM,IAAI,MAAM,8CAA+C,EAEjEH,EAAcG,EACdF,EAAaf,EAAU,KAAKc,CAAW,EACvC,IAAMf,EAAgBC,EAAU,KAAKV,EAAE,IAAI,IAAM,EAC3CW,EAAgBD,EAAU,KAAKT,EAAE,IAAI,IAAM,EAC3CW,EAAuBZ,EAAE,KAAK,OAAS,GAAKA,EAAE,KAAKA,EAAE,KAAK,OAAS,CAAC,EAAI,IAAM,EAC9Ea,EAAuBZ,EAAE,KAAK,OAAS,GAAKA,EAAE,KAAKA,EAAE,KAAK,OAAS,CAAC,EAAI,IAAM,EACpFyB,EAAY,KAAKjB,CAAa,EAC9BiB,EAAY,KAAKf,CAAa,EAC9Be,EAAY,KAAKd,CAAoB,EACrCc,EAAY,KAAKb,CAAoB,EAErC,IAAIgB,EAAkB,EACtB,QAASC,EAAI,EAAGA,EAAIN,EAAY,OAAQM,IAAK,CAC3C,IAAMC,EAAO/B,EAAE,KAAKA,EAAE,KAAK,OAAS8B,CAAC,GAAK,EACpCE,EAAO/B,EAAE,KAAKA,EAAE,KAAK,OAAS6B,CAAC,GAAK,EAC1C,GAAIC,IAASC,EACXH,GAAmBE,MAEnB,MAEJ,CACIF,EAAkB,IAAM,GAC1BtC,EAA8B,GAC9BF,EAAY,KACHoB,GAAiBE,GAAiBC,GAAwBC,KACnExB,EAAY,GAEhB,MAEEA,EAAY,GAEdqC,EAAY,KAAKrC,CAAS,EAC1B,IAAMO,EAAoBqC,GAAqBjC,EAAE,KAAK,MAAM,GAAKiC,GAAqBhC,EAAE,KAAK,MAAM,GAC/FgC,GAAqBT,EAAY,MAAM,EAC3C,MAAO,CACL,KAAAJ,EACA,YAAa,CACX,KAAMC,EAAWK,EAAY,IAAKV,GAAMA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,EAC9D,kBAAmBpB,EAAoB,CAAC,OAAQ,MAAM,EAAI,CAAC,OAAQ,MAAM,CAC3E,EACA,gBAAkBX,GAAiBlB,GAC/BkB,EAAce,EAAE,KAAMC,EAAE,KAAMuB,EAAanC,EAAWkC,EAAahC,EAA6BC,EAChGQ,EAAE,SAAUC,EAAE,SAAUqB,EAAgB1B,EAAmBC,CAAwB,EACvF,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAM2B,EAAa,SAAUF,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,GAA0B,CAAsB,CAAC,EAC3F,gBAAiB7B,EACb,CACE,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKc,EAAU,KAAKc,CAAW,EAAI,CAAC,CAAC,EACjE,GAAGU,EAA2BlC,EAAE,IAAI,EACpC,GAAGkC,EAA2BjC,EAAE,IAAI,EACpC,GAAGiC,EAA2BV,CAAW,CAC3C,EACA,CACE,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKd,EAAU,KAAKc,CAAW,EAAI,CAAC,CAAC,CACnE,CACN,EACF,CACF,EAEEvD,GACF,CAACkE,EAAyBf,EAAc5B,EAA8BK,EACrEwB,EAAmBC,IAAkC,CACpDa,EAAQ,QAAQnE,GACZoD,EAAMC,GAAY,GAAIc,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAG3C,EAAUK,EACtEyB,CAAc,CAAC,CACrB,EAESpD,GAAOiE,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa9B,GAAOgE,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa7B,GAAS+D,GAAkC,CACtDlE,GACIkE,EAAS,QAAU,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEa5B,GAAO8D,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa3B,GAAO6D,GAAkC,CACpD,IAAMC,EAAO7B,EAAc,QAAS4B,EAAQ,OAAO,CAAC,EAAE,SAAUA,EAAQ,OAAO,CAAC,EAAE,IAAI,EAAE,KAAK,MAE7FlE,GACIkE,EAAS,MAAQ,CAAC,OAAQ,CAAC,EAAGlC,IAAM,cAAc,CAAC,IAAIA,CAAC,IAAK,OAAQ,CAAC,EAAGA,IAAM,qBAAqB,CAAC,IAAIA,CAAC,GAAG,EAC7G;AAAA,wBACkBmC,CAAI,SAASA,CAAI,QAAQA,CAAI;AAAA,iBACpCA,CAAI;AAAA,iBACJA,CAAI;AAAA,uBACEA,CAAI;AAAA,iBACVA,CAAI;AAAA;AAAA,+BAEUA,CAAI,6BAA6BA,CAAI,qBAAqBA,CAAI,IAV1EA,IAAS,MAAQ,QAAU,EAW5B;AAAA;AAAA,oCAEkBA,CAAI,eAAeA,CAAI,cAAcA,CAAI;AAAA;AAAA,oBAEzDA,CAAI;AAAA;AAAA,OAEjB,CACP,EAEa7D,GAAO4D,GAAkC,CACpDlE,GAAYkE,EAAS,MAAO,CAACnC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEazB,GAAW2D,GAAkC,CACxDlE,GACIkE,EAAS,UAAY,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEaxB,GAAQ0D,GAAkC,CACrDlE,GACIkE,EAAS,OAAS,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACnG,QAAwB,CAC9B,EAEavB,GAAkByD,GAAkC,CAC/DlE,GACIkE,EAAS,iBAAmB,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAC3G,OAAW,QAAwB,CACzC,EAEatB,GAAewD,GAAkC,CAC5DlE,GACIkE,EAAS,cAAgB,CAAC,OAAQ,CAACnC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EACxG,OAAW,QAAwB,CACzC,ICjRA,IAcMoC,GAqBAC,GAWAC,GAmBAC,GAkGOC,GAKAC,GAxKbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMV,GAAkBW,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAGlC,IAAMC,EAAYD,EAAO,CAAC,EAAE,SACtBE,EAAsBF,EAAO,CAAC,EAAE,KAAK,OAE3C,QAAWG,KAASH,EAAQ,CAE1B,GAAIG,EAAM,WAAaF,EACrB,MAAM,IAAI,MAAM,kCAAkC,EAIpD,GAAIE,EAAM,KAAK,SAAWD,EACxB,MAAM,IAAI,MAAM,0CAA0C,CAE9D,CACF,EAEMZ,GAA0B,CAACc,EAAyBC,IAAwC;AAAA;AAAA,wCAE1DD,CAAe,MAAMC,CAAmB;AAAA,gCAChDD,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,KAGtBb,GAAmB,CAACS,EAAkCM,IAA0B,CACpF,IAAMF,EAAkBJ,EAAO,OAEzBO,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIJ,EAAiB,EAAEI,EAAG,CACxC,IAAMC,EAAgBH,EAAO,YAAY,aAAcN,EAAOQ,CAAC,EAAE,aAAa,SAAS,CAAC,EACpFJ,IAAoB,EACtBG,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,qBAAqBC,CAAC,QAAQC,CAAa,IAAI,EACrDD,IAAMJ,EAAkB,EACjCG,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,0BAA0BC,CAAC,OAAOC,CAAa,IAAI,CAEtE,CACA,OAAOF,EAAU,KAAK;AAAA,CAAI,CAC5B,EAEMf,GAA0B,CAACQ,EAA+BU,IAA8B,CAC5F,IAAMC,EAAaX,EAAO,CAAC,EAAE,KAAK,MAAM,EACxC,GAAIU,GAAQC,EAAW,QAAUD,EAAQ,GAAKC,EAAW,OACvD,MAAM,IAAI,MAAM,8DAA+D,EAEjF,IAAMC,EAAgBF,EAAO,EAAKC,EAAW,OAASD,EAAOA,EAGvDG,EAAcF,EAAW,MAAM,CAAC,EACtC,QAASH,EAAI,EAAGA,EAAIR,EAAO,OAAQQ,IAAK,CACtC,IAAMM,EAAad,EAAOQ,CAAC,EAAE,KAAK,MAAM,EACxC,QAASO,EAAY,EAAGA,EAAYJ,EAAW,OAAQI,IAErD,GAAIA,IAAcH,EAChBC,EAAYD,CAAY,GAAKE,EAAWC,CAAS,UAG1CJ,EAAWI,CAAS,IAAMD,EAAWC,CAAS,EACrD,MAAM,IAAI,MAAM,kCAAkC,CAGxD,CAEA,IAAMC,EAAaC,EAAU,KAAKJ,CAAW,EAEvCK,EAAmB,IAAI,MAAclB,EAAO,MAAM,EAClDmB,EAAY,IAAI,MAAqBnB,EAAO,MAAM,EAClDoB,EAAWpB,EAAO,CAAC,EAAE,SAEvBqB,EAAc,EACZC,EAAwD,CAAC,EACzDC,EAAoB,CAAC,EACrBC,EAA4B,CAAC,EAC7BC,EAAoC,CAAC,CAAC,KAAM,SAAU,KAAMT,CAAU,CAAC,EAC7E,QAASR,EAAI,EAAGA,EAAIR,EAAO,OAAQ,EAAEQ,EACnCa,GAAerB,EAAOQ,CAAC,EAAE,KAAKI,CAAY,EAC1CM,EAAiBV,CAAC,EAAIa,EACtBG,EAA0B,KAAKE,GAAqB1B,EAAOQ,CAAC,EAAE,KAAK,MAAM,CAAC,EAC1Ee,EAAkB,KAAKC,EAA0BhB,CAAC,EAAIR,EAAOQ,CAAC,EAAE,KAAK,OAASR,EAAOQ,CAAC,EAAE,IAAI,EAC5FW,EAAUX,CAAC,EAAImB,EAAc,QAAQnB,CAAC,GAAIY,EAAUG,EAAkBf,CAAC,CAAC,EACxEc,EAAkB,KAAKE,EAA0BhB,CAAC,EAAI,OAAS,MAAM,EACrEiB,EAAgB,KAAK,CAAC,KAAM,SAAU,KAAMP,EAAiBV,CAAC,CAAC,CAAC,EAElE,QAASA,EAAI,EAAGA,EAAIR,EAAO,OAAQ,EAAEQ,EAC/BgB,EAA0BhB,CAAC,GAC7BiB,EAAgB,KAAK,GAAGG,EAA2B5B,EAAOQ,CAAC,EAAE,IAAI,CAAC,EAItE,IAAMqB,EAA6BH,GAAqBb,EAAY,MAAM,EACtEgB,GACFJ,EAAgB,KAAK,GAAGG,EAA2Bf,CAAW,CAAC,EAGjE,IAAMiB,EAAoBD,EAA6BhB,EAAY,OAASA,EACtEP,EAASyB,EAAe,SAAUX,EAAUU,CAAiB,EAE7DE,EAAc1B,EAAO,WAAW,UAAWM,CAAY,EACvDP,EACF,MAAM,KAAK,MAAMa,EAAiB,MAAM,EAAE,KAAK,CAAC,EAAE,IAAIV,GAAK,4BAA4BA,CAAC,EAAE,EAAE,KAAK,GAAG,EAClGyB,EAAmBC,GAA+B;AAAA;AAAA,KAErD,IAAM,CACPA,EAAa,gBAAgB,aAAc,KAAK,EAChD,QAAS1B,EAAI,EAAGA,EAAIR,EAAO,OAAQQ,IACjC0B,EAAa,gBAAgB,mBAAmB1B,CAAC,GAAI,KAAK,EAE5D,OAAO0B,EAAa,iBAAiB,GAAGf,EAAWb,CAAM,CAC3D,GAAG,CAAC;AAAA;AAAA,IAEFhB,GAAwB4B,EAAiB,OAAQb,CAAmB,CAAC;AAAA;AAAA,IAErE6B,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,oBAE3D5B,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2CAEb0B,CAAW;AAAA;AAAA,0CAEZd,EAAiB,MAAM,MAAMb,CAAmB;AAAA,QAClF2B,CAAW;AAAA;AAAA;AAAA,MAGbzC,GAAiB4B,EAAWb,CAAM,CAAC;AAAA,KAGvC,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGI,CAAI,GAAI,kBAAAY,CAAiB,EAChD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUb,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKgB,EAAa,EAAuB,CAAC,EAClE,gBAAAS,CACF,GACA,gBAAAQ,CACF,CACF,EAEaxC,GAAS,CAAC0C,EAAyBC,IAAuC,CACrF/C,GAAe8C,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ3C,GAAwB2C,EAAQ,OAAQC,EAAW,IAAI,CAAC,CAC1E,EAEa1C,GAAyB0C,GAClCC,GAA4B,CAAC,KAAMD,EAAW,IAAc,CAAC,ICzKjE,IAYaE,GAsBAC,GAlCbC,GAAAC,EAAA,kBAGAC,KASaJ,GAAuB,CAACK,EAA0CC,IAClB,CACvD,OAAQD,EAAW,WAAY,CAC7B,IAAK,OACH,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,sBAAsBC,CAAS,SAAS,EAC3F,IAAK,UACH,MAAO,CACL,mBAAoB,GACpB,gBAAiB,YAAYA,CAAS,YAAYA,CAAS,wBAC7D,EACF,IAAK,OACH,MAAO,CACL,mBAAoB,mBAAmBA,CAAS,IAAID,EAAW,OAAQ,qBAAqBC,CAAS,IACjGD,EAAW,OAAQ,KACvB,gBAAiB,6CACnB,EAEF,QACE,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,EAAE,CACvD,CACF,EAESJ,GACRI,GAAgF,CAC/E,IAAME,EAAaF,GAAY,YAAwB,GAEvD,GAAIE,IAAe,OAAQ,CACzB,GAAM,CAACC,EAASC,CAAO,EAAIJ,GAAY,mBAAyC,CAACK,GAAUC,EAAQ,EACnG,MAAO,CAAC,WAAAJ,EAAY,QAAAE,EAAS,QAAAD,EAAS,mBAAoB,GAAGD,CAAU,IAAIC,CAAO,IAAIC,CAAO,EAAE,CACjG,CACA,MAAO,CAAC,WAAAF,EAAY,mBAAoBA,CAAU,CACpD,IC3CJ,IAqBaK,GAeAC,GApCbC,GAAAC,EAAA,kBAqBaH,GAAc,CAACI,EAAmBC,IAAqB,CAClE,OAAQD,EAAW,CACjB,IAAK,GACH,OAAOC,EACT,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,QACE,MAAM,IAAI,MAAM,GAAGD,CAAS,8BAA8B,CAC9D,CACF,EAEaH,GAAeK,GAA6B;AAAA,QACjDA,EAAU,iDAAmD,EAAE;UCrCvE,IAqBaC,GArBbC,GAAAC,EAAA,kBAqBaF,GAAiBG,GAAuB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAO3CA,CAAS,YAAYA,CAAS,YAAYA,CAAS;AAAA;IC5B7D,IA6BMC,GAiBAC,GAyBOC,GAuFPC,GAiBAC,GAKOC,GAgKPC,GA8EOC,GAlabC,GAAAC,EAAA,kBAsBAC,KAEAC,KACAC,KAEAC,KAEMb,GAA6B,CAACc,EAAoBC,IAClDD,EACK;AAAA;AAAA;AAAA,wDAG6CC,EAAY,iBAAmB,EAAE;AAAA,UAI9E;AAAA;AAAA;AAAA,gDAGqCA,EAAY,iBAAmB,EAAE;AAAA,UAK3Ed,GAAyB,CAACe,EAAqBC,IAC/CD,EACK;AAAA;AAAA;AAAA;AAAA,UAIDC,IAAqB,EAAI,GAAK,6DAA6D;AAAA;AAAA;AAAA;AAAA;AAAA,YAKzFA,IAAqB,EAAI,GAAK,2CAA2C;AAAA,WAG1E;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMCA,IAAqB,EAAI,GAAK,yCAAyC;AAAA,WAKtEf,GACT,CAACgB,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,KAAe,CACpF,IAAMC,EAAaL,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CO,EAAaN,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CQ,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EACtCP,EAAmBS,EAAaP,EAAc,CAAC,EAC/CS,EAAgBP,EAAYF,EAAc,CAAC,EAEjD,GAAI,GAAIH,GAAcC,IAAqB,GAAKC,EAAc,CAAC,IAAM,GAC7D,CAACF,IAAeC,IAAqB,GAAKA,IAAqB,KACjES,EAAaP,EAAc,CAAC,IAAM,GAAKE,EAAYF,EAAc,CAAC,IAAM,GAAKD,EAAc,CAAC,IAAM,GACtG,MAAM,IAAI,MAAM,iBAAiBF,CAAU,8BACvCC,CAAgB,yBAAyBC,EAAc,CAAC,CAAC;AAAA,oCACjCD,CAAgB;AAAA,eACrCS,CAAU,yCAAyCP,EAAc,CAAC,CAAC,eACtEE,CAAS,0CAA0CF,EAAc,CAAC,CAAC,kBACnED,EAAc,CAAC,CAAC,aAAa,EAEnC,MAAO;AAAA,yCAC4BD,CAAgB,IAAIG,CAAI,MAAMM,EAAaT,CAAgB,MAAMU,CAAU;AAAA,2CACzEP,CAAI,MAAMK,EAAaP,EAAc,CAAC,CAAC,MAAMG,CAAS;AAAA;AAAA,uBAE1EH,EAAc,CAAC,CAAC;AAAA,uBAChBA,EAAc,CAAC,CAAC;AAAA,2BACZD,CAAgB;AAAA,oBACvBI,CAAS;AAAA;AAAA,2BAEFF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAUrEG,EAAS,IAAM,iBAAiB;AAAA,IAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,8CACvCS,CAAU;AAAA;AAAA,mBAErCF,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,yCAAyC;AAAA,iBAClGC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,wBAE9CH,CAAI;AAAA;AAAA;AAAA,8BAGEQ,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAM/B5B,GAA2BgB,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,0CAInBa,CAAa;AAAA;AAAA;AAAA,sFAI7Cb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAU/BE,IAAqB,EAAI,GAAK,4DAA4D;AAAA;AAAA,YAE1FhB,GAAuBe,EAAYC,CAAgB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAU5D,EAEEd,GAAyB,CAACW,EAAoBC,IAC9CD,EACK;AAAA;AAAA;AAAA,yCAG8BC,EAAY,iBAAmB,EAAE;AAAA,cAI/D;AAAA;AAAA;AAAA,iCAGsBA,EAAY,iBAAmB,EAAE;AAAA,cAK5DX,GAA2BY,GAC7BA,EAAa,gDAAkD,gDAItDX,GACT,CAACa,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,GACtEM,EAA4B,KAAkB,CAC7C,IAAML,EAAaN,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CM,EAAaP,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CO,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EAE5C,GAAI,EAAEG,EAAaR,EAAc,CAAC,IAAM,GAAKO,EAAaP,EAAc,CAAC,IAAM,GACzEE,EAAYF,EAAc,CAAC,IAAM,GACrC,MAAM,IAAI,MAAM,cAAcQ,CAAU,yCACpCR,EAAc,CAAC,CAAC,gBAAgBO,CAAU,yCAC1CP,EAAc,CAAC,CAAC,eAAeE,CAAS,yCAAyCF,EAAc,CAAC,CAAC,EAAE,EAEzG,IAAMW,EAAgBH,EAAaR,EAAc,CAAC,EAC5CY,EAAgBL,EAAaP,EAAc,CAAC,EAC5CS,EAAgBP,EAAYF,EAAc,CAAC,EAC3Ca,EAAgBH,EAClB;AAAA;AAAA;AAAA,gDAGsCL,CAAU;AAAA,gDACVC,CAAU;AAAA;AAAA;AAAA;AAAA;AAAA,iDAKTE,CAAU,2BAA2BR,EAAc,CAAC,CAAC;AAAA,mDACnDO,CAAU,2BAA2BP,EAAc,CAAC,CAAC;AAAA,YAC5FhB,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,iDAIRM,CAAS,2BAA2BF,EAAc,CAAC,CAAC;AAAA,uDAC9CM,CAAU,2BAA2BN,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,uCAGrEJ,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAO5CK,CAAI;AAAA;AAAA;AAAA,2DAG2BD,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,0BAI7DH,EAAa,oCAAoCG,EAAc,CAAC,CAAC,KACpD,iCAAiCA,EAAc,CAAC,CAAC,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0DAUzBA,EAAc,CAAC,CAAC;AAAA;AAAA,4DAEdA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,MAKlE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CAMkCK,CAAU;AAAA;AAAA,kCAEpBM,CAAa;AAAA,kCACbC,CAAa;AAAA,kCACbH,CAAa;AAAA;AAAA;AAAA;AAAA,sCAITE,CAAa;AAAA,wCACXC,CAAa;AAAA;AAAA;AAAA,QAG7C5B,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,sCAKfa,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BAMrBb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAOvCK,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOpBhB,GAAwBY,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBrC,MAAO;AAAA,yCAC4BI,CAAI,KAAKM,CAAU,MAAMC,CAAU;AAAA,yCACnCP,CAAI,KAAKK,CAAU,MAAMJ,CAAS;AAAA,yBAClDH,EAAc,CAAC,CAAC;AAAA,yBAChBA,EAAc,CAAC,CAAC;AAAA,sBACnBG,CAAS;AAAA;AAAA,2BAEJF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,kBAInEG,EAAS,IAAM,iBAAiB;AAAA,MAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,qBAClEO,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,yCAAyC;AAAA,mBAClGC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,4BAE5CH,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ1BY,CAAa;AAAA;AAAA,CAGf,EAEE1B,GACF,CAAC2B,EAAmBC,EAAkBC,EAAyBC,EAC9DC,EAAuCC,EAAiB,KAAkB,CACzE,GAAM,CAACC,EAAaC,EAAaC,CAAU,EAAIJ,EACzC,CAACK,EAAeC,EAAWC,EAAWC,CAAc,EAAIT,EACxDU,EAAiBC,GAAiBR,EAAaE,CAAU,EACzDO,EAAiBD,GAAiBP,EAAaC,CAAU,EACzDQ,EAAWC,GAA4Bd,EAAU,CAAC,EAAE,KAAK,MAAM,EAC/De,EAAc,IAAM,CACxB,IAAMC,EAAQT,EAAU,KAClBU,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBX,EAAU,KAAK,OAAO,IACpD,QAASY,EAAIH,EAAQ,EAAI,EAAGI,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAV,EAAe,QAAQS,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcF,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBE,CACT,EACMG,EAAc,IAAM,CACxB,IAAMC,EAAQd,EAAU,KAClBS,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBV,EAAU,KAAK,OAAO,IACpD,QAASW,EAAIG,EAAQ,EAAI,EAAGF,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAR,EAAe,QAAQO,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcI,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBJ,CACT,EAwCA,MAvCe;AAAA,kEAC6CZ,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBkB,EAAY,CAAC;AAAA,kBACLR,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kEAKcD,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBwB,EAAY,CAAC;AAAA,kBACLb,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,6DAKSe,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BACnEhB,CAAS;AAAA;AAAA;AAAA;AAAA,UAKzBC,EACI,mBAAmBI,EAAiB,cAAgB,GAAGqB,GAAY1B,EAAWgB,CAAQ,CAAC,aAAa,IAChE,EAAsC;AAAA,UAC9Ed,CAAe;AAAA,UACfU,EAAe,aAAa,oBAAqB,OAAO,CAAC;AAAA;AAAA;AAAA,KAK/D,EAEStC,GACT,CAACqD,EAA+BC,EAAoDC,EACnFC,EACAzB,EAAiB,KAAyD,CACzE,IAAM0B,EAASJ,EAAO,CAAC,EAAE,KACnBK,EAASL,EAAO,CAAC,EAAE,KAEnBM,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAaF,EAAO,MAAM,EAAG,EAAE,EAE/BG,EAAYL,EAAsBA,EAAoB,MAAM,EAAG,EAAE,EAAID,EAAY,MAAM,EAAG,EAAE,EAC5FO,EAAsBC,GAAqBF,EAAU,MAAM,EAC3DG,EAAmBF,EAAsBD,EAAU,OAASA,EAC5DrD,EAAYyD,GAAiB,YAAaZ,EAAO,CAAC,EAAE,SAAUW,EAAkB,CAAC,EACjFE,EAAYC,EAAU,KAAKN,CAAS,EAEpCO,EAAYX,EAAOA,EAAO,OAAS,CAAC,EACpCY,EAAWZ,EAAOA,EAAO,OAAS,CAAC,EACnCa,EAAYZ,EAAOA,EAAO,OAAS,CAAC,EACpCa,EAASF,EAAW,IAAM,GAAKC,EAAY,IAAM,EAGjDE,EAAoBJ,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDxD,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClD6D,EAAW,CACf,KAAK,KAAKH,EAAY1D,EAAc,CAAC,EAAI4D,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKJ,EAAYxD,EAAc,CAAC,EAAI4D,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKN,EAAYtD,EAAc,CAAC,EAAI4D,EAAkB,CAAC,CAAC,CAC/D,EAEM9B,EAAWC,GAA4BU,EAAO,CAAC,EAAE,QAAQ,EACzDqB,EAAaH,EAAS,EAAI,EAE1BI,EAAa,CAAC,GAAGhB,EAAYS,EAAWC,EAAWK,CAAU,EAC7DE,EAAwBb,GAAqBY,EAAW,MAAM,EAC9DE,EAAeD,EAAwBD,EAAW,OAASA,EAE3DG,EAAa,CAAC,GAAGlB,EAAYS,EAAUC,EAAYI,CAAU,EAC7DK,EAAwBhB,GAAqBe,EAAW,MAAM,EAC9DE,EAAeD,EAAwBD,EAAW,OAASA,EAE3DG,GAAkB,CAACf,EAAWE,EAAWE,EAAYI,CAAU,EAE/DQ,GAAIC,EAAc,IAAK9B,EAAO,CAAC,EAAE,SAAUwB,EAAcH,CAAU,EACnEU,GAAID,EAAc,IAAK9B,EAAO,CAAC,EAAE,SAAU2B,EAAcN,CAAU,EACnEW,EAAS/C,EAAe,SAAUe,EAAO,CAAC,EAAE,SAAU4B,GAAgB,OAAQP,CAAU,EACxFY,GAAiB,CAACJ,GAAGE,EAAC,EACtBG,GACF,CAAC,CAAC,KAAM,QAAS,KAAMnB,CAAS,EAAG,CAAC,KAAM,QAAS,KAAME,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMD,CAAQ,CAAC,EACpGP,GACFyB,GAAgB,KAAK,GAAGC,EAA2B3B,CAAS,CAAC,EAE3De,GACFW,GAAgB,KAAK,GAAGC,EAA2Bb,CAAU,CAAC,EAE5DI,GACFQ,GAAgB,KAAK,GAAGC,EAA2BV,CAAU,CAAC,EAEhE,IAAMW,GAAwD,CAAC,EAC/DA,GAAkB,KAAKb,EAAwB,OAAS,MAAM,EAC9Da,GAAkB,KAAKV,EAAwB,OAAS,MAAM,EAE9D,IAAMpD,GAAU0B,EAAO,OAAS,EAC1B,CAAC,mBAAAqC,GAAoB,gBAAA9D,EAAe,EAAI+D,GAAqBrC,EAAsB+B,EAAO,KAAK,KAAK,EACpGO,GAAmB7F,GACrB2E,EAAY/C,GAASC,GAAiB,CAACpB,EAAW0E,GAAGE,GAAGC,CAAM,EAAG,CAAC1B,EAAYC,EAAYC,CAAS,EACnG9B,CAAc,EAClB,GAAIJ,GAAS,CACX,IAAMkE,EAAiB9D,EAAiB2C,EAAa,EACrDY,GAAe,KAAKH,EAAc,OAAQ9B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQwC,CAAc,CAAC,EACpGN,GAAgB,KAAK,GAAGC,EAA2BnC,EAAO,CAAC,EAAE,IAAI,CAAC,EAElEoC,GAAkB,KAAK,MAAM,CAC/B,CACAF,GAAgB,KAAK,GAAGC,EAA2BP,EAAe,CAAC,EAEnE,IAAMa,EAAmBC,GAA+B;AAAA,IAEpDA,EAAa,gBAAgB,YAAa,KAAK,EAC1C,gBAAgB,YAAa,KAAK,EAClC,gBAAgB,WAAY,KAAK,EACjC,0BAA0BvF,CAAS,EACnC,iBAAiB,GAAG8E,GAAgBD,CAAM,CAAC;AAAA,IACtDK,EAAkB;AAAA,IAClBE,EAAgB;AAAA,IAEVrB,EAAS5E,GAA2B6E,EAAmB5D,EAAe8B,EAAUlC,CAAS,EAChFV,GAAuB0E,EAAmB5D,EAAe8B,EAAUlC,CAAS,CAAC;AAAA,qBAG1F,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM8C,EAAqB,mBAAqB,GAAGkB,CAAiB,GAC7DD,CAAM,GACNxC,CAAc,GACrB,kBAAA0D,EACF,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMlC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGoB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,gBAAAc,EACF,GACA,gBAAAO,CACF,CACF,IC3gBJ,IAgCME,GA6HOC,GA7JbC,GAAAC,EAAA,kBAqBAC,KAGAC,KAEAC,KAEAC,KACAC,KACAC,KAEMT,GACF,CAACU,EAAyBC,EAAoBC,EAAoBC,EAAmBC,EAAU,GAC9FC,EAA4BC,EAAoB,EAAGC,EAAoB,EAAGC,EAAmB,EAC7FC,EAAW,QAAkB,CAC5B,IAAMC,EAAeF,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,uBACT,IAAK,GACH,MAAO,kBAAkBC,CAAQ,8CACnC,IAAK,GACH,MAAO,2BACT,QACE,MAAM,IAAI,MAAM,oBAAoBD,CAAgB,oBAAoB,CAC5E,CACF,EACMG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,oDACT,IAAK,GACH,MAAO,wDACT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBZ,EAAiB;AAAA;AAAA,MAGA;AAAA;AAAA,MAIjCa,EAAkBb,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCc,EAAUd,EAAiB,2BAA6B,2BACxDe,EAASf,EAAiB,2BAA6B,2BACvDgB,EAAMhB,EAAiB,MAAQ,MAC/BiB,EAAMjB,EAAiB,MAAQ,MAC/BkB,EAAe;AAAA;AAAA,qBAENlB,EAAiB,gCAAkC,+BAA+B;AAAA,mBACpFgB,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA,iBAELC,CAAG;AAAA,iBACHA,CAAG;AAAA;AAAA;AAAA,gBAGJA,CAAG;AAAA,oBACCE,GAAYb,EAAmBG,CAAQ,CAAC;AAAA;AAAA;AAAA,8BAG9BK,CAAO,2BAA2BC,CAAM;AAAA,QAC9DH,CAAa;AAAA;AAAA,QAEbF,EAAYJ,CAAiB,CAAC;AAAA;AAAA,qBAI1Bc,EAAUpB,EAAkBC,GAAaE,EAAW;AAAA,wBACxCG,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SACbN,GAAYD,EAAY;AAAA,wBACxCI,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SAEzCY,EAAU,GAAGV,EAAYJ,CAAiB,CAAC,GAE3Ce,EAAUH,GAAYX,EAAkBC,CAAQ,EAChDc,EACFvB,EAAiBmB,GAAYb,EAAmBG,CAAQ,EAAIU,GAAYZ,EAAmBE,CAAQ,EACjGe,EACFxB,EAAiBmB,GAAYZ,EAAmBE,CAAQ,EAAIU,GAAYb,EAAmBG,CAAQ,EACjG,CAAC,mBAAAgB,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBtB,EAAYiB,CAAO,EAuBtF,MAtBiB;AAAA,MACjBG,CAAkB;AAAA,yDACiCF,CAAK;AAAA,QACtDvB,EAAiBoB,EAAUC,CAAO;AAAA;AAAA;AAAA,yDAGeG,CAAK;AAAA,QACtDxB,EAAiBqB,EAAUD,CAAO;AAAA;AAAA;AAAA,gEAGsBE,CAAO;AAAA,0BAC7Cd,CAAgB;AAAA;AAAA;AAAA;AAAA,uBAInBR,EAAiB,gCAAkC,+BAA+B;AAAA,QACjGa,CAAe;AAAA,QACfe,GAAYxB,CAAO,CAAC;AAAA,QACpBsB,CAAe;AAAA;AAAA;AAAA,MAKnB,EAESnC,GACT,CAACsC,EAA+BxB,EAA4ByB,EAAgCC,EAC3FC,EAAmBC,EAAkBC,EAAkBC,IAAoD,CAC1G,IAAMnC,EAAiBK,EAAW,SAAW,OACvC+B,EAAapC,EAAiB6B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClEQ,EAAYP,EAAY,CAAC,EACzBQ,EAAWtC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAYvC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAcxC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAE7DW,EAASzC,IAAmBoC,EAAa,IAAM,GAAKA,EAAa,IAAM,IAAMI,EAAc,IAAM,EAGjGE,EAAY1C,EAAiBwC,EAAcF,EAAWC,EACtDI,EAAY3C,EAAiBsC,EAAWC,EAAYC,EACpDI,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClDC,EAAoBd,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDe,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,iCAAiCD,CAAQ,EAAE,EAEtE,IAAMtC,EAAmBiC,EAAUzC,GAAkBoC,EAAa,IAAM,EAAI,EAAI,EAAK,EAE/EY,EAAaJ,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDI,EAAaL,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDK,EAAY,KAAK,IAAIN,EAAc,CAAC,EAAIpC,EAAkBoC,EAAc,CAAC,CAAC,EAE1E3C,EAAY8B,EAAYiB,IAAe,EACvC9C,EAAY8B,EAAYiB,IAAe,EACvC9C,EAAW8B,EAAWiB,IAAc,EAEpCC,EAAeV,EAAS,CAACjC,EAAkB,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EAC3D4C,EAAIC,GAA4BxB,EAAO,CAAC,EAAE,QAAQ,EAGlDyB,GAAab,EAAS,EAAI,EAC1Bc,GACF,CAAC,CAAC,KAAM,QAAS,KAAMxB,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMC,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMC,CAAQ,CAAC,EAClGuB,GACFC,EAAc,IAAK5B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQrB,IAAqB,EAAI,EAAIA,CAAgB,EACzGkD,EAAID,EAAc,IAAK5B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQyB,EAAU,EAC5EK,GAAiB,CAACH,GAAGE,CAAC,EAE5BH,GAAgB,KAAK,GAAGK,EAA2B/B,EAAO,CAAC,EAAE,IAAI,CAAC,EAClE0B,GAAgB,KAAK,GAAGK,EAA2B/B,EAAO,CAAC,EAAE,IAAI,CAAC,EAElE,IAAIgC,GAAmB;AAAA,qDACwBpB,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,8BAChDX,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA;AAAA,6EAEsBX,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA;AAAA,qCAEjEX,EAAS,MAAQ,EAAE;AAAA,SAElD,GAAIP,EAAS,CACX,IAAM4B,GAAOL,EAAc,OAAQ5B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQyB,EAAU,EACxFK,GAAe,KAAKG,EAAI,EAExBP,GAAgB,KAAK,GAAGK,EAA2B/B,EAAO,CAAC,EAAE,IAAI,CAAC,EAElEgC,IAAoB;AAAA,0DAC8BpB,EAAS,QAAQW,CAAC,IAAMA,CAAC;AAAA,+BACpDpD,EAAiB,IAAM,GAAG,GAAGyC,EAAS,MAAQ,EAAE;AAAA,UAEzE,CACA,IAAMsB,GAASC,EAAe,SAAUnC,EAAO,CAAC,EAAE,SAAUC,EAAY,OAAQwB,EAAU,EAC1F,OAAAC,GAAgB,KAAK,GAAGK,EAA2B9B,CAAW,CAAC,EACxD,CACL,KAAM,eACN,YAAa,CAAC,KAAMzB,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMyB,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,gBAAAS,EACF,GACA,gBAAkBU,IAA+B;AAAA,UAC/CC,GAAc,yBAAyB,CAAC;AAAA;AAAA;AAAA;AAAA,UAKtCD,GAAa,gBAAgB,YAAa,KAAK,EAC1C,gBAAgB,YAAa,KAAK,EAClC,gBAAgB,WAAY,KAAK,EACjC,iBAAiB,GAAGN,GAAgBI,EAAM,CAAC;AAAA,mDACT1D,EAAW,YAAY,CAAC,CAAC,KAAKA,EAAW,YAAY,CAAC,CAAC;AAAA,4CAC9DA,EAAW,KAAK,CAAC,CAAC,KAAKA,EAAW,KAAK,CAAC,CAAC;AAAA,+CACtCA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC7CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,UAC1FwD,EAAgB;AAAA,UAEdvE,GACIU,EAAgBC,EAAWC,EAAWC,EAAU+B,EAAS7B,EAAY8C,EAAa,CAAC,EAAGA,EAAa,CAAC,EACpGA,EAAa,CAAC,EAAGC,CAAC,CAAC;AAAA,cAEvBX,EACI0B,GAA2BtB,EAAmBD,EAAeQ,EAAG,OAAW,CAACpD,EAAgBkD,CAAS,EACrGkB,GACIvB,EAAmBD,EAAeQ,EAAG,OAAW,CAACpD,EAAgBkD,EAAW,GAAO,OACnFf,CAAyB,CAAC,EACxC,CACF,ICtQJ,IAeakC,GAfbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KACAC,KAMaN,GACT,CAACO,EAA+BC,EAC/BC,IAAqF,CACpF,IAAMC,EAAUH,EAAO,OAAS,EAC1BI,EAAcD,EAAU,8BAAgC,GACxDE,EAASL,EAAO,CAAC,EAAE,KACnBM,EAASN,EAAO,CAAC,EAAE,KACnBO,EAAyBD,EAAO,CAAC,EAAIL,EAAW,MAEhDO,EAAgBP,EAAW,SAAW,OACtCQ,EAAcC,GAChBL,EAAQC,EAAQL,EAAW,UAAWA,EAAW,KAAMA,EAAW,QAASO,CAAa,EACtFG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAASC,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAUS,CAAW,EACjE,CAAC,mBAAAM,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBhB,EAAYY,EAAO,KAAK,KAAK,EAC1FK,EAAIC,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUK,CAAM,EACjDe,EAAID,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUM,CAAM,EACjDe,EAAY,CAACH,EAAGE,CAAC,EACnBjB,GACFkB,EAAU,KAAKF,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,CAAC,EAGvE,IAAMsB,EAAmBC,GAA+B;AAAA,oCAC1BtB,EAAW,QAAQ,CAAC,CAAC,MAAMA,EAAW,QAAQ,CAAC,CAAC;AAAA,iCACnDA,EAAW,KAAK,CAAC,CAAC,MAAMA,EAAW,KAAK,CAAC,CAAC;AAAA;AAAA,IAEvEsB,EAAa,iBAAiB,GAAGF,EAAWR,CAAM,CAAC;AAAA;AAAA,IAEnDE,CAAkB;AAAA;AAAA,IAElBQ,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCZ,CAAU,CAAC;AAAA;AAAA,0BAE1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,8CAEhBL,EAAgB,EAAI,CAAC;AAAA,yDACVA,EAAgB,EAAI,CAAC,oBACpEA,EAAgB,EAAI,CAAC;AAAA,2CACYD,CAAsB;AAAA;AAAA,iBAEhDM,EAAO,KAAK,KAAK,MAAMA,EAAO,KAAK,KAAK;AAAA,kDACPP,EAAO,CAAC,CAAC;AAAA,uCACpBA,EAAO,CAAC,CAAC;AAAA,8CACFA,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,yCAE9BI,EAAOG,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,8CAIxBF,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA,yCAC9BI,EAAOG,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAK5DA,EAAgBU,EAAE,IAAI,QAAS,UAAW,SAAU,eAAe,EACnDA,EAAE,IAAI,QAAS,gBAAiB,UAAW,QAAQ,CAAC;AAAA,uBACvDE,EAAE,IAAI,iBAAkB,aAAc,UAAW,QAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,MAK3EhB,CAAW;AAAA,MACXY,CAAe;AAAA,MACfH,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,KAEzC,MAAO,CACL,KAAM,cACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CACR,KAAMC,EAA6BA,EAA2BO,CAAW,EAAIA,EAC7E,SAAUT,EAAO,CAAC,EAAE,QACtB,CAAC,EACD,cAAe,CAAC,EAAG,KAAK,KAAKW,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAW,CACF,CACF,IChGJ,IAWaE,GA0IPC,GAUOC,GA/JbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KACAC,KAEaR,GACT,CAACS,EAA+BC,EAAoDC,EACnFC,EACAC,EAAiB,KAAyD,CACzE,IAAMC,EAASL,EAAO,CAAC,EAAE,KACnBM,EAASN,EAAO,CAAC,EAAE,KAEnBO,EAAIF,EAAOA,EAAO,OAAS,CAAC,EAC5BG,EAAIF,EAAOA,EAAO,OAAS,CAAC,EAC5BG,EAAIJ,EAAOA,EAAO,OAAS,CAAC,EAC5BK,EAAaC,GAAiBH,CAAC,EAC/BI,EAAcD,GAAiBF,CAAC,EAChCI,EAAeF,GAAiBJ,CAAC,EACjCO,EAAaC,EAAU,KAAKb,CAAW,EAAIQ,EAAaG,EACxDG,EAAUhB,EAAO,OAAS,EAC1BiB,EAAYd,EAAsBA,EAAoB,MAAM,EAAG,EAAE,EAAID,EAAY,MAAM,EAAG,EAAE,EAE5FgB,EAAsB,CADVH,EAAU,KAAKE,CAAS,EACFV,EAAGC,CAAC,EACtCW,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAML,CAAU,EAAG,CAAC,KAAM,SAAU,KAAMP,CAAC,EAAG,CAAC,KAAM,SAAU,KAAMC,CAAC,EACvF,CAAC,KAAM,SAAU,KAAMC,CAAC,EAAG,GAAGW,EAA2BH,CAAS,EAAG,GAAGG,EAA2Bf,CAAM,EACzG,GAAGe,EAA2Bd,CAAM,CACtC,EACIU,GACFG,EAAgB,KAAK,GAAGC,EAA2BpB,EAAO,CAAC,EAAE,IAAI,CAAC,EAEpEmB,EAAgB,KAAK,GAAGC,EAA2BF,CAAmB,CAAC,EAEvE,IAAMG,EAAmBC,GAA+B,CACtD,IAAMC,EAAYC,GAAiB,aAAcxB,EAAO,CAAC,EAAE,SAAUiB,EAAU,MAAM,EAC/EQ,EAAIC,EAAc,IAAK1B,EAAO,CAAC,EAAE,SAAUK,EAAO,OAAQO,CAAW,EACrEe,EAAID,EAAc,IAAK1B,EAAO,CAAC,EAAE,SAAUM,EAAO,OAAQI,CAAU,EACpEkB,EAASC,EAAe,SAAU7B,EAAO,CAAC,EAAE,SAAUkB,EAAoB,OAAQR,CAAU,EAC5F,CAAC,mBAAAoB,EAAoB,gBAAAC,CAAe,EAAIC,GAAqB/B,EAAsB2B,EAAO,KAAK,KAAK,EACpGK,EAAiB,CAACR,EAAGE,CAAC,EACxBO,EAAc,GAClB,GAAIlB,EAAS,CACX,IAAMmB,GAAiB/B,EAAiBM,EAAa,EACrDuB,EAAe,KAAKP,EAAc,OAAQ1B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQmC,EAAc,CAAC,EACpGD,EAAc,GACV9B,EAAiB,uBAAuB+B,EAAc,KACrC,YAAYP,EAAO,KAAK,KAAK,kBAAkB,EACtE,CAEA,IAAMQ,GAAa/B,EAAO,MAAM,EAAG,EAAE,EAC/BgC,GAAa/B,EAAO,MAAM,EAAG,EAAE,EAC/BgC,GAAiBC,GAAiBH,GAAYnB,CAAS,EACvDuB,EAAiBD,GAAiBF,GAAYpB,CAAS,EACvDwB,GAAa,CAACC,GAAyBC,KAA4B,CACvE,IAAMC,GAAOF,GAAS,KAChBG,GAAOH,GAAS,KACtB,GAAIE,KAAS,EACX,MAAO,OAAOC,EAAI,cAAcH,GAAS,KAAK,OAAO,YAEvD,IAAMI,GAAYvB,EAAU,KACxBwB,EAAS,OAAOF,EAAI,aAAaH,GAAS,KAAK,OAAO,IAC1D,QAASM,EAAIJ,GAAO,EAAI,EAAGK,GAAIH,GAAY,EAAGE,GAAK,EAAGA,IAAKC,KACzDF,GAAU;AAAA,EAAKF,EAAI,YAAYG,CAAC,OAAOF,GAAY,EAAI,iBAAiBG,EAAC,IAAM,eAAe,IAEhG,OAAAN,GAAc,QAAQK,GAAK,CACzBD,GAAU;AAAA,EAAKF,EAAI,YAAYG,CAAC,QAClC,CAAC,EACDD,GAAU,GAAGF,EAAI,YAAYD,GAAO,CAAC;AAAA,uBACxBC,EAAI,YAAYD,GAAO,CAAC,UAC9BG,CACT,EAEMG,GAAa,IAAc,CAC/B,IAAIC,GAAU,eAAe1B,EAAE,KAAK,KAAK,IACzC,QAASuB,GAAI,EAAGA,GAAIpC,EAAaoC,KAC/BG,IAAW;AAAA,0BACGH,EAAC,yBAAyBA,EAAC,2BAA2BtC,CAAU,KAEhF,QAASsC,GAAI,EAAGA,GAAInC,EAAcmC,KAAK,CACrCG,IAAW,iCAAiCH,EAAC,yBAAyBpC,CAAW,KAEjF,QAASqC,GAAI,EAAGA,GAAIrC,EAAaqC,KAC/BE,IAAW;AAAA,qBACJH,EAAC,WAAWrB,EAAE,KAAK,KAAK,UAAUf,IAAgB,EAAI,GAAK,IAAIqC,EAAC,GAAG,YAAYA,EAAC,YACnFD,EAAC;AAAA,CAET,CACA,OAAOG,EACT,EAEA,MAAO;AAAA,IAEH7B,EAAa,gBAAgB,aAAc,KAAK,EAC3C,gBAAgB,IAAK,KAAK,EAC1B,gBAAgB,IAAK,KAAK,EAC1B,gBAAgB,IAAK,KAAK,EAC1B,0BAA0BC,CAAS,EACnC,iBAAiB,GAAGU,EAAgBL,CAAM,CAAC;AAAA,IACxDE,CAAkB;AAAA,IAClBR,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,4CACnCZ,CAAU,QAAQA,CAAU;AAAA,8CAC1BA,CAAU;AAAA,iCACvBG,CAAY;AAAA,qCACRA,CAAY;AAAA;AAAA;AAAA,MAG3CX,EAAY,SAAW,EAAI,GAAK,uBAAuBqB,EAAU,gBAAgB,OAAO,CAAC,GAAG;AAAA,MAC5FkB,GAAWhB,EAAGa,EAAc,CAAC;AAAA,qBACdb,EAAE,gBAAgB,WAAW,CAAC;AAAA,MAC7CgB,GAAWd,EAAGa,CAAc,CAAC;AAAA,qBACdb,EAAE,gBAAgB,WAAW,CAAC;AAAA,wBAC3BC,EAAO,KAAK,KAAK,KAAKf,CAAY;AAAA,oDACND,CAAW;AAAA,QACvDsC,GAAW,CAAC;AAAA;AAAA,2BAEOrC,CAAY;AAAA;AAAA,QAE/BqB,CAAW;AAAA,QACXH,CAAe;AAAA,0BACGH,EAAO,KAAK,OAAO;AAAA,qBACxBA,EAAO,gBAAgB,aAAa,CAAC;AAAA,QAClDA,EAAO,YAAY,YAAYlB,CAAU,GAAI,OAAO,CAAC;AAAA;AAAA;AAAA,GAIvD,EACA,MAAO,CACL,KAAM,cACN,YAAa,CACX,KAAM,GAAGT,EAAqB,kBAAkB,IAAIS,CAAU,IAAIE,CAAW,IAAIC,CAAY,IACzFT,CAAc,GAClB,kBAAmBY,EAAU,CAAC,OAAQ,OAAQ,MAAM,EAAI,CAAC,OAAQ,MAAM,CACzE,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMd,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAa,EAAuB,CAAC,EAClE,gBAAAK,CACF,GACA,gBAAAE,CACF,CACF,EAEE7B,GAAkBQ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EACxF,MAAM,IAAI,MAAM,kCAAkC,CAEtD,EAEaP,GAAU2D,GAAkC,CACvD5D,GAAe4D,EAAQ,MAAM,EAC7B,IAAMlD,EAAcmD,GAAc,UAAUD,EAAQ,OAAO,CAAC,EAAE,KAAMA,EAAQ,OAAO,CAAC,EAAE,KAAM,EAAI,EAChG,GAAI,CAAClD,EACH,MAAM,IAAI,MAAM,uCAAwC,EAE1D,IAAMM,EAAIN,EAAYA,EAAY,OAAS,CAAC,EACtCO,EAAI2C,EAAQ,OAAO,CAAC,EAAE,KAAKA,EAAQ,OAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EAC9D5C,EAAI,GAAKC,EAAI,EACf2C,EAAQ,QACJ7D,GAA6B6D,EAAQ,OAAQ,CAAC,WAAY,GAAI,mBAAoB,EAAE,EAAGlD,CAAW,CAAC,EAEvGkD,EAAQ,QAAQE,GAAwBF,EAAQ,OAAQ,CAAC,WAAY,GAAI,mBAAoB,EAAE,EAAGlD,CAAW,CAAC,CAElH,IC7KA,IAeaqD,GA6BPC,GAEAC,GAmDAC,GAmBOC,GAgBPC,GAgHAC,GA0BOC,GA9QbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KACAC,KACAC,KACAC,KACAC,KACAC,KAEajB,GACT,CAACkB,EAA+BC,EAAgCC,EAC/DC,EAA+BC,EAA4BC,IAAqC,CAC/F,IAAMC,EAAYN,EAAW,CAAC,EACxBO,EAAoBP,EAAW,MAAMK,EAAgB,EAAI,EAAGA,EAAgB,EAAI,CAAC,EACjFG,EAAcD,EAAkB,OAChCE,EAAcR,EAAY,CAAC,EAE3BS,EADqBT,EAAY,MAAM,CAAC,EACA,IAAI,CAACU,EAAGC,IAAMD,GAAKA,EAAI,IAAMT,EAAUU,CAAC,EAAI,EAAE,EAEtFC,EAD2BN,EAAkB,IAAI,CAACI,EAAGC,IAAMD,EAAIR,EAAWS,CAAC,EAAIT,EAAWS,EAAIJ,CAAW,CAAC,EAEnF,IAAI,CAACG,EAAGC,IAAM,KAAK,OAAOD,EAAID,EAAmBE,CAAC,EAAIR,EAAQQ,CAAC,GAAKR,EAAQQ,CAAC,CAAC,CAAC,EAC5G,OAAAC,EAAY,OAAO,EAAG,EAAGP,CAAS,EAClCO,EAAY,OAAOR,EAAgB,EAAI,EAAG,EAAGI,CAAW,EACjDI,CACT,EAcE9B,GAA2B,CAAC,EAAG,EAAG,EAAG,CAAC,EAEtCC,GAAiB,CAAC8B,EAA+BC,IAAqC,CAG1F,GAAI,CAACD,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAME,EAAcF,EAAO,CAAC,EAAE,KAAKC,EAAW,SAAW,OAASD,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFG,EAAkBH,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIC,EAAW,MACvD,GAAIC,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,GAAIH,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAC/F,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMN,EAAcM,EAAO,CAAC,EAAE,KAAK,OAAS,EAE5C,GAAIC,EAAW,UAAU,SAAWP,EAClC,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAIvD,GAAIO,EAAW,QAAQ,SAAWP,EAChC,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAIrD,GAAIO,EAAW,KAAK,SAAWP,EAAc,EAC3C,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAKtD,GAAIO,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWD,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAEM7B,GAA4B,CAA2B8B,EAAeD,IAAqC,CAC/G,IAAMb,EAAcc,EAAW,YAAY,MAAM,EAEjD,QAASH,EAAI,EAAGA,EAAIE,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEF,EACvCX,EAAYW,EAAI,CAAC,IAAM,IACzBX,EAAYW,EAAI,CAAC,EAAIE,EAAO,CAAC,EAAE,KAAKF,CAAC,GAGzC,IAAMM,EAAOH,EAAW,KAAK,MAAM,EACnCI,GAAa,yBACTL,EAAO,CAAC,EAAE,KAAMC,EAAW,QAASA,EAAW,UAAWd,EAAaiB,EAAMH,EAAW,SAAW,OACnGA,EAAW,OAAO,EAGtB,IAAMK,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EACrD,cAAO,OAAOK,EAAe,CAAC,YAAAnB,EAAa,KAAAiB,EAAM,SAAUH,EAAW,QAAQ,CAAC,EACxEK,CACT,EAEalC,GAAuB6B,GAAwD,CAC1F,IAAMM,EAAuBC,GAAkCP,CAAU,EAEnEQ,EAASR,EAAW,OACpBS,EAAU,CAAC,SAAU,QAAS,aAAc,YAAY,EAAET,EAAW,QAAkB,EACvFb,EAAYa,EAAW,UACvBU,EAAQV,EAAW,MACnBd,EAAcc,EAAW,aACzBG,EAAOH,EAAW,KAClBX,EAAUW,EAAW,QACrBW,EAAYX,EAAW,WAA6B,EAE1D,OAAOY,GACH,CAAC,QAAAH,EAAS,OAAAD,EAAQ,UAAArB,EAAW,MAAAuB,EAAO,YAAAxB,EAAa,KAAAiB,EAAM,QAAAd,EAAS,SAAAsB,EAAU,GAAGL,CAAoB,CAAC,CACxG,EAEMlC,GAAS,CAACyC,EAAyBd,EAA+BC,IAAqC,CAC3G,IAAMc,EAAqB5C,GAA0B8B,EAAYD,CAAM,EAKvE,GAAIC,EAAW,QAAU,EAAG,CAC1Ba,EAAQ,QAAQE,GAA6BhB,EAAQe,CAAkB,CAAC,EACxE,MACF,CAEA,IAAME,EAAiBhB,EAAW,SAAW,OACvCiB,EAAUlB,EAAO,SAAW,EAC5BmB,EAAcnB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACnDG,EAAapB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EAClDI,EAAgBrB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACrDK,EAAetB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BuB,EAAcvB,EAAO,CAAC,EAAE,KAAK,CAAC,EAE9BD,EAAc/B,GAChBgC,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMC,EAAW,UAAWc,EAAmB,KAAMd,EAAW,QAC1FgB,CAAc,EACZO,EAAYzB,EAAYkB,EAAiB,EAAI,CAAC,EAC9CQ,EAAW1B,EAAYkB,EAAiB,EAAI,CAAC,EAC7CtB,EAAcI,EAAYkB,EAAiB,EAAI,CAAC,EAEhDS,EAAWT,GAAkBK,IAAiBH,GAAeI,IAAgBH,GAC/EnB,EAAW,KAAK,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,EACvD,GAAIyB,GACCJ,IAAiB,GAAKC,IAAgB,GAAKtB,EAAW,UAAU,CAAC,IAAM,GAAKA,EAAW,UAAU,CAAC,IAAM,GACxGA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,GACrFA,EAAW,KAAK,CAAC,IAAM,EAAI,CAE9B,IAAM0B,EAAQ5B,EAAY,CAAC,EACvB6B,EAAWC,EAAWC,EACpBC,EAAe,CAAC,EACtB,GAAId,EAAgB,CAClB,IAAMe,GAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG/B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAACgC,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAIlE,GAHIA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,IAE5BN,EAAU,CACZ,IAAMQ,GAAYf,EAAcC,EAAaC,EAC7CO,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAG2B,EAAOO,EAAS,CAAC,EACnDL,EAAYG,GAAiB,QAAQ,CAAC,EAAGE,GAAWvC,CAAW,CAAC,EAChEmC,EAAoB,CAAC,EAAGH,EAAOhC,CAAW,CAC5C,MACEiC,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAOR,EAAcC,EAAYC,CAAa,CAAC,EAC9EQ,EAAYG,GAAiB,QAAQ,CAAC,EAAGX,EAAe1B,CAAW,CAAC,EACpEmC,EAAoB,CAACH,EAAOH,EAAYC,EAAU9B,CAAW,EAE/DoC,EAAa,KAAKH,CAAS,EAC3BG,EAAa,KAAKF,CAAS,CAC7B,MACED,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAON,EAAeF,EAAcC,CAAU,CAAC,EAC9ES,EAAY7B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAGL,EAAa0B,CAAa,CAAC,EAC7DS,EAAoB,CAACH,EAAOhC,EAAa6B,EAAYC,CAAQ,EAC7DM,EAAa,KAAKF,CAAS,EAC3BE,EAAa,KAAKH,CAAS,EAEzBV,GACFa,EAAa,KAAK/B,EAAO,CAAC,CAAC,EAE7B,IAAMmC,EAAIL,EAAkB,CAAC,EACvBM,EAAIL,EAAa,CAAC,EAAE,KAAKA,EAAa,CAAC,EAAE,KAAK,OAAS,CAAC,EAE1DI,EAAI,GAAKC,EAAI,EACftB,EAAQ,QACJuB,GACIN,EAAchB,EAAoBhB,EAAa+B,EAAmBb,CAAc,EACpF,CAAC,OAAQc,CAAY,CAAC,EAE1BjB,EAAQ,QACJwB,GAAwBP,EAAchB,EAAoBhB,EAAa+B,EAAmBb,CAAc,EACxG,CAAC,OAAQc,CAAY,CAAC,EAE5B,MACF,CAIA,IAAMQ,EAAgE,GAGhEP,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG/B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAACgC,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAIhC,IAAMQ,EAAa,CAACxC,EAAO,CAAC,EAAGgC,CAAgB,EAC3Cd,GACFsB,EAAW,KAAKxC,EAAO,CAAC,CAAC,EAI3B,IAAMyC,EAAYxB,EAAiBO,EAAYC,EAAW9B,EACpD+C,EAAYzB,EAAiBtB,EAAc6B,EAAYC,EACvDkB,EAAWrB,EAAeC,EAAcF,EAC9CP,EAAQ,QACJ8B,GACIJ,EAAYzB,EAAoBhB,EAAa0C,EAAWC,EAAWC,EAAUzB,EAC7EqB,CAAyB,EAC7B,CAAC,OAAQC,CAAU,CAAC,CAC1B,EAEMlE,GAAS,CAACwC,EAAyBb,IAAqC,CAE5E,IAAMV,EAAgBU,EAAW,SAAW,OACtCD,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdvB,EAEI,CAACuB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACIA,EAAQ,OAAO,SAAW,GAC5Bd,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAMV,EAAO,CAAC,EAAGH,EAAW,KAAK,CAAC,EAAG,EAAGA,EAAW,KAAK,CAAC,CAAC,EACpDX,EAAU,CAAC,CAAC,EAAE,OAAOW,EAAW,OAAO,EACvCb,EAAY,CAAC,CAAC,EAAE,OAAOa,EAAW,SAAS,EAC3Cd,EAAc,CAAC,CAAC,EAAE,OAAOc,EAAW,WAAW,EAC/Cc,EAAqB5C,GAA0B,CAAC,GAAG8B,EAAY,KAAAG,EAAM,QAAAd,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGa,CAAM,EACnHc,EAAQ,QAAQE,GACZhB,EAAQe,EACRhB,GAAeR,EAAgB,CAACQ,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAAI,CAAC,CAAC,CAAC,CAC3F,EAEaxB,GAAO,CAACuC,EAAyBb,IAAqC,CACjF/B,GAAe4C,EAAQ,OAAQb,CAAU,EACrCa,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCxC,GAAOwC,EAASb,CAAU,EAE1B5B,GAAOyC,EAASA,EAAQ,OAAQb,CAAU,CAE9C,ICrRA,IAgCM4C,GA4HOC,GA5JbC,GAAAC,EAAA,kBAqBAC,KAGAC,KAEAC,KAEAC,KACAC,KACAC,KAEMT,GACF,CAACU,EAAyBC,EAAU,GAAOC,EAAqCC,EAAmB,IAAc,CAC/G,IAAMC,EAAOC,GAAYF,EAAkB,KAAK,EAC1CG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,sEACT,IAAK,GACH,MAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAUT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBP,EAAiB;AAAA;AAAA,QAGA;AAAA;AAAA,QAIjCQ,EAAkBR,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCS,EAAUT,EAAiB,iBAAmB,iBAC9CU,EAASV,EAAiB,iBAAmB,iBAC7CW,EAAMX,EAAiB,MAAQ,MAC/BY,EAAMZ,EAAiB,MAAQ,MAE/Ba,EAAe;AAAA,yBACFb,EAAiB,iBAAmB,gBAAgB;AAAA,uBACtDA,EAAiB,gCAAkC,+BAA+B;AAAA,qBACpFW,CAAG;AAAA,qBACHA,CAAG;AAAA;AAAA,mBAELC,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA;AAAA,kCAGYH,CAAO;AAAA,iBACxBL,CAAI;AAAA;AAAA,kCAEaM,CAAM;AAAA,iBACvBN,CAAI;AAAA;AAAA;AAAA;AAAA,kBAIHQ,CAAG;AAAA,QACbL,CAAa;AAAA,0EACqDJ,CAAgB,KAE9EW,EAAUd,EAAiB;AAAA,0BACbG,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SACoB;AAAA,0BACbD,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SAEPW,EAAU;AAAA,0BACIZ,CAAgB;AAAA,yBACjBH,EAAiB,iBAAmB,gBAAgB;AAAA;AAAA;AAAA,YAInEA,EAAiB,sDACA,qDAAqD;AAAA;AAAA;AAAA,UAGtEM,EAAYH,CAAgB,CAAC;AAAA;AAAA,eAExBC,CAAI;AAAA,QAGP,CAAC,mBAAAY,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBhB,EAAYE,CAAI,EAsBnF,MArBiB;AAAA,QACfY,CAAkB;AAAA,uDAC6BZ,CAAI;AAAA,MACrDJ,EAAiBc,EAAUC,CAAO;AAAA;AAAA;AAAA,uDAGeX,CAAI;AAAA,MACrDJ,EAAiBe,EAAUD,CAAO;AAAA;AAAA;AAAA,iEAGyBV,CAAI;AAAA,wBAC7CD,CAAgB;AAAA;AAAA;AAAA,uBAGjBH,EAAiB,gCAAkC,+BAA+B;AAAA,QACjGQ,CAAe;AAAA,QACfW,GAAYlB,CAAO,CAAC;AAAA,QACpBgB,CAAe;AAAA,8EACuDd,CAAgB;AAAA;AAAA,IAI1F,EAESZ,GACT,CAAC6B,EAA+BlB,EAAqCmB,EACpEC,EAAmBC,EAAmBC,EAAkBC,EACxDC,IAAoD,CACnD,IAAM1B,EAAiBE,EAAW,SAAW,OACvCyB,EAAa3B,EAAiBoB,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClEQ,EAAYP,EAAY,CAAC,EACzBQ,EAAW7B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAY9B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAc/B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC7DW,EACFhC,EAAiB2B,EAAa,IAAM,GAAKI,EAAc,IAAM,EAAIF,EAAW,IAAM,GAAKE,EAAc,IAAM,EAGzGE,EAAYjC,EAAiB+B,EAAcF,EAAWC,EACtDI,EAAYlC,EAAiB6B,EAAWC,EAAYC,EACpDI,EAA0CH,EAC5C,CAAC,EAAG,EAAG,CAAC,EACR,CAAEC,GAAa,GAAKC,GAAa,EAAK,EAAI,GAAID,EAAY,GAAKC,GAAa,EAAI,EAAI,GAAI,CAAC,EACvFE,EACFJ,EAAS,CAAC,EAAG,EAAG,CAAC,EAAI,CAACC,GAAa,EAAI,EAAI,EAAGA,EAAY,GAAKC,GAAa,EAAI,EAAI,EAAG,CAAC,EACtFG,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,wCAAwCD,CAAQ,EAAE,EAE7E,IAAMlC,EAAmB6B,EAAS,EAAI,EAChCO,EAAY,KAAK,IAAIJ,EAAc,CAAC,EAAIhC,EAAkBgC,EAAc,CAAC,CAAC,EAC1EK,EAAaR,EAAS,EAAI,EAC1BS,EACF,CAAC,CAAC,KAAM,QAAS,KAAMnB,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMC,CAAS,EAAG,CAAC,KAAM,QAAS,KAAMC,CAAQ,CAAC,EAClGkB,EAAIC,EAAc,IAAKvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQoB,CAAU,EAC5EI,EAAID,EAAc,IAAKvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ,CAAC,EACnEyB,EAASC,EAAe,SAAU1B,EAAO,CAAC,EAAE,SAAUC,EAAY,OAAQmB,CAAU,EACpFO,EAAiB,CAACL,EAAGE,CAAC,EAC5BH,EAAgB,KAAK,GAAGO,EAA2B5B,EAAO,CAAC,EAAE,IAAI,CAAC,EAClEqB,EAAgB,KAAK,GAAGO,EAA2B5B,EAAO,CAAC,EAAE,IAAI,CAAC,EAElE,IAAI6B,EAAmB,GACvB,GAAIxB,EAAS,CACX,IAAMyB,GAAOP,EAAc,OAAQvB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQoB,CAAU,EACxFO,EAAe,KAAKG,EAAI,EACxBT,EAAgB,KAAK,GAAGO,EAA2B5B,EAAO,CAAC,EAAE,IAAI,CAAC,EAElE6B,GAAoB;AAAA,0DAC8BjB,EAAS,YAAc,KAAK;AAAA,+BACvDhC,EAAiB,IAAM,GAAG,GAAGgC,EAAS,MAAQ,EAAE;AAAA,UAEzE,CAEA,OAAAS,EAAgB,KAAK,GAAGO,EAA2B3B,CAAW,CAAC,EAExD,CACL,KAAM,wBACN,YAAa,CAAC,KAAMnB,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMmB,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,gBAAAI,CACF,GACA,gBAAkBU,IAA+B;AAAA,UAC/CC,GAAc,yBAAyB,CAAC;AAAA,UAEtCD,GAAa,gBAAgB,YAAa,KAAK,EAC1C,gBAAgB,YAAa,KAAK,EAClC,gBAAgB,WAAY,KAAK,EACjC,iBAAiB,GAAGJ,EAAgBF,CAAM,CAAC;AAAA,oDACRzB,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,mDACzBlB,EAAW,YAAYF,EAAiB,EAAI,CAAC,CAAC,KACrFE,EAAW,YAAYF,EAAiB,EAAI,CAAC,CAAC;AAAA;AAAA,gBAG9CE,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYF,EAAiB,EAAI,CAAC,EAAI,IAAME,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gBAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYF,EAAiB,EAAI,CAAC,EAAI,IAAME,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gFAExFA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,8EAEvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,gDACHA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC9CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClEoB,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/ByB,CAAgB;AAAA,UAChB3D,GAA6BU,EAAgByB,EAASvB,EAAYC,CAAgB,CAAC;AAAA,UAEjF6B,EAASqB,GACIjB,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,CAAS,EAClFe,GACIlB,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,EAAW,GAChF,OAAWb,CAAyB,CAAC,EACxD,CACF,IChQJ,IA0BM6B,GAsNOC,GAhPbC,GAAAC,EAAA,kBAmBAC,KAEAC,KAEAC,KAGMN,GACF,CAACO,EAA4BC,EAA+BC,EAC3DC,EAAgCC,EAAkBC,EAA+BC,EAAS,GAC1FC,IAA6B,CAC5B,IAAMC,EAAiBN,EAAW,SAAW,OACvCO,EAASD,EAAiB,EAAI,EAC9BE,EAASF,EAAiB,EAAI,EAC9BG,EAAaH,EAAiB,EAAI,EAClCI,EAAaC,EAAU,KAAKV,CAAW,EACvCW,EAAgBR,EAAS,EAAI,EAC7BS,EAAQb,EAAW,MACnBc,EAASf,EAAO,CAAC,EAAE,KACnBgB,EAAwBD,EAAO,CAAC,EAAID,EACpCG,EAAyBF,EAAO,CAAC,EAEnCG,EAAmB;AAAA,iDACoBb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,0BAC9DD,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,KAEvDH,IACFe,GAAoB;AAAA,sDAC0Bb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,2BAClEC,EAAiB,IAAM,GAAG,GAAGF,EAAS,MAAQ,EAAE;AAAA,QAGrE,IAAMc,EAAad,EAAS,EAAI,EAC1Be,EAAIC,EAAc,IAAKrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACrEG,EAAKD,EAAc,KAAMrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACvEI,EAAiB,CAACD,EAAIF,CAAC,EACzBjB,GACFoB,EAAe,KAAKF,EAAc,OAAQrB,EAAO,CAAC,EAAE,SAAU,CAACE,EAAYQ,CAAU,CAAC,EAAGS,CAAU,CAAC,EAEtG,IAAMK,EAASC,EAAe,SAAUzB,EAAO,CAAC,EAAE,SAAUE,EAAaiB,CAAU,EAC7EO,EAAe;AAAA,2BACAtB,EAAuB,cAAgB,gBAAgB;AAAA,kBAChEA,EAAuB,cAAgB,gBAAgB;AAAA,kBACvDA,EAAuB,cAAgB,gBAAgB,MAAMS,CAAa;AAAA,wBACpET,EAAuB,cAAgB,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM7CE,CAAQ,MAAMO,CAAa;AAAA,8BAC/BA,CAAa;AAAA,8BACbP,CAAQ;AAAA;AAAA;AAAA,uBAGfA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,oCAExCA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOnBA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA,0BACpDA,CAAQ,wBAAwBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sCAO/CA,CAAQ;AAAA;AAAA;AAAA;AAAA,wCAINA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAUhBc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAMhBgB,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA;AAAA,iDAEjBhB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMdI,CAAU;AAAA;AAAA,gCAErBU,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCASZc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA,oCACjChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mCAUTO,CAAa;AAAA,qCACXV,EAAU,YAAc,QAAQG,CAAQ,QAAQ;AAAA,YACzEkB,EAAO,IAAI,QAAS,IAAK,QAAS,KAAM,OAAO,CAAC;AAAA;AAAA,SAGhDG,EAAc;AAAA,gCACMH,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBAC5CA,EAAO,WAAW,gBAAiB,CAAC,CAAC;AAAA,qBACxCA,EAAO,WAAW,gBAAiBd,CAAU,CAAC;AAAA,oBAC/Cc,EAAO,WAAW,gBAAiBhB,CAAM,CAAC;AAAA,oBAC1CgB,EAAO,WAAW,gBAAiBf,CAAM,CAAC;AAAA;AAAA;AAAA;AAAA,+BAI/BQ,CAAsB;AAAA,6CACRA,CAAsB;AAAA;AAAA;AAAA,0BAGzCX,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA,yBAKTA,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,sCAEvCA,CAAQ,gBAAgBE,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAUzCF,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,wCAEvCA,CAAQ,gBAAgBG,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA,6CAKzBO,CAAqB;AAAA,2CACvBA,CAAqB;AAAA,+BAEtDT,EAAiBe,EAAG,IAAI,QAAS,OAAQ,OAAQ,cAAc,EAC9CA,EAAG,IAAI,QAAS,eAAgB,OAAQ,MAAM,CAAC;AAAA,+BAC3CF,EAAE,IAAI,eAAgB,cAAe,cAAe,aAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM/DjB,EAAU,WAAa,GAAGG,CAAQ,OAAO;AAAA,YAC/DkB,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,UAG/C,MAAO;AAAA,IACTzB,EAAa,iBAAiB,GAAGwB,EAAgBC,CAAM,CAAC;AAAA,IACxDN,CAAgB;AAAA,2CACuBhB,EAAY,KAAK,GAAG,CAAC;AAAA,8CAClBF,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,0CAC5BC,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,6CAC5CA,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC,KACjFN,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC;AAAA,4CACZN,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,YAGrFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,YAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,0EACxBA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,0EACvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,MAC3GF,EAAa,UAAU,CAAC;AAAA,MACxBA,EAAa,sCAAsCY,CAAU,CAAC;AAAA,IAChEN,EAASqB,EAAeC,CAAW,GACnC,EAESlC,GACT,CAACO,EAA+BC,EAC/B2B,IAAqF,CACpF,IAAMzB,EAAUH,EAAO,OAAS,EAE1BE,EAAcD,EAAW,YACzBU,EAAaC,EAAU,KAAKV,CAAW,EAMvC2B,EAAW,CACf,KAAK,KAAKlB,EAAa,EAAE,EACzB,EACA,CACF,EACAmB,GAAU,UAAW,IAAM,uCAAuCD,CAAQ,EAAE,EAE5E,IAAMvB,EAAWyB,GAA4B/B,EAAO,CAAC,EAAE,QAAQ,EAC/D,MAAO,CACL,KAAM,kBACN,YAAa,CAAC,KAAMC,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,cAAe,CAAC,EAAG4B,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,QAAS,CAAC,CACR,KAAMD,EAA6BA,EAA2B1B,CAAW,EAAIA,EAC7E,SAAUF,EAAO,CAAC,EAAE,QACtB,CAAC,CACH,GACA,gBAAkBD,GAA+BP,GAC7CO,EAAcC,EAAQC,EAAYC,EAAaC,EAAS0B,EAAS,CAAC,IAAM,GAAKA,EAAS,CAAC,IAAM,EAAG,GAChGvB,CAAQ,CACd,CACF,IClRJ,IAaM0B,GAIAC,GAWAC,GAkCAC,GA4COC,GA8BPC,GAqEAC,GAEAC,GAsDAC,GA6COC,GAlTbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEAC,KACAC,KAEMhB,GACF,CAACiB,EAAeC,EAAgBC,EAAaC,EAAgBC,EAAkBC,KAC1EL,EAAQ,GAAKC,EAASC,GAAOC,EAAS,GAAKC,EAAW,EAAIC,EAE7DrB,GAAoB,CAACsB,EAAkBC,EAAiBC,EAAgBC,EAAcC,IAAiB,CAC3G,IAAMC,EAAW,KAAK,MAAML,EAAW,CAAC,EACpCC,IAAY,cACdC,EAAKC,CAAI,EAAIE,EACbH,EAAKE,CAAI,EAAIJ,EAAWK,GACfJ,IAAY,eACrBC,EAAKC,CAAI,EAAIH,EAAWK,EACxBH,EAAKE,CAAI,EAAIC,EAEjB,EAEM1B,GACF,CAAC2B,EAA+BC,EAAgCC,EAA8BP,EAC7FQ,EAAeP,EAAgBQ,EAA4BC,EAAwBC,EACnFC,IAA0B,CACzB,IAAMC,EAAcR,EAAW,OAAS,EAClCS,EAAoBF,EAAY,SAAW,EACjD,GAAID,EAAc,SAAW,EAC3B,QAASI,EAAI,EAAGA,EAAIF,EAAa,EAAEE,EACjCJ,EAAc,KAAK,CAAC,EAGxB,IAAMK,EAAYX,EAAW,CAAC,EACxBY,EAAcX,EAAYI,EAAgB,EAAI,CAAC,EAAIF,EACzD,QAASO,EAAI,EAAGG,EAAIb,EAAW,OAASQ,GAAeH,EAAgB,EAAI,GAAIK,EAAIF,EAAa,EAAEE,EAAG,EAAEG,EAAG,CACxG,IAAMC,EAASd,EAAWa,CAAC,EACrBpB,EAAUgB,EAAoBK,EAASV,EAAQM,CAAC,EAAIH,EAAYG,CAAC,EACjEhB,EAAWvB,GAAgB2C,EAAQV,EAAQM,CAAC,EAAGd,EAAKc,CAAC,EAAGT,EAAYY,CAAC,EAAGX,EAAUQ,CAAC,EAAGjB,CAAO,EACnGrB,GAAkBsB,EAAUC,EAASC,EAAMc,EAAGA,EAAIF,CAAW,EACzDC,GACFF,EAAY,KACRH,EAAQM,CAAC,GAAKI,EAAS,GAAKR,EAAcI,CAAC,GAAKT,EAAYY,CAAC,EAAI,GAAKX,EAAUQ,CAAC,EAAI,EAAId,EAAKc,CAAC,EAC/Fd,EAAKc,EAAIF,CAAW,CAAC,CAE7B,CACAD,EAAY,OAAO,EAAG,EAAGI,CAAS,EAClCJ,EAAY,OAAOF,EAAgB,EAAI,EAAG,EAAGO,CAAW,CAC1D,EAQEtC,GACF,CAAoCyC,EAAeC,IAAqC,CACtF,IAAMf,EAAcc,EAAW,YAAY,MAAM,EAEjD,GAAIA,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAClGjB,EAAY,OAAS,EACrB,QAASS,EAAI,EAAGA,EAAIM,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEN,EAC3CT,EAAY,KAAKe,EAAO,CAAC,EAAE,KAAKN,CAAC,CAAC,CAEtC,CACA,IAAMS,EAAiBJ,EAAW,SAAW,OAC7Cd,EAAY,OAAO,EAAG,EAAGe,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC1Cf,EAAY,OAAOkB,EAAiB,EAAI,EAAG,EAAGH,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAE/D,IAAMpB,EAAOmB,EAAW,KAAK,MAAM,EAC7BR,EAAcQ,EAAW,YAAY,MAAM,EAC3CT,EAAgBS,EAAW,cAAc,MAAM,EAC/Cf,EAAagB,EAAO,CAAC,EAAE,KACzBd,EAAYa,EAAW,UAAU,MAAM,EAC3C,GAAIb,EAAU,OAAO,CAACe,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC9C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5Cd,EAAY,IAAI,MAAMM,CAAW,EAAE,KAAK,CAAC,CAC3C,CACA,IAAIJ,EAAUW,EAAW,QAAQ,MAAM,EACvC,GAAIX,EAAQ,OAAO,CAACa,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC5C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5CZ,EAAU,IAAI,MAAMI,CAAW,EAAE,KAAK,CAAC,CACzC,CAGAnC,GACI2B,EAAYC,EAAaC,EAAWa,EAAW,QAASA,EAAW,MAAOnB,EAAMQ,EAASe,EACzFb,EAAeC,CAAW,EAG9B,IAAMa,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EAC/CM,EAAWN,EAAW,SAAW,CACrCd,EAAY,KAAK,IAAI,EAAGL,EAAK,KAAK,GAAG,EAAGQ,EAAQ,KAAK,GAAG,EAAGE,EAAc,KAAK,GAAG,EAAGC,EAAY,KAAK,GAAG,EACxGL,EAAU,KAAK,GAAG,CACpB,EAAE,KAAK,GAAG,EACV,cAAO,OAAOkB,EAAe,CAAC,YAAAnB,EAAa,KAAAL,EAAM,cAAAU,EAAe,YAAAC,EAAa,UAAAL,EAAW,QAAAE,EAAS,SAAAiB,CAAQ,CAAC,EACnGD,CACT,EAES7C,GAAgCwC,GAAiE,CAC5G,IAAMO,EAAuBC,GAAkCR,CAAU,EAEnES,EAAST,EAAW,OACpBpB,EACF,CAAC,SAAU,QAAS,aACnB,YAAY,EAAE,OAAOoB,EAAW,QAAW,IAAc,EAAIA,EAAW,OAAiB,EACxFb,EAAYa,EAAW,UACvBZ,EAAQY,EAAW,MACnBd,EAAcc,EAAW,YACzBnB,EAAOmB,EAAW,KAClBX,EAAUW,EAAW,QACrBU,EAAYV,EAAW,SAA2B,EAClDT,EAAgBS,EAAW,cAC3BR,EAAcQ,EAAW,YAC/B,OAAOW,GAA4B,CACjC,QAAA/B,EACA,OAAA6B,EACA,UAAAtB,EACA,MAAAC,EACA,YAAAF,EACA,cAAAK,EACA,YAAAC,EACA,KAAAX,EACA,QAAAQ,EACA,SAAAqB,EACA,GAAGH,CACL,CAAC,CACH,EAEM9C,GAAiB,CAACwC,EAA+BD,IAA8C,CAGnG,GAAI,CAACC,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,2CAA2C,EAG7D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAMW,EAAcX,EAAO,CAAC,EAAE,KAAKD,EAAW,SAAW,OAASC,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFY,EAAkBZ,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,GAAIW,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMC,EAAcb,EAAO,CAAC,EAAE,KAAK,CAAC,EAAID,EAAW,MAGnD,GAAIC,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMa,GAC/E,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMrB,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAG5C,GAFqBD,EAAW,UAAU,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEnDH,EAAW,UAAU,SAAWP,EAClD,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAKvD,GAFmBO,EAAW,QAAQ,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEjDH,EAAW,QAAQ,SAAWP,EAC9C,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAKrD,GADgBO,EAAW,KAAK,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAC9CH,EAAW,KAAK,SAAWP,EAAc,EACtD,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAItD,GAAIO,EAAW,cAAc,SAAWP,GAAeO,EAAW,cAAc,SAAW,EACzF,MAAM,IAAI,MAAM,4BAA4BP,CAAW,GAAG,EAM5D,GADuBO,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GACrDH,EAAW,YAAY,SAAW,GACpDA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5D,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAID,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAGMvC,GAAsB,CAAC,EAAG,EAAG,EAAG,CAAC,EAEjCC,GACF,CAACoD,EAAyBd,EAA+BD,IAA8C,CACrG,IAAMgB,EAAqBzD,GAAmCyC,EAAYC,CAAM,EAC1EG,EAAiBJ,EAAW,SAAW,OACvCR,EAAcwB,EAAmB,YACjCnB,EAAcL,EAAYY,EAAiB,EAAI,CAAC,EAChDa,EAAgBhB,EAAO,CAAC,EAAE,KAAKG,EAAiB,EAAI,CAAC,EAI3D,GAAIY,EAAmB,QAAU,GAAMnB,IAAgB,GAAKoB,IAAkB,EAAI,CAChFF,EAAQ,QAAQG,GAAiCjB,EAAQe,CAAkB,CAAC,EAC5E,MACF,CACA,IAAMG,EAAY3B,EAAYY,EAAiB,EAAI,CAAC,EAC9CgB,EAAW5B,EAAYY,EAAiB,EAAI,CAAC,EAC7CiB,EAAepB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BqB,EAAcrB,EAAO,CAAC,EAAE,KAAK,CAAC,EAE9BsB,EAAYnB,EAAiBe,EAAYC,EAAWvB,EACpD2B,EAAYpB,EAAiBP,EAAcsB,EAAYC,EACvDK,EAAWJ,EAAeC,EAAcL,EAExCS,EAAgE,GAIhEC,EAAoBZ,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJa,GAA2B3B,EAAO,CAAC,EAAGvC,EAAmB,EACzD,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAACsC,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACe,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKY,GAIhC,IAAME,EAAsB,CAAC5B,EAAO,CAAC,EAAG0B,CAAgB,EAClDG,EAAU7B,EAAO,SAAW,EAC9B6B,IACE,CAAC1B,GAAkBH,EAAO,CAAC,EAAE,KAAK,SAAW,EAC/C4B,EAAoB,KAAK5B,EAAO,CAAC,EAAE,QAAQ,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAG,CAAC,CAAC,CAAC,EAErE4B,EAAoB,KAAK5B,EAAO,CAAC,CAAC,GAKtCc,EAAQ,QACJgB,GACIF,EAAqBb,EAAoBxB,EAAa+B,EAAWC,EAAWC,EAAUK,EACtFJ,CAAyB,EAC7B,CAAC,OAAQG,CAAmB,CAAC,CACnC,EAEEjE,GAAkB,CAACmD,EAAyBf,IAA8C,CAE9F,IAAMV,EAAgBU,EAAW,SAAW,OAEtCC,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdzB,EAEI,CAACyB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACId,EAAO,SAAW,GACpBA,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAI7B,EAAcc,EAAW,aACzBd,EAAY,SAAW,GAAKA,EAAY,CAAC,IAAM,KACjDA,EAAc,CAAC6B,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,GAE1C,IAAI5B,EAAYa,EAAW,WACvBb,EAAU,SAAW,GAAKA,EAAU,CAAC,IAAM,KAC7CA,EAAY,CAAC,CAAC,GAEhB,IAAIE,EAAUW,EAAW,SACrBX,EAAQ,SAAW,GAAKA,EAAQ,CAAC,IAAM,KACzCA,EAAU,CAAC,CAAC,GAEd,IAAIR,EAAOmB,EAAW,KAClBnB,EAAK,SAAW,IAClBA,EAAO,CAAC,EAAG,CAAC,GAEdA,EAAO,CAAC,EAAGA,EAAK,CAAC,EAAG,EAAGA,EAAK,CAAC,CAAC,EAC9BQ,EAAU,CAAC,CAAC,EAAE,OAAOA,CAAO,EAC5BF,EAAY,CAAC,CAAC,EAAE,OAAOA,CAAS,EAChCD,EAAc,CAAC,CAAC,EAAE,OAAOA,CAAW,EACpC,IAAM8B,EACFzD,GAAmC,CAAC,GAAGyC,EAAY,KAAAnB,EAAM,QAAAQ,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGe,CAAM,EACrGc,EAAQ,QAAQG,GACZjB,EAAQe,EACRxB,GAAeF,EAAgB,CAACE,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAC/C,CAACA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,CAAC,CAAC,CACtF,EAEa3B,GAAgB,CAACkD,EAAyBf,IAA8C,CACnGvC,GAAesD,EAAQ,OAAQf,CAAU,EACrCe,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCnD,GAAgBmD,EAASf,CAAU,EAEnCrC,GAAgBoD,EAASA,EAAQ,OAAQf,CAAU,CAEvD,ICzTA,IAgBMgC,GAkDOC,GAOAC,GAzEbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMR,GACF,CAACS,EAAmBC,EAA+BC,EAAuBC,IACvD,CACb,IAAMC,EAAaC,EAAU,KAAKJ,CAAU,EACtCK,EAAOL,EAAW,OAClBM,EAAQC,EAAc,QAASR,EAAWM,CAAI,EAC9CG,EAASC,EAAe,SAAUV,EAAWM,CAAI,EACjDK,EAAYT,EAAU,WAAa,EAAiBA,EAAU,cAAc,EAAE,CAAC,EAC3B,OAAOA,EAAU,iBAAiB,EAAE,CAAC,CAAC,EAC1FU,EAAOP,EAAU,cAAcM,EAAWL,CAAI,EAC9CO,EAAmBC,GAA+B,CACtD,IAAMC,EAAQ,QAAQR,EAAM,WAAW,eAAgB,eAAe,CAAC,KACjES,EAAMC,GAAa,uBAAwB,gBAAiBX,CAAI,EAChEY,EAAaf,EAAW,QAAUY,GAASZ,EAAW,UAAY,OAAS,IAAM,IACjFgB,EAAahB,EAAW,QAAUa,EAAMD,GAASZ,EAAW,UAAY,GAAK,QACnF,MAAO;AAAA,kBAEHW,EAAa,gBAAgB,aAAc,KAAK,EAC3C,gBAAgB,OAAQ,KAAK,EAC7B,iBAAiBP,EAAOE,CAAM,CAAC;AAAA,kBAClCK,EAAa,UAAU,CAAC;AAAA,oBACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,uCACtDL,EAAO,gBAAgB,YAAY,CAAC;AAAA,8BAC7CA,EAAO,KAAK,KAAK;AAAA,sCACTS,CAAU;AAAA,qCACXC,CAAU;AAAA;AAAA,sBAEzBZ,EAAM,WAAW,eAAgB,gBAAiB,QAAQ,CAAC;AAAA,kCAC/CA,EAAM,aAAa,cAAc,CAAC;AAAA;AAAA,oBAEhDE,EAAO,YAAY,aAAc,KAAK,CAAC;AAAA,kBAEjD,EACA,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMN,EAAW,SAAU,kBAAmB,CAAC,MAAM,CAAC,EACpE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMF,EAAY,SAAUD,CAAS,CAAC,EACjD,cAAe,CAAC,EAAG,KAAK,KAAKI,EAAa,EAAuB,CAAC,EAClE,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAMA,CAAU,EAAG,CAAC,KAAM,QAAS,KAAMQ,CAAI,EAC9D,GAAGQ,EAA2BnB,CAAU,EAAG,GAAGmB,EAA2BnB,CAAU,CACrF,CAEF,GACA,gBAAAY,CACF,CACF,EAGKrB,GAAS,CAAC6B,EAAyBlB,IAAuC,CACrF,IAAMF,EAAaoB,EAAQ,OAAO,CAAC,EAAE,KAC/BrB,EAAYqB,EAAQ,OAAO,CAAC,EAAE,SAC9BT,EAAOS,EAAQ,OAAO,CAAC,EAC7BA,EAAQ,QAAQ9B,GAAwBS,EAAWC,EAAYW,EAAMT,CAAU,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACjG,EAEaV,GAAyBU,GAA0D,CAC9F,IAAMmB,EAAYnB,EAAW,YAAwB,EAC/CoB,EAAUpB,EAAW,UAAsB,EACjD,OAAOqB,GAA4B,CAAC,UAAAF,EAAW,QAAAC,CAAO,CAAC,CACzD,IC7EA,IAsBME,GAEAC,GACAC,GACAC,GACAC,GAQAC,GAqBAC,GA4HAC,GAEAC,GAqHOC,GASAC,GApTbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAcMf,GACF,qBACEC,GAAc,IAAMD,GAAgB,KACpCE,GAAkB,IAAMD,GAAc,IACtCE,GAAa,IAAMF,GAAc,MAAQA,GACzCG,GAAiB,IAAMD,GAAa,IAQpCE,GAAN,KAAiB,CACf,YAAYW,EAAa,GAAI,CAC3B,KAAK,gBAAkB,IAAI,IAC3B,KAAK,WAAaA,CACpB,CAGA,UAAUC,EAAgBC,EAAe,CACvC,IAAIC,EAAQ,KAAK,gBAAgB,IAAIF,CAAM,EACvCE,IAAU,OACZA,EAAQ,CAACD,CAAK,EAEdC,EAAM,KAAKD,CAAK,EAElB,KAAK,gBAAgB,IAAID,EAAQE,CAAK,CACxC,CAIF,EAEMb,GAAN,KAAqB,CACnB,YAAYc,EAA+CC,EAAkB,CAAlB,cAAAA,EACzD,KAAK,YAAc,GACnB,KAAK,aAAe,IAAI,IACxB,KAAK,IAAM,IAAI,MACf,KAAK,WAAa,CAAC,EAGnB,GAAI,CAACC,EAAKC,CAAG,EAAIF,EAAS,SAAS,IAAI,EAAIA,EAAS,MAAM,KAAM,CAAC,EAAI,CAACA,EAAU,EAAE,EAClF,GAAI,CAACC,EAAI,MAAM,OAAOlB,EAAc,CAAC,EACnC,MAAM,IAAI,MAAM,kBAAkB,EAapC,GAXmBkB,EAAI,MAAM,GAAG,EACrB,QAAQ,CAACE,EAAWN,IAAU,CACvC,IAAMO,EAAOL,EAAOF,CAAK,EAAE,KAAK,MAAM,EACtC,GAAI,CAACM,EAAU,MAAM,OAAOtB,EAAe,CAAC,EAC1C,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMwB,EAAa,KAAK,YAAYF,EAAW,GAAMC,EAAMP,CAAK,EAChE,KAAK,IAAI,KAAKQ,CAAU,CAC1B,CAAC,EAGGH,IAAQ,GAEVA,GAAO,CAAC,GAAG,KAAK,aAAa,QAAQ,CAAC,EAC1B,OAAO,CAAC,CAACI,EAAKC,CAAI,IAAOA,EAAK,QAAU,GAAKD,IAAQ,KAAM,EAC3D,IAAI,CAAC,CAACA,CAAG,IAAMA,CAAG,EAClB,KAAK,EAAE,UAEf,CAACJ,EAAI,MAAM,OAAOtB,EAAW,CAAC,EAChC,MAAM,IAAI,MAAM,aAAa,EAKdsB,EAAI,MAAM,OAAOvB,GAAe,GAAG,CAAC,GAC3C,QAASiB,GAAW,CAC9B,GAAIA,IAAW,MACb,KAAK,WAAa,KAAK,WAAW,OAAO,KAAK,YAAY,MACrD,CACL,IAAMW,EAAO,KAAK,aAAa,IAAIX,CAAM,EACzC,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,oBAAoB,EAEtC,KAAK,WAAW,KAAKA,EAAK,QAAQ,CACpC,CACF,CAAC,EACD,KAAK,IAAM,KAAK,YAAYL,EAAK,GAAO,KAAK,UAAU,CACzD,CAGA,UAAUN,EAAgBY,EAAkBb,EAAoB,CAC9D,IAAIY,EAAO,KAAK,aAAa,IAAIX,CAAM,EACvC,GAAIW,IAAS,OAAW,CACtB,GAAIA,EAAK,WAAaC,GAAYD,EAAK,QAAU,EAC/C,MAAM,IAAI,MAAM,oBAAoB,EAEpCA,EAAK,QACLA,EAAK,aAAa,KAAKZ,CAAU,CAErC,MACEY,EAAO,CAAC,MAAO,EAAG,SAAAC,EAAU,aAAc,CAACb,CAAU,CAAC,EAExD,KAAK,aAAa,IAAIC,EAAQW,CAAI,CACpC,CAGA,YAAYE,EAAcC,EAAkBN,EAAyBP,EAAQ,GAAgB,CAC3F,IAAMc,EAAOP,EAAK,OACdQ,EAAW,GACXC,EAAe,CAAC,EAChBC,EAAU,EAEd,GAAI,CAACL,EAAK,MAAM,OAAO5B,EAAe,CAAC,GAAM,CAAC6B,GAAWD,IAAS,GAChE,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMM,EAAeN,EAAK,MAAM,OAAO9B,GAAe,GAAG,CAAC,EACpD0B,EAAa,IAAIrB,GAAWa,CAAK,EAEvC,OAAAkB,GAAc,QAAQ,CAACnB,EAAgBoB,IAAc,CACnD,GAAIpB,IAAW,MAAO,CACpB,GAAIgB,EACF,MAAM,IAAI,MAAM,6CAA6C,EAE/DA,EAAW,GACX,IAAMK,EAAoBN,EAAOI,EAAa,OAAS,EACvD,GAAIE,EAAoB,EACtB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GADAJ,EAAeT,EAAK,MAAMU,EAASA,EAAUG,CAAiB,EAC1D,KAAK,aACP,GAAI,KAAK,aAAa,SAAWJ,EAAa,QAC1C,KAAK,aAAa,SAAS,IAAMA,EAAa,SAAS,EACzD,MAAM,IAAI,MAAM,8BAA8B,UAEvCH,EACT,KAAK,YAAc,GACnB,KAAK,aAAeG,MAEpB,OAAM,IAAI,MAAM,uCAAuC,EAGzD,QAASK,EAAI,EAAGA,EAAIL,EAAa,OAAQK,IAAK,CAC5C,IAAMtB,EAAS,OAAO,aAAa,IAAI,WAAW,CAAC,EAAIsB,CAAC,EACxDb,EAAW,UAAUT,EAAQoB,EAAIE,CAAC,EAClC,KAAK,UAAUtB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAC/C,CACF,MACEQ,EAAW,UAAUT,EAAQoB,GAAK,KAAK,YAAc,KAAK,aAAa,OAAS,EAAI,EAAE,EACtF,KAAK,UAAUpB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAEjD,CAAC,EACMQ,CACT,CAQF,EAEMnB,GAAaiC,GAAyBA,EAAO,OAE7ChC,GACF,CAACiC,EAA+CC,EAAuCC,EACtFC,EAAgCC,IAAgD,CAE/E,IAAMC,EADeJ,EAAY,IAAI,CAACjB,EAAMP,IAAUuB,EAA0BvB,CAAK,EAAIO,EAAK,OAASA,CAAI,EAC5E,IAAI,CAACsB,EAAa7B,IAAU8B,EAAc,QAAQ9B,CAAK,GAAIyB,EAAUI,CAAW,CAAC,EAC1GE,EAAaC,EAAU,KAAKL,CAAW,EACvCM,EAA6BC,GAAqBP,EAAY,MAAM,EACpEQ,EAAoBF,EAA6BN,EAAY,OAASA,EACtES,EAASC,EAAe,SAAUZ,EAAUU,CAAiB,EAC7DG,EACF,CAAC,GAAGZ,EAAe,aAAa,KAAK,CAAC,EAAE,OAAQ3B,GAAW,CAAC2B,EAAe,IAAI,gBAAgB,IAAI3B,CAAM,CAAC,EACxGwC,EAAmBC,GAA+B,CACtD,IAAMC,EAAoB,CAAC,EACrBC,EAAW,kBACXC,EAAU,iBACVC,EAAY,eACZC,EAAgC,CAAC,EACjCC,EAAiC,CAAC,EAClCC,EAAiC,CAAC,EAClCC,EAA4B,CAAC,EAC7BC,EAAyBvB,EAAe,aAAa,OAASA,EAAe,IAAI,gBAAgB,KACvGA,EAAe,aAAa,QAAQ,CAAChB,EAAMX,IAAW,CACpD,GAAI2B,EAAe,IAAI,gBAAgB,IAAI3B,CAAM,EAAG,CAClD,IAAMmD,EAAcxB,EAAe,IAAI,gBAAgB,IAAI3B,CAAM,IAAI,CAAC,EAClEmD,IAAgB,QAClBxB,EAAe,IAAI,QAAQ,CAACd,EAAMO,IAAM,CACtC,GAAIT,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMgC,GAAUvC,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAIoD,KAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,GAAQ,QAASnD,IAAU,CACzByC,EAAQ,KAAK,GACTb,EAAUT,CAAC,EAAE,WACT,QAAQA,CAAC,UAAWnB,GAAOoC,EAAO,WAAW,gBAAiBc,CAAW,CAAC,CAAC,EAAE,CACvF,CAAC,CACH,CACF,CAAC,CAEL,MACExB,EAAe,IAAI,QAAQ,CAACd,EAAMO,IAAM,CACtC,GAAIT,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMgC,EAAUvC,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAIoD,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAASnD,IAAU,CACzB6C,EAAoB,KAAK,GAAGjB,EAAUT,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,GAAO,GAAGD,CAAM,EAAE,CAAC,EAAE,CAC/F,CAAC,EACDiD,EAAgB,KAAK,WAAWpB,EAAUT,CAAC,EAAE,aAAa,QAAQA,CAAC,SAAS,CAAC,GAAG,CAClF,CACF,CAAC,EACD2B,EAAqB,KACjB,WAAW/C,CAAM,cAAcA,CAAM,eAAeV,GAAUU,CAAM,CAAC,KAAKA,CAAM,OAAO,EAC3FgD,EAAqB,KAAK,GAAG,CAEjC,CAAC,EACD,IAAMK,EAAYH,EACd,CACE,GAAGR,EACH,aAAab,EAAU,IAAI,CAACyB,EAAUlC,IAAMkC,EAAS,aAAa,QAAQlC,CAAC,SAAS,CAAC,EAAE,KAAK,KAAK,CAAC,GACpG,EACA,CACE,GAAGsB,EACHE,EACA,GAAGG,EACH,GAAGD,EACHH,EACA,GAAGM,EACHJ,EACA,GAAGG,CACL,EACJ,MAAO;AAAA,cAEHP,EACK,iBAAiBF,EAAgB,IAAKvC,IAAY,CAAC,KAAM,GAAGV,GAAUU,CAAM,CAAC,GAAI,KAAM,KAAK,EAAE,CAAC,EAC/F,gBAAgB,aAAc,KAAK,EACnC,iBAAiB,GAAG6B,EAAWQ,CAAM,CAAC;AAAA;AAAA,cAEzCI,EAAa,UAAU,CAAC;AAAA,cACxBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,kCACrDJ,EAAO,gBAAgB,YAAY,CAAC;AAAA,cACxDR,EAAU,IAAI,CAAC0B,EAAMnC,IAAM,YAAYA,CAAC,YAAYS,EAAUT,CAAC,EAAE,KAAK,OAAO,GAAG,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,cAC5FiC,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,cACpBhB,EAAO,YAAY,aAAc,KAAK,CAAC;AAAA,YAE/C,EACA,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAMV,EAAe,SACrB,kBAAmBH,EAA0B,IAAKgC,GAAuBA,EAAqB,OAAS,MAAM,CAC/G,EACA,WAAY,IAAM,CAGhB,IAAMC,EACFlB,EAAgB,OAAQvC,GAAW2B,EAAe,aAAa,IAAI3B,CAAM,CAAC,EACrE,IAAKA,IAAY,CAAC,KAAM,SAAU,KAAM2B,EAAe,aAAa,IAAI3B,CAAM,GAAG,UAAY,CAAC,EAAE,EACzGyD,EAAoB,KAAK,CAAC,KAAM,SAAU,KAAMzB,CAAU,CAAC,EAC3D,IAAM0B,EACFjC,EAAY,OAAO,CAAC,EAAGxB,IAAUuB,EAA0BvB,CAAK,CAAC,EAC5D,IAAI,CAACO,EAAMmD,IAAM,CAAC,GAAGC,EAA2BpD,CAAI,CAAC,CAAC,EACtD,OAAO,CAACqD,EAAKC,IAAyBD,EAAI,OAAOC,CAAoB,EAAGL,CAAmB,EACpG,OAAIvB,GACFwB,EAAgB,KAAK,GAAGE,EAA2BhC,CAAW,CAAC,EAEzD,CACN,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAAF,CAAQ,CAAC,EACvC,cAAe,CAAC,EAAG,KAAK,KAAKM,EAAa,EAAuB,CAAC,EAClE,gBAAA0B,CACF,CACF,EACA,gBAAAlB,CACF,CACF,EAEShD,GAAS,CAACuE,EAAyBC,IAAuC,CACrF,IAAMrC,EAAiB,IAAItC,GAAe0E,EAAQ,OAAQC,EAAW,QAAQ,EACvExC,EAA4BuC,EAAQ,OAAO,IAAI,CAACE,EAAON,IAAMxB,GAAqB8B,EAAM,KAAK,MAAM,CAAC,EACpGrC,EAAcD,EAAe,WAC7BF,EAAcsC,EAAQ,OAAO,IAAI,CAACE,EAAON,IAAMM,EAAM,IAAI,EAC/DF,EAAQ,QAAQxE,GACZiC,EAA2BC,EAAasC,EAAQ,OAAO,CAAC,EAAE,SAAUpC,EAAgBC,CAAW,CAAC,CACtG,EAEanC,GAAyBuE,GAA0D,CAC9F,IAAM5D,EAAY4D,EAAW,SAAoB,QAAQ,OAAQ,EAAE,EACnE,OAAOE,GAA4B,CAAC,SAAA9D,CAAQ,CAAC,CAC/C,ICvTA,IAUM+D,GAiBAC,GAYAC,GAIAC,GAoEOC,GA/GbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,0BAA0B,EAE5C,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EAEzDG,EAAaD,EAAM,OAASD,EAAW,OAAS,EAAIC,EAAM,OAASD,EAAW,OAC9EG,EAAkBH,EAAW,OAASC,EAAM,OAAS,EAAID,EAAW,OAASC,EAAM,OACvF,KAAOC,EAAaD,EAAM,QAAUE,EAAkBH,EAAW,OAAQ,EAAEE,EAAY,EAAEC,EACvF,GAAIF,EAAMC,CAAU,IAAMF,EAAWG,CAAe,GAAKF,EAAMC,CAAU,IAAM,GAC3EF,EAAWG,CAAe,IAAM,EAClC,MAAM,IAAI,MAAM,oDAAoD,CAG1E,EAEMb,GAAmB,CAACc,EAA2BC,IAAwC,CAC3F,IAAMC,EAAOF,EAAO,OAASC,EAAO,OAC9BJ,EAAkB,CAAC,EACzB,QAASM,EAAI,EAAGA,EAAID,EAAM,EAAEC,EAC1BN,EAAM,KAAKG,EAAOG,CAAC,CAAC,EAEtB,QAASA,EAAI,EAAGA,EAAIF,EAAO,OAAQ,EAAEE,EACnCN,EAAM,KAAKI,EAAOE,CAAC,IAAM,EAAIH,EAAOG,EAAID,CAAI,EAAID,EAAOE,CAAC,CAAC,EAE3D,OAAON,CACT,EAEMV,GAAuB,CAACS,EAA+BC,IACxDD,EAAW,OAASC,EAAM,OAAUX,GAAiBU,EAAYC,CAAK,EAAIX,GAAiBW,EAAOD,CAAU,EAG3GR,GAA2BO,GAA+C,CAC9E,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EACvDS,EAAwBjB,GAAqBS,EAAYC,CAAK,EAC9DQ,EAAWV,EAAO,CAAC,EAAE,SACrBW,EAAaD,IAAa,EAAgB,EAAI,EAC9CE,EAAa,KAAK,KAAKC,EAAU,KAAKJ,CAAW,EAAIE,CAAU,EAE/DG,EAA0BC,GAAqBd,EAAW,MAAM,EAChEe,EAA2BD,GAAqBN,EAAY,MAAM,EAGlEQ,EAAmBC,GAA+B,CACtD,IAAMC,EAAmBL,EAA0Bb,EAAW,OAASA,EACjEmB,EAAoBJ,EAA2BP,EAAY,OAASA,EACpEY,EAAQC,EAAc,QAASZ,EAAUS,EAAkBR,CAAU,EACrEY,EAASC,EAAe,SAAUd,EAAUU,EAAmBT,CAAU,EAC3Ec,EACJ,GAAIf,IAAa,EAAe,CAC9B,IAAMgB,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO;AAAA,6BAChDD,CAAC,MAAML,EAAO,gBAAgB,kBAAkBK,CAAC,GAAG,CAAC;AAAA,sBAC5DA,CAAC,MAAMP,EAAM,2BAA2B,gBAAgBO,CAAC,GAAIL,CAAM,CAAC;AAAA,qBACrEK,CAAC,YAAYA,CAAC;AAAA,yBACVA,CAAC,YAAYA,CAAC;AAAA,YAC3BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIR,EAAM,YAAY,QAAQO,CAAC,EAAE,CAAC,aAAaA,CAAC;AAAA,UAEhFH,EAAa;AAAA,0CACuBd,CAAU;AAAA;AAAA,UAE1Ce,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,UAClCH,EAAO,YAAY,aAAc,MAAM,CAAC;AAAA,QAE9C,MACEE,EAAa;AAAA,8BACWF,EAAO,gBAAgB,YAAY,CAAC;AAAA,4BACtCF,EAAM,2BAA2B,gBAAiBE,CAAM,CAAC;AAAA,UAC3EA,EAAO,YAAY,aAAcF,EAAM,YAAY,aAAa,CAAC,CAAC;AAAA,SAGxE,MAAO;AAAA,MACLH,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBG,EAAOE,CAAM,CAAC;AAAA,MAC/EL,EAAa,UAAU,CAAC;AAAA,MACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,MACvEO,CAAU,EACd,EAEMK,EAAoC,CAAC,CAAC,KAAM,SAAU,KAAMlB,CAAU,CAAC,EAC7E,OAAIE,GACFgB,EAAgB,KAAK,GAAGC,EAA2B9B,CAAU,CAAC,EAE5De,GACFc,EAAgB,KAAK,GAAGC,EAA2BtB,CAAW,CAAC,EAE1D,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGA,EAAY,MAAM,GAAI,kBAAmB,CAACK,EAA0B,OAAS,MAAM,CAAC,EAC3G,gBAAAG,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMR,EAAa,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKY,EAAa,EAAuB,CAAC,EAClE,gBAAAkB,CACF,EACF,CACF,EAEapC,GAAUsC,GAAkC,CACvD1C,GAAe0C,EAAQ,MAAM,EAC7BA,EAAQ,QAAQvC,GAAwBuC,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxE,IClHA,IAeMC,GAMAC,GAwHOC,GAGAC,GAhJbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,CAE/C,EAEMT,GAA0B,CAACS,EAA+BC,IAA8C,CAC5G,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAeH,EAAO,CAAC,EAAE,KAEzBI,EAAYF,EAAW,OACvBG,EAAOC,EAAU,cAAcL,EAAW,KAAMG,CAAS,EAEzDG,EAAcL,EAAW,MAAM,CAAC,EACtCK,EAAY,OAAOF,EAAM,EAAG,GAAGF,CAAY,EAE3C,IAAMK,EAAeN,EAAWG,CAAI,EAC9BI,EAAaT,EAAO,CAAC,EAAE,WAAa,EAAgB,EAAI,EACxDU,EAAa,KAAK,KAAKJ,EAAU,KAAKC,CAAW,EAAIE,CAAU,EAE/DE,EAA4BC,GAAqBZ,EAAO,CAAC,EAAE,KAAK,MAAM,EACtEa,EAAmBF,EAA4BX,EAAO,CAAC,EAAE,KAAK,OAASA,EAAO,CAAC,EAAE,KACjFc,EAA8BF,GAAqBZ,EAAO,CAAC,EAAE,KAAK,MAAM,EACxEe,EAAqBD,EAA8Bd,EAAO,CAAC,EAAE,KAAK,OAASA,EAAO,CAAC,EAAE,KACrFgB,EAA6BJ,GAAqBL,EAAY,MAAM,EACpEU,EAAoBD,EAA6BT,EAAY,OAASA,EAEtEW,EACF,CAAC,CAAC,KAAM,SAAU,KAAMR,CAAU,EAAG,CAAC,KAAM,QAAS,KAAMF,CAAY,EAAG,CAAC,KAAM,SAAU,KAAMH,CAAI,CAAC,EACtGM,GACFO,EAAgB,KAAK,GAAGC,EAA2BnB,EAAO,CAAC,EAAE,IAAI,CAAC,EAEhEc,GACFI,EAAgB,KAAK,GAAGC,EAA2BnB,EAAO,CAAC,EAAE,IAAI,CAAC,EAEhEgB,GACFE,EAAgB,KAAK,GAAGC,EAA2BZ,CAAW,CAAC,EAGjE,IAAMa,EAAwD,CAAC,EAC/DA,EAAkB,KAAKT,EAA4B,OAAS,MAAM,EAClES,EAAkB,KAAKN,EAA8B,OAAS,MAAM,EAEpE,IAAMO,EAAmBC,GAA+B,CACtD,IAAMC,EAAOC,EAAc,OAAQxB,EAAO,CAAC,EAAE,SAAUa,EAAkBJ,CAAU,EAC7EgB,EAAUD,EAAc,eAAgBxB,EAAO,CAAC,EAAE,SAAUe,CAAkB,EAC9EW,EAASC,EAAe,SAAU3B,EAAO,CAAC,EAAE,SAAUiB,EAAmBR,CAAU,EAEnFmB,EAAmBC,GAA6B,CACpD,IAAMC,EAAc3B,EAAa,OAC7B4B,EAAU,qBAAqBF,CAAC,OAAOJ,EAAQ,KAAK,OAAO,OAC/D,QAASO,EAAI,EAAGA,EAAIF,EAAaE,IAC/BD,GAAW,GAAGD,EAAc,EAAI,iBAAiBD,CAAC,IAAIG,CAAC,IAAM,iBAAiBH,CAAC,EAAE,MAC7EtB,EAAY,OAAS,EAAI,gBAAgBsB,CAAC,oBAAoBG,CAAC,IAAM,gBAAgBH,CAAC,EAAE,IAE9FE,GAAW;AAAA,mBACEF,CAAC,MAAMJ,EAAQ,aAAa,iBAAiBI,CAAC,EAAE,CAAC;AAAA,mBACjDA,CAAC;AAAA,iBACHA,CAAC,SAASA,CAAC;AAAA;AAAA,2BAEDA,CAAC,MAAMN,EAAK,KAAK,OAAO;AAAA,UAE7C,QAASS,EAAI,EAAGC,GAAI,EAAGD,EAAI5B,EAAW4B,IAChCA,IAAM3B,GACR0B,GAAW,GAAG3B,EAAY,EAAI,cAAcyB,CAAC,IAAIG,CAAC,IAAM,cAAcH,CAAC,EAAE,aAAaA,CAAC,KACvFI,IAAKH,IAELC,GAAW,GAAG3B,EAAY,EAAI,cAAcyB,CAAC,IAAIG,CAAC,IAAM,cAAcH,CAAC,EAAE,MACrEtB,EAAY,OAAS,EAAI,gBAAgBsB,CAAC,IAAII,EAAC,IAAM,gBAAgBJ,CAAC,EAAE,IAC5EI,MAGJ,OAAOF,CACT,EACIG,EACJ,GAAIlC,EAAO,CAAC,EAAE,WAAa,EAAe,CACxC,IAAMmC,EAAmB,CAACC,EAAgBP,EAAWQ,EAAW,KAAO;AAAA,6BAChDR,CAAC,MAAMH,EAAO,gBAAgB,kBAAkBG,CAAC,GAAG,CAAC;AAAA,YACtED,EAAgBC,CAAC,CAAC;AAAA,sBACRA,CAAC,MAAMN,EAAK,gBAAgB,cAAcM,CAAC,EAAE,CAAC;AAAA,qBAC/CA,CAAC,YAAYA,CAAC;AAAA,yBACVA,CAAC,YAAYA,CAAC;AAAA,YAC3BO,CAAM,IAAIP,CAAC,OAAOQ,CAAQ,IAAId,EAAK,YAAY,QAAQM,CAAC,EAAE,CAAC,aAAaA,CAAC;AAAA,UAE/EK,EAAa;AAAA,0CACuBzB,CAAU;AAAA;AAAA,UAE1C0B,EAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCA,EAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCA,EAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCA,EAAiB,QAAS,EAAG,KAAK,CAAC;AAAA,UACnCT,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,OAE/C,MACEQ,EAAa;AAAA,4BACSR,EAAO,gBAAgB,YAAY,CAAC;AAAA,QACxDE,EAAgB,EAAE,CAAC;AAAA,oBACPL,EAAK,aAAa,aAAa,CAAC;AAAA,QAC5CG,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,QAG7C,MAAO;AAAA,QAEHJ,EAAa,gBAAgB,aAAc,KAAK,EAC3C,gBAAgB,eAAgB,KAAK,EACrC,gBAAgB,OAAQ,KAAK,EAC7B,iBAAiBC,EAAME,EAASC,CAAM,CAAC;AAAA,QAC5CJ,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,UACzEY,CAAU;AAAA,QAElB,EACA,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMjC,EAAW,SAAU,kBAAAmB,CAAiB,EAC1D,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMb,EAAa,SAAUP,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAG,KAAK,KAAKU,EAAa,EAAuB,CAAC,EAClE,gBAAAQ,CACF,GACA,gBAAAG,CACF,CACF,EAEa7B,GAAyBS,GAClCqC,GAA4B,CAAC,KAAMrC,EAAW,IAAc,CAAC,EAEpDR,GAAS,CAAC8C,EAAyBtC,IAAuC,CACrF,IAAMD,EAASuC,EAAQ,OACvBjD,GAAeU,CAAM,EACrBuC,EAAQ,QAAQhD,GAAwBgD,EAAQ,OAAQtC,CAAU,CAAC,CACrE,ICpJA,IAcMuC,GAeAC,GA+DOC,GAGAC,GA/FbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,CAAC,EAAE,KAAK,OAAS,EAC1B,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM;AAAA,4DACwC,CAE5D,EAEMR,GACF,CAACQ,EAA+BC,IAAsD,CACpF,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAsBH,EAAO,CAAC,EAAE,SAChCI,EAAYF,EAAW,OAEvBG,EAAeL,EAAO,CAAC,EAAE,KACzBM,EAAkBN,EAAO,CAAC,EAAE,SAC5BO,EAAOC,EAAU,cAAcP,EAAW,KAAMG,CAAS,EACzDK,EAAeP,EAAWK,CAAI,EAE9BG,EAAcL,EAAa,MAAM,CAAC,EAClCM,EAAaH,EAAU,KAAKE,CAAW,EAEvCE,EAAQC,EAAc,QAASV,EAAqBC,CAAS,EAC7DU,EAAUD,EAAc,eAAgBP,EAAiBD,EAAa,MAAM,EAC5EU,EAASC,EAAe,SAAUb,EAAqBO,EAAY,MAAM,EAGzEO,EACF,CAAC,CAAC,KAAM,SAAU,KAAMN,CAAU,EAAG,CAAC,KAAM,QAAS,KAAMF,CAAY,EAAG,CAAC,KAAM,SAAU,KAAMF,CAAI,CAAC,EAC1G,OAAAU,EAAgB,KAAK,GAAGC,EAA2BhB,CAAU,CAAC,EAC9De,EAAgB,KAAK,GAAGC,EAA2Bb,CAAY,CAAC,EAChEY,EAAgB,KAAK,GAAGC,EAA2BR,CAAW,CAAC,EA4BxD,CACL,KAAM,iBACN,YAAa,CAAC,kBA7B8C,CAAC,OAAQ,MAAM,CA6B5C,EAC/B,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUV,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKW,EAAa,EAAuB,CAAC,EAClE,gBAAAM,CACF,GACA,gBA9BuBE,GAA+B;AAAA,QAEpDA,EAAa,gBAAgB,aAAc,KAAK,EAC3C,gBAAgB,eAAgB,KAAK,EACrC,gBAAgB,OAAQ,KAAK,EAC7B,iBAAiBP,EAAOE,EAASC,CAAM,CAAC;AAAA,QAC/CI,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,4BAErDJ,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,kBAE9CD,EAAQ,YAAY,YAAY,CAAC;AAAA;AAAA;AAAA;AAAA,2BAIxBF,EAAM,KAAK,OAAO;AAAA,QACrCA,EAAM,WAAW,eAAgB,gBAAiB,UAAU,CAAC;AAAA,oBACjDA,EAAM,aAAa,cAAc,CAAC;AAAA;AAAA,QAE9CG,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAY3C,CACF,EAEStB,GAAiCQ,GAC1CmB,GAA4B,CAAC,KAAMnB,EAAW,IAAc,CAAC,EAEpDP,GAAiB,CAAC2B,EAAyBpB,IAA+C,CACrG,IAAMD,EAASqB,EAAQ,OACvB9B,GAAeS,CAAM,EACrBqB,EAAQ,QAAQ7B,GAAgC6B,EAAQ,OAAQpB,CAAU,CAAC,CAC7E,ICnGA,IAUMqB,GA0BAC,GAuFOC,GAQAC,GAnIbC,GAAAC,EAAA,kBAIAC,KAIAC,KAEMP,GAAkBQ,GAAwC,CAC9D,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,EACjD,MAAM,IAAI,MAAM,0BAA0B,EAG5C,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,UACjCA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,SAC3D,MAAM,IAAI,MAAM,4BAA4B,CAEhD,EASMP,GAAwB,CAACO,EAA+BC,IAA4C,CACxG,IAAMC,EAASF,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9BG,EAASH,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9B,CAACI,EAAGC,EAAGC,CAAC,EAAIC,GAAS,qBACvBL,EAAQD,EAAW,OAAQE,EAAQF,EAAW,OAAQD,EAAO,SAAW,EAAIA,EAAO,CAAC,EAAE,KAAO,MAAS,EACpGQ,EAAc,CAACJ,EAAGC,CAAC,EACzB,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,qCAAsC,EAExD,IAAMC,EAAaC,EAAU,KAAKF,CAAW,EACvCG,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAMF,CAAU,EAAG,CAAC,KAAM,SAAU,KAAML,CAAC,EAAG,CAAC,KAAM,SAAU,KAAMC,CAAC,EAAG,CAAC,KAAM,SAAU,KAAMC,CAAC,EAClH,CAAC,KAAM,UAAW,KAAML,EAAW,KAAK,EAAG,CAAC,KAAM,UAAW,KAAMA,EAAW,IAAI,CACpF,EACMW,EAAwD,CAAC,OAAQ,MAAM,EACzEZ,EAAO,SAAW,IACpBW,EAAgB,KAAK,GAAGE,EAA2Bb,EAAO,CAAC,EAAE,IAAI,CAAC,EAClEY,EAAkB,KAAK,MAAM,GAE/BD,EAAgB,KAAK,GAAGE,EAA2BL,CAAW,CAAC,EAE/D,IAAMM,EAAmBC,GAA+B,CACtD,IAAIC,EAAO,GACPf,EAAW,QAAUA,EAAW,OAClCe,EAAO,0DACEf,EAAW,QAAU,CAACA,EAAW,OAC1Ce,EAAO,0DACE,CAACf,EAAW,QAAUA,EAAW,OAC1Ce,EAAO,0DACE,CAACf,EAAW,QAAU,CAACA,EAAW,SAC3Ce,EAAO,2DAGT,IAAMC,EAAiBhB,EAAW,QAAU,EAAI,GAAK,2BAC/CiB,EAAIC,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACzDoB,EAAID,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACzDqB,EAAWH,EAAE,KAAK,MACpBI,EAAwB,KACtBC,EAAY,CAACL,EAAGE,CAAC,EACnBpB,EAAO,SAAW,IACpBsB,EAAIH,EAAc,IAAKnB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EAChEuB,EAAU,KAAKD,CAAC,GAElB,IAAME,EAASC,EAAe,SAAUzB,EAAO,CAAC,EAAE,SAAUQ,EAAY,MAAM,EAC9Ee,EAAU,KAAKC,CAAM,EACrB,IAAME,EAA8B,CAClC,CAAC,KAAM,cAAe,KAAM,KAAK,EAAG,CAAC,KAAM,IAAK,KAAM,KAAK,EAAG,CAAC,KAAM,IAAK,KAAM,KAAK,EAAG,CAAC,KAAM,IAAK,KAAM,KAAK,EAC/G,CAAC,KAAM,QAAS,KAAM,KAAK,EAAG,CAAC,KAAM,OAAQ,KAAM,KAAK,CAC1D,EACA,MAAO;AAAA,IACPX,EAAa,iBAAiBW,CAAQ,EAAE,iBAAiB,GAAGH,CAAS,CAAC;AAAA;AAAA,IAEtER,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kBAK9DM,CAAQ;AAAA;AAAA,QAElBL,CAAI;AAAA;AAAA;AAAA,MAGNC,CAAc;AAAA,OACb,IACGK,GAAK,KACA,iBAAiBA,EAAE,2BAA2B,aAAcE,CAAM,CAAC,8BACtEF,EAAE,YAAY,SAAS,CAAC,IAEvB,IACN,CAAC;AAAA;AAAA,IAGN,EAEA,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAM,GAAGrB,EAAW,QAAQ,GAAI,kBAAAW,CAAiB,EAC/D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMJ,EAAa,SAAUR,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKS,EAAa,EAAuB,CAAC,EAClE,gBAAAE,CACF,GACA,gBAAAG,CACF,CACF,EAEapB,GAAuBO,GAAwD,CAC1F,IAAM0B,EAAS1B,EAAW,OACpB2B,EAAS3B,EAAW,OACpB4B,EAAQ5B,EAAW,MACnB6B,EAAO7B,EAAW,KACxB,MAAO,CAAC,OAAA0B,EAAQ,OAAAC,EAAQ,MAAAC,EAAO,KAAAC,EAAM,SAAU,GAAG7B,EAAW,MAAM,IAAIA,EAAW,MAAM,IAAIA,EAAW,QAAU,CAAC,EAAE,CACtH,EAEaN,GAAO,CAACoC,EAAyB9B,IAAqC,CACjFT,GAAeuC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQtC,GAAsBsC,EAAQ,OAAQ9B,CAAU,CAAC,CACnE,ICtIA,IAeM+B,GAwGAC,GAuHAC,GAoDOC,GAlSbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAOMR,GACF,CAACS,EAA+BC,IAAoD,CAClF,IAAMC,EAASF,EAAO,CAAC,EAAE,KACnBG,EAAcD,EACdE,EAAO,EACPC,EAAYC,EAAU,gBAAgBJ,EAAQE,CAAI,EAClDG,EAAWD,EAAU,kBAAkBJ,EAAQE,CAAI,EACnDI,EAAaC,GAAiBF,CAAQ,EACtCG,EAAiBH,EAAWC,EAC5BG,EAAa,CAACT,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGQ,CAAc,EAClDE,EAAwD,CAAC,OAAQ,OAAQ,MAAM,EAC/EC,EACF,CAAC,CAAC,KAAM,SAAU,KAAMN,CAAQ,EAAG,CAAC,KAAM,SAAU,KAAMG,CAAc,CAAC,EAC7EG,EAAgB,KAAK,GAAGC,EAA2BH,CAAU,EAAG,GAAGG,EAA2BH,CAAU,CAAC,EAEzG,IAAMI,EAAmBC,GAA+B,CACtD,IAAMC,EAAIC,EAAc,IAAKlB,EAAO,CAAC,EAAE,SAAUW,EAAW,OAAQH,CAAU,EACxEW,EAAQD,EAAc,QAASlB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACjEoB,EAAOF,EAAc,OAAQlB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/DqB,EAASC,EAAe,SAAUtB,EAAO,CAAC,EAAE,SAAUW,EAAW,OAAQH,CAAU,EACnFe,EAAY,CAACN,EAAGE,EAAOC,EAAMC,CAAM,EACnCG,EAAWP,EAAE,KAAK,MAClBQ,EAAUjB,IAAe,EAAI,MAAQ,MAAMA,CAAU,QACrDkB,EAAgB,GAEhBC,EAA8B,CAAC,CAAC,KAAM,WAAY,KAAM,KAAK,EAAG,CAAC,KAAM,iBAAkB,KAAM,KAAK,CAAC,EAC3G,MAAO;AAAA;AAAA;AAAA,2CAG4BF,CAAO,KAAKC,CAAa;AAAA,0BAC1CA,CAAa;AAAA,IACnCV,EAAa,iBAAiBW,CAAQ,EAAE,iBAAiB,GAAGJ,CAAS,CAAC;AAAA,IACtEP,EAAa,UAAUU,CAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAOrBD,CAAO;AAAA;AAAA,4BAECA,CAAO,IAAIR,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qBAahDW,GAAU,qBAAsBpB,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gBAKhDiB,CAAO;AAAA;AAAA,yBAEEA,CAAO,IAAIR,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC,OAAOQ,CAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAcpDG,GAAU,qBAAsBpB,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,gFAISP,EAAW,OAAO;AAAA,yCACzDkB,EAAM,YAAY,SAAS,CAAC;AAAA,6BACxCC,EAAK,YAAY,SAAS,CAAC;AAAA;AAAA,oBAEpCH,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC,MAAMO,CAAQ,IAAIC,CAAO,qBAAqBD,CAAQ,IAC5FC,CAAO;AAAA,QACXJ,EAAO,IAAI,QAAS,UAAW,IAAK,OAAO,CAAC;AAAA;AAAA,IAG9C,EACA,MAAO,CACD,KAAM,wBAEV,YAAa,CAAC,KAAM,GAAGpB,EAAW,OAAO,IAAIO,CAAU,GAAI,kBAAAI,CAAiB,EAC5E,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMT,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAGK,CAAS,EAC5B,gBAAAQ,CACF,GACA,gBAAAE,CACF,CACF,EAEEvB,GACF,CAACqC,EAAyBC,EAAmBX,EAAmBC,EAAkB,EAAWW,EAAWC,EACvGC,IAAoB,CACnB,IAAMzB,EAAaC,GAAiBuB,CAAC,EAC/BE,EAAK,GAGLC,EAAa3B,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC5D4B,EAAc5B,IAAe,EAAI,MAAQ,MAAMA,CAAU,IACzD6B,EAAiB,CAACC,EAAcC,IAAiB,GAAGJ,CAAU,IAAIG,CAAI,KAAKC,CAAI,IAC/EC,EAAc,EAAIR,EAAIxB,EACtBiC,EAAS,KAAK,KAAKV,EAAIG,CAAE,EAEzBQ,EAA4D,CAAC,MAAM,EACnEC,EAAwC,CAC5C,CAAC,KAAM,SAAU,KAAMF,CAAM,EAAG,CAAC,KAAM,SAAU,KAAMV,CAAC,EAAG,CAAC,KAAM,SAAU,KAAM,KAAK,MAAMC,EAAIxB,CAAU,CAAC,EAC5G,CAAC,KAAM,SAAU,KAAM,KAAK,MAAMuB,EAAIC,EAAIxB,CAAU,CAAC,CACvD,EAEMoC,EAAuB5B,GAA+B,CAC1D,IAAM6B,EAAc3B,EAAc,QAASY,EAAM,SAAUA,EAAM,KAAMtB,CAAU,EACjF,MAAO;AAAA,IACXQ,EAAa,iBAAiB6B,CAAW,CAAC;AAAA,kEACoBV,CAAU;AAAA;AAAA;AAAA;AAAA,IAIxEnB,EAAa,UAAUkB,CAAE,CAAC;AAAA,4CACcA,CAAE;AAAA,+CACCA,CAAE;AAAA,8BACnBA,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAQhBY,GAAW,MAAOtC,CAAU,CAAC;AAAA,uBACtBsC,GAAW,MAAOtC,CAAU,CAAC;AAAA;AAAA,sBAE9B4B,CAAW;AAAA;AAAA;AAAA;AAAA,2BAINC,EAAe,MAAO,YAAY,CAAC;AAAA,IAExD,EAEMU,EAAalB,EAAQ,QACvB,CACE,KAAM,0BACN,YAAa,CAAC,KAAM,GAAGrB,CAAU,GAAI,kBAAmBkC,CAAqB,EAC7E,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAAC,EAAGV,EAAGE,EAAI,CAAC,EAAG,UAAwB,CAChD,EACA,cAAe,CAAC,EAAG,EAAIF,EAAIxB,CAAU,EACrC,gBAAiBmC,CACnB,GACA,gBAAiBC,CACnB,EACA,CAAC,OAAQ,CAACd,CAAK,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAEjCjB,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAM2B,CAAW,EAAG,CAAC,KAAM,SAAU,KAAMT,CAAC,EAC7D,CAAC,KAAM,SAAU,KAAM,KAAK,MAAMC,EAAIxB,CAAU,CAAC,EAAG,CAAC,KAAM,SAAU,KAAM,KAAK,MAAM0B,EAAKF,EAAIxB,CAAU,CAAC,CAC5G,EACMI,EAAwD,CAAC,OAAQ,OAAQ,MAAM,EAC/EG,EAAmBC,GAA+B,CACtD,IAAMgC,EAAc9B,EAAc,QAASC,EAAM,SAAUA,EAAM,KAAMX,CAAU,EAC3EyC,EAAa/B,EAAc,OAAQE,EAAK,SAAUA,EAAK,KAAMZ,CAAU,EAC7E,MAAO;AAAA,2DAC4C2B,CAAU;AAAA,2DACVa,EAAY,KAAK,OAAO;AAAA,0DACzBC,EAAW,KAAK,OAAO;AAAA,kEACfd,CAAU;AAAA;AAAA;AAAA;AAAA,IAIxEnB,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,wBAAwB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gBAKlE8B,GAAW,MAAOtC,CAAU,CAAC;AAAA,uBACtBsC,GAAW,MAAOtC,CAAU,CAAC;AAAA,+BACrB0B,CAAE;AAAA,gEAC+BA,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4DAMND,CAAO;AAAA,qCAC9BG,CAAW;AAAA,yBACvBA,CAAW;AAAA;AAAA,2BAETC,EAAe,eAAgB,cAAc,CAAC;AAAA,IAEnE,EACA,OAAOR,EAAQ,QACX,CACE,KAAM,uCAEN,YAAa,CAAC,KAAM,GAAGrB,CAAU,IAAIyB,CAAO,GAAI,kBAAArB,CAAiB,EACjE,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAAC,EAAGoB,EAAG,CAAC,EAAG,UAAwB,CAC5C,EACA,cAAe,CAAC,EAAG,KAAK,KAAKQ,EAAc,EAAuB,CAAC,EACnE,gBAAA3B,CACF,GACA,gBAAAE,CACF,EACA,CAAC,OAAQ,CAACgC,EAAY5B,EAAOC,CAAI,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAC3D,EAEE3B,GACF,CAACoC,EAAyB7B,EAA+BC,IAAuC,CAC9F,IAAMC,EAASF,EAAO,CAAC,EAAE,KACnBG,EAAcD,EACdgD,EAAIhD,EAAO,CAAC,EACZiD,EAAIjD,EAAOA,EAAO,OAAS,CAAC,EAC5BkD,EAAI9C,EAAU,kBAAkBJ,EAAQ,CAAC,EAAIiD,EAC7C3C,EAAaC,GAAiB0C,CAAC,EAC/BE,EAAa/C,EAAU,KAAKH,CAAW,EAAIK,EAC3CK,EACF,CAAC,CAAC,KAAM,SAAU,KAAMuC,CAAC,EAAG,CAAC,KAAM,SAAU,KAAM,KAAK,MAAMD,EAAI3C,CAAU,CAAC,CAAC,EAC5EI,EAAwD,CAAC,OAAQ,MAAM,EAEvE0C,EAAoB9D,GAAYqC,EAAS7B,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGkD,EAAGE,EAAGD,EAAGlD,EAAW,OAAO,EACrGc,EAAmBC,GAA+B,CACtD,IAAMQ,EAAW+B,GAA4BvD,EAAO,CAAC,EAAE,QAAQ,EACzDwD,EAAYhD,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC3DiD,EAAgBjD,IAAe,EAAIgB,EAAW,MAAMhB,CAAU,IAAIgB,CAAQ,IAE1EqB,EAAc3B,EAAc,QAASlB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMQ,CAAU,EACnFkD,EAAepC,EAAe,SAAUtB,EAAO,CAAC,EAAE,SAAUG,EAAaK,CAAU,EAEzF,MAAO;AAAA,2DAC4CqC,EAAY,KAAK,OAAO;AAAA,gEACnBW,CAAS;AAAA,kEACPE,EAAa,KAAK,OAAO;AAAA;AAAA;AAAA;AAAA,IAIvF1C,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kDAMsByC,CAAa,eAAeA,CAAa;AAAA,IAErF,EACA5B,EAAQ,QACJ,CACE,KAAM,4BACN,YAAa,CAAC,KAAM,GAAGrB,CAAU,GAAI,kBAAAI,CAAiB,EACtD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKqD,EAAa,EAAuB,CAAC,EAClE,gBAAAxC,CACF,GACA,gBAAAE,CACF,EACA,CAAC,OAAQ,CAACf,EAAO,CAAC,EAAGsD,CAAiB,CAAC,CAAC,CAC9C,EAES5D,GAAe,CAACmC,EAAyB5B,IAA6C,CAC7FA,EAAW,SAAW,OACxBR,GAAkCoC,EAASA,EAAQ,OAAQ5B,CAAU,EAErE4B,EAAQ,QAAQtC,GAA8BsC,EAAQ,OAAQ5B,CAAU,CAAC,CAE7E,ICxSA,IAeM0D,GAMAC,GA0GOC,GA/HbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAOMP,GAAkBQ,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,CAE3D,EAEMP,GACF,CAACO,EAA+BC,EAAiCC,IAAqC,CACpG,IAAMC,EAASH,EAAO,CAAC,EAAE,KACnBI,EAAQJ,EAAO,CAAC,EAChBK,EAAOL,EAAO,CAAC,EAEfM,EAAcH,EACdI,EAAOC,EAAU,cAAcP,EAAW,KAAME,EAAO,MAAM,EAC7DM,EAAYD,EAAU,gBAAgBL,EAAQI,CAAI,EAClDG,EAAWF,EAAU,kBAAkBL,EAAQI,CAAI,EAEnDI,EAAYH,EAAU,KAAKJ,EAAM,IAAI,EACrCQ,EAAWP,EAAOG,EAAU,KAAKH,EAAK,IAAI,EAAI,EACpD,GAAIM,IAAcD,GAAaL,GAAQO,IAAaF,EAClD,MAAM,IAAI,MAAM,+BAA+BA,CAAQ;AAAA;AAAA,2BAEpCC,CAAS,qBAAqBC,CAAQ,EAAE,EAG7D,IAAMC,EAA6B,CAAC,EACpC,QAASC,EAAI,EAAGA,EAAIX,EAAO,OAAQ,EAAEW,EAC/BA,EAAIP,EACNM,EAAiB,KAAKV,EAAOW,CAAC,CAAC,EAE/BD,EAAiB,KAAK,CAAC,EAG3B,IAAME,EAAaC,GAAiBN,CAAQ,EACtCO,EAAwD,CAAC,OAAQ,MAAM,EACvEC,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAMT,CAAS,EAAG,CAAC,KAAM,UAAW,KAAMC,CAAQ,EACnE,CAAC,KAAM,SAAU,KAAM,KAAK,MAAMA,EAAWK,CAAU,CAAC,EAAG,CAAC,KAAM,UAAW,KAAMd,EAAW,OAAO,CACvG,EACII,GACFY,EAAkB,KAAK,MAAM,EAE/B,IAAME,EAAoBjB,EAAc,EAClCkB,EAAkBlB,EAAc,EAEhCmB,EAAmBC,GAA+B,CACtD,IAAMC,EAAWC,GAA4BxB,EAAO,CAAC,EAAE,QAAQ,EACzDyB,EAAY,CAChBC,EAAc,IAAK1B,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMe,CAAU,EACjEW,EAAc,QAAStB,EAAM,SAAUA,EAAM,KAAMW,CAAU,CAC/D,EACIV,GACFoB,EAAU,KAAKC,EAAc,OAAQrB,EAAK,SAAUA,EAAK,KAAMU,CAAU,CAAC,EAE5EU,EAAU,KAAKE,EAAe,SAAU3B,EAAO,CAAC,EAAE,SAAUM,EAAaS,CAAU,CAAC,EAChFI,GACFM,EAAU,KAAKE,EAAe,qBAAoCd,CAAgB,CAAC,EAEjFO,GACFK,EAAU,KAAKE,EAAe,mBAAkCd,CAAgB,CAAC,EAGnF,IAAMe,EAA8B,CAClC,CAAC,KAAM,aAAc,KAAM,KAAK,EAAG,CAAC,KAAM,YAAa,KAAM,KAAK,EAClE,CAAC,KAAM,uBAAwB,KAAM,KAAK,EAAG,CAAC,KAAM,UAAW,KAAM,KAAK,CAC5E,EACA,MAAO;AAAA,IACXN,EAAa,iBAAiBM,CAAQ,EAAE,iBAAiB,GAAGH,CAAS,CAAC;AAAA,IACtEH,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,uBAExDO,GAAW,MAAOd,CAAU,CAAC;AAAA,6BACvBc,GAAW,MAAOd,CAAU,CAAC;AAAA;AAAA;AAAA,oBAGtCe,GAAUP,EAAUR,EAAY,eAAe,CAAC;AAAA;AAAA;AAAA;AAAA,iBAInDgB,GAAU,aAAchB,CAAU,CAAC;AAAA,4BACxBgB,GAAU,mBAAoBhB,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI9Ce,GAAUP,EAAUR,EAAY,eAAe,CAAC;AAAA,uBAChDe,GAAUP,EAAUR,EAAY,UAAU,CAAC;AAAA,6BACrCU,EAAU,CAAC,EAAE,KAAK,KAAK;AAAA,UAC1CpB,EAAO,KAAKyB,GAAUP,EAAUR,EAAY,SAAS,CAAC,GAAK,EAAE;AAAA;AAAA;AAAA;AAAA,MAIjEI,EAAoB,sCAAwC,EAAE;AAAA,MAC9DC,EAAkB,8CAAgD,EAAE;AAAA,IAEpE,EACMY,EAAU,CAAC,CAAC,KAAM1B,EAAa,SAAUN,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAImB,GACFa,EAAQ,KAAK,CAAC,KAAMnB,EAAkB,UAAwB,CAAC,EAE7DO,GACFY,EAAQ,KAAK,CAAC,KAAMnB,EAAkB,UAAwB,CAAC,EAG1D,CACL,KAAM,qBACN,YAAa,CAAC,KAAM,GAAGE,CAAU,IAAIb,CAAW,GAAI,kBAAAe,CAAiB,EACrE,WAAY,KACP,CAAC,QAAAe,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKvB,EAAY,EAAuB,CAAC,EAAG,gBAAAS,CAAe,GAClG,gBAAAG,CACF,CACF,EAES3B,GAAY,CAACuC,EAAyBhC,IAA0C,CAC3FT,GAAeyC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQxC,GAA2BwC,EAAQ,OAAQhC,EAAYgC,EAAQ,WAAW,CAAC,CAC7F,IClIA,IAYMC,GA0NOC,GAGPC,GAEAC,GAwCAC,GA2BOC,GA9SbC,GAAAC,EAAA,kBAIAC,KACAC,KACAC,KAEAC,KACAC,KACAC,KAEMb,GAAiB,CAACc,EAA+BC,IAAoD,CACzG,IAAMC,EAAQF,EAAO,CAAC,EAChBG,EAAMH,EAAO,CAAC,EACdI,EAAQJ,EAAO,CAAC,EAChBK,EAAOL,EAAO,CAAC,EACfM,EAAiBN,EAAO,CAAC,EACzBO,EAAuBP,EAAO,CAAC,EAC/BQ,EAAUR,EAAO,CAAC,EAClBS,EAAYT,EAAO,CAAC,EAoC1B,GAAIE,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMQ,EAAe,GACfC,EAAYT,EAAM,KAAK,CAAC,EACxBU,EAAiBV,EAAM,KAAK,CAAC,EAC7BW,EAAaX,EAAM,KAAK,SAAW,EAAKQ,EAAeR,EAAM,KAAK,CAAC,EAAI,EAAIA,EAAM,KAAK,CAAC,EAChDD,EAAW,SAAWC,EAAM,KAAK,CAAC,EAC3EY,EAAmBF,EAEnBG,EAAqB,EACrBC,EAAoB,EAClBC,EAAW,KAAK,MAAMJ,EAAaZ,EAAW,QAAQ,EAC5D,GAAIO,GAAWC,EAAW,CACxB,GAAID,EAAQ,KAAK,SAAW,EAC1B,MAAM,IAAI,MAAM,mDAAmD,EAErE,GAAIC,EAAU,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,qDAAqD,EAEvEM,EAAqBP,EAAQ,KAAK,CAAC,EACnCQ,EAAoBR,EAAQ,KAAK,CAAC,CACpC,SAAWA,GAAWC,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAG1F,IAAIS,EACJ,GAAIf,EAAK,CACP,GAAID,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kEAAkE,EAEpF,GAAIC,EAAI,KAAK,OAAS,GAAKA,EAAI,KAAK,OAAS,EAC3C,MAAM,IAAI,MAAM,uDAAuD,EAEzE,GAAID,EAAM,KAAK,CAAC,IAAMC,EAAI,KAAK,CAAC,EAC9B,MAAM,IAAI,MAAM,4DAA4D,EAG9E,GAAIA,EAAI,KAAK,SAAW,EAAG,CACzB,GAAIA,EAAI,KAAK,CAAC,IAAMD,EAAM,KAAK,CAAC,EAC9B,MAAM,IAAI,MAAM,6DAA6D,EAE/EgB,EAAY,EACZJ,EAAmBX,EAAI,KAAK,CAAC,CAC/B,SAAWA,EAAI,KAAK,SAAW,EAAG,CAChC,GAAIA,EAAI,KAAK,CAAC,IAAMF,EAAW,UAAYE,EAAI,KAAK,CAAC,IAAM,GAAKA,EAAI,KAAK,CAAC,IAAMc,EAC9E,MAAM,IAAI,MAAM,4FAA4F,EAE9G,GAAIb,EACF,MAAM,IAAI,MAAM,yDAAyD,EAE3Ec,EAAY,EACZJ,EAAmBX,EAAI,KAAK,CAAC,CAC/B,KAAO,CACL,GAAIA,EAAI,KAAK,CAAC,IAAMF,EAAW,UAAYE,EAAI,KAAK,CAAC,IAAMc,EACzD,MAAM,IAAI,MAAM,wFAAwF,EAG1GC,EAAY,EACZJ,EAAmBX,EAAI,KAAK,CAAC,CAC/B,CACF,KAAO,CACL,GAAID,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,uEAAuE,EAEzF,GAAIA,EAAM,KAAK,SAAW,IAAMA,EAAM,KAAK,CAAC,IAAMD,EAAW,UAAYC,EAAM,KAAK,CAAC,IAAM,GACzF,MAAM,IAAI,MAAM,8FAA8F,EAGhHgB,EAAY,CACd,CAEA,GAAIb,EAAM,CACR,GAAIA,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,8CAA8C,EAGhE,GAAID,GACEF,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,CAAC,IAAM,EAC/C,MAAM,IAAI,MAAM,oCAAoC,CAG1D,CAEA,IAAIiB,IACJ,GAAIb,EAAgB,CAClBa,EAAW,EACX,IAAMC,EAAWd,EAAe,KAUhC,MATIc,EAAS,SAAW,EAClBA,EAAS,CAAC,IAAMT,EAClBQ,EAAW,EACFC,EAAS,CAAC,IAAM,EAAIT,EAAY,IACzCQ,EAAW,GAEJC,EAAS,SAAW,GAAKA,EAAS,CAAC,IAAMT,GAAaS,EAAS,CAAC,IAAMN,IAC/EK,EAAW,GAETA,IAAa,EACT,IAAI,MAAM,0FAA0F,EAEtG,IAAI,MAAM,oBAAoB,CACtC,CAEA,IAAIE,EAAe,GACfC,EAAcT,EAClB,GAAIT,EAAO,CACT,GAAIA,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,qDAAqD,EAGvE,GAAIF,EAAM,KAAK,CAAC,IAAME,EAAM,KAAK,CAAC,EAChC,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIA,EAAM,KAAK,SAAW,EAAG,CAC3B,GAAIU,IAAqBV,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,wEAAwE,EAE1FkB,EAAclB,EAAM,KAAK,CAAC,CAC5B,KAAO,CACL,GAAIU,IAAqBV,EAAM,KAAK,CAAC,EACnC,MAAM,IAAI,MAAM,kFAAkF,EAEpGkB,EAAclB,EAAM,KAAK,CAAC,EAAIA,EAAM,KAAK,CAAC,EAC1CiB,EAAe,EACjB,CACF,CAEA,IAAME,EAAsBR,EAAqBD,EAC3CU,EAAsB,GAO5B,GAAIlB,EACF,MAAM,IAAI,MAAM,mCAAmC,EAErD,GAAIC,EACF,MAAM,IAAI,MAAM,6BAA6B,EAE/C,GAAIC,EACF,MAAM,IAAI,MAAM,0BAA0B,EAE5C,GAAIC,EACF,MAAM,IAAI,MAAM,4BAA4B,EAG9C,MAAO,CACL,UAAAE,EACA,eAAAC,EACA,mBAAAG,EACA,iBAAAD,EACA,oBAAAS,EACA,kBAAAP,EACA,gBAAiB,EACjB,WAAAH,EACA,YAAAS,EACA,SAAAL,EACA,UAAW,KAAK,MAAMK,EAAcrB,EAAW,QAAQ,EACvD,SAAUA,EAAW,SACrB,iBAAkB,GAClB,uBAAwB,GACxB,gBAAiBA,EAAW,gBAC5B,SAAAkB,EACA,MAAOlB,EAAW,MAClB,oBAAAuB,EACA,aAAAH,EACA,UAAAH,CACF,CACF,EAEa/B,GAAqCc,GAC9CwB,GAA4B,CAAC,GAAGxB,CAAU,CAAC,EAEzCb,GAAgDqC,GAA4B,CAAC,KAAM,CAAC,EAAG,EAAG,EAAG,CAAC,CAAC,CAAC,EAEhGpC,GACF,CAACqC,EAAyBC,EAAiBtB,EAAkBM,EAAmBC,EAC/EC,EAAoBe,IAAuB,CAC1C,IAAMC,EAAc,CAAClB,EAAWC,EAAgBC,CAAU,EACpDiB,EAAaC,EAAU,KAAKF,CAAW,EACvCG,EACF,CAAC,CAAC,KAAM,SAAU,KAAMF,CAAU,EAAG,CAAC,KAAM,SAAU,KAAMF,CAAU,EAAG,CAAC,KAAM,SAAU,KAAMf,CAAU,CAAC,EAEzGoB,EAAmBC,GAA+B,CACtD,IAAMC,EAASC,EAAe,gBAAiBT,EAAI,SAAUE,CAAW,EAClEQ,EAAWC,EAAc,MAAOX,EAAI,SAAUE,CAAW,EACzDU,EAAYD,EAAc,OAAQjC,EAAK,SAAUwB,CAAW,EAE5DW,EAA8B,CAClC,CAAC,KAAM,cAAe,KAAM,KAAK,EAAG,CAAC,KAAM,cAAe,KAAM,KAAK,EAAG,CAAC,KAAM,cAAe,KAAM,KAAK,CAC3G,EACA,MAAO;AAAA,IACXN,EAAa,iBAAiBM,CAAQ,EAAE,iBAAiBH,EAAUE,EAAWJ,CAAM,CAAC;AAAA,IACrFD,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA;AAAA;AAAA,IAK1E,EAEA,OAAOR,EAAQ,QACX,CACE,KAAM,4BACN,YAAa,CAAC,kBAAmB,CAAC,OAAQ,MAAM,CAAC,EACjD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMG,EAAa,SAAUF,EAAI,SAAU,aAAgC,CAAC,EACvF,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,EAClE,gBAAAE,CACF,GACA,gBAAAC,CACF,EACA,CAAC,OAAQ,CAACN,EAAKtB,CAAI,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAC7C,EAEEf,GACF,CAACoC,EAAyBf,EAAmB8B,EAAkB7B,EAAwBK,EACtFyB,EAAmBrC,EAAmBuB,IAAwB,CAG7D,IAAIe,EAAgBD,EACpB,GAAKrC,EAOE,CACL,GAAIO,IAAmB,EACrB,MAAM,IAAI,MAAM,mFAAmF,EAEnG,OAAA+B,EACItD,GAAiBqC,EAASgB,EAAOrC,EAAMM,EAAWC,EAAgB6B,EAAWxB,EAAUW,CAAW,EACtGe,EAAgBA,EAAc,QAAQ,CAAChC,EAAWC,EAAgB6B,EAAUxB,CAAQ,CAAC,EAC9ES,EAAQ,QACXkB,GAA2BD,EAAevD,GAAyB,IAAI,EACvE,CAAC,OAAQ,CAACuD,CAAa,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAEnD,KAjBE,QAAID,EAAM,KAAK,SAAW,IACxBC,EAAgBD,EAAM,QAAQ,CAAC/B,EAAWC,EAAgB6B,EAAUxB,CAAQ,CAAC,GAExES,EAAQ,QACXkB,GAA2BD,EAAevD,GAAyB,IAAI,EACvE,CAAC,OAAQ,CAACuD,CAAa,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAanD,EAESpD,GAAqB,CAACmC,EAAyBzB,IAAqC,CAC/F,IAAM4C,EAAS3D,GAAewC,EAAQ,OAAQzB,CAAU,EAExD,GAAIyB,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpC,MAAM,IAAI,MAAM,+BAA+B,EAGjD,GAAIA,EAAQ,OAAO,CAAC,GAAG,KAAK,SAAW,EACrC,MAAM,IAAI,MAAM,8BAA8B,EAIhD,IAAMoB,EAASpB,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,GAAKA,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,GACvFA,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EAEhCqB,EAAIzD,GACNoC,EAASmB,EAAO,UAAWA,EAAO,SAAUA,EAAO,eAAgBA,EAAO,SAAUnB,EAAQ,OAAO,CAAC,EACpGA,EAAQ,OAAO,CAAC,EAAG,CAAC,EAExB,GAAIoB,EACF,OAAOE,GACHtB,EAASqB,EAAGrB,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAG,OAAW,OAAW,OAC3FA,EAAQ,OAAO,CAAC,EAAGmB,EAAQ5C,CAAU,EAG3C,IAAMgD,EAAI3D,GACNoC,EAASmB,EAAO,UAAWA,EAAO,SAAUA,EAAO,iBAAkBA,EAAO,SAAUnB,EAAQ,OAAO,CAAC,EACtGA,EAAQ,OAAO,CAAC,EAAGmB,EAAO,UAAU,EAElCK,EAAI5D,GACNoC,EAASmB,EAAO,UAAWA,EAAO,SAAUA,EAAO,iBAAkBA,EAAO,UAAWnB,EAAQ,OAAO,CAAC,EACvGA,EAAQ,OAAO,CAAC,EAAG,EAAImB,EAAO,UAAU,EAE5CG,GACItB,EAASqB,EAAGE,EAAGC,EAAGxB,EAAQ,OAAO,CAAC,EAAG,OAAWA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGmB,EACzG5C,CAAU,CAChB,IClVA,IAiBMkD,GAmBAC,GA0BAC,GA2BAC,GAuBAC,GAuBAC,GAeAC,GAkDAC,GA0BOC,GAlObC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KASMb,GAAkBc,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,QAAU,EAAG,CACtB,IAAIC,EAAYD,EAAO,CAAC,EAAE,KAAK,OAAS,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EAI9D,GAHIA,EAAO,SAAW,IACpBC,EAAYD,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAEpD,CAACC,EACH,MAAM,IAAI,MAAM,6EAA6E,CAEjG,CACF,EAEMd,GAAiB,CAACe,EAAuBC,EAAmBC,IAA+B,CAC/F,IAAIC,EAAQ,GACZ,QAASC,EAAIH,EAAY,EAAGG,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,sBACSH,EAAO,WAAW,UAAWI,CAAC,CAAC,OAAOC,GAAa,gBAAiBD,EAAGF,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,2BAI7EG,GAAa,mBAAoBD,EAAGH,CAAS,CAAC;AAAA;AAAA;AAAA,gCAGzCI,GAAa,qBAAsBD,EAAGH,CAAS,CAAC;AAAA,UAI9E,MAAO;AAAA,oBACWD,EAAO,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA,cAIvBG,CAAK;AAAA;AAAA;AAAA,OAInB,EAEMjB,GAAgB,CAACc,EAAuBC,EAAmBC,IAA+B,CAC9F,IAAIC,EAAQ,GACZ,QAASC,EAAIH,EAAY,EAAGG,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACaH,EAAO,WAAW,UAAWI,CAAC,CAAC,OAAOC,GAAa,gBAAiBD,EAAGF,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,yCAKnEG,GAAa,mBAAoBD,EAAGH,CAAS,CAAC;AAAA;AAAA,gCAEvDI,GAAa,mBAAoBD,EAAGH,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,oCAI1CI,GAAa,qBAAsBD,EAAGH,CAAS,CAAC;AAAA,cAIlF,MAAO;AAAA;AAAA;AAAA,gBAGOE,CAAK;AAAA;AAAA,WAGrB,EAEMhB,GAAa,CAACa,EAAuBC,EAAmBC,IAA+B,CAC3F,IAAIC,EAAQ,GACZ,QAASC,EAAIH,EAAY,EAAGG,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACaH,EAAO,WAAW,UAAWI,CAAC,CAAC,OAAOC,GAAa,gBAAiBD,EAAGF,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,+BAI7EG,GAAa,mBAAoBD,EAAGH,CAAS,CAAC;AAAA,4BACjDI,GAAa,mBAAoBD,EAAGH,CAAS,CAAC;AAAA;AAAA,oCAEtCI,GAAa,qBAAsBD,EAAGH,CAAS,CAAC;AAAA,cAIlF,MAAO;AAAA;AAAA;AAAA,gBAGOE,CAAK;AAAA;AAAA,WAGrB,EAEMf,GAAa,CAACY,EAAuBC,EAAmBC,IAA+B,CAC3F,IAAIC,EAAQ,GACZ,QAASC,EAAIH,EAAY,EAAGG,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACaH,EAAO,WAAW,UAAWI,CAAC,CAAC,OAAOC,GAAa,gBAAiBD,EAAGF,CAAU,CAAC;AAAA;AAAA,6BAE/EG,GAAa,mBAAoBD,EAAGH,CAAS,CAAC;AAAA;AAAA,+BAE5CI,GAAa,mBAAoBD,EAAGH,CAAS,CAAC;AAAA,6BAChDI,GAAa,mBAAoBD,EAAGH,CAAS,CAAC;AAAA;AAAA,oCAEvCI,GAAa,qBAAsBD,EAAGH,CAAS,CAAC;AAAA,cAIlF,MAAO;AAAA;AAAA;AAAA,gBAGOE,CAAK;AAAA;AAAA,WAGrB,EAEMd,GAAgB,CAACW,EAAuBC,EAAmBK,IAAsC,CACrG,OAAQA,EAAW,KAAM,CACvB,IAAK,GACH,OAAOrB,GAAee,EAAQC,EAAWK,EAAW,KAAK,MAAM,EACjE,IAAK,GACH,OAAOpB,GAAcc,EAAQC,EAAWK,EAAW,KAAK,MAAM,EAChE,IAAK,GACH,OAAOnB,GAAWa,EAAQC,EAAWK,EAAW,KAAK,MAAM,EAC7D,IAAK,GACH,OAAOlB,GAAWY,EAAQC,EAAWK,EAAW,KAAK,MAAM,EAC7D,QACE,MAAM,IAAI,MAAM,cAAc,CAClC,CACF,EAEMhB,GAAuB,CAACQ,EAA+BQ,IAA2C,CACtG,IAAMC,EAAcC,EAAU,SAASV,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGQ,EAAW,IAAI,EACxEG,EAAYX,EAAO,CAAC,EAAE,KAEtBY,EACF,CAAC,CAAC,KAAM,SAAU,KAFHF,EAAU,KAAKD,CAAW,CAEP,EAAG,CAAC,KAAM,SAAU,KAAMD,EAAW,IAAI,CAAC,EAChF,GAAIA,EAAW,OAAS,EAAG,CACzB,IAAMK,EAAiBC,GAA2Bd,EAAO,CAAC,EAAE,QAAQ,EACpEY,EAAgB,KAAK,CAAC,KAAMC,EAAgB,KAAML,EAAW,KAAK,CAAC,CACrE,CAEAI,EAAgB,KAAK,GAAGG,EAA2Bf,EAAO,CAAC,EAAE,IAAI,EAAG,GAAGe,EAA2BN,CAAW,CAAC,EAC9G,IAAMO,EAAwD,CAAC,MAAM,EAE/DC,EAAmBC,GAA+B,CACtD,IAAMhB,EAASiB,EAAe,SAAUnB,EAAO,CAAC,EAAE,SAAUS,EAAY,MAAM,EACxEW,EAAQC,EAAc,IAAKrB,EAAO,CAAC,EAAE,SAAUW,EAAU,MAAM,EAC/DW,EAAWF,EAAM,KAAK,MACtBG,EAAahC,GAAcW,EAAQS,EAAU,OAAQH,CAAU,EAC/DgB,EACF,CAAC,CAAC,KAAM,cAAe,KAAM,KAAK,EAAG,CAAC,KAAM,OAAQ,KAAM,MAAO,OAAQhB,EAAW,KAAK,MAAM,CAAC,EACpG,OAAIA,EAAW,OAAS,GACtBgB,EAAS,KAAK,CAAC,KAAM,iBAAkB,KAAMF,CAAkC,CAAC,EAG3E;AAAA,cACGJ,EAAa,iBAAiBM,CAAQ,EAAE,iBAAiBJ,EAAOlB,CAAM,CAAC;AAAA,cACvEgB,EAAa,UAAU,CAAC;AAAA,cACxBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,4BAE5DhB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,0BAEtCoB,CAAQ;AAAA,cACpBC,CAAU;AAAA;AAAA,UAGtB,EAEA,MAAO,CACL,KAAM,MACN,YAAa,CAAC,KAAM,GAAGf,EAAW,IAAI,GAAI,kBAAAQ,CAAiB,EAC3D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMP,EAAa,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKU,EAAU,KAAKD,CAAW,EAAI,EAAuB,CAAC,EACnF,gBAAAG,CACF,GACA,gBAAAK,CACF,CACF,EAEMxB,GAAgC,CAACO,EAA+BQ,IAA6C,CACjH,GAAIR,EAAO,OAAS,EAAG,CACrB,IAAMyB,EAAezB,EAAO,CAAC,EAAE,iBAAiB,EAC1C0B,EAAS1B,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,KAAQA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAI,EAElFG,EAAYH,EAAO,CAAC,EAAE,KAAK,OAC3B2B,EAAa,IAAI,WAAW,EAAIxB,CAAS,EAAE,KAAK,CAAC,EACvD,GAAIH,EAAO,QAAU,EAAG,CACtB,IAAM4B,EAAO5B,EAAO,CAAC,EAAE,iBAAiB,EACxC,QAAS,EAAI,EAAG,EAAI4B,EAAK,OAAQ,IAC/BD,EAAW,OAAOC,EAAK,CAAC,CAAC,CAAC,EAAI,OAAOH,EAAa,CAAC,CAAC,EACpDE,EAAW,OAAOC,EAAK,CAAC,CAAC,EAAIzB,CAAS,EAAI,OAAOsB,EAAa,EAAIG,EAAK,MAAM,CAAC,CAElF,MACEH,EAAa,QAAQ,CAACI,EAAG,IAAMF,EAAW,OAAO,CAAC,CAAC,EAAK,OAAOE,CAAC,CAAE,EAGpE,IAAMC,EAAiB,CAAC,EACxB,OAAAH,EAAW,QAAQE,GAAKC,EAAK,KAAKD,CAAC,CAAC,EAE7B,CAAC,KAAMrB,EAAW,KAAM,MAAAkB,EAAO,KAAAI,CAAI,CAC5C,KACE,QAAOtB,CAEX,EAEad,GAAM,CAACqC,EAAyBvB,IAAoC,CAC/EtB,GAAe6C,EAAQ,MAAM,EAC7B,IAAMC,EAAoBvC,GAA8BsC,EAAQ,OAAQvB,CAAU,EAClFuB,EAAQ,QAAQvC,GAAqBuC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxF,ICtOA,IAkBMC,GAMAC,GA4BAC,GA0DAC,GAsJAC,GAGAC,GAGAC,GAGAC,GAaAC,GAiCOC,GAYAC,GAKPC,GAWOC,GAKAC,GAUPC,GA4BOC,GAKAC,GAgBAC,GAKAC,GA5ZbC,GAAAC,EAAA,kBAGAC,KAGAC,KAIAC,KAQMvB,GAAkBwB,GAAwC,CAC9D,GAAIC,GAAI,OAAO,uBAAyB,CAACD,GAAUA,EAAO,SAAW,GACnE,MAAM,IAAI,MAAM,4BAA4B,CAEhD,EAEMvB,GAA0C,CAC5CyB,EAAmBC,EAA2BC,IAAyD,CACzG,IAAMC,EAAiBF,EAAW,SAAW,OACvCG,EAA2BJ,EAAM,KAAK,MAAM,EAC9CG,GACFC,EAAyB,OAAO,EAAG,EAAGA,EAAyB,IAAI,CAAE,EAEvE,IAAMC,EAAe,OAAO,eAAe,KAAKJ,EAAY,WAAW,EACjEK,EAAcL,EAAW,YAAY,MAAM,EAC3CM,EAAUN,EAAW,QAAQ,MAAM,EACnCO,EAAsBH,EAAgBJ,EAAiC,UAAU,MAAM,EAAI,CAAC,EAC5FQ,EAAOR,EAAW,KAAK,MAAM,EACnCS,GAAa,qBAAqBR,EAAkBE,EAA0BE,EAAaC,EAASC,EAAWC,CAAI,EAEnH,IAAME,EAA4BD,GAAa,uBAC3CR,EAAkBE,EAA0BG,EAASC,EAAWF,EAAaG,EAAMR,EAAW,OAAO,EAEnGW,EAAgB,OAAO,OAAO,CAAC,EAAGX,CAAU,EAC9CI,EACF,OAAO,OAAOO,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,UAAAD,EAAW,SAAUP,EAAW,QAAQ,CAAC,EAEnG,OAAO,OAAOW,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,SAAUR,EAAW,QAAQ,CAAC,EAE1F,IAAMY,EAA2BF,EAA0B,MAAM,EACjE,OAAAE,EAAyB,KAAKA,EAAyB,OAAO,EAAG,CAAC,EAAE,CAAC,CAAC,EAC/D,CAACD,EAAeT,EAAiBU,EAA2BF,CAAyB,CAC9F,EAEMnC,GAAuB,CACzBsC,EACAb,IAAgG,CAClG,IAAME,EAAiBF,EAAW,SAAW,OACvCc,EAAaC,EAAU,KAAKF,CAAW,EACvCG,EAAaD,EAAU,KAAKf,EAAW,WAAW,EAClDiB,EAAoC,CAAC,CAAC,KAAM,SAAU,KAAMH,CAAU,EAAG,CAAC,KAAM,SAAU,KAAME,CAAU,CAAC,EAC3GE,EAA8B,CAAC,CAAC,KAAM,aAAc,KAAM,KAAK,EAAG,CAAC,KAAM,aAAc,KAAM,KAAK,CAAC,EACzG,GAAIlB,EAAW,YAAY,QAAU,EAAG,CACtC,IAAMmB,EAAKnB,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7DoB,EAAKpB,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrDqB,EAAUrB,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxDsB,EAAQtB,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClDuB,EAAoB,CAAC,EAAEF,EAAUC,GACvCL,EAAgB,KACZ,CAAC,KAAM,SAAU,KAAME,CAAE,EACzB,CAAC,KAAM,SAAU,KAAMC,CAAE,EACzB,CAAC,KAAM,SAAU,KAAMC,CAAO,EAC9B,CAAC,KAAM,SAAU,KAAMC,CAAK,CAChC,EACAJ,EAAS,KACL,CAAC,KAAM,KAAM,KAAM,KAAK,EAAG,CAAC,KAAM,KAAM,KAAM,KAAK,EAAG,CAAC,KAAM,UAAW,KAAM,KAAK,EACnF,CAAC,KAAM,QAAS,KAAM,KAAK,CAAC,EAEhC,IAAIM,EAAoB,GACxB,GAAIxB,EAAW,YAAY,SAAW,EAAG,CACvC,IAAMyB,EAAKzB,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7D0B,EAAK1B,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrD2B,EAAU3B,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxD4B,EAAQ5B,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EACxDwB,EAAoB,CAAC,EAAEG,EAAUC,GACjCX,EAAgB,KACZ,CAAC,KAAM,SAAU,KAAMQ,CAAE,EAAG,CAAC,KAAM,SAAU,KAAMC,CAAE,EAAG,CAAC,KAAM,SAAU,KAAMC,CAAO,EACtF,CAAC,KAAM,SAAU,KAAMC,CAAK,CAAC,EAEjCV,EAAS,KACL,CAAC,KAAM,KAAM,KAAM,KAAK,EAAG,CAAC,KAAM,KAAM,KAAM,KAAK,EAAG,CAAC,KAAM,UAAW,KAAM,KAAK,EACnF,CAAC,KAAM,QAAS,KAAM,KAAK,CAAC,CAClC,CACA,MAAO,CAACD,EAAiBC,EAAU,GAAMK,EAAmBC,CAAiB,CAC/E,KAAO,CACL,GAAItB,EACF,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAM2B,EAAgBd,EAAU,eAAef,EAAW,WAAW,EACrEiB,EAAgB,KACZ,CAAC,KAAM,SAAU,KAAMY,CAAa,EAAG,CAAC,KAAM,SAAU,KAAM7B,EAAW,IAAI,EAC7E,CAAC,KAAM,SAAU,KAAMA,EAAW,OAAO,CAAC,EAC9CkB,EAAS,KACL,CAAC,KAAM,gBAAiB,KAAM,MAAO,OAAQW,EAAc,MAAM,EACjE,CAAC,KAAM,OAAQ,KAAM,MAAO,OAAQ7B,EAAW,KAAK,MAAM,EAC1D,CAAC,KAAM,UAAW,KAAM,MAAO,OAAQA,EAAW,QAAQ,MAAM,CAAC,EAErE,IAAM8B,EAAU9B,EAAW,KAAK,OAAO,CAAC+B,EAAKC,IAAQD,EAAMC,CAAG,EAC9D,MAAO,CAACf,EAAiBC,EAAU,CAAC,CAACY,EAAS,GAAO,EAAK,CAC5D,CACF,EAEMtD,GAAsB,CACxByD,EAA4BC,EAAkBC,EAAcC,EAAyBpC,EACrFqC,EAAaC,EAAaC,EAAerB,EAA6BY,EAAkBP,EACxFC,IAAuC,CACzC,IAAMtB,EAAiBF,EAAW,SAAW,OACvCwC,EAAWN,EAAE,KAAK,MAClBO,EAASC,EAAe,SAAUR,EAAE,KAAK,OAAQE,CAAe,EAEtE,GAAIpC,EAAW,YAAY,QAAU,EAAG,CACtC,IAAI2C,EAAQ,GACRC,EAAQ,GACRC,EAAW,GACTC,EAAUX,GAAQjC,EAAiB,EAAI,GAsB7C,GArBIqB,EACFoB,EAAQ;AAAA;AAAA,6BAEeG,CAAO,eAAeA,CAAO;AAAA,iCACzBA,CAAO,qBAAqBA,CAAO;AAAA,4CACxBA,CAAO;AAAA;AAAA;AAAA;AAAA,kCAIjBZ,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAGjBM,EAAQ;AAAA;AAAA,6BAEeG,CAAO,eAAeA,CAAO;AAAA,kCACxBZ,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAIfrC,EAAW,YAAY,SAAW,EAAG,CACvC,IAAM+C,EAAUZ,GAAQjC,EAAiB,EAAI,GACzCsB,EACFoB,EAAQ;AAAA;AAAA,6BAEaG,CAAO,eAAeA,CAAO;AAAA,iCACzBA,CAAO,qBAAqBA,CAAO,yBAAyBA,CAAO;AAAA;AAAA;AAAA;AAAA,gBAM5FH,EAAQ;AAAA;AAAA,6BAEaG,CAAO,eAAeA,CAAO;AAAA,kBAGpDF,EAAW;AAAA;AAAA,aAGb,CAoBA,MAlBoB;AAAA,cACVZ,EAAa,iBAAiBf,CAAQ,EAAE,iBAAiBgB,EAAGO,CAAM,CAAC;AAAA;AAAA,cAEnER,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,8BAE3DQ,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,4BAEvCD,CAAQ,IAAID,CAAK;AAAA;AAAA,gBAE7BK,CAAK;AAAA,gBACLD,CAAK;AAAA,gBACLE,CAAQ;AAAA,gBACRP,CAAG;AAAA;AAAA;AAAA,cAKjB,KAAO,CACL,GAAIpC,EACF,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAM8C,EAAchD,EAAW,YAAY,OACrCiD,EAAWjD,EAAW,KAAK,OAC7BkD,EAAU,GACd,OAAIpB,EACFoB,EAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAQgBhB,EAAE,gBAAgB,UAAU,CAAC;AAAA,kBAC3CG,CAAG;AAAA,iBAGfa,EAAU;AAAA;AAAA,8BAEchB,EAAE,gBAAgB,UAAU,CAAC;AAAA,gBAC3CG,CAAG;AAAA,cAGK;AAAA,cACVJ,EAAa,iBAAiBf,CAAQ,EAAE,iBAAiBgB,EAAGO,CAAM,CAAC;AAAA;AAAA,cAEnER,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,8BAC3DQ,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,wCAE3BO,CAAW;AAAA;AAAA,4BAEvBR,CAAQ,IAAID,CAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uCAMNS,EAAc,CAAC;AAAA,0CACZG,GAAa,yBAA0B,IAAKH,CAAW,CAAC;AAAA,2CACvDG,GAAa,yBAA0B,IAAKH,CAAW,CAAC;AAAA;AAAA,0BAEzEA,EAAc,CAAC;AAAA;AAAA;AAAA,+BAGVb,EAAOa,CAAW,UAAUb,CAAI;AAAA,+CAEvDgB,GAAa,mBAAoB,OAAOhB,EAAOa,CAAW,IAAKA,CAAW,CAAC;AAAA,oCAC/Cb,EAAOa,CAAW,QAAQG,GAAa,gBAAiB,SAAUF,CAAQ,CAAC;AAAA,oBAC3FC,CAAO;AAAA;AAAA,gBAEXZ,CAAG;AAAA;AAAA;AAAA,cAKjB,CACF,EAcM7D,GAAiCuB,GAClC,GAAGA,EAAW,MAAM,IAAIA,EAAW,QAAQ,IAAIA,EAAW,OAAO,IAAIA,EAAW,YAAY,MAAM,GAEjGtB,GAA4CsB,GAC7C,GAAGvB,GAA8BuB,CAAU,CAAC,IAAIA,EAAW,eAAe,GAEzErB,GAAwCqB,GACzC,GAAGvB,GAA8BuB,CAAU,CAAC,IAAIA,EAAW,YAAY,IAAIA,EAAW,SAAS,GAE9FpB,GAA6BoB,IAA+D,CAChG,OAAQA,EAAW,OACnB,QAAS,CAAC,SAAU,QAAS,aAAc,YAAY,EAAEA,EAAW,QAAkB,EACtF,SAAUA,EAAW,UACrB,YAAaA,EAAW,aACxB,QAASA,EAAW,QACpB,KAAMA,EAAW,IACnB,GAMMnB,GACF,CAACuE,EAAcrD,EAAmBE,EAA2BD,IAAmD,CAC9G,GAAM,CAACqD,EAAoBxC,CAAW,EAClCvC,GAAwCyB,EAAOC,EAAYC,CAAgB,EACzEiC,EAAIoB,EAAc,IAAKvD,EAAM,SAAUA,EAAM,KAAK,MAAM,EACxDyC,EAAWN,EAAE,KAAK,MAElBG,EAAM,kBACRC,EAAM,GACNe,EAAmB,gBACrBf,GAAO,YAAYE,CAAQ,yBAE3BF,GAAO,YAAYE,CAAQ,oCAE7B,GAAM,CAACvB,EAAiBC,EAAUY,EAASP,EAAmBC,CAAiB,EAC3EjD,GAAqBsC,EAAawC,CAAkB,EACxDpC,EAAgB,KAAK,GAAGsC,EAA2BxD,EAAM,IAAI,EAAG,GAAGwD,EAA2B1C,CAAW,CAAC,EAC1G,IAAM2C,EAAwD,CAAC,MAAM,EACrE,MAAO,CACL,KAAAJ,EACA,YACI,CAAC,KAAM,GAAGpD,EAAW,QAAQ,IAAI8B,CAAO,IAAIP,CAAiB,IAAIC,CAAiB,GAAI,kBAAAgC,CAAiB,EAC3G,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAM3C,EAAa,SAAUd,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKgB,EAAU,KAAKF,CAAW,EAAI,EAAuB,CAAC,EACnF,gBAAAI,CACF,GACA,gBAAiBgB,GAAgBzD,GAC7ByD,EAAcC,EAAGnC,EAAM,KAAK,OAAQc,EAAY,OAAQwC,EAAoBhB,EAAKC,EAAK,EAAKpB,EAC3FY,EAASP,EAAmBC,CAAiB,CACnD,CACF,EAES1C,GAA8BkB,GAA+D,CACxG,IAAMyD,EAAmBzD,EAAW,oBAAiC,EAE/D0D,EAAO9E,GAA0BoB,CAAU,EAEjD,GAAI0D,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAE1F,IAAMC,EAAwB,CAAC,gBAAAF,EAAiB,GAAGC,EAAM,SAAU,EAAE,EACrE,MAAO,CAAC,GAAGC,EAAuB,SAAUjF,GAAyCiF,CAAqB,CAAC,CAC7G,EAEa5E,GAAc,CAAC6E,EAAyB5D,IAA4C,CAC/F3B,GAAeuF,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ/E,GAA6B,cAAe+E,EAAQ,OAAO,CAAC,EAAG,GAAO5D,CAAU,CAAC,CACnG,EAEMhB,GAAuB,CAC3B,QAAS,GACT,SAAU,EACV,gBAAiB,GACjB,YAAa,CAAC,EACd,QAAS,CAAC,EACV,KAAM,CAAC,EACP,aAAc,EACd,UAAW,CAAC,CACd,EAEaC,GAAoCe,GAA+D,CAC9G,IAAM6D,EAAS7D,EAAW,OAC1B,MAAO,CAAC,OAAA6D,EAAQ,GAAG7E,GAAsB,SAAU6E,CAAM,CAC3D,EAEa3E,GAAoB,CAAC0E,EAAyB5D,IAA4C,CACrG3B,GAAeuF,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ/E,GAA6B,oBAAqB+E,EAAQ,OAAO,CAAC,EAAG,GAAM5D,CAAU,CAAC,CACxG,EAOMb,GACF,CAACiE,EAAcrD,EAAmBE,EAA2BD,IAA+C,CAC1G,GAAM,CAACqD,EAAoBxC,CAAW,EAClCvC,GAAwCyB,EAAOC,EAAYC,CAAgB,EACzEoC,EAAM;AAAA;AAAA,MAGNC,EAAM,GACNJ,EAAIoB,EAAc,IAAKvD,EAAM,SAAUA,EAAM,KAAK,MAAM,EACxDyD,EAAwD,CAAC,MAAM,EAC/D,CAACvC,EAAiBC,EAAUY,EAASP,EAAmBC,CAAiB,EAC3EjD,GAAqBsC,EAAawC,CAAkB,EACxD,OAAApC,EAAgB,KAAK,GAAGsC,EAA2BxD,EAAM,IAAI,EAAG,GAAGwD,EAA2B1C,CAAW,CAAC,EACnG,CACL,KAAAuC,EACA,YACI,CAAC,KAAM,GAAGpD,EAAW,QAAQ,IAAI8B,CAAO,IAAIP,CAAiB,IAAIC,CAAiB,GAAI,kBAAAgC,CAAiB,EAC3G,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAM3C,EAAa,SAAUd,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKgB,EAAU,KAAKF,CAAW,EAAI,EAAuB,CAAC,EACnF,gBAAAI,CACF,GACA,gBAAiBgB,GAAgBzD,GAC7ByD,EAAcC,EAAGnC,EAAM,KAAK,OAAQc,EAAY,OAAQwC,EAAoBhB,EAAKC,EAAK,KAAMpB,EAC5FY,EAASP,EAAmBC,CAAiB,CACnD,CACF,EAESpC,GAAU,CAACwE,EAAyB5D,IAAwC,CACvF3B,GAAeuF,EAAQ,MAAM,EAC7BA,EAAQ,QAAQzE,GAAyB,UAAWyE,EAAQ,OAAO,CAAC,EAAG,GAAO5D,CAAU,CAAC,CAC3F,EAEaX,GAA0BW,GAA2D,CAChG,IAAM8D,EAAe9D,EAAW,cAC1BO,EAAYP,EAAW,UAEvB0D,EAAO9E,GAA0BoB,CAAU,EAEjD,GAAI8D,IAAiB,EACnB,MAAM,IAAI,MAAM,6DAA6D,EAE/E,GAAIJ,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,oEAAoE,EAEtF,IAAMK,EAAoB,CAAC,aAAAD,EAAc,UAAAvD,EAAW,GAAGmD,EAAM,SAAU,EAAE,EACzE,MAAO,CAAC,GAAGK,EAAmB,SAAUpF,GAAqCoF,CAAiB,CAAC,CACjG,EAEazE,GAAgCU,GAA2D,CACtG,IAAM6D,EAAS7D,EAAW,OAC1B,MAAO,CAAC,OAAA6D,EAAQ,GAAG7E,GAAsB,SAAU6E,CAAM,CAC3D,EAEatE,GAAgB,CAACqE,EAAyB5D,IAAwC,CAC7F3B,GAAeuF,EAAQ,MAAM,EAC7BA,EAAQ,QAAQzE,GAAyB,gBAAiByE,EAAQ,OAAO,CAAC,EAAG,GAAM5D,CAAU,CAAC,CAChG,IC/ZA,IAUMgE,GAUAC,GAqCOC,GAzDbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GAAwB,CAACQ,EAAeC,EAAeC,IAAwB,CACnF,IAAMC,EAAiBH,IAAUC,EAC3BG,EAA8BJ,EAAQC,GAASC,EAAQ,EACvDG,EAA8BL,EAAQC,GAASC,EAAQ,EAE7D,GAAIC,GAAkBC,GAA+BC,EACnD,MAAM,IAAI,MAAM,2CAA4C,CAEhE,EAEMZ,GAAyB,CAACO,EAAeC,EAAeC,EAAeI,IAAoC,CAC/G,IAAMC,EAAc,KAAK,IAAI,KAAK,MAAMN,EAAQD,GAASE,CAAK,CAAC,EACzDM,EAAwB,CAACD,CAAW,EACpCE,EAAaF,EACbG,EAAiBC,GAA2BL,CAAQ,EACpDM,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAMH,CAAU,EAAG,CAAC,KAAMC,EAAgB,KAAMV,CAAK,EAAG,CAAC,KAAMU,EAAgB,KAAMR,CAAK,EAC3G,GAAGW,EAA2BL,CAAW,CAC3C,EAEMM,EAAmBC,GAA+B,CACtD,IAAMC,EAASC,EAAe,SAAUX,EAAUE,EAAY,MAAM,EAC9DU,EAAWF,EAAO,KAAK,MACvBG,EAA8B,CAClC,CAAC,KAAM,aAAc,KAAM,KAAK,EAAG,CAAC,KAAM,QAAS,KAAMD,CAAkC,EAC3F,CAAC,KAAM,QAAS,KAAMA,CAAkC,CAC1D,EACA,MAAO;AAAA,UACDH,EAAa,iBAAiBI,CAAQ,EAAE,iBAAiBH,CAAM,CAAC;AAAA,UAChED,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,gDACnCG,CAAQ;AAAA,QAEtD,EAEA,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,GAAGZ,CAAQ,EAAE,EACjC,gBAAAQ,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMN,EAAa,SAAAF,CAAQ,CAAC,EACvC,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,EAClE,gBAAAG,CACF,EACF,CACF,EAEalB,GAAS0B,GAAkC,CACtD,IAAIpB,EAAQ,EACRC,EAAQ,EACRC,EAAQ,EACRkB,EAAQ,OAAO,CAAC,EAAE,WAAa,GACjCpB,EAAQoB,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3CnB,EAAQmB,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3ClB,EAAQkB,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,GAClCA,EAAQ,OAAO,CAAC,EAAE,WAAa,IACxCpB,EAAQoB,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7CnB,EAAQmB,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7ClB,EAAQkB,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,GAE3CC,GAAI,OAAO,sBACb7B,GAAsBQ,EAAOC,EAAOC,CAAK,EAG3CkB,EAAQ,QAAQ3B,GAAuBO,EAAOC,EAAOC,EAAOkB,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CACvG,IC3EA,IAgCME,GAuBAC,GASAC,GA8CAC,GAkDAC,GAkCAC,GAaAC,GAwBAC,GAyBAC,GAuBAC,GAkCAC,GAWAC,GAQAC,GAsDAC,GA6EAC,GAwEAC,GAuHAC,GAOOC,GAaAC,GAlqBbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KAuBMvB,GAAiB,CAACwB,EAAkBC,IAAuC,CAK/E,GAJAD,EAAO,MAAOE,GAAUA,EAAQ,IAAM,IAAM,CAClB,MAAM,IAAI,MAAM,oDAAoD,CACtE,EAAE,EAEtBF,EAAO,OAAS,GAClB,GAAIC,EAAW,OAAS,UACtB,GAAI,EAAED,EAAO,SAAW,GAAKA,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GACtGA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GACxDA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MACN;AAAA,oGACwF,UAErFC,EAAW,OAAS,SACzB,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,+DAA+D,EAIvF,EAEMvB,GAAe,CAACuB,EAA2BG,EAAyBC,IAA2B,CACnGD,EAAK,MAAOD,GAAUA,GAAS,GAAKA,EAAQE,IAAS,IAAM,CACnC,MAAM,IAAI,MAAM,qEAAqE,CACvF,EAAE,EACxB,IAAMC,EAAY,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAG,EAC1C,OAAAD,EAAK,QAAQ,CAACD,EAAOI,IAAUD,EAAUH,CAAK,EAAIF,EAAOM,CAAK,CAAC,EACxDD,CACT,EAEM3B,GACF,CAAC6B,EAA+BN,EAA8BO,EAAsBR,EACnFS,EAAiBC,IAAwB,CACxC,GAAM,CAACC,EAAeC,EAAkBC,CAAe,EAClDL,EAAe,GAAM,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,GAAKD,EAAO,OAAS,EAAK,EAAI,GAAI,EAAE,EACrEH,EAAOG,EAAO,CAAC,EAAE,KAAK,OAC5B,GAAII,EAAgB,GAAKJ,EAAO,OAASI,GAAiBJ,EAAOI,CAAa,EAAE,KAAK,OAAS,EAC5FJ,EAAOI,CAAa,EAAE,gBAAgB,EAAE,QAAST,GAAUQ,EAAI,KAAKR,CAAK,CAAC,UAEjED,EAAW,0BAA4B,qBAChD,MAAM,IAAI,MAAM,2FAA2F,EAG7G,GAAIW,EAAmB,GAAKL,EAAO,OAASK,GAAoBL,EAAOK,CAAgB,EAAE,KAAK,OAAS,EAAG,CAExG,GADAL,EAAOK,CAAgB,EAAE,gBAAgB,EAAE,QAASV,GAAUF,EAAO,KAAKE,CAAK,CAAC,EAC5EF,EAAO,SAAW,GACjBA,EAAO,SAAWI,GAASI,GAAgB,IAAMR,EAAO,SAAWC,EAAW,KAAK,OACtF,MAAM,IAAI,MACN,6FAA6F,EAEnGzB,GAAewB,EAAQC,CAAU,EAC7BA,EAAW,KAAK,OAAS,GAC3BxB,GAAauB,EAAQC,EAAW,KAAMG,CAAI,EAAE,QAAQ,CAACF,EAAOI,IAAUN,EAAOM,CAAK,EAAIJ,CAAK,CAE/F,CACA,GAAIW,EAAkB,GAAKN,EAAO,OAASM,IACzCN,EAAOM,CAAe,EAAE,iBAAiB,EAAE,QAASX,GAAUO,EAAM,KAAK,OAAOP,CAAK,CAAC,CAAC,EACnFO,EAAM,SAAWL,GAASI,GAAgB,IAAMC,EAAM,SAAWR,EAAW,KAAK,QACnF,MAAM,IAAI,MAAM,4FAA4F,EAIhH,GAAIA,EAAW,KAAK,OAAS,EAAG,CAC9B,GAAID,EAAO,SAAWC,EAAW,KAAK,OACpC,MAAM,IAAI,MAAM,0FAA0F,EAE5G,GAAIQ,EAAM,SAAWR,EAAW,KAAK,OACnC,MAAM,IAAI,MACN,8FAA8F,CAEtG,CACA,GAAI,OAAOD,EAAW,KAAe,OAAOS,EAAU,KAAeT,EAAO,OAAS,GAAKS,EAAM,OAASL,EACvG,MAAM,IAAI,MAAM,yDAAyD,CAE7E,EAEEzB,GACF,CAACmC,EAAiDC,IAC9C,wEAAwEA,CAAK;AAAA,sCAC/CA,CAAK,aAAaA,CAAK,QAAQA,CAAK,OACrE,IAAM,CACD,OAAQD,EAAwB,CAC9B,IAAK,aACH,MAAO,UAAUC,CAAK,uBACxB,IAAK,qBACH,MAAO;AAAA,8BACSA,CAAK;AAAA;AAAA;AAAA,qBAIvB,IAAK,uBACH,MAAO,WAAWA,CAAK,8BACzB,IAAK,gBACH,MAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAMaA,CAAK;AAAA;AAAA,0BAEbA,CAAK,6DAA6DA,CAAK;AAAA;AAAA,qBAGrF,IAAK,qBACH,MAAO;AAAA,wCACmBA,CAAK;AAAA,2BAClBA,CAAK,sCAAsCA,CAAK;AAAA,0BACjDA,CAAK;AAAA;AAAA,yDAE0BA,CAAK;AAAA,qBAElD,IAAK,uBACH,MAAO,gCAAgCA,CAAK;AAAA,uCACnBA,CAAK;AAAA,mCACTA,CAAK;AAAA;AAAA,sCAEFA,CAAK,qCAC/B,IAAK,aACH,MAAO,YAAYA,CAAK,qCAC1B,QACE,MAAM,IAAI,MAAM,6BAA6BD,CAAsB,mBAAmB,CAC1F,CACF,GAAG,EACP,IAEElC,GAA8B,CAACoC,EAA0BR,EAAsBO,IACjF,6CAA6CA,CAAK,4BAA4BA,CAAK,MAAQ,IAAM,CAC/F,OAAQC,EAAa,CACnB,IAAK,oBACH,MAAO,yIAKT,IAAK,QACH,MAAO,2BACT,IAAK,OACH,MAAO,0BACT,IAAK,qBACH,MAAO,0KAKT,IAAK,SACL,QACE,GAAIR,EAAe,GACjB,MAAO,mLAOT,MAAM,IAAI,MAAM,gBAAgBQ,CAAW,mBAAmB,CAClE,CACF,GAAG,EACH,IAEEnC,GAAY,CAAC6B,EAAwBP,EAAyBC,IAA2B,CAC7F,IAAMa,EAAS,IAAI,MAAMb,CAAI,EAAE,KAAK,CAAC,EAAE,OAAO,IAAI,MAAMA,CAAI,EAAE,KAAK,CAAC,CAAC,EAC/Dc,EAAWR,EAAI,SAAW,EAAIO,EAASP,EAAI,MAAM,EACvD,OAAIP,EAAK,OAAS,GAChBA,EAAK,QAAQ,CAACgB,EAAGC,IAAM,CACrBH,EAAOE,CAAC,EAAID,EAASE,CAAC,EACtBH,EAAOG,EAAIhB,CAAI,EAAIc,EAASf,EAAK,OAASiB,CAAC,CAC7C,CAAC,EACMH,GAEFC,CACT,EAEMpC,GACF,CAACuC,EAA+BrB,EAA2BS,EAA0BN,IACrE,CACV,IAAImB,EAAwB,CAAC,EAC7B,GAAIb,EAAM,OAAS,EACjB,GAAIN,EAAK,OAAS,EAAG,CAEnB,GADAkB,EAAW,QAASF,GAAMG,EAAY,KAAKH,CAAC,CAAC,EACzC,KAAK,IAAI,GAAGhB,CAAI,EAAIkB,EAAW,OACjC,MAAM,IAAI,MAAM,sBAAsB,EAExClB,EAAK,QAAQ,CAACgB,EAAGC,IAAME,EAAYH,CAAC,EAAIV,EAAMW,CAAC,CAAC,CAClD,MACEX,EAAM,QAASU,GAAMG,EAAY,KAAKH,CAAC,CAAC,MAErC,CACL,GAAInB,EAAO,SAAW,EACpB,MAAM,IAAI,MAAM,yCAAyC,EAEzDsB,EAAcD,EAAW,IAAI,CAACnB,EAAOI,IAAU,KAAK,MAAMJ,EAAQF,EAAOM,CAAK,CAAC,CAAC,CAEpF,CACA,OAAOgB,CACT,EAEFvC,GAAoB,CAACsC,EAA+BrB,EAAkBC,IAAiC,CAC3G,IAAMsB,GAAiB,IAAM,CAC3B,OAAQtB,EAAW,sBAAuB,CACxC,IAAK,aACH,OAAOA,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAImB,GAAKpB,EAAOoB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGpB,EAAQ,OAAO,SAAS,EAC1E,IAAK,cACH,OAAOC,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAImB,GAAKpB,EAAOoB,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGpB,EAAQ,OAAO,SAAS,EAC1E,QACE,MAAM,IAAI,MAAM,4BAA4BC,EAAW,qBAAqB,mBAAmB,CACnG,CACF,GAAG,EACHD,EAAO,KAAK,EAAK,EAAGA,EAAO,MAAM,EACjC,IAAMwB,EAAsBH,EAAW,MAAM,EAC7C,OAAIpB,EAAW,KAAK,OAAS,GAC3BA,EAAW,KAAK,QAASkB,GAAMnB,EAAOmB,CAAC,EAAII,CAAa,EACxDtB,EAAW,KAAK,QAASkB,GAAMK,EAAoBL,CAAC,EAAI,KAAK,MAAME,EAAWF,CAAC,EAAInB,EAAOmB,CAAC,CAAC,CAAC,IAE7FnB,EAAO,KAAKuB,EAAe,EAAGvB,EAAO,MAAM,EAC3CwB,EAAoB,QAAQ,CAACL,EAAGC,IAAMI,EAAoBJ,CAAC,EAAI,KAAK,MAAMD,EAAInB,EAAOoB,CAAC,CAAC,CAAC,GAEnFI,CACT,EAEMxC,GACF,CAACyC,EAAuBJ,EAA+BC,EAAgCI,EACtFC,IAA8B;AAAA,mEACgCF,EAAO,KAAK,OAAO,cAC9EA,EAAO,KAAK,KAAK,KAAKH,EAAY,MAAM;AAAA,oCACZG,EAAO,KAAK,KAAK,KAAKH,EAAY,MAAM;AAAA,gCAC5CA,EAAY,MAAM;AAAA,6BACrBG,EAAO,WAAW,iBAAkB,GAAG,CAAC;AAAA,sBAC/CG,GAAa,kBAAmB,IAAKF,CAAY,CAAC;AAAA,wBAChDE,GAAa,eAAgB,IAAKD,CAAS,CAAC;AAAA,uBAC7CC,GAAa,eAAgB,OAAOP,EAAW,MAAM,GAAIM,CAAS,CAAC;AAAA;AAAA,kCAExDF,EAAO,KAAK,KAAK;AAAA;AAAA,gCAEnBG,GAAa,uBAAwB,IAAKP,EAAW,MAAM,CAAC;AAAA,iCAC3DO,GAAa,wBAAyB,IAAKN,EAAY,MAAM,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAQzFrC,GACF,CAAC4C,EAAsBJ,EAAuBJ,EAA+BC,EAC5EI,EAAsBC,EAAmBG,IAAsC;AAAA,gEACpBL,EAAO,KAAK,OAAO,QAAQI,EAAM,KAAK,OAAO;AAAA,2BAClFA,EAAM,KAAK,OAAO;AAAA,gCACbP,EAAY,MAAM;AAAA,6BACrBG,EAAO,WAAW,iBAAkB,GAAG,CAAC;AAAA;AAAA,sBAE/CG,GAAa,kBAAmB,IAAKF,CAAY,CAAC;AAAA;AAAA;AAAA;AAAA,0BAI9CE,GAAa,eAAgB,IAAKD,CAAS,CAAC;AAAA,yBAC7CC,GAAa,eAAgB,OAAOP,EAAW,MAAM,GAAIM,CAAS,CAAC;AAAA,gCAC5DC,GAAa,uBAAwB,IAAKP,EAAW,MAAM,CAAC;AAAA,iCAC3DO,GAAa,wBAAyB,IAAKN,EAAY,MAAM,CAAC;AAAA;AAAA;AAAA,iBAG9EQ,CAAgB,4CAA4CL,EAAO,KAAK,KAAK;AAAA;AAAA;AAAA,wCAGtDA,EAAO,KAAK,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAS/CI,EAAM,WAAW,gBAAiB,IAAK,cAAc,CAAC;AAAA;AAAA;AAAA,OAI1D3C,GAAoB,CAAC2C,EAAsBR,IAA0C;AAAA,0CACjDQ,EAAM,KAAK,OAAO;AAAA,gCAC5BR,EAAW,MAAM;AAAA,4BACrBQ,EAAM,WAAW,gBAAiB,GAAG,CAAC;AAAA,gDAClBD,GAAa,uBAAwB,IAAKP,EAAW,MAAM,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,OAOtGlC,GACF,CAAC0C,EAAsBE,EAAoBC,EAAkBC,IACzDJ,EAAM,KAAOI,EAAc;AAAA,MAC7BJ,EAAM,WAAW,gBAAiBE,EAAY,SAAS,CAAC;AAAA,MACxDF,EAAM,WAAW,gBAAiBG,EAAU,OAAO,CAAC;AAAA,EAEvB,GAE7B5C,GACF,CAACyC,EAAsBJ,EAAuBJ,EAA+BS,EAC5EI,IAAuC,CAEtC,GAAM,CAACF,EAAUG,EAAWC,EAAUL,CAAU,EAC5CV,EAAW,SAAW,EAAI,CAAC,GAAI,EAAG,EAAG,EAAE,EAAc,CAAC,EAAG,EAAG,EAAG,CAAC,EAC9DN,EAAQc,EAAM,KAAK,MACzB,MAAO;AAAA,wEAC2Dd,CAAK;AAAA,2BAClDc,EAAM,KAAK,OAAO;AAAA,QACrCA,EAAM,WAAW,gBAAiBM,EAAW,mBAAmBd,EAAWc,CAAS,CAAC,QAAQ,CAAC;AAAA,QAC9FN,EAAM,WAAW,gBAAiBO,EAAU,mBAAmBf,EAAWe,CAAQ,CAAC,QAAQ,CAAC;AAAA,QAC5FjD,GAA0B0C,EAAOE,EAAYC,EAAU,CAAC,CAAC;AAAA,eAClDH,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA;AAAA,+CAGHJ,EAAO,KAAK,OAAO,QAAQV,CAAK;AAAA;AAAA,gBAE/DA,CAAK,sBAAsBoB,CAAS;AAAA,gBACpCpB,CAAK,sBAAsBqB,CAAQ;AAAA,QAEzCN,EACI,yBAAyBT,EAAWc,CAAS,CAAC,8BAA8Bd,EAAWe,CAAQ,CAAC;AAAA,iBAC7FF,CAAkB;AAAA,SAErB,EAAE;AAAA,8BACcb,EAAWc,CAAS,CAAC;AAAA,8BACrBd,EAAWe,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,2BAKvBf,EAAW,OAAS,EAAI,uBAAuBU,CAAU,KAAO,GAAG;AAAA,0BACpEV,EAAW,OAAS,EAAI,uBAAuBW,CAAQ,KAAO,GAAG;AAAA,iBAC1EjB,CAAK;AAAA,iBACLA,CAAK;AAAA,iBACLA,CAAK;AAAA,iBACLA,CAAK;AAAA,iBACLA,CAAK,gBAAgBA,CAAK;AAAA,iBAC1BA,CAAK,UAAUA,CAAK;AAAA,iBACpBA,CAAK,gBAAgBA,CAAK;AAAA,iBAC1BA,CAAK,UAAUA,CAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAWjC,EAEE1B,GACF,CAACwC,EAAsBJ,EAAuBJ,EAA+BC,EAC5EtB,EAA2BU,EAAwB2B,EAAqBP,EACxEI,EAA4BI,IAAoC,CAC/D,IAAMC,EAAOlB,EAAW,SAAW,EAC7BmB,EAAS,GACT,CAACL,EAAWC,CAAQ,EAAIG,EAAO,CAAC,EAAG,CAAC,EAAIC,EAAS,CAAC,EAAG,CAAC,EAAI,CAAC,EAAG,CAAC,EAC/DzB,EAAQc,EAAM,KAAK,MACnBY,EAAoCC,GAAwB,CAChE,IAAMC,EAAYD,IAAQP,EAAY,MAAQ,MAC9C,MAAO;AAAA,WACJQ,CAAS,qCAAqCd,EAAM,KAAK,OAAO,qBAC/DJ,EAAO,KAAK,OAAO,QAAQV,CAAK;AAAA,6BACfU,EAAO,WAAW,iBAAkBiB,CAAG,CAAC;AAAA,2BAC1C3B,CAAK,+DAA+Df,EAAO0C,CAAG,CAAC;AAAA,UAChGpB,EAAYoB,CAAG,CAAC,KAAKrB,EAAWqB,CAAG,CAAC,KAAKhC,EAAIgC,CAAG,CAAC,KAAKhC,EAAIgC,CAAG,CAAC,MAAMrB,EAAW,MAAM;AAAA,gCAC/DN,CAAK;AAAA;AAAA;AAAA,cAGvBe,CAAgB,0CAA0CT,EAAWqB,CAAG,CAAC;AAAA,mBACpER,CAAkB;AAAA;AAAA,0BAEXnB,CAAK,gBAAgBA,CAAK;AAAA;AAAA,gBAEpC4B,CAAS,KAAK5B,CAAK,oBAAoBA,CAAK;AAAA,gBAC5C4B,CAAS,WAAWA,CAAS,OAAOtB,EAAWqB,CAAG,CAAC;AAAA,eACpD,IACDJ,EACK;AAAA,mCAEER,EACF,UAAUI,CAAkB,IAE5B,GAAGS,CAAS,iBAAiBA,CAAS,KAAKtB,EAAWqB,CAAG,CAAC,WAElE,CAAC;AAAA;AAAA,kCAEsBb,EAAM,KAAK,OAAO;AAAA,YACxCA,EAAM,WAAW,qBAAsBa,EAAK,OAAOC,CAAS,GAAG,CAAC;AAAA,0BAEhED,IAAQP,EAAYN,EAAM,aAAa,oBAAoB,EACvC,2DAA2D;AAAA;AAAA;AAAA,QAIrF,EAEA,MAAO;AAAA,MACPY,EAAiCN,CAAS,CAAC;AAAA,MAC3CM,EAAiCL,CAAQ,CAAC;AAAA,qCACXrB,CAAK,cAAcA,CAAK;AAAA;AAAA,wBAErCA,CAAK,gBAAgBA,CAAK;AAAA,wBAC1BA,CAAK;AAAA,wBACLA,CAAK;AAAA,uBACNA,CAAK;AAAA,oBACRsB,CAAW,wBAAwBA,CAAW,yBACxDA,CAAW,yBAAyBA,CAAW;AAAA,oBACrCA,CAAW,mBAAmBA,CAAW;AAAA,oBACzCA,CAAW,2BAA2BA,CAAW;AAAA,oBACjDA,CAAW,yBAAyBA,CAAW,0BACzDA,CAAW,0BAA0BA,CAAW;AAAA;AAAA;AAAA;AAAA,qCAIrBtB,CAAK,sBAAsBA,CAAK,YAAYA,CAAK;AAAA,oBAClEA,CAAK;AAAA;AAAA;AAAA;AAAA,4CAImBU,EAAO,KAAK,OAAO,QAAQV,CAAK;AAAA,yBACnDc,EAAM,KAAK,OAAO;AAAA;AAAA;AAAA,KAIvC,EAEEvC,GACF,CAACuC,EAAsBJ,EAAuBJ,EAA+BS,EAC5EI,IAAuC,CAEtC,GAAM,CAACF,EAAUY,EAAUT,EAAWC,EAAUL,CAAU,EACtDV,EAAW,SAAW,EAAI,CAAC,GAAI,EAAG,EAAG,EAAG,EAAE,EAAc,CAAC,EAAG,EAAG,EAAG,EAAG,CAAC,EACpEN,EAAQc,EAAM,KAAK,MACzB,MAAO;AAAA,wFAC2Ed,CAAK;AAAA,2BAClEc,EAAM,KAAK,OAAO;AAAA,QACrCA,EAAM,WAAW,gBAAiBe,EAAU,qBAAqBvB,EAAWuB,CAAQ,CAAC,QAAQ,CAAC;AAAA,QAC9Ff,EAAM,WAAW,gBAAiBM,EAAW,sBAAsBd,EAAWc,CAAS,CAAC,QAAQ,CAAC;AAAA,QACjGN,EAAM,WAAW,gBAAiBO,EAAU,qBAAqBf,EAAWe,CAAQ,CAAC,QAAQ,CAAC;AAAA,QAC9FjD,GAA0B0C,EAAOE,EAAYC,EAAU,CAAC,CAAC;AAAA,eAClDH,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA;AAAA,gDAGFJ,EAAO,KAAK,OAAO,QAAQV,CAAK;AAAA;AAAA,kBAE9DA,CAAK,sBAAsB6B,CAAQ;AAAA,mBAClC7B,CAAK,sBAAsBoB,CAAS;AAAA,kBACrCpB,CAAK,sBAAsBqB,CAAQ;AAAA,QAE3CN,EAAmB,6BAA6BT,EAAWuB,CAAQ,CAAC,oCAC7CvB,EAAWc,CAAS,CAAC,kCAAkCd,EAAWe,CAAQ,CAAC;AAAA,eAC7FF,CAAkB;AAAA,WAEJ,EAAE;AAAA;AAAA,gCAECb,EAAWuB,CAAQ,CAAC;AAAA,oCAChBvB,EAAWc,CAAS,CAAC;AAAA,kCACvBd,EAAWe,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAO3Bf,EAAW,OAAS,EAAI,uBAAuBU,CAAU,KAAO,GAAG;AAAA,0BACpEV,EAAW,OAAS,EAAI,uBAAuBW,CAAQ,KAAO,GAAG;AAAA;AAAA,kBAEzEjB,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,kBACLA,CAAK;AAAA,iBACNA,CAAK,kBAAkBA,CAAK;AAAA,iBAC5BA,CAAK,UAAUA,CAAK;AAAA,iBACpBA,CAAK,mBAAmBA,CAAK;AAAA,iBAC7BA,CAAK,UAAUA,CAAK;AAAA,iBACpBA,CAAK,kBAAkBA,CAAK;AAAA,iBAC5BA,CAAK,UAAUA,CAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAgBjC,EAEExB,GACF,CAACsD,EAAyB5C,EAA8BO,EAAsBsC,EAC7ErC,EAA0BsC,IAA6C,CACtE,IAAM1B,EAAawB,EAAY,KACzBnC,EAAM7B,GAAUkE,EAAU9C,EAAW,KAAMoB,EAAW,MAAM,EAE9DC,EAAcxC,GAAgBuC,EAAYyB,EAAarC,EAAOR,EAAW,IAAI,EAC7ED,EAAS8C,EAAY,MAAM,EAC3BA,EAAY,SAAW,IACzB9C,EAASqB,EAAW,IAAI,CAACnB,EAAOI,IAAUJ,IAAU,EAAI,EAAMoB,EAAYhB,CAAK,EAAIJ,CAAK,EACpFD,EAAW,wBAA0B,YACvCqB,EAAcvC,GAAkBsC,EAAYrB,EAAQC,CAAU,IAGlE,IAAMwB,EAASuB,EAAe,SAAUH,EAAY,SAAUvB,EAAY,MAAM,EAC1EO,EAAQoB,EAAc,QAASJ,EAAY,SAAUxB,EAAW,MAAM,EACtE6B,EAAaC,EAAU,KAAK7B,CAAW,EACvC8B,EAAU/B,EAAW,SAAWC,EAAY,QAAUD,EAAW,MAAM,CAACgC,EAAGjC,IAAMiC,IAAM/B,EAAYF,CAAC,CAAC,EACrGU,EAAmB7B,EAAW,0BAA4B,qBAC1DiC,EAAqBjC,EAAW,mBAChCqD,EAAWzB,EAAM,KAAK,MACtB0B,EAAmBC,GAA+B;AAAA,QACtDJ,EAAU,GAAK;AAAA,QACfzE,GAA2CsB,EAAW,wBAAyBqD,CAAQ,CAAC;AAAA,SACvF,IAAM,CACP,OAAQrD,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA,gBACHf,GAAkB2C,EAAOR,CAAU,CAAC;AAAA,gBACpCzC,GAA4BqB,EAAW,YAAaO,EAAc8C,CAAQ,CAAC;AAAA,gBAE3ErE,GACI4C,EAAOJ,EAAQJ,EAAYC,EAAatB,EAAO,OAAQU,EAAI,OAAQoB,CAAgB,CAAC;AAAA,gBAE9F,IAAK,SACH,MAAO;AAAA,gBACH9C,GAA0CyC,EAAQJ,EAAYC,EAAatB,EAAO,OAAQU,EAAI,MAAM,CAAC;AAAA,iBACpG,IAAM,CACT,GAAIW,EAAW,SAAW,GAAKA,EAAW,SAAW,EACnD,MAAO,GAAGjC,GAAsByC,EAAOJ,EAAQJ,EAAYS,EAAkBI,CAAkB,CAAC,GAC3F,GAAIb,EAAW,SAAW,GAAKA,EAAW,SAAW,EAC1D,MAAO,GAAG/B,GAAuBuC,EAAOJ,EAAQJ,EAAYS,EAAkBI,CAAkB,CAAC,GAEjG,MAAM,MAAM,kFAAkF,CAElG,GAAG,CAAC;AAAA,cAEN,IAAK,QACH,MAAO;AAAA,eACJ,IAAM,CACP,GAAIb,EAAW,SAAW,GAAKA,EAAW,SAAW,EACnD,MAAO,GACHhC,GACIwC,EAAOJ,EAAQJ,EAAYC,EAAatB,EAAQU,EAAKT,EAAW,YAAa6B,EAC7E7B,EAAW,mBAAoBA,EAAW,cAAc,CAAC,GAEjE,MAAM,MAAM,2EAA2E,CAE3F,GAAG,CAAC;AAAA,cAEN,QACE,MAAM,MAAM,qBAAqB,CACrC,CACF,GAAG,CAAC;AAAA,OACH;AAAA,QAEGuD,EAAa,gBAAgB,cAAe,KAAK,EAC5C,gBAAgB,SAAU,MAAOxD,EAAO,MAAM,EAC9C,gBAAgB,MAAO,MAAOU,EAAI,MAAM,EACxC,iBAAiBmB,EAAOJ,CAAM,CAAC;AAAA,QACtC+B,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,UAC1EJ,EAAU,0CAA4C;AAAA,+BACjC3B,EAAO,gBAAgB,YAAY,CAAC;AAAA,6BACtCI,EAAM,KAAK,OAAO;AAAA,WACpC,IAAM,CACT,OAAQ5B,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA;AAAA,yCAEsB4B,EAAM,aAAa,eAAe,CAAC;AAAA;AAAA,yCAEnC5B,EAAW,kBAAkB;AAAA,mBAE5D,IAAK,SACH,MAAO,wBACFoB,EAAW,SAAW,GAAKA,EAAW,SAAW,EAAK,wBACA,wBAAwB,oBACrF,IAAK,QACH,MAAO,6DACT,QACE,MAAM,MAAM,4BAA4BpB,EAAW,IAAI,EAAE,CAC7D,CACF,GAAG,CAAC;AAAA,CACT;AAAA,SAGK,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM,GAAGA,EAAW,QAAQ,IAAIO,CAAY,IAAIR,EAAO,OAAS,EAAIA,EAAS,EAAE,IAC3ES,EAAM,OAAS,EAAIA,EAAQ,EAAE,IAAIC,EAAI,OAAS,EAAIA,EAAM,EAAE,IAAI0C,CAAO,IAAI/B,CAAU,GACvF,kBAAmB,CAAC,MAAM,CAC5B,EACA,gBAAAkC,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMjC,EAAa,SAAUuB,EAAY,QAAQ,CAAC,EAC7D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,EAClE,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAMA,CAAU,EACjC,CAAC,KAAM,UAAW,KAAMlD,CAAM,EAC9B,CAAC,KAAM,UAAW,KAAMU,CAAG,EAC3B,GAAG+C,EAA2BpC,CAAU,EACxC,GAAGoC,EAA2BnC,CAAW,CAC3C,CACF,EACF,CACF,EAEE9B,GAAuCkE,GAAoC,CAC/E,IAAMC,EAAmBD,EAAQ,iBAGjC,OAF2B,IAAI,YAAYC,EAAkBA,EAAiB,WAAY,CAAC,EACnD,CAAC,CAE3C,EAEalE,GAAS,CAACiE,EAAyBzD,IAAuC,CACrF,IAAMD,EAAmB,CAAC,EACpBS,EAAkB,CAAC,EACnBC,EAAgB,CAAC,EACjBF,EAAehB,GAAoCkE,CAAO,EAChE,GAAIzD,EAAW,YAAc,EAC3B,MAAM,MAAM,6DAA6D,EAE3EvB,GAAegF,EAAQ,OAAQzD,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAC3EgD,EAAQ,QACJnE,GAAwBmE,EAAQ,OAAO,CAAC,EAAGzD,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC7G,EAEahB,GAAyBO,GAA0D,CAC9F,IAAM2D,EAAY3D,EAAW,UACvBE,EAAOF,EAAW,KAClB4D,EACF5D,EAAW,wBACToC,EAAcpC,EAAW,YACzBqC,EAAiBrC,EAAW,iBAA6B,EACzDiC,EAAqBjC,EAAW,mBAChC6D,EAA+C7D,EAAW,sBAC1D8D,EAAa9D,EAAW,KAExBe,EAA4Bf,EAAW,cAAgB,GAAK,SAAWA,EAAW,YACxF,OAAO+D,GAA4B,CACjC,UAAAJ,EACA,KAAAzD,EACA,wBAAA0D,EACA,YAAAxB,EACA,eAAAC,EACA,mBAAAJ,EACA,sBAAA4B,EACA,KAAAC,EACA,YAAA/C,CACF,CAAC,CACH,ICzrBA,IAeMiD,GAyDAC,GAyFOC,GAoBAC,GArLbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,IAAMC,EAAoBD,EAAO,CAAC,EAC5BE,EAAmBF,EAAO,CAAC,EAC3BG,EAAoBH,EAAO,CAAC,EAElC,GAAIC,EAAM,WAAaC,EAAK,UAAYD,EAAM,WAAaE,EAAM,SAC/D,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAIF,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAIC,EAAK,KAAK,SAAW,GAAKA,EAAK,KAAK,SAAW,EACjD,MAAM,IAAI,MAAM,uBAAuB,EAGzC,IAAME,EAAaH,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EAC7CI,EAAiBJ,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EACvD,GAAIC,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAME,EACtC,MAAM,IAAI,MAAM,8CAA8C,EAEhE,GAAIF,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMG,EACtC,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIF,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,IAAMC,EACxC,MAAM,IAAI,MAAM,+CAA+C,EAEjE,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBN,EAAO,CAAC,EACjC,GAAIM,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMF,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CAEA,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMO,EAAmBP,EAAO,CAAC,EACjC,GAAIO,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMH,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CACF,EAEMb,GACF,CAACS,EAA+BQ,EAAqCC,EAAqBC,IACvE,CACb,IAAMC,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAcH,EACdI,EAAaH,EACbR,EAAaO,EAAW,MAAM,EAAE,EAAE,CAAC,EACnCK,EAAmBN,EAAaC,EAAW,MAAM,EAAG,EAAE,EAAE,OAAO,CAAC,EAAI,CAAC,EACrEM,EAAejB,EAAO,OAAS,EAC/BkB,EAAelB,EAAO,OAAS,EAC/BmB,EAAgBT,GAAcD,EAAc,EAC5CW,EAAqBV,GAAcD,EAAc,EACjDY,EAA4BZ,EAAc,EAE1Ca,EAAaC,GAAiBnB,CAAU,EACxCoB,EAAY,CAChBC,EAAc,IAAKzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACjEG,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACpEG,EAAc,QAASzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CACvE,EACIL,GACFO,EAAU,KAAKC,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAElFJ,GACFM,EAAU,KAAKC,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAEtFE,EAAU,KAAKE,EAAe,SAAU1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAChFH,GACFK,EAAU,KAAKE,EAAe,eAA8BV,CAAgB,CAAC,EAE3EI,GACFI,EAAU,KAAKE,EAAe,iBAAgCV,CAAgB,CAAC,EAE7EK,GACFG,EAAU,KAAKE,EAAe,mBAAoB1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAEhG,IAAMK,EAAWC,GAA4B5B,EAAO,CAAC,EAAE,QAAQ,EACzD6B,EAAmBC,GAA+B;AAAA,gCAClC1B,CAAU;AAAA,0CACAA,EAAakB,CAAU;AAAA,6BACpCd,EAAW,OAAO;AAAA;AAAA,QAEvCsB,EAAa,iBAAiB,GAAGN,CAAS,CAAC;AAAA;AAAA,QAE3CM,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCf,EAAaX,CAAU,CAAC;AAAA;AAAA,oBAEjE2B,GAAW,MAAOT,CAAU,CAAC;AAAA,0BACvBS,GAAW,MAAOT,CAAU,CAAC;AAAA;AAAA;AAAA,4BAG3BJ,EAAe,UAAY,KAAK;AAAA;AAAA;AAAA,YAGhDG,EAA4B,wCAA0C,EAAE;AAAA;AAAA,2BAEzDW,GAAUL,EAAUL,EAAY,OAAO,CAAC;AAAA;AAAA;AAAA;AAAA,qBAI9CW,GAAU,MAAOX,CAAU,CAAC;AAAA,8BACnBW,GAAU,YAAaX,CAAU,CAAC;AAAA,UACtDH,EAAgB,iCAAmC,EAAE;AAAA,UACrDC,EAAqB,6CAA+C,EAAE;AAAA;AAAA,uDAEzBO,CAAQ,aAAaA,CAAQ;AAAA,eACrEV,EAAe,UAAY,KAAK;AAAA;AAAA,SAG/BiB,EAAU,CAAC,CAAC,KAAMpB,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIS,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMvB,EAAY,SAAUX,EAAO,CAAC,EAAE,QAAQ,CAAC,EAGxD,CACL,KAAM,yBACN,YAAa,CAAC,KAAMQ,EAAW,QAAQ,EACvC,gBAAAqB,EACA,WAAY,KAAO,CAAC,QAAAK,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKnB,EAAaX,EAAa,EAAE,CAAC,CAAC,EAC1F,CACF,EAEKZ,GAAgB,CAAC2C,EAAyB3B,IAA8C,CAGnGlB,GAAe6C,EAAQ,MAAM,EAG7B,IAAMD,EAAU,CAAC,CAAC,EACdC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAK,CAAC,EAEhBC,EAAQ,QACJ5C,GAA+B4C,EAAQ,OAAQ3B,EAAY2B,EAAQ,YAAa,EAAU,EAAG,CAAC,QAAAD,CAAO,CAAC,CAC5G,EAEazC,GAAgCe,GAAiE,CAC5G,IAAM4B,EAAU5B,EAAW,QAC3B,OAAO6B,GAA4B,CAAC,QAAAD,CAAO,CAAC,CAC9C,ICxLA,IAiBME,GAkBAC,GAcAC,GAeAC,GAcAC,GAsBAC,GAmFOC,GAYAC,GAnMbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAQMb,GAAiB,CAACc,EAA+BC,IAAsC,CAC3F,GAAI,CAACD,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIC,EAAW,KAAK,SAAW,GAC7B,GAAIA,EAAW,KAAK,SAAWA,EAAW,OAAO,QAAUA,EAAW,KAAK,SAAWA,EAAW,KAAK,OACpG,MAAM,IAAI,MAAM,iDAAiD,UAE1DA,EAAW,OAAO,SAAWA,EAAW,KAAK,OACtD,MAAM,IAAI,MAAM,2CAA2C,EAE7DD,EAAO,MAAM,CAAC,EAAE,QAAQ,CAACE,EAAGC,IAAQ,CAClC,GAAIH,EAAOG,EAAM,CAAC,EAAE,WAAa,GAAkBH,EAAOG,EAAM,CAAC,EAAE,WAAa,EAC9E,MAAM,IAAI,MAAM,SAASA,CAAG,qCAAqC,CAErE,CAAC,CACH,EAEMhB,GAAY,CAACa,EAA+BG,IAA0B,CAC1E,IAAMC,EAAkB,CAAC,EACzB,GAAIJ,EAAO,OAASG,EAClB,GAAIH,EAAOG,CAAG,EAAE,WAAa,EAC3BH,EAAOG,CAAG,EAAE,iBAAiB,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,UACxDL,EAAOG,CAAG,EAAE,WAAa,EAClCH,EAAOG,CAAG,EAAE,cAAc,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,MAE9D,OAAM,IAAI,MAAM,SAASF,CAAG,qCAAqC,EAGrE,OAAOC,CACT,EAEMhB,GACF,CAACY,EAA+BC,IAAiD,CAC/E,GAAID,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBnB,GAAUa,EAAQ,CAAC,EACtCO,EAAiBpB,GAAUa,EAAQ,CAAC,EACtCQ,EAAiBrB,GAAUa,EAAQ,CAAC,EACxC,OAAIQ,EAAK,SAAW,IAClBA,EAAO,CAAC,GAAG,MAAMR,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,KAAK,CAAC,GAEzCS,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,KACE,QAAOP,CAEX,EAEEZ,GACF,CAACqB,EAAeC,EAAeC,EAA+BJ,EAAyBK,IACzE,CACR,IAAIC,EAAWJ,EAIf,OAHIA,EAAQ,IACVI,GAAYF,EAAWJ,EAAKG,CAAK,CAAC,GAEhCE,EAAMF,CAAK,EAAI,EACV,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,EAAI,CAAC,CAAC,EAE3D,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,CAAC,CAAC,CAElE,EAEFrB,GACF,CAACc,EAAsBW,EAAuBH,IAC1C,4CAA4CG,EAAO,KAAK,OAAO,QAAQX,EAAM,KAAK,OAAO;AAAA,+BAClEA,EAAM,KAAK,OAAO;AAAA;AAAA,yBAExBQ,EAAW,MAAM;AAAA,kCACRI,GAAa,uBAAwB,IAAKJ,EAAW,MAAM,CAAC;AAAA,4BAClEI,GAAa,iBAAkB,IAAKJ,EAAW,MAAM,CAAC;AAAA,4BACtDI,GAAa,iBAAkB,IAAKJ,EAAW,MAAM,CAAC;AAAA,6BACrDI,GAAa,kBAAmB,IAAKJ,EAAW,MAAM,CAAC;AAAA,iCACnDG,EAAO,WAAW,iBAAkB,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAO3DX,EAAM,WAAW,gBAAiB,IAAK,aAAa,CAAC;AAAA;AAAA;AAAA,SAK7Db,GAAyB,CAACS,EAA+BC,IAA6C,CAC1G,IAAMW,EAAaZ,EAAO,CAAC,EAAE,KACvBiB,EAAYC,EAAU,KAAKN,CAAU,EACrCJ,EAAQP,EAAW,KAAK,OAAS,EAAKiB,EAAU,cAAcjB,EAAW,KAAMW,EAAW,MAAM,EAC1D,CAAC,GAAG,MAAMA,EAAW,MAAM,EAAE,KAAK,CAAC,EAC3EC,EAAQ1B,GAAUa,EAAQ,CAAC,EAC/Ba,EAAM,QAASM,GAASA,IAAS,IAAM,IAAM,CACnB,MAAM,IAAI,MAAM,kBAAkB,CACpC,EAAE,EACtBN,EAAM,SAAW,IACnBA,EAAQ,MAAML,EAAK,MAAM,EAAE,KAAK,CAAC,GAEnC,IAAMF,EAASL,EAAW,OAAO,IAAI,CAACmB,EAAOC,IAAMhC,GAAkB+B,EAAOC,EAAGT,EAAYJ,EAAMK,CAAK,CAAC,EAEjGN,EAAON,EAAW,KAAK,IAAI,CAACqB,EAAKD,IAAMhC,GAAkBiC,EAAKD,EAAGT,EAAYJ,EAAMK,CAAK,CAAC,EAE/F,GAAIL,EAAK,SAAWF,EAAO,QAAUE,EAAK,SAAWD,EAAK,OACxD,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIC,EAAK,SAAWI,EAAW,OAC7B,QAASS,EAAI,EAAGA,EAAIT,EAAW,OAAQ,EAAES,EAClCb,EAAK,SAASa,CAAC,IAClBf,EAAO,OAAOe,EAAG,EAAG,CAAC,EACrBd,EAAK,OAAOc,EAAG,EAAGT,EAAWS,CAAC,CAAC,EAC/BR,EAAM,OAAOQ,EAAG,EAAG,CAAC,GAI1B,IAAME,EAAQV,EAAM,IAAIM,GAAQ,KAAK,KAAKA,CAAI,CAAC,EAE/CN,EAAM,QAAQ,CAACM,EAAME,EAAGG,IAAU,CAChC,GAAIL,EAAO,EAAG,CACZ,IAAMM,GAAYlB,EAAKc,CAAC,EAAIf,EAAOe,CAAC,GAAKF,EACnCO,EAASpB,EAAOe,CAAC,EACjBM,EAAWD,EAASD,EAAWZ,EAAMQ,CAAC,EAC5Cf,EAAOe,CAAC,EAAIM,EACZpB,EAAKc,CAAC,EAAIK,EACVF,EAAMH,CAAC,EAAI,CAACF,CACd,CACF,CAAC,EAED,IAAMS,EAAchB,EAAW,MAAM,CAAC,EACtCJ,EAAK,QAAQ,CAACqB,EAAM3B,IAAM,CACxB0B,EAAYC,CAAI,EAAI,KAAK,MAAMtB,EAAKsB,CAAI,EAAIvB,EAAOuB,CAAI,GAAKhB,EAAMgB,CAAI,CAAC,CACzE,CAAC,EACD,IAAMC,EAA+B,CAAC,KAAMF,EAAa,SAAU5B,EAAO,CAAC,EAAE,QAAQ,EAE/Ee,EAASgB,EAAe,SAAU/B,EAAO,CAAC,EAAE,SAAU4B,EAAY,MAAM,EACxExB,EAAQ4B,EAAc,QAAShC,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,MAAM,EACxEiC,EAAaf,EAAU,KAAKU,CAAW,EACvCM,EAA8B,CAClC,CAAC,KAAM,aAAc,KAAM,KAAK,EAAG,CAAC,KAAM,SAAU,KAAM,MAAO,OAAQ5B,EAAO,MAAM,EACtF,CAAC,KAAM,QAAS,KAAM,MAAO,OAAQiB,EAAM,MAAM,EAAG,CAAC,KAAM,QAAS,KAAM,MAAO,OAAQV,EAAM,MAAM,CACvG,EAEMsB,EAAoC,CACxC,CAAC,KAAM,SAAU,KAAMF,CAAU,EAAG,CAAC,KAAM,SAAU,KAAM3B,CAAM,EAAG,CAAC,KAAM,QAAS,KAAMiB,CAAK,EAC/F,CAAC,KAAM,SAAU,KAAMV,CAAK,EAAG,GAAGuB,EAA2BpC,EAAO,CAAC,EAAE,IAAI,EAC3E,GAAGoC,EAA2BR,CAAW,CAC3C,EAEMS,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiBJ,CAAQ,EAAE,iBAAiB9B,EAAOW,CAAM,CAAC;AAAA,UACrEzB,GAA0Bc,EAAOW,EAAQH,CAAU,CAAC;AAAA,UACpD0B,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA,iCACpDvB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAEzDA,EAAO,YAAY,aAAcX,EAAM,aAAa,eAAe,CAAC,CAAC;AAAA,SAE/E,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,GAAGmB,EAAM,MAAM,IAAIjB,EAAO,MAAM,IAAIO,EAAM,MAAM,GAAI,kBAAmB,CAAC,MAAM,CAAC,EACnG,gBAAAwB,EACA,WAAY,KAAO,CACjB,QAAS,CAACP,CAAgB,EAC1B,cAAe,CAAC,EAAG,KAAK,KAAKb,EAAY,EAAuB,CAAC,EACjE,gBAAAkB,CACF,EACF,CACF,EAEa3C,GAAQ,CAAC+C,EAAyBtC,IAAsC,CACnFf,GAAeqD,EAAQ,OAAQtC,CAAU,EACzC,IAAMuC,EAAoBpD,GAAgCmD,EAAQ,OAAQtC,CAAU,EACpFsC,EAAQ,QAAQhD,GAAuBgD,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAO1F,EAEa/C,GAAwBQ,GAAyD,CAC5F,IAAMK,EAASL,EAAW,OACpBM,EAAON,EAAW,KAClBO,EAAOP,EAAW,KACxB,OAAOQ,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,ICxMA,IAcMiC,GAUAC,GAwHOC,GAKAC,GArJbC,GAAAC,EAAA,kBAQAC,KACAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,8BAA8B,CAElD,EAMMR,GAA2B,CAACS,EAAmBC,IAA+C,CAClG,IAAMC,EAAQF,EAAM,KACdG,EAAaC,EAAU,KAAKF,CAAK,EACjCG,EAAK,GACPC,EAAOL,EAAW,KAItB,GAHIK,EAAO,IACTA,EAAOJ,EAAM,OAASI,GAEpBA,EAAOJ,EAAM,OAAS,EACxB,MAAM,IAAI,MAAM,0CAA0C,EAG5D,IAAMK,EAAOL,EAAMI,CAAI,EACjBE,EAAOL,EAAaI,EACpBE,EAAaC,GAAiBH,CAAI,EAClCI,EAAaJ,EAAOE,EAEpBG,EAAY,CAACC,EAAcJ,IAC3BA,IAAe,EACV,WAAWI,CAAI,OAAOA,CAAI,YAAYA,CAAI,OAAOA,CAAI,OACnDJ,IAAe,EACjB,OAAOI,CAAI,OAAOA,CAAI,MACpBJ,IAAe,EACjB,WAAWI,CAAI,OAAOA,CAAI,QAAQA,CAAI,MAGxCA,EAEHC,EAAIC,EAAc,IAAKf,EAAM,SAAUA,EAAM,KAAMS,CAAU,EAC7DO,EAASC,EAAe,SAAUjB,EAAM,SAAUA,EAAM,KAAMS,CAAU,EACxES,EAAYJ,EAAE,KAAK,MAEnBK,EAAgBC,GAA4BpB,EAAM,QAAQ,IAAM,MAClE,mBAAmBkB,CAAS,oBAC5B,mBAAmBA,CAAS,eAC1BG,EAAmBC,GAA+B;AAAA,sCACpBJ,CAAS;AAAA,sCACTA,CAAS;AAAA,4CACHA,CAAS,KAAKb,CAAE;AAAA;AAAA,4DAEAa,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,gEAKLA,CAAS;AAAA;AAAA;AAAA;AAAA,QAIjEI,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBR,EAAGE,CAAM,CAAC;AAAA,QAC7EM,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA,qBAGXjB,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAMbc,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAmBID,CAAS,IAAIN,EAAU,kBAAmBH,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,0BAKtDS,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAeRA,CAAS,IAAIK,GAAU,kBAAmBd,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAU9E,MAAO,CACL,KAAM,UACN,YAAa,CAAC,KAAM,GAAGA,CAAU,GAAI,kBAAmB,CAAC,MAAM,CAAC,EAChE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMP,EAAO,SAAUF,EAAM,QAAQ,CAAC,EACjD,cAAe,CAAC,EAAGQ,CAAI,EACvB,gBAAiB,CAAC,CAAC,KAAM,SAAU,KAAMG,CAAU,CAAC,CACtD,GACA,gBAAAU,CACF,CACF,EAEa7B,GAAU,CAACgC,EAAyBvB,IAAwC,CACvFX,GAAekC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQjC,GAAyBiC,EAAQ,OAAO,CAAC,EAAGvB,CAAU,CAAC,CACzE,EAEaR,GAA0BQ,GACnCwB,GAA4B,CAAC,KAAMxB,EAAW,IAAc,CAAC,ICtJjE,IAgBMyB,GAMAC,GAWAC,GASAC,GAqBAC,GAwDOC,GAOAC,GA9HbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAQMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,CAEpC,EAEMX,GACF,CAACW,EAA+BC,IAAiD,CAC/E,IAAMC,EAAuB,CAAC,EAC1BC,EAAqBF,EAAW,WACpC,OAAID,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQI,GAAKF,EAAW,KAAK,OAAOE,CAAC,CAAC,CAAC,EACpED,EAAaD,EAAW,QAEnBG,GAA4B,CAAC,WAAAF,EAAY,KAAMF,EAAW,KAAM,WAAAC,CAAU,CAAC,CACpF,EAEEZ,GAA4BgB,GAAoC;AAAA;AAAA,gCAEtCA,CAAe;AAAA,kBAC7BC,GAAa,8BAA+B,IAAKD,CAAe,CAAC;AAAA;AAAA;AAAA;AAAA,aAItEA,CAAe;AAAA,GAEtBf,GAAuBiB,GAAsC,CACjE,IAAMF,EAAkBE,EAAQ,OAC1BC,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIJ,EAAiB,EAAEI,EAAG,CACxC,IAAMC,EAAgBH,EAAQE,CAAC,EAAE,aAAa,UAAW,mBAAmB,EACxEJ,IAAoB,EACtBG,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,wBAAwBC,CAAC,QAAQC,CAAa,IAAI,EACxDD,IAAMJ,EAAkB,EACjCG,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,6BAA6BC,CAAC,OAAOC,CAAa,IAAI,CAEzE,CACA,MAAO;AAAA,wDAC+CH,EAAQ,CAAC,EAAE,KAAK,OAAO;AAAA,UACrEC,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,QAE9B,EAEMjB,GAAyB,CAACQ,EAA+BC,IAA6C,CAC1G,IAAMW,EAAaZ,EAAO,CAAC,EAAE,KACvBa,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAWf,EAAO,CAAC,EAAE,SACrBgB,EAAOF,EAAU,cAAcb,EAAW,KAAMW,EAAW,MAAM,EACjEJ,EAAU,IAAI,MAAqBP,EAAW,UAAU,EACxDgB,EAAQC,EAAc,QAASH,EAAUH,CAAU,EACnDO,EAAkB,IAAI,MAAclB,EAAW,UAAU,EACzDmB,EAAkC,CAAC,EACnCC,EAA2B,CAAC,EAC9BC,EAAc,EACZC,EAAoC,CAAC,CAAC,KAAM,SAAU,KAAMV,CAAS,CAAC,EAC5E,QAASH,EAAI,EAAGA,EAAIT,EAAW,WAAYS,IAAK,CAC9CY,GAAerB,EAAW,WAAWS,CAAC,EACtCS,EAAgBT,CAAC,EAAIY,EACrB,IAAME,EAAcZ,EAAW,MAAM,EACrCY,EAAYvB,EAAW,IAAI,EAAIA,EAAW,WAAWS,CAAC,EACtDW,EAAa,KAAKG,CAAW,EAC7BhB,EAAQE,CAAC,EAAIe,EAAe,SAASf,CAAC,GAAIK,EAAUS,CAAW,EAC/DJ,EAAkB,KAAK,CAAC,KAAMC,EAAaX,CAAC,EAAG,SAAUV,EAAO,CAAC,EAAE,QAAQ,CAAC,CAC9E,CACAuB,EAAgB,KAAK,CAAC,KAAM,SAAU,KAAMJ,CAAe,CAAC,EAC5DI,EAAgB,KAAK,GAAGG,EAA2Bd,CAAU,CAAC,EAC9DS,EAAa,QAASG,GAAgBD,EAAgB,KAAK,GAAGG,EAA2BF,CAAW,CAAC,CAAC,EACtG,IAAMG,EAAmBC,GAA+B;AAAA,IAEpDA,EAAa,gBAAgB,aAAc,KAAK,EAC3C,gBAAgB,qBAAsB,MAAOT,EAAgB,MAAM,EACnE,iBAAiBF,EAAO,GAAGT,CAAO,CAAC;AAAA,IAC1ClB,GAAyB6B,EAAgB,MAAM,CAAC;AAAA,IAChD5B,GAAoBiB,CAAO,CAAC;AAAA;AAAA,IAE5BoB,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,oBAE3DX,EAAM,gBAAgB,YAAY,CAAC;AAAA,kBACrCA,EAAM,WAAW,UAAWD,CAAI,CAAC;AAAA;AAAA;AAAA,iBAGlCT,GAAa,8BAA+B,qBAAsBY,EAAgB,MAAM,CAAC;AAAA,QAClGF,EAAM,WAAW,UAAWD,EAAM,OAAO,CAAC;AAAA;AAAA;AAAA,KAIhD,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAMf,EAAW,SAAU,kBAAmB,CAAC,MAAM,CAAC,EACpE,gBAAA0B,EACA,WAAY,KAAO,CACjB,QAASP,EACT,cAAe,CAAC,EAAG,KAAK,KAAKP,EAAY,EAAuB,CAAC,EACjE,gBAAAU,CACF,EACF,CACF,EAEa9B,GAAQ,CAACoC,EAAyB5B,IAAsC,CACnFb,GAAeyC,EAAQ,MAAM,EAC7B,IAAMC,EACFD,EAAQ,OAAO,SAAW,EAAI5B,EAAaZ,GAAgCwC,EAAQ,OAAQ5B,CAAU,EACzG4B,EAAQ,QAAQrC,GAAuBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC1F,EAEapC,GAAwBO,GAAyD,CAC5F,IAAMe,EAAOf,EAAW,KAClBC,EAAuBD,EAAW,WAClCE,EAAaF,EAAW,WAAuB,EAAIC,EAAW,OAASD,EAAW,WACxF,GAAIE,IAAeD,EAAW,OAC5B,MAAM,IAAI,MAAM,+CAA+C,EAEjE,OAAOG,GAA4B,CAAC,KAAAW,EAAM,WAAAb,EAAY,WAAAD,CAAU,CAAC,CACnE,ICtIA,IAUM6B,GAIAC,GAyBAC,GAUOC,GAyCAC,GA1FbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMT,GAAcU,GAChB,MAAM,KAAKA,EAAkB,iBAAiB,EAAG,MAAM,EAGrDT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,CAAC,EAAE,WAAa,GAChEA,EAAO,CAAC,EAAE,WAAa,GACzB,MAAM,IAAI,MAAM,uDAAuD,EAGzE,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,oCAAoC,EAKtD,GAFmCX,GAAWW,EAAO,CAAC,CAAC,EAE3C,SAAWA,EAAO,CAAC,EAAE,KAAK,OACpC,MAAM,IAAI,MAAM,uFAAuF,CAE3G,EAEMT,GAAiB,CAACU,EAA+BC,IAAkD,CACvG,IAAMC,EAAwB,CAAC,EAE/B,QAASC,EAAI,EAAGA,EAAIH,EAAW,OAAQ,EAAEG,EACvCD,EAAY,KAAKF,EAAWG,CAAC,EAAIF,EAAQE,CAAC,CAAC,EAG7C,OAAOD,CACT,EAEaX,GAAyBQ,GAA+C,CACnF,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAA6Bb,GAAWW,EAAO,CAAC,CAAC,EACjDG,EAAcZ,GAAeU,EAAYC,CAAO,EAChDG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAAWP,EAAO,CAAC,EAAE,SACrBQ,EAAQC,EAAc,QAASF,EAAUN,EAAW,MAAM,EAC1DS,EAASC,EAAe,SAAUJ,EAAUJ,EAAY,MAAM,EAE9DS,EAAmBC,GAA+B;AAAA,2BAC/BL,EAAM,QAAQ,GAAGP,CAAU,CAAC;AAAA,QAC/CY,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,QAClFG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA,6BACrDH,EAAO,gBAAgB,YAAY,CAAC;AAAA,2BACtCF,EAAM,KAAK,OAAO;AAAA,4BACjBP,EAAW,MAAM;AAAA,4BACjBO,EAAM,WAAW,uBAAwB,GAAG,CAAC;AAAA,gCACzCE,EAAO,WAAW,iBAAkB,GAAG,CAAC;AAAA;AAAA,UAE9DF,EAAM,WAAW,gBAAiB,IAAK,iBAAiB,CAAC;AAAA;AAAA,QAE3DE,EAAO,YAAY,aAAcF,EAAM,aAAa,eAAe,CAAC,CAAC;AAAA,OAG3E,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAM,GAAGN,CAAO,GAAI,kBAAmB,CAAC,MAAM,CAAC,EAC7D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,EAClE,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAMA,CAAU,EAAG,GAAGS,EAA2Bd,EAAO,CAAC,EAAE,IAAI,EAChF,GAAGc,EAA2BX,CAAW,CAC3C,CACF,GACA,gBAAAS,CACF,CACF,EAEanB,GAAQsB,GAAkC,CACrDzB,GAAeyB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQvB,GAAsBuB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACtE,IC7FA,IAUMC,GA2DAC,GAqCOC,GA1GbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GACF,CAACQ,EAA4BC,EAA+BC,EAA+BC,EAC1FC,IAAuB,CACtB,IAAMC,EAASC,EAAe,cAAeF,EAAYF,EAAW,OAAQ,CAAC,EACvEK,EAAIC,EAAc,SAAUP,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ,CAAC,EACxEQ,EAAID,EAAc,SAAUP,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ,CAAC,EACxES,EAAIF,EAAc,SAAUP,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAK,OAAQ,CAAC,EAE1EU,EACEC,EAAa,CAACL,EAAWE,EAAWC,IAAc,UAAUD,CAAC,KAAKF,CAAC,KAAKG,CAAC,IAC/E,GAAI,CAACP,EACHQ,EAAaN,EAAO,YAChB,aACAO,EAAWL,EAAE,YAAY,YAAY,EAAGE,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAChG,CACL,IAAMG,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,EAAc,iBAAiBF,CAAC,gBAAgBA,CAAC,IACjDG,EAAc,iBAAiBH,CAAC,gBAAgBA,CAAC,IAEjDI,EAAc,sBAAsBJ,CAAC,OAAO,cAAiB,EAAIA,GAAK,CAAE,KAC9E,MAAO;AAAA,gCACeA,CAAC,MAAMV,EAAO,gBAAgB,qBAAqBU,CAAC,GAAG,CAAC;AAAA,0BAC9DA,CAAC,MAAMR,EAAE,2BAA2B,iBAAiBQ,CAAC,GAAIV,CAAM,CAAC;AAAA,0BACjEU,CAAC,MAAMN,EAAE,2BAA2B,iBAAiBM,CAAC,GAAIV,CAAM,CAAC;AAAA,0BACjEU,CAAC,MAAML,EAAE,2BAA2B,iBAAiBK,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAClEU,CAAC,cAAcA,CAAC;AAAA,yBAChBA,CAAC,cAAcA,CAAC;AAAA,yBAChBA,CAAC,cAAcA,CAAC;AAAA,6BACZA,CAAC,cAAcA,CAAC;AAAA,6BAChBA,CAAC,cAAcA,CAAC;AAAA,cAC/BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIJ,EAAWK,EAAaC,EAAaC,CAAW,CAAC;AAAA,WAErF,EACIf,IAAe,EACjBO,EAAa;AAAA;AAAA,cAETE,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,wGAGtCF,EAAa;AAAA,cACTE,EAAiB,0BAA2B,CAAC,CAAC;AAAA,cAC9CA,EAAiB,0BAA2B,CAAC,CAAC;AAAA,cAC9CA,EAAiB,0BAA2B,CAAC,CAAC;AAAA,cAC9CA,EAAiB,0BAA2B,CAAC,CAAC;AAAA,WAGtD,CAEA,MAAO;AAAA,UACHb,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBU,EAAGH,EAAGE,EAAGJ,CAAM,CAAC;AAAA,UACjFL,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,UACvEW,CAAU;AAAA,QAEhB,EAEElB,GAA4BQ,GAA+C,CAC/E,IAAMmB,EAAQnB,EAAO,CAAC,EAAE,KAClBoB,EAAQpB,EAAO,CAAC,EAAE,KAClBqB,EAAQrB,EAAO,CAAC,EAAE,KAClBsB,EAAiBtB,EAAO,CAAC,EAAE,SAE3BE,EAAc,EAAEqB,EAAU,SAASJ,EAAOC,CAAK,GAAKG,EAAU,SAASH,EAAOC,CAAK,GACrFG,EAAcL,EACdM,EAAaF,EAAU,KAAKJ,CAAK,EAC/BO,EAAU,KAAK,KAAKD,EAAa,CAAC,EAGxC,GAAIvB,EAAa,CACf,IAAMyB,EAAkBC,GAAc,UAAUA,GAAc,UAAUT,EAAOC,EAAO,EAAK,EAAIC,EAAO,EAAK,EAC3G,GAAI,CAACM,EACH,MAAM,IAAI,MAAM,6CAA8C,EAEhEH,EAAcG,EACdF,EAAaF,EAAU,KAAKC,CAAW,CACzC,CAEA,MAAO,CACL,KAAM,QACN,YAAa,CAAC,kBAAmB,CAAC,OAAQ,OAAQ,MAAM,CAAC,EACzD,gBAAkBzB,GACdR,GAA2BQ,EAAcC,EAAQwB,EAAatB,EAAaoB,CAAc,EAC7F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAME,EAAa,SAAUF,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,GAA0B,CAAgB,CAAC,EACrF,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAMC,CAAO,EAAG,GAAGG,EAA2BR,CAAK,EAAG,GAAGQ,EAA2BV,CAAK,EAC1G,GAAGU,EAA2BT,CAAK,EAAG,GAAGS,EAA2BL,CAAW,CACjF,CACF,EACF,CACF,EAEa/B,GAASqC,GAAkC,CACtDA,EAAQ,QAAQtC,GAAyBsC,EAAQ,MAAM,CAAC,CAC1D,IC5GA,IAyCaC,GAzCbC,GAAAC,EAAA,kBAGAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KAOalC,GAA+D,IAAI,IAAI,CAClF,CAAC,MAAO,CAAUmC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAwB,CAAC,EAC7C,CAAC,SAAU,CAACC,GAAQD,EAAwB,CAAC,EAC7C,CAAC,OAAQ,CAAUE,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,YAAa,CAACC,EAAS,CAAC,EAEzB,CAAC,cAAe,CAAMC,GAAkBC,EAA0B,CAAC,EACnE,CAAC,qBAAsB,CAACC,EAAS,CAAC,EAClC,CAAC,UAAW,CAACC,EAAO,CAAC,EACrB,CAAC,gBAAiB,CAACC,EAAa,CAAC,EACjC,CAAC,OAAQ,CAAUC,GAAeC,EAAmB,CAAC,EACtD,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,gBAAiB,CAACC,GAAeC,EAA4B,CAAC,EAC/D,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,MAAO,CAAUC,GAAcC,EAAoB,CAAC,EACrD,CAAC,QAAS,CAAWC,EAAK,CAAC,EAC3B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EACnB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,YAAa,CAACjB,GAAMC,EAAmB,CAAC,EACzC,CAAC,SAAU,CAACiB,GAAQC,EAAqB,CAAC,EAC1C,CAAC,iBAAkB,CAACC,GAAgBC,EAA6B,CAAC,EAClE,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,oBAAqB,CAAMC,GAAwBC,EAAgC,CAAC,EACrF,CAAC,gBAAiB,CAAMC,GAAoBC,EAA4B,CAAC,EACzE,CAAC,UAAW,CAAWC,EAAO,CAAC,EAC/B,CAAC,iBAAkB,CAAWC,EAAc,CAAC,EAC7C,CAAC,wBAAyB,CAACC,EAAY,CAAC,EACxC,CAAC,qBAAsB,CAACC,EAAS,CAAC,EAClC,CAAC,YAAa,CAAUC,GAAoBrB,EAAoB,CAAC,EACjE,CAAC,OAAQ,CAAWsB,EAAI,CAAC,EACzB,CAAC,cAAe,CAAWC,EAAW,CAAC,EACvC,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EAEnB,CAAC,UAAW,CAAMC,GAAcC,EAAsB,CAAC,EACvD,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,qBAAsB,CAACC,GAAoBC,EAAiC,CAAC,EAC9E,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAACC,EAAG,CAAC,EACb,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,QAAS,CAACC,EAAK,CAAC,EACjB,CAAC,aAAc,CAAUC,EAAU,CAAC,EACpC,CAAC,YAAa,CAACC,EAAS,CAAC,EACzB,CAAC,aAAc,CAACC,EAAU,CAAC,EAC3B,CAAC,YAAa,CAACC,EAAS,CAAC,EACzB,CAAC,YAAa,CAACC,EAAS,CAAC,EACzB,CAAC,aAAc,CAACC,EAAU,CAAC,EAC3B,CAAC,WAAY,CAACC,EAAQ,CAAC,EACvB,CAAC,WAAY,CAACC,EAAQ,CAAC,EACvB,CAAC,eAAgB,CAACC,EAAY,CAAC,EAC/B,CAAC,kBAAmB,CAACC,EAAe,CAAC,EACrC,CAAC,kBAAmB,CAACC,EAAe,CAAC,EACrC,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,UAAW,CAAUC,EAAO,CAAC,EAC9B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,yBAA0B,CAACC,GAAeC,EAA4B,CAAC,EACxE,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,UAAW,CAACC,GAASC,EAAsB,CAAC,EAC7C,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,kBAAmB,CAAUC,GAA0BjE,EAAoB,CAAC,EAC7E,CAAC,OAAQ,CAACkE,EAAI,CAAC,EACf,CAAC,YAAa,CAACC,GAAWC,EAAwB,CAAC,EACnD,CAAC,QAAS,CAACC,EAAK,CAAC,CACnB,CAAC,IChID,IAsBaC,GAtBbC,GAAAC,EAAA,kBAGAC,KAEAC,KAEAC,KAGAC,KAYaN,GAAN,KAAqB,CAI1B,YAAoBO,EAAwB,CAAxB,aAAAA,EAClB,KAAK,KAAO,IAAI,IAChB,KAAK,gBAAkB,EACzB,CACA,YAAYC,EAAkC,CAC5C,OAAO,KAAK,KAAK,IAAIA,CAAG,CAC1B,CACA,YAAYA,EAAcC,EAA0B,CAClD,KAAK,KAAK,IAAID,EAAKC,CAAQ,CAC7B,CACA,IAAIC,EAAyBC,EAAyCC,EAClEC,EAAmBC,EAAoBC,EACvCC,EAA0D,CAC5DC,GAAiBP,EAAc,YAAY,IAAI,EAC/C,IAAMQ,EAAS,KAAK,QAAQ,OAEtBC,EAAqB,KAAK,QAAQ,sBAAsB,EAC9DA,EAAmB,YAAYT,EAAc,eAAe,EAC5D,IAAMU,EAAU,CAAC,EACjB,QAAWC,KAASR,EAClBO,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQC,EAAM,MAAM,CAAC,CAAC,EAE1E,QAAWC,KAAUR,EACnBM,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQE,EAAO,MAAM,CAAC,CAAC,EAEvEN,GACFI,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAUJ,CAAoB,CAAC,EAExE,IAAMO,EAAYL,EAAO,gBACrB,CAAC,OAAQR,EAAc,gBAAgB,mBAAmB,CAAC,EAAG,QAAAU,EAAS,MAAOV,EAAc,YAAY,IAAI,CAAC,EAOjH,GANAS,EAAmB,aAAa,EAAGI,CAAS,EAE5CJ,EAAmB,mBAAmB,GAAGJ,CAAa,EAEtD,KAAK,QAAQ,wBAET,KAAK,QAAQ,eAAe,EAAG,CAC7B,OAAO,KAAK,QAAQ,UAAc,MACpC,KAAK,QAAQ,UAAY,KAAK,QAAQ,eAAe,OAEjD,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,aAAa,GAE5F,IAAMS,EAAW,KAAK,QAAQ,eAAe,OAEzC,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,QAAQ,EAErF,KAAK,QAAQ,eAAe,EAC5B,KAAK,QAAQ,kBAAkB,EAAE,gBAAgB,KAAK,QAAQ,SAAW,EAAG,EAAG,KAAK,QAAQ,UAAU,OAAQ,CAAC,EAC/G,KAAK,QAAQ,kBAAkB,EAAE,mBAC7B,KAAK,QAAQ,UAAU,OAAQ,EAAGA,EAAS,OAAQ,EAAG,KAAK,QAAQ,cAAgB,CAAC,EACxF,KAAK,QAAQ,MAAM,EAEnB,IAAMC,EAAW,KAAK,QAAQ,gBACxBC,EAAa,KAAK,QAAQ,QAAQ,IAAID,CAAQ,EAE/CD,EAAS,OAAO,SAAS,WAAW,IAAI,EAAE,KAAK,IAAM,CACxD,IAAMG,EAAa,IAAI,eAAeH,EAAS,OAAO,eAAe,CAAC,EAChE,CAACI,EAAcC,CAAU,EAAIF,EAC7B,CAACG,EAAYC,CAAU,EAAIL,EAEjCF,EAAS,OAAO,MAAM,EAElB,OAAO,KAAK,QAAQ,cAAkB,MACxC,KAAK,QAAQ,cAAgBI,GAG/B,IAAMI,EAAY,OAAOJ,EAAe,KAAK,QAAQ,aAAa,EAC5DK,EAAU,OAAOJ,EAAa,KAAK,QAAQ,aAAa,EAE9D,GAAI,CAAC,OAAO,cAAcG,CAAS,GAAK,CAAC,OAAO,cAAcC,CAAO,EACnE,MAAM,IAAI,WAAW,2BAA2B,EAIlD,GADA,KAAK,QAAQ,eAAe,QAAQT,EAAS,EAAE,EAC3C,KAAK,QAAQ,IAAI,OAAO,WAAW,OACrC,KAAK,QAAQ,IAAI,OAAO,UAAU,OAAO,CACvC,QAAS,EACT,eAAgBb,EAAiB,IAC7BuB,IAAU,CAAC,KAAMA,EAAM,KAAM,SAAUC,GAA2BD,EAAM,QAAQ,CAAC,EAAE,EACvF,gBAAiBtB,EAAkB,IAC/BsB,IAAU,CAAC,KAAMA,EAAM,KAAM,SAAUC,GAA2BD,EAAM,QAAQ,CAAC,EAAE,EACvF,SAAAT,EACA,WAAAK,EACA,WAAAC,EACA,UAAAC,EACA,QAAAC,CACF,CAAC,MACI,CAEL,IAAIG,EAAc,GAClBzB,EAAiB,QAAQ,CAACuB,EAAOG,IAAM,CACrCD,GAAe,SAASC,CAAC,OAAOH,EAAM,IAAI,OAAOC,GAA2BD,EAAM,QAAQ,CAAC,IAC7F,CAAC,EACD,IAAII,EAAe,GACnB1B,EAAkB,QAAQ,CAACsB,EAAOG,IAAM,CACtCC,GAAgB,UAAUD,CAAC,OAAOH,EAAM,IAAI,OAAOC,GAA2BD,EAAM,QAAQ,CAAC,IAC/F,CAAC,EAED,QAAQ,IAAI,uBAAuBT,CAAQ,IAAIM,CAAU,IAAIrB,EAAc,YAAY,IAAI,KAAK0B,CAAW,GACvGE,CAAY,mBAAmBL,EAAUD,CAAS,KAAK,CAC7D,CACF,CAAC,CACH,CAEI,KAAK,QAAQ,uBAAyB,IACxC,KAAK,QAAQ,MAAM,EAErBO,GAAe7B,EAAc,YAAY,IAAI,CAC/C,CACA,SAAgB,CAEhB,CACA,MAAM8B,EAA0BC,EAAiE,CAC/FxB,GAAiBuB,EAAY,IAAI,EACjC,IAAMtB,EAAS,KAAK,QAAQ,OACtBwB,EAAuB,CAAC,EAC1BxB,EAAO,SAAS,IAAI,YAAY,GAClCwB,EAAW,KAAK,aAAa,EAE/B,IAAMC,EAAeC,GAAmBH,CAA2B,EAC7DI,EAAWL,EAAY,gBAAgBG,CAAY,EACnDG,EAAO,GAAGJ,EAAW,KAAK;AAAA,CAAI,CAAC;AAAA,EAAKC,EAAa,yBAAyB;AAAA,EAAKE,CAAQ,GACvFE,EAAe7B,EAAO,mBAAmB,CAAC,KAAA4B,EAAM,MAAON,EAAY,IAAI,CAAC,EAC9EQ,GAAU,UAAW,IAAM,YAAYR,EAAY,IAAI,iBAAiBM,CAAI,EAAE,EAE9E,IAAMG,EAAkB/B,EAAO,sBAC3B,CAAC,QAAS,CAAC,OAAQ6B,EAAc,WAAY,MAAM,EAAG,OAAQ,OAAQ,MAAOP,EAAY,IAAI,CAAC,EAElG,OAAAD,GAAeC,EAAY,IAAI,EACxB,CAAC,YAAAA,EAAa,gBAAAS,CAAe,CACtC,CAEA,2BAA2BlC,EACE,CAC3B,IAAMmC,EAAI,OAAOnC,GAAkB,SAAWA,EAAgBA,EAAc,EACtEoC,EAAI,OAAOpC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEqC,EAAI,OAAOrC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEsC,EAAoB,KAAK,QAAQ,OAAO,OAAO,iCACrD,GAAIH,GAAKG,GAAqBF,GAAKE,GAAqBD,GAAKC,EAC3D,MAAO,CAACH,EAAGC,EAAGC,CAAC,EAEjB,IAAME,EAAOJ,EAAIC,EAAIC,EACjBG,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EAC/C,GAAIC,EAAkBF,EAAmB,CAEvC,GADAE,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EACvCC,EAAkBF,EACpB,MAAM,IAAI,MAAM,6CAA6C,EAE/D,MAAO,CAACE,EAAiBA,EAAiBA,CAAe,CAC3D,KACE,OAAO,CAACA,EAAiBA,EAAiB,CAAC,CAE/C,CACF,ICnLA,IAYMC,GA4CAC,GAqBOC,GA7EbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KACAC,KACAC,KACAC,KAGMV,GACF,CAACW,EAAqCC,IAA2E,CAC/G,GAAIA,EAAkB,SAAWD,EAAa,OAC5C,MAAM,IAAI,MAAM,4BAA4BC,EAAkB,MAAM,wCAChED,EAAa,MAAM,GAAG,EAG5B,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIH,EAAa,OAAQ,EAAEG,EAAG,CAC5C,IAAMC,EAAOJ,EAAaG,CAAC,EAAE,SAC7B,OAAQF,EAAkBE,CAAC,EAAG,CAC5B,IAAK,OAAQ,CACXD,EAAW,KAAK,EAAE,EAClB,KACF,CACA,IAAK,OAAQ,CACXA,EAAW,KAAK,GAAGE,CAAI,EAAE,EACzB,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAOL,EAAaG,CAAC,EAAE,KAAK,OAClCD,EAAW,KAAK,GAAGE,CAAI,IAAIC,CAAI,EAAE,EACjC,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAON,EAAaG,CAAC,EAAE,KAAK,KAAK,GAAG,EAC1CD,EAAW,KAAK,GAAGE,CAAI,IAAIE,CAAI,EAAE,EACjC,KACF,CACA,QACE,MAAM,IAAI,MAAM,iCAAiCL,EAAkBE,CAAC,CAAC,EAAE,CAC3E,CACF,CAEA,OAAOD,EAAW,KAAK,GAAG,CAC5B,EASEZ,GACF,CAACiB,EAA0BP,EAAqCQ,IAA0C,CAGxG,IAAIC,EAAMF,EAAY,KACtB,OAAIA,EAAY,aAAa,OAC3BE,GAAO,IAAMF,EAAY,YAAY,KAAO,KAE9CE,GAAO,IAAMD,EACT,IACOnB,GACIW,EACAO,EAAY,aAAa,mBACrB,IAAI,MAAwCP,EAAa,MAAM,EAAE,KAAK,MAAM,CAAC,CAAC,GAC1FS,CACT,EAMSlB,GAAN,KAAoB,CAApB,cAiBL,qBAA+B,KAoC/B,KAAQ,eAAyC,KACjD,KAAQ,mBAAiD,KACzD,2BAAwB,EAIxB,mBAAgB,EAQhB,gCAA4E,IAAI,IAlChF,IAAI,yBAAoD,CACtD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,yEAAyE,EAG3F,IAAImB,EAAO,KAAK,iBAAiB,IAAI,KAAK,eAAe,EACzD,OAAKA,IACHA,EAAO,CAAC,EACR,KAAK,iBAAiB,IAAI,KAAK,gBAAiBA,CAAI,GAG/CA,CACT,CAwBA,MAAM,WAAWC,EAAUC,EAAoC,CAC7D,KAAK,IAAMD,EACX,IAAME,EAAqC,CAAC,EACtCC,EAAwC,CAC5C,eAAgB,CACd,+BAAgCF,EAAQ,OAAO,+BAC/C,iCAAkCA,EAAQ,OAAO,iCACjD,4BAA6BA,EAAQ,OAAO,4BAC5C,cAAeA,EAAQ,OAAO,cAC9B,kCAAmCA,EAAQ,OAAO,kCAClD,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,wBAC3C,EACA,iBAAAC,CACF,EAEID,EAAQ,SAAS,IAAI,iBAAiB,GACxCC,EAAiB,KAAK,iBAAiB,EAErCD,EAAQ,SAAS,IAAI,YAAY,GACnCC,EAAiB,KAAK,YAAY,EAGpC,KAAK,OAAS,MAAMD,EAAQ,cAAcE,CAAgB,EAC1D,KAAK,eAAiBC,GAAqB,IAAI,EAC/C,KAAK,eAAiB,IAAIC,GAAe,IAAI,EAC7C,KAAK,QAAU,IAAI,IACnB,KAAK,qBAAuB,IAAI,IAChC,KAAK,iBAAmB,IAAI,IAG5BC,GAAgBN,EAAI,SAAW,CAAC,CAACA,EAAI,KAAK,EAI1C,KAAK,OAAO,kBAAoBO,GAAM,CAChCA,EAAG,iBAAiB,oBAEtB,QAAQ,MAAM,mDAAmDA,EAAG,MAAM,OAAO,EAAE,CAEvF,EAEA,OAAO,eAAe,KAAK,IAAI,OAAQ,SAAU,CAAC,MAAO,KAAK,MAAM,CAAC,CACvE,CAEA,SAAgB,CACV,OAAO,KAAK,SAAa,KAC3B,KAAK,SAAS,QAAQ,EAExB,KAAK,eAAe,QAAQ,CAC9B,CAEA,mBAAuC,CACrC,OAAK,KAAK,iBACR,KAAK,eAAiB,KAAK,OAAO,qBAAqB,GAElD,KAAK,cACd,CAEA,uBAA+C,CAC7C,GAAI,CAAC,KAAK,mBAAoB,CAC5B,IAAMC,EAAkD,CAAC,EACrD,KAAK,eAAe,IAClB,OAAO,KAAK,SAAa,MAC3B,KAAK,SAAW,KAAK,OAAO,eAAe,CACzC,KAAM,YACN,MAAO,KAAK,aACd,CAAC,GAEHA,EAAsB,gBAAkB,CACtC,SAAU,KAAK,SACf,0BAA2B,EAC3B,oBAAqB,CACvB,GAGF,KAAK,mBAAqB,KAAK,kBAAkB,EAAE,iBAAiBA,CAAqB,CAC3F,CACA,OAAO,KAAK,kBACd,CAEA,gBAAuB,CACjB,KAAK,qBACP,KAAK,mBAAmB,IAAI,EAC5B,KAAK,mBAAqB,KAE9B,CAEA,OAAc,CACR,KAAK,iBACP,KAAK,eAAe,EACpB,KAAK,OAAO,MAAM,OAAO,CAAC,KAAK,kBAAkB,EAAE,OAAO,CAAC,CAAC,EAC5D,KAAK,eAAe,sBAAsB,EAC1C,KAAK,eAAiB,KACtB,KAAK,sBAAwB,EAEjC,CAEA,gBAA0B,CACxB,OAAO,KAAK,OAAO,SAAS,IAAI,iBAAiB,IAC5C,KAAK,IAAI,OAAO,WAAW,OAAS,WACnC,CAAC,KAAK,IAAI,OAAO,WAAW,MAAQ,KAAK,IAAI,OAAO,gBAAkB,UAC9E,CAaA,IAAIC,EAAsBC,EAAyCC,EAC/DC,EACAC,EAAmG,CACrGC,GAAiBL,EAAQ,IAAI,EAE7B,IAAMM,EAAwB,CAAC,EAC/B,QAASvB,EAAI,EAAGA,EAAIkB,EAAiB,OAAQ,EAAElB,EAAG,CAChD,IAAMwB,EAAU,KAAK,eAAe,IAAIN,EAAiBlB,CAAC,EAAE,IAAI,EAChE,GAAI,CAACwB,EACH,MAAM,IAAI,MAAM,0BAA0BN,EAAiBlB,CAAC,EAAE,IAAI,EAAE,EAEtEuB,EAAWvB,CAAC,EAAIwB,CAClB,CAEA,GAAM,CAAC,QAAAC,EAAS,cAAAC,EAAe,gBAAAC,CAAe,EAAIV,EAAQ,WAAWC,CAAgB,EAG/EU,EAAyBT,EAAc,SAAW,EAAIM,EAAQ,IAAI,CAACI,EAAG7B,IAAMA,CAAC,EAAImB,EACvF,GAAIS,EAAuB,SAAWH,EAAQ,OAC5C,MAAM,IAAI,MAAM,eAAeG,EAAuB,MAAM,qBAAqBH,EAAQ,MAAM,GAAG,EAIpG,IAAMK,EAAkC,CAAC,EACnCC,EAAyB,CAAC,EAChC,QAAS/B,EAAI,EAAGA,EAAIyB,EAAQ,OAAQ,EAAEzB,EAAG,CAIvC,GAAI,CAAC,OAAO,UAAU4B,EAAuB5B,CAAC,CAAC,GAAK4B,EAAuB5B,CAAC,EAAI,IAC5E4B,EAAuB5B,CAAC,GAAKyB,EAAQ,OACvC,MAAM,IAAI,MAAM,yBAAyBG,EAAuB5B,CAAC,CAAC,EAAE,EAEtE,GAAI4B,EAAuB5B,CAAC,IAAM,GAChC,SAEF,IAAMgC,EAAcJ,EAAuB5B,CAAC,IAAM,GAC5CiC,EAAeL,EAAuB5B,CAAC,IAAM,GAC7CkC,EAAcF,GAAeC,EAC/BZ,EAAyBI,EAAQzB,CAAC,EAAE,SAAUyB,EAAQzB,CAAC,EAAE,IAAI,EAC7DoB,EAAmBQ,EAAuB5B,CAAC,EAAGyB,EAAQzB,CAAC,EAAE,SAAUyB,EAAQzB,CAAC,EAAE,IAAI,EAChFwB,EAAU,KAAK,eAAe,IAAIU,EAAW,IAAI,EACvD,GAAI,CAACV,EACH,MAAM,IAAI,MAAM,2BAA2BU,EAAW,IAAI,EAAE,EAK9D,GAHIF,GACF,KAAK,cAAc,KAAKR,CAAO,EAE7BS,EAAc,CAChB,IAAIE,EAAiB,KAAK,qBAAqB,IAAI,KAAK,eAAgB,EACnEA,IACHA,EAAiB,CAAC,EAClB,KAAK,qBAAqB,IAAI,KAAK,gBAAkBA,CAAc,GAErEA,EAAe,KAAKX,CAAO,CAC7B,CACAM,EAAkB,KAAKI,CAAU,EACjCH,EAAY,KAAKP,CAAO,CAC1B,CAMA,IAAIY,EACJ,GAAIT,EAAiB,CACnB,IAAIU,EAAgB,EACdC,EAAoB,CAAC,EAE3BX,EAAgB,QAAQY,GAAK,CAC3B,IAAMhC,EAAO,OAAOgC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACvD,GAAIhC,EAAK,SAAW,EAClB,OAGF,IAAMiC,EAAgBjC,EAAK,QAAU,EAAIA,EAAK,OAAS,EAAI,GAC3D8B,EAAgB,KAAK,KAAKA,EAAgBG,CAAa,EAAIA,EAC3DF,EAAQ,KAAKD,CAAa,EAI1BA,GAAiB9B,EAAK,OAAS,EAAI,KAAK,KAAKA,EAAK,OAAS,CAAC,EAAI,GAAKA,EAAK,OAAS,CACrF,CAAC,EAID,IAAMkC,EAAsB,GAC5BJ,EAAgB,KAAK,KAAKA,EAAgBI,CAAmB,EAAIA,EACjE,IAAMC,EAAc,IAAI,YAAYL,CAAa,EACjDV,EAAgB,QAAQ,CAACY,EAAGvC,IAAM,CAChC,IAAM2C,EAASL,EAAQtC,CAAC,EAClBO,EAAO,OAAOgC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACnDA,EAAE,OAAS,QACb,IAAI,WAAWG,EAAaC,EAAQpC,EAAK,MAAM,EAAE,IAAIA,CAAI,EAChDgC,EAAE,OAAS,SACpB,IAAI,YAAYG,EAAaC,EAAQpC,EAAK,MAAM,EAAE,IAAIA,CAAI,EAE1D,IAAI,aAAamC,EAAaC,EAAQpC,EAAK,MAAM,EAAE,IAAIA,CAAI,CAE/D,CAAC,EAED,IAAMqC,EAEF,KAAK,eAAe,OAAOP,EAAe,eAAe,SAAW,eAAe,OAAO,EAC9F,KAAK,OAAO,MAAM,YAAYO,EAAkB,OAAQ,EAAGF,EAAa,EAAGL,CAAa,EACxF,KAAK,eAAe,QAAQO,EAAkB,EAAE,EAChDR,EAAuB,CAAC,OAAQ,EAAG,KAAMC,EAAe,OAAQO,EAAkB,MAAM,CAC1F,CAEA,IAAMC,EAA0B,KAAK,eAAe,2BAA2BnB,CAAa,EACtFrB,EAAuBwC,EAAwB,CAAC,IAAM,GAAKA,EAAwB,CAAC,IAAM,EAE1FvC,EAAMnB,GAAwB8B,EAASC,EAAkBb,CAAoB,EAC/EyC,EAAW,KAAK,eAAe,YAAYxC,CAAG,EAClD,OAAKwC,IACHA,EAAW,KAAK,eAAe,MAAM7B,EAAS4B,CAAuB,EACrE,KAAK,eAAe,YAAYvC,EAAKwC,CAAQ,EAC7CC,GAAU,OAAQ,IAAM,mBAAmBzC,CAAG,kBAAkBW,EAAQ,IAAI,EAAE,GAGhF8B,GACI,OACA,IAAM,yBAAyB9B,EAAQ,IAAI,UAAUX,CAAG,UAAUuC,EAAwB,CAAC,CAAC,IACxFA,EAAwB,CAAC,CAAC,IAAIA,EAAwB,CAAC,CAAC,EAAE,EAClE,KAAK,eAAe,IAChBC,EAAU5B,EAAkBY,EAAmBP,EAAYQ,EAAac,EACxET,CAAoB,EAExBY,GAAe/B,EAAQ,IAAI,EACpBa,CACT,CAEA,OAAOmB,EAAmB1C,EAAwB,CAChD,KAAK,eAAe,OAAO0C,EAAW1C,CAAI,CAC5C,CAEA,OAAO2C,EAAaC,EAAmB,CACrC,KAAK,eAAe,OAAOD,EAAKC,CAAG,CACrC,CAEA,MAAM,SAASF,EAAmBG,EAAkD,CAGlF,MAAM,KAAK,eAAe,SAASH,EAAWG,CAAe,CAC/D,CAEA,MAAMC,EAAsB,CAC1B,OAAO,KAAK,eAAe,OAAOA,CAAI,EAAE,EAC1C,CAEA,KAAKC,EAAqB,CACxB,OAAO,KAAK,eAAe,QAAQA,CAAG,CACxC,CAEA,aAAaC,EAAgBC,EAAkBC,EAAoBC,EAAwB,CACzF,IAAMC,EAAKC,GAAwB,IAAIL,CAAM,EAC7C,GAAI,CAACI,EACH,MAAM,IAAI,MAAM,2BAA2BJ,CAAM,EAAE,EAGrD,KAAK,QAAQ,IAAIC,EAAU,CAACD,EAAQG,EAAUC,EAAG,CAAC,EAAG,CAACA,EAAG,CAAC,EAAGF,CAAS,CAAC,CAAC,CAC1E,CAEA,cAAcD,EAAwB,CACpC,IAAMrB,EAAiB,KAAK,qBAAqB,IAAIqB,CAAQ,EAC7D,GAAIrB,EAAgB,CAClB,QAAW5B,KAAQ4B,EACjB,KAAK,eAAe,QAAQ5B,EAAK,EAAE,EAErC,KAAK,qBAAqB,OAAOiD,CAAQ,CAC3C,CAEA,KAAK,iBAAiB,OAAOA,CAAQ,EACrC,KAAK,QAAQ,OAAOA,CAAQ,CAC9B,CAEA,cAAcA,EAAkBK,EAAyBC,EAA6C,CACpG,IAAMC,EAAS,KAAK,QAAQ,IAAIP,CAAQ,EACxC,GAAI,CAACO,EACH,MAAM,IAAI,MAAM,uBAAuBP,CAAQ,EAAE,EAEnD,GAAM,CAACD,EAAQG,EAAUM,EAAaC,CAAU,EAAIF,EACpD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,YAAYR,CAAM,KAAKG,CAAQ,2CAA2C,EAE5F,KAAK,gBAAkBF,EAGnBS,EAAW,CAAC,IACdA,EAAW,CAAC,EAAIA,EAAW,CAAC,EAAEA,EAAW,CAAC,CAAC,EAC3CA,EAAW,CAAC,EAAI,QAGlBlB,GAAU,OAAQ,IAAM,kCAAkCQ,CAAM,KAAKG,CAAQ,MAAM,EAEnF,IAAMQ,EAAgB,KAAK,IAAI,MAE/B,KAAK,cAAgB,CAAC,EACtB,GAAI,CACF,OAAIA,GACF,KAAK,OAAO,eAAe,YAAY,EAGzCF,EAAYH,EAASI,EAAW,CAAC,CAAC,EAC3B,CACT,OAASE,EAAG,CACV,OAAAL,EAAO,KAAK,QAAQ,QAAQ,qBAAqBP,CAAM,KAAKG,CAAQ,aAAaS,CAAC,EAAE,CAAC,EAC9E,CACT,QAAE,CACID,GACFJ,EAAO,KAAK,KAAK,OAAO,cAAc,EAAE,KACpCM,GAAOA,EAAM,qCAAqCb,CAAM,KAAKG,CAAQ,MAAMU,EAAI,OAAO,GAAK,IAAI,CAAC,EAGtG,QAAW7D,KAAQ,KAAK,cACtB,KAAK,eAAe,QAAQA,EAAK,EAAE,EAErC,KAAK,cAAgB,CAAC,EACtB,KAAK,gBAAkB,IACzB,CACF,CAGA,eAAe8D,EAAmBC,EAAeC,EAAmBlB,EAAsB,CACxF,IAAImB,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EACxEG,IACHA,EAA4B,IAAI,IAChC,KAAK,2BAA2B,IAAIH,EAAWG,CAAyB,GAG1E,IAAMC,EAAiBD,EAA0B,IAAIF,CAAK,EACpDI,EAAK,KAAK,eAAe,uBAAuBH,EAAQlB,EAAMoB,IAAiB,CAAC,CAAC,EACvF,OAAAD,EAA0B,IAAIF,EAAO,CAACI,EAAIH,CAAM,CAAC,EAC1CG,CACT,CACA,kBAAkBL,EAAyB,CACzC,IAAMG,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EAC3EG,IACFA,EAA0B,QAAQG,GAAc,KAAK,eAAe,yBAAyBA,EAAW,CAAC,CAAC,CAAC,EAC3G,KAAK,2BAA2B,OAAON,CAAS,EAEpD,CACA,UAAUpB,EAA8B,CACtC,IAAMzB,EAAU,KAAK,eAAe,IAAIyB,CAAS,EACjD,GAAI,CAACzB,EACH,MAAM,IAAI,MAAM,2BAA2ByB,CAAS,EAAE,EAExD,OAAOzB,EAAQ,MACjB,CACA,iBAAiBoD,EAAsBvB,EAAcpD,EAClB,CACjC,MAAO,UAAY,CACjB,IAAMM,EAAO,MAAMsE,GAAgB,KAAMD,EAAWvB,CAAI,EACxD,OAAOyB,GAAWvE,EAAK,OAAQN,CAAI,CACrC,CACF,CAEF,ICvgBA,IAAA8E,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAgBMC,GAuCAC,GA2FOF,GAlJbG,GAAAC,EAAA,kBAMAC,KAEAC,KACAC,KAEAC,KAKMP,GAAN,MAAMQ,CAAqC,CACzC,YACYC,EAAuCC,EAAkCC,EACjEC,EAAyB,CADjC,YAAAH,EAAuC,cAAAC,EAAkC,UAAAC,EACjE,UAAAC,CAA0B,CAE9C,iBAAgC,CAC9B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMC,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,aACJ,IAAI,aAAa,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CAChG,CAEA,kBAAkC,CAChC,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,cACJ,IAAI,cAAc,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjG,CAEA,eAA4B,CAC1B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,WAAe,IAAI,WAAW,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjH,CAEA,QAAQE,EAAwC,CAC9C,GAAID,EAAU,KAAKC,CAAO,IAAMD,EAAU,KAAK,KAAK,IAAI,EACtD,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAO,IAAIN,EAAe,KAAK,OAAQ,KAAK,SAAU,KAAK,KAAMO,CAAO,CAC1E,CACF,EAEMd,GAAN,KAAmD,CAYjD,YAAoBQ,EAA+BO,EAAwBC,EAA2B,CAAlF,YAAAR,EAA+B,aAAAO,EAFnD,KAAQ,iBAAmB,EAC3B,KAAQ,eAAiB,EAEvB,IAAME,EAAUT,EAAO,QAGnBU,EAAaF,IAAsB,EACvC,KAAK,gBAAkBC,EAAQC,GAAW,EAC1C,IAAMC,EAAaF,EAAQC,GAAW,EACtC,KAAK,YAAcD,EAAQC,GAAW,EACtC,KAAK,iBAAmBD,EAAQC,GAAW,EAC3C,KAAK,eAAiBD,EAAQC,GAAW,EAEzC,IAAME,EAAuB,CAAC,EAC9B,QAAS,EAAI,EAAG,EAAID,EAAY,IAAK,CACnC,IAAMV,EAAWQ,EAAQC,GAAW,EAC9BR,EAAOO,EAAQC,GAAW,EAC1BG,EAAMJ,EAAQC,GAAW,EACzBP,EAAiB,CAAC,EACxB,QAASW,EAAI,EAAGA,EAAID,EAAKC,IACvBX,EAAK,KAAKM,EAAQC,GAAW,CAAC,EAEhCE,EAAO,KAAK,IAAIrB,GAAeS,EAAQC,EAAUC,EAAMC,CAAI,CAAC,CAC9D,CACA,KAAK,OAASS,CAChB,CA/BA,IAAI,kBAA6C,CAC/C,OAAO,KAAK,QAAQ,uBACtB,CACA,IAAI,kBAA+B,CACjC,OAAO,KAAK,OAAO,OAAO,SAAS,KAAK,iBAAkB,KAAK,iBAAmB,KAAK,cAAc,CACvG,CA4BA,QAAQG,EAAsBC,EAAyE,CAErG,IAAMC,EACFD,GAAsB,QAAQ,IAAIE,GAAK,OAAOA,GAAM,SAAW,KAAK,OAAOA,CAAC,EAAIA,CAAC,GAAK,KAAK,OAEzFC,EAAgBH,GAAsB,SAAW,CAAC,EAClDI,EAAqB,CAACC,EAAepB,EAAkBE,IACzD,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,OAAOoB,EAAOlB,CAAI,EAAGA,CAAI,EACtEmB,EAAwB,CAACrB,EAAkBE,IAAwC,CACvF,IAAMoB,EAAcC,GAAqBvB,CAAQ,EACjD,GAAI,CAACsB,EACH,MAAM,IAAI,MAAM,0BAA0BtB,CAAQ,EAAE,EAEtD,IAAMwB,EAAaF,EAAclB,EAAU,KAAKF,CAAI,EACpD,OAAO,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,QAAQ,eAAe,OAAOwB,CAAU,EAAE,GAAItB,CAAI,CAC1G,EACA,OAAO,KAAK,QAAQ,IAAIY,EAASE,EAAcE,EAAeC,EAAoBE,CAAqB,CACzG,CAEA,OAAOD,EAAelB,EAAiC,CACrD,IAAMuB,EAAQ,KAAK,OAAO,UAAU,EACpC,GAAI,CACF,IAAMxB,EAAO,KAAK,OAAO,YAAY,EAAIC,EAAK,QAAU,CAAsB,EAC1EwB,EAASzB,GAAQ,EACrB,KAAK,OAAO,QAAQyB,GAAQ,EAAIxB,EAAK,OACrC,QAASe,EAAI,EAAGA,EAAIf,EAAK,OAAQe,IAC/B,KAAK,OAAO,QAAQS,GAAQ,EAAIxB,EAAKe,CAAC,EAExC,OAAO,KAAK,OAAO,YAAY,KAAK,gBAAiBG,EAAOnB,CAAI,CAClE,OAAS0B,EAAG,CACV,MAAM,IAAI,MACN,sCAAsCP,CAAK,gBAAgBlB,CAAI,8GAErDyB,CAAC,EAAE,CACnB,QAAE,CACA,KAAK,OAAO,aAAaF,CAAK,CAChC,CACF,CACF,EAgBapC,GAAO,MAAMU,EAAuB6B,EAAUC,IAA0C,CACnG,IAAMC,EAAW/B,EAAO,SACxB,GAAI,CAAC+B,EACH,MAAM,IAAI,MAAM,mFAAmF,EAGrG,IAAMxB,EAAU,IAAIyB,GACpB,MAAMzB,EAAQ,WAAWsB,EAAKC,CAAU,EAExCC,EAEIxB,EAGC0B,GAAiB1B,EAAQ,MAAM0B,CAAI,EAGnCC,GAAgB3B,EAAQ,KAAK2B,CAAG,EAGjC,CAACC,EAAaC,EAAaH,EAAcI,EAAc,KAAU,CAC/D,GAAIA,EACFC,GAAU,UAAW,IAAM,kCAAkCH,CAAG,SAASC,CAAG,UAAUH,CAAI,EAAE,EAC5F1B,EAAQ,OAAO4B,EAAKC,CAAG,MAClB,CACLE,GAAU,UAAW,IAAM,yCAAyCH,CAAG,eAAeC,CAAG,UAAUH,CAAI,EAAE,EACzG,IAAM/B,EAAOF,EAAO,OAAO,SAASmC,EAAKA,EAAMF,CAAI,EACnD1B,EAAQ,OAAO6B,EAAKlC,CAAI,CAC1B,CACF,EAGA,MAAMqC,EAAmBC,EAAoBP,IACxB,CACfK,GACI,UACA,IAAM,wCAAwCC,CAAS,gBAAgBC,CAAU,UAAUP,CAAI,EAAE,EAErG,MAAM1B,EAAQ,SAASgC,EAAW,IAAMvC,EAAO,OAAO,SAASwC,EAAYA,EAAaP,CAAI,CAAC,CAC/F,EAGJ,CAACQ,EAAcC,EAAgBC,IAAuBpC,EAAQ,aAC1DkC,EAAMC,EAAQC,EACdd,EAAI,OAAStB,EAAQ,eAAe,EAAIP,EAAO,aAAaA,EAAO,iBAAiB0C,CAAM,CAAC,EAAI,GAAGA,CAAM,EAAE,EAG7GA,GAAmBnC,EAAQ,cAAcmC,CAAM,EAGhD,CAACA,EAAgBlC,EAA2BoC,EAAuBC,IAAwC,CACzGP,GACI,UACA,IAAM,mCAAmCM,CAAa,YAAYF,CAAM,uBACpElC,CAAiB,EAAE,EAC3B,IAAMsC,EAAU,IAAItD,GAAmBQ,EAAQO,EAASC,CAAiB,EACzE,OAAOD,EAAQ,cAAcmC,EAAQI,EAASD,CAAM,CACtD,CAAC,CACP,IC5MA,IA8DME,GAWOC,GAWAC,GA2DPC,GAOAC,GAqBOC,GAkBAC,GAuGAC,GAoBAC,GAqEAC,GA6NAC,GAgBAC,GA1mBbC,GAAAC,EAAA,kBAMAC,KACAC,KACAC,KACAC,KACAC,KAoDMlB,GAAU,CAACmB,EAAoBC,IAA+B,CAChDC,GAAY,EAAE,SAASF,EAAYC,CAAY,IAC/C,GAChBE,GAAe,+BAAgC,CAEnD,EAMarB,GAAc,MAAMsB,GAA4B,CAE3DvB,GAAQuB,EAAI,KAAK,WAAaC,GAAqBD,EAAI,QAAQ,CAAC,CAClE,EAQarB,GAAS,MAAMqB,EAAUE,IAAkC,CACtE,GAAkCA,IAAW,SAAU,CAErD,GAAI,OAAO,UAAc,KAAe,CAAC,UAAU,IACjD,MAAM,IAAI,MAAM,gDAAgD,EAElE,IAAMC,EAAU,MAAM,UAAU,IAAI,eAAe,EACnD,GAAI,CAACA,EACH,MAAM,IAAI,MACN,0GAA0G,EAGhH,GAAI,CAACH,EAAI,KAAK,KACZ,MAAM,IAAI,MACN,qGAAqG,EAM3G,IAAMI,EAAW,cAAuB,KACxC,MAAMA,EAASN,GAAY,EAAGE,EAAKG,CAAO,CAC5C,CACF,EAoCMvB,GAAiB,IAAI,IAOrBC,GAA8BwB,GAA4C,CAC9E,IAAMC,EAAOR,GAAY,EACnBS,EAAQD,EAAK,UAAU,EAC7B,GAAI,CACF,IAAME,EAAaF,EAAK,WAAW,CAAC,EAEpC,OADkBA,EAAK,wBAAwBD,EAAeG,EAAYA,EAAa,CAAC,IACtE,GAChBT,GAAe,uCAAwC,EAElD,CAACO,EAAK,OAAOE,EAAa,CAAC,EAAGF,EAAK,OAAOE,EAAa,EAAI,CAAC,CAAC,CACtE,QAAE,CACAF,EAAK,aAAaC,CAAK,CACzB,CACF,EAQazB,GAA0B2B,GAAwC,CAC7E,IAAMH,EAAOR,GAAY,EACnBY,EAAkBJ,EAAK,QAAQG,EAAM,UAAU,EACrD,GAAIC,IAAoB,EACtB,MAAM,IAAI,MAAM,+DAA+DD,EAAM,UAAU,GAAG,EAEpG,OAAAH,EAAK,OAAO,IAAIG,EAAOC,CAAe,EAC/B,CAACA,EAAiBD,EAAM,UAAU,CAC3C,EAUa1B,GACT,CAAC4B,EACAC,IAA2E,CAC1E,IAAIF,EAAyBG,EACvBP,EAAOR,GAAY,EAErB,MAAM,QAAQa,CAAS,EAEzB,CAACD,EAAiBG,CAAe,EAAIF,EAC5BA,EAAU,SAAWL,EAAK,OAAO,OAE1C,CAACI,EAAiBG,CAAe,EAAI,CAACF,EAAU,WAAYA,EAAU,UAAU,EAGhF,CAACD,EAAiBG,CAAe,EAAI/B,GAAuB6B,CAAS,EAGvE,IAAIN,EAAgB,EAChBS,EAAuB,EACvBC,EAAkB,EAClBC,EAAmB,CAAC,EAClBC,EAAwB,CAAC,EACzBC,EAAyB,CAAC,EAEhC,GAAI,CACF,CAACJ,EAAsBE,CAAM,EAAIG,GAAkBP,CAAO,EAE1DP,EAAgBC,EAAK,kBAAkBI,EAAiBG,EAAiBC,CAAoB,EACzFT,IAAkB,GACpBN,GAAe,yBAA0B,EAG3C,GAAM,CAACqB,EAAYC,CAAW,EAAIxC,GAA2BwB,CAAa,EAEpEiB,EAAa,CAAC,EACdC,EAAc,CAAC,EACfC,EAAwE,CAAC,EAC/E,QAASC,EAAI,EAAGA,EAAIL,EAAYK,IAAK,CACnC,IAAMC,EAAOpB,EAAK,iBAAiBD,EAAeoB,CAAC,EAC/CC,IAAS,GACX3B,GAAe,0BAA2B,EAE5CkB,EAAsB,KAAKS,CAAI,EAC/BJ,EAAW,KAAKhB,EAAK,aAAaoB,CAAI,CAAC,CACzC,CACA,QAASD,EAAI,EAAGA,EAAIJ,EAAaI,IAAK,CACpC,IAAMC,EAAOpB,EAAK,kBAAkBD,EAAeoB,CAAC,EAChDC,IAAS,GACX3B,GAAe,2BAA4B,EAE7CmB,EAAuB,KAAKQ,CAAI,EAChC,IAAMC,EAAarB,EAAK,aAAaoB,CAAI,EACzCH,EAAY,KAAKI,CAAU,EAEK,CAC9B,IAAMC,EAAW,OAAOhB,GAAS,yBAA4B,SACzDA,EAAQ,wBACRA,GAAS,0BAA0Be,CAAU,GAAK,MACtD,GAAIC,IAAa,OAASA,IAAa,cAAgBA,IAAa,aAClE,MAAM,IAAI,MAAM,4CAA4CA,CAAQ,GAAG,EAEzEJ,EAAyB,KAAKI,CAAQ,CACxC,CACF,CAGA,IAAIC,EAAoC,KACxC,OAAkCL,EAAyB,KAAKM,GAAKA,IAAM,YAAY,IACrFf,EAAkBT,EAAK,kBAAkBD,CAAa,EAClDU,IAAoB,GACtBhB,GAAe,0BAA2B,EAG5C8B,EAAe,CACb,OAAQd,EACR,yBAAAS,EACA,gCAAiCA,EAAyB,IAAIM,GAAKC,GAAyBD,CAAC,CAAC,CAChG,GAGFlD,GAAe,IAAIyB,EAAe,CAACA,EAAeY,EAAuBC,EAAwBW,CAAY,CAAC,EACvG,CAACxB,EAAeiB,EAAYC,CAAW,CAChD,OAASS,EAAG,CACV,MAAAf,EAAsB,QAAQgB,GAAO3B,EAAK,SAAS2B,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAO3B,EAAK,SAAS2B,CAAG,CAAC,EAEpDlB,IAAoB,GACtBT,EAAK,mBAAmBS,CAAe,EAGrCV,IAAkB,GACpBC,EAAK,mBAAmBD,CAAa,EAEjC2B,CACR,QAAE,CACA1B,EAAK,MAAMI,CAAe,EACtBI,IAAyB,GAC3BR,EAAK,0BAA0BQ,CAAoB,EAErDE,EAAO,QAAQkB,GAAS5B,EAAK,MAAM4B,CAAK,CAAC,CAC3C,CACF,EAESlD,GAAkBmD,GAA4B,CACzD,IAAM7B,EAAOR,GAAY,EACnBsC,EAAUxD,GAAe,IAAIuD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,+CAA+CD,CAAS,EAAE,EAE5E,GAAM,CAAC9B,EAAeY,EAAuBC,EAAwBmB,CAAc,EAAID,EAEnFC,GACF/B,EAAK,mBAAmB+B,EAAe,MAAM,EAG/C/B,EAAK,wBAAwB6B,CAAS,EAEtClB,EAAsB,QAAQgB,GAAO3B,EAAK,SAAS2B,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAO3B,EAAK,SAAS2B,CAAG,CAAC,EACxD3B,EAAK,mBAAmBD,CAAa,EACrCzB,GAAe,OAAOuD,CAAS,CACjC,EAEalD,GACT,CAACqD,EAA6BC,EAAyBvB,EAAkBmB,EAAmBK,IAChF,CACN,GAAI,CAACF,EAAQ,CACXC,EAAc,KAAK,CAAC,EACpB,MACF,CAEA,IAAMjC,EAAOR,GAAY,EAEnB2C,EAAWH,EAAO,CAAC,EACnBI,EAAOJ,EAAO,CAAC,EACfV,EAAWU,EAAO,CAAC,EAErBK,EACAC,EAEJ,GAAIH,IAAa,UAAYb,IAAa,aACxC,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIA,IAAa,aAAc,CAC7B,IAAMiB,EAAYP,EAAO,CAAC,EAAE,UACtBQ,EAAqBC,GAAqBC,GAA2BP,CAAQ,CAAC,EACpFG,EAAiBF,EAAK,OAAO,CAACO,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAIJ,EACnDH,EAAUrC,EAAK,mBAAmB6B,EAAWK,EAAOK,EAAWD,CAAc,CAC/E,KAAO,CACL,IAAMO,EAAOb,EAAO,CAAC,EAErB,GAAI,MAAM,QAAQa,CAAI,EAAG,CAEvBP,EAAiB,EAAIO,EAAK,OAC1BR,EAAUrC,EAAK,QAAQsC,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB,IAAIS,EAAYT,EAAU,EAC1B,QAASlB,EAAI,EAAGA,EAAI0B,EAAK,OAAQ1B,IAAK,CACpC,GAAI,OAAO0B,EAAK1B,CAAC,GAAM,SACrB,MAAM,IAAI,UAAU,wBAAwBA,CAAC,kBAAkB,EAEjEnB,EAAK,QAAQ8C,GAAW,EAAIC,GAAgBF,EAAK1B,CAAC,EAAGT,CAAM,CAC7D,CACF,MACE4B,EAAiBO,EAAK,WACtBR,EAAUrC,EAAK,QAAQsC,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnBrC,EAAK,OAAO,IAAI,IAAI,WAAW6C,EAAK,OAAQA,EAAK,WAAYP,CAAc,EAAGD,CAAO,CAEzF,CAEA,IAAMpC,EAAQD,EAAK,UAAU,EACvBgD,EAAahD,EAAK,WAAW,EAAIoC,EAAK,MAAM,EAClD,GAAI,CACF,IAAIa,EAAWD,EAAa,EAC5BZ,EAAK,QAAQc,GAAKlD,EAAK,OAAOiD,GAAU,EAAIC,CAAC,EAC7C,IAAMlB,EAAShC,EAAK,iBAChB0C,GAA2BP,CAAQ,EAAGE,EAASC,EAAgBU,EAAYZ,EAAK,OAChFX,GAAyBH,CAAQ,CAAC,EAClCU,IAAW,GACbvC,GAAe,iDAAiDoC,CAAS,WAAWK,CAAK,GAAG,EAE9FD,EAAc,KAAKD,CAAM,CAC3B,QAAE,CACAhC,EAAK,aAAaC,CAAK,CACzB,CACF,EAKKrB,GAAM,MACfiD,EAAmBsB,EAAwBC,EAAgCC,EAC3EC,EAA2ChD,IAAoE,CACjH,IAAMN,EAAOR,GAAY,EACnBsC,EAAUxD,GAAe,IAAIuD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,6CAA6CD,CAAS,EAAE,EAE1E,GAAM,CAAC9B,EAAeY,EAAuBC,EAAwBmB,CAAc,EAAID,EAEjFhB,EAAaqC,EAAa,OAC1BpC,EAAcsC,EAAc,OAE9BE,EAAmB,EACnBC,EAA6B,CAAC,EAE5BC,EAA+B,CAAC,EAChCC,EAAgC,CAAC,EACjCC,EAA8B,CAAC,EAE/BC,EAAiB5D,EAAK,UAAU,EAChC6D,EAAoB7D,EAAK,WAAWc,EAAa,CAAC,EAClDgD,EAAmB9D,EAAK,WAAWc,EAAa,CAAC,EACjDiD,EAAqB/D,EAAK,WAAWe,EAAc,CAAC,EACpDiD,EAAoBhE,EAAK,WAAWe,EAAc,CAAC,EAEzD,GAAI,CACF,CAACwC,EAAkBC,CAAgB,EAAIS,GAAc3D,CAAO,EAG5D,QAASa,GAAI,EAAGA,GAAIL,EAAYK,KAC9BxC,GAAyByE,EAAajC,EAAC,EAAGsC,EAAoBE,EAAmB9B,EAAWsB,EAAahC,EAAC,CAAC,EAI7G,QAASA,GAAI,EAAGA,GAAIJ,EAAaI,KAC/BxC,GACI2E,EAAcnC,EAAC,EAAGuC,EAAqBC,EAAmB9B,EAAWf,EAAauC,EAAclC,EAAC,CAAC,EAGxG,IAAI+C,EAAmBL,EAAoB,EACvCM,EAAkBL,EAAmB,EACrCM,EAAoBL,EAAqB,EACzCM,EAAmBL,EAAoB,EAC3C,QAAS7C,GAAI,EAAGA,GAAIL,EAAYK,KAC9BnB,EAAK,QAAQkE,GAAkB,EAAIT,EAAmBtC,EAAC,EACvDnB,EAAK,QAAQmE,GAAiB,EAAIxD,EAAsBwC,EAAahC,EAAC,CAAC,EAEzE,QAASA,GAAI,EAAGA,GAAIJ,EAAaI,KAC/BnB,EAAK,QAAQoE,GAAmB,EAAIV,EAAoBvC,EAAC,EACzDnB,EAAK,QAAQqE,GAAkB,EAAIzD,EAAuByC,EAAclC,EAAC,CAAC,EAG5E,GAAkCY,EAAgB,CAChD,GAAM,CAAC,OAAAuC,GAAQ,yBAAApD,GAA0B,gCAAAqD,CAA+B,EAAIxC,EAE5E,GAAIpB,EAAsB,SAAWG,EACnC,MAAM,IAAI,MAAM,2BACZA,CAAU,4DAA4DH,EAAsB,MAAM,IAAI,EAI5G,QAASQ,GAAI,EAAGA,GAAIL,EAAYK,KAAK,CACnC,IAAMe,GAAQiB,EAAahC,EAAC,EACV,MAAMnB,EAAK,cAAcsE,GAAQ3D,EAAsBuB,EAAK,EAAGuB,EAAmBtC,EAAC,CAAC,IACpF,GAChB1B,GAAe,oBAAoB0B,EAAC,iBAAiBU,CAAS,GAAG,CAErE,CAGA,QAASV,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMe,GAAQmB,EAAclC,EAAC,EACZmC,EAAcnC,EAAC,IAAI,CAAC,EAIjBnB,EAAK,eAAesE,GAAQ1D,EAAuBsB,EAAK,EAAGwB,EAAoBvC,EAAC,EAAG,CAAC,IACpF,GAChB1B,GAAe,mCAAmC0B,EAAC,iBAAiBU,CAAS,GAAG,EAK9E7B,EAAK,eAAesE,GAAQ1D,EAAuBsB,EAAK,EAAG,EAAGqC,EAAgCrC,EAAK,CAAC,IACtF,GAChBzC,GAAe,qBAAqB0B,EAAC,QAAQD,GAAyBC,EAAC,CAAC,gBAAgBU,CAAS,GAAG,CAG1G,CACF,CAEA,IAAI2C,EAE8BzC,EAChCyC,EAAY,MAAMxE,EAAK,mBACnBD,EAAegC,EAAe,OAAQhB,EAAagD,EAAoBR,CAAgB,EAE3FiB,EAAY,MAAMxE,EAAK,QACnBD,EAAe+D,EAAkBD,EAAmB/C,EAAYkD,EAAmBjD,EACnFgD,EAAoBR,CAAgB,EAGtCiB,IAAc,GAChB/E,GAAe,0BAA0B,EAG3C,IAAMgF,GAA2B,CAAC,EAElC,QAAStD,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMa,GAAShC,EAAK,QAAQ+D,EAAqB,EAAI5C,EAAC,EACtD,GAAIa,KAAW0B,EAAoBvC,EAAC,EAAG,CAErCsD,GAAO,KAAKnB,EAAcnC,EAAC,CAAE,EAC7B,QACF,CAEA,IAAMuD,EAA2B1E,EAAK,UAAU,EAE1C2E,GAAmB3E,EAAK,WAAW,EAAI,CAAC,EAE1C4E,GAAmB,GACnBC,GAA6B3E,GAAa,EAC9C,GAAI,CACgBF,EAAK,kBACnBgC,GAAQ2C,GAAkBA,GAAmB,EAAGA,GAAmB,EAAGA,GAAmB,EAAE,IAC7E,GAChBlF,GAAe,4CAA4C0B,EAAC,GAAG,EAEjE,IAAI2D,GAAkBH,GAAmB,EACnCxC,GAAWnC,EAAK,QAAQ8E,IAAiB,EAC/C5E,GAAaF,EAAK,QAAQ8E,IAAiB,EAC3C,IAAM9B,EAAahD,EAAK,QAAQ8E,IAAiB,EAC3CC,EAAa/E,EAAK,QAAQ8E,IAAiB,EAC3C1C,GAAO,CAAC,EACd,QAASjB,GAAI,EAAGA,GAAI4D,EAAY5D,KAC9BiB,GAAK,KAAKpC,EAAK,QAAQgD,EAAa,EAAI7B,EAAC,CAAC,EAE5CnB,EAAK,SAASgD,CAAU,EAExB,IAAMgC,GAAO5C,GAAK,OAAO,CAACO,GAAGC,KAAMD,GAAIC,GAAG,CAAC,EAC3CiC,GAAOI,GAA2B9C,EAAQ,EAE1C,IAAM+C,GAAoBnD,GAAgB,yBAAyBsB,EAAclC,EAAC,CAAC,EAEnF,GAAI0D,KAAS,SAAU,CACrB,GAAIK,KAAsB,aACxB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,IAAMC,GAAuB,CAAC,EAC1BrC,GAAY5C,GAAa,EAC7B,QAASiB,GAAI,EAAGA,GAAI6D,GAAM7D,KAAK,CAC7B,IAAMiE,GAASpF,EAAK,QAAQ8C,IAAW,EACjCuC,GAAiBlE,KAAM6D,GAAO,EAAI,OAAYhF,EAAK,QAAQ8C,EAAS,EAAIsC,GAC9ED,GAAW,KAAKnF,EAAK,aAAaoF,GAAQC,EAAc,CAAC,CAC3D,CACAZ,GAAO,KAAK,CAACI,GAAMzC,GAAM+C,GAAY,KAAK,CAAC,CAC7C,SAGMD,KAAsB,cAAgBF,GAAO,EAAG,CAClD,IAAMzC,GAAYvC,EAAK,cAAcE,EAAU,EACzCoF,GAAc7C,GAAqBN,EAAQ,EACjD,GAAImD,KAAgB,QAAa,CAACC,GAAyBV,EAAI,EAC7D,MAAM,IAAI,MAAM,0BAA0BA,EAAI,EAAE,EAIlDD,GAAmB,GAEnBH,GAAO,KAAK,CACVI,GAAMzC,GAAM,CACV,UAAAG,GACA,SAAUvC,EAAK,qBAAqBuC,GAAWyC,GAAOM,GAAaT,EAAI,EACvE,QAAS,IAAM,CACb7E,EAAK,kBAAkBgC,EAAM,CAC/B,CACF,EACA,YACF,CAAC,CACH,KAAO,CACL,IAAMwD,GAAwBC,GAAkCZ,EAAI,EAC9DhC,GAAO,IAAI2C,GAAsBR,EAAI,EAC3C,IAAI,WAAWnC,GAAK,OAAQA,GAAK,WAAYA,GAAK,UAAU,EACvD,IAAI7C,EAAK,OAAO,SAASE,GAAYA,GAAa2C,GAAK,UAAU,CAAC,EACvE4B,GAAO,KAAK,CAACI,GAAMzC,GAAMS,GAAM,KAAK,CAAC,CACvC,CAEJ,QAAE,CACA7C,EAAK,aAAa0E,CAAwB,EACtCG,KAAS,UAAY3E,IACvBF,EAAK,MAAME,EAAU,EAElB0E,IACH5E,EAAK,kBAAkBgC,EAAM,CAEjC,CACF,CAEA,OAAID,GACF/B,EAAK,sBAAsB+B,EAAe,MAAM,EAG3C0C,EACT,QAAE,CACAzE,EAAK,aAAa4D,CAAc,EAEhCH,EAAmB,QAAQiC,GAAK1F,EAAK,kBAAkB0F,CAAC,CAAC,EACzDhC,EAAoB,QAAQgC,GAAK1F,EAAK,kBAAkB0F,CAAC,CAAC,EAC1D/B,EAAkB,QAAQgC,GAAK3F,EAAK,MAAM2F,CAAC,CAAC,EAExCpC,IAAqB,GACvBvD,EAAK,sBAAsBuD,CAAgB,EAE7CC,EAAiB,QAAQmC,GAAK3F,EAAK,MAAM2F,CAAC,CAAC,CAC7C,CACF,EAKa9G,GAAgBgD,GAA4B,CACvD,IAAM7B,EAAOR,GAAY,EACnBsC,EAAUxD,GAAe,IAAIuD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,oBAAoB,EAEtC,IAAM/B,EAAgB+B,EAAQ,CAAC,EAGzB8D,EAAkB5F,EAAK,iBAAiBD,CAAa,EACvD6F,IAAoB,GACtBnG,GAAe,iCAAkC,EAEnDO,EAAK,SAAS4F,CAAe,CAC/B,EAEa9G,GAA8B+G,GAAsE,CAC/G,IAAMC,EAA6B,CAAC,EACpC,QAAW9D,KAAU6D,EAAS,CAC5B,IAAMhD,EAAOb,EAAO,CAAC,EACjB,CAAC,MAAM,QAAQa,CAAI,GAAK,WAAYA,GACtCiD,EAAQ,KAAKjD,EAAK,MAAM,CAE5B,CACA,OAAOiD,CACT,ICnnBA,IAAAC,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,mhpSCAA,IASMC,GACFC,GACAC,GACAC,GACAC,GAGAC,GACEC,GAEAC,GASAC,GAMAC,GA8BAC,GAEOC,GAsDAC,GAaAC,GAaAC,GAuBAC,GAaAC,GAyBAC,GA/MbC,GAAAC,EAAA,kBAGAC,KAGAC,KACAC,KAEMtB,GAAU,IAAe,CAAC,CAACuB,GAAI,KAAK,OAAS,OAAO,SAAa,IAEnErB,GAAe,GACfC,GAAc,GACdC,GAAU,GAIRE,GAAiF,IAAI,IAErFC,GAAmB,CAACiB,EAA8BC,IAA+C,CACrG,IAAMC,EAAQpB,GAAgB,IAAIkB,CAAI,EAClCE,EACFA,EAAM,KAAKD,CAAS,EAEpBnB,GAAgB,IAAIkB,EAAM,CAACC,CAAS,CAAC,CAEzC,EAEMjB,GAAe,IAAY,CAC/B,GAAIN,IAAgB,CAACC,IAAeC,IAAW,CAACH,GAC9C,MAAM,IAAI,MAAM,kBAAkB,CAEtC,EAEMQ,GAAwBkB,GAA2C,CACvE,OAAQA,EAAG,KAAK,KAAM,CACpB,IAAK,YACHzB,GAAe,GACXyB,EAAG,KAAK,KACVvB,GAAU,GACVC,GAAkB,CAAC,EAAEsB,EAAG,KAAK,GAAG,IAEhCxB,GAAc,GACdE,GAAkB,CAAC,EAAE,GAEvB,MACF,IAAK,UACL,IAAK,YACL,IAAK,SACL,IAAK,UACL,IAAK,MACL,IAAK,gBAAiB,CACpB,IAAMoB,EAAYnB,GAAgB,IAAIqB,EAAG,KAAK,IAAI,EAC9CA,EAAG,KAAK,IACVF,EAAU,MAAM,EAAG,CAAC,EAAEE,EAAG,KAAK,GAAG,EAEjCF,EAAU,MAAM,EAAG,CAAC,EAAEE,EAAG,KAAK,GAAI,EAEpC,KACF,CACA,QACF,CACF,EAEMjB,GAAY,OAAO,SAAa,IAAe,UAAU,eAAqC,IAAM,OAE7FC,GAAqC,SAA0B,CAC1E,GAAI,CAAAR,GAGJ,IAAID,GACF,MAAM,IAAI,MAAM,0CAA4C,EAE9D,GAAIE,GACF,MAAM,IAAI,MAAM,uCAAyC,EAK3D,GAFAF,GAAe,GAEuBF,GAAQ,EAE5C,OAAIuB,GAAI,KAAK,YAAc,QACrBb,IAAaA,GAAU,QAAQ,OAAO,IAAM,IAC9Ca,GAAI,KAAK,UAAYb,GAAU,OAAO,EAAG,CAAEA,GAAW,YAAY,GAAG,EAAI,CAAC,GAIvE,IAAI,QAAc,CAACkB,EAASC,IAAW,CAC5C5B,IAAa,UAAU,EAEvB,IAAM6B,EAAY,IAAI,gBAAgB,IAAI,KACtC,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAC9B7B,GAAc,IAAI,OAAO6B,EAAW,CAAC,KAAM,uBAAuB,CAAC,EACnE7B,GAAY,QAAW0B,GAAmBE,EAAOF,CAAE,EACnD1B,GAAY,UAAYQ,GACxB,IAAI,gBAAgBqB,CAAS,EAC7BzB,GAAoB,CAACuB,EAASC,CAAM,EACpC,IAAME,EAA0B,CAAC,KAAM,YAAa,GAAKR,EAAG,EAC5DtB,GAAY,YAAY8B,CAAO,CACjC,CAAC,EAGD,GAAI,CACF,MAAMC,GAAsBT,GAAI,IAAI,EACpC,MAAWU,GAAYV,EAAG,EAC1BpB,GAAc,EAChB,OAAS,EAAG,CACV,MAAAC,GAAU,GACJ,CACR,QAAE,CACAF,GAAe,EACjB,EAEJ,EAEaU,GAAkB,MAAMsB,GAAkC,CACrE,GAAsClC,GAAQ,EAC5C,OAAAQ,GAAa,EACN,IAAI,QAAc,CAACoB,EAASC,IAAW,CAC5CtB,GAAiB,UAAW,CAACqB,EAASC,CAAM,CAAC,EAC7C,IAAME,EAA0B,CAAC,KAAM,UAAW,GAAK,CAAC,OAAAG,EAAQ,IAAAX,EAAG,CAAC,EACpEtB,GAAa,YAAY8B,CAAO,CAClC,CAAC,EAED,MAAWI,GAAOZ,GAAKW,CAAM,CAEjC,EAEarB,GAAyB,MAAMuB,GACJpC,GAAQ,GAC5CQ,GAAa,EACN,IAAI,QAAoC,CAACoB,EAASC,IAAW,CAClEtB,GAAiB,YAAa,CAACqB,EAASC,CAAM,CAAC,EAC/C,IAAME,EAA0B,CAAC,KAAM,YAAa,GAAK,CAAC,OAAAK,CAAM,CAAC,EACjEnC,GAAa,YAAY8B,EAAS,CAACK,EAAO,MAAM,CAAC,CACnD,CAAC,GAEWvB,GAAuBuB,CAAM,EAIhCtB,GACT,MAAMuB,EAA8CC,IACR,CACtC,GAAsCtC,GAAQ,EAAG,CAE/C,GAAIsC,GAAS,wBACX,MAAM,IAAI,MAAM,sEAAsE,EAExF,OAAA9B,GAAa,EACN,IAAI,QAAqC,CAACoB,EAASC,IAAW,CACnEtB,GAAiB,SAAU,CAACqB,EAASC,CAAM,CAAC,EAC5C,IAAME,EAA0B,CAAC,KAAM,SAAU,GAAK,CAAC,MAAAM,EAAO,QAAAC,CAAO,CAAC,EAChEC,EAA+B,CAAC,EAClCF,aAAiB,YACnBE,EAAa,KAAKF,EAAM,MAAM,EAEhCpC,GAAa,YAAY8B,EAASQ,CAAY,CAChD,CAAC,CACH,KACE,QAAYzB,GAAcuB,EAAOC,CAAO,CAE5C,EAEKvB,GAAiB,MAAMyB,GAAqC,CACvE,GAAsCxC,GAAQ,EAC5C,OAAAQ,GAAa,EACN,IAAI,QAAc,CAACoB,EAASC,IAAW,CAC5CtB,GAAiB,UAAW,CAACqB,EAASC,CAAM,CAAC,EAC7C,IAAME,EAA0B,CAAC,KAAM,UAAW,GAAKS,CAAS,EAChEvC,GAAa,YAAY8B,CAAO,CAClC,CAAC,EAEIhB,GAAeyB,CAAS,CAEjC,EAEaxB,GAAM,MACfwB,EAAmBC,EAAwBC,EAA0BC,EACrEC,EAAqCN,IAAoE,CAC3G,GAAsCtC,GAAQ,EAAG,CAE/C,GAAI0C,EAAO,KAAKG,GAAKA,EAAE,CAAC,IAAM,KAAK,EACjC,MAAM,IAAI,MAAM,iDAAiD,EAGnE,GAAID,EAAQ,KAAKC,GAAKA,CAAC,EACrB,MAAM,IAAI,MAAM,yDAAyD,EAE3E,OAAArC,GAAa,EACN,IAAI,QAAsC,CAACoB,EAASC,IAAW,CACpEtB,GAAiB,MAAO,CAACqB,EAASC,CAAM,CAAC,EACzC,IAAMiB,EAAqBJ,EACrBX,EACF,CAAC,KAAM,MAAO,GAAK,CAAC,UAAAS,EAAW,aAAAC,EAAc,OAAQK,EAAoB,cAAAH,EAAe,QAAAL,CAAO,CAAC,EACpGrC,GAAa,YAAY8B,EAAcgB,GAA2BD,CAAkB,CAAC,CACvF,CAAC,CACH,KACE,QAAY9B,GAAIwB,EAAWC,EAAcC,EAAQC,EAAeC,EAASN,CAAO,CAEpF,EAEarB,GAAe,MAAMuB,GAAqC,CACrE,GAAsCxC,GAAQ,EAC5C,OAAAQ,GAAa,EACN,IAAI,QAAc,CAACoB,EAASC,IAAW,CAC5CtB,GAAiB,gBAAiB,CAACqB,EAASC,CAAM,CAAC,EACnD,IAAME,EAA0B,CAAC,KAAM,gBAAiB,GAAKS,CAAS,EACtEvC,GAAa,YAAY8B,CAAO,CAClC,CAAC,EAEId,GAAauB,CAAS,CAE/B,IC1NA,IAUaQ,GAWAC,GAiBAC,GAtCbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEaP,GAAuB,CAACQ,EAAgBC,IAA0C,CAC7F,OAAQD,EAAO,SAAU,CACvB,IAAK,MACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAMA,EAAO,KAAM,KAAK,EACtD,IAAK,aACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAC,UAAWA,EAAO,SAAS,EAAG,YAAY,EAC/E,QACE,MAAM,IAAI,MAAM,0BAA0BA,EAAO,QAAQ,QAAQC,EAAQ,CAAC,EAAE,CAChF,CACF,EAEaR,GAAwBO,GAAmC,CACtE,OAAQA,EAAO,CAAC,EAAG,CACjB,IAAK,MACH,OAAO,IAAIE,GAAOF,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,CAAC,EACnD,IAAK,aAAc,CACjB,IAAMG,EAAWH,EAAO,CAAC,EACzB,GAAI,CAACI,GAAyBD,CAAQ,EACpC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,+BAA+B,EAErF,GAAM,CAAC,UAAAE,EAAW,SAAAC,EAAU,QAAAC,CAAO,EAAIP,EAAO,CAAC,EAC/C,OAAOE,GAAO,cAAcG,EAAW,CAAC,SAAAF,EAAU,KAAMH,EAAO,CAAC,EAAG,SAAAM,EAAU,QAAAC,CAAO,CAAC,CACvF,CACA,QACE,MAAM,IAAI,MAAM,0BAA0BP,EAAO,CAAC,CAAC,EAAE,CACzD,CACF,EAEaN,GAAN,KAA8E,CAMnF,MAAM,8BAA8Bc,EAAmD,CAGrF,IAAMC,EAAW,MAAM,MAAMD,CAAI,EACjC,GAAIC,EAAS,SAAW,IACtB,MAAM,IAAI,MAAM,yBAAyBD,CAAI,EAAE,EAEjD,IAAME,EAAc,MAAMD,EAAS,YAAY,EAC/C,OAAOE,GAAuB,IAAI,WAAWD,CAAW,CAAC,CAC3D,CAEA,MAAM,UAAUE,EAAiCC,EAA0D,CACzGC,GAAiB,EACjB,IAAIC,EAEA,OAAOH,GAAiB,SACtB,OAAO,QAAY,KAAe,QAAQ,UAAY,QAAQ,SAAS,KAEzEG,EAAQ,KAAM,SAASH,CAAY,EAInCG,EAAQ,MAAM,KAAK,8BAA8BH,CAAY,EAG/DG,EAAQH,EAGV,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMI,GAAcD,EAAOF,CAAO,EACxFI,GAAe,CACjB,CAEA,MAAM,SAAyB,CAC7B,OAAOC,GAAe,KAAK,SAAS,CACtC,CAEA,MAAM,IAAIC,EAAiCC,EAAqCP,EACzC,CACrCC,GAAiB,EACjB,IAAMO,EAAuB,CAAC,EACxBC,EAAyB,CAAC,EAChC,OAAO,QAAQH,CAAK,EAAE,QAAQI,GAAO,CACnC,IAAMC,EAAOD,EAAI,CAAC,EACZvB,EAASuB,EAAI,CAAC,EACdE,EAAQ,KAAK,WAAW,QAAQD,CAAI,EAC1C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,kBAAkBD,CAAI,GAAG,EAE3CH,EAAW,KAAKrB,CAAM,EACtBsB,EAAa,KAAKG,CAAK,CACzB,CAAC,EAED,IAAMC,EAAkC,CAAC,EACnCC,EAA0B,CAAC,EACjC,OAAO,QAAQP,CAAO,EAAE,QAAQG,GAAO,CACrC,IAAMC,EAAOD,EAAI,CAAC,EACZvB,EAASuB,EAAI,CAAC,EACdE,EAAQ,KAAK,YAAY,QAAQD,CAAI,EAC3C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,mBAAmBD,CAAI,GAAG,EAE5CE,EAAY,KAAK1B,CAAM,EACvB2B,EAAc,KAAKF,CAAK,CAC1B,CAAC,EAED,IAAMG,EACFP,EAAW,IAAI,CAACQ,EAAGC,IAAMtC,GAAqBqC,EAAG,IAAM,UAAU,KAAK,WAAWP,EAAaQ,CAAC,CAAC,CAAC,GAAG,CAAC,EACnGC,EAAUL,EAAY,IACxB,CAACG,EAAGC,IAAMD,EAAIrC,GAAqBqC,EAAG,IAAM,WAAW,KAAK,YAAYF,EAAcG,CAAC,CAAC,CAAC,GAAG,EAAI,IAAI,EAElGE,EAAU,MAAMC,GAAI,KAAK,UAAWX,EAAcM,EAAQD,EAAeI,EAASlB,CAAO,EAEzFqB,EAAuC,CAAC,EAC9C,QAASJ,EAAI,EAAGA,EAAIE,EAAQ,OAAQF,IAClCI,EAAU,KAAK,YAAYP,EAAcG,CAAC,CAAC,CAAC,EAAIJ,EAAYI,CAAC,GAAKrC,GAAqBuC,EAAQF,CAAC,CAAC,EAEnG,OAAAb,GAAe,EACRiB,CACT,CAEA,gBAAuB,CAEvB,CAEA,cAAqB,CACdC,GAAa,KAAK,SAAS,CAClC,CACF,ICnIA,IAeaC,GAuBAC,GAtCbC,GAAAC,EAAA,kBAIAC,KAEAC,KACAC,KAQaN,GAAkB,IAAY,CAiBzC,IAhBI,OAAOO,GAAI,KAAK,aAAgB,UAAYA,GAAI,KAAK,YAAc,KACrEA,GAAI,KAAK,YAAc,GAGrB,OAAOA,GAAI,KAAK,MAAS,YAC3BA,GAAI,KAAK,KAAO,IAGd,OAAOA,GAAI,KAAK,OAAU,YAC5BA,GAAI,KAAK,MAAQ,IAGf,OAAOA,GAAI,KAAK,OAAU,YAC5BA,GAAI,KAAK,MAAQ,IAGf,OAAOA,GAAI,KAAK,YAAe,UAAY,CAAC,OAAO,UAAUA,GAAI,KAAK,UAAU,GAAKA,GAAI,KAAK,YAAc,EAAG,CACjH,IAAMC,EAAqB,OAAO,UAAc,IAAc,SAAK,EAAE,OAAS,UAAU,oBACxFD,GAAI,KAAK,WAAa,KAAK,IAAI,EAAG,KAAK,MAAMC,GAAsB,GAAK,CAAC,CAAC,CAC5E,CACF,EAEaP,GAAN,KAAuD,CAS5D,MAAM,KAAKQ,EAAoC,CAE7CT,GAAgB,EAGhB,MAAMU,GAAmC,EAGzC,MAAMC,GAAgBF,CAAW,CACnC,CAKA,MAAM,8BAA8BG,EAAiCC,EAChC,CACnC,IAAMC,EAAU,IAAIC,GACpB,aAAMD,EAAQ,UAAUF,EAAcC,CAAO,EACtC,QAAQ,QAAQC,CAAO,CAChC,CACF,ICnEA,IAAAE,GAAA,GAAAC,GAAAD,GAAA,iBAAAE,KAAA,IAIaA,GAJbC,GAAAC,EAAA,kBAGAC,KACaH,GAAc,IAAII,KCI/BC,KACAA,KAGAA,KCNO,IAAMC,GAAU,SDIvB,IAAOC,GAAQC,GAUe,CAC5B,IAAMC,EAA4C,cAAoC,YAGpFC,GAAgB,SAAUD,EAAa,CAAC,EAE1CC,GAAgB,MAAOD,EAAa,EAAE,EACtCC,GAAgB,OAAQD,EAAa,EAAE,EAErCC,GAAgB,UAAWD,EAAa,CAAC,CAK7C,CAEA,OAAO,eAAeE,GAAI,SAAU,MAAO,CAAC,MAAOC,GAAS,WAAY,EAAI,CAAC",
  "names": ["backends", "backendsSortedByPriority", "registerBackend", "resolveBackend", "init_backend_impl", "__esmMin", "name", "backend", "priority", "currentBackend", "i", "backendHints", "backendNames", "errors", "backendName", "backendInfo", "isInitializing", "e", "init_backend", "__esmMin", "init_backend_impl", "version", "init_version", "__esmMin", "logLevelValue", "env", "init_env_impl", "__esmMin", "init_version", "version", "value", "env", "init_env", "__esmMin", "init_env_impl", "tensorToDataURL", "tensorToImageData", "init_tensor_conversion_impl", "__esmMin", "tensor", "options", "canvas", "pixels2DContext", "width", "height", "inputformat", "norm", "normMean", "normBias", "stride", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "j", "R", "G", "B", "A", "image", "channels", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "bufferToTensor", "tensorFromImage", "tensorFromTexture", "tensorFromGpuBuffer", "tensorFromPinnedBuffer", "init_tensor_factory_impl", "__esmMin", "init_tensor_impl", "buffer", "options", "height", "width", "norm", "normMean", "normBias", "inputformat", "outputformat", "stride", "float32Data", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "Tensor", "image", "isHTMLImageEle", "isImageDataEle", "isImageBitmap", "isString", "data", "bufferToTensorOptions", "canvas", "pixels2DContext", "tempCanvas", "resolve", "reject", "context", "newImage", "img", "texture", "download", "dispose", "dims", "gpuBuffer", "dataType", "type", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "isBigIntChecked", "checkBigInt", "init_tensor_impl_type_mapping", "__esmMin", "isBigInt64ArrayAvailable", "isBigUint64ArrayAvailable", "calculateSize", "tensorReshape", "init_tensor_utils_impl", "__esmMin", "init_tensor_impl", "dims", "size", "i", "dim", "tensor", "Tensor", "Tensor", "init_tensor_impl", "__esmMin", "init_tensor_conversion_impl", "init_tensor_factory_impl", "init_tensor_impl_type_mapping", "init_tensor_utils_impl", "arg0", "arg1", "arg2", "checkBigInt", "type", "dims", "expectedTypedArrayConstructor", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "data", "maybeDims", "typedArrayConstructor", "firstElementType", "mappedType", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "size", "calculateSize", "image", "options", "tensorFromImage", "texture", "tensorFromTexture", "gpuBuffer", "tensorFromGpuBuffer", "buffer", "tensorFromPinnedBuffer", "tensorToDataURL", "tensorToImageData", "releaseData", "tensorReshape", "Tensor", "init_tensor", "__esmMin", "init_tensor_impl", "TRACE", "TRACE_FUNC", "TRACE_FUNC_BEGIN", "TRACE_FUNC_END", "init_trace", "__esmMin", "init_env_impl", "deviceType", "label", "env", "msg", "extraMsg", "stack", "hasTraceFunc", "i", "InferenceSession", "init_inference_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "init_trace", "_InferenceSession", "handler", "feeds", "arg1", "arg2", "TRACE_FUNC_BEGIN", "fetches", "options", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "TRACE_FUNC_END", "arg0", "arg3", "filePathOrUint8Array", "buffer", "byteOffset", "byteLength", "backendHints", "i", "resolveBackend", "InferenceSession", "init_inference_session", "__esmMin", "init_inference_session_impl", "init_onnx_value", "__esmMin", "noBackendErrMsg", "TrainingSession", "init_training_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_TrainingSession", "handler", "hasOptimizerModel", "hasEvalModel", "trainingOptions", "sessionOptions", "evalModel", "optimizerModel", "options", "backendHints", "i", "backend", "resolveBackend", "inputNames", "outputNames", "feeds", "arg1", "arg2", "fetches", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "trainableOnly", "array", "paramsSize", "TrainingSession", "init_training_session", "__esmMin", "init_training_session_impl", "esm_exports", "__export", "InferenceSession", "TRACE", "TRACE_FUNC_BEGIN", "TRACE_FUNC_END", "Tensor", "TrainingSession", "env", "registerBackend", "init_esm", "__esmMin", "init_backend", "init_env", "init_inference_session", "init_tensor", "init_trace", "init_onnx_value", "init_training_session", "fs_exports", "__export", "readFile", "init_fs", "__esmMin", "path_exports", "__export", "join", "init_path", "__esmMin", "require_ort_wasm_simd_jsep", "__commonJSMin", "exports", "module", "ortWasm", "_scriptDir", "moduleArg", "d", "aa", "k", "a", "b", "c", "e", "f", "h", "l", "r", "m", "p", "n", "u", "w", "t", "g", "q", "ba", "ca", "x", "y", "da", "z", "ea", "A", "B", "C", "D", "fs", "fa", "ha", "E", "F", "noExitRuntime", "H", "I", "J", "K", "L", "M", "N", "O", "P", "ia", "ja", "ka", "la", "ma", "na", "oa", "Q", "pa", "R", "qa", "S", "ra", "sa", "ta", "ua", "va", "T", "wa", "U", "v", "xa", "ya", "za", "Aa", "Ba", "Ca", "Da", "Ea", "Fa", "V", "Ga", "Ha", "Ja", "Ia", "Ka", "La", "Na", "Pa", "Oa", "Qa", "Ra", "Sa", "Ta", "Ua", "Ma", "G", "W", "Va", "X", "Y", "Wa", "Xa", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "kb", "jb", "lb", "mb", "nb", "ob", "Z", "pb", "qb", "require_worker_threads", "__commonJSMin", "require_perf_hooks", "__commonJSMin", "os_exports", "__export", "cpus", "init_os", "__esmMin", "require_ort_wasm_simd_threaded_jsep", "__commonJSMin", "exports", "module", "ortWasmThreaded", "_scriptDir", "moduleArg", "d", "l", "p", "t", "v", "aa", "z", "ba", "A", "ca", "da", "ea", "fa", "ha", "B", "ia", "C", "a", "b", "c", "e", "f", "h", "k", "q", "m", "n", "r", "w", "y", "D", "g", "u", "ja", "ka", "la", "E", "ma", "F", "G", "H", "I", "na", "oa", "J", "pa", "fs", "qa", "ra", "sa", "ta", "K", "L", "noExitRuntime", "M", "N", "ua", "P", "Q", "va", "wa", "xa", "ya", "za", "Aa", "R", "Ba", "S", "Ca", "Da", "Ea", "T", "Fa", "Ga", "Ha", "Ia", "U", "Ja", "V", "x", "Ka", "La", "Ma", "W", "Na", "Oa", "Pa", "Qa", "X", "Sa", "Ra", "Ta", "Ua", "Va", "Wa", "Xa", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "jb", "kb", "lb", "mb", "nb", "ob", "pb", "qb", "rb", "sb", "tb", "ub", "vb", "wb", "xb", "Y", "yb", "zb", "Ab", "Bb", "Db", "Cb", "Eb", "Fb", "Hb", "Gb", "Ib", "Jb", "Kb", "Lb", "Nb", "Mb", "Ob", "Pb", "Qb", "Rb", "Sb", "Tb", "Vb", "Wb", "Xb", "Yb", "Zb", "$b", "Ub", "O", "ac", "bc", "cc", "Z", "dc", "ec", "fc", "gc", "hc", "ic", "jc", "kc", "lc", "mc", "nc", "oc", "pc", "qc", "rc", "sc", "vc", "tc", "uc", "wc", "xc", "yc", "zc", "require_ort_wasm_threaded_worker", "__commonJSMin", "exports", "module", "ortWasmFactory", "ortWasmFactoryThreaded", "wasm", "initialized", "initializing", "aborted", "isMultiThreadSupported", "isSimdSupported", "getWasmFileName", "initializeWebAssembly", "getInstance", "init_wasm_factory", "__esmMin", "useSimd", "useThreads", "flags", "timeout", "numThreads", "simd", "wasmPaths", "wasmPrefixOverride", "wasmFileName", "wasmPathOverride", "isTimeout", "tasks", "resolve", "reject", "factory", "config", "fileName", "scriptDirectory", "prefix", "scriptSourceCode", "module", "what", "allocWasmString", "iterateExtraOptions", "checkLastError", "init_wasm_utils", "__esmMin", "init_wasm_factory", "data", "allocs", "wasm", "getInstance", "dataLength", "dataOffset", "options", "prefix", "seen", "handler", "key", "value", "name", "message", "stack", "paramsOffset", "errorCode", "errorMessagePointer", "errorMessage", "setRunOptions", "init_run_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "options", "wasm", "getInstance", "runOptionsHandle", "allocs", "runOptions", "tagDataOffset", "allocWasmString", "checkLastError", "iterateExtraOptions", "key", "value", "keyDataOffset", "valueDataOffset", "e", "alloc", "getGraphOptimzationLevel", "getExecutionMode", "appendDefaultOptions", "setExecutionProviders", "setSessionOptions", "init_session_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "graphOptimizationLevel", "executionMode", "options", "session", "ep", "sessionOptionsHandle", "executionProviders", "allocs", "epName", "webnnOptions", "keyDataOffset", "allocWasmString", "valueDataOffset", "getInstance", "checkLastError", "numThreads", "webgpuOptions", "epNameDataOffset", "wasm", "sessionOptions", "logIdDataOffset", "logSeverityLevel", "logVerbosityLevel", "optimizedModelFilePathOffset", "name", "value", "nameOffset", "iterateExtraOptions", "key", "e", "alloc", "tensorDataTypeStringToEnum", "tensorDataTypeEnumToString", "getTensorElementSize", "tensorTypeToTypedArrayConstructor", "logLevelStringToEnum", "isGpuBufferSupportedType", "dataLocationStringToEnum", "init_wasm_common", "__esmMin", "type", "typeProto", "dateType", "logLevel", "location", "logLevelPrefix", "doLog", "configLogLevel", "debug", "configureLogger", "LOG", "LOG_DEBUG", "init_log", "__esmMin", "init_wasm_common", "level", "message", "$configLogLevel", "$debug", "logLevel", "msg", "messageLevel", "logLevelStringToEnum", "configLevel", "args", "createView", "init_tensor_view", "__esmMin", "init_wasm_common", "dataBuffer", "type", "tensorTypeToTypedArrayConstructor", "init_types", "__esmMin", "calcNormalizedBufferSize", "guid", "createNewGpuDataId", "downloadGpuData", "GpuDataManagerImpl", "createGpuDataManager", "init_gpu_data_manager", "__esmMin", "init_log", "init_types", "size", "backend", "gpuBuffer", "originalSize", "getTargetBuffer", "bufferSize", "gpuReadBuffer", "commandEncoder", "arrayBuffer", "targetBuffer", "id", "data", "srcArrayBuffer", "srcOffset", "srcLength", "gpuDataCache", "gpuBufferForUploading", "LOG_DEBUG", "sourceId", "destinationId", "sourceGpuDataCache", "destinationGpuDataCache", "buffer", "previousBuffer", "usage", "isStorage", "isUniform", "freeBuffers", "buffers", "gpuData", "cachedData", "storage", "args", "AttributeWithCacheKeyImpl", "createAttributeWithCacheKey", "init_attribute_with_cache_key", "__esmMin", "attribute", "name", "MatMulUtil", "BroadcastUtil", "ShapeUtil", "PoolConvUtil", "GemmUtil", "MIN_CLIP", "MAX_CLIP", "init_util", "__esmMin", "a", "b", "adims", "bdims", "isMatMul", "arank", "brank", "crank", "cdims", "cShapeMatMul", "aLen", "bLen", "shape", "finalShape", "inputRank", "finalRank", "i", "_ShapeUtil", "dims", "axis", "start", "end", "size", "rank", "strides", "tensorRank", "axes", "x", "perm", "v", "pad", "shape1", "shape2", "_PoolConvUtil", "isGlobalOperator", "inputDims", "kernelShape", "dilations", "pads", "dim", "isChannelLast", "autoPad", "outputDims", "filterDims", "inSize", "stride", "dilation", "kernel", "padHeadIndex", "padTailIndex", "dkernel", "padNeeded", "leftShape", "transLeft", "rightShape", "transRight", "biasShape", "M", "K", "N", "kDim", "WORKGROUP_SIZE", "getWgslMappedType", "tensorTypeToWsglStorageType", "tensorTypeToWsglValueType", "createTensorShapeVariables", "getMaxComponents", "fillVector", "castToF32", "sumVector", "getElementAt", "createIndicesHelper", "inputVariable", "outputVariable", "internalVariable", "ShaderHelperImpl", "createShaderHelper", "getBroadcastDims", "enableShapesUniforms", "init_common", "__esmMin", "init_wasm_common", "init_util", "type", "components", "mappedType", "dims", "ShapeUtil", "size", "dataType", "value", "name", "index", "length", "tensorType", "shapeOrRank", "usage", "useUniform", "rank", "rankIdentity", "indicesType", "valueType", "storageType", "normalizeDim", "dim", "implementationUsed", "uniformPrefix", "shape", "strides", "o2iSnippet", "i", "offsetToIndicesImplementation", "offsetToIndices", "varOffset", "offsets", "indicesToOffsetImplementation", "indicesToOffset", "varIndices", "indices", "init", "indicesGet", "idx", "indicesSet", "broadcastedIndicesToOffsetImplementation", "broadcastedIndicesToOffset", "output", "implKey", "setByOffset", "offset", "getByOffset", "getByIndicesImplementation", "getImplementation", "functionParams", "dimsParams", "get", "normalizedIndices", "getByIndices", "setByIndicesImplementation", "setImplementation", "impls", "needShapeStrides", "impl", "indicesAndValue", "normalizedDispatchGroup", "workgroupSize", "workgroupSizeX", "workgroupSizeY", "workgroupSizeZ", "is1DimensionDispatch", "paramList", "globalIdxDefinition", "variable", "bindingIndex", "access", "variables", "v", "additionalUniforms", "uniformSnippets", "typeTemp", "dispatchGroup", "inShape", "outShape", "inRank", "a", "_rank", "validateInputs", "getAdjustedPerm", "getOutputShape", "permFunctionBody", "createTransposeProgramInfo", "transpose", "parseTransposeAttributes", "init_transpose", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputRank", "perm", "inputShape", "ShapeUtil", "rank", "input", "output", "reverseFunc", "i", "inputTensor", "permAttr", "inputDataType", "useShapesUniforms", "enableShapesUniforms", "outputShape", "outShapeOrRank", "inShapeOrRank", "outputVariable", "inputVariable", "getShaderSource", "shaderHelper", "outputSize", "createTensorShapeVariables", "context", "attributes", "createAttributeWithCacheKey", "reduceOps", "reduceSharedOps", "reduceInitValues", "reduceOutputValues", "getInnerMostAxes", "computeOutAndReduceShapes", "expandShapeToKeepDim", "areAxesInnerMostDims", "getAxesPermutation", "createReduceSharedProgramInfo", "reduceCommon", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "init_reduce_shared", "__esmMin", "init_util", "init_common", "init_reduce", "init_transpose", "numInnerAxes", "rank", "res", "i", "shape", "axes", "outputShape", "dim", "reduceShape", "expandShape", "shapeIdx", "axis", "name", "shaderCache", "inputs", "reduceType", "outputDataType", "inputShape", "outputSize", "ShapeUtil", "reduceSize", "input", "inputVariable", "output", "outputVariable", "workgroupSize", "sharedMemorySnippet", "shaderHelper", "context", "attributes", "updatedAttributes", "createReduceAttributesFromInputs", "updatedAxes", "_dim", "normalizeAxes", "permutedAxes", "createTransposeProgramInfo", "finalOutputShape", "validateInputs", "noOp", "createReduceProgramInfo", "createReduceAttributesFromInputs", "runReduceProgram", "reduceLogSumNaive", "reduceL1Naive", "reduceL2Naive", "reduceLogSumExpNaive", "reduceMaxNaive", "reduceMeanNaive", "reduceMinNaive", "reduceProdNaive", "reduceSumNaive", "reduceSumSquareNaive", "useNaiveReduceMethod", "reduceMean", "reduceL1", "reduceL2", "reduceLogSumExp", "reduceMax", "reduceMin", "reduceProd", "reduceSum", "reduceSumSquare", "reduceLogSum", "init_reduce", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "init_reduce_shared", "inputs", "input", "name", "shaderCache", "reduceOp", "axesInput", "outputDataType", "keepDims", "noopWithEmptyAxes", "outputShape", "inputShape", "inputRank", "axes", "ShapeUtil", "reduceOnAllAxes", "d", "i", "outputRank", "outputSize", "shaderHelper", "idxCopy", "inputVariable", "output", "outputVariable", "ops", "reduceOps", "k", "l", "createTensorShapeVariables", "attributes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "_output", "idxZero", "size", "shape", "reduceSize", "dim", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "validateInputs", "argMin", "argMax", "parseArgMinMaxAttributes", "init_argminmax", "__esmMin", "init_wasm_common", "init_attribute_with_cache_key", "init_reduce", "inputs", "context", "attributes", "argMinMaxOp", "input", "output", "axes", "idxZero", "k", "createReduceProgramInfo", "createAttributeWithCacheKey", "validateAttentionInputs", "computeInPlaceSoftmax", "computeAttentionProbs", "computeVxAttentionScore", "applyAttention", "prepare", "attention", "init_attention", "__esmMin", "init_wasm_common", "init_types", "init_common", "inputs", "attributes", "input", "weights", "bias", "maskIndex", "past", "relativePositionBias", "batchSize", "sequenceLength", "inputHiddenSize", "qHiddenSize", "kHiddenSize", "vHiddenSize", "sz", "kvSequenceLength", "pastSequenceLength", "totalSequenceLength", "maxSequenceLength", "maskType", "context", "n", "d", "components", "getMaxComponents", "WG", "dComp", "elementsPerWG", "programUniforms", "tensorDataTypeEnumToString", "dataType", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "inputHelper", "outputVariable", "threadMaxValue", "elemValueType", "tensorTypeToWsglValueType", "uniforms", "fillVector", "castToF32", "sumVector", "q", "key", "_bias", "parameters", "probsShape", "alpha", "vectorizedHeadSize", "TILE_SIZE", "dispatch", "tensorDataType", "qInput", "inputVariable", "kInput", "output", "probs", "v", "params", "outputShape", "probsHelper", "vHelper", "k", "_maskIndex", "_past", "_pastKey", "_pastValue", "M", "K", "N", "outputQ", "outputK", "outputV", "weight", "validateInputs", "createBatchNormInferenceProgramInfo", "parseBatchNormAttributes", "batchNorm", "init_batch_norm", "__esmMin", "init_esm", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "checkShapeEqual", "actual", "expected", "message", "r", "v", "shape", "epsilon", "spatial", "format", "yShape", "components", "getMaxComponents", "cComponents", "outputSize", "ShapeUtil", "useShapesUniforms", "enableShapesUniforms", "shapeOrRank", "x", "inputVariable", "scale", "bias", "inputMean", "inputVar", "y", "outputVariable", "calcCOffset", "cOffset", "i", "getInferenceModeShaderSource", "helper", "createTensorShapeVariables", "createAttributeWithCacheKey", "context", "outputCount", "updatedAttributes", "env", "validateInputs", "createBiasAddProgramInfo", "biasAdd", "init_bias_add", "__esmMin", "init_util", "init_common", "inputs", "outputShape", "channels", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "bias", "residual", "output", "outputVariable", "shaderHelper", "context", "createElementwiseProgramShader", "createElementwiseProgramInfo", "abs", "acos", "acosh", "asin", "asinh", "atan", "atanh", "parseCastAttributes", "cast", "generateClipAttributesFromInputs", "clip", "ceil", "cos", "cosh", "parseAlphaAttributes", "elu", "erfImpl", "erf", "exp", "floor", "gelu", "leakyRelu", "not", "neg", "reciprocal", "relu", "sigmoid", "sin", "sinh", "sqrt", "tan", "tanh", "thresholdedRelu", "log", "init_unary_op", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "shaderHelper", "datasize", "inputDataType", "outputDataType", "funcCall", "additionalImplementation", "vecSize", "expression", "input", "inputVariable", "output", "outputVariable", "name", "cacheKey", "ShapeUtil", "inputTensors", "context", "attributes", "createAttributeWithCacheKey", "func", "inputs", "min", "MIN_CLIP", "max", "MAX_CLIP", "clipAttributes", "dataType", "tensorTypeToWsglValueType", "a", "varType", "validateInputs", "createBiasSplitGeluProgramInfo", "biasSplitGelu", "init_bias_split_gelu", "__esmMin", "init_util", "init_common", "init_unary_op", "inputs", "outputShape", "input", "inputVariable", "bias", "output", "outputVariable", "outputSize", "ShapeUtil", "dataType", "tensorTypeToWsglStorageType", "shaderHelper", "erfImpl", "context", "createBinaryOpProgramShader", "createBinaryOpProgramInfo", "runBinaryOp", "add", "div", "equal", "mul", "pow", "sub", "greater", "less", "greaterOrEqual", "lessOrEqual", "init_binary_op", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "dimsA", "dimsB", "dimsOutput", "vectorize", "doBroadcast", "sharedDimensionDivisibleBy4", "funcCall", "typeA", "typeB", "typeOutput", "useShapesUniforms", "additionalImplementation", "expressionScalar", "expressionVector", "a", "b", "inputAShapeOrRank", "inputBShapeOrRank", "outputShapeOrRank", "output", "outputVariable", "inputVariable", "assignment", "isAOneElement", "ShapeUtil", "isBOneElement", "aLastDimDivisibleBy4", "bLastDimDivisibleBy4", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "name", "cacheKey", "outputDataType", "isBroadcast", "outputShape", "outputSize", "cacheKeyAux", "calculatedShape", "BroadcastUtil", "sharedDimension", "i", "dimA", "dimB", "enableShapesUniforms", "createTensorShapeVariables", "context", "type", "validateInputs", "calculateInputIndexImpl", "assignOutputData", "createConcatProgramInfo", "concat", "parseConcatAttributes", "init_concat", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputType", "inputDimensionality", "input", "numberOfTensors", "sizeInConcatAxisStr", "output", "codeLines", "i", "returnSnippet", "axis", "inputShape", "adjustedAxis", "outputShape", "dataNShape", "axisIndex", "outputSize", "ShapeUtil", "sizeInConcatAxis", "inputVars", "dataType", "previousSum", "inputDependencies", "inputShapeOrRanks", "enableInputShapesUniforms", "programUniforms", "enableShapesUniforms", "inputVariable", "createTensorShapeVariables", "enableOutputShapesUniforms", "outputShapeOrRank", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "attributes", "createAttributeWithCacheKey", "getActivationSnippet", "parseInternalActivationAttributes", "init_fuse_utils", "__esmMin", "init_util", "attributes", "valueType", "activation", "clipMin", "clipMax", "MIN_CLIP", "MAX_CLIP", "typeSnippet", "biasSnippet", "init_activation_util", "__esmMin", "component", "dataType", "hasBias", "utilFunctions", "init_conv_util", "__esmMin", "strideStr", "writeDataToSubAVec4Snippet", "calculateResultSnippet", "makeMatMulPackedVec4Source", "writeDataToSubASnippet", "readDataFromSubASnippet", "makeMatMulPackedSource", "matMulReadWriteFnSource", "createMatmulProgramInfo", "init_matmul_packed_webgpu", "__esmMin", "init_util", "init_common", "init_fuse_utils", "init_activation_util", "transpose", "batchDims", "transposeA", "innerElementSize", "workPerThread", "workgroupSize", "type", "tileInner", "splitK", "splitedDimInner", "tileAOuter", "tileBOuter", "tileAWidth", "tileAHight", "rowPerThreadB", "sequentialAccessByThreads", "rowPerThreadA", "colPerThreadA", "matmulSnippet", "component", "hasBias", "applyActivation", "variables", "batchShapes", "isChannelsLast", "batchAShape", "batchBShape", "batchShape", "batchVariable", "aVariable", "bVariable", "outputVariable", "broadCastADims", "getBroadcastDims", "broadCastBDims", "dataType", "tensorTypeToWsglStorageType", "getAIndices", "aRank", "batchRank", "resStr", "i", "j", "getBIndices", "bRank", "typeSnippet", "inputs", "activationAttributes", "outputShape", "reshapedOutputShape", "aShape", "bShape", "outerDimsA", "outerDimsB", "outerDims", "enableBatchUniforms", "enableShapesUniforms", "batchShapeOrRank", "internalVariable", "batchSize", "ShapeUtil", "dimAOuter", "dimInner", "dimBOuter", "isVec4", "elementsPerThread", "dispatch", "components", "aShapeTemp", "enableAShapesUniforms", "aShapeOrRank", "bShapeTemp", "enableBShapesUniforms", "bShapeOrRank", "outputShapeTemp", "A", "inputVariable", "B", "output", "inputVariables", "programUniforms", "createTensorShapeVariables", "inputDependencies", "activationFunction", "getActivationSnippet", "declareFunctions", "biasComponents", "getShaderSource", "shaderHelper", "conv2dCommonSnippet", "createConv2DMatMulProgramInfo", "init_conv2d_mm_webgpu", "__esmMin", "init_log", "init_common", "init_fuse_utils", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "fitAOuter", "fitBOuter", "fitInner", "addBias", "attributes", "innerElementSizeX", "innerElementSizeW", "innerElementSize", "dataType", "getXSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readXSnippet", "typeSnippet", "sampleX", "sampleW", "resType", "aType", "bType", "activationFunction", "applyActivation", "getActivationSnippet", "biasSnippet", "inputs", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileAOuter", "tileBOuter", "tileInner", "elementsSize", "t", "tensorTypeToWsglStorageType", "components", "programUniforms", "x", "inputVariable", "w", "inputVariables", "createTensorShapeVariables", "declareFunctions", "bias", "output", "outputVariable", "shaderHelper", "utilFunctions", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createGroupedConvProgramInfo", "init_conv_grouped", "__esmMin", "init_util", "init_common", "init_conv", "init_fuse_utils", "inputs", "attributes", "squeezeOutputShapeFunction", "hasBias", "processBias", "xShape", "wShape", "outputChannelsPerGroup", "isChannelLast", "outputShape", "calculateOutputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "activationFunction", "applyActivation", "getActivationSnippet", "x", "inputVariable", "w", "inputVars", "getShaderSource", "shaderHelper", "createNaiveMatmulProgramInfo", "validateInputs", "matMul", "init_matmul", "__esmMin", "init_util", "init_matmul_packed_webgpu", "init_common", "init_fuse_utils", "inputs", "activationAttributes", "outputShape", "reshapedOutputShape", "isChannelsLast", "aShape", "bShape", "M", "N", "K", "components", "getMaxComponents", "aComponents", "outputNumber", "outputSize", "ShapeUtil", "hasBias", "outerDims", "outputShapeInShader", "programUniforms", "createTensorShapeVariables", "getShaderSource", "shaderHelper", "batchDims", "internalVariable", "a", "inputVariable", "b", "output", "outputVariable", "activationFunction", "applyActivation", "getActivationSnippet", "inputVariables", "processBias", "biasComponents", "outerDimsA", "outerDimsB", "broadCastADims", "getBroadcastDims", "broadCastBDims", "getIndices", "variable", "broadCastDims", "rank", "name", "batchRank", "resStr", "i", "j", "calcResult", "calcStr", "context", "BroadcastUtil", "createMatmulProgramInfo", "calculateOutputShape", "weightTransposeAttribute", "validateInputs", "getAdjustedConvAttributes", "parseConvAttributes", "conv2d", "conv1d", "conv", "init_conv", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_conv2d_mm_webgpu", "init_matmul_packed_webgpu", "init_conv_grouped", "init_fuse_utils", "init_matmul", "init_transpose", "inputShape", "kernelShape", "dilations", "adjustPads", "strides", "isChannelLast", "batchSize", "inputSpatialShape", "spatialRank", "outChannels", "dilatedKernelShape", "v", "i", "outputShape", "inputs", "attributes", "dataChannel", "filterInChannel", "pads", "PoolConvUtil", "newAttributes", "activationAttributes", "parseInternalActivationAttributes", "format", "autoPad", "group", "wIsConst", "createAttributeWithCacheKey", "context", "adjustedAttributes", "createGroupedConvProgramInfo", "isChannelsLast", "hasBias", "inputHeight", "inputWidth", "inputChannels", "weightHeight", "weightWidth", "outHeight", "outWidth", "sameSize", "batch", "xReshaped", "wReshaped", "matmulOutputShape", "matmulInputs", "transposedWeight", "createTransposeProgramInfo", "sharedDim", "N", "K", "createNaiveMatmulProgramInfo", "createMatmulProgramInfo", "sequentialAccessByThreads", "convInputs", "dimAOuter", "dimBOuter", "dimInner", "createConv2DMatMulProgramInfo", "conv2dTransposeCommonSnippet", "createConv2DTransposeMatMulProgramInfo", "init_conv_backprop_mm_webgpu", "__esmMin", "init_log", "init_common", "init_fuse_utils", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "addBias", "attributes", "innerElementSize", "type", "typeSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readASnippet", "sampleA", "sampleW", "activationFunction", "applyActivation", "getActivationSnippet", "biasSnippet", "inputs", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileInner", "components", "programUniforms", "x", "inputVariable", "w", "output", "outputVariable", "inputVariables", "createTensorShapeVariables", "declareFunctions", "bias", "shaderHelper", "utilFunctions", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createConvTranspose2DOpProgramShaderSource", "createConvTranspose2DProgramInfo", "init_conv_backprop_webgpu", "__esmMin", "init_log", "init_util", "init_common", "shaderHelper", "inputs", "attributes", "outputShape", "hasBias", "is1DimensionDispatch", "isVec4", "dataType", "isChannelsLast", "rowDim", "colDim", "channelDim", "outputSize", "ShapeUtil", "workPerThread", "group", "wShape", "inputChannelsPerGroup", "outputChannelsPerGroup", "declareFunctions", "components", "w", "inputVariable", "dy", "inputVariables", "output", "outputVariable", "codeSnippet4", "codeSnippet", "squeezeOutputShapeFunction", "dispatch", "LOG_DEBUG", "tensorTypeToWsglStorageType", "computeTotalPad", "distributePadding", "calculateOutputShapeAndPads", "getAdjustedConvTransposeAttributes", "parseConvTransposeAttributes", "validateInputs", "weightTransposePerm", "convTranspose2d", "convTranspose1d", "convTranspose", "init_conv_transpose", "__esmMin", "init_attribute_with_cache_key", "init_conv_backprop_mm_webgpu", "init_conv_backprop_webgpu", "init_fuse_utils", "init_transpose", "inDim", "stride", "adj", "kernel", "dilation", "outSize", "totalPad", "autoPad", "pads", "head", "tail", "smallPad", "inputShape", "kernelShape", "dilations", "group", "strides", "isChannelLast", "outputPadding", "outputShape", "spatialRank", "updateOutputShape", "i", "batchSize", "outChannels", "j", "inSize", "attributes", "inputs", "a", "b", "isChannelsLast", "newAttributes", "cacheKey", "activationAttributes", "parseInternalActivationAttributes", "format", "wIsConst", "createAttributeWithCacheKey", "dataChannel", "filterInChannel", "featureMaps", "context", "adjustedAttributes", "inputChannels", "createConvTranspose2DProgramInfo", "outHeight", "outWidth", "weightHeight", "weightWidth", "dimAOuter", "dimBOuter", "dimInner", "sequentialAccessByThreads", "transposedWeight", "createTransposeProgramInfo", "convTransposeInputs", "hasBias", "createConv2DTransposeMatMulProgramInfo", "createCumsumProgramInfo", "cumsum", "parseCumSumAttributes", "init_cumsum", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputType", "inputShape", "axisInput", "attributes", "outputSize", "ShapeUtil", "rank", "input", "inputVariable", "output", "outputVariable", "axisValue", "axis", "getShaderSource", "shaderHelper", "index", "max", "getElementAt", "lowerLimit", "upperLimit", "createTensorShapeVariables", "context", "exclusive", "reverse", "createAttributeWithCacheKey", "symbolPattern", "termPattern", "termPatternOnly", "lhsPattern", "lhsPatternOnly", "EinsumTerm", "EinsumEquation", "appendMax", "createEinsumProgramInfo", "einsum", "parseEinsumAttributes", "init_einsum", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputIndex", "symbol", "index", "value", "inputs", "equation", "lhs", "rhs", "inputTerm", "dims", "einsumTerm", "sym", "info", "dimValue", "term", "isInput", "rank", "ellipsis", "ellipsisDims", "nextDim", "indexSymbols", "i", "ellipsisDimLength", "j", "name", "enableInputShapesUniforms", "inputShapes", "dataType", "einsumEquation", "outputShape", "inputVars", "shapeOrRank", "inputVariable", "outputSize", "ShapeUtil", "enableOutputShapesUniforms", "enableShapesUniforms", "outputShapeOrRank", "output", "outputVariable", "uniformsSymbols", "getShaderSource", "shaderHelper", "idxCopy", "initProd", "initSum", "updateSum", "reduceOpsSetIndices", "reduceOpsLoopHeaders", "reduceOpsLoopFooters", "reduceOpCompute", "isReduceOpsWithoutLoop", "outputIndex", "indices", "reduceOps", "inputVar", "_var", "enableShapeUniform", "programUniformsInit", "programUniforms", "_", "createTensorShapeVariables", "acc", "inputProgramUniforms", "context", "attributes", "input", "createAttributeWithCacheKey", "validateInputs", "getAdjustedShape", "calculateOutputShape", "createExpandProgramInfo", "expand", "init_expand", "__esmMin", "init_wasm_common", "init_util", "init_common", "inputs", "inputShape", "shape", "shapeIndex", "inputShapeIndex", "shape1", "shape2", "diff", "i", "outputShape", "dataType", "components", "outputSize", "ShapeUtil", "enableInputShapeUniform", "enableShapesUniforms", "enableOutputShapeUniform", "getShaderSource", "shaderHelper", "inputShapeOrRank", "outputShapeOrRank", "input", "inputVariable", "output", "outputVariable", "assignment", "singleAssignment", "resStr", "x", "typeCast", "programUniforms", "createTensorShapeVariables", "context", "validateInputs", "createGatherProgramInfo", "parseGatherAttributes", "gather", "init_gather", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "indicesShape", "inputRank", "axis", "ShapeUtil", "outputShape", "axisDimLimit", "components", "outputSize", "enableInputShapesUniforms", "enableShapesUniforms", "inputShapeOrRank", "enableIndicesShapesUniforms", "indicesShapeOrRank", "enableOutputShapesUniforms", "outputShapeOrRank", "programUniforms", "createTensorShapeVariables", "inputDependencies", "getShaderSource", "shaderHelper", "data", "inputVariable", "indices", "output", "outputVariable", "calcDataIndices", "x", "indicesRank", "calcStr", "i", "j", "assignment", "singleAssignment", "resStr", "typeCast", "createAttributeWithCacheKey", "context", "validateInputs", "createGatherElementsProgramInfo", "parseGatherElementsAttributes", "gatherElements", "init_gather_elements", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "inputOutputDataType", "inputRank", "indicesShape", "indicesDataType", "axis", "ShapeUtil", "axisDimLimit", "outputShape", "outputSize", "input", "inputVariable", "indices", "output", "outputVariable", "programUniforms", "createTensorShapeVariables", "shaderHelper", "createAttributeWithCacheKey", "context", "validateInputs", "createGemmProgramInfo", "parseGemmAttributes", "gemm", "init_gemm", "__esmMin", "init_util", "init_common", "inputs", "attributes", "aShape", "bShape", "M", "N", "K", "GemmUtil", "outputShape", "outputSize", "ShapeUtil", "programUniforms", "inputDependencies", "createTensorShapeVariables", "getShaderSource", "shaderHelper", "line", "calculateAlpha", "a", "inputVariable", "b", "dataType", "c", "variables", "output", "outputVariable", "uniforms", "transA", "transB", "alpha", "beta", "context", "createInstanceNormProgramInfo", "computeMean", "createInstanceNormNHWCProgramInfo", "instanceNorm", "init_instance_norm", "__esmMin", "init_wasm_common", "init_util", "init_common", "inputs", "attributes", "xShape", "outputShape", "axis", "normCount", "ShapeUtil", "normSize", "components", "getMaxComponents", "normPackedSize", "inputShape", "inputDependencies", "programUniforms", "createTensorShapeVariables", "getShaderSource", "shaderHelper", "x", "inputVariable", "scale", "bias", "output", "outputVariable", "variables", "dataType", "f32Type", "workgroupSize", "uniforms", "sumVector", "context", "input", "h", "c", "epsilon", "WG", "outputType", "sumCastType", "setOutputValue", "var1", "var2", "unitsOfWork", "wgSize", "meanInputDependencies", "meanProgramUniforms", "getMeanShaderSource", "inputHelper", "fillVector", "meanValues", "scaleHelper", "biasHelper", "N", "C", "H", "outputSize", "channelScaleShift", "tensorTypeToWsglStorageType", "scaleType", "scaleCastType", "outputHelper", "validateInputs", "createLayerNormProgramInfo", "layerNorm", "init_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_common", "inputs", "attributes", "outputCount", "xShape", "scale", "bias", "outputShape", "axis", "ShapeUtil", "normCount", "normSize", "scaleSize", "biasSize", "meanInvStdDevDim", "i", "components", "getMaxComponents", "inputDependencies", "programUniforms", "hasMeanDataOutput", "hasInvStdOutput", "getShaderSource", "shaderHelper", "dataType", "tensorTypeToWsglStorageType", "variables", "inputVariable", "outputVariable", "uniforms", "fillVector", "castToF32", "sumVector", "outputs", "context", "validateInputs", "parseMultiHeadAttentionAttributes", "weightTransposeAttribute", "addBiasTranspose", "maybeTransposeToBNSHAndAddBias", "multiHeadAttention", "init_multi_head_attentiion", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_types", "init_attention", "init_common", "init_transpose", "inputs", "attributes", "query", "key", "value", "bias", "keyPaddingMask", "relativePositionBias", "pastKey", "pastValue", "dmmhaPacking", "batchSize", "sequenceLength", "hiddenSize", "kvSequenceLength", "pastSequenceLength", "maxSequenceLength", "headSize", "qkvFormat", "maskType", "maskDims", "passPastInKv", "vHiddenSize", "totalSequenceLength", "broadcastResPosBias", "createAttributeWithCacheKey", "context", "qkv", "biasOffset", "outputShape", "outputSize", "ShapeUtil", "programUniforms", "getShaderSource", "shaderHelper", "output", "outputVariable", "qkvInput", "inputVariable", "biasInput", "uniforms", "numHeads", "input", "reshapedInput", "createTransposeProgramInfo", "params", "kvBNSH", "Q", "applyAttention", "K", "V", "validateInputs", "getPadConstant", "getPadReflect", "getPadEdge", "getPadWrap", "getPadSnippet", "createPadProgramInfo", "createPadAttributesFromInputs", "pad", "init_pad", "__esmMin", "init_wasm_common", "init_util", "init_common", "inputs", "validPads", "output", "inputRank", "padsLength", "block", "i", "getElementAt", "attributes", "outputShape", "ShapeUtil", "inputDims", "programUniforms", "tensorDataType", "tensorDataTypeEnumToString", "createTensorShapeVariables", "inputDependencies", "getShaderSource", "shaderHelper", "outputVariable", "input", "inputVariable", "dataType", "padSnippet", "uniforms", "bigInt64Pads", "value", "updatePads", "axes", "v", "pads", "context", "updatedAttributes", "validateInputs", "getAdjustedPoolAttributesAndOutputShape", "getUniformAndPadInfo", "generatePoolingCode", "createShaderKeyFromAttributes", "createAveragePoolShaderKeyFromAttributes", "createMaxPoolShaderKeyFromAttributes", "parsePoolCommonAttributes", "createAveragePoolProgramInfo", "parseAveragePoolAttributes", "averagePool", "globalPoolAttributes", "parseGlobalAveragePoolAttributes", "globalAveragePool", "createMaxPoolProgramInfo", "maxPool", "parseMaxPoolAttributes", "parseGlobalMaxPoolAttributes", "globalMaxPool", "init_pool", "__esmMin", "init_esm", "init_util", "init_common", "inputs", "env", "input", "attributes", "isGlobalOperator", "isChannelsLast", "inputShapeAsChannelFirst", "hasDilations", "kernelShape", "strides", "dilations", "pads", "PoolConvUtil", "outputShapeAsChannelFirst", "newAttributes", "outputShapeAsChannelLast", "outputShape", "outputSize", "ShapeUtil", "kernelSize", "programUniforms", "uniforms", "kw", "sw", "pwStart", "pwEnd", "pwStartEndNotZero", "phStartEndNotZero", "kh", "sh", "phStart", "phEnd", "kernelStrides", "hasPads", "sum", "cur", "shaderHelper", "x", "rank", "outputShapeRank", "op1", "op2", "start", "dataType", "output", "outputVariable", "codeW", "codeH", "codeHEnd", "dimIdxW", "dimIdxH", "stridesRank", "padsRank", "padCode", "getElementAt", "name", "adjustedAttributes", "inputVariable", "createTensorShapeVariables", "inputDependencies", "countIncludePad", "attr", "averagePoolAttributes", "context", "format", "storageOrder", "maxPoolAttributes", "validateInputsContent", "createRangeProgramInfo", "range", "init_range", "__esmMin", "init_esm", "init_wasm_common", "init_common", "start", "limit", "delta", "sameStartLimit", "increasingRangeNegativeStep", "decreasingRangePositiveStep", "dataType", "numElements", "outputShape", "outputSize", "tensorDataType", "tensorDataTypeEnumToString", "programUniforms", "createTensorShapeVariables", "getShaderSource", "shaderHelper", "output", "outputVariable", "wgslType", "uniforms", "context", "env", "validateScales", "updateScales", "validateInputs", "getOriginalCoordinateFromResizedCoordinate", "getNearestPixelFromOriginal", "updateRoI", "initOutputShape", "adjustOutputShape", "calculateOriginalIndicesFromOutputIndices", "calculateInputIndicesFromOutputIndices", "checkInputIndices", "setChannelAndBatchIndices", "bilinearInterpolation", "bicubicInterpolation", "trilinearInterpolation", "createResizeProgramInfo", "getOpsetVersionFromCustomDataBuffer", "resize", "parseResizeAttributes", "init_resize", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "scales", "attributes", "value", "axes", "rank", "newScales", "index", "inputs", "opsetVersion", "sizes", "roi", "roiInputIndex", "scalesInputIndex", "sizesInputIndex", "coordinateTransferMode", "dType", "nearestMode", "roiTmp", "roiLocal", "v", "i", "inputShape", "outputShape", "scaleInPolicy", "adjustedOutputShape", "output", "scalesLength", "roiLength", "getElementAt", "input", "useExtrapolation", "channelIdx", "batchIdx", "spacialDims", "extrapolationValue", "heightIdx", "widthIdx", "cubicCoeffA", "excludeOutside", "is2D", "isNchw", "createCubicInterpolationFunction", "idx", "direction", "depthIdx", "inputTensor", "scalesInput", "roiInput", "outputVariable", "inputVariable", "outputSize", "ShapeUtil", "noScale", "d", "dataType", "getShaderSource", "shaderHelper", "createTensorShapeVariables", "context", "customDataBuffer", "antialias", "coordinateTransformMode", "keepAspectRatioPolicy", "mode", "createAttributeWithCacheKey", "validateInputs", "createSkipLayerNormProgramInfo", "skipLayerNorm", "parseSkipLayerNormAttributes", "init_skip_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "skip", "gamma", "hiddenSize", "sequenceLength", "beta", "bias", "attributes", "outputCount", "isTraining", "inputShape", "inputSize", "ShapeUtil", "outputShape", "outputSize", "meanInvStdDevDim", "hasBetaInput", "hasBiasInput", "hasMeanOutput", "hasInvStdDevOutput", "hasInputSkipBiasSumOutput", "components", "getMaxComponents", "variables", "inputVariable", "outputVariable", "dataType", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "outputs", "context", "epsilon", "createAttributeWithCacheKey", "validateInputs", "readInput", "createSliceAttributesFromInputs", "fixStartEndValues", "calculateInputIndicesImpl", "createSliceProgramInfo", "slice", "parseSliceAttributes", "init_slice", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "_", "idx", "input", "v", "starts", "ends", "axes", "createAttributeWithCacheKey", "value", "index", "inputShape", "steps", "newValue", "output", "getElementAt", "inputSize", "ShapeUtil", "step", "start", "i", "end", "signs", "array", "numSteps", "newEnd", "newStart", "outputShape", "axis", "outputTensorInfo", "outputVariable", "inputVariable", "outputSize", "uniforms", "programUniforms", "createTensorShapeVariables", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "validateInputs", "createSoftmaxProgramInfo", "softmax", "parseSoftmaxAttributes", "init_softmax", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "shape", "outputSize", "ShapeUtil", "WG", "axis", "cols", "rows", "components", "getMaxComponents", "packedCols", "maxVector", "name", "x", "inputVariable", "output", "outputVariable", "valueType", "threadMaxDecl", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "sumVector", "context", "createAttributeWithCacheKey", "validateInputs", "createSplitAttributesFromInputs", "calculateOutputIndexImpl", "writeBufferDataImpl", "createSplitProgramInfo", "split", "parseSplitAttributes", "init_split", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "splitSizes", "numOutputs", "v", "createAttributeWithCacheKey", "numberOfTensors", "getElementAt", "outputs", "codeLines", "i", "returnSnippet", "inputShape", "inputSize", "ShapeUtil", "dataType", "axis", "input", "inputVariable", "sizeInSplitAxis", "outputsTensorInfo", "outputShapes", "previousSum", "programUniforms", "outputShape", "outputVariable", "createTensorShapeVariables", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "getRepeats", "validateInputs", "getOutputShape", "createTileProgramInfo", "tile", "init_tile", "__esmMin", "init_wasm_common", "init_util", "init_common", "repeatsTensorView", "inputs", "inputShape", "repeats", "outputShape", "i", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "createTensorShapeVariables", "context", "createWhereOpProgramShader", "createWhereOpProgramInfo", "where", "init_where", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "inputs", "dimsOutput", "isBroadcast", "typeOutput", "output", "outputVariable", "a", "inputVariable", "b", "c", "assignment", "expression", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "expressionC", "dimsA", "dimsB", "dimsC", "outputDataType", "ShapeUtil", "outputShape", "outputSize", "vecSize", "calculatedShape", "BroadcastUtil", "createTensorShapeVariables", "context", "WEBGPU_OP_RESOLVE_RULES", "init_op_resolve_rules", "__esmMin", "init_argminmax", "init_attention", "init_batch_norm", "init_bias_add", "init_bias_split_gelu", "init_binary_op", "init_concat", "init_conv", "init_conv_transpose", "init_cumsum", "init_einsum", "init_expand", "init_gather", "init_gather_elements", "init_gemm", "init_instance_norm", "init_layer_norm", "init_matmul", "init_multi_head_attentiion", "init_pad", "init_pool", "init_range", "init_reduce", "init_resize", "init_skip_layer_norm", "init_slice", "init_softmax", "init_split", "init_tile", "init_transpose", "init_unary_op", "init_where", "abs", "acos", "acosh", "add", "argMax", "parseArgMinMaxAttributes", "argMin", "asin", "asinh", "atan", "atanh", "attention", "averagePool", "parseAveragePoolAttributes", "batchNorm", "biasAdd", "biasSplitGelu", "cast", "parseCastAttributes", "ceil", "clip", "concat", "parseConcatAttributes", "conv", "parseConvAttributes", "convTranspose", "parseConvTransposeAttributes", "cos", "cosh", "cumsum", "parseCumSumAttributes", "div", "einsum", "parseEinsumAttributes", "elu", "parseAlphaAttributes", "equal", "erf", "exp", "expand", "floor", "gather", "parseGatherAttributes", "gatherElements", "parseGatherElementsAttributes", "gelu", "gemm", "parseGemmAttributes", "globalAveragePool", "parseGlobalAveragePoolAttributes", "globalMaxPool", "parseGlobalMaxPoolAttributes", "greater", "greaterOrEqual", "instanceNorm", "layerNorm", "leakyRelu", "less", "lessOrEqual", "log", "matMul", "maxPool", "parseMaxPoolAttributes", "mul", "multiHeadAttention", "parseMultiHeadAttentionAttributes", "neg", "not", "pad", "pow", "range", "reciprocal", "reduceMin", "reduceMean", "reduceMax", "reduceSum", "reduceProd", "reduceL1", "reduceL2", "reduceLogSum", "reduceLogSumExp", "reduceSumSquare", "relu", "resize", "parseResizeAttributes", "sigmoid", "sin", "sinh", "slice", "parseSliceAttributes", "skipLayerNorm", "parseSkipLayerNormAttributes", "split", "parseSplitAttributes", "sqrt", "softmax", "parseSoftmaxAttributes", "sub", "tan", "tanh", "thresholdedRelu", "tile", "transpose", "parseTransposeAttributes", "where", "ProgramManager", "init_program_manager", "__esmMin", "init_esm", "init_wasm_common", "init_log", "init_common", "backend", "key", "artifact", "buildArtifact", "inputTensorViews", "outputTensorViews", "inputs", "outputs", "dispatchGroup", "uniformBufferBinding", "TRACE_FUNC_BEGIN", "device", "computePassEncoder", "entries", "input", "output", "bindGroup", "syncData", "kernelId", "kernelInfo", "mappedData", "startTimeU64", "endTimeU64", "kernelType", "kernelName", "startTime", "endTime", "value", "tensorDataTypeEnumToString", "inputShapes", "i", "outputShapes", "TRACE_FUNC_END", "programInfo", "normalizedDispatchGroupSize", "extensions", "shaderHelper", "createShaderHelper", "userCode", "code", "shaderModule", "LOG_DEBUG", "computePipeline", "x", "y", "z", "limitPerDimension", "size", "dispatchAverage", "getProgramInputTensorInfoDependencyKey", "getProgramInfoUniqueKey", "WebGpuBackend", "init_backend_webgpu", "__esmMin", "init_esm", "init_log", "init_tensor_view", "init_gpu_data_manager", "init_op_resolve_rules", "init_program_manager", "inputTensors", "inputDependencies", "inputInfos", "i", "type", "rank", "dims", "programInfo", "is1DimensionDispatch", "key", "data", "env", "adapter", "requiredFeatures", "deviceDescriptor", "createGpuDataManager", "ProgramManager", "configureLogger", "ev", "computePassDescriptor", "program", "inputTensorViews", "outputIndices", "createKernelOutput", "createIntermediateOutput", "TRACE_FUNC_BEGIN", "inputDatas", "gpuData", "outputs", "dispatchGroup", "programUniforms", "validatedOutputIndices", "_", "outputTensorViews", "outputDatas", "isTemporary", "isPersistent", "tensorView", "persistentData", "uniformBufferBinding", "currentOffset", "offsets", "v", "baseAlignment", "maxAlignmentOfField", "arrayBuffer", "offset", "uniformBufferData", "normalizedDispatchGroup", "artifact", "LOG_DEBUG", "TRACE_FUNC_END", "gpuDataId", "src", "dst", "getTargetBuffer", "size", "ptr", "opType", "kernelId", "attribute", "nodeName", "op", "WEBGPU_OP_RESOLVE_RULES", "context", "errors", "kernel", "kernelEntry", "attributes", "useErrorScope", "e", "err", "sessionId", "index", "buffer", "sessionInputOutputMapping", "previousBuffer", "id", "bufferInfo", "gpuBuffer", "downloadGpuData", "createView", "init_exports", "__export", "init", "TensorViewImpl", "ComputeContextImpl", "init_init", "__esmMin", "init_wasm_common", "init_backend_webgpu", "init_log", "init_util", "_TensorViewImpl", "module", "dataType", "data", "dims", "elementCount", "ShapeUtil", "newDims", "backend", "contextDataOffset", "heapU32", "dataIndex", "inputCount", "inputs", "dim", "d", "program", "inputsOutputsMapping", "mappedInputs", "i", "outputIndices", "createKernelOutput", "index", "createTemporaryOutput", "elementSize", "getTensorElementSize", "bufferSize", "stack", "offset", "e", "env", "gpuAdapter", "jsepInit", "WebGpuBackend", "size", "ptr", "src", "dst", "isSourceGpu", "LOG_DEBUG", "gpuDataId", "dataOffset", "name", "kernel", "attribute", "sessionHandle", "errors", "context", "initOrt", "initRuntime", "initEp", "activeSessions", "getSessionInputOutputCount", "copyFromExternalBuffer", "createSession", "releaseSession", "prepareInputOutputTensor", "run", "endProfiling", "extractTransferableBuffers", "init_wasm_core_impl", "__esmMin", "init_run_options", "init_session_options", "init_wasm_common", "init_wasm_factory", "init_wasm_utils", "numThreads", "loggingLevel", "getInstance", "checkLastError", "env", "logLevelStringToEnum", "epName", "adapter", "initJsep", "sessionHandle", "wasm", "stack", "dataOffset", "model", "modelDataOffset", "modelData", "options", "modelDataLength", "sessionOptionsHandle", "ioBindingHandle", "allocs", "inputNamesUTF8Encoded", "outputNamesUTF8Encoded", "setSessionOptions", "inputCount", "outputCount", "inputNames", "outputNames", "outputPreferredLocations", "i", "name", "nameString", "location", "bindingState", "l", "dataLocationStringToEnum", "e", "buf", "alloc", "sessionId", "session", "ioBindingState", "tensor", "tensorHandles", "index", "dataType", "dims", "rawData", "dataByteLength", "gpuBuffer", "elementSizeInBytes", "getTensorElementSize", "tensorDataTypeStringToEnum", "a", "b", "data", "dataIndex", "allocWasmString", "dimsOffset", "dimIndex", "d", "inputIndices", "inputTensors", "outputIndices", "outputTensors", "runOptionsHandle", "runOptionsAllocs", "inputTensorHandles", "outputTensorHandles", "inputOutputAllocs", "beforeRunStack", "inputValuesOffset", "inputNamesOffset", "outputValuesOffset", "outputNamesOffset", "setRunOptions", "inputValuesIndex", "inputNamesIndex", "outputValuesIndex", "outputNamesIndex", "handle", "outputPreferredLocationsEncoded", "errorCode", "output", "beforeGetTensorDataStack", "tensorDataOffset", "keepOutputTensor", "type", "tensorDataIndex", "dimsLength", "size", "tensorDataTypeEnumToString", "preferredLocation", "stringData", "offset", "maxBytesToRead", "elementSize", "isGpuBufferSupportedType", "typedArrayConstructor", "tensorTypeToTypedArrayConstructor", "v", "p", "profileFileName", "tensors", "buffers", "require_main", "__commonJSMin", "exports", "module", "isProxy", "proxyWorker", "initializing", "initialized", "aborted", "initWasmCallbacks", "queuedCallbacks", "enqueueCallbacks", "ensureWorker", "onProxyWorkerMessage", "scriptSrc", "initializeWebAssemblyAndOrtRuntime", "initializeOrtEp", "copyFromExternalBuffer", "createSession", "releaseSession", "run", "endProfiling", "init_proxy_wrapper", "__esmMin", "init_esm", "init_wasm_core_impl", "init_wasm_factory", "env", "type", "callbacks", "queue", "ev", "resolve", "reject", "workerUrl", "message", "initializeWebAssembly", "initRuntime", "epName", "initEp", "buffer", "model", "options", "transferable", "sessionId", "inputIndices", "inputs", "outputIndices", "outputs", "t", "serializableInputs", "extractTransferableBuffers", "encodeTensorMetadata", "decodeTensorMetadata", "OnnxruntimeWebAssemblySessionHandler", "init_session_handler_inference", "__esmMin", "init_esm", "init_proxy_wrapper", "init_wasm_common", "tensor", "getName", "Tensor", "dataType", "isGpuBufferSupportedType", "gpuBuffer", "download", "dispose", "path", "response", "arrayBuffer", "copyFromExternalBuffer", "pathOrBuffer", "options", "TRACE_FUNC_BEGIN", "model", "createSession", "TRACE_FUNC_END", "releaseSession", "feeds", "fetches", "inputArray", "inputIndices", "kvp", "name", "index", "outputArray", "outputIndices", "inputs", "t", "i", "outputs", "results", "run", "resultMap", "endProfiling", "initializeFlags", "OnnxruntimeWebAssemblyBackend", "init_backend_wasm", "__esmMin", "init_esm", "init_proxy_wrapper", "init_session_handler_inference", "env", "numCpuLogicalCores", "backendName", "initializeWebAssemblyAndOrtRuntime", "initializeOrtEp", "pathOrBuffer", "options", "handler", "OnnxruntimeWebAssemblySessionHandler", "backend_wasm_inference_exports", "__export", "wasmBackend", "init_backend_wasm_inference", "__esmMin", "init_backend_wasm", "OnnxruntimeWebAssemblyBackend", "init_esm", "version", "lib_default", "esm_exports", "wasmBackend", "registerBackend", "env", "version"]
}
