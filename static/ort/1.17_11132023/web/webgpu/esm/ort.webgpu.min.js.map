{
  "version": 3,
  "sources": ["../../node_modules/onnxruntime-common/lib/backend-impl.ts", "../../node_modules/onnxruntime-common/lib/backend.ts", "../../node_modules/onnxruntime-common/lib/version.ts", "../../node_modules/onnxruntime-common/lib/env-impl.ts", "../../node_modules/onnxruntime-common/lib/env.ts", "../../node_modules/onnxruntime-common/lib/tensor-conversion-impl.ts", "../../node_modules/onnxruntime-common/lib/tensor-factory-impl.ts", "../../node_modules/onnxruntime-common/lib/tensor-impl-type-mapping.ts", "../../node_modules/onnxruntime-common/lib/tensor-utils-impl.ts", "../../node_modules/onnxruntime-common/lib/tensor-impl.ts", "../../node_modules/onnxruntime-common/lib/tensor.ts", "../../node_modules/onnxruntime-common/lib/inference-session-impl.ts", "../../node_modules/onnxruntime-common/lib/inference-session.ts", "../../node_modules/onnxruntime-common/lib/onnx-value.ts", "../../node_modules/onnxruntime-common/lib/training-session-impl.ts", "../../node_modules/onnxruntime-common/lib/training-session.ts", "../../node_modules/onnxruntime-common/lib/index.ts", "nodejs-ignore:fs", "nodejs-ignore:path", "../../lib/wasm/binding/ort-wasm-simd.jsep.js", "nodejs-ignore:worker_threads", "nodejs-ignore:perf_hooks", "nodejs-ignore:os", "../../lib/wasm/binding/ort-wasm-simd-threaded.jsep.js", "../../lib/wasm/binding/ort-wasm-threaded.worker.js", "../../lib/wasm/wasm-factory.ts", "../../lib/wasm/wasm-utils.ts", "../../lib/wasm/run-options.ts", "../../lib/wasm/session-options.ts", "../../lib/wasm/wasm-common.ts", "../../lib/wasm/jsep/log.ts", "../../lib/wasm/jsep/tensor-view.ts", "../../lib/wasm/jsep/webgpu/types.ts", "../../lib/wasm/jsep/webgpu/gpu-data-manager.ts", "../../lib/wasm/jsep/webgpu/attribute-with-cache-key.ts", "../../lib/wasm/jsep/util.ts", "../../lib/wasm/jsep/webgpu/ops/common.ts", "../../lib/wasm/jsep/webgpu/ops/transpose.ts", "../../lib/wasm/jsep/webgpu/ops/reduce-shared.ts", "../../lib/wasm/jsep/webgpu/ops/reduce.ts", "../../lib/wasm/jsep/webgpu/ops/argminmax.ts", "../../lib/wasm/jsep/webgpu/ops/bias-add.ts", "../../lib/wasm/jsep/webgpu/ops/unary-op.ts", "../../lib/wasm/jsep/webgpu/ops/bias-split-gelu.ts", "../../lib/wasm/jsep/webgpu/ops/binary-op.ts", "../../lib/wasm/jsep/webgpu/ops/concat.ts", "../../lib/wasm/jsep/webgpu/ops/fuse-utils.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/activation_util.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_util.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/matmul_packed_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv2d_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-grouped.ts", "../../lib/wasm/jsep/webgpu/ops/conv.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_mm_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_webgpu.ts", "../../lib/wasm/jsep/webgpu/ops/conv-transpose.ts", "../../lib/wasm/jsep/webgpu/ops/einsum.ts", "../../lib/wasm/jsep/webgpu/ops/expand.ts", "../../lib/wasm/jsep/webgpu/ops/gather.ts", "../../lib/wasm/jsep/webgpu/ops/gather-elements.ts", "../../lib/wasm/jsep/webgpu/ops/gemm.ts", "../../lib/wasm/jsep/webgpu/ops/instance-norm.ts", "../../lib/wasm/jsep/webgpu/ops/layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/matmul.ts", "../../lib/wasm/jsep/webgpu/ops/pad.ts", "../../lib/wasm/jsep/webgpu/ops/pool.ts", "../../lib/wasm/jsep/webgpu/ops/range.ts", "../../lib/wasm/jsep/webgpu/ops/resize.ts", "../../lib/wasm/jsep/webgpu/ops/skip-layer-norm.ts", "../../lib/wasm/jsep/webgpu/ops/slice.ts", "../../lib/wasm/jsep/webgpu/ops/softmax.ts", "../../lib/wasm/jsep/webgpu/ops/split.ts", "../../lib/wasm/jsep/webgpu/ops/tile.ts", "../../lib/wasm/jsep/webgpu/ops/where.ts", "../../lib/wasm/jsep/webgpu/op-resolve-rules.ts", "../../lib/wasm/jsep/webgpu/program-manager.ts", "../../lib/wasm/jsep/backend-webgpu.ts", "../../lib/wasm/jsep/init.ts", "../../lib/wasm/wasm-core-impl.ts", "proxy-worker:./proxy-worker/main", "../../lib/wasm/proxy-wrapper.ts", "../../lib/wasm/session-handler-inference.ts", "../../lib/backend-wasm.ts", "../../lib/backend-wasm-inference.ts", "../../lib/index.ts", "../../lib/version.ts"],
  "sourcesContent": ["// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Backend} from './backend.js';\n\ninterface BackendInfo {\n  backend: Backend;\n  priority: number;\n\n  initPromise?: Promise<void>;\n  initialized?: boolean;\n  aborted?: boolean;\n}\n\nconst backends: Map<string, BackendInfo> = new Map();\nconst backendsSortedByPriority: string[] = [];\n\n/**\n * Register a backend.\n *\n * @param name - the name as a key to lookup as an execution provider.\n * @param backend - the backend object.\n * @param priority - an integer indicating the priority of the backend. Higher number means higher priority. if priority\n * < 0, it will be considered as a 'beta' version and will not be used as a fallback backend by default.\n *\n * @ignore\n */\nexport const registerBackend = (name: string, backend: Backend, priority: number): void => {\n  if (backend && typeof backend.init === 'function' && typeof backend.createInferenceSessionHandler === 'function') {\n    const currentBackend = backends.get(name);\n    if (currentBackend === undefined) {\n      backends.set(name, {backend, priority});\n    } else if (currentBackend.priority > priority) {\n      // same name is already registered with a higher priority. skip registeration.\n      return;\n    } else if (currentBackend.priority === priority) {\n      if (currentBackend.backend !== backend) {\n        throw new Error(`cannot register backend \"${name}\" using priority ${priority}`);\n      }\n    }\n\n    if (priority >= 0) {\n      const i = backendsSortedByPriority.indexOf(name);\n      if (i !== -1) {\n        backendsSortedByPriority.splice(i, 1);\n      }\n\n      for (let i = 0; i < backendsSortedByPriority.length; i++) {\n        if (backends.get(backendsSortedByPriority[i])!.priority <= priority) {\n          backendsSortedByPriority.splice(i, 0, name);\n          return;\n        }\n      }\n      backendsSortedByPriority.push(name);\n    }\n    return;\n  }\n\n  throw new TypeError('not a valid backend');\n};\n\n/**\n * Resolve backend by specified hints.\n *\n * @param backendHints - a list of execution provider names to lookup. If omitted use registered backends as list.\n * @returns a promise that resolves to the backend.\n *\n * @ignore\n */\nexport const resolveBackend = async(backendHints: readonly string[]): Promise<Backend> => {\n  const backendNames = backendHints.length === 0 ? backendsSortedByPriority : backendHints;\n  const errors = [];\n  for (const backendName of backendNames) {\n    const backendInfo = backends.get(backendName);\n    if (backendInfo) {\n      if (backendInfo.initialized) {\n        return backendInfo.backend;\n      } else if (backendInfo.aborted) {\n        continue;  // current backend is unavailable; try next\n      }\n\n      const isInitializing = !!backendInfo.initPromise;\n      try {\n        if (!isInitializing) {\n          backendInfo.initPromise = backendInfo.backend.init();\n        }\n        await backendInfo.initPromise;\n        backendInfo.initialized = true;\n        return backendInfo.backend;\n      } catch (e) {\n        if (!isInitializing) {\n          errors.push({name: backendName, err: e});\n        }\n        backendInfo.aborted = true;\n      } finally {\n        delete backendInfo.initPromise;\n      }\n    }\n  }\n\n  throw new Error(`no available backend found. ERR: ${errors.map(e => `[${e.name}] ${e.err}`).join(', ')}`);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {TrainingSession} from './training-session.js';\n\n/**\n * @ignore\n */\nexport declare namespace SessionHandler {\n  type FeedsType = {[name: string]: OnnxValue};\n  type FetchesType = {[name: string]: OnnxValue | null};\n  type ReturnType = {[name: string]: OnnxValue};\n}\n\n/**\n * Represents shared SessionHandler functionality\n *\n * @ignore\n */\ninterface SessionHandler {\n  dispose(): Promise<void>;\n\n  readonly inputNames: readonly string[];\n  readonly outputNames: readonly string[];\n}\n\n/**\n * Represent a handler instance of an inference session.\n *\n * @ignore\n */\nexport interface InferenceSessionHandler extends SessionHandler {\n  startProfiling(): void;\n  endProfiling(): void;\n\n  run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n}\n\n/**\n * Represent a handler instance of a training inference session.\n *\n * @ignore\n */\nexport interface TrainingSessionHandler extends SessionHandler {\n  runTrainStep(\n      feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType,\n      options: InferenceSession.RunOptions): Promise<SessionHandler.ReturnType>;\n\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n}\n\n/**\n * Represent a backend that provides implementation of model inferencing.\n *\n * @ignore\n */\nexport interface Backend {\n  /**\n   * Initialize the backend asynchronously. Should throw when failed.\n   */\n  init(): Promise<void>;\n\n  createInferenceSessionHandler(uriOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n\n  createTrainingSessionHandler?\n      (checkpointStateUriOrBuffer: TrainingSession.URIorBuffer, trainModelUriOrBuffer: TrainingSession.URIorBuffer,\n       evalModelUriOrBuffer: TrainingSession.URIorBuffer, optimizerModelUriOrBuffer: TrainingSession.URIorBuffer,\n       options: InferenceSession.SessionOptions): Promise<TrainingSessionHandler>;\n}\n\nexport {registerBackend} from './backend-impl.js';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from './env.js';\nimport {version} from './version.js';\n\ntype LogLevelType = Env['logLevel'];\n\nlet logLevelValue: Required<LogLevelType> = 'warning';\n\nexport const env: Env = {\n  wasm: {} as Env.WebAssemblyFlags,\n  webgl: {} as Env.WebGLFlags,\n  webgpu: {} as Env.WebGpuFlags,\n  versions: {common: version},\n\n  set logLevel(value: LogLevelType) {\n    if (value === undefined) {\n      return;\n    }\n    if (typeof value !== 'string' || ['verbose', 'info', 'warning', 'error', 'fatal'].indexOf(value) === -1) {\n      throw new Error(`Unsupported logging level: ${value}`);\n    }\n    logLevelValue = value;\n  },\n  get logLevel(): Required<LogLevelType> {\n    return logLevelValue;\n  },\n};\n\n// set property 'logLevel' so that they can be correctly transferred to worker by `postMessage()`.\nObject.defineProperty(env, 'logLevel', {enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env as envImpl} from './env-impl.js';\n\nexport declare namespace Env {\n  export type WasmPrefixOrFilePaths = string|{\n    /* eslint-disable @typescript-eslint/naming-convention */\n    'ort-wasm.wasm'?: string;\n    'ort-wasm-threaded.wasm'?: string;\n    'ort-wasm-simd.wasm'?: string;\n    'ort-training-wasm-simd.wasm'?: string;\n    'ort-wasm-simd-threaded.wasm'?: string;\n    /* eslint-enable @typescript-eslint/naming-convention */\n  };\n  export interface WebAssemblyFlags {\n    /**\n     * set or get number of thread(s). If omitted or set to 0, number of thread(s) will be determined by system. If set\n     * to 1, no worker thread will be spawned.\n     *\n     * This setting is available only when WebAssembly multithread feature is available in current context.\n     *\n     * @defaultValue `0`\n     */\n    numThreads?: number;\n\n    /**\n     * set or get a boolean value indicating whether to enable SIMD. If set to false, SIMD will be forcely disabled.\n     *\n     * This setting is available only when WebAssembly SIMD feature is available in current context.\n     *\n     * @defaultValue `true`\n     */\n    simd?: boolean;\n\n    /**\n     * Set or get a number specifying the timeout for initialization of WebAssembly backend, in milliseconds. A zero\n     * value indicates no timeout is set.\n     *\n     * @defaultValue `0`\n     */\n    initTimeout?: number;\n\n    /**\n     * Set a custom URL prefix to the .wasm files or a set of overrides for each .wasm file. The override path should be\n     * an absolute path.\n     */\n    wasmPaths?: WasmPrefixOrFilePaths;\n\n    /**\n     * Set or get a boolean value indicating whether to proxy the execution of main thread to a worker thread.\n     *\n     * @defaultValue `false`\n     */\n    proxy?: boolean;\n  }\n\n  export interface WebGLFlags {\n    /**\n     * Set or get the WebGL Context ID (webgl or webgl2).\n     *\n     * @defaultValue `'webgl2'`\n     */\n    contextId?: 'webgl'|'webgl2';\n    /**\n     * Get the WebGL rendering context.\n     */\n    readonly context: WebGLRenderingContext;\n    /**\n     * Set or get the maximum batch size for matmul. 0 means to disable batching.\n     *\n     * @deprecated\n     */\n    matmulMaxBatchSize?: number;\n    /**\n     * Set or get the texture cache mode.\n     *\n     * @defaultValue `'full'`\n     */\n    textureCacheMode?: 'initializerOnly'|'full';\n    /**\n     * Set or get the packed texture mode\n     *\n     * @defaultValue `false`\n     */\n    pack?: boolean;\n    /**\n     * Set or get whether enable async download.\n     *\n     * @defaultValue `false`\n     */\n    async?: boolean;\n  }\n\n  export interface WebGpuFlags {\n    /**\n     * Set or get the profiling mode.\n     */\n    profilingMode?: 'off'|'default';\n    /**\n     * Get the device for WebGPU.\n     *\n     * When use with TypeScript, the type of this property is `GPUDevice` defined in \"@webgpu/types\".\n     * Use `const device = env.webgpu.device as GPUDevice;` in TypeScript to access this property with correct type.\n     *\n     * see comments on {@link GpuBufferType} for more details about why not use types defined in \"@webgpu/types\".\n     */\n    readonly device: unknown;\n    /**\n     * Set or get whether validate input content.\n     *\n     * @defaultValue `false`\n     */\n    validateInputContent?: boolean;\n  }\n}\n\nexport interface Env {\n  /**\n   * set the severity level for logging.\n   *\n   * @defaultValue `'warning'`\n   */\n  logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal';\n  /**\n   * Indicate whether run in debug mode.\n   *\n   * @defaultValue `false`\n   */\n  debug?: boolean;\n\n  /**\n   * Get version of the current package.\n   */\n  readonly versions: {\n    readonly common: string;\n    readonly web?: string;\n    readonly node?: string;\n    // eslint-disable-next-line @typescript-eslint/naming-convention\n    readonly 'react-native'?: string;\n  };\n\n  /**\n   * Represent a set of flags for WebAssembly\n   */\n  readonly wasm: Env.WebAssemblyFlags;\n\n  /**\n   * Represent a set of flags for WebGL\n   */\n  readonly webgl: Env.WebGLFlags;\n\n  /**\n   * Represent a set of flags for WebGPU\n   */\n  readonly webgpu: Env.WebGpuFlags;\n\n  [name: string]: unknown;\n}\n\n/**\n * Represent a set of flags as a global singleton.\n */\nexport const env: Env = envImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {Tensor} from './tensor.js';\n\n/**\n * implementation of Tensor.toDataURL()\n */\nexport const tensorToDataURL = (tensor: Tensor, options?: TensorToDataUrlOptions): string => {\n  const canvas = document.createElement('canvas');\n  canvas.width = tensor.dims[3];\n  canvas.height = tensor.dims[2];\n  const pixels2DContext = canvas.getContext('2d');\n\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n    }\n\n    const inputformat = options?.format !== undefined ? options.format : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 0];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    // Default pointer assignments\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    for (let i = 0; i < height; i++) {\n      for (let j = 0; j < width; j++) {\n        const R = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n        const G = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n        const B = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n        const A = aTensorPointer === -1 ?\n            255 :\n            ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands\n        pixels2DContext.fillStyle = 'rgba(' + R + ',' + G + ',' + B + ',' + A + ')';\n        pixels2DContext.fillRect(j, i, 1, 1);\n      }\n    }\n    return canvas.toDataURL();\n  } else {\n    throw new Error('Can not access image data');\n  }\n};\n\n/**\n * implementation of Tensor.toImageData()\n */\nexport const tensorToImageData = (tensor: Tensor, options?: TensorToImageDataOptions): ImageData => {\n  const pixels2DContext = document.createElement('canvas').getContext('2d');\n  let image: ImageData;\n  if (pixels2DContext != null) {\n    // Default values for height and width & format\n    let width: number;\n    let height: number;\n    let channels: number;\n    if (options?.tensorLayout !== undefined && options.tensorLayout === 'NHWC') {\n      width = tensor.dims[2];\n      height = tensor.dims[1];\n      channels = tensor.dims[3];\n    } else {  // Default layout is NCWH\n      width = tensor.dims[3];\n      height = tensor.dims[2];\n      channels = tensor.dims[1];\n    }\n    const inputformat = options !== undefined ? (options.format !== undefined ? options.format : 'RGB') : 'RGB';\n\n    const norm = options?.norm;\n    let normMean: [number, number, number, number];\n    let normBias: [number, number, number, number];\n    if (norm === undefined || norm.mean === undefined) {\n      normMean = [255, 255, 255, 255];\n    } else {\n      if (typeof (norm.mean) === 'number') {\n        normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n      } else {\n        normMean = [norm.mean[0], norm.mean[1], norm.mean[2], 255];\n        if (norm.mean[3] !== undefined) {\n          normMean[3] = norm.mean[3];\n        }\n      }\n    }\n    if (norm === undefined || norm.bias === undefined) {\n      normBias = [0, 0, 0, 0];\n    } else {\n      if (typeof (norm.bias) === 'number') {\n        normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n      } else {\n        normBias = [norm.bias[0], norm.bias[1], norm.bias[2], 0];\n        if (norm.bias[3] !== undefined) {\n          normBias[3] = norm.bias[3];\n        }\n      }\n    }\n\n    const stride = height * width;\n    if (options !== undefined) {\n      if (options.format !== undefined && (channels === 4 && options.format !== 'RGBA') ||\n          (channels === 3 && (options.format !== 'RGB' && options.format !== 'BGR'))) {\n        throw new Error('Tensor format doesn\\'t match input tensor dims');\n      }\n    }\n\n    // Default pointer assignments\n    const step = 4;\n    let rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n    let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n    // Updating the pointer assignments based on the input image format\n    if (inputformat === 'RGBA') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n      aTensorPointer = stride * 3;\n    } else if (inputformat === 'RGB') {\n      rTensorPointer = 0;\n      gTensorPointer = stride;\n      bTensorPointer = stride * 2;\n    } else if (inputformat === 'RBG') {\n      rTensorPointer = 0;\n      bTensorPointer = stride;\n      gTensorPointer = stride * 2;\n    }\n\n    image = pixels2DContext.createImageData(width, height);\n\n    for (let i = 0; i < height * width;\n         rImagePointer += step, gImagePointer += step, bImagePointer += step, aImagePointer += step, i++) {\n      image.data[rImagePointer] = ((tensor.data[rTensorPointer++] as number) - normBias[0]) * normMean[0];  // R value\n      image.data[gImagePointer] = ((tensor.data[gTensorPointer++] as number) - normBias[1]) * normMean[1];  // G value\n      image.data[bImagePointer] = ((tensor.data[bTensorPointer++] as number) - normBias[2]) * normMean[2];  // B value\n      image.data[aImagePointer] = aTensorPointer === -1 ?\n          255 :\n          ((tensor.data[aTensorPointer++] as number) - normBias[3]) * normMean[3];  // A value\n    }\n\n  } else {\n    throw new Error('Can not access image data');\n  }\n  return image;\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OptionsDimensions, OptionsFormat, OptionsNormalizationParameters, OptionsTensorFormat, OptionsTensorLayout, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\ninterface BufferToTensorOptions extends OptionsDimensions, OptionsTensorLayout, OptionsNormalizationParameters,\n                                        OptionsFormat, OptionsTensorFormat {}\n\n/**\n * Create a new tensor object from image object\n *\n * @param buffer - Extracted image buffer data - assuming RGBA format\n * @param imageFormat - input image configuration - required configurations height, width, format\n * @param tensorFormat - output tensor configuration - Default is RGB format\n */\nexport const bufferToTensor = (buffer: Uint8ClampedArray|undefined, options: BufferToTensorOptions): Tensor => {\n  if (buffer === undefined) {\n    throw new Error('Image buffer must be defined');\n  }\n  if (options.height === undefined || options.width === undefined) {\n    throw new Error('Image height and width must be defined');\n  }\n  if (options.tensorLayout === 'NHWC') {\n    throw new Error('NHWC Tensor layout is not supported yet');\n  }\n\n  const {height, width} = options;\n\n  const norm = options.norm ?? {mean: 255, bias: 0};\n  let normMean: [number, number, number, number];\n  let normBias: [number, number, number, number];\n\n  if (typeof (norm.mean) === 'number') {\n    normMean = [norm.mean, norm.mean, norm.mean, norm.mean];\n  } else {\n    normMean = [norm.mean![0], norm.mean![1], norm.mean![2], norm.mean![3] ?? 255];\n  }\n\n  if (typeof (norm.bias) === 'number') {\n    normBias = [norm.bias, norm.bias, norm.bias, norm.bias];\n  } else {\n    normBias = [norm.bias![0], norm.bias![1], norm.bias![2], norm.bias![3] ?? 0];\n  }\n\n  const inputformat = options.format !== undefined ? options.format : 'RGBA';\n  // default value is RGBA since imagedata and HTMLImageElement uses it\n\n  const outputformat =\n      options.tensorFormat !== undefined ? (options.tensorFormat !== undefined ? options.tensorFormat : 'RGB') : 'RGB';\n  const stride = height * width;\n  const float32Data = outputformat === 'RGBA' ? new Float32Array(stride * 4) : new Float32Array(stride * 3);\n\n  // Default pointer assignments\n  let step = 4, rImagePointer = 0, gImagePointer = 1, bImagePointer = 2, aImagePointer = 3;\n  let rTensorPointer = 0, gTensorPointer = stride, bTensorPointer = stride * 2, aTensorPointer = -1;\n\n  // Updating the pointer assignments based on the input image format\n  if (inputformat === 'RGB') {\n    step = 3;\n    rImagePointer = 0;\n    gImagePointer = 1;\n    bImagePointer = 2;\n    aImagePointer = -1;\n  }\n\n  // Updating the pointer assignments based on the output tensor format\n  if (outputformat === 'RGBA') {\n    aTensorPointer = stride * 3;\n  } else if (outputformat === 'RBG') {\n    rTensorPointer = 0;\n    bTensorPointer = stride;\n    gTensorPointer = stride * 2;\n  } else if (outputformat === 'BGR') {\n    bTensorPointer = 0;\n    gTensorPointer = stride;\n    rTensorPointer = stride * 2;\n  }\n\n  for (let i = 0; i < stride;\n       i++, rImagePointer += step, bImagePointer += step, gImagePointer += step, aImagePointer += step) {\n    float32Data[rTensorPointer++] = (buffer[rImagePointer] + normBias[0]) / normMean[0];\n    float32Data[gTensorPointer++] = (buffer[gImagePointer] + normBias[1]) / normMean[1];\n    float32Data[bTensorPointer++] = (buffer[bImagePointer] + normBias[2]) / normMean[2];\n    if (aTensorPointer !== -1 && aImagePointer !== -1) {\n      float32Data[aTensorPointer++] = (buffer[aImagePointer] + normBias[3]) / normMean[3];\n    }\n  }\n\n  // Float32Array -> ort.Tensor\n  const outputTensor = outputformat === 'RGBA' ? new Tensor('float32', float32Data, [1, 4, height, width]) :\n                                                 new Tensor('float32', float32Data, [1, 3, height, width]);\n  return outputTensor;\n};\n\n/**\n * implementation of Tensor.fromImage().\n */\nexport const tensorFromImage = async(\n    image: ImageData|HTMLImageElement|ImageBitmap|string,\n    options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n    TensorFromUrlOptions): Promise<Tensor> => {\n  // checking the type of image object\n  const isHTMLImageEle = typeof (HTMLImageElement) !== 'undefined' && image instanceof HTMLImageElement;\n  const isImageDataEle = typeof (ImageData) !== 'undefined' && image instanceof ImageData;\n  const isImageBitmap = typeof (ImageBitmap) !== 'undefined' && image instanceof ImageBitmap;\n  const isString = typeof image === 'string';\n\n  let data: Uint8ClampedArray|undefined;\n  let bufferToTensorOptions: BufferToTensorOptions = options ?? {};\n\n  // filling and checking image configuration options\n  if (isHTMLImageEle) {\n    // HTMLImageElement - image object - format is RGBA by default\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      let height = image.height;\n      let width = image.width;\n      if (options !== undefined && options.resizedHeight !== undefined && options.resizedWidth !== undefined) {\n        height = options.resizedHeight;\n        width = options.resizedWidth;\n      }\n\n      if (options !== undefined) {\n        bufferToTensorOptions = options;\n        if (options.tensorFormat !== undefined) {\n          throw new Error('Image input config format must be RGBA for HTMLImageElement');\n        } else {\n          bufferToTensorOptions.tensorFormat = 'RGBA';\n        }\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      } else {\n        bufferToTensorOptions.tensorFormat = 'RGBA';\n        bufferToTensorOptions.height = height;\n        bufferToTensorOptions.width = width;\n      }\n\n      pixels2DContext.drawImage(image, 0, 0);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isImageDataEle) {\n    let height: number;\n    let width: number;\n\n    if (options !== undefined && options.resizedWidth !== undefined && options.resizedHeight !== undefined) {\n      height = options.resizedHeight;\n      width = options.resizedWidth;\n    } else {\n      height = image.height;\n      width = image.width;\n    }\n\n    if (options !== undefined) {\n      bufferToTensorOptions = options;\n    }\n    bufferToTensorOptions.format = 'RGBA';\n    bufferToTensorOptions.height = height;\n    bufferToTensorOptions.width = width;\n\n    if (options !== undefined) {\n      const tempCanvas = document.createElement('canvas');\n\n      tempCanvas.width = width;\n      tempCanvas.height = height;\n\n      const pixels2DContext = tempCanvas.getContext('2d');\n\n      if (pixels2DContext != null) {\n        pixels2DContext.putImageData(image, 0, 0);\n        data = pixels2DContext.getImageData(0, 0, width, height).data;\n      } else {\n        throw new Error('Can not access image data');\n      }\n    } else {\n      data = image.data;\n    }\n  } else if (isImageBitmap) {\n    // ImageBitmap - image object - format must be provided by user\n    if (options === undefined) {\n      throw new Error('Please provide image config with format for Imagebitmap');\n    }\n\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width;\n    canvas.height = image.height;\n    const pixels2DContext = canvas.getContext('2d');\n\n    if (pixels2DContext != null) {\n      const height = image.height;\n      const width = image.width;\n      pixels2DContext.drawImage(image, 0, 0, width, height);\n      data = pixels2DContext.getImageData(0, 0, width, height).data;\n      bufferToTensorOptions.height = height;\n      bufferToTensorOptions.width = width;\n      return bufferToTensor(data, bufferToTensorOptions);\n    } else {\n      throw new Error('Can not access image data');\n    }\n  } else if (isString) {\n    return new Promise((resolve, reject) => {\n      const canvas = document.createElement('canvas');\n      const context = canvas.getContext('2d');\n      if (!image || !context) {\n        return reject();\n      }\n      const newImage = new Image();\n      newImage.crossOrigin = 'Anonymous';\n      newImage.src = image;\n      newImage.onload = () => {\n        canvas.width = newImage.width;\n        canvas.height = newImage.height;\n        context.drawImage(newImage, 0, 0, canvas.width, canvas.height);\n        const img = context.getImageData(0, 0, canvas.width, canvas.height);\n\n        bufferToTensorOptions.height = canvas.height;\n        bufferToTensorOptions.width = canvas.width;\n        resolve(bufferToTensor(img.data, bufferToTensorOptions));\n      };\n    });\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n\n  if (data !== undefined) {\n    return bufferToTensor(data, bufferToTensorOptions);\n  } else {\n    throw new Error('Input data provided is not supported - aborted tensor creation');\n  }\n};\n\n/**\n * implementation of Tensor.fromTexture().\n */\nexport const tensorFromTexture = <T extends TensorInterface.TextureDataTypes>(\n    texture: TensorInterface.TextureType, options: TensorFromTextureOptions<T>): Tensor => {\n  const {width, height, download, dispose} = options;\n  // Always assume RGBAF32. TODO: support different texture format\n  const dims = [1, height, width, 4];\n  return new Tensor({location: 'texture', type: 'float32', texture, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromGpuBuffer().\n */\nexport const tensorFromGpuBuffer = <T extends TensorInterface.GpuBufferDataTypes>(\n    gpuBuffer: TensorInterface.GpuBufferType, options: TensorFromGpuBufferOptions<T>): Tensor => {\n  const {dataType, dims, download, dispose} = options;\n  return new Tensor({location: 'gpu-buffer', type: dataType ?? 'float32', gpuBuffer, dims, download, dispose});\n};\n\n/**\n * implementation of Tensor.fromPinnedBuffer().\n */\nexport const tensorFromPinnedBuffer = <T extends TensorInterface.CpuPinnedDataTypes>(\n    type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor =>\n    new Tensor({location: 'cpu-pinned', type, data: buffer, dims: dims ?? [buffer.length]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\nexport type SupportedTypedArrayConstructors = Float32ArrayConstructor|Uint8ArrayConstructor|Int8ArrayConstructor|\n    Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|Uint8ArrayConstructor|\n    Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor;\nexport type SupportedTypedArray = InstanceType<SupportedTypedArrayConstructors>;\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP = new Map<string, SupportedTypedArrayConstructors>([\n  ['float32', Float32Array],\n  ['uint8', Uint8Array],\n  ['int8', Int8Array],\n  ['uint16', Uint16Array],\n  ['float16', Uint16Array],\n  ['int16', Int16Array],\n  ['int32', Int32Array],\n  ['bool', Uint8Array],\n  ['float64', Float64Array],\n  ['uint32', Uint32Array],\n]);\n\n// a runtime map that maps type string to TypedArray constructor. Should match Tensor.DataTypeMap.\nexport const NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP = new Map<SupportedTypedArrayConstructors, Tensor.Type>([\n  [Float32Array, 'float32'],\n  [Uint8Array, 'uint8'],\n  [Int8Array, 'int8'],\n  [Uint16Array, 'uint16'],\n  [Int16Array, 'int16'],\n  [Int32Array, 'int32'],\n  [Float64Array, 'float64'],\n  [Uint32Array, 'uint32'],\n]);\n\n// the following code allows delaying execution of BigInt checking. This allows lazy initialization for\n// NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP and NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, which allows BigInt polyfill\n// if available.\nlet isBigIntChecked = false;\nexport const checkBigInt = () => {\n  if (!isBigIntChecked) {\n    isBigIntChecked = true;\n    const isBigInt64ArrayAvailable = typeof BigInt64Array !== 'undefined' && typeof BigInt64Array.from === 'function';\n    const isBigUint64ArrayAvailable =\n        typeof BigUint64Array !== 'undefined' && typeof BigUint64Array.from === 'function';\n\n    if (isBigInt64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('int64', BigInt64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigInt64Array, 'int64');\n    }\n    if (isBigUint64ArrayAvailable) {\n      NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.set('uint64', BigUint64Array);\n      NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.set(BigUint64Array, 'uint64');\n    }\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TextureConstructorParameters} from './tensor-factory.js';\nimport {Tensor} from './tensor-impl.js';\n\n/**\n * calculate size from dims.\n *\n * @param dims the dims array. May be an illegal input.\n */\nexport const calculateSize = (dims: readonly unknown[]): number => {\n  let size = 1;\n  for (let i = 0; i < dims.length; i++) {\n    const dim = dims[i];\n    if (typeof dim !== 'number' || !Number.isSafeInteger(dim)) {\n      throw new TypeError(`dims[${i}] must be an integer, got: ${dim}`);\n    }\n    if (dim < 0) {\n      throw new RangeError(`dims[${i}] must be a non-negative integer, got: ${dim}`);\n    }\n    size *= dim;\n  }\n  return size;\n};\n\n/**\n * implementation of Tensor.reshape()\n */\nexport const tensorReshape = (tensor: Tensor, dims: readonly number[]): Tensor => {\n  switch (tensor.location) {\n    case 'cpu':\n      return new Tensor(tensor.type, tensor.data, dims);\n    case 'cpu-pinned':\n      return new Tensor({\n        location: 'cpu-pinned',\n        data: tensor.data as CpuPinnedConstructorParameters['data'],\n        type: tensor.type as CpuPinnedConstructorParameters['type'],\n        dims,\n      });\n    case 'texture':\n      return new Tensor({\n        location: 'texture',\n        texture: tensor.texture,\n        type: tensor.type as TextureConstructorParameters['type'],\n        dims,\n      });\n    case 'gpu-buffer':\n      return new Tensor({\n        location: 'gpu-buffer',\n        gpuBuffer: tensor.gpuBuffer,\n        type: tensor.type as GpuBufferConstructorParameters['type'],\n        dims,\n      });\n    default:\n      throw new Error(`tensorReshape: tensor location ${tensor.location} is not supported`);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorToDataURL, tensorToImageData} from './tensor-conversion-impl.js';\nimport {TensorToDataUrlOptions, TensorToImageDataOptions} from './tensor-conversion.js';\nimport {tensorFromGpuBuffer, tensorFromImage, tensorFromPinnedBuffer, tensorFromTexture} from './tensor-factory-impl.js';\nimport {CpuPinnedConstructorParameters, GpuBufferConstructorParameters, TensorFromGpuBufferOptions, TensorFromImageBitmapOptions, TensorFromImageDataOptions, TensorFromImageElementOptions, TensorFromTextureOptions, TensorFromUrlOptions, TextureConstructorParameters} from './tensor-factory.js';\nimport {checkBigInt, NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP, NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP, SupportedTypedArray, SupportedTypedArrayConstructors} from './tensor-impl-type-mapping.js';\nimport {calculateSize, tensorReshape} from './tensor-utils-impl.js';\nimport {Tensor as TensorInterface} from './tensor.js';\n\n// type aliases for those exported from Tensor interface\n\ntype TensorType = TensorInterface.Type;\ntype TensorDataType = TensorInterface.DataType;\ntype TensorDataLocation = TensorInterface.DataLocation;\ntype TensorTextureType = TensorInterface.TextureType;\ntype TensorGpuBufferType = TensorInterface.GpuBufferType;\n\n/**\n * the implementation of Tensor interface.\n *\n * @ignore\n */\nexport class Tensor implements TensorInterface {\n  // #region constructors\n\n  /**\n   * Construct a new CPU tensor object from the given type, data and dims.\n   */\n  constructor(\n      type: TensorType, data: TensorDataType|readonly string[]|readonly number[]|readonly boolean[],\n      dims?: readonly number[]);\n  /**\n   * Construct a new CPU tensor object from the given data and dims. Type is inferred from data.\n   */\n  constructor(data: TensorDataType|readonly string[]|readonly boolean[], dims?: readonly number[]);\n  /**\n   * Construct a new tensor object from the pinned CPU data with the given type and dims.\n   *\n   * Tensor's location will be set to 'cpu-pinned'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: CpuPinnedConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGL texture with the given type and dims.\n   *\n   * Tensor's location will be set to 'texture'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: TextureConstructorParameters);\n  /**\n   * Construct a new tensor object from the WebGPU buffer with the given type and dims.\n   *\n   * Tensor's location will be set to 'gpu-buffer'.\n   *\n   * @param params - Specify the parameters to construct the tensor.\n   */\n  constructor(params: GpuBufferConstructorParameters);\n\n  /**\n   * implementation.\n   */\n  constructor(\n      arg0: TensorType|TensorDataType|readonly string[]|readonly boolean[]|CpuPinnedConstructorParameters|\n      TextureConstructorParameters|GpuBufferConstructorParameters,\n      arg1?: TensorDataType|readonly number[]|readonly string[]|readonly boolean[], arg2?: readonly number[]) {\n    // perform one-time check for BigInt support\n    checkBigInt();\n\n    let type: TensorType;\n    let dims: readonly number[];\n\n    if (typeof arg0 === 'object' && 'location' in arg0) {\n      //\n      // constructing tensor from specific location\n      //\n      this.dataLocation = arg0.location;\n      type = arg0.type;\n      dims = arg0.dims;\n      switch (arg0.location) {\n        case 'cpu-pinned': {\n          const expectedTypedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(type);\n          if (!expectedTypedArrayConstructor) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from pinned buffer`);\n          }\n          if (!(arg0.data instanceof expectedTypedArrayConstructor)) {\n            throw new TypeError(`buffer should be of type ${expectedTypedArrayConstructor.name}`);\n          }\n          this.cpuData = arg0.data;\n          break;\n        }\n        case 'texture': {\n          if (type !== 'float32') {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from texture`);\n          }\n          this.gpuTextureData = arg0.texture;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        case 'gpu-buffer': {\n          if ((type !== 'float32' && type !== 'float16' && type !== 'int32' && type !== 'int64' && type !== 'uint32' &&\n               type !== 'bool')) {\n            throw new TypeError(`unsupported type \"${type}\" to create tensor from gpu buffer`);\n          }\n          this.gpuBufferData = arg0.gpuBuffer;\n          this.downloader = arg0.download;\n          this.disposer = arg0.dispose;\n          break;\n        }\n        default:\n          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);\n      }\n    } else {\n      //\n      // constructing tensor of location 'cpu'\n      //\n      let data: TensorDataType;\n      let maybeDims: typeof arg1|typeof arg2;\n      // check whether arg0 is type or data\n      if (typeof arg0 === 'string') {\n        //\n        // Override: constructor(type, data, ...)\n        //\n        type = arg0;\n        maybeDims = arg2;\n        if (arg0 === 'string') {\n          // string tensor\n          if (!Array.isArray(arg1)) {\n            throw new TypeError('A string tensor\\'s data must be a string array.');\n          }\n          // we don't check whether every element in the array is string; this is too slow. we assume it's correct and\n          // error will be populated at inference\n          data = arg1;\n        } else {\n          // numeric tensor\n          const typedArrayConstructor = NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP.get(arg0);\n          if (typedArrayConstructor === undefined) {\n            throw new TypeError(`Unsupported tensor type: ${arg0}.`);\n          }\n          if (Array.isArray(arg1)) {\n            if (arg0 === 'float16') {\n              // Throw error here because when user try to use number array as data,\n              // e.g. new Tensor('float16', [1, 2, 3, 4], dims)), it will actually call\n              // Uint16Array.from(arg1) which generates wrong data.\n              throw new TypeError(\n                  'Creating a float16 tensor from number array is not supported. Please use Uint16Array as data.');\n            } else if (arg0 === 'uint64' || arg0 === 'int64') {\n              // use 'as any' here because:\n              // 1. TypeScript's check on type of 'Array.isArray()' does not work with readonly arrays.\n              // see https://github.com/microsoft/TypeScript/issues/17002\n              // 2. TypeScript's check on union type of '(BigInt64ArrayConstructor|BigUint64ArrayConstructor).from()'\n              // does not accept parameter mapFn.\n              // 3. parameters of 'SupportedTypedArrayConstructors.from()' does not match the requirement of the union\n              // type.\n\n              // assume 'arg1' is of type \"readonly number[]|readonly bigint[]\" here.\n\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1, BigInt);\n            } else {\n              // assume 'arg1' is of type \"readonly number[]\" here.\n              // eslint-disable-next-line @typescript-eslint/no-explicit-any\n              data = (typedArrayConstructor as any).from(arg1);\n            }\n          } else if (arg1 instanceof typedArrayConstructor) {\n            data = arg1;\n          } else {\n            throw new TypeError(`A ${type} tensor's data must be type of ${typedArrayConstructor}`);\n          }\n        }\n      } else {\n        //\n        // Override: constructor(data, ...)\n        //\n        maybeDims = arg1;\n        if (Array.isArray(arg0)) {\n          // only boolean[] and string[] is supported\n          if (arg0.length === 0) {\n            throw new TypeError('Tensor type cannot be inferred from an empty array.');\n          }\n          const firstElementType = typeof arg0[0];\n          if (firstElementType === 'string') {\n            type = 'string';\n            data = arg0;\n          } else if (firstElementType === 'boolean') {\n            type = 'bool';\n            // 'arg0' is of type 'boolean[]'. Uint8Array.from(boolean[]) actually works, but typescript thinks this is\n            // wrong type. We use 'as any' to make it happy.\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            data = Uint8Array.from(arg0 as any[]);\n          } else {\n            throw new TypeError(`Invalid element type of data array: ${firstElementType}.`);\n          }\n        } else {\n          // get tensor type from TypedArray\n          const mappedType =\n              NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP.get(arg0.constructor as SupportedTypedArrayConstructors);\n          if (mappedType === undefined) {\n            throw new TypeError(`Unsupported type for tensor data: ${arg0.constructor}.`);\n          }\n          type = mappedType;\n          data = arg0 as SupportedTypedArray;\n        }\n      }\n\n      // type and data is processed, now processing dims\n      if (maybeDims === undefined) {\n        // assume 1-D tensor if dims omitted\n        maybeDims = [data.length];\n      } else if (!Array.isArray(maybeDims)) {\n        throw new TypeError('A tensor\\'s dims must be a number array');\n      }\n      dims = maybeDims as readonly number[];\n\n      this.cpuData = data;\n      this.dataLocation = 'cpu';\n    }\n\n    // perform check on dims\n    const size = calculateSize(dims);\n    // if data is on CPU, check whether data length matches tensor size\n    if (this.cpuData && size !== this.cpuData.length) {\n      throw new Error(`Tensor's size(${size}) does not match data length(${this.cpuData.length}).`);\n    }\n\n    this.type = type;\n    this.dims = dims;\n    this.size = size;\n  }\n  // #endregion\n\n  // #region factory\n  static async fromImage(\n      image: ImageData|HTMLImageElement|ImageBitmap|string,\n      options?: TensorFromImageDataOptions|TensorFromImageElementOptions|TensorFromImageBitmapOptions|\n      TensorFromUrlOptions): Promise<TensorInterface> {\n    return tensorFromImage(image, options);\n  }\n\n  static fromTexture<T extends TensorInterface.TextureDataTypes>(\n      texture: TensorTextureType, options: TensorFromTextureOptions<T>): TensorInterface {\n    return tensorFromTexture(texture, options);\n  }\n\n  static fromGpuBuffer<T extends TensorInterface.GpuBufferDataTypes>(\n      gpuBuffer: TensorGpuBufferType, options: TensorFromGpuBufferOptions<T>): TensorInterface {\n    return tensorFromGpuBuffer(gpuBuffer, options);\n  }\n\n  static fromPinnedBuffer<T extends TensorInterface.CpuPinnedDataTypes>(\n      type: T, buffer: TensorInterface.DataTypeMap[T], dims?: readonly number[]): Tensor {\n    return tensorFromPinnedBuffer(type, buffer, dims);\n  }\n\n  // #endregion\n\n  // #region conversions\n  toDataURL(options?: TensorToDataUrlOptions): string {\n    return tensorToDataURL(this, options);\n  }\n\n  toImageData(options?: TensorToImageDataOptions): ImageData {\n    return tensorToImageData(this, options);\n  }\n  // #endregion\n\n  // #region public fields\n  readonly dims: readonly number[];\n  readonly type: TensorType;\n  readonly size: number;\n  // #endregion\n\n  // #region private fields\n\n  /**\n   * stores the location of the data.\n   */\n  private dataLocation: TensorDataLocation;\n\n  /**\n   * stores the data on CPU, if location is 'cpu' or 'cpu-pinned'. otherwise empty.\n   */\n  private cpuData?: TensorDataType;\n\n  /**\n   * stores the underlying texture when location is 'texture'. otherwise empty.\n   */\n  private gpuTextureData?: TensorTextureType;\n\n  /**\n   * stores the underlying GPU buffer when location is 'gpu-buffer'. otherwise empty.\n   */\n  private gpuBufferData?: TensorGpuBufferType;\n\n  /**\n   * stores an optional downloader function to download data from GPU to CPU.\n   */\n  private downloader?(): Promise<TensorDataType>;\n\n  /**\n   * a flag indicating whether the data is being downloaded from GPU to CPU.\n   */\n  private isDownloading?: boolean;\n\n  /**\n   * stores an optional disposer function to dispose the underlying data.\n   */\n  private disposer?(): void;\n  // #endregion\n\n  // #region properties\n  get data(): TensorDataType {\n    this.ensureValid();\n    if (!this.cpuData) {\n      throw new Error(\n          'The data is not on CPU. Use `getData()` to download GPU data to CPU, ' +\n          'or use `texture` or `gpuBuffer` property to access the GPU data directly.');\n    }\n    return this.cpuData;\n  }\n\n  get location(): TensorDataLocation {\n    return this.dataLocation;\n  }\n\n  get texture(): TensorTextureType {\n    this.ensureValid();\n    if (!this.gpuTextureData) {\n      throw new Error('The data is not stored as a WebGL texture.');\n    }\n    return this.gpuTextureData;\n  }\n\n  get gpuBuffer(): TensorGpuBufferType {\n    this.ensureValid();\n    if (!this.gpuBufferData) {\n      throw new Error('The data is not stored as a WebGPU buffer.');\n    }\n    return this.gpuBufferData;\n  }\n  // #endregion\n\n  // #region methods\n\n  async getData(releaseData?: boolean): Promise<TensorDataType> {\n    this.ensureValid();\n    switch (this.dataLocation) {\n      case 'cpu':\n      case 'cpu-pinned':\n        return this.data;\n      case 'texture':\n      case 'gpu-buffer': {\n        if (!this.downloader) {\n          throw new Error('The current tensor is not created with a specified data downloader.');\n        }\n        if (this.isDownloading) {\n          throw new Error('The current tensor is being downloaded.');\n        }\n        try {\n          this.isDownloading = true;\n          const data = await this.downloader();\n          this.downloader = undefined;\n          this.dataLocation = 'cpu';\n          this.cpuData = data;\n\n          if (releaseData && this.disposer) {\n            this.disposer();\n            this.disposer = undefined;\n          }\n\n          return data;\n\n        } finally {\n          this.isDownloading = false;\n        }\n      }\n      default:\n        throw new Error(`cannot get data from location: ${this.dataLocation}`);\n    }\n  }\n\n  dispose(): void {\n    if (this.isDownloading) {\n      throw new Error('The current tensor is being downloaded.');\n    }\n\n    if (this.disposer) {\n      this.disposer();\n      this.disposer = undefined;\n    }\n    this.cpuData = undefined;\n    this.gpuTextureData = undefined;\n    this.gpuBufferData = undefined;\n    this.downloader = undefined;\n    this.isDownloading = undefined;\n\n    this.dataLocation = 'none';\n  }\n\n  // #endregion\n\n  // #region tensor utilities\n  private ensureValid(): void {\n    if (this.dataLocation === 'none') {\n      throw new Error('The tensor is disposed.');\n    }\n  }\n\n  reshape(dims: readonly number[]): TensorInterface {\n    this.ensureValid();\n    if (this.downloader || this.disposer) {\n      throw new Error('Cannot reshape a tensor that owns GPU resource.');\n    }\n    return tensorReshape(this, dims);\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorFactory} from './tensor-factory.js';\nimport {Tensor as TensorImpl} from './tensor-impl.js';\nimport {TypedTensorUtils} from './tensor-utils.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\n/**\n * represent a basic tensor with specified dimensions and data type.\n */\ninterface TypedTensorBase<T extends Tensor.Type> {\n  /**\n   * Get the dimensions of the tensor.\n   */\n  readonly dims: readonly number[];\n  /**\n   * Get the data type of the tensor.\n   */\n  readonly type: T;\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is not on CPU (eg. it's in the form of WebGL texture or WebGPU buffer), throw error.\n   */\n  readonly data: Tensor.DataTypeMap[T];\n  /**\n   * Get the location of the data.\n   */\n  readonly location: Tensor.DataLocation;\n  /**\n   * Get the WebGL texture that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGL texture, throw error.\n   */\n  readonly texture: Tensor.TextureType;\n  /**\n   * Get the WebGPU buffer that holds the tensor data.\n   *\n   * If the data is not on GPU as WebGPU buffer, throw error.\n   */\n  readonly gpuBuffer: Tensor.GpuBufferType;\n\n  /**\n   * Get the buffer data of the tensor.\n   *\n   * If the data is on CPU, returns the data immediately.\n   * If the data is on GPU, downloads the data and returns the promise.\n   *\n   * @param releaseData - whether release the data on GPU. Ignore if data is already on CPU.\n   */\n  getData(releaseData?: boolean): Promise<Tensor.DataTypeMap[T]>;\n\n  /**\n   * Dispose the tensor data.\n   *\n   * If the data is on CPU, remove its internal reference to the underlying data.\n   * If the data is on GPU, release the data on GPU.\n   *\n   * After calling this function, the tensor is considered no longer valid. Its location will be set to 'none'.\n   */\n  dispose(): void;\n}\n\nexport declare namespace Tensor {\n  interface DataTypeMap {\n    float32: Float32Array;\n    uint8: Uint8Array;\n    int8: Int8Array;\n    uint16: Uint16Array;\n    int16: Int16Array;\n    int32: Int32Array;\n    int64: BigInt64Array;\n    string: string[];\n    bool: Uint8Array;\n    float16: Uint16Array;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: Float64Array;\n    uint32: Uint32Array;\n    uint64: BigUint64Array;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  interface ElementTypeMap {\n    float32: number;\n    uint8: number;\n    int8: number;\n    uint16: number;\n    int16: number;\n    int32: number;\n    int64: bigint;\n    string: string;\n    bool: boolean;\n    float16: number;  // Keep using Uint16Array until we have a concrete solution for float 16.\n    float64: number;\n    uint32: number;\n    uint64: bigint;\n    // complex64: never;\n    // complex128: never;\n    // bfloat16: never;\n  }\n\n  type DataType = DataTypeMap[Type];\n  type ElementType = ElementTypeMap[Type];\n\n  /**\n   * supported data types for constructing a tensor from a pinned CPU buffer\n   */\n  export type CpuPinnedDataTypes = Exclude<Tensor.Type, 'string'>;\n\n  /**\n   * type alias for WebGL texture\n   */\n  export type TextureType = WebGLTexture;\n\n  /**\n   * supported data types for constructing a tensor from a WebGL texture\n   */\n  export type TextureDataTypes = 'float32';\n\n  /**\n   * type alias for WebGPU buffer\n   *\n   * The reason why we don't use type \"GPUBuffer\" defined in webgpu.d.ts from @webgpu/types is because \"@webgpu/types\"\n   * requires \"@types/dom-webcodecs\" as peer dependency when using TypeScript < v5.1 and its version need to be chosen\n   * carefully according to the TypeScript version being used. This means so far there is not a way to keep every\n   * TypeScript version happy. It turns out that we will easily broke users on some TypeScript version.\n   *\n   * for more info see https://github.com/gpuweb/types/issues/127\n   */\n  export type GpuBufferType = {size: number; mapState: 'unmapped' | 'pending' | 'mapped'};\n\n  /**\n   * supported data types for constructing a tensor from a WebGPU buffer\n   */\n  export type GpuBufferDataTypes = 'float32'|'float16'|'int32'|'int64'|'uint32'|'bool';\n\n  /**\n   * represent where the tensor data is stored\n   */\n  export type DataLocation = 'none'|'cpu'|'cpu-pinned'|'texture'|'gpu-buffer';\n\n  /**\n   * represent the data type of a tensor\n   */\n  export type Type = keyof DataTypeMap;\n}\n\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface TypedTensor<T extends Tensor.Type> extends TypedTensorBase<T>, TypedTensorUtils<T> {}\n/**\n * Represent multi-dimensional arrays to feed to or fetch from model inferencing.\n */\nexport interface Tensor extends TypedTensorBase<Tensor.Type>, TypedTensorUtils<Tensor.Type> {}\n\n/**\n * type TensorConstructor defines the constructors of 'Tensor' to create CPU tensor instances.\n */\nexport interface TensorConstructor {\n  // #region CPU tensor - specify element type\n  /**\n   * Construct a new string tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'string', data: Tensor.DataTypeMap['string']|readonly string[],\n      dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: 'bool', data: Tensor.DataTypeMap['bool']|readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new 64-bit integer typed tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends 'uint64'|'int64'>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly bigint[]|readonly number[],\n      dims?: readonly number[]): TypedTensor<T>;\n\n  /**\n   * Construct a new numeric tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new<T extends Exclude<Tensor.Type, 'string'|'bool'|'uint64'|'int64'>>(\n      type: T, data: Tensor.DataTypeMap[T]|readonly number[], dims?: readonly number[]): TypedTensor<T>;\n  // #endregion\n\n  // #region CPU tensor - infer element types\n\n  /**\n   * Construct a new float32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float32Array, dims?: readonly number[]): TypedTensor<'float32'>;\n\n  /**\n   * Construct a new int8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int8Array, dims?: readonly number[]): TypedTensor<'int8'>;\n\n  /**\n   * Construct a new uint8 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint8Array, dims?: readonly number[]): TypedTensor<'uint8'>;\n\n  /**\n   * Construct a new uint16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint16Array, dims?: readonly number[]): TypedTensor<'uint16'>;\n\n  /**\n   * Construct a new int16 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int16Array, dims?: readonly number[]): TypedTensor<'int16'>;\n\n  /**\n   * Construct a new int32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Int32Array, dims?: readonly number[]): TypedTensor<'int32'>;\n\n  /**\n   * Construct a new int64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigInt64Array, dims?: readonly number[]): TypedTensor<'int64'>;\n\n  /**\n   * Construct a new string tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly string[], dims?: readonly number[]): TypedTensor<'string'>;\n\n  /**\n   * Construct a new bool tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: readonly boolean[], dims?: readonly number[]): TypedTensor<'bool'>;\n\n  /**\n   * Construct a new float64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Float64Array, dims?: readonly number[]): TypedTensor<'float64'>;\n\n  /**\n   * Construct a new uint32 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Uint32Array, dims?: readonly number[]): TypedTensor<'uint32'>;\n\n  /**\n   * Construct a new uint64 tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: BigUint64Array, dims?: readonly number[]): TypedTensor<'uint64'>;\n\n  // #endregion\n\n  // #region CPU tensor - fall back to non-generic tensor type declaration\n\n  /**\n   * Construct a new tensor object from the given type, data and dims.\n   *\n   * @param type - Specify the element type.\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(type: Tensor.Type, data: Tensor.DataType|readonly number[]|readonly string[]|readonly bigint[]|readonly boolean[],\n      dims?: readonly number[]): Tensor;\n\n  /**\n   * Construct a new tensor object from the given data and dims.\n   *\n   * @param data - Specify the CPU tensor data.\n   * @param dims - Specify the dimension of the tensor. If omitted, a 1-D tensor is assumed.\n   */\n  new(data: Tensor.DataType, dims?: readonly number[]): Tensor;\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const Tensor = TensorImpl as (TensorConstructor & TensorFactory);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {InferenceSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSessionInterface} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\n\ntype SessionOptions = InferenceSessionInterface.SessionOptions;\ntype RunOptions = InferenceSessionInterface.RunOptions;\ntype FeedsType = InferenceSessionInterface.FeedsType;\ntype FetchesType = InferenceSessionInterface.FetchesType;\ntype ReturnType = InferenceSessionInterface.ReturnType;\n\nexport class InferenceSession implements InferenceSessionInterface {\n  private constructor(handler: InferenceSessionHandler) {\n    this.handler = handler;\n  }\n  run(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  run(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async run(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSessionInterface.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    // feeds, fetches and options are prepared\n\n    const results = await this.handler.run(feeds, fetches, options);\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n\n  static create(path: string, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: SessionOptions):\n      Promise<InferenceSessionInterface>;\n  static create(buffer: Uint8Array, options?: SessionOptions): Promise<InferenceSessionInterface>;\n  static async create(\n      arg0: string|ArrayBufferLike|Uint8Array, arg1?: SessionOptions|number, arg2?: number,\n      arg3?: SessionOptions): Promise<InferenceSessionInterface> {\n    // either load from a file or buffer\n    let filePathOrUint8Array: string|Uint8Array;\n    let options: SessionOptions = {};\n\n    if (typeof arg0 === 'string') {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (arg0 instanceof Uint8Array) {\n      filePathOrUint8Array = arg0;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n    } else if (\n        arg0 instanceof ArrayBuffer ||\n        (typeof SharedArrayBuffer !== 'undefined' && arg0 instanceof SharedArrayBuffer)) {\n      const buffer = arg0;\n      let byteOffset = 0;\n      let byteLength = arg0.byteLength;\n      if (typeof arg1 === 'object' && arg1 !== null) {\n        options = arg1;\n      } else if (typeof arg1 === 'number') {\n        byteOffset = arg1;\n        if (!Number.isSafeInteger(byteOffset)) {\n          throw new RangeError('\\'byteOffset\\' must be an integer.');\n        }\n        if (byteOffset < 0 || byteOffset >= buffer.byteLength) {\n          throw new RangeError(`'byteOffset' is out of range [0, ${buffer.byteLength}).`);\n        }\n        byteLength = arg0.byteLength - byteOffset;\n        if (typeof arg2 === 'number') {\n          byteLength = arg2;\n          if (!Number.isSafeInteger(byteLength)) {\n            throw new RangeError('\\'byteLength\\' must be an integer.');\n          }\n          if (byteLength <= 0 || byteOffset + byteLength > buffer.byteLength) {\n            throw new RangeError(`'byteLength' is out of range (0, ${buffer.byteLength - byteOffset}].`);\n          }\n          if (typeof arg3 === 'object' && arg3 !== null) {\n            options = arg3;\n          } else if (typeof arg3 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'byteLength\\' must be a number.');\n        }\n      } else if (typeof arg1 !== 'undefined') {\n        throw new TypeError('\\'options\\' must be an object.');\n      }\n      filePathOrUint8Array = new Uint8Array(buffer, byteOffset, byteLength);\n    } else {\n      throw new TypeError('Unexpected argument[0]: must be \\'path\\' or \\'buffer\\'.');\n    }\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    const handler = await backend.createInferenceSessionHandler(filePathOrUint8Array, options);\n    return new InferenceSession(handler);\n  }\n\n  startProfiling(): void {\n    this.handler.startProfiling();\n  }\n  endProfiling(): void {\n    this.handler.endProfiling();\n  }\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  private handler: InferenceSessionHandler;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession as InferenceSessionImpl} from './inference-session-impl.js';\nimport {OnnxValue, OnnxValueDataLocation} from './onnx-value.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace InferenceSession {\n  // #region input/output types\n\n  type OnnxValueMapType = {readonly [name: string]: OnnxValue};\n  type NullableOnnxValueMapType = {readonly [name: string]: OnnxValue | null};\n\n  /**\n   * A feeds (model inputs) is an object that uses input names as keys and OnnxValue as corresponding values.\n   */\n  type FeedsType = OnnxValueMapType;\n\n  /**\n   * A fetches (model outputs) could be one of the following:\n   *\n   * - Omitted. Use model's output names definition.\n   * - An array of string indicating the output names.\n   * - An object that use output names as keys and OnnxValue or null as corresponding values.\n   *\n   * @remark\n   * different from input argument, in output, OnnxValue is optional. If an OnnxValue is present it will be\n   * used as a pre-allocated value by the inference engine; if omitted, inference engine will allocate buffer\n   * internally.\n   */\n  type FetchesType = readonly string[]|NullableOnnxValueMapType;\n\n  /**\n   * A inferencing return type is an object that uses output names as keys and OnnxValue as corresponding values.\n   */\n  type ReturnType = OnnxValueMapType;\n\n  // #endregion\n\n  // #region session options\n\n  /**\n   * A set of configurations for session behavior.\n   */\n  export interface SessionOptions {\n    /**\n     * An array of execution provider options.\n     *\n     * An execution provider option can be a string indicating the name of the execution provider,\n     * or an object of corresponding type.\n     */\n    executionProviders?: readonly ExecutionProviderConfig[];\n\n    /**\n     * The intra OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    intraOpNumThreads?: number;\n\n    /**\n     * The inter OP threads number.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native).\n     */\n    interOpNumThreads?: number;\n\n    /**\n     * The free dimension override.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    freeDimensionOverrides?: {readonly [dimensionName: string]: number};\n\n    /**\n     * The optimization level.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    graphOptimizationLevel?: 'disabled'|'basic'|'extended'|'all';\n\n    /**\n     * Whether enable CPU memory arena.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableCpuMemArena?: boolean;\n\n    /**\n     * Whether enable memory pattern.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    enableMemPattern?: boolean;\n\n    /**\n     * Execution mode.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    executionMode?: 'sequential'|'parallel';\n\n    /**\n     * Optimized model file path.\n     *\n     * If this setting is specified, the optimized model will be dumped. In browser, a blob will be created\n     * with a pop-up window.\n     */\n    optimizedModelFilePath?: string;\n\n    /**\n     * Wether enable profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    enableProfiling?: boolean;\n\n    /**\n     * File prefix for profiling.\n     *\n     * This setting is a placeholder for a future use.\n     */\n    profileFilePrefix?: string;\n\n    /**\n     * Log ID.\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logId?: string;\n\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Specify string as a preferred data location for all outputs, or an object that use output names as keys and a\n     * preferred data location as corresponding values.\n     *\n     * This setting is available only in ONNXRuntime Web for WebGL and WebGPU EP.\n     */\n    preferredOutputLocation?: OnnxValueDataLocation|{readonly [outputName: string]: OnnxValueDataLocation};\n\n    /**\n     * Store configurations for a session. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_session_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     * ```js\n     * extra: {\n     *   session: {\n     *     set_denormal_as_zero: \"1\",\n     *     disable_prepacking: \"1\"\n     *   },\n     *   optimization: {\n     *     enable_gelu_approximation: \"1\"\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #region execution providers\n\n  // Currently, we have the following backends to support execution providers:\n  // Backend Node.js binding: supports 'cpu' and 'cuda'.\n  // Backend WebAssembly: supports 'cpu', 'wasm', 'xnnpack' and 'webnn'.\n  // Backend ONNX.js: supports 'webgl'.\n  // Backend React Native: supports 'cpu', 'xnnpack', 'coreml' (iOS), 'nnapi' (Android).\n  interface ExecutionProviderOptionMap {\n    cpu: CpuExecutionProviderOption;\n    coreml: CoreMlExecutionProviderOption;\n    cuda: CudaExecutionProviderOption;\n    dml: DmlExecutionProviderOption;\n    tensorrt: TensorRtExecutionProviderOption;\n    wasm: WebAssemblyExecutionProviderOption;\n    webgl: WebGLExecutionProviderOption;\n    xnnpack: XnnpackExecutionProviderOption;\n    webgpu: WebGpuExecutionProviderOption;\n    webnn: WebNNExecutionProviderOption;\n    nnapi: NnapiExecutionProviderOption;\n  }\n\n  type ExecutionProviderName = keyof ExecutionProviderOptionMap;\n  type ExecutionProviderConfig =\n      ExecutionProviderOptionMap[ExecutionProviderName]|ExecutionProviderOption|ExecutionProviderName|string;\n\n  export interface ExecutionProviderOption {\n    readonly name: string;\n  }\n  export interface CpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cpu';\n    useArena?: boolean;\n  }\n  export interface CudaExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'cuda';\n    deviceId?: number;\n  }\n  export interface CoreMlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    coreMlFlags?: number;\n  }\n  export interface DmlExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'dml';\n    deviceId?: number;\n  }\n  export interface TensorRtExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'tensorrt';\n    deviceId?: number;\n  }\n  export interface WebAssemblyExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'wasm';\n  }\n  export interface WebGLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgl';\n    // TODO: add flags\n  }\n  export interface XnnpackExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'xnnpack';\n  }\n  export interface WebGpuExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webgpu';\n    preferredLayout?: 'NCHW'|'NHWC';\n  }\n  export interface WebNNExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'webnn';\n    deviceType?: 'cpu'|'gpu';\n    numThreads?: number;\n    powerPreference?: 'default'|'low-power'|'high-performance';\n  }\n  export interface CoreMLExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'coreml';\n    useCPUOnly?: boolean;\n    enableOnSubgraph?: boolean;\n    onlyEnableDeviceWithANE?: boolean;\n  }\n  export interface NnapiExecutionProviderOption extends ExecutionProviderOption {\n    readonly name: 'nnapi';\n    useFP16?: boolean;\n    useNCHW?: boolean;\n    cpuDisabled?: boolean;\n    cpuOnly?: boolean;\n  }\n  // #endregion\n\n  // #endregion\n\n  // #region run options\n\n  /**\n   * A set of configurations for inference run behavior\n   */\n  export interface RunOptions {\n    /**\n     * Log severity level. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/common/logging/severity.h\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    logSeverityLevel?: 0|1|2|3|4;\n\n    /**\n     * Log verbosity level.\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    logVerbosityLevel?: number;\n\n    /**\n     * Terminate all incomplete OrtRun calls as soon as possible if true\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     */\n    terminate?: boolean;\n\n    /**\n     * A tag for the Run() calls using this\n     *\n     * This setting is available only in ONNXRuntime (Node.js binding and react-native) or WebAssembly backend\n     */\n    tag?: string;\n\n    /**\n     * Set a single run configuration entry. See\n     * https://github.com/microsoft/onnxruntime/blob/main/include/onnxruntime/core/session/\n     * onnxruntime_run_options_config_keys.h\n     *\n     * This setting is available only in WebAssembly backend. Will support Node.js binding and react-native later\n     *\n     * @example\n     *\n     * ```js\n     * extra: {\n     *   memory: {\n     *     enable_memory_arena_shrinkage: \"1\",\n     *   }\n     * }\n     * ```\n     */\n    extra?: Record<string, unknown>;\n  }\n\n  // #endregion\n\n  // #region value metadata\n\n  // eslint-disable-next-line @typescript-eslint/no-empty-interface\n  interface ValueMetadata {\n    // TBD\n  }\n\n  // #endregion\n}\n\n/**\n * Represent a runtime instance of an ONNX model.\n */\nexport interface InferenceSession {\n  // #region run()\n\n  /**\n   * Execute the model asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Execute the model asynchronously with the given feeds, fetches and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for detail.\n   * @param fetches - Representation of the model output. See type description of `InferenceSession.OutputType` for\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  run(feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n\n  // #endregion\n\n  // #region profiling\n\n  /**\n   * Start profiling.\n   */\n  startProfiling(): void;\n\n  /**\n   * End profiling.\n   */\n  endProfiling(): void;\n\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n\n  // /**\n  //  * Get input metadata of the loaded model.\n  //  */\n  // readonly inputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // /**\n  //  * Get output metadata of the loaded model.\n  //  */\n  // readonly outputMetadata: ReadonlyArray<Readonly<InferenceSession.ValueMetadata>>;\n\n  // #endregion\n}\n\nexport interface InferenceSessionFactory {\n  // #region create()\n\n  /**\n   * Create a new inference session and load model asynchronously from an ONNX model file.\n   *\n   * @param uri - The URI or file path of the model to load.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(uri: string, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from segment of an array bufer.\n   *\n   * @param buffer - An ArrayBuffer representation of an ONNX model.\n   * @param byteOffset - The beginning of the specified portion of the array buffer.\n   * @param byteLength - The length in bytes of the array buffer.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: ArrayBufferLike, byteOffset: number, byteLength?: number, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSession>;\n\n  /**\n   * Create a new inference session and load model asynchronously from a Uint8Array.\n   *\n   * @param buffer - A Uint8Array representation of an ONNX model.\n   * @param options - specify configuration for creating a new inference session.\n   * @returns A promise that resolves to an InferenceSession object.\n   */\n  create(buffer: Uint8Array, options?: InferenceSession.SessionOptions): Promise<InferenceSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const InferenceSession: InferenceSessionFactory = InferenceSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from './tensor.js';\n\ntype NonTensorType = never;\n\n/**\n * Type OnnxValue Represents both tensors and non-tensors value for model's inputs/outputs.\n *\n * NOTE: currently not support non-tensor\n */\nexport type OnnxValue = Tensor|NonTensorType;\n\n/**\n * Type OnnxValueDataLocation represents the location of the data of an OnnxValue.\n */\nexport type OnnxValueDataLocation = Tensor.DataLocation;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {resolveBackend} from './backend-impl.js';\nimport {SessionHandler, TrainingSessionHandler} from './backend.js';\nimport {InferenceSession as InferenceSession} from './inference-session.js';\nimport {OnnxValue} from './onnx-value.js';\nimport {Tensor} from './tensor.js';\nimport {TrainingSession as TrainingSessionInterface, TrainingSessionCreateOptions} from './training-session.js';\n\ntype SessionOptions = InferenceSession.SessionOptions;\ntype FeedsType = InferenceSession.FeedsType;\ntype FetchesType = InferenceSession.FetchesType;\ntype ReturnType = InferenceSession.ReturnType;\ntype RunOptions = InferenceSession.RunOptions;\n\nconst noBackendErrMsg: string = 'Training backend could not be resolved. ' +\n    'Make sure you\\'re using the correct configuration & WebAssembly files.';\n\nexport class TrainingSession implements TrainingSessionInterface {\n  private constructor(handler: TrainingSessionHandler) {\n    this.handler = handler;\n  }\n  private handler: TrainingSessionHandler;\n\n  get inputNames(): readonly string[] {\n    return this.handler.inputNames;\n  }\n  get outputNames(): readonly string[] {\n    return this.handler.outputNames;\n  }\n\n  static async create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: SessionOptions):\n      Promise<TrainingSession> {\n    const evalModel: string|Uint8Array = trainingOptions.evalModel || '';\n    const optimizerModel: string|Uint8Array = trainingOptions.optimizerModel || '';\n    const options: SessionOptions = sessionOptions || {};\n\n    // get backend hints\n    const eps = options.executionProviders || [];\n    const backendHints = eps.map(i => typeof i === 'string' ? i : i.name);\n    const backend = await resolveBackend(backendHints);\n    if (backend.createTrainingSessionHandler) {\n      const handler = await backend.createTrainingSessionHandler(\n          trainingOptions.checkpointState, trainingOptions.trainModel, evalModel, optimizerModel, options);\n      return new TrainingSession(handler);\n    } else {\n      throw new Error(noBackendErrMsg);\n    }\n  }\n\n  /**\n   * Helper function for runTrainStep and future runStep methods that handles the type-narrowing conversion from\n   * the given parameters to SessionHandler.FetchesType and RunOptions.\n   *\n   * @param feeds the required input\n   * @param arg1 narrowed & converted into the SessionHandler.FetchesType or RunOptions object\n   * @param arg2 optional RunOptions object.\n   * @returns\n   */\n  typeNarrowingForRunStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions):\n      [SessionHandler.FetchesType, RunOptions] {\n    const fetches: {[name: string]: OnnxValue|null} = {};\n    let options: RunOptions = {};\n    // check inputs\n    if (typeof feeds !== 'object' || feeds === null || feeds instanceof Tensor || Array.isArray(feeds)) {\n      throw new TypeError(\n          '\\'feeds\\' must be an object that use input names as keys and OnnxValue as corresponding values.');\n    }\n\n    let isFetchesEmpty = true;\n    // determine which override is being used\n    if (typeof arg1 === 'object') {\n      if (arg1 === null) {\n        throw new TypeError('Unexpected argument[1]: cannot be null.');\n      }\n      if (arg1 instanceof Tensor) {\n        throw new TypeError('\\'fetches\\' cannot be a Tensor');\n      }\n\n      if (Array.isArray(arg1)) {\n        if (arg1.length === 0) {\n          throw new TypeError('\\'fetches\\' cannot be an empty array.');\n        }\n        isFetchesEmpty = false;\n        // output names\n        for (const name of arg1) {\n          if (typeof name !== 'string') {\n            throw new TypeError('\\'fetches\\' must be a string array or an object.');\n          }\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new RangeError(`'fetches' contains invalid output name: ${name}.`);\n          }\n          fetches[name] = null;\n        }\n\n        if (typeof arg2 === 'object' && arg2 !== null) {\n          options = arg2;\n        } else if (typeof arg2 !== 'undefined') {\n          throw new TypeError('\\'options\\' must be an object.');\n        }\n      } else {\n        // decide whether arg1 is fetches or options\n        // if any output name is present and its value is valid OnnxValue, we consider it fetches\n        let isFetches = false;\n        const arg1Keys = Object.getOwnPropertyNames(arg1);\n        for (const name of this.outputNames) {\n          if (arg1Keys.indexOf(name) !== -1) {\n            const v = (arg1 as InferenceSession.NullableOnnxValueMapType)[name];\n            if (v === null || v instanceof Tensor) {\n              isFetches = true;\n              isFetchesEmpty = false;\n              fetches[name] = v;\n            }\n          }\n        }\n\n        if (isFetches) {\n          if (typeof arg2 === 'object' && arg2 !== null) {\n            options = arg2;\n          } else if (typeof arg2 !== 'undefined') {\n            throw new TypeError('\\'options\\' must be an object.');\n          }\n        } else {\n          options = arg1 as RunOptions;\n        }\n      }\n    } else if (typeof arg1 !== 'undefined') {\n      throw new TypeError('Unexpected argument[1]: must be \\'fetches\\' or \\'options\\'.');\n    }\n\n    // check if all inputs are in feed\n    for (const name of this.inputNames) {\n      if (typeof feeds[name] === 'undefined') {\n        throw new Error(`input '${name}' is missing in 'feeds'.`);\n      }\n    }\n\n    // if no fetches is specified, we use the full output names list\n    if (isFetchesEmpty) {\n      for (const name of this.outputNames) {\n        fetches[name] = null;\n      }\n    }\n\n    return [fetches, options];\n  }\n\n  /**\n   * Helper method for runTrainStep and any other runStep methods. Takes the ReturnType result from the SessionHandler\n   * and changes it into a map of Tensors.\n   *\n   * @param results\n   * @returns\n   */\n  convertHandlerReturnTypeToMapOfTensors(results: SessionHandler.ReturnType): ReturnType {\n    const returnValue: {[name: string]: OnnxValue} = {};\n    for (const key in results) {\n      if (Object.hasOwnProperty.call(results, key)) {\n        const result = results[key];\n        if (result instanceof Tensor) {\n          returnValue[key] = result;\n        } else {\n          returnValue[key] = new Tensor(result.type, result.data, result.dims);\n        }\n      }\n    }\n    return returnValue;\n  }\n\n  runTrainStep(feeds: FeedsType, options?: RunOptions): Promise<ReturnType>;\n  runTrainStep(feeds: FeedsType, fetches: FetchesType, options?: RunOptions): Promise<ReturnType>;\n  async runTrainStep(feeds: FeedsType, arg1?: FetchesType|RunOptions, arg2?: RunOptions): Promise<ReturnType> {\n    const [fetches, options] = this.typeNarrowingForRunStep(feeds, arg1, arg2);\n    const results = await this.handler.runTrainStep(feeds, fetches, options);\n    return this.convertHandlerReturnTypeToMapOfTensors(results);\n  }\n\n  async loadParametersBuffer(_array: Uint8Array, _trainableOnly: boolean): Promise<void> {\n    throw new Error('Method not implemented.');\n  }\n\n  async getContiguousParameters(_trainableOnly: boolean): Promise<Uint8Array> {\n    throw new Error('Method not implemented.');\n  }\n\n  async release(): Promise<void> {\n    return this.handler.dispose();\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from './inference-session.js';\nimport {TrainingSession as TrainingSessionImpl} from './training-session-impl.js';\n\n/* eslint-disable @typescript-eslint/no-redeclare */\n\nexport declare namespace TrainingSession {\n  /**\n   * Either URI file path (string) or Uint8Array containing model or checkpoint information.\n   */\n  type URIorBuffer = string|Uint8Array;\n}\n\n/**\n * Represent a runtime instance of an ONNX training session,\n * which contains a model that can be trained, and, optionally,\n * an eval and optimizer model.\n */\nexport interface TrainingSession {\n  // #region run()\n\n  /**\n   * Run TrainStep asynchronously with the given feeds and options.\n   *\n   * @param feeds - Representation of the model input. See type description of `InferenceSession.InputType` for\n   detail.\n   * @param options - Optional. A set of options that controls the behavior of model training.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding values.\n   */\n  runTrainStep(feeds: InferenceSession.FeedsType, options?: InferenceSession.RunOptions):\n      Promise<InferenceSession.ReturnType>;\n\n  /**\n   * Run a single train step with the given inputs and options.\n   *\n   * @param feeds - Representation of the model input.\n   * @param fetches - Representation of the model output.\n   * detail.\n   * @param options - Optional. A set of options that controls the behavior of model inference.\n   * @returns A promise that resolves to a map, which uses output names as keys and OnnxValue as corresponding\n   values.\n   */\n  runTrainStep(\n      feeds: InferenceSession.FeedsType, fetches: InferenceSession.FetchesType,\n      options?: InferenceSession.RunOptions): Promise<InferenceSession.ReturnType>;\n\n  // #endregion\n\n  // #region copy parameters\n  /**\n   * Copies from a buffer containing parameters to the TrainingSession parameters.\n   *\n   * @param buffer - buffer containing parameters\n   * @param trainableOnly - True if trainable parameters only to be modified, false otherwise.\n   */\n  loadParametersBuffer(array: Uint8Array, trainableOnly: boolean): Promise<void>;\n\n  /**\n   * Copies from the TrainingSession parameters to a buffer.\n   *\n   * @param trainableOnly - True if trainable parameters only to be copied, false othrwise.\n   * @returns A promise that resolves to a buffer of the requested parameters.\n   */\n  getContiguousParameters(trainableOnly: boolean): Promise<Uint8Array>;\n  // #endregion\n\n  // #region release()\n\n  /**\n   * Release the inference session and the underlying resources.\n   */\n  release(): Promise<void>;\n  // #endregion\n\n  // #region metadata\n\n  /**\n   * Get input names of the loaded model.\n   */\n  readonly inputNames: readonly string[];\n\n  /**\n   * Get output names of the loaded model.\n   */\n  readonly outputNames: readonly string[];\n  // #endregion\n}\n\n/**\n * Represents the optional parameters that can be passed into the TrainingSessionFactory.\n */\nexport interface TrainingSessionCreateOptions {\n  /**\n   * URI or buffer for a .ckpt file that contains the checkpoint for the training model.\n   */\n  checkpointState: TrainingSession.URIorBuffer;\n  /**\n   * URI or buffer for the .onnx training file.\n   */\n  trainModel: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx optimizer model file.\n   */\n  optimizerModel?: TrainingSession.URIorBuffer;\n  /**\n   * Optional. URI or buffer for the .onnx eval model file.\n   */\n  evalModel?: TrainingSession.URIorBuffer;\n}\n\n/**\n * Defines method overload possibilities for creating a TrainingSession.\n */\nexport interface TrainingSessionFactory {\n  // #region create()\n\n  /**\n   * Creates a new TrainingSession and asynchronously loads any models passed in through trainingOptions\n   *\n   * @param trainingOptions specify models and checkpoints to load into the Training Session\n   * @param sessionOptions specify configuration for training session behavior\n   *\n   * @returns Promise that resolves to a TrainingSession object\n   */\n  create(trainingOptions: TrainingSessionCreateOptions, sessionOptions?: InferenceSession.SessionOptions):\n      Promise<TrainingSession>;\n\n  // #endregion\n}\n\n// eslint-disable-next-line @typescript-eslint/naming-convention\nexport const TrainingSession: TrainingSessionFactory = TrainingSessionImpl;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/**\n * # ONNX Runtime JavaScript API\n *\n * ONNX Runtime JavaScript API is a unified API for all JavaScript usages, including the following NPM packages:\n *\n * - [onnxruntime-node](https://www.npmjs.com/package/onnxruntime-node)\n * - [onnxruntime-web](https://www.npmjs.com/package/onnxruntime-web)\n * - [onnxruntime-react-native](https://www.npmjs.com/package/onnxruntime-react-native)\n *\n * See also:\n * - [Get Started](https://onnxruntime.ai/docs/get-started/with-javascript.html)\n * - [Inference examples](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js)\n *\n * @packageDocumentation\n */\n\nexport * from './backend.js';\nexport * from './env.js';\nexport * from './inference-session.js';\nexport * from './tensor.js';\nexport * from './onnx-value.js';\nexport * from './training-session.js';\n", "export const readFile = undefined;", "export const join = undefined;", "\nvar ortWasm = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nvar d=moduleArg,aa,k;d.ready=new Promise((a,b)=>{aa=a;k=b});\"use strict\";\nd.jsepInit=(a,b,c,e,f,h,l,n)=>{d.ab=a;d.Ra=b;d.Ta=c;d.La=e;d.Sa=f;d.xa=h;d.Ua=l;d.Va=n;b=(m,q,p)=>(...u)=>{const w=t,g=q?.();u=m(...u);const r=q?.();g!==r&&(m=r,p(g),q=p=null);return t!=w?ba():u};c=m=>async(...q)=>{try{if(d.Fa)throw Error(\"Session already started\");const p=d.Fa={Wa:q[0],errors:[]},u=await m(...q);if(d.Fa!==p)throw Error(\"Session mismatch\");a.flush();const w=p.errors;if(0<w.length){let g=await Promise.all(w);g=g.filter(r=>r);if(0<g.length)throw Error(g.join(\"\\n\"));}return u}finally{d.Fa=\nnull}};d._OrtRun=c(b(d._OrtRun,()=>d._OrtRun,m=>d._OrtRun=m));d._OrtRunWithBinding=c(b(d._OrtRunWithBinding,()=>d._OrtRunWithBinding,m=>d._OrtRunWithBinding=m));d._OrtBindInput=b(d._OrtBindInput,()=>d._OrtBindInput,m=>d._OrtBindInput=m);d.jsepRegisterBuffer=(m,q,p,u)=>a.registerBuffer(m,q,p,u);d.jsepUnregisterBuffers=m=>{a.unregisterBuffers(m)};d.jsepGetBuffer=m=>a.getBuffer(m);d.jsepCreateDownloader=(m,q,p)=>a.createDownloader(m,q,p)};\nvar ca=Object.assign({},d),da=\"./this.program\",x=(a,b)=>{throw b;},ea=\"object\"==typeof window,y=\"function\"==typeof importScripts,fa=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,z=\"\",ha,A,B;\nif(fa){var fs=require(\"fs\"),ia=require(\"path\");z=y?ia.dirname(z)+\"/\":__dirname+\"/\";ha=(a,b)=>{a=a.startsWith(\"file://\")?new URL(a):ia.normalize(a);return fs.readFileSync(a,b?void 0:\"utf8\")};B=a=>{a=ha(a,!0);a.buffer||(a=new Uint8Array(a));return a};A=(a,b,c,e=!0)=>{a=a.startsWith(\"file://\")?new URL(a):ia.normalize(a);fs.readFile(a,e?void 0:\"utf8\",(f,h)=>{f?c(f):b(e?h.buffer:h)})};!d.thisProgram&&1<process.argv.length&&(da=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);x=(a,b)=>{process.exitCode=\na;throw b;};d.inspect=()=>\"[Emscripten Module object]\"}else if(ea||y)y?z=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(z=document.currentScript.src),_scriptDir&&(z=_scriptDir),0!==z.indexOf(\"blob:\")?z=z.substr(0,z.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):z=\"\",ha=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.send(null);return b.responseText},y&&(B=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),\nA=(a,b,c)=>{var e=new XMLHttpRequest;e.open(\"GET\",a,!0);e.responseType=\"arraybuffer\";e.onload=()=>{200==e.status||0==e.status&&e.response?b(e.response):c()};e.onerror=c;e.send(null)};var ja=d.print||console.log.bind(console),C=d.printErr||console.error.bind(console);Object.assign(d,ca);ca=null;d.thisProgram&&(da=d.thisProgram);d.quit&&(x=d.quit);var D;d.wasmBinary&&(D=d.wasmBinary);var noExitRuntime=d.noExitRuntime||!0;\"object\"!=typeof WebAssembly&&E(\"no native wasm support detected\");\nvar F,G,I=!1,J,K,L,M,N,ka,la;function ma(){var a=F.buffer;d.HEAP8=K=new Int8Array(a);d.HEAP16=new Int16Array(a);d.HEAP32=M=new Int32Array(a);d.HEAPU8=L=new Uint8Array(a);d.HEAPU16=new Uint16Array(a);d.HEAPU32=N=new Uint32Array(a);d.HEAPF32=ka=new Float32Array(a);d.HEAPF64=la=new Float64Array(a)}var O,na=[],oa=[],pa=[];function qa(){var a=d.preRun.shift();na.unshift(a)}var P=0,ra=null,Q=null;\nfunction E(a){if(d.onAbort)d.onAbort(a);a=\"Aborted(\"+a+\")\";C(a);I=!0;J=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");k(a);throw a;}function sa(a){return a.startsWith(\"data:application/octet-stream;base64,\")}var R;R=\"ort-wasm-simd.wasm\";if(!sa(R)){var ta=R;R=d.locateFile?d.locateFile(ta,z):z+ta}function ua(a){if(a==R&&D)return new Uint8Array(D);if(B)return B(a);throw\"both async and sync fetching of the wasm failed\";}\nfunction va(a){if(!D&&(ea||y)){if(\"function\"==typeof fetch&&!a.startsWith(\"file://\"))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>ua(a));if(A)return new Promise((b,c)=>{A(a,e=>b(new Uint8Array(e)),c)})}return Promise.resolve().then(()=>ua(a))}function wa(a,b,c){return va(a).then(e=>WebAssembly.instantiate(e,b)).then(e=>e).then(c,e=>{C(\"failed to asynchronously prepare wasm: \"+e);E(e)})}\nfunction xa(a,b){var c=R;return D||\"function\"!=typeof WebAssembly.instantiateStreaming||sa(c)||c.startsWith(\"file://\")||fa||\"function\"!=typeof fetch?wa(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(e=>WebAssembly.instantiateStreaming(e,a).then(b,function(f){C(\"wasm streaming compile failed: \"+f);C(\"falling back to ArrayBuffer instantiation\");return wa(c,a,b)}))}\nvar S,ya={916496:a=>{d.xa(\"Abs\",a,void 0)},916547:a=>{d.xa(\"Neg\",a,void 0)},916598:a=>{d.xa(\"Floor\",a,void 0)},916651:a=>{d.xa(\"Ceil\",a,void 0)},916703:a=>{d.xa(\"Reciprocal\",a,void 0)},916761:a=>{d.xa(\"Sqrt\",a,void 0)},916813:a=>{d.xa(\"Exp\",a,void 0)},916864:a=>{d.xa(\"Erf\",a,void 0)},916915:a=>{d.xa(\"Sigmoid\",a,void 0)},916970:a=>{d.xa(\"Log\",a,void 0)},917021:a=>{d.xa(\"Sin\",a,void 0)},917072:a=>{d.xa(\"Cos\",a,void 0)},917123:a=>{d.xa(\"Tan\",a,void 0)},917174:a=>{d.xa(\"Asin\",a,void 0)},917226:a=>{d.xa(\"Acos\",\na,void 0)},917278:a=>{d.xa(\"Atan\",a,void 0)},917330:a=>{d.xa(\"Sinh\",a,void 0)},917382:a=>{d.xa(\"Cosh\",a,void 0)},917434:a=>{d.xa(\"Asinh\",a,void 0)},917487:a=>{d.xa(\"Acosh\",a,void 0)},917540:a=>{d.xa(\"Atanh\",a,void 0)},917593:a=>{d.xa(\"Tanh\",a,void 0)},917645:a=>{d.xa(\"Not\",a,void 0)},917696:(a,b,c)=>{d.xa(\"ClipV10\",a,{min:b,max:c})},917768:a=>{d.xa(\"Clip\",a,void 0)},917820:(a,b)=>{d.xa(\"Elu\",a,{alpha:b})},917878:a=>{d.xa(\"Relu\",a,void 0)},917930:(a,b)=>{d.xa(\"LeakyRelu\",a,{alpha:b})},917994:(a,b)=>\n{d.xa(\"ThresholdedRelu\",a,{alpha:b})},918064:(a,b)=>{d.xa(\"Cast\",a,{to:b})},918122:a=>{d.xa(\"Add\",a,void 0)},918173:a=>{d.xa(\"Sub\",a,void 0)},918224:a=>{d.xa(\"Mul\",a,void 0)},918275:a=>{d.xa(\"Div\",a,void 0)},918326:a=>{d.xa(\"Pow\",a,void 0)},918377:a=>{d.xa(\"Equal\",a,void 0)},918430:a=>{d.xa(\"Greater\",a,void 0)},918485:a=>{d.xa(\"GreaterOrEqual\",a,void 0)},918547:a=>{d.xa(\"Less\",a,void 0)},918599:a=>{d.xa(\"LessOrEqual\",a,void 0)},918658:(a,b,c,e,f)=>{d.xa(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},918822:(a,b,c,e,f)=>{d.xa(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},918985:(a,b,c,e,f)=>{d.xa(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},919148:(a,b,c,e,f)=>{d.xa(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},919312:(a,b,c,e,f)=>{d.xa(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},919475:(a,b,c,e,f)=>{d.xa(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},919637:(a,b,c,e,f)=>{d.xa(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},919799:(a,b,c,e,f)=>{d.xa(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},919965:(a,b,c,e,f)=>{d.xa(\"ReduceSumSquare\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},920134:(a,b,c,e,f)=>{d.xa(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},920303:a=>{d.xa(\"Where\",a,void 0)},920356:(a,b,c)=>{d.xa(\"Transpose\",a,{perm:b?Array.from(M.subarray(c>>>0,c+b>>>0)):[]})},920469:(a,b,c,e,f,h,l,n,m,q,p,u,w,g,r)=>{d.xa(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,l],strides:[n],wIsConst:()=>!!K[q>>>0],outputPadding:p?\nArray.from(M.subarray(u>>>0,u+p>>>0)):[],outputShape:w?Array.from(M.subarray(g>>>0,g+w>>>0)):[],activation:T(r)})},920883:(a,b,c,e,f,h,l,n,m,q,p,u,w,g)=>{d.xa(\"ConvTranspose\",a,{format:n?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(M.subarray(c>>>0,c+2>>>0)),group:e,kernelShape:Array.from(M.subarray(f>>>0,f+2>>>0)),pads:Array.from(M.subarray(h>>>0,h+4>>>0)),strides:Array.from(M.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!K[m>>>0],outputPadding:0<q?Array.from(M.subarray(p>>>0,p+q>>>0)):[],outputShape:0<\nu?Array.from(M.subarray(w>>>0,w+u>>>0)):[],activation:T(g)})},921440:(a,b,c,e,f,h,l,n,m,q,p,u,w,g,r)=>{d.xa(\"ConvTranspose\",a,{format:m?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:e,kernel_shape:[f],pads:[h,l],strides:[n],wIsConst:()=>!!K[q>>>0],outputPadding:p?Array.from(M.subarray(u>>>0,u+p>>>0)):[],outputShape:w?Array.from(M.subarray(g>>>0,g+w>>>0)):[],activation:T(r)})},921854:(a,b,c,e,f,h,l,n,m,q,p,u,w,g)=>{d.xa(\"ConvTranspose\",a,{format:n?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(M.subarray(c>>>\n0,c+2>>>0)),group:e,kernelShape:Array.from(M.subarray(f>>>0,f+2>>>0)),pads:Array.from(M.subarray(h>>>0,h+4>>>0)),strides:Array.from(M.subarray(l>>>0,l+2>>>0)),wIsConst:()=>!!K[m>>>0],outputPadding:0<q?Array.from(M.subarray(p>>>0,p+q>>>0)):[],outputShape:0<u?Array.from(M.subarray(w>>>0,w+u>>>0)):[],activation:T(g)})},922411:(a,b)=>{d.xa(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},922502:(a,b,c,e,f,h,l,n,m,q,p,u,w,g,r,v)=>{d.xa(\"AveragePool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,\nstorage_order:f,dilations:[h,l],kernel_shape:[n,m],pads:[q,p,u,w],strides:[g,r]})},922786:(a,b)=>{d.xa(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},922877:(a,b,c,e,f,h,l,n,m,q,p,u,w,g,r,v)=>{d.xa(\"AveragePool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,l],kernel_shape:[n,m],pads:[q,p,u,w],strides:[g,r]})},923161:(a,b)=>{d.xa(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},923248:(a,b,c,e,f,h,l,n,m,q,p,u,w,g,r,v)=>{d.xa(\"MaxPool\",a,{format:v?\n\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,l],kernel_shape:[n,m],pads:[q,p,u,w],strides:[g,r]})},923528:(a,b)=>{d.xa(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},923615:(a,b,c,e,f,h,l,n,m,q,p,u,w,g,r,v)=>{d.xa(\"MaxPool\",a,{format:v?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:e,storage_order:f,dilations:[h,l],kernel_shape:[n,m],pads:[q,p,u,w],strides:[g,r]})},923895:(a,b,c,e,f)=>{d.xa(\"Gemm\",a,{alpha:b,beta:c,transA:e,transB:f})},923999:a=>{d.xa(\"MatMul\",\na,void 0)},924053:(a,b,c,e)=>{d.xa(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},924161:(a,b,c,e)=>{d.xa(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:e})},924269:(a,b)=>{d.xa(\"Softmax\",a,{axis:b})},924332:(a,b)=>{d.xa(\"Concat\",a,{axis:b})},924392:(a,b,c,e,f)=>{d.xa(\"Split\",a,{axis:b,numOutputs:c,splitSizes:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},924537:a=>{d.xa(\"Expand\",a,void 0)},924591:(a,b)=>{d.xa(\"Gather\",a,{axis:Number(b)})},924662:(a,b)=>{d.xa(\"GatherElements\",a,{axis:Number(b)})},\n924741:(a,b,c,e,f,h,l,n,m,q,p)=>{d.xa(\"Resize\",a,{antialias:b,axes:c?Array.from(M.subarray(e>>>0,e+c>>>0)):[],coordinateTransformMode:T(f),cubicCoeffA:h,excludeOutside:l,extrapolationValue:n,keepAspectRatioPolicy:T(m),mode:T(q),nearestMode:T(p)})},925092:(a,b,c,e,f,h,l)=>{d.xa(\"Slice\",a,{starts:b?Array.from(M.subarray(c>>>0,c+b>>>0)):[],ends:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[],axes:h?Array.from(M.subarray(l>>>0,l+h>>>0)):[]})},925323:a=>{d.xa(\"Tile\",a,void 0)},925375:(a,b,c)=>{d.xa(\"LayerNormalization\",\na,{axis:Number(b),epsilon:Number(c)})},925482:(a,b,c)=>{d.xa(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},925596:(a,b,c)=>{d.xa(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},925710:a=>{d.xa(\"Range\",a,void 0)},925763:(a,b)=>{d.xa(\"Einsum\",a,{equation:T(b)})},925844:(a,b,c,e,f)=>{d.xa(\"Pad\",a,{mode:b,value:c,pads:e?Array.from(M.subarray(f>>>0,f+e>>>0)):[]})},925976:a=>{d.xa(\"Gelu\",a,void 0)},926028:a=>{d.xa(\"BiasAdd\",a,void 0)},926083:a=>{d.xa(\"BiasSplitGelu\",a,void 0)},\n926144:(a,b)=>{d.xa(\"SkipLayerNormalization\",a,{epsilon:b})},926225:(a,b,c,e,f,h,l,n,m,q,p,u,w)=>{d.xa(\"Conv\",a,{format:m?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:e,kernel_shape:[f],pads:h?Array.from(M.subarray(l>>>0,l+h>>>0)):[],strides:[n],w_is_const:()=>!!K[q>>>0],activation:T(p),activation_params:u?Array.from(ka.subarray(w>>>0,w+u>>>0)):[]})},926606:(a,b,c,e,f,h,l,n,m,q,p,u,w,g,r,v)=>{d.xa(\"Conv\",a,{format:u?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,e],group:f,kernel_shape:[h,l],pads:n?Array.from(M.subarray(m>>>\n0,m+n>>>0)):[],strides:[q,p],w_is_const:()=>!!K[w>>>0],activation:T(g),activation_params:r?Array.from(ka.subarray(v>>>0,v+r>>>0)):[]})},927008:a=>{d.Ua(a)},927042:(a,b)=>d.Va(a,b,d.Fa.Wa,d.Fa.errors),927154:a=>d.Ra(a),927187:a=>d.Ta(a),927219:(a,b,c)=>{d.La(a,b,c,!0)},927258:(a,b,c)=>{d.La(a,b,c)}};function za(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}var Aa=a=>{for(;0<a.length;)a.shift()(d)};\nfunction Ba(a){this.Ka=a-24;this.Pa=function(b){N[this.Ka+4>>2>>>0]=b};this.Oa=function(b){N[this.Ka+8>>2>>>0]=b};this.Ma=function(b,c){this.Na();this.Pa(b);this.Oa(c)};this.Na=function(){N[this.Ka+16>>2>>>0]=0}}\nvar Ca=0,Da=0,Ea=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Fa=(a,b,c)=>{b>>>=0;var e=b+c;for(c=b;a[c]&&!(c>=e);)++c;if(16<c-b&&a.buffer&&Ea)return Ea.decode(a.subarray(b,c));for(e=\"\";b<c;){var f=a[b++];if(f&128){var h=a[b++]&63;if(192==(f&224))e+=String.fromCharCode((f&31)<<6|h);else{var l=a[b++]&63;f=224==(f&240)?(f&15)<<12|h<<6|l:(f&7)<<18|h<<12|l<<6|a[b++]&63;65536>f?e+=String.fromCharCode(f):(f-=65536,e+=String.fromCharCode(55296|f>>10,56320|f&1023))}}else e+=String.fromCharCode(f)}return e},\nT=(a,b)=>(a>>>=0)?Fa(L,a,b):\"\",Ga=a=>{for(var b=0,c=0;c<a.length;++c){var e=a.charCodeAt(c);127>=e?b++:2047>=e?b+=2:55296<=e&&57343>=e?(b+=4,++c):b+=3}return b},Ha=(a,b,c,e)=>{c>>>=0;if(!(0<e))return 0;var f=c;e=c+e-1;for(var h=0;h<a.length;++h){var l=a.charCodeAt(h);if(55296<=l&&57343>=l){var n=a.charCodeAt(++h);l=65536+((l&1023)<<10)|n&1023}if(127>=l){if(c>=e)break;b[c++>>>0]=l}else{if(2047>=l){if(c+1>=e)break;b[c++>>>0]=192|l>>6}else{if(65535>=l){if(c+2>=e)break;b[c++>>>0]=224|l>>12}else{if(c+\n3>=e)break;b[c++>>>0]=240|l>>18;b[c++>>>0]=128|l>>12&63}b[c++>>>0]=128|l>>6&63}b[c++>>>0]=128|l&63}}b[c>>>0]=0;return c-f},U=a=>0===a%4&&(0!==a%100||0===a%400),Ia=[0,31,60,91,121,152,182,213,244,274,305,335],Ja=[0,31,59,90,120,151,181,212,243,273,304,334],La=a=>{var b=Ga(a)+1,c=Ka(b);c&&Ha(a,L,c,b);return c},Ma=[],Na=(a,b)=>{Ma.length=0;var c;for(b>>=2;c=L[a++>>>0];)b+=105!=c&b,Ma.push(105==c?M[b>>>0]:la[b++>>>1]),++b;return Ma},Oa={},Ra=()=>{if(!Qa){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",\nPWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:da||\"./this.program\"},b;for(b in Oa)void 0===Oa[b]?delete a[b]:a[b]=Oa[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Qa=c}return Qa},Qa,Sa=[null,[],[]],Ta=[31,29,31,30,31,30,31,31,30,31,30,31],Ua=[31,28,31,30,31,30,31,31,30,31,30,31];function Va(a){var b=Array(Ga(a)+1);Ha(a,b,0,b.length);return b}\nfunction Wa(a,b,c,e){function f(g,r,v){for(g=\"number\"==typeof g?g.toString():g||\"\";g.length<r;)g=v[0]+g;return g}function h(g,r){return f(g,r,\"0\")}function l(g,r){function v(Pa){return 0>Pa?-1:0<Pa?1:0}var H;0===(H=v(g.getFullYear()-r.getFullYear()))&&0===(H=v(g.getMonth()-r.getMonth()))&&(H=v(g.getDate()-r.getDate()));return H}function n(g){switch(g.getDay()){case 0:return new Date(g.getFullYear()-1,11,29);case 1:return g;case 2:return new Date(g.getFullYear(),0,3);case 3:return new Date(g.getFullYear(),\n0,2);case 4:return new Date(g.getFullYear(),0,1);case 5:return new Date(g.getFullYear()-1,11,31);case 6:return new Date(g.getFullYear()-1,11,30)}}function m(g){var r=g.Da;for(g=new Date((new Date(g.Ea+1900,0,1)).getTime());0<r;){var v=g.getMonth(),H=(U(g.getFullYear())?Ta:Ua)[v];if(r>H-g.getDate())r-=H-g.getDate()+1,g.setDate(1),11>v?g.setMonth(v+1):(g.setMonth(0),g.setFullYear(g.getFullYear()+1));else{g.setDate(g.getDate()+r);break}}v=new Date(g.getFullYear()+1,0,4);r=n(new Date(g.getFullYear(),\n0,4));v=n(v);return 0>=l(r,g)?0>=l(v,g)?g.getFullYear()+1:g.getFullYear():g.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;e>>>=0;var q=M[e+40>>2>>>0];e={Za:M[e>>2>>>0],Ya:M[e+4>>2>>>0],Ga:M[e+8>>2>>>0],Ja:M[e+12>>2>>>0],Ha:M[e+16>>2>>>0],Ea:M[e+20>>2>>>0],Ca:M[e+24>>2>>>0],Da:M[e+28>>2>>>0],bb:M[e+32>>2>>>0],Xa:M[e+36>>2>>>0],$a:q?T(q):\"\"};c=T(c);q={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\n\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var p in q)c=c.replace(new RegExp(p,\"g\"),q[p]);var u=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),w=\"January February March April May June July August September October November December\".split(\" \");q={\"%a\":g=>u[g.Ca].substring(0,3),\"%A\":g=>u[g.Ca],\"%b\":g=>w[g.Ha].substring(0,\n3),\"%B\":g=>w[g.Ha],\"%C\":g=>h((g.Ea+1900)/100|0,2),\"%d\":g=>h(g.Ja,2),\"%e\":g=>f(g.Ja,2,\" \"),\"%g\":g=>m(g).toString().substring(2),\"%G\":g=>m(g),\"%H\":g=>h(g.Ga,2),\"%I\":g=>{g=g.Ga;0==g?g=12:12<g&&(g-=12);return h(g,2)},\"%j\":g=>{for(var r=0,v=0;v<=g.Ha-1;r+=(U(g.Ea+1900)?Ta:Ua)[v++]);return h(g.Ja+r,3)},\"%m\":g=>h(g.Ha+1,2),\"%M\":g=>h(g.Ya,2),\"%n\":()=>\"\\n\",\"%p\":g=>0<=g.Ga&&12>g.Ga?\"AM\":\"PM\",\"%S\":g=>h(g.Za,2),\"%t\":()=>\"\\t\",\"%u\":g=>g.Ca||7,\"%U\":g=>h(Math.floor((g.Da+7-g.Ca)/7),2),\"%V\":g=>{var r=Math.floor((g.Da+\n7-(g.Ca+6)%7)/7);2>=(g.Ca+371-g.Da-2)%7&&r++;if(r)53==r&&(v=(g.Ca+371-g.Da)%7,4==v||3==v&&U(g.Ea)||(r=1));else{r=52;var v=(g.Ca+7-g.Da-1)%7;(4==v||5==v&&U(g.Ea%400-1))&&r++}return h(r,2)},\"%w\":g=>g.Ca,\"%W\":g=>h(Math.floor((g.Da+7-(g.Ca+6)%7)/7),2),\"%y\":g=>(g.Ea+1900).toString().substring(2),\"%Y\":g=>g.Ea+1900,\"%z\":g=>{g=g.Xa;var r=0<=g;g=Math.abs(g)/60;return(r?\"+\":\"-\")+String(\"0000\"+(g/60*100+g%60)).slice(-4)},\"%Z\":g=>g.$a,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");for(p in q)c.includes(p)&&(c=c.replace(new RegExp(p,\n\"g\"),q[p](e)));c=c.replace(/\\0\\0/g,\"%\");p=Va(c);if(p.length>b)return 0;K.set(p,a>>>0);return p.length-1}function V(a){try{a()}catch(b){E(b)}}function Xa(a){var b={},c;for(c in a)(function(e){var f=a[e];b[e]=\"function\"==typeof f?function(){W.push(e);try{return f.apply(null,arguments)}finally{I||(W.pop()===e||E(),t&&1===X&&0===W.length&&(X=0,V(Ya),\"undefined\"!=typeof Fibers&&Fibers.cb()))}}:f})(c);return b}var X=0,t=null,Za=0,W=[],$a={},ab={},bb=0,cb=null,db=[];\nfunction ba(){return new Promise((a,b)=>{cb={resolve:a,reject:b}})}function eb(){var a=Ka(65548),b=a+12;N[a>>2>>>0]=b;N[a+4>>2>>>0]=b+65536;b=W[0];var c=$a[b];void 0===c&&(c=bb++,$a[b]=c,ab[c]=b);M[a+8>>2>>>0]=c;return a}\nfunction fb(a){if(!I){if(0===X){var b=!1,c=!1;a((e=0)=>{if(!I&&(Za=e,b=!0,c)){X=2;V(()=>gb(t));\"undefined\"!=typeof Browser&&Browser.Ia.Qa&&Browser.Ia.resume();e=!1;try{var f=(0,G[ab[M[t+8>>2>>>0]]])()}catch(n){f=n,e=!0}var h=!1;if(!t){var l=cb;l&&(cb=null,(e?l.reject:l.resolve)(f),h=!0)}if(e&&!h)throw f;}});c=!0;b||(X=1,t=eb(),\"undefined\"!=typeof Browser&&Browser.Ia.Qa&&Browser.Ia.pause(),V(()=>hb(t)))}else 2===X?(X=0,V(ib),jb(t),t=null,db.forEach(e=>{if(!I)try{if(e(),!noExitRuntime)try{J=J=e=J;if(!noExitRuntime){if(d.onExit)d.onExit(e);\nI=!0}x(e,new za(e))}catch(f){f instanceof za||\"unwind\"==f||x(1,f)}}catch(f){f instanceof za||\"unwind\"==f||x(1,f)}})):E(`invalid state: ${X}`);return Za}}function kb(a){return fb(b=>{a().then(b)})}var Y=[],Z=void 0,lb=[];\nfunction mb(a,b){if(!Z){Z=new WeakMap;var c=O.length;if(Z)for(var e=0;e<0+c;e++){var f=e;var h=Y[f];h||(f>=Y.length&&(Y.length=f+1),Y[f]=h=O.get(f));(f=h)&&Z.set(f,e)}}if(c=Z.get(a)||0)return c;if(lb.length)c=lb.pop();else{try{O.grow(1)}catch(n){if(!(n instanceof RangeError))throw n;throw\"Unable to grow wasm table. Set ALLOW_TABLE_GROWTH.\";}c=O.length-1}try{e=c,O.set(e,a),Y[e]=O.get(e)}catch(n){if(!(n instanceof TypeError))throw n;if(\"function\"==typeof WebAssembly.Function){e=WebAssembly.Function;\nf={i:\"i32\",j:\"i64\",f:\"f32\",d:\"f64\",p:\"i32\"};h={parameters:[],results:\"v\"==b[0]?[]:[f[b[0]]]};for(var l=1;l<b.length;++l)h.parameters.push(f[b[l]]);b=new e(h,a)}else{e=[1];f=b.slice(0,1);b=b.slice(1);h={i:127,p:127,j:126,f:125,d:124};e.push(96);l=b.length;128>l?e.push(l):e.push(l%128|128,l>>7);for(l=0;l<b.length;++l)e.push(h[b[l]]);\"v\"==f?e.push(0):e.push(1,h[f]);b=[0,97,115,109,1,0,0,0,1];f=e.length;128>f?b.push(f):b.push(f%128|128,f>>7);b.push.apply(b,e);b.push(2,7,1,1,101,1,102,0,0,7,5,1,1,102,\n0,0);b=new WebAssembly.Module(new Uint8Array(b));b=(new WebAssembly.Instance(b,{e:{f:a}})).exports.f}e=c;O.set(e,b);Y[e]=O.get(e)}Z.set(a,c);return c}\nvar ob={n:function(a,b,c){return kb(async()=>{await d.Sa(a,b,c)})},a:function(a,b,c){a>>>=0;(new Ba(a)).Ma(b>>>0,c>>>0);Ca=a;Da++;throw Ca;},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},F:function(){},m:function(){},A:function(){},x:function(){},I:function(){},y:function(){},M:()=>!0,q:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);M[c>>2>>>0]=a.getUTCSeconds();M[c+4>>2>>>0]=\na.getUTCMinutes();M[c+8>>2>>>0]=a.getUTCHours();M[c+12>>2>>>0]=a.getUTCDate();M[c+16>>2>>>0]=a.getUTCMonth();M[c+20>>2>>>0]=a.getUTCFullYear()-1900;M[c+24>>2>>>0]=a.getUTCDay();M[c+28>>2>>>0]=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864E5|0},r:function(a,b,c){a=b+2097152>>>0<4194305-!!a?(a>>>0)+4294967296*b:NaN;c>>>=0;a=new Date(1E3*a);M[c>>2>>>0]=a.getSeconds();M[c+4>>2>>>0]=a.getMinutes();M[c+8>>2>>>0]=a.getHours();M[c+12>>2>>>0]=a.getDate();M[c+16>>2>>>0]=a.getMonth();M[c+20>>2>>>\n0]=a.getFullYear()-1900;M[c+24>>2>>>0]=a.getDay();M[c+28>>2>>>0]=(U(a.getFullYear())?Ia:Ja)[a.getMonth()]+a.getDate()-1|0;M[c+36>>2>>>0]=-(60*a.getTimezoneOffset());b=(new Date(a.getFullYear(),6,1)).getTimezoneOffset();var e=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();M[c+32>>2>>>0]=(b!=e&&a.getTimezoneOffset()==Math.min(e,b))|0},s:function(a){a>>>=0;var b=new Date(M[a+20>>2>>>0]+1900,M[a+16>>2>>>0],M[a+12>>2>>>0],M[a+8>>2>>>0],M[a+4>>2>>>0],M[a>>2>>>0],0),c=M[a+32>>2>>>0],e=b.getTimezoneOffset(),\nf=(new Date(b.getFullYear(),6,1)).getTimezoneOffset(),h=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),l=Math.min(h,f);0>c?M[a+32>>2>>>0]=Number(f!=h&&l==e):0<c!=(l==e)&&(f=Math.max(h,f),b.setTime(b.getTime()+6E4*((0<c?l:f)-e)));M[a+24>>2>>>0]=b.getDay();M[a+28>>2>>>0]=(U(b.getFullYear())?Ia:Ja)[b.getMonth()]+b.getDate()-1|0;M[a>>2>>>0]=b.getSeconds();M[a+4>>2>>>0]=b.getMinutes();M[a+8>>2>>>0]=b.getHours();M[a+12>>2>>>0]=b.getDate();M[a+16>>2>>>0]=b.getMonth();M[a+20>>2>>>0]=b.getYear();a=b.getTime()/\n1E3;return nb((S=a,1<=+Math.abs(S)?0<S?+Math.floor(S/4294967296)>>>0:~~+Math.ceil((S-+(~~S>>>0))/4294967296)>>>0:0)),a>>>0},o:function(){return-52},p:function(){},v:function(a,b,c){function e(m){return(m=m.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?m[1]:\"GMT\"}c>>>=0;var f=(new Date).getFullYear(),h=new Date(f,0,1),l=new Date(f,6,1);f=h.getTimezoneOffset();var n=l.getTimezoneOffset();N[a>>>0>>2>>>0]=60*Math.max(f,n);M[b>>>0>>2>>>0]=Number(f!=n);a=e(h);b=e(l);a=La(a);b=La(b);n<f?(N[c>>2>>>0]=a,N[c+\n4>>2>>>0]=b):(N[c>>2>>>0]=b,N[c+4>>2>>>0]=a)},e:()=>{E(\"\")},b:function(a,b,c){a>>>=0;b=Na(b>>>0,c>>>0);return ya[a].apply(null,b)},j:function(a,b,c){a>>>=0;b=Na(b>>>0,c>>>0);return ya[a].apply(null,b)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(a,b,c){b>>>=0;return L.copyWithin(a>>>0>>>0,b>>>0,b+(c>>>0)>>>0)},u:function(a){a>>>=0;var b=L.length;if(4294901760<a)return!1;for(var c=1;4>=c;c*=2){var e=b*(1+.2/c);e=Math.min(e,a+100663296);var f=Math;\ne=Math.max(a,e);a:{f=f.min.call(f,4294901760,e+(65536-e%65536)%65536)-F.buffer.byteLength+65535>>>16;try{F.grow(f);ma();var h=1;break a}catch(l){}h=void 0}if(h)return!0}return!1},D:function(a,b){a>>>=0;b>>>=0;var c=0;Ra().forEach(function(e,f){var h=b+c;f=N[a+4*f>>2>>>0]=h;for(h=0;h<e.length;++h)K[f++>>0>>>0]=e.charCodeAt(h);K[f>>0>>>0]=0;c+=e.length+1});return 0},E:function(a,b){a>>>=0;b>>>=0;var c=Ra();N[a>>2>>>0]=c.length;var e=0;c.forEach(function(f){e+=f.length+1});N[b>>2>>>0]=e;return 0},f:()=>\n52,l:function(){return 52},t:function(){return 70},k:function(a,b,c,e){b>>>=0;c>>>=0;e>>>=0;for(var f=0,h=0;h<c;h++){var l=N[b>>2>>>0],n=N[b+4>>2>>>0];b+=8;for(var m=0;m<n;m++){var q=L[l+m>>>0],p=Sa[a];0===q||10===q?((1===a?ja:C)(Fa(p,0)),p.length=0):p.push(q)}f+=n}N[e>>2>>>0]=f;return 0},G:Wa,d:function(a,b,c,e){return Wa(a>>>0,b>>>0,c>>>0,e>>>0)},i:function(a,b,c,e){const f=O.length;a=new Uint8Array(L.slice(a+b,a+c));try{var h=new WebAssembly.Module(a),l=new WebAssembly.Instance(h,{env:{memory:F}}),\nn;for(n in l.exports)mb(l.exports[n]);return f<O.length?f:e}catch(m){return console.log(m),e}}};\n(function(){function a(c){c=c.exports;c=Xa(c);G=c=pb(c);F=G.N;ma();O=G.sa;oa.unshift(G.O);P--;d.monitorRunDependencies&&d.monitorRunDependencies(P);if(0==P&&(null!==ra&&(clearInterval(ra),ra=null),Q)){var e=Q;Q=null;e()}return c}var b={a:ob};P++;d.monitorRunDependencies&&d.monitorRunDependencies(P);if(d.instantiateWasm)try{return d.instantiateWasm(b,a)}catch(c){C(\"Module.instantiateWasm callback failed with error: \"+c),k(c)}xa(b,function(c){a(c.instance)}).catch(k);return{}})();\nd._OrtInit=(a,b)=>(d._OrtInit=G.P)(a,b);d._OrtGetLastError=(a,b)=>(d._OrtGetLastError=G.Q)(a,b);d._OrtCreateSessionOptions=(a,b,c,e,f,h,l,n,m,q)=>(d._OrtCreateSessionOptions=G.R)(a,b,c,e,f,h,l,n,m,q);d._OrtAppendExecutionProvider=(a,b)=>(d._OrtAppendExecutionProvider=G.S)(a,b);d._OrtAddFreeDimensionOverride=(a,b,c)=>(d._OrtAddFreeDimensionOverride=G.T)(a,b,c);d._OrtAddSessionConfigEntry=(a,b,c)=>(d._OrtAddSessionConfigEntry=G.U)(a,b,c);d._OrtReleaseSessionOptions=a=>(d._OrtReleaseSessionOptions=G.V)(a);\nd._OrtCreateSession=(a,b,c)=>(d._OrtCreateSession=G.W)(a,b,c);d._OrtReleaseSession=a=>(d._OrtReleaseSession=G.X)(a);d._OrtGetInputOutputCount=(a,b,c)=>(d._OrtGetInputOutputCount=G.Y)(a,b,c);d._OrtGetInputName=(a,b)=>(d._OrtGetInputName=G.Z)(a,b);d._OrtGetOutputName=(a,b)=>(d._OrtGetOutputName=G._)(a,b);d._OrtFree=a=>(d._OrtFree=G.$)(a);d._OrtCreateTensor=(a,b,c,e,f,h)=>(d._OrtCreateTensor=G.aa)(a,b,c,e,f,h);d._OrtGetTensorData=(a,b,c,e,f)=>(d._OrtGetTensorData=G.ba)(a,b,c,e,f);\nd._OrtReleaseTensor=a=>(d._OrtReleaseTensor=G.ca)(a);d._OrtCreateRunOptions=(a,b,c,e)=>(d._OrtCreateRunOptions=G.da)(a,b,c,e);d._OrtAddRunConfigEntry=(a,b,c)=>(d._OrtAddRunConfigEntry=G.ea)(a,b,c);d._OrtReleaseRunOptions=a=>(d._OrtReleaseRunOptions=G.fa)(a);d._OrtCreateBinding=a=>(d._OrtCreateBinding=G.ga)(a);d._OrtBindInput=(a,b,c)=>(d._OrtBindInput=G.ha)(a,b,c);d._OrtBindOutput=(a,b,c,e)=>(d._OrtBindOutput=G.ia)(a,b,c,e);d._OrtClearBoundOutputs=a=>(d._OrtClearBoundOutputs=G.ja)(a);\nd._OrtReleaseBinding=a=>(d._OrtReleaseBinding=G.ka)(a);d._OrtRunWithBinding=(a,b,c,e,f)=>(d._OrtRunWithBinding=G.la)(a,b,c,e,f);d._OrtRun=(a,b,c,e,f,h,l,n)=>(d._OrtRun=G.ma)(a,b,c,e,f,h,l,n);d._OrtEndProfiling=a=>(d._OrtEndProfiling=G.na)(a);d._JsepOutput=(a,b,c)=>(d._JsepOutput=G.oa)(a,b,c);d._JsepGetNodeName=a=>(d._JsepGetNodeName=G.pa)(a);\nvar Ka=d._malloc=a=>(Ka=d._malloc=G.qa)(a),jb=d._free=a=>(jb=d._free=G.ra)(a),nb=a=>(nb=G.ta)(a),qb=()=>(qb=G.ua)(),rb=a=>(rb=G.va)(a),sb=a=>(sb=G.wa)(a),hb=a=>(hb=G.ya)(a),Ya=()=>(Ya=G.za)(),gb=a=>(gb=G.Aa)(a),ib=()=>(ib=G.Ba)();d.___start_em_js=927291;d.___stop_em_js=928064;function pb(a){a=Object.assign({},a);var b=e=>()=>e()>>>0,c=e=>f=>e(f)>>>0;a.__errno_location=b(a.__errno_location);a.malloc=c(a.malloc);a.stackSave=b(a.stackSave);a.stackAlloc=c(a.stackAlloc);return a}d.stackAlloc=sb;\nd.stackSave=qb;d.stackRestore=rb;d.addFunction=mb;d.UTF8ToString=T;d.stringToUTF8=(a,b,c)=>Ha(a,L,b,c);d.lengthBytesUTF8=Ga;var tb;Q=function ub(){tb||vb();tb||(Q=ub)};\nfunction vb(){function a(){if(!tb&&(tb=!0,d.calledRun=!0,!I)){Aa(oa);aa(d);if(d.onRuntimeInitialized)d.onRuntimeInitialized();if(d.postRun)for(\"function\"==typeof d.postRun&&(d.postRun=[d.postRun]);d.postRun.length;){var b=d.postRun.shift();pa.unshift(b)}Aa(pa)}}if(!(0<P)){if(d.preRun)for(\"function\"==typeof d.preRun&&(d.preRun=[d.preRun]);d.preRun.length;)qa();Aa(na);0<P||(d.setStatus?(d.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){d.setStatus(\"\")},1);a()},1)):a())}}\nif(d.preInit)for(\"function\"==typeof d.preInit&&(d.preInit=[d.preInit]);0<d.preInit.length;)d.preInit.pop()();vb();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasm;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasm);\n", "", "", "export const cpus = undefined;", "\nvar ortWasmThreaded = (() => {\n  var _scriptDir = typeof document !== 'undefined' && document.currentScript ? document.currentScript.src : undefined;\n  if (typeof __filename !== 'undefined') _scriptDir = _scriptDir || __filename;\n  return (\nfunction(moduleArg = {}) {\n\nfunction e(){m.buffer!=q.buffer&&v();return q}function x(){m.buffer!=q.buffer&&v();return aa}function ba(){m.buffer!=q.buffer&&v();return ca}function da(){m.buffer!=q.buffer&&v();return ea}function y(){m.buffer!=q.buffer&&v();return fa}function A(){m.buffer!=q.buffer&&v();return ha}function ia(){m.buffer!=q.buffer&&v();return ja}function ka(){m.buffer!=q.buffer&&v();return la}var B=moduleArg,ma,na;B.ready=new Promise((a,b)=>{ma=a;na=b});\"use strict\";\nB.jsepInit=(a,b,c,d,f,g,k,l)=>{B.oc=a;B.Wb=b;B.Yb=c;B.Lb=d;B.Xb=f;B.cb=g;B.Zb=k;B.$b=l;b=(n,p,r)=>(...u)=>{const w=C,h=p?.();u=n(...u);const t=p?.();h!==t&&(n=t,r(h),p=r=null);return C!=w?oa():u};c=n=>async(...p)=>{try{if(B.Cb)throw Error(\"Session already started\");const r=B.Cb={cc:p[0],errors:[]},u=await n(...p);if(B.Cb!==r)throw Error(\"Session mismatch\");a.flush();const w=r.errors;if(0<w.length){let h=await Promise.all(w);h=h.filter(t=>t);if(0<h.length)throw Error(h.join(\"\\n\"));}return u}finally{B.Cb=\nnull}};B._OrtRun=c(b(B._OrtRun,()=>B._OrtRun,n=>B._OrtRun=n));B._OrtRunWithBinding=c(b(B._OrtRunWithBinding,()=>B._OrtRunWithBinding,n=>B._OrtRunWithBinding=n));B._OrtBindInput=b(B._OrtBindInput,()=>B._OrtBindInput,n=>B._OrtBindInput=n);B.jsepRegisterBuffer=(n,p,r,u)=>a.registerBuffer(n,p,r,u);B.jsepUnregisterBuffers=n=>{a.unregisterBuffers(n)};B.jsepGetBuffer=n=>a.getBuffer(n);B.jsepCreateDownloader=(n,p,r)=>a.createDownloader(n,p,r)};\nvar pa=Object.assign({},B),qa=\"./this.program\",ra=(a,b)=>{throw b;},sa=\"object\"==typeof window,D=\"function\"==typeof importScripts,E=\"object\"==typeof process&&\"object\"==typeof process.versions&&\"string\"==typeof process.versions.node,F=B.ENVIRONMENT_IS_PTHREAD||!1,G=\"\";function ta(a){return B.locateFile?B.locateFile(a,G):G+a}var ua,va,wa;\nif(E){var fs=require(\"fs\"),xa=require(\"path\");G=D?xa.dirname(G)+\"/\":__dirname+\"/\";ua=(b,c)=>{b=ya(b)?new URL(b):xa.normalize(b);return fs.readFileSync(b,c?void 0:\"utf8\")};wa=b=>{b=ua(b,!0);b.buffer||(b=new Uint8Array(b));return b};va=(b,c,d,f=!0)=>{b=ya(b)?new URL(b):xa.normalize(b);fs.readFile(b,f?void 0:\"utf8\",(g,k)=>{g?d(g):c(f?k.buffer:k)})};!B.thisProgram&&1<process.argv.length&&(qa=process.argv[1].replace(/\\\\/g,\"/\"));process.argv.slice(2);ra=(b,c)=>{process.exitCode=b;throw c;};B.inspect=()=>\n\"[Emscripten Module object]\";let a;try{a=require(\"worker_threads\")}catch(b){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),b;}global.Worker=a.Worker}else if(sa||D)D?G=self.location.href:\"undefined\"!=typeof document&&document.currentScript&&(G=document.currentScript.src),(typeof _scriptDir !== \"undefined\" && _scriptDir)&&(G=_scriptDir),0!==G.indexOf(\"blob:\")?G=G.substr(0,G.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):G=\"\",E||(ua=a=>{var b=new XMLHttpRequest;b.open(\"GET\",\na,!1);b.send(null);return b.responseText},D&&(wa=a=>{var b=new XMLHttpRequest;b.open(\"GET\",a,!1);b.responseType=\"arraybuffer\";b.send(null);return new Uint8Array(b.response)}),va=(a,b,c)=>{var d=new XMLHttpRequest;d.open(\"GET\",a,!0);d.responseType=\"arraybuffer\";d.onload=()=>{200==d.status||0==d.status&&d.response?b(d.response):c()};d.onerror=c;d.send(null)});E&&\"undefined\"==typeof performance&&(global.performance=require(\"perf_hooks\").performance);var za=console.log.bind(console),Aa=console.error.bind(console);\nE&&(za=(...a)=>fs.writeSync(1,a.join(\" \")+\"\\n\"),Aa=(...a)=>fs.writeSync(2,a.join(\" \")+\"\\n\"));var Ba=za,H=Aa;Object.assign(B,pa);pa=null;\"object\"!=typeof WebAssembly&&I(\"no native wasm support detected\");var m,Ca,J=!1,K,q,aa,ca,ea,fa,ha,ja,L,Da,la;\nfunction v(){var a=m.buffer;B.HEAP8=q=new Int8Array(a);B.HEAP16=ca=new Int16Array(a);B.HEAPU8=aa=new Uint8Array(a);B.HEAPU16=ea=new Uint16Array(a);B.HEAP32=fa=new Int32Array(a);B.HEAPU32=ha=new Uint32Array(a);B.HEAPF32=ja=new Float32Array(a);B.HEAPF64=la=new Float64Array(a);B.HEAP64=L=new BigInt64Array(a);B.HEAPU64=Da=new BigUint64Array(a)}var Ea=16777216;5242880<=Ea||I(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+Ea+\"! (STACK_SIZE=5242880)\");\nif(F)m=B.wasmMemory;else if(m=new WebAssembly.Memory({initial:Ea/65536,maximum:65536,shared:!0}),!(m.buffer instanceof SharedArrayBuffer))throw H(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),E&&H(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),Error(\"bad memory\");\nv();Ea=m.buffer.byteLength;var Fa=[],Ga=[],Ha=[],Ia=0,Ja=null,Ka=null;function La(){Ia--;if(0==Ia&&(null!==Ja&&(clearInterval(Ja),Ja=null),Ka)){var a=Ka;Ka=null;a()}}function I(a){a=\"Aborted(\"+a+\")\";H(a);J=!0;K=1;a=new WebAssembly.RuntimeError(a+\". Build with -sASSERTIONS for more info.\");na(a);throw a;}var Ma=a=>a.startsWith(\"data:application/octet-stream;base64,\"),ya=a=>a.startsWith(\"file://\"),Na;Na=\"ort-wasm-simd-threaded.wasm\";Ma(Na)||(Na=ta(Na));\nfunction Oa(a){if(wa)return wa(a);throw\"both async and sync fetching of the wasm failed\";}function Pa(a){if(sa||D){if(\"function\"==typeof fetch&&!ya(a))return fetch(a,{credentials:\"same-origin\"}).then(b=>{if(!b.ok)throw\"failed to load wasm binary file at '\"+a+\"'\";return b.arrayBuffer()}).catch(()=>Oa(a));if(va)return new Promise((b,c)=>{va(a,d=>b(new Uint8Array(d)),c)})}return Promise.resolve().then(()=>Oa(a))}\nfunction Qa(a,b,c){return Pa(a).then(d=>WebAssembly.instantiate(d,b)).then(d=>d).then(c,d=>{H(`failed to asynchronously prepare wasm: ${d}`);I(d)})}function Ra(a,b){var c=Na;return\"function\"!=typeof WebAssembly.instantiateStreaming||Ma(c)||ya(c)||E||\"function\"!=typeof fetch?Qa(c,a,b):fetch(c,{credentials:\"same-origin\"}).then(d=>WebAssembly.instantiateStreaming(d,a).then(b,function(f){H(`wasm streaming compile failed: ${f}`);H(\"falling back to ArrayBuffer instantiation\");return Qa(c,a,b)}))}\nvar Sa={1441368:a=>{B.cb(\"Abs\",a,void 0)},1441419:a=>{B.cb(\"Neg\",a,void 0)},1441470:a=>{B.cb(\"Floor\",a,void 0)},1441523:a=>{B.cb(\"Ceil\",a,void 0)},1441575:a=>{B.cb(\"Reciprocal\",a,void 0)},1441633:a=>{B.cb(\"Sqrt\",a,void 0)},1441685:a=>{B.cb(\"Exp\",a,void 0)},1441736:a=>{B.cb(\"Erf\",a,void 0)},1441787:a=>{B.cb(\"Sigmoid\",a,void 0)},1441842:a=>{B.cb(\"Log\",a,void 0)},1441893:a=>{B.cb(\"Sin\",a,void 0)},1441944:a=>{B.cb(\"Cos\",a,void 0)},1441995:a=>{B.cb(\"Tan\",a,void 0)},1442046:a=>{B.cb(\"Asin\",a,void 0)},1442098:a=>\n{B.cb(\"Acos\",a,void 0)},1442150:a=>{B.cb(\"Atan\",a,void 0)},1442202:a=>{B.cb(\"Sinh\",a,void 0)},1442254:a=>{B.cb(\"Cosh\",a,void 0)},1442306:a=>{B.cb(\"Asinh\",a,void 0)},1442359:a=>{B.cb(\"Acosh\",a,void 0)},1442412:a=>{B.cb(\"Atanh\",a,void 0)},1442465:a=>{B.cb(\"Tanh\",a,void 0)},1442517:a=>{B.cb(\"Not\",a,void 0)},1442568:(a,b,c)=>{B.cb(\"ClipV10\",a,{min:b,max:c})},1442640:a=>{B.cb(\"Clip\",a,void 0)},1442692:(a,b)=>{B.cb(\"Elu\",a,{alpha:b})},1442750:a=>{B.cb(\"Relu\",a,void 0)},1442802:(a,b)=>{B.cb(\"LeakyRelu\",\na,{alpha:b})},1442866:(a,b)=>{B.cb(\"ThresholdedRelu\",a,{alpha:b})},1442936:a=>{B.Zb(a)},1442970:(a,b)=>B.$b(a,b,B.Cb.cc,B.Cb.errors),1443082:(a,b)=>{B.cb(\"Cast\",a,{to:b})},1443140:a=>{B.cb(\"Add\",a,void 0)},1443191:a=>{B.cb(\"Sub\",a,void 0)},1443242:a=>{B.cb(\"Mul\",a,void 0)},1443293:a=>{B.cb(\"Div\",a,void 0)},1443344:a=>{B.cb(\"Pow\",a,void 0)},1443395:a=>{B.cb(\"Equal\",a,void 0)},1443448:a=>{B.cb(\"Greater\",a,void 0)},1443503:a=>{B.cb(\"GreaterOrEqual\",a,void 0)},1443565:a=>{B.cb(\"Less\",a,void 0)},1443617:a=>\n{B.cb(\"LessOrEqual\",a,void 0)},1443676:(a,b,c,d,f)=>{B.cb(\"ReduceMean\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1443840:(a,b,c,d,f)=>{B.cb(\"ReduceMax\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1444003:(a,b,c,d,f)=>{B.cb(\"ReduceMin\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1444166:(a,b,c,d,f)=>{B.cb(\"ReduceProd\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?\nArray.from(y().subarray(f>>>0,f+d>>>0)):[]})},1444330:(a,b,c,d,f)=>{B.cb(\"ReduceSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1444493:(a,b,c,d,f)=>{B.cb(\"ReduceL1\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1444655:(a,b,c,d,f)=>{B.cb(\"ReduceL2\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1444817:(a,b,c,d,f)=>{B.cb(\"ReduceLogSum\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,\naxes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1444983:(a,b,c,d,f)=>{B.cb(\"ReduceSumSquare\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1445152:(a,b,c,d,f)=>{B.cb(\"ReduceLogSumExp\",a,{keepDims:!!b,noopWithEmptyAxes:!!c,axes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1445321:a=>{B.cb(\"Where\",a,void 0)},1445374:(a,b,c)=>{B.cb(\"Transpose\",a,{perm:b?Array.from(y().subarray(c>>>0,c+b>>>0)):[]})},1445487:(a,b,c,d,f,g,k,l,n,p,r,u,w)=>{B.cb(\"Conv\",\na,{format:n?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c],group:d,kernel_shape:[f],pads:g?Array.from(y().subarray(k>>>0,k+g>>>0)):[],strides:[l],w_is_const:()=>!!e()[p>>>0],activation:M(r),activation_params:u?Array.from(ia().subarray(w>>>0,w+u>>>0)):[]})},1445868:(a,b,c,d,f,g,k,l,n,p,r,u,w,h,t,z)=>{B.cb(\"Conv\",a,{format:u?\"NHWC\":\"NCHW\",auto_pad:b,dilations:[c,d],group:f,kernel_shape:[g,k],pads:l?Array.from(y().subarray(n>>>0,n+l>>>0)):[],strides:[p,r],w_is_const:()=>!!e()[w>>>0],activation:M(h),activation_params:t?\nArray.from(ia().subarray(z>>>0,z+t>>>0)):[]})},1446270:(a,b,c,d,f,g,k,l,n,p,r,u,w,h,t)=>{B.cb(\"ConvTranspose\",a,{format:n?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:d,kernel_shape:[f],pads:[g,k],strides:[l],wIsConst:()=>!!e()[p>>>0],outputPadding:r?Array.from(y().subarray(u>>>0,u+r>>>0)):[],outputShape:w?Array.from(y().subarray(h>>>0,h+w>>>0)):[],activation:M(t)})},1446684:(a,b,c,d,f,g,k,l,n,p,r,u,w,h)=>{B.cb(\"ConvTranspose\",a,{format:l?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(y().subarray(c>>>\n0,c+2>>>0)),group:d,kernelShape:Array.from(y().subarray(f>>>0,f+2>>>0)),pads:Array.from(y().subarray(g>>>0,g+4>>>0)),strides:Array.from(y().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!e()[n>>>0],outputPadding:0<p?Array.from(y().subarray(r>>>0,r+p>>>0)):[],outputShape:0<u?Array.from(y().subarray(w>>>0,w+u>>>0)):[],activation:M(h)})},1447241:(a,b,c,d,f,g,k,l,n,p,r,u,w,h,t)=>{B.cb(\"ConvTranspose\",a,{format:n?\"NHWC\":\"NCHW\",autoPad:b,dilations:[c],group:d,kernel_shape:[f],pads:[g,k],strides:[l],wIsConst:()=>\n!!e()[p>>>0],outputPadding:r?Array.from(y().subarray(u>>>0,u+r>>>0)):[],outputShape:w?Array.from(y().subarray(h>>>0,h+w>>>0)):[],activation:M(t)})},1447655:(a,b,c,d,f,g,k,l,n,p,r,u,w,h)=>{B.cb(\"ConvTranspose\",a,{format:l?\"NHWC\":\"NCHW\",autoPad:b,dilations:Array.from(y().subarray(c>>>0,c+2>>>0)),group:d,kernelShape:Array.from(y().subarray(f>>>0,f+2>>>0)),pads:Array.from(y().subarray(g>>>0,g+4>>>0)),strides:Array.from(y().subarray(k>>>0,k+2>>>0)),wIsConst:()=>!!e()[n>>>0],outputPadding:0<p?Array.from(y().subarray(r>>>\n0,r+p>>>0)):[],outputShape:0<u?Array.from(y().subarray(w>>>0,w+u>>>0)):[],activation:M(h)})},1448212:(a,b)=>{B.cb(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},1448303:(a,b,c,d,f,g,k,l,n,p,r,u,w,h,t,z)=>{B.cb(\"AveragePool\",a,{format:z?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:f,dilations:[g,k],kernel_shape:[l,n],pads:[p,r,u,w],strides:[h,t]})},1448587:(a,b)=>{B.cb(\"GlobalAveragePool\",a,{format:b?\"NHWC\":\"NCHW\"})},1448678:(a,b,c,d,f,g,k,l,n,p,r,u,w,h,t,z)=>{B.cb(\"AveragePool\",\na,{format:z?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:f,dilations:[g,k],kernel_shape:[l,n],pads:[p,r,u,w],strides:[h,t]})},1448962:(a,b)=>{B.cb(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},1449049:(a,b,c,d,f,g,k,l,n,p,r,u,w,h,t,z)=>{B.cb(\"MaxPool\",a,{format:z?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:f,dilations:[g,k],kernel_shape:[l,n],pads:[p,r,u,w],strides:[h,t]})},1449329:(a,b)=>{B.cb(\"GlobalMaxPool\",a,{format:b?\"NHWC\":\"NCHW\"})},1449416:(a,\nb,c,d,f,g,k,l,n,p,r,u,w,h,t,z)=>{B.cb(\"MaxPool\",a,{format:z?\"NHWC\":\"NCHW\",auto_pad:b,ceil_mode:c,count_include_pad:d,storage_order:f,dilations:[g,k],kernel_shape:[l,n],pads:[p,r,u,w],strides:[h,t]})},1449696:(a,b,c,d,f)=>{B.cb(\"Gemm\",a,{alpha:b,beta:c,transA:d,transB:f})},1449800:a=>{B.cb(\"MatMul\",a,void 0)},1449854:(a,b,c,d)=>{B.cb(\"ArgMax\",a,{keepDims:!!b,selectLastIndex:!!c,axis:d})},1449962:(a,b,c,d)=>{B.cb(\"ArgMin\",a,{keepDims:!!b,selectLastIndex:!!c,axis:d})},1450070:(a,b)=>{B.cb(\"Softmax\",\na,{axis:b})},1450133:(a,b)=>{B.cb(\"Concat\",a,{axis:b})},1450193:(a,b,c,d,f)=>{B.cb(\"Split\",a,{axis:b,numOutputs:c,splitSizes:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1450338:a=>{B.cb(\"Expand\",a,void 0)},1450392:(a,b)=>{B.cb(\"Gather\",a,{axis:Number(b)})},1450463:(a,b)=>{B.cb(\"GatherElements\",a,{axis:Number(b)})},1450542:(a,b,c,d,f,g,k,l,n,p,r)=>{B.cb(\"Resize\",a,{antialias:b,axes:c?Array.from(y().subarray(d>>>0,d+c>>>0)):[],coordinateTransformMode:M(f),cubicCoeffA:g,excludeOutside:k,extrapolationValue:l,\nkeepAspectRatioPolicy:M(n),mode:M(p),nearestMode:M(r)})},1450893:(a,b,c,d,f,g,k)=>{B.cb(\"Slice\",a,{starts:b?Array.from(y().subarray(c>>>0,c+b>>>0)):[],ends:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[],axes:g?Array.from(y().subarray(k>>>0,k+g>>>0)):[]})},1451124:a=>{B.cb(\"Tile\",a,void 0)},1451176:(a,b,c)=>{B.cb(\"LayerNormalization\",a,{axis:Number(b),epsilon:Number(c)})},1451283:(a,b,c)=>{B.cb(\"InstanceNormalization\",a,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},1451397:(a,b,c)=>{B.cb(\"InstanceNormalization\",\na,{epsilon:b,format:c?\"NHWC\":\"NCHW\"})},1451511:a=>{B.cb(\"Range\",a,void 0)},1451564:(a,b)=>{B.cb(\"Einsum\",a,{equation:M(b)})},1451645:(a,b,c,d,f)=>{B.cb(\"Pad\",a,{mode:b,value:c,pads:d?Array.from(y().subarray(f>>>0,f+d>>>0)):[]})},1451777:a=>{B.cb(\"Gelu\",a,void 0)},1451829:a=>{B.cb(\"BiasAdd\",a,void 0)},1451884:a=>{B.cb(\"BiasSplitGelu\",a,void 0)},1451945:(a,b)=>{B.cb(\"SkipLayerNormalization\",a,{epsilon:b})},1452026:a=>B.Wb(a),1452059:a=>B.Yb(a),1452091:(a,b,c)=>{B.Lb(a,b,c,!0)},1452130:(a,b,c)=>{B.Lb(a,\nb,c)}};function Ta(a){this.name=\"ExitStatus\";this.message=`Program terminated with exit(${a})`;this.status=a}\nvar Ua=a=>{a.terminate();a.onmessage=()=>{}},Va=a=>{if(0==N.zb.length){var b=ta(\"ort-wasm-simd-threaded.worker.js\");b=new Worker(b);N.zb.push(b);N.ac(N.zb[0])}b=N.zb.pop();if(!b)return 6;N.wb.push(b);N.nb[a.vb]=b;b.vb=a.vb;var c={cmd:\"run\",start_routine:a.dc,arg:a.Rb,pthread_ptr:a.vb};E&&b.unref();b.postMessage(c,a.kc);return 0},O=0,Wa=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf8\"):void 0,Xa=(a,b,c)=>{b>>>=0;var d=b+c;for(c=b;a[c]&&!(c>=d);)++c;if(16<c-b&&a.buffer&&Wa)return Wa.decode(a.buffer instanceof\nSharedArrayBuffer?a.slice(b,c):a.subarray(b,c));for(d=\"\";b<c;){var f=a[b++];if(f&128){var g=a[b++]&63;if(192==(f&224))d+=String.fromCharCode((f&31)<<6|g);else{var k=a[b++]&63;f=224==(f&240)?(f&15)<<12|g<<6|k:(f&7)<<18|g<<12|k<<6|a[b++]&63;65536>f?d+=String.fromCharCode(f):(f-=65536,d+=String.fromCharCode(55296|f>>10,56320|f&1023))}}else d+=String.fromCharCode(f)}return d},M=(a,b)=>(a>>>=0)?Xa(x(),a,b):\"\";function Ya(a){if(F)return P(0,1,a);K=a;0<O||(N.ec(),J=!0);ra(a,new Ta(a))}\nvar $a=a=>{K=a;if(F)throw Za(a),\"unwind\";Ya(a)};function ab(){Fa.unshift(()=>{Ia++;La()})}\nvar N={zb:[],wb:[],Qb:[],nb:{},Fb(){F?(N.receiveObjectTransfer=N.bc,N.threadInitTLS=N.Pb,N.setExitStatus=N.Ob):ab()},Ob:a=>{K=a},pc:[\"$terminateWorker\"],ec:()=>{for(var a of N.wb)Ua(a);for(a of N.zb)Ua(a);N.zb=[];N.wb=[];N.nb=[]},Nb:a=>{var b=a.vb;delete N.nb[b];N.zb.push(a);N.wb.splice(N.wb.indexOf(a),1);a.vb=0;bb(b)},bc(){},Pb(){N.Qb.forEach(a=>a())},ac:a=>new Promise(b=>{a.onmessage=g=>{g=g.data;var k=g.cmd;if(g.targetThread&&g.targetThread!=cb()){var l=N.nb[g.targetThread];l?l.postMessage(g,g.transferList):\nH(`Internal error! Worker sent a message \"${k}\" to target pthread ${g.targetThread}, but that thread no longer exists!`)}else if(\"checkMailbox\"===k)db();else if(\"spawnThread\"===k)Va(g);else if(\"cleanupThread\"===k)(g=N.nb[g.thread])||I(),N.Nb(g);else if(\"killThread\"===k)g=g.thread,k=N.nb[g],delete N.nb[g],Ua(k),bb(g),N.wb.splice(N.wb.indexOf(k),1),k.vb=0;else if(\"cancelThread\"===k)N.nb[g.thread].postMessage({cmd:\"cancel\"});else if(\"loaded\"===k)a.loaded=!0,b(a);else if(\"alert\"===k)alert(`Thread ${g.threadId}: ${g.text}`);\nelse if(\"setimmediate\"===g.target)a.postMessage(g);else if(\"callHandler\"===k)B[g.handler](...g.args);else k&&H(`worker sent an unknown command ${k}`)};a.onerror=g=>{H(`${\"worker sent an error!\"} ${g.filename}:${g.lineno}: ${g.message}`);throw g;};E&&(a.on(\"message\",g=>a.onmessage({data:g})),a.on(\"error\",g=>a.onerror(g)));var c=[],d=[],f;for(f of d)B.hasOwnProperty(f)&&c.push(f);a.postMessage({cmd:\"load\",handlers:c,urlOrBlob:B.mainScriptUrlOrBlob||_scriptDir,wasmMemory:m,wasmModule:Ca})})};\nB.PThread=N;var eb=a=>{for(;0<a.length;)a.shift()(B)};B.establishStackSpace=()=>{var a=cb(),b=A()[a+52>>>2>>>0];a=A()[a+56>>>2>>>0];fb(b,b-a);gb(b)};function Za(a){if(F)return P(1,0,a);$a(a)}B.invokeEntryPoint=(a,b)=>{a=hb.apply(null,[a,b]);0<O?N.Ob(a):ib(a)};function jb(a){this.Ab=a-24;this.lc=function(b){A()[this.Ab+4>>>2>>>0]=b};this.Ib=function(b){A()[this.Ab+8>>>2>>>0]=b};this.Fb=function(b,c){this.Hb();this.lc(b);this.Ib(c)};this.Hb=function(){A()[this.Ab+16>>>2>>>0]=0}}var kb=0,lb=0;\nfunction mb(a,b,c,d){return F?P(2,1,a,b,c,d):nb(a,b,c,d)}function nb(a,b,c,d){a>>>=0;b>>>=0;c>>>=0;d>>>=0;if(\"undefined\"==typeof SharedArrayBuffer)return H(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var f=[];if(F&&0===f.length)return mb(a,b,c,d);a={dc:c,vb:a,Rb:d,kc:f};return F?(a.nc=\"spawnThread\",postMessage(a,f),0):Va(a)}function ob(a,b,c){return F?P(3,1,a,b,c):0}function pb(a,b){if(F)return P(4,1,a,b)}\nvar qb=a=>{for(var b=0,c=0;c<a.length;++c){var d=a.charCodeAt(c);127>=d?b++:2047>=d?b+=2:55296<=d&&57343>=d?(b+=4,++c):b+=3}return b},rb=(a,b,c,d)=>{c>>>=0;if(!(0<d))return 0;var f=c;d=c+d-1;for(var g=0;g<a.length;++g){var k=a.charCodeAt(g);if(55296<=k&&57343>=k){var l=a.charCodeAt(++g);k=65536+((k&1023)<<10)|l&1023}if(127>=k){if(c>=d)break;b[c++>>>0]=k}else{if(2047>=k){if(c+1>=d)break;b[c++>>>0]=192|k>>6}else{if(65535>=k){if(c+2>=d)break;b[c++>>>0]=224|k>>12}else{if(c+3>=d)break;b[c++>>>0]=240|k>>\n18;b[c++>>>0]=128|k>>12&63}b[c++>>>0]=128|k>>6&63}b[c++>>>0]=128|k&63}}b[c>>>0]=0;return c-f},sb=(a,b,c)=>rb(a,x(),b,c);function tb(a,b){if(F)return P(5,1,a,b)}function ub(a,b,c){if(F)return P(6,1,a,b,c)}function vb(a,b,c){return F?P(7,1,a,b,c):0}function wb(a,b){if(F)return P(8,1,a,b)}function xb(a,b,c){if(F)return P(9,1,a,b,c)}function yb(a,b,c,d){if(F)return P(10,1,a,b,c,d)}function zb(a,b,c,d){if(F)return P(11,1,a,b,c,d)}function Ab(a,b,c,d){if(F)return P(12,1,a,b,c,d)}\nfunction Bb(a){if(F)return P(13,1,a)}function Cb(a,b){if(F)return P(14,1,a,b)}function Db(a,b,c){if(F)return P(15,1,a,b,c)}var Eb=a=>{if(null===a)return\"null\";var b=typeof a;return\"object\"===b||\"array\"===b||\"function\"===b?a.toString():\"\"+a},Fb,Q=a=>{for(var b=\"\";x()[a>>>0];)b+=Fb[x()[a++>>>0]];return b},Gb={},Hb={},Ib={},R;\nfunction Jb(a,b,c={}){var d=b.name;if(!a)throw new R(`type \"${d}\" must have a positive integer typeid pointer`);if(Hb.hasOwnProperty(a)){if(c.Ub)return;throw new R(`Cannot register type '${d}' twice`);}Hb[a]=b;delete Ib[a];Gb.hasOwnProperty(a)&&(b=Gb[a],delete Gb[a],b.forEach(f=>f()))}function S(a,b,c={}){if(!(\"argPackAdvance\"in b))throw new TypeError(\"registerType registeredInstance requires argPackAdvance\");Jb(a,b,c)}\nvar Kb=(a,b,c)=>{switch(b){case 1:return c?d=>e()[d>>>0>>>0]:d=>x()[d>>>0>>>0];case 2:return c?d=>ba()[d>>>1>>>0]:d=>da()[d>>>1>>>0];case 4:return c?d=>y()[d>>>2>>>0]:d=>A()[d>>>2>>>0];case 8:return c?d=>L[d>>>3]:d=>Da[d>>>3];default:throw new TypeError(`invalid integer width (${b}): ${a}`);}};function Lb(){this.ub=[void 0];this.Kb=[]}var T=new Lb;function Mb(a){a>>>=0;a>=T.Ab&&0===--T.get(a).Mb&&T.Ib(a)}\nvar U=a=>{if(!a)throw new R(\"Cannot use deleted val. handle = \"+a);return T.get(a).value},V=a=>{switch(a){case void 0:return 1;case null:return 2;case !0:return 3;case !1:return 4;default:return T.Hb({Mb:1,value:a})}};function Nb(a){return this.fromWireType(y()[a>>>2>>>0])}\nvar Ob=(a,b)=>{switch(b){case 4:return function(c){return this.fromWireType(ia()[c>>>2>>>0])};case 8:return function(c){return this.fromWireType(ka()[c>>>3>>>0])};default:throw new TypeError(`invalid float width (${b}): ${a}`);}};function Pb(a){return this.fromWireType(A()[a>>>2>>>0])}\nvar Qb=\"undefined\"!=typeof TextDecoder?new TextDecoder(\"utf-16le\"):void 0,Rb=(a,b)=>{var c=a>>1;for(var d=c+b/2;!(c>=d)&&da()[c>>>0];)++c;c<<=1;if(32<c-a&&Qb)return Qb.decode(x().slice(a,c));c=\"\";for(d=0;!(d>=b/2);++d){var f=ba()[a+2*d>>>1>>>0];if(0==f)break;c+=String.fromCharCode(f)}return c},Sb=(a,b,c)=>{void 0===c&&(c=2147483647);if(2>c)return 0;c-=2;var d=b;c=c<2*a.length?c/2:a.length;for(var f=0;f<c;++f){var g=a.charCodeAt(f);ba()[b>>>1>>>0]=g;b+=2}ba()[b>>>1>>>0]=0;return b-d},Tb=a=>2*a.length,\nUb=(a,b)=>{for(var c=0,d=\"\";!(c>=b/4);){var f=y()[a+4*c>>>2>>>0];if(0==f)break;++c;65536<=f?(f-=65536,d+=String.fromCharCode(55296|f>>10,56320|f&1023)):d+=String.fromCharCode(f)}return d},Vb=(a,b,c)=>{b>>>=0;void 0===c&&(c=2147483647);if(4>c)return 0;var d=b;c=d+c-4;for(var f=0;f<a.length;++f){var g=a.charCodeAt(f);if(55296<=g&&57343>=g){var k=a.charCodeAt(++f);g=65536+((g&1023)<<10)|k&1023}y()[b>>>2>>>0]=g;b+=4;if(b+4>c)break}y()[b>>>2>>>0]=0;return b-d},Wb=a=>{for(var b=0,c=0;c<a.length;++c){var d=\na.charCodeAt(c);55296<=d&&57343>=d&&++c;b+=4}return b},Xb=a=>{if(!J)try{if(a(),!(0<O))try{F?ib(K):$a(K)}catch(b){b instanceof Ta||\"unwind\"==b||ra(1,b)}}catch(b){b instanceof Ta||\"unwind\"==b||ra(1,b)}};function Yb(a){a>>>=0;\"function\"===typeof Atomics.mc&&(Atomics.mc(y(),a>>>2,a).value.then(db),a+=128,Atomics.store(y(),a>>>2,1))}B.__emscripten_thread_mailbox_await=Yb;var db=()=>{var a=cb();a&&(Yb(a),Xb(()=>Zb()))};B.checkMailbox=db;var ac=a=>{var b=$b();a=a();gb(b);return a};\nfunction P(a,b){var c=arguments.length-2,d=arguments;return ac(()=>{for(var f=2*c,g=bc(8*f),k=g>>>3,l=0;l<c;l++){var n=d[2+l];\"bigint\"==typeof n?(L[k+2*l]=1n,L[k+2*l+1]=n):(L[k+2*l]=0n,ka()[k+2*l+1>>>0]=n)}return cc(a,f,g,b)})}\nvar dc=[],fc=(a,b)=>{var c=Hb[a];if(void 0===c)throw a=ec(a),c=Q(a),W(a),new R(b+\" has unknown type \"+c);return c},gc={},hc=a=>{var b=gc[a];return void 0===b?Q(a):b},ic=[],jc=()=>\"object\"==typeof globalThis?globalThis:Function(\"return this\")(),kc=a=>{var b=ic.length;ic.push(a);return b},lc=(a,b)=>{for(var c=Array(a),d=0;d<a;++d)c[d]=fc(A()[b+4*d>>>2>>>0],\"parameter \"+d);return c},mc=a=>{if(void 0===a)return\"_unknown\";a=a.replace(/[^a-zA-Z0-9_]/g,\"$\");var b=a.charCodeAt(0);return 48<=b&&57>=b?`_${a}`:\na};function nc(a,b){a=mc(a);return{[a]:function(){return b.apply(this,arguments)}}[a]}function oc(a){var b=Function;if(!(b instanceof Function))throw new TypeError(`new_ called with constructor type ${typeof b} which is not a function`);var c=nc(b.name||\"unknownFunctionName\",function(){});c.prototype=b.prototype;c=new c;a=b.apply(c,a);return a instanceof Object?a:c}\nvar pc=a=>{for(var b=\"\",c=0;c<a;++c)b+=(0!==c?\", \":\"\")+\"arg\"+c;var d=\"return function emval_allocator_\"+a+\"(constructor, argTypes, args) {\\n  var HEAPU32 = getMemory();\\n\";for(c=0;c<a;++c)d+=\"var argType\"+c+\" = requireRegisteredType(HEAPU32[((argTypes)>>>2)], 'parameter \"+c+\"');\\nvar arg\"+c+\" = argType\"+c+\".readValueFromPointer(args);\\nargs += argType\"+c+\"['argPackAdvance'];\\nargTypes += 4;\\n\";return(new Function(\"requireRegisteredType\",\"Module\",\"valueToHandle\",\"getMemory\",d+(\"var obj = new constructor(\"+\nb+\");\\nreturn valueToHandle(obj);\\n}\\n\")))(fc,B,V,()=>A())},qc={},rc=a=>0===a%4&&(0!==a%100||0===a%400),tc=[0,31,60,91,121,152,182,213,244,274,305,335],uc=[0,31,59,90,120,151,181,212,243,273,304,334];function vc(a,b,c,d,f,g,k){return F?P(16,1,a,b,c,d,f,g,k):-52}function wc(a,b,c,d,f,g){if(F)return P(17,1,a,b,c,d,f,g)}\nvar yc=a=>{var b=qb(a)+1,c=xc(b);c&&sb(a,c,b);return c},zc=[],Ac=(a,b)=>{zc.length=0;for(var c;c=x()[a++>>>0];){var d=105!=c;d&=112!=c;b+=d&&b%8?4:0;zc.push(112==c?A()[b>>>2>>>0]:106==c?L[b>>>3]:105==c?y()[b>>>2>>>0]:ka()[b>>>3>>>0]);b+=d?8:4}return zc},Bc={},Dc=()=>{if(!Cc){var a={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(\"object\"==typeof navigator&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:qa||\"./this.program\"},b;for(b in Bc)void 0===\nBc[b]?delete a[b]:a[b]=Bc[b];var c=[];for(b in a)c.push(`${b}=${a[b]}`);Cc=c}return Cc},Cc;function Ec(a,b){if(F)return P(18,1,a,b);a>>>=0;b>>>=0;var c=0;Dc().forEach((d,f)=>{var g=b+c;f=A()[a+4*f>>>2>>>0]=g;for(g=0;g<d.length;++g)e()[f++>>>0>>>0]=d.charCodeAt(g);e()[f>>>0>>>0]=0;c+=d.length+1});return 0}function Fc(a,b){if(F)return P(19,1,a,b);a>>>=0;b>>>=0;var c=Dc();A()[a>>>2>>>0]=c.length;var d=0;c.forEach(f=>d+=f.length+1);A()[b>>>2>>>0]=d;return 0}function Gc(a){return F?P(20,1,a):52}\nfunction Hc(a,b,c,d){return F?P(21,1,a,b,c,d):52}function Ic(a,b,c,d){return F?P(22,1,a,b,c,d):70}var Jc=[null,[],[]];function Kc(a,b,c,d){if(F)return P(23,1,a,b,c,d);b>>>=0;c>>>=0;d>>>=0;for(var f=0,g=0;g<c;g++){var k=A()[b>>>2>>>0],l=A()[b+4>>>2>>>0];b+=8;for(var n=0;n<l;n++){var p=x()[k+n>>>0],r=Jc[a];0===p||10===p?((1===a?Ba:H)(Xa(r,0)),r.length=0):r.push(p)}f+=l}A()[d>>>2>>>0]=f;return 0}var Lc=[31,29,31,30,31,30,31,31,30,31,30,31],Mc=[31,28,31,30,31,30,31,31,30,31,30,31];\nfunction Nc(a){var b=Array(qb(a)+1);rb(a,b,0,b.length);return b}var Oc=(a,b)=>{e().set(a,b>>>0)};\nfunction Pc(a,b,c,d){function f(h,t,z){for(h=\"number\"==typeof h?h.toString():h||\"\";h.length<t;)h=z[0]+h;return h}function g(h,t){return f(h,t,\"0\")}function k(h,t){function z(sc){return 0>sc?-1:0<sc?1:0}var X;0===(X=z(h.getFullYear()-t.getFullYear()))&&0===(X=z(h.getMonth()-t.getMonth()))&&(X=z(h.getDate()-t.getDate()));return X}function l(h){switch(h.getDay()){case 0:return new Date(h.getFullYear()-1,11,29);case 1:return h;case 2:return new Date(h.getFullYear(),0,3);case 3:return new Date(h.getFullYear(),\n0,2);case 4:return new Date(h.getFullYear(),0,1);case 5:return new Date(h.getFullYear()-1,11,31);case 6:return new Date(h.getFullYear()-1,11,30)}}function n(h){var t=h.xb;for(h=new Date((new Date(h.yb+1900,0,1)).getTime());0<t;){var z=h.getMonth(),X=(rc(h.getFullYear())?Lc:Mc)[z];if(t>X-h.getDate())t-=X-h.getDate()+1,h.setDate(1),11>z?h.setMonth(z+1):(h.setMonth(0),h.setFullYear(h.getFullYear()+1));else{h.setDate(h.getDate()+t);break}}z=new Date(h.getFullYear()+1,0,4);t=l(new Date(h.getFullYear(),\n0,4));z=l(z);return 0>=k(t,h)?0>=k(z,h)?h.getFullYear()+1:h.getFullYear():h.getFullYear()-1}a>>>=0;b>>>=0;c>>>=0;d>>>=0;var p=A()[d+40>>>2>>>0];d={ic:y()[d>>>2>>>0],hc:y()[d+4>>>2>>>0],Db:y()[d+8>>>2>>>0],Jb:y()[d+12>>>2>>>0],Eb:y()[d+16>>>2>>>0],yb:y()[d+20>>>2>>>0],tb:y()[d+24>>>2>>>0],xb:y()[d+28>>>2>>>0],qc:y()[d+32>>>2>>>0],fc:y()[d+36>>>2>>>0],jc:p?M(p):\"\"};c=M(c);p={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\n\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var r in p)c=c.replace(new RegExp(r,\"g\"),p[r]);var u=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),w=\"January February March April May June July August September October November December\".split(\" \");p={\"%a\":h=>u[h.tb].substring(0,3),\"%A\":h=>\nu[h.tb],\"%b\":h=>w[h.Eb].substring(0,3),\"%B\":h=>w[h.Eb],\"%C\":h=>g((h.yb+1900)/100|0,2),\"%d\":h=>g(h.Jb,2),\"%e\":h=>f(h.Jb,2,\" \"),\"%g\":h=>n(h).toString().substring(2),\"%G\":h=>n(h),\"%H\":h=>g(h.Db,2),\"%I\":h=>{h=h.Db;0==h?h=12:12<h&&(h-=12);return g(h,2)},\"%j\":h=>{for(var t=0,z=0;z<=h.Eb-1;t+=(rc(h.yb+1900)?Lc:Mc)[z++]);return g(h.Jb+t,3)},\"%m\":h=>g(h.Eb+1,2),\"%M\":h=>g(h.hc,2),\"%n\":()=>\"\\n\",\"%p\":h=>0<=h.Db&&12>h.Db?\"AM\":\"PM\",\"%S\":h=>g(h.ic,2),\"%t\":()=>\"\\t\",\"%u\":h=>h.tb||7,\"%U\":h=>g(Math.floor((h.xb+7-h.tb)/\n7),2),\"%V\":h=>{var t=Math.floor((h.xb+7-(h.tb+6)%7)/7);2>=(h.tb+371-h.xb-2)%7&&t++;if(t)53==t&&(z=(h.tb+371-h.xb)%7,4==z||3==z&&rc(h.yb)||(t=1));else{t=52;var z=(h.tb+7-h.xb-1)%7;(4==z||5==z&&rc(h.yb%400-1))&&t++}return g(t,2)},\"%w\":h=>h.tb,\"%W\":h=>g(Math.floor((h.xb+7-(h.tb+6)%7)/7),2),\"%y\":h=>(h.yb+1900).toString().substring(2),\"%Y\":h=>h.yb+1900,\"%z\":h=>{h=h.fc;var t=0<=h;h=Math.abs(h)/60;return(t?\"+\":\"-\")+String(\"0000\"+(h/60*100+h%60)).slice(-4)},\"%Z\":h=>h.jc,\"%%\":()=>\"%\"};c=c.replace(/%%/g,\"\\x00\\x00\");\nfor(r in p)c.includes(r)&&(c=c.replace(new RegExp(r,\"g\"),p[r](d)));c=c.replace(/\\0\\0/g,\"%\");r=Nc(c);if(r.length>b)return 0;Oc(r,a);return r.length-1}var Qc=a=>{try{a()}catch(b){I(b)}};function Rc(){var a=Y,b={},c;for(c in a)(function(d){var f=a[d];b[d]=\"function\"==typeof f?function(){Sc.push(d);try{return f.apply(null,arguments)}finally{J||(Sc.pop()===d||I(),C&&1===Z&&0===Sc.length&&(Z=0,O+=1,Qc(Tc),\"undefined\"!=typeof Fibers&&Fibers.rc()))}}:f})(c);return b}\nvar Z=0,C=null,Uc=0,Sc=[],Vc={},Wc={},Xc=0,Yc=null,Zc=[];function oa(){return new Promise((a,b)=>{Yc={resolve:a,reject:b}})}function $c(){var a=xc(65548),b=a+12;A()[a>>>2>>>0]=b;A()[a+4>>>2>>>0]=b+65536;b=Sc[0];var c=Vc[b];void 0===c&&(c=Xc++,Vc[b]=c,Wc[c]=b);b=c;y()[a+8>>>2>>>0]=b;return a}function ad(){var a=y()[C+8>>>2>>>0];a=Y[Wc[a]];--O;return a()}\nfunction bd(a){if(!J){if(0===Z){var b=!1,c=!1;a((d=0)=>{if(!J&&(Uc=d,b=!0,c)){Z=2;Qc(()=>cd(C));\"undefined\"!=typeof Browser&&Browser.Gb.Tb&&Browser.Gb.resume();d=!1;try{var f=ad()}catch(l){f=l,d=!0}var g=!1;if(!C){var k=Yc;k&&(Yc=null,(d?k.reject:k.resolve)(f),g=!0)}if(d&&!g)throw f;}});c=!0;b||(Z=1,C=$c(),\"undefined\"!=typeof Browser&&Browser.Gb.Tb&&Browser.Gb.pause(),Qc(()=>dd(C)))}else 2===Z?(Z=0,Qc(ed),W(C),C=null,Zc.forEach(d=>Xb(d))):I(`invalid state: ${Z}`);return Uc}}\nfunction fd(a){return bd(b=>{a().then(b)})}N.Fb();for(var gd=Array(256),hd=0;256>hd;++hd)gd[hd]=String.fromCharCode(hd);Fb=gd;R=B.BindingError=class extends Error{constructor(a){super(a);this.name=\"BindingError\"}};B.InternalError=class extends Error{constructor(a){super(a);this.name=\"InternalError\"}};Object.assign(Lb.prototype,{get(a){return this.ub[a]},has(a){return void 0!==this.ub[a]},Hb(a){var b=this.Kb.pop()||this.ub.length;this.ub[b]=a;return b},Ib(a){this.ub[a]=void 0;this.Kb.push(a)}});\nT.ub.push({value:void 0},{value:null},{value:!0},{value:!1});T.Ab=T.ub.length;B.count_emval_handles=()=>{for(var a=0,b=T.Ab;b<T.ub.length;++b)void 0!==T.ub[b]&&++a;return a};\nvar jd=[Ya,Za,mb,ob,pb,tb,ub,vb,wb,xb,yb,zb,Ab,Bb,Cb,Db,vc,wc,Ec,Fc,Gc,Hc,Ic,Kc],ld={ta:function(a,b,c){return fd(async()=>{await B.Xb(a,b,c)})},b:function(a,b,c){a>>>=0;(new jb(a)).Fb(b>>>0,c>>>0);kb=a;lb++;throw kb;},fa:function(a){kd(a>>>0,!D,1,!sa,131072,!1);N.Pb()},D:function(a){a>>>=0;F?postMessage({cmd:\"cleanupThread\",thread:a}):((a=N.nb[a])||I(),N.Nb(a))},X:nb,u:ob,la:pb,T:tb,V:ub,M:vb,ja:wb,ca:xb,ia:yb,F:zb,U:Ab,R:Bb,ka:Cb,S:Db,I:function(a,b,c,d,f){a>>>=0;b>>>=0;c>>>=0;b=Q(b);var g=-1!=\nb.indexOf(\"u\");g&&(f=(1n<<64n)-1n);S(a,{name:b,fromWireType:k=>k,toWireType:function(k,l){if(\"bigint\"!=typeof l&&\"number\"!=typeof l)throw new TypeError(`Cannot convert \"${Eb(l)}\" to ${this.name}`);if(l<d||l>f)throw new TypeError(`Passing a number \"${Eb(l)}\" from JS side to C/C++ side to an argument of type \"${b}\", which is outside the valid range [${d}, ${f}]!`);return l},argPackAdvance:8,readValueFromPointer:Kb(b,c,!g),Bb:null})},ra:function(a,b,c,d){a>>>=0;b=Q(b>>>0);S(a,{name:b,fromWireType:function(f){return!!f},\ntoWireType:function(f,g){return g?c:d},argPackAdvance:8,readValueFromPointer:function(f){return this.fromWireType(x()[f>>>0])},Bb:null})},qa:function(a,b){a>>>=0;b=Q(b>>>0);S(a,{name:b,fromWireType:c=>{var d=U(c);Mb(c);return d},toWireType:(c,d)=>V(d),argPackAdvance:8,readValueFromPointer:Nb,Bb:null})},H:function(a,b,c){a>>>=0;c>>>=0;b=Q(b>>>0);S(a,{name:b,fromWireType:d=>d,toWireType:(d,f)=>f,argPackAdvance:8,readValueFromPointer:Ob(b,c),Bb:null})},w:function(a,b,c,d,f){a>>>=0;c>>>=0;b=Q(b>>>0);\n-1===f&&(f=4294967295);f=l=>l;if(0===d){var g=32-8*c;f=l=>l<<g>>>g}var k=b.includes(\"unsigned\")?function(l,n){return n>>>0}:function(l,n){return n};S(a,{name:b,fromWireType:f,toWireType:k,argPackAdvance:8,readValueFromPointer:Kb(b,c,0!==d),Bb:null})},p:function(a,b,c){function d(g){var k=A()[g>>>2>>>0];g=A()[g+4>>>2>>>0];return new f(e().buffer,g,k)}a>>>=0;var f=[Int8Array,Uint8Array,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array,BigInt64Array,BigUint64Array][b];c=Q(c>>>0);\nS(a,{name:c,fromWireType:d,argPackAdvance:8,readValueFromPointer:d},{Ub:!0})},J:function(a,b){a>>>=0;b=Q(b>>>0);var c=\"std::string\"===b;S(a,{name:b,fromWireType:function(d){var f=A()[d>>>2>>>0],g=d+4;if(c)for(var k=g,l=0;l<=f;++l){var n=g+l;if(l==f||0==x()[n>>>0]){k=M(k,n-k);if(void 0===p)var p=k;else p+=String.fromCharCode(0),p+=k;k=n+1}}else{p=Array(f);for(l=0;l<f;++l)p[l]=String.fromCharCode(x()[g+l>>>0]);p=p.join(\"\")}W(d);return p},toWireType:function(d,f){f instanceof ArrayBuffer&&(f=new Uint8Array(f));\nvar g=\"string\"==typeof f;if(!(g||f instanceof Uint8Array||f instanceof Uint8ClampedArray||f instanceof Int8Array))throw new R(\"Cannot pass non-string to std::string\");var k=c&&g?qb(f):f.length;var l=xc(4+k+1),n=l+4;A()[l>>>2>>>0]=k;if(c&&g)sb(f,n,k+1);else if(g)for(g=0;g<k;++g){var p=f.charCodeAt(g);if(255<p)throw W(n),new R(\"String has UTF-16 code units that do not fit in 8 bits\");x()[n+g>>>0]=p}else for(g=0;g<k;++g)x()[n+g>>>0]=f[g];null!==d&&d.push(W,l);return l},argPackAdvance:8,readValueFromPointer:Pb,\nBb(d){W(d)}})},B:function(a,b,c){a>>>=0;b>>>=0;c>>>=0;c=Q(c);if(2===b){var d=Rb;var f=Sb;var g=Tb;var k=()=>da();var l=1}else 4===b&&(d=Ub,f=Vb,g=Wb,k=()=>A(),l=2);S(a,{name:c,fromWireType:n=>{for(var p=A()[n>>>2>>>0],r=k(),u,w=n+4,h=0;h<=p;++h){var t=n+4+h*b;if(h==p||0==r[t>>>l])w=d(w,t-w),void 0===u?u=w:(u+=String.fromCharCode(0),u+=w),w=t+b}W(n);return u},toWireType:(n,p)=>{if(\"string\"!=typeof p)throw new R(`Cannot pass non-string to C++ string type ${c}`);var r=g(p),u=xc(4+r+b);A()[u>>>2]=r>>\nl;f(p,u+4,r+b);null!==n&&n.push(W,u);return u},argPackAdvance:8,readValueFromPointer:Nb,Bb(n){W(n)}})},sa:function(a,b){a>>>=0;b=Q(b>>>0);S(a,{Vb:!0,name:b,argPackAdvance:0,fromWireType:()=>{},toWireType:()=>{}})},oa:()=>!0,P:function(a,b){a>>>=0;a==b>>>0?setTimeout(()=>db()):F?postMessage({targetThread:a,cmd:\"checkMailbox\"}):(a=N.nb[a])&&a.postMessage({cmd:\"checkMailbox\"})},Y:function(a,b,c,d){b>>>=0;c/=2;dc.length=c;d=d>>>0>>>3;for(var f=0;f<c;f++)dc[f]=L[d+2*f]?L[d+2*f+1]:ka()[d+2*f+1>>>0];a=0>\na?Sa[-a-1]:jd[a];N.Sb=b;b=a.apply(null,dc);N.Sb=0;return b},ea:Yb,na:function(a){E&&N.nb[a>>>0].ref()},v:function(a,b,c){b>>>=0;c>>>=0;a=U(a>>>0);b=fc(b,\"emval::as\");var d=[],f=V(d);A()[c>>>2>>>0]=f;return b.toWireType(d,a)},l:function(a,b,c,d,f){c>>>=0;d>>>=0;f>>>=0;a=ic[a>>>0];b=U(b>>>0);c=hc(c);var g=[];a=a(b,c,g,f);g.length&&(A()[d>>>2>>>0]=V(g));return a},c:Mb,L:function(a,b){b>>>=0;a=U(a>>>0);b=U(b);return a==b},q:function(a){a>>>=0;if(0===a)return V(jc());a=hc(a);return V(jc()[a])},k:function(a,\nb){b=lc(a,b>>>0);var c=b.shift();a--;for(var d=[\"retType\"],f=[c],g=\"\",k=0;k<a;++k)g+=(0!==k?\", \":\"\")+\"arg\"+k,d.push(\"argType\"+k),f.push(b[k]);k=c.name+\"_$\"+b.map(p=>p.name).join(\"_\")+\"$\";var l=\"return function \"+mc(\"methodCaller_\"+k)+\"(handle, name, destructors, args) {\\n\",n=0;for(k=0;k<a;++k)l+=\"    var arg\"+k+\" = argType\"+k+\".readValueFromPointer(args\"+(n?\"+\"+n:\"\")+\");\\n\",n+=b[k].argPackAdvance;l+=\"    var rv = handle[name](\"+g+\");\\n\";for(k=0;k<a;++k)b[k].deleteObject&&(l+=\"    argType\"+k+\".deleteObject(arg\"+\nk+\");\\n\");c.Vb||(l+=\"    return retType.toWireType(destructors, rv);\\n\");d.push(l+\"};\\n\");a=oc(d).apply(null,f);return kc(a)},t:function(a,b){b>>>=0;a=U(a>>>0);b=U(b);return V(a[b])},h:function(a){a>>>=0;4<a&&(T.get(a).Mb+=1)},r:function(a,b,c,d){c>>>=0;d>>>=0;a=U(a>>>0);var f=qc[b];f||(f=pc(b),qc[b]=f);return f(a,c,d)},x:function(){return V([])},m:function(a){a=U(a>>>0);for(var b=Array(a.length),c=0;c<a.length;c++)b[c]=a[c];return V(b)},e:function(a){return V(hc(a>>>0))},j:function(){return V({})},\ni:function(a){a>>>=0;for(var b=U(a);b.length;){var c=b.pop();b.pop()(c)}Mb(a)},g:function(a,b,c){b>>>=0;c>>>=0;a=U(a>>>0);b=U(b);c=U(c);a[b]=c},d:function(a,b){b>>>=0;a=fc(a>>>0,\"_emval_take_value\");a=a.readValueFromPointer(b);return V(a)},$:function(a,b){a=-9007199254740992>a||9007199254740992<a?NaN:Number(a);b>>>=0;a=new Date(1E3*a);y()[b>>>2>>>0]=a.getUTCSeconds();y()[b+4>>>2>>>0]=a.getUTCMinutes();y()[b+8>>>2>>>0]=a.getUTCHours();y()[b+12>>>2>>>0]=a.getUTCDate();y()[b+16>>>2>>>0]=a.getUTCMonth();\ny()[b+20>>>2>>>0]=a.getUTCFullYear()-1900;y()[b+24>>>2>>>0]=a.getUTCDay();a=(a.getTime()-Date.UTC(a.getUTCFullYear(),0,1,0,0,0,0))/864E5|0;y()[b+28>>>2>>>0]=a},aa:function(a,b){a=-9007199254740992>a||9007199254740992<a?NaN:Number(a);b>>>=0;a=new Date(1E3*a);y()[b>>>2>>>0]=a.getSeconds();y()[b+4>>>2>>>0]=a.getMinutes();y()[b+8>>>2>>>0]=a.getHours();y()[b+12>>>2>>>0]=a.getDate();y()[b+16>>>2>>>0]=a.getMonth();y()[b+20>>>2>>>0]=a.getFullYear()-1900;y()[b+24>>>2>>>0]=a.getDay();var c=(rc(a.getFullYear())?\ntc:uc)[a.getMonth()]+a.getDate()-1|0;y()[b+28>>>2>>>0]=c;y()[b+36>>>2>>>0]=-(60*a.getTimezoneOffset());c=(new Date(a.getFullYear(),6,1)).getTimezoneOffset();var d=(new Date(a.getFullYear(),0,1)).getTimezoneOffset();a=(c!=d&&a.getTimezoneOffset()==Math.min(d,c))|0;y()[b+32>>>2>>>0]=a},ba:function(a){a>>>=0;var b=new Date(y()[a+20>>>2>>>0]+1900,y()[a+16>>>2>>>0],y()[a+12>>>2>>>0],y()[a+8>>>2>>>0],y()[a+4>>>2>>>0],y()[a>>>2>>>0],0),c=y()[a+32>>>2>>>0],d=b.getTimezoneOffset(),f=(new Date(b.getFullYear(),\n6,1)).getTimezoneOffset(),g=(new Date(b.getFullYear(),0,1)).getTimezoneOffset(),k=Math.min(g,f);0>c?y()[a+32>>>2>>>0]=Number(f!=g&&k==d):0<c!=(k==d)&&(f=Math.max(g,f),b.setTime(b.getTime()+6E4*((0<c?k:f)-d)));y()[a+24>>>2>>>0]=b.getDay();c=(rc(b.getFullYear())?tc:uc)[b.getMonth()]+b.getDate()-1|0;y()[a+28>>>2>>>0]=c;y()[a>>>2>>>0]=b.getSeconds();y()[a+4>>>2>>>0]=b.getMinutes();y()[a+8>>>2>>>0]=b.getHours();y()[a+12>>>2>>>0]=b.getDate();y()[a+16>>>2>>>0]=b.getMonth();y()[a+20>>>2>>>0]=b.getYear();\nreturn BigInt(b.getTime()/1E3)},Z:vc,_:wc,O:function(a,b,c){function d(p){return(p=p.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?p[1]:\"GMT\"}a>>>=0;b>>>=0;c>>>=0;var f=(new Date).getFullYear(),g=new Date(f,0,1),k=new Date(f,6,1);f=g.getTimezoneOffset();var l=k.getTimezoneOffset(),n=Math.max(f,l);A()[a>>>2>>>0]=60*n;y()[b>>>2>>>0]=Number(f!=l);a=d(g);b=d(k);a=yc(a);b=yc(b);l<f?(A()[c>>>2>>>0]=a,A()[c+4>>>2>>>0]=b):(A()[c>>>2>>>0]=b,A()[c+4>>>2>>>0]=a)},o:()=>{I(\"\")},f:function(a,b,c){a>>>=0;b=Ac(b>>>\n0,c>>>0);return Sa[a].apply(null,b)},K:function(a,b,c){a>>>=0;b=Ac(b>>>0,c>>>0);return Sa[a].apply(null,b)},E:()=>{},G:()=>Date.now(),ma:()=>{O+=1;throw\"unwind\";},Q:function(){return 4294901760},n:()=>performance.timeOrigin+performance.now(),z:()=>E?require(\"os\").cpus().length:navigator.hardwareConcurrency,N:function(a){a>>>=0;var b=x().length;if(a<=b||4294901760<a)return!1;for(var c=1;4>=c;c*=2){var d=b*(1+.2/c);d=Math.min(d,a+100663296);var f=Math;d=Math.max(a,d);a:{f=(f.min.call(f,4294901760,d+\n(65536-d%65536)%65536)-m.buffer.byteLength+65535)/65536;try{m.grow(f);v();var g=1;break a}catch(k){}g=void 0}if(g)return!0}return!1},ga:Ec,ha:Fc,W:$a,y:Gc,C:Hc,da:Ic,A:Kc,a:m||B.wasmMemory,pa:Pc,s:function(a,b,c,d){return Pc(a>>>0,b>>>0,c>>>0,d>>>0)}},Y=function(){var a={a:ld};Ia++;Ra(a,function(b){var c=b.module;Y=b.instance.exports;Y=Rc();Y=md();N.Qb.push(Y.$a);Ga.unshift(Y.ua);Ca=c;La()}).catch(na);return{}}();B._OrtInit=(a,b)=>(B._OrtInit=Y.va)(a,b);\nB._OrtGetLastError=(a,b)=>(B._OrtGetLastError=Y.wa)(a,b);B._OrtCreateSessionOptions=(a,b,c,d,f,g,k,l,n,p)=>(B._OrtCreateSessionOptions=Y.xa)(a,b,c,d,f,g,k,l,n,p);B._OrtAppendExecutionProvider=(a,b)=>(B._OrtAppendExecutionProvider=Y.ya)(a,b);B._OrtAddFreeDimensionOverride=(a,b,c)=>(B._OrtAddFreeDimensionOverride=Y.za)(a,b,c);B._OrtAddSessionConfigEntry=(a,b,c)=>(B._OrtAddSessionConfigEntry=Y.Aa)(a,b,c);B._OrtReleaseSessionOptions=a=>(B._OrtReleaseSessionOptions=Y.Ba)(a);\nB._OrtCreateSession=(a,b,c)=>(B._OrtCreateSession=Y.Ca)(a,b,c);B._OrtReleaseSession=a=>(B._OrtReleaseSession=Y.Da)(a);B._OrtGetInputOutputCount=(a,b,c)=>(B._OrtGetInputOutputCount=Y.Ea)(a,b,c);B._OrtGetInputName=(a,b)=>(B._OrtGetInputName=Y.Fa)(a,b);B._OrtGetOutputName=(a,b)=>(B._OrtGetOutputName=Y.Ga)(a,b);B._OrtFree=a=>(B._OrtFree=Y.Ha)(a);B._OrtCreateTensor=(a,b,c,d,f,g)=>(B._OrtCreateTensor=Y.Ia)(a,b,c,d,f,g);B._OrtGetTensorData=(a,b,c,d,f)=>(B._OrtGetTensorData=Y.Ja)(a,b,c,d,f);\nB._OrtReleaseTensor=a=>(B._OrtReleaseTensor=Y.Ka)(a);B._OrtCreateRunOptions=(a,b,c,d)=>(B._OrtCreateRunOptions=Y.La)(a,b,c,d);B._OrtAddRunConfigEntry=(a,b,c)=>(B._OrtAddRunConfigEntry=Y.Ma)(a,b,c);B._OrtReleaseRunOptions=a=>(B._OrtReleaseRunOptions=Y.Na)(a);B._OrtCreateBinding=a=>(B._OrtCreateBinding=Y.Oa)(a);B._OrtBindInput=(a,b,c)=>(B._OrtBindInput=Y.Pa)(a,b,c);B._OrtBindOutput=(a,b,c,d)=>(B._OrtBindOutput=Y.Qa)(a,b,c,d);B._OrtClearBoundOutputs=a=>(B._OrtClearBoundOutputs=Y.Ra)(a);\nB._OrtReleaseBinding=a=>(B._OrtReleaseBinding=Y.Sa)(a);B._OrtRunWithBinding=(a,b,c,d,f)=>(B._OrtRunWithBinding=Y.Ta)(a,b,c,d,f);B._OrtRun=(a,b,c,d,f,g,k,l)=>(B._OrtRun=Y.Ua)(a,b,c,d,f,g,k,l);B._OrtEndProfiling=a=>(B._OrtEndProfiling=Y.Va)(a);B._JsepOutput=(a,b,c)=>(B._JsepOutput=Y.Wa)(a,b,c);B._JsepGetNodeName=a=>(B._JsepGetNodeName=Y.Xa)(a);var cb=B._pthread_self=()=>(cb=B._pthread_self=Y.Ya)(),xc=B._malloc=a=>(xc=B._malloc=Y.Za)(a),W=B._free=a=>(W=B._free=Y._a)(a);\nB.__emscripten_tls_init=()=>(B.__emscripten_tls_init=Y.$a)();var ec=a=>(ec=Y.ab)(a);B.__embind_initialize_bindings=()=>(B.__embind_initialize_bindings=Y.bb)();var kd=B.__emscripten_thread_init=(a,b,c,d,f,g)=>(kd=B.__emscripten_thread_init=Y.db)(a,b,c,d,f,g);B.__emscripten_thread_crashed=()=>(B.__emscripten_thread_crashed=Y.eb)();\nvar cc=(a,b,c,d)=>(cc=Y.fb)(a,b,c,d),bb=a=>(bb=Y.gb)(a),ib=B.__emscripten_thread_exit=a=>(ib=B.__emscripten_thread_exit=Y.hb)(a),Zb=B.__emscripten_check_mailbox=()=>(Zb=B.__emscripten_check_mailbox=Y.ib)(),fb=(a,b)=>(fb=Y.jb)(a,b),$b=()=>($b=Y.kb)(),gb=a=>(gb=Y.lb)(a),bc=a=>(bc=Y.mb)(a),hb=B.dynCall_ii=(a,b)=>(hb=B.dynCall_ii=Y.ob)(a,b),dd=a=>(dd=Y.pb)(a),Tc=()=>(Tc=Y.qb)(),cd=a=>(cd=Y.rb)(a),ed=()=>(ed=Y.sb)();B.___start_em_js=1452163;B.___stop_em_js=1452324;\nfunction md(){var a=Y;a=Object.assign({},a);var b=d=>()=>d()>>>0,c=d=>f=>d(f)>>>0;a.__errno_location=b(a.__errno_location);a.Ya=b(a.Ya);a.Za=c(a.Za);a.ab=c(a.ab);a.kb=b(a.kb);a.mb=c(a.mb);return a}B.wasmMemory=m;B.stackAlloc=bc;B.stackSave=$b;B.stackRestore=gb;B.keepRuntimeAlive=()=>0<O;B.UTF8ToString=M;B.stringToUTF8=sb;B.lengthBytesUTF8=qb;B.ExitStatus=Ta;B.PThread=N;var nd;Ka=function od(){nd||pd();nd||(Ka=od)};\nfunction pd(){0<Ia||(F?(ma(B),F||eb(Ga),startWorker(B)):(eb(Fa),0<Ia||nd||(nd=!0,B.calledRun=!0,J||(F||eb(Ga),ma(B),F||eb(Ha)))))}pd();\n\n\n  return moduleArg.ready\n}\n\n);\n})();\nif (typeof exports === 'object' && typeof module === 'object')\n  module.exports = ortWasmThreaded;\nelse if (typeof define === 'function' && define['amd'])\n  define([], () => ortWasmThreaded);\n", "\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason??e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(\"worker.js received unknown command \"+e.data.cmd),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport * as path from 'node:path';\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from './binding/ort-wasm';\nimport {OrtWasmThreadedModule} from './binding/ort-wasm-threaded';\n\n/* eslint-disable @typescript-eslint/no-require-imports */\nlet ortWasmFactory: EmscriptenModuleFactory<OrtWasmModule>;\n\nif (!BUILD_DEFS.DISABLE_TRAINING) {\n  ortWasmFactory = require('./binding/ort-training-wasm-simd.js');\n} else {\n  ortWasmFactory =\n      BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm.js') : require('./binding/ort-wasm-simd.jsep.js');\n}\n\nconst ortWasmFactoryThreaded: EmscriptenModuleFactory<OrtWasmModule> = !BUILD_DEFS.DISABLE_WASM_THREAD ?\n    (BUILD_DEFS.DISABLE_WEBGPU ? require('./binding/ort-wasm-threaded.js') :\n                                 require('./binding/ort-wasm-simd-threaded.jsep.js')) :\n    ortWasmFactory;\n/* eslint-enable @typescript-eslint/no-require-imports */\n\nlet wasm: OrtWasmModule|undefined;\nlet initialized = false;\nlet initializing = false;\nlet aborted = false;\n\nconst isMultiThreadSupported = (): boolean => {\n  try {\n    // If 'SharedArrayBuffer' is not available, WebAssembly threads will not work.\n    if (typeof SharedArrayBuffer === 'undefined') {\n      return false;\n    }\n\n    // Test for transferability of SABs (for browsers. needed for Firefox)\n    // https://groups.google.com/forum/#!msg/mozilla.dev.platform/IHkBZlHETpA/dwsMNchWEQAJ\n    if (typeof MessageChannel !== 'undefined') {\n      new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));\n    }\n\n    // Test for WebAssembly threads capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing threaded instructions.\n    return WebAssembly.validate(new Uint8Array([\n      0, 97, 115, 109, 1, 0,  0,  0, 1, 4, 1,  96, 0,   0,  3, 2, 1,  0, 5,\n      4, 1,  3,   1,   1, 10, 11, 1, 9, 0, 65, 0,  254, 16, 2, 0, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst isSimdSupported = (): boolean => {\n  try {\n    // Test for WebAssembly SIMD capability (for both browsers and Node.js)\n    // This typed array is a WebAssembly program containing SIMD instructions.\n\n    // The binary data is generated from the following code by wat2wasm:\n    //\n    // (module\n    //   (type $t0 (func))\n    //   (func $f0 (type $t0)\n    //     (drop\n    //       (i32x4.dot_i16x8_s\n    //         (i8x16.splat\n    //           (i32.const 0))\n    //         (v128.const i32x4 0x00000000 0x00000000 0x00000000 0x00000000)))))\n\n    return WebAssembly.validate(new Uint8Array([\n      0,   97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1,   28,  0, 65, 0,\n      253, 15, 253, 12,  0, 0, 0, 0, 0, 0, 0, 0,  0, 0, 0, 0, 0, 0, 0,  0,  253, 186, 1, 26, 11\n    ]));\n  } catch (e) {\n    return false;\n  }\n};\n\nconst getWasmFileName = (useSimd: boolean, useThreads: boolean) => {\n  if (useSimd) {\n    if (!BUILD_DEFS.DISABLE_TRAINING) {\n      return 'ort-training-wasm-simd.wasm';\n    }\n    return useThreads ? 'ort-wasm-simd-threaded.wasm' : 'ort-wasm-simd.wasm';\n  } else {\n    return useThreads ? 'ort-wasm-threaded.wasm' : 'ort-wasm.wasm';\n  }\n};\n\nexport const initializeWebAssembly = async(flags: Env.WebAssemblyFlags): Promise<void> => {\n  if (initialized) {\n    return Promise.resolve();\n  }\n  if (initializing) {\n    throw new Error('multiple calls to \\'initializeWebAssembly()\\' detected.');\n  }\n  if (aborted) {\n    throw new Error('previous call to \\'initializeWebAssembly()\\' failed.');\n  }\n\n  initializing = true;\n\n  // wasm flags are already initialized\n  const timeout = flags.initTimeout!;\n  const numThreads = flags.numThreads!;\n  const simd = flags.simd!;\n\n  const useThreads = numThreads > 1 && isMultiThreadSupported();\n  const useSimd = simd && isSimdSupported();\n\n  const wasmPaths = flags.wasmPaths;\n  const wasmPrefixOverride = typeof wasmPaths === 'string' ? wasmPaths : undefined;\n  const wasmFileName = getWasmFileName(useSimd, useThreads);\n  const wasmPathOverride = typeof wasmPaths === 'object' ? wasmPaths[wasmFileName] : undefined;\n\n  let isTimeout = false;\n\n  const tasks: Array<Promise<void>> = [];\n\n  // promise for timeout\n  if (timeout > 0) {\n    tasks.push(new Promise((resolve) => {\n      setTimeout(() => {\n        isTimeout = true;\n        resolve();\n      }, timeout);\n    }));\n  }\n\n  // promise for module initialization\n  tasks.push(new Promise((resolve, reject) => {\n    const factory = useThreads ? ortWasmFactoryThreaded : ortWasmFactory;\n    const config: Partial<OrtWasmModule> = {\n      locateFile: (fileName: string, scriptDirectory: string) => {\n        if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads && fileName.endsWith('.worker.js') &&\n            typeof Blob !== 'undefined') {\n          return URL.createObjectURL(new Blob(\n              [\n                // This require() function is handled by esbuild plugin to load file content as string.\n                // eslint-disable-next-line @typescript-eslint/no-require-imports\n                require('./binding/ort-wasm-threaded.worker.js')\n              ],\n              {type: 'text/javascript'}));\n        }\n\n        if (fileName.endsWith('.wasm')) {\n          if (wasmPathOverride) {\n            return wasmPathOverride;\n          }\n\n          const prefix = wasmPrefixOverride ?? scriptDirectory;\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            if (wasmFileName === 'ort-wasm-simd.wasm') {\n              return prefix + 'ort-wasm-simd.jsep.wasm';\n            } else if (wasmFileName === 'ort-wasm-simd-threaded.wasm') {\n              return prefix + 'ort-wasm-simd-threaded.jsep.wasm';\n            }\n          }\n\n          return prefix + wasmFileName;\n        }\n\n        return scriptDirectory + fileName;\n      }\n    };\n\n    if (!BUILD_DEFS.DISABLE_WASM_THREAD && useThreads) {\n      if (typeof Blob === 'undefined') {\n        config.mainScriptUrlOrBlob = path.join(__dirname, 'ort-wasm-threaded.js');\n      } else {\n        const scriptSourceCode = `var ortWasmThreaded=${factory.toString()};`;\n        config.mainScriptUrlOrBlob = new Blob([scriptSourceCode], {type: 'text/javascript'});\n      }\n    }\n\n    factory(config).then(\n        // wasm module initialized successfully\n        module => {\n          initializing = false;\n          initialized = true;\n          wasm = module;\n          resolve();\n        },\n        // wasm module failed to initialize\n        (what) => {\n          initializing = false;\n          aborted = true;\n          reject(what);\n        });\n  }));\n\n  await Promise.race(tasks);\n\n  if (isTimeout) {\n    throw new Error(`WebAssembly backend initializing failed due to timeout: ${timeout}ms`);\n  }\n};\n\nexport const getInstance = (): OrtWasmModule => {\n  if (initialized && wasm) {\n    return wasm;\n  }\n\n  throw new Error('WebAssembly is not initialized yet.');\n};\n\nexport const dispose = (): void => {\n  if (initialized && !initializing && !aborted) {\n    initializing = true;\n\n    (wasm as OrtWasmThreadedModule).PThread?.terminateAllThreads();\n    wasm = undefined;\n\n    initializing = false;\n    initialized = false;\n    aborted = true;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {getInstance} from './wasm-factory';\n\nexport const allocWasmString = (data: string, allocs: number[]): number => {\n  const wasm = getInstance();\n\n  const dataLength = wasm.lengthBytesUTF8(data) + 1;\n  const dataOffset = wasm._malloc(dataLength);\n  wasm.stringToUTF8(data, dataOffset, dataLength);\n  allocs.push(dataOffset);\n\n  return dataOffset;\n};\n\ninterface ExtraOptionsHandler {\n  (name: string, value: string): void;\n}\n\nexport const iterateExtraOptions =\n    (options: Record<string, unknown>, prefix: string, seen: WeakSet<Record<string, unknown>>,\n     handler: ExtraOptionsHandler): void => {\n      if (typeof options == 'object' && options !== null) {\n        if (seen.has(options)) {\n          throw new Error('Circular reference in options');\n        } else {\n          seen.add(options);\n        }\n      }\n\n      Object.entries(options).forEach(([key, value]) => {\n        const name = (prefix) ? prefix + key : key;\n        if (typeof value === 'object') {\n          iterateExtraOptions(value as Record<string, unknown>, name + '.', seen, handler);\n        } else if (typeof value === 'string' || typeof value === 'number') {\n          handler(name, value.toString());\n        } else if (typeof value === 'boolean') {\n          handler(name, (value) ? '1' : '0');\n        } else {\n          throw new Error(`Can't handle extra config type: ${typeof value}`);\n        }\n      });\n    };\n\n/**\n * check web assembly API's last error and throw error if any error occurred.\n * @param message a message used when an error occurred.\n */\nexport const checkLastError = (message: string): void => {\n  const wasm = getInstance();\n\n  const stack = wasm.stackSave();\n  try {\n    const paramsOffset = wasm.stackAlloc(8);\n    wasm._OrtGetLastError(paramsOffset, paramsOffset + 4);\n    const errorCode = wasm.HEAP32[paramsOffset / 4];\n    const errorMessagePointer = wasm.HEAPU32[paramsOffset / 4 + 1];\n    const errorMessage = errorMessagePointer ? wasm.UTF8ToString(errorMessagePointer) : '';\n    throw new Error(`${message} ERROR_CODE: ${errorCode}, ERROR_MESSAGE: ${errorMessage}`);\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nexport const setRunOptions = (options: InferenceSession.RunOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let runOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const runOptions: InferenceSession.RunOptions = options || {};\n\n  try {\n    if (options?.logSeverityLevel === undefined) {\n      runOptions.logSeverityLevel = 2;  // Default to warning\n    } else if (\n        typeof options.logSeverityLevel !== 'number' || !Number.isInteger(options.logSeverityLevel) ||\n        options.logSeverityLevel < 0 || options.logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${options.logSeverityLevel}`);\n    }\n\n    if (options?.logVerbosityLevel === undefined) {\n      runOptions.logVerbosityLevel = 0;  // Default to 0\n    } else if (typeof options.logVerbosityLevel !== 'number' || !Number.isInteger(options.logVerbosityLevel)) {\n      throw new Error(`log verbosity level is not valid: ${options.logVerbosityLevel}`);\n    }\n\n    if (options?.terminate === undefined) {\n      runOptions.terminate = false;\n    }\n\n    let tagDataOffset = 0;\n    if (options?.tag !== undefined) {\n      tagDataOffset = allocWasmString(options.tag, allocs);\n    }\n\n    runOptionsHandle = wasm._OrtCreateRunOptions(\n        runOptions.logSeverityLevel!, runOptions.logVerbosityLevel!, !!runOptions.terminate!, tagDataOffset);\n    if (runOptionsHandle === 0) {\n      checkLastError('Can\\'t create run options.');\n    }\n\n    if (options?.extra !== undefined) {\n      iterateExtraOptions(options.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddRunConfigEntry(runOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a run config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [runOptionsHandle, allocs];\n  } catch (e) {\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {InferenceSession} from 'onnxruntime-common';\n\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError, iterateExtraOptions} from './wasm-utils';\n\nconst getGraphOptimzationLevel = (graphOptimizationLevel: string|unknown): number => {\n  switch (graphOptimizationLevel) {\n    case 'disabled':\n      return 0;\n    case 'basic':\n      return 1;\n    case 'extended':\n      return 2;\n    case 'all':\n      return 99;\n    default:\n      throw new Error(`unsupported graph optimization level: ${graphOptimizationLevel}`);\n  }\n};\n\nconst getExecutionMode = (executionMode: 'sequential'|'parallel'): number => {\n  switch (executionMode) {\n    case 'sequential':\n      return 0;\n    case 'parallel':\n      return 1;\n    default:\n      throw new Error(`unsupported execution mode: ${executionMode}`);\n  }\n};\n\nconst appendDefaultOptions = (options: InferenceSession.SessionOptions): void => {\n  if (!options.extra) {\n    options.extra = {};\n  }\n  if (!options.extra.session) {\n    options.extra.session = {};\n  }\n  const session = options.extra.session as Record<string, string>;\n  if (!session.use_ort_model_bytes_directly) {\n    // eslint-disable-next-line camelcase\n    session.use_ort_model_bytes_directly = '1';\n  }\n\n  // if using JSEP with WebGPU, always disable memory pattern\n  if (options.executionProviders &&\n      options.executionProviders.some(ep => (typeof ep === 'string' ? ep : ep.name) === 'webgpu')) {\n    options.enableMemPattern = false;\n  }\n};\n\nconst setExecutionProviders =\n    (sessionOptionsHandle: number, executionProviders: readonly InferenceSession.ExecutionProviderConfig[],\n     allocs: number[]): void => {\n      for (const ep of executionProviders) {\n        let epName = typeof ep === 'string' ? ep : ep.name;\n\n        // check EP name\n        switch (epName) {\n          case 'xnnpack':\n            epName = 'XNNPACK';\n            break;\n          case 'webnn':\n            epName = 'WEBNN';\n            if (typeof ep !== 'string') {\n              const webnnOptions = ep as InferenceSession.WebNNExecutionProviderOption;\n              if (webnnOptions?.deviceType) {\n                const keyDataOffset = allocWasmString('deviceType', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.deviceType, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'deviceType' - ${webnnOptions.deviceType}.`);\n                }\n              }\n              if (webnnOptions?.numThreads) {\n                let numThreads = webnnOptions.numThreads;\n                // Just ignore invalid webnnOptions.numThreads.\n                if (typeof numThreads != 'number' || !Number.isInteger(numThreads) || numThreads < 0) {\n                  numThreads = 0;\n                }\n                const keyDataOffset = allocWasmString('numThreads', allocs);\n                const valueDataOffset = allocWasmString(numThreads.toString(), allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(`Can't set a session config entry: 'numThreads' - ${webnnOptions.numThreads}.`);\n                }\n              }\n              if (webnnOptions?.powerPreference) {\n                const keyDataOffset = allocWasmString('powerPreference', allocs);\n                const valueDataOffset = allocWasmString(webnnOptions.powerPreference, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'powerPreference' - ${webnnOptions.powerPreference}.`);\n                }\n              }\n            }\n            break;\n          case 'webgpu':\n            epName = 'JS';\n            if (typeof ep !== 'string') {\n              const webgpuOptions = ep as InferenceSession.WebGpuExecutionProviderOption;\n              if (webgpuOptions?.preferredLayout) {\n                if (webgpuOptions.preferredLayout !== 'NCHW' && webgpuOptions.preferredLayout !== 'NHWC') {\n                  throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${webgpuOptions.preferredLayout}`);\n                }\n                const keyDataOffset = allocWasmString('preferredLayout', allocs);\n                const valueDataOffset = allocWasmString(webgpuOptions.preferredLayout, allocs);\n                if (getInstance()._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !==\n                    0) {\n                  checkLastError(\n                      `Can't set a session config entry: 'preferredLayout' - ${webgpuOptions.preferredLayout}.`);\n                }\n              }\n            }\n            break;\n          case 'wasm':\n          case 'cpu':\n            continue;\n          default:\n            throw new Error(`not supported execution provider: ${epName}`);\n        }\n\n        const epNameDataOffset = allocWasmString(epName, allocs);\n        if (getInstance()._OrtAppendExecutionProvider(sessionOptionsHandle, epNameDataOffset) !== 0) {\n          checkLastError(`Can't append execution provider: ${epName}.`);\n        }\n      }\n    };\n\nexport const setSessionOptions = (options?: InferenceSession.SessionOptions): [number, number[]] => {\n  const wasm = getInstance();\n  let sessionOptionsHandle = 0;\n  const allocs: number[] = [];\n\n  const sessionOptions: InferenceSession.SessionOptions = options || {};\n  appendDefaultOptions(sessionOptions);\n\n  try {\n    const graphOptimizationLevel = getGraphOptimzationLevel(sessionOptions.graphOptimizationLevel ?? 'all');\n    const executionMode = getExecutionMode(sessionOptions.executionMode ?? 'sequential');\n    const logIdDataOffset =\n        typeof sessionOptions.logId === 'string' ? allocWasmString(sessionOptions.logId, allocs) : 0;\n\n    const logSeverityLevel = sessionOptions.logSeverityLevel ?? 2;  // Default to 2 - warning\n    if (!Number.isInteger(logSeverityLevel) || logSeverityLevel < 0 || logSeverityLevel > 4) {\n      throw new Error(`log serverity level is not valid: ${logSeverityLevel}`);\n    }\n\n    const logVerbosityLevel = sessionOptions.logVerbosityLevel ?? 0;  // Default to 0 - verbose\n    if (!Number.isInteger(logVerbosityLevel) || logVerbosityLevel < 0 || logVerbosityLevel > 4) {\n      throw new Error(`log verbosity level is not valid: ${logVerbosityLevel}`);\n    }\n\n    const optimizedModelFilePathOffset = typeof sessionOptions.optimizedModelFilePath === 'string' ?\n        allocWasmString(sessionOptions.optimizedModelFilePath, allocs) :\n        0;\n\n    sessionOptionsHandle = wasm._OrtCreateSessionOptions(\n        graphOptimizationLevel, !!sessionOptions.enableCpuMemArena, !!sessionOptions.enableMemPattern, executionMode,\n        !!sessionOptions.enableProfiling, 0, logIdDataOffset, logSeverityLevel, logVerbosityLevel,\n        optimizedModelFilePathOffset);\n    if (sessionOptionsHandle === 0) {\n      checkLastError('Can\\'t create session options.');\n    }\n\n    if (sessionOptions.executionProviders) {\n      setExecutionProviders(sessionOptionsHandle, sessionOptions.executionProviders, allocs);\n    }\n\n    if (sessionOptions.freeDimensionOverrides) {\n      for (const [name, value] of Object.entries(sessionOptions.freeDimensionOverrides)) {\n        if (typeof name !== 'string') {\n          throw new Error(`free dimension override name must be a string: ${name}`);\n        }\n        if (typeof value !== 'number' || !Number.isInteger(value) || value < 0) {\n          throw new Error(`free dimension override value must be a non-negative integer: ${value}`);\n        }\n        const nameOffset = allocWasmString(name, allocs);\n        if (wasm._OrtAddFreeDimensionOverride(sessionOptionsHandle, nameOffset, value) !== 0) {\n          checkLastError(`Can't set a free dimension override: ${name} - ${value}.`);\n        }\n      }\n    }\n\n    if (sessionOptions.extra !== undefined) {\n      iterateExtraOptions(sessionOptions.extra, '', new WeakSet<Record<string, unknown>>(), (key, value) => {\n        const keyDataOffset = allocWasmString(key, allocs);\n        const valueDataOffset = allocWasmString(value, allocs);\n\n        if (wasm._OrtAddSessionConfigEntry(sessionOptionsHandle, keyDataOffset, valueDataOffset) !== 0) {\n          checkLastError(`Can't set a session config entry: ${key} - ${value}.`);\n        }\n      });\n    }\n\n    return [sessionOptionsHandle, allocs];\n  } catch (e) {\n    if (sessionOptionsHandle !== 0) {\n      wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n    }\n    allocs.forEach(alloc => wasm._free(alloc));\n    throw e;\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\n// This file includes common definitions. They do NOT have dependency on the WebAssembly instance.\n\n/**\n * Copied from ONNX definition. Use this to drop dependency 'onnx_proto' to decrease compiled .js file size.\n */\nexport const enum DataType {\n  undefined = 0,\n  float = 1,\n  uint8 = 2,\n  int8 = 3,\n  uint16 = 4,\n  int16 = 5,\n  int32 = 6,\n  int64 = 7,\n  string = 8,\n  bool = 9,\n  float16 = 10,\n  double = 11,\n  uint32 = 12,\n  uint64 = 13,\n  complex64 = 14,\n  complex128 = 15,\n  bfloat16 = 16\n}\n\n/**\n * Map string tensor data to enum value\n */\nexport const tensorDataTypeStringToEnum = (type: string): DataType => {\n  switch (type) {\n    case 'int8':\n      return DataType.int8;\n    case 'uint8':\n      return DataType.uint8;\n    case 'bool':\n      return DataType.bool;\n    case 'int16':\n      return DataType.int16;\n    case 'uint16':\n      return DataType.uint16;\n    case 'int32':\n      return DataType.int32;\n    case 'uint32':\n      return DataType.uint32;\n    case 'float16':\n      return DataType.float16;\n    case 'float32':\n      return DataType.float;\n    case 'float64':\n      return DataType.double;\n    case 'string':\n      return DataType.string;\n    case 'int64':\n      return DataType.int64;\n    case 'uint64':\n      return DataType.uint64;\n\n    default:\n      throw new Error(`unsupported data type: ${type}`);\n  }\n};\n\n/**\n * Map enum value to string tensor data\n */\nexport const tensorDataTypeEnumToString = (typeProto: DataType): Tensor.Type => {\n  switch (typeProto) {\n    case DataType.int8:\n      return 'int8';\n    case DataType.uint8:\n      return 'uint8';\n    case DataType.bool:\n      return 'bool';\n    case DataType.int16:\n      return 'int16';\n    case DataType.uint16:\n      return 'uint16';\n    case DataType.int32:\n      return 'int32';\n    case DataType.uint32:\n      return 'uint32';\n    case DataType.float16:\n      return 'float16';\n    case DataType.float:\n      return 'float32';\n    case DataType.double:\n      return 'float64';\n    case DataType.string:\n      return 'string';\n    case DataType.int64:\n      return 'int64';\n    case DataType.uint64:\n      return 'uint64';\n\n    default:\n      throw new Error(`unsupported data type: ${typeProto}`);\n  }\n};\n\n/**\n * get tensor element size in bytes by the given data type\n * @returns size in integer or undefined if the data type is not supported\n */\nexport const getTensorElementSize = (dateType: number): number|\n    undefined => [undefined, 4, 1, 1, 2, 2, 4, 8, undefined, 1, 2, 8, 4, 8, undefined, undefined, undefined][dateType];\n\n/**\n * get typed array constructor by the given tensor type\n */\nexport const tensorTypeToTypedArrayConstructor = (type: Tensor.Type): Float32ArrayConstructor|Uint8ArrayConstructor|\n    Int8ArrayConstructor|Uint16ArrayConstructor|Int16ArrayConstructor|Int32ArrayConstructor|BigInt64ArrayConstructor|\n    Uint8ArrayConstructor|Float64ArrayConstructor|Uint32ArrayConstructor|BigUint64ArrayConstructor => {\n      switch (type) {\n        case 'float16':\n          return Uint16Array;\n        case 'float32':\n          return Float32Array;\n        case 'uint8':\n          return Uint8Array;\n        case 'int8':\n          return Int8Array;\n        case 'uint16':\n          return Uint16Array;\n        case 'int16':\n          return Int16Array;\n        case 'int32':\n          return Int32Array;\n        case 'bool':\n          return Uint8Array;\n        case 'float64':\n          return Float64Array;\n        case 'uint32':\n          return Uint32Array;\n        case 'int64':\n          return BigInt64Array;\n        case 'uint64':\n          return BigUint64Array;\n        default:\n          throw new Error(`unsupported type: ${type}`);\n      }\n    };\n\n/**\n * Map string log level to integer value\n */\nexport const logLevelStringToEnum = (logLevel?: 'verbose'|'info'|'warning'|'error'|'fatal'): number => {\n  switch (logLevel) {\n    case 'verbose':\n      return 0;\n    case 'info':\n      return 1;\n    case 'warning':\n      return 2;\n    case 'error':\n      return 3;\n    case 'fatal':\n      return 4;\n    default:\n      throw new Error(`unsupported logging level: ${logLevel}`);\n  }\n};\n\n/**\n * Check whether the given tensor type is supported by GPU buffer\n */\nexport const isGpuBufferSupportedType = (type: Tensor.Type): type is Tensor.GpuBufferDataTypes => type === 'float32' ||\n    type === 'int32' || type === 'int64' || type === 'bool' || type === 'float16' || type === 'uint32';\n\n/**\n * Map string data location to integer value\n */\nexport const dataLocationStringToEnum = (location: Tensor.DataLocation): number => {\n  switch (location) {\n    case 'none':\n      return 0;\n    case 'cpu':\n      return 1;\n    case 'cpu-pinned':\n      return 2;\n    case 'texture':\n      return 3;\n    case 'gpu-buffer':\n      return 4;\n    default:\n      throw new Error(`unsupported data location: ${location}`);\n  }\n};\n\n/**\n * Map integer data location to string value\n */\nexport const dataLocationEnumToString = (location: number): Tensor.DataLocation|undefined =>\n    (['none', 'cpu', 'cpu-pinned', 'texture', 'gpu-buffer'] as const)[location];\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {logLevelStringToEnum} from '../wasm-common';\n\ntype LogLevel = NonNullable<Env['logLevel']>;\ntype MessageString = string;\ntype MessageFunction = () => string;\ntype Message = MessageString|MessageFunction;\n\nconst logLevelPrefix = ['V', 'I', 'W', 'E', 'F'];\n\nconst doLog = (level: number, message: string): void => {\n  // eslint-disable-next-line no-console\n  console.log(`[${logLevelPrefix[level]},${new Date().toISOString()}]${message}`);\n};\n\nlet configLogLevel: LogLevel|undefined;\nlet debug: boolean|undefined;\n\nexport const configureLogger = ($configLogLevel: LogLevel, $debug: boolean): void => {\n  configLogLevel = $configLogLevel;\n  debug = $debug;\n};\n\n/**\n * A simple logging utility to log messages to the console.\n */\nexport const LOG = (logLevel: LogLevel, msg: Message): void => {\n  const messageLevel = logLevelStringToEnum(logLevel);\n  const configLevel = logLevelStringToEnum(configLogLevel);\n  if (messageLevel >= configLevel) {\n    doLog(messageLevel, typeof msg === 'function' ? msg() : msg);\n  }\n};\n\n/**\n * A simple logging utility to log messages to the console. Only logs when debug is enabled.\n */\nexport const LOG_DEBUG: typeof LOG = (...args: Parameters<typeof LOG>) => {\n  if (debug) {\n    LOG(...args);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Tensor} from 'onnxruntime-common';\n\nimport {tensorTypeToTypedArrayConstructor} from '../wasm-common';\n\nexport const createView = (dataBuffer: ArrayBuffer, type: Tensor.Type): Int32Array|Uint32Array|BigInt64Array|\n    BigUint64Array|Uint8Array|Float32Array|Float64Array|Int8Array|Int16Array|Uint16Array =>\n        new (tensorTypeToTypedArrayConstructor(type))(dataBuffer);\n\n/**\n * a TensorView does not own the data.\n */\nexport interface TensorView {\n  readonly data: number;\n  readonly dataType: number;\n  readonly dims: readonly number[];\n\n  /**\n   * get a Float32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getFloat32Array(): Float32Array;\n\n  /**\n   * get a BigInt64Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getBigInt64Array(): BigInt64Array;\n\n  /**\n   * get a Int32Array data view of the tensor data. tensor data must be on CPU.\n   */\n  getInt32Array(): Int32Array;\n\n  /**\n   * create a new tensor view with the same data but different dimensions.\n   */\n  reshape(newDims: readonly number[]): TensorView;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../tensor-view';\n\nimport {ShaderHelper} from './ops/common';\n\nexport enum GpuDataType {\n  default = 0,\n  upload = 1,\n  profile = 2\n}\nexport type GpuDataId = number;\n\nexport interface GpuData {\n  type: GpuDataType;\n  id: GpuDataId;\n  buffer: GPUBuffer;\n}\n\nexport interface TensorInfo {\n  dims: readonly number[];\n  dataType: number;\n}\n\n\nexport interface ProgramUniform {\n  type: 'int32'|'float32'|'uint32';\n  data: number|readonly number[];\n}\n\n/**\n * Represent the dependency of a program on a specific input tensor.\n *\n * - 'none': the shader/uniform does not depend on this input's info\n * - 'type': the shader/uniform depends on data type of this input\n * - 'rank': the shader/uniform depends on data type and the rank of this input\n * - 'dims': the shader/uniform depends on data type and the dims of this input\n * - 'data': the shader/uniform depends on data type, the dims and the data of this input\n */\nexport type ProgramInputTensorInfoDependency = 'none'|'type'|'rank'|'dims'|'data';\n\n/**\n * Represent information about a program's cache for shader.\n */\nexport interface ProgramShaderCacheInfo {\n  /**\n   * an optional string as a cache hint in the artifact cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains initializing-time information, such as the attributes or any information of\n   * initializers. It should NOT contain any runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'dims' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n/**\n * Represent information about a program's cache for uniform.\n */\nexport interface ProgramUniformCacheInfo {\n  /**\n   * an optional string as a cache hint in the uniform cache. If this is not specified, the cache hint will be empty.\n   *\n   * This hint string should only contains runtime information, such as the shape of inputs.\n   */\n  hint?: string;\n\n  /**\n   * an optional list of dependencies of the program on the input tensors. If this is not specified, the program depends\n   * on 'none' of all inputs.\n   */\n  inputDependencies?: ProgramInputTensorInfoDependency[];\n}\n\n\n/**\n * A set of data that represent a shader program\n */\nexport interface ProgramInfo {\n  /**\n   * the name of the program. used for debugging and profiling\n   */\n  name: string;\n\n  /**\n   * an optional object describing the cache information of the program shader.\n   *\n   * If this is not specified, assume hint is empty and inputDependencies are ['dims'] for all inputs.\n   */\n  shaderCache?: ProgramShaderCacheInfo;\n\n  /**\n   * the shader's processing source code.\n   *\n   * This function will be called when shader cache missed.\n   */\n  getShaderSource: (shaderHelper: ShaderHelper) => string;\n\n  /**\n   * A function to get run data required to run the program.\n   *\n   * This function will be called every time the program is executed. Should keep this function as simple as possible.\n   */\n  getRunData: (inputs: readonly TensorView[]) => {\n    outputs: readonly TensorInfo[];\n    dispatchGroup: {x: number; y?: number; z?: number};\n    programUniforms?: readonly ProgramUniform[];\n  };\n}\n\nexport interface Artifact {\n  programInfo: ProgramInfo;\n  computePipeline: GPUComputePipeline;\n}\n\nexport interface ComputeContextInputsOutputsMapping {\n  /**\n   * specify the mapping to the program's inputs. the value can be a number or a tensor view.\n   * - if it's a number, it's the index of the kernel's input\n   * - if it's a tensor view, it's an existing tensor view that will be used as the input\n   *\n   * if inputs is not specified, the mapping will be the kernel's inputs in order.\n   */\n  readonly inputs?: ReadonlyArray<TensorView|number>;\n  /**\n   * specify the mapping to the program's outputs. the value must be a number.\n   * - if it's a non-negative number, it's the index of the kernel's output\n   * - if it's -1, it's an output that will be created as a temporary value. this value will be released after\n   * the kernel is executed.\n   * - if it's -2, it's an output that will be created as a persistent value. this value will be released when the\n   * kernel is released.\n   *\n   * if outputs is not specified, the mapping will be the kernel's outputs in order.\n   */\n  readonly outputs?: readonly number[];\n}\n\n/**\n * A ComputeContext instance carries the states that representing the current running of a kernel.\n */\nexport interface ComputeContext {\n  /**\n   * stores the pointer to OpKernelContext\n   */\n  readonly opKernelContext: number;\n\n  /**\n   * a list of inputs, each input is an instance of TensorView\n   */\n  readonly inputs: readonly TensorView[];\n\n  /**\n   * a custom data object that can be used to store any data that is needed by the kernel\n   */\n  readonly kernelCustomData: {[key: string]: unknown};\n\n  /**\n   * a buffer that can be used to access custom data created each time the kernel is executed\n   */\n  readonly customDataBuffer: Uint8Array;\n\n  /**\n   * a number of outputs for the node\n   */\n  readonly outputCount: number;\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[];\n  output(index: number, dims: readonly number[]): number;\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\n\nimport {GpuData, GpuDataId, GpuDataType} from './types';\n\n/**\n * manages GpuDataId -> GpuBuffer\n */\nexport interface GpuDataManager {\n  /**\n   * copy data from CPU to GPU.\n   */\n  upload(id: GpuDataId, data: Uint8Array): void;\n  /**\n   * copy data from GPU to GPU.\n   */\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void;\n  /**\n   * create new data on GPU.\n   */\n  create(size: number, usage?: number): GpuData;\n  /**\n   * get GPU data by ID.\n   */\n  get(id: GpuDataId): GpuData|undefined;\n  /**\n   * release the data on GPU by ID.\n   *\n   * @return size of the data released\n   */\n  release(id: GpuDataId): number;\n  /**\n   * copy data from GPU to CPU.\n   */\n  download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void>;\n\n  /**\n   * refresh the buffers that marked for release.\n   *\n   * when release() is called, the buffer is not released immediately. this is because we need to wait for the commands\n   * to be submitted to the GPU. this function is called after the commands are submitted so that the buffers can be\n   * actually released.\n   */\n  refreshPendingBuffers(): void;\n\n  /**\n   * register an external buffer for IO Binding. If the buffer is already registered, return the existing GPU data ID.\n   *\n   * GPU data manager only manages a mapping between the buffer and the GPU data ID. It will not manage the lifecycle of\n   * the external buffer.\n   */\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number;\n\n  /**\n   * unregister an external buffer for IO Binding.\n   */\n  unregisterExternalBuffer(buffer: GPUBuffer): void;\n\n  /**\n   * destroy all gpu buffers. Call this when the session.release is called.\n   */\n  dispose(): void;\n}\n\ninterface StorageCacheValue {\n  gpuData: GpuData;\n  originalSize: number;\n}\n\n/**\n * normalize the buffer size so that it fits the 128-bits (16 bytes) alignment.\n */\nconst calcNormalizedBufferSize = (size: number) => Math.ceil(size / 16) * 16;\n\nlet guid = 1;\nconst createNewGpuDataId = () => guid++;\n\n/**\n * exported standard download function. This function is used by the session to download the data from GPU, and also by\n * factory to create GPU tensors with the capacity of downloading data from GPU.\n *\n * @param backend - the WebGPU backend\n * @param gpuBuffer - the GPU buffer to download\n * @param originalSize - the original size of the data\n * @param getTargetBuffer - optional. If provided, the data will be copied to the target buffer. Otherwise, a new buffer\n * will be created and returned.\n */\nexport const downloadGpuData =\n    async(backend: WebGpuBackend, gpuBuffer: GPUBuffer, originalSize: number, getTargetBuffer?: () => Uint8Array):\n        Promise<Uint8Array> => {\n          const bufferSize = calcNormalizedBufferSize(originalSize);\n          const gpuReadBuffer = backend.device.createBuffer(\n              // eslint-disable-next-line no-bitwise\n              {size: bufferSize, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ});\n          try {\n            const commandEncoder = backend.getCommandEncoder();\n            backend.endComputePass();\n            commandEncoder.copyBufferToBuffer(\n                gpuBuffer /* source buffer */, 0 /* source offset */, gpuReadBuffer /* destination buffer */,\n                0 /* destination offset */, bufferSize /* size */\n            );\n            backend.flush();\n\n            await gpuReadBuffer.mapAsync(GPUMapMode.READ);\n\n            const arrayBuffer = gpuReadBuffer.getMappedRange();\n            if (getTargetBuffer) {\n              // if we already have a CPU buffer to accept the data, no need to clone the ArrayBuffer.\n              const targetBuffer = getTargetBuffer();\n              targetBuffer.set(new Uint8Array(arrayBuffer, 0, originalSize));\n              return targetBuffer;\n            } else {\n              // the mapped ArrayBuffer will be released when the GPU buffer is destroyed. Need to clone the\n              // ArrayBuffer.\n              return new Uint8Array(arrayBuffer.slice(0, originalSize));\n            }\n          } finally {\n            gpuReadBuffer.destroy();\n          }\n        };\n\nclass GpuDataManagerImpl implements GpuDataManager {\n  // GPU Data ID => GPU Data ( storage buffer )\n  private storageCache: Map<GpuDataId, StorageCacheValue>;\n\n  // pending buffers for uploading ( data is unmapped )\n  private buffersForUploadingPending: GPUBuffer[];\n  // pending buffers for computing\n  private buffersPending: GPUBuffer[];\n\n  // The reusable storage buffers for computing.\n  private freeBuffers: Map<number, GPUBuffer[]>;\n  // The reusable uniform buffers\n  private freeUniformBuffers: Map<number, GPUBuffer[]>;\n\n  // The external buffers registered users for IO Binding.\n  private externalBuffers: Map<GPUBuffer, GpuDataId>;\n\n  constructor(private backend: WebGpuBackend) {\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n    this.buffersForUploadingPending = [];\n    this.buffersPending = [];\n    this.externalBuffers = new Map();\n  }\n\n  upload(id: GpuDataId, data: Uint8Array): void {\n    const srcArrayBuffer = data.buffer;\n    const srcOffset = data.byteOffset;\n    const srcLength = data.byteLength;\n    const size = calcNormalizedBufferSize(srcLength);\n\n    // get destination gpu buffer\n    const gpuDataCache = this.storageCache.get(id);\n    if (!gpuDataCache) {\n      throw new Error('gpu data for uploading does not exist');\n    }\n    if (gpuDataCache.originalSize !== srcLength) {\n      throw new Error(`inconsistent data size. gpu data size=${gpuDataCache.originalSize}, data size=${srcLength}`);\n    }\n\n    // create gpu buffer\n    const gpuBufferForUploading = this.backend.device.createBuffer(\n        // eslint-disable-next-line no-bitwise\n        {mappedAtCreation: true, size, usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC});\n\n    // copy (upload) data\n    const arrayBuffer = gpuBufferForUploading.getMappedRange();\n    new Uint8Array(arrayBuffer).set(new Uint8Array(srcArrayBuffer, srcOffset, srcLength));\n    gpuBufferForUploading.unmap();\n\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(gpuBufferForUploading, 0, gpuDataCache.gpuData.buffer, 0, size);\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.upload(id=${id})`);\n\n    this.buffersForUploadingPending.push(gpuBufferForUploading);\n  }\n\n  memcpy(sourceId: GpuDataId, destinationId: GpuDataId): void {\n    // get source gpu buffer\n    const sourceGpuDataCache = this.storageCache.get(sourceId);\n    if (!sourceGpuDataCache) {\n      throw new Error('source gpu data for memcpy does not exist');\n    }\n    // get destination gpu buffer\n    const destinationGpuDataCache = this.storageCache.get(destinationId);\n    if (!destinationGpuDataCache) {\n      throw new Error('destination gpu data for memcpy does not exist');\n    }\n    if (sourceGpuDataCache.originalSize !== destinationGpuDataCache.originalSize) {\n      throw new Error('inconsistent source and destination gpu data size');\n    }\n    const size = calcNormalizedBufferSize(sourceGpuDataCache.originalSize);\n\n    // GPU copy\n    const commandEncoder = this.backend.getCommandEncoder();\n    this.backend.endComputePass();\n    commandEncoder.copyBufferToBuffer(\n        sourceGpuDataCache.gpuData.buffer, 0, destinationGpuDataCache.gpuData.buffer, 0, size);\n  }\n\n  registerExternalBuffer(buffer: GPUBuffer, originalSize: number, previousBuffer?: GPUBuffer): number {\n    let id: number|undefined;\n    if (previousBuffer) {\n      id = this.externalBuffers.get(previousBuffer);\n      if (id === undefined) {\n        throw new Error('previous buffer is not registered');\n      }\n      if (buffer === previousBuffer) {\n        LOG_DEBUG(\n            'verbose',\n            () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${\n                id}, buffer is the same, skip.`);\n        return id;\n      }\n      this.externalBuffers.delete(previousBuffer);\n    } else {\n      id = createNewGpuDataId();\n    }\n\n    this.storageCache.set(id, {gpuData: {id, type: GpuDataType.default, buffer}, originalSize});\n    this.externalBuffers.set(buffer, id);\n    LOG_DEBUG(\n        'verbose',\n        () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${originalSize}) => id=${id}, registered.`);\n    return id;\n  }\n\n  unregisterExternalBuffer(buffer: GPUBuffer): void {\n    const id = this.externalBuffers.get(buffer);\n    if (id !== undefined) {\n      this.storageCache.delete(id);\n      this.externalBuffers.delete(buffer);\n      LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${id}`);\n    }\n  }\n\n  // eslint-disable-next-line no-bitwise\n  create(size: number, usage = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST): GpuData {\n    const bufferSize = calcNormalizedBufferSize(size);\n\n    let gpuBuffer;\n    // Currently, only storage buffers are reused.\n    // eslint-disable-next-line no-bitwise\n    const isStorage = (usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE;\n    // eslint-disable-next-line no-bitwise\n    const isUniform = (usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM;\n    if (isStorage || isUniform) {\n      const freeBuffers = isStorage ? this.freeBuffers : this.freeUniformBuffers;\n      let buffers = freeBuffers.get(bufferSize);\n      if (!buffers) {\n        buffers = [];\n        freeBuffers.set(bufferSize, buffers);\n      }\n      if (buffers.length > 0) {\n        gpuBuffer = buffers.pop() as GPUBuffer;\n      } else {\n        // create gpu buffer\n        gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n      }\n    } else {\n      // create gpu buffer\n      gpuBuffer = this.backend.device.createBuffer({size: bufferSize, usage});\n    }\n\n    const gpuData = {id: createNewGpuDataId(), type: GpuDataType.default, buffer: gpuBuffer};\n    this.storageCache.set(gpuData.id, {gpuData, originalSize: size});\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.create(size=${size}) => id=${gpuData.id}`);\n    return gpuData;\n  }\n\n  get(id: GpuDataId): GpuData|undefined {\n    return this.storageCache.get(id)?.gpuData;\n  }\n\n  release(id: GpuDataId): number {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('releasing data does not exist');\n    }\n\n    LOG_DEBUG('verbose', () => `[WebGPU] GpuDataManager.release(id=${id}), gpuDataId=${cachedData.gpuData.id}`);\n\n    this.storageCache.delete(id);\n    this.buffersPending.push(cachedData.gpuData.buffer);\n    // cachedData.gpuData.buffer.destroy();\n\n    return cachedData.originalSize;\n  }\n\n  async download(id: GpuDataId, getTargetBuffer: () => Uint8Array): Promise<void> {\n    const cachedData = this.storageCache.get(id);\n    if (!cachedData) {\n      throw new Error('data does not exist');\n    }\n\n    await downloadGpuData(this.backend, cachedData.gpuData.buffer, cachedData.originalSize, getTargetBuffer);\n  }\n\n  refreshPendingBuffers(): void {\n    for (const buffer of this.buffersForUploadingPending) {\n      // upload buffer is only useful in the session creation time. So we don't need to reuse them in session running.\n      buffer.destroy();\n    }\n    this.buffersForUploadingPending = [];\n    for (const buffer of this.buffersPending) {\n      // eslint-disable-next-line no-bitwise\n      if ((buffer.usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE) {\n        // Put the pending buffer to freeBuffers list instead of really destroying it for buffer reusing.\n        this.freeBuffers.get(buffer.size)!.push(buffer);\n        // eslint-disable-next-line no-bitwise\n      } else if ((buffer.usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM) {\n        // Put the pending buffer to freeUniformBuffers list instead of really destroying it for buffer reusing.\n        this.freeUniformBuffers.get(buffer.size)!.push(buffer);\n      } else {\n        buffer.destroy();\n      }\n    }\n    this.buffersPending = [];\n  }\n\n  dispose() {\n    this.freeBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n    this.freeUniformBuffers.forEach((buffers) => {\n      buffers.forEach(buffer => {\n        buffer.destroy();\n      });\n    });\n\n    this.storageCache.forEach((storage) => {\n      storage.gpuData.buffer.destroy();\n    });\n\n    this.storageCache = new Map();\n    this.freeBuffers = new Map();\n    this.freeUniformBuffers = new Map();\n  }\n}\n\nexport const createGpuDataManager = (...args: ConstructorParameters<typeof GpuDataManagerImpl>): GpuDataManager =>\n    new GpuDataManagerImpl(...args);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nclass AttributeWithCacheKeyImpl {\n  constructor(attribute: Record<string, unknown>) {\n    Object.assign(this, attribute);\n  }\n\n  private _cacheKey: string;\n  public get cacheKey(): string {\n    if (!this._cacheKey) {\n      this._cacheKey =\n          Object.getOwnPropertyNames(this).sort().map(name => `${(this as Record<string, unknown>)[name]}`).join(';');\n    }\n    return this._cacheKey;\n  }\n}\n\nexport interface AttributeWithCacheKey {\n  readonly cacheKey: string;\n}\n\n/**\n * create a new object from the given attribute, and add a cacheKey property to it\n */\nexport const createAttributeWithCacheKey = <T extends Record<string, unknown>>(attribute: T): T&AttributeWithCacheKey =>\n    new AttributeWithCacheKeyImpl(attribute) as unknown as T & AttributeWithCacheKey;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable no-param-reassign */\n\nexport class MatMulUtil {\n  /**\n   * Calculate the expected shape when matrix multiplication\n   * @param a The shape of tensor A. Should be a tuple of 2 positive integers\n   * @param b The shape of tensor B. Should be a tuple of 2 positive integers\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcMatMulShape(a: [number, number], b: [number, number]): [number, number]|undefined {\n    return (a[1] !== b[0]) ? undefined : [a[0], b[1]];\n  }\n}\n\n\nexport class BroadcastUtil {\n  /**\n   * Calculate the expected shape when broadcasting 2 tensors\n   * @param a The shape of tensor A. Should be an array of positive integers\n   * @param b The shape of tensor B. Should be an array of positive integers\n   * @param isMatMul Whether the operation is MatMul\n   * @returns The expected shape of the result, or undefined if N/A\n   */\n  static calcShape(adims: readonly number[], bdims: readonly number[], isMatMul = false): readonly number[]|undefined {\n    const arank = adims.length;\n    const brank = bdims.length;\n    if (arank === 0) {\n      return bdims;\n    }\n    if (brank === 0) {\n      return adims;\n    }\n    const crank = Math.max(adims.length, bdims.length);\n    const cdims = new Array<number>(crank);\n\n    // calculate the last 2 dimension if it is MatMul\n    if (isMatMul) {\n      if (arank < 2 || brank < 2) {\n        return undefined;\n      }\n      const cShapeMatMul =\n          MatMulUtil.calcMatMulShape([adims[arank - 2], adims[arank - 1]], [bdims[brank - 2], bdims[brank - 1]]);\n      if (cShapeMatMul === undefined) {\n        return undefined;\n      }\n      [cdims[crank - 2], cdims[crank - 1]] = cShapeMatMul;\n    }\n\n    for (let i = isMatMul ? 3 : 1; i <= crank; i++) {\n      const aLen = arank - i < 0 ? 1 : adims[arank - i];\n      const bLen = brank - i < 0 ? 1 : bdims[brank - i];\n\n      if (aLen !== bLen && aLen > 1 && bLen > 1) {\n        return undefined;\n      }\n      cdims[crank - i] = Math.max(aLen, bLen);\n    }\n\n    return cdims;\n  }\n\n  /**\n   * Determine if a shape is unidirectional broadcastable to another shape\n   * @param shape The input shape\n   * @param finalShape The desired shape after broadcasting\n   */\n  static isValidBroadcast(shape: readonly number[], finalShape: readonly number[]): boolean {\n    // align shape to the right\n    const inputRank = shape.length;\n    const finalRank = finalShape.length;\n    if (inputRank > finalRank) {\n      return false;\n    }\n    for (let i = 1; i <= inputRank; i++) {\n      if (shape[inputRank - i] !== 1 && shape[inputRank - i] !== finalShape[finalRank - i]) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n\n\nexport class ShapeUtil {\n  /**\n   * calculate the size (number of elements)\n   */\n  static size(dims: readonly number[]): number {\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) from the given axis (inclusive)\n   */\n  static sizeFromDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeFromDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, axis, dims.length);\n  }\n\n  /**\n   * calculate the size (number of elements) to the given axis (exclusive)\n   */\n  static sizeToDimension(dims: readonly number[], axis: number): number {\n    if (axis < 0 || axis > dims.length) {\n      throw new Error(`invalid dimension of ${axis} for sizeToDimension as Tensor has ${dims.length} dimensions.`);\n    }\n    return ShapeUtil.getSizeFromDimensionRange(dims, 0, axis);\n  }\n\n  /**\n   * calculate the size (number of elements) from and to the given axis [start, end)\n   */\n  static getSizeFromDimensionRange(dims: readonly number[], start: number, end: number): number {\n    let size = 1;\n    for (let i = start; i < end; i++) {\n      // safety check as this method is called by multiple other methods requiring size.\n      // size cannot be negative.\n      if (dims[i] < 0) {\n        throw new Error(\n            // eslint-disable-next-line max-len\n            'cannot get valid size from specified dimension range. Most likely the range contains negative values in them.');\n      }\n      size *= dims[i];\n    }\n    return size;\n  }\n\n  static computeStrides(dims: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    if (rank === 0) {\n      return [];\n    } else if (rank === 1) {\n      return [1];\n    }\n    const strides = new Array(rank);\n    strides[rank - 1] = 1;\n    strides[rank - 2] = dims[rank - 1];\n    for (let i = rank - 3; i >= 0; --i) {\n      strides[i] = strides[i + 1] * dims[i + 1];\n    }\n    return strides;\n  }\n\n  /**\n   * normailze axis of range [-r, r) into [0, r).\n   */\n  static normalizeAxis(axis: number, tensorRank: number): number {\n    if (axis < -tensorRank && axis >= tensorRank) {\n      throw new Error('unsupported axis for this operation.');\n    }\n    return axis < 0 ? axis + tensorRank : axis;\n  }\n\n  static normalizeAxes(axes: readonly number[], tensorRank?: number): number[] {\n    return axes.map(x => this.normalizeAxis(x, tensorRank ?? axes.length));\n  }\n\n  /**\n   * Sorts a given array based on the indices in the Perm array\n   * Used in Transpose\n   * @param a Array to be sorted such as dims or strides\n   * @param perm Perm given; if null a will be reversed\n   */\n  static sortBasedOnPerm(a: readonly number[], perm?: readonly number[]): readonly number[] {\n    if (perm) {\n      return perm.map((v) => a[v]);\n    } else {\n      return a.slice().reverse();\n    }\n  }\n\n  /**\n   * Pads a given shape according to the padding values\n   * @param dims shape of the Tensor to be padded\n   * @param pad pad values\n   */\n  static padShape(dims: readonly number[], pad: readonly number[]): readonly number[] {\n    const rank = dims.length;\n    return dims.map((v, i) => v + pad[i] + pad[i + rank]);\n  }\n\n  /**\n   * Determines if the two shapes are identical\n   * @param shape1\n   * @param shape2\n   */\n  static areEqual(shape1: readonly number[], shape2: readonly number[]): boolean {\n    if (shape1.length !== shape2.length) {\n      return false;\n    }\n    return shape1.every((v, i) => v === shape2[i]);\n  }\n}\n\nexport class PoolConvUtil {\n  /**\n   * Adjust the kernel, strides, pads to correct rank. Set to default value if not present\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   */\n  static adjustPoolAttributes(\n      isGlobalOperator: boolean, inputDims: readonly number[], kernelShape: number[], strides: number[],\n      dilations: number[], pads: number[]): void {\n    if (!isGlobalOperator && kernelShape.length !== inputDims.length - 2) {\n      throw new Error('length of specified kernel shapes should be 2 less than length of input dimensions');\n    }\n\n    if (isGlobalOperator) {\n      // adjust kernel shape to cover the input dims\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        if (dim >= kernelShape.length) {\n          kernelShape.push(inputDims[dim + 2]);\n        } else {\n          kernelShape[dim] = inputDims[dim + 2];\n        }\n      }\n    }\n\n    // adjust strides length to match kernel shape length\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < strides.length) {\n        if (strides[dim] < 0) {\n          throw new Error('strides should be greater than or equal to 1');\n        }\n      } else {\n        strides.push(1);\n      }\n    }\n\n    // adjust dilation value\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (dim < dilations.length) {\n        if (dilations[dim] < 0) {\n          throw new Error('dilations should be greater than or equal to 1');\n        }\n      } else {\n        dilations.push(1);\n      }\n    }\n\n    // adjust pads length to match 2 * kernel shape length\n    for (let dim = 0; dim < kernelShape.length * 2; dim++) {\n      if (dim < pads.length) {\n        if (pads[dim] < 0) {\n          throw new Error('pad should be greater than or equal to 1');\n        }\n      } else {\n        pads.push(0);\n      }\n    }\n\n    // sanity checks for values in kernel shapes and pads\n    for (let dim = 0; dim < kernelShape.length; dim++) {\n      if (kernelShape[dim] <= 0) {\n        throw new Error('kernel shapes need to be greater than 0');\n      }\n\n      if (pads[dim] >= kernelShape[dim] || pads[dim + kernelShape.length] >= kernelShape[dim]) {\n        throw new Error('pads should be smaller than kernel');\n      }\n    }\n  }\n\n  // adjust pad values based on 'autoPad' attribute\n  static adjustPadsBasedOnAutoPad(\n      inputDims: readonly number[], strides: readonly number[], dilations: readonly number[],\n      kernelShape: readonly number[], pads: number[], isChannelLast: boolean, autoPad?: string): void {\n    if (!autoPad) {\n      return;\n    }\n\n    if (pads.length !== 2 * (inputDims.length - 2)) {\n      throw new Error('length of pads should be twice the length of data dimensions');\n    }\n\n    if (strides.length !== (inputDims.length - 2)) {\n      throw new Error('length of strides should be the length of data dimensions');\n    }\n\n    if (kernelShape.length !== (inputDims.length - 2)) {\n      throw new Error('length of kernel shapes should be the length of data dimensions');\n    }\n\n    for (let dim = 0; dim < inputDims.length - 2; dim++) {\n      PoolConvUtil.adjustPadAndReturnShape(\n          inputDims[dim + (isChannelLast ? 1 : 2)], strides[dim], dilations[dim], kernelShape[dim], pads, dim,\n          dim + inputDims.length - 2, autoPad);\n    }\n  }\n\n  /**\n   * Calculate the output shape for Pool ops based on input attributes. (Should be used only for Pool ops)\n   * @param isGlobalOperator If true, perform global pooling.\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param strides Stride along each axis.\n   * @param dilations Dilation along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computePoolOutputShape(\n      isGlobalOperator: boolean, inputDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0) {\n      throw new Error('input shape must be of size greater than 0');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], inputDims[1]];\n\n    PoolConvUtil.computeShapeHelper(\n        isGlobalOperator, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  /**\n   * Calculate the output shape for Conv op based on input attributes. (Should be used only for Conv op)\n   * @param inputDims The input tensor dimension. (inputs[0].dims)\n   * @param filterDims The filter tensor dimension. (inputs[1].dims)\n   * @param strides Stride along each axis.\n   * @param kernelShape The size of the kernel along each axis.\n   * @param pads Padding for the beginning and ending along each axis.\n   * @param autoPad DEPRECATED attribute supported for legacy models. Specifies how to implicitly calculate pads in each\n   *     dimension. Can take values NOTSET, SAME_UPPER, SAME_LOWER, or VALID.\n   */\n  static computeConvOutputShape(\n      inputDims: readonly number[], filterDims: readonly number[], strides: number[], dilations: number[],\n      kernelShape: number[], pads: number[], autoPad?: string): number[] {\n    if (inputDims.length <= 0 || filterDims.length <= 0) {\n      throw new Error('invalid input tensor dims or invalid filter tensor dims');\n    }\n\n    // Add batch size and number of channels of output\n    const outputDims = [inputDims[0], filterDims[0]];\n\n    PoolConvUtil.computeShapeHelper(false, inputDims, outputDims, strides, dilations, kernelShape, pads, autoPad);\n    return outputDims;\n  }\n\n  // will compute output shapes for data dimensions ONLY (i.e.) no batch size and channels\n  // called by computePoolOutputShape() and computeConvOutputShape()\n  // adjust pads based on 'autoPad' attribute prior to shape computation\n  private static computeShapeHelper(\n      isGlobalOperator: boolean, inputDims: readonly number[], outputDims: number[], strides: readonly number[],\n      dilations: readonly number[], kernelShape: readonly number[], pads: number[], autoPad?: string) {\n    if (isGlobalOperator) {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(1);\n      }\n    } else {\n      for (let dim = 0; dim < inputDims.length - 2; dim++) {\n        outputDims.push(PoolConvUtil.adjustPadAndReturnShape(\n            inputDims[dim + 2], strides[dim], dilations[dim], kernelShape[dim], pads, dim, dim + inputDims.length - 2,\n            autoPad));\n      }\n    }\n  }\n\n  // helper for computeShapeHelper() and adjustPadsBasedOnAutoPad()\n  // adjusts pad value for given 'autoPad' string and computes output shape along a particular dimension\n  private static adjustPadAndReturnShape(\n      inSize: number, stride: number, dilation: number, kernel: number, pads: number[], padHeadIndex: number,\n      padTailIndex: number, autoPad?: string): number {\n    const dkernel = dilation * (kernel - 1) + 1;\n    if (autoPad && autoPad !== 'NOTSET') {\n      switch (autoPad) {\n        case 'VALID':\n          pads[padHeadIndex] = 0;\n          pads[padTailIndex] = 0;\n          return Math.floor(((inSize - dkernel) / stride) + 1);\n        case 'SAME_LOWER':\n        case 'SAME_UPPER':\n          if (dilation !== 1) {\n            throw new Error('Dilation not supported for SAME_UPPER or SAME_LOWER');\n          } else {\n            const legacyTargetSize = (inSize + stride - 1) / stride;\n            const padNeeded = (legacyTargetSize - 1) * stride + kernel - inSize;\n            pads[padHeadIndex] =\n                (autoPad === 'SAME_LOWER') ? Math.floor((padNeeded + 1) / 2) : Math.floor(padNeeded / 2);\n            pads[padTailIndex] = padNeeded - pads[padHeadIndex];\n            return Math.floor(((inSize + padNeeded - kernel) / stride) + 1);\n          }\n        default:\n          throw new Error('Unsupported AutoPad type');\n      }\n    } else {\n      return Math.floor(((inSize + pads[padHeadIndex] + pads[padTailIndex] - dkernel) / stride) + 1);\n    }\n  }\n}\n\nexport class GemmUtil {\n  // will make sure input shapes are compatible for this op\n  // and return back the shape of the output in the form of a tuple\n  // will throw exception if the input shapes are not compatible\n  static getShapeOfGemmResult(\n      leftShape: readonly number[], transLeft: boolean, rightShape: readonly number[], transRight: boolean,\n      biasShape?: readonly number[]): readonly number[] {\n    if (leftShape.length !== 2 || rightShape.length !== 2) {\n      throw new Error('shape need to be of size 2');\n    }\n\n    let M: number;\n    let K: number;\n    let N: number;\n\n    if (transLeft) {\n      M = leftShape[1];\n      K = leftShape[0];\n    } else {\n      M = leftShape[0];\n      K = leftShape[1];\n    }\n\n    let kDim = -1;\n\n    if (transRight) {\n      N = rightShape[0];\n      kDim = 1;\n    } else {\n      N = rightShape[1];\n      kDim = 0;\n    }\n\n    if (rightShape[kDim] !== K) {\n      throw new Error('dimension mismatch');\n    }\n\n    if (M <= 0 || N <= 0 || K <= 0) {\n      throw new Error('invalid shape specified');\n    }\n\n    if (biasShape && !BroadcastUtil.isValidBroadcast(biasShape, [M, N])) {\n      throw new Error('gemm: invalid bias shape for broadcast');\n    }\n\n    return [M, N, K];\n  }\n}\n\n\nexport const MIN_CLIP = -3.4028234663852886e+38;\nexport const MAX_CLIP = 3.4028234663852886e+38;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {ShapeUtil} from '../../util';\nimport {ProgramUniform} from '../types';\n\n/**\n * constant value for a workgroup size.\n *\n * We definitely can do further optimization in future, but for now we use 64.\n *\n * rule of thumb: Use [a workgroup size of] 64 unless you know what GPU you are targeting or that your workload\n *                needs something different.\n *\n * from: https://surma.dev/things/webgpu/\n **/\nexport const WORKGROUP_SIZE = 64;\n\ninterface IndicesHelperTypes {\n  /**\n   * WGSL type of indices expression\n   */\n  readonly indices: string;\n\n  /**\n   * WGSL type of a value\n   */\n  readonly value: string;\n\n  /**\n   * WGSL type of storage type representing a value\n   *\n   * This is usually the same to `value`, but for some type (eg. bool), we need to use `u32` as storage type for\n   * value type `vec4<bool>`\n   */\n  readonly storage: string;\n\n  /**\n   * tensor type as represented in TensorView\n   */\n  readonly tensor: number;\n}\n\n/**\n * A helper class for generating WGSL code for manipulating indices and data for a shader's input or output.\n *\n * This class is designed to offer a unified way to generate WGSL code for manipulating indices and data for a shader's\n * input or output.\n *\n * The following is a list of terminologies used in this class:\n * - `offset`: a uint32 value representing the offset of an element in the data buffer.\n * - `indices`: an abstraction of a multi-dimensional array's indices representing the data's index on each dimension.\n * - `value`: a value of a data element.\n *\n * Users are expected to create an instance of this class for each shader's input or output, and use the instance to\n * generate WGSL code for manipulating indices and data. The following 2 exported functions are for users to call to\n * create an instance of an indices helper:\n * - `inputVariable()`: create an indices helper instance for an input.\n * - `outputVariable()`: create an indices helper instance for an output.\n *\n * An indices helper instance contains helper functions for the following operations:\n * - access readonly basic information, including: `name`(the name of the input or output), `usage`(whether it's an\n * input or an output) and `shape`(the passed in shape).\n * - `type`: access readonly type information, including: `indices`(the type of indices), `value`(the type of value at\n * runtime), `storage`(the type of value at storage) and `tensor`(the tensor type as represented in TensorView).\n * - generate WGSL code for getting indices from offset. Use `offsetToIndices()` for WGSL code snippet to calculate\n * indices from offset, and use `indicesToOffset()` for WGSL code snippet to calculate offset from indices.\n * - to manipulate an instance of indices, use `setIndices()` and `getIndices()` to set and get the indices on an\n * indices variable.\n * - to manipulate data, use `set()`/`get()` to access data at the given indices from parameter list, use\n * `setByIndices()`/`getByIndices()` to access data at the given indices from an indices variable, and use\n * `setByOffset()`/`getByOffset()` to access data at the given offset.\n * - `impl`: get WGSL code of function implementation for the util functions mentioned above.\n */\nexport interface IndicesHelper {\n  /**\n   * get WGSL code of function implementation for the util functions.\n   *\n   */\n  readonly impl: () => string;\n\n  /**\n   * get type info\n   */\n  readonly type: IndicesHelperTypes;\n\n  /**\n   * WGSL code of a expression for getting indices from offset.\n   *\n   * @param varOffset - a u32 expression representing the offset.\n   *\n   * @returns an `type.indices` expression\n   */\n  readonly offsetToIndices: (varOffset: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting offset from indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the indices.\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesToOffset: (varIndices: string) => string;\n\n  /**\n   * WGSL code of an `u32` expression for getting original offset from broadcasted indices.\n   *\n   * @param varIndices - a `type.indices` expression representing the output indices.\n   * @param output - output IndicesHelper.\n   *\n   * @returns an `u32` expression\n   */\n  readonly broadcastedIndicesToOffset: (varIndices: string, output: IndicesHelper) => string;\n\n  /**\n   * WGSL code of generating an indices literal\n   *\n   * @param init - initial value.\n   */\n  readonly indices: (...init: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code of a statement for setting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to set. can be a number or a string (WGSL `u32` expression).\n   * @param value - the value to set. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns a WGSL statement\n   */\n  readonly indicesSet: (varIndices: string, idx: number|string, value: number|string) => void;\n\n  /**\n   * WGSL code of an `u32` expression for getting indices.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param idx - the index of the indices to get. can be a number or a string (WGSL `u32` expression).\n   *\n   * @returns an `u32` expression\n   */\n  readonly indicesGet: (varIndices: string, idx: number|string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices.\n   *\n   * @param indicesAndValue - an array of numbers or strings (WGSL `u32` expression) representing the indices, followed\n   *     by the value to set. This array should have exactly `shape.length + 1` elements.\n   */\n  readonly set: (...indicesAndValue: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByIndices: (varIndices: string, value: string) => string;\n\n  /**\n   * WGSL code for a statement for setting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   * @param value - the value to set. should be a WGSL expression.\n   */\n  readonly setByOffset: (offset: number|string, value: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices.\n   *\n   * @param indices - an array of numbers or strings (WGSL `u32` expression) representing the indices.\n   */\n  readonly get: (...indices: ReadonlyArray<number|string>) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given indices variable.\n   *\n   * @param varIndices - a variable name for the indices.\n   */\n  readonly getByIndices: (varIndices: string) => string;\n\n  /**\n   * WGSL code for an expression for getting data at the given offset.\n   *\n   * @param offset - a number or a string (WGSL `u32` expression) representing the offset.\n   */\n  readonly getByOffset: (offset: number|string) => string;\n\n  /**\n   * name of the data variable\n   */\n  readonly name: string;\n\n  /**\n   * whether the helper is for an input or an output.\n   */\n  readonly usage: 'input'|'output';\n\n  /**\n   * the rank of the input or output.\n   */\n  readonly rank: number;\n\n  /**\n   * a string representing the variable name for the shape of the input or output.\n   */\n  readonly shape: string;\n\n  /**\n   * a string representing the variable name for the strides of the input or output.\n   */\n  readonly strides: string;\n}\n\nconst getWgslMappedType = (type: number, components: 1|2|3|4): string|[string, string] => {\n  if (components === 3) {\n    throw new Error('vec3 has same alignment as vec4, use vec4 instead');\n  }\n\n  // return type is [ storage type, runtime type ] or a single string for both\n  switch (type) {\n    case DataType.float16:\n      return components > 1 ? `vec${components}<f16>` : 'f16';\n    case DataType.float:\n      return components > 1 ? `vec${components}<f32>` : 'f32';\n    case DataType.int32:\n      return components > 1 ? `vec${components}<i32>` : 'i32';\n    case DataType.uint32:\n      return components > 1 ? `vec${components}<u32>` : 'u32';\n    case DataType.int64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'i32'];\n    case DataType.uint64:\n      if (components > 1) {\n        throw new Error('currently not supported vecX of uint64 yet');\n      }\n      return ['vec2<u32>', 'u32'];\n    case DataType.bool:\n      if (components !== 4) {\n        throw new Error('bool must be vec4');\n      }\n      return ['u32', 'vec4<bool>'];\n\n    default:\n      throw new Error(`Unknown data type: ${type}`);\n  }\n};\n\nexport const tensorTypeToWsglStorageType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[0];\n};\n\nexport const tensorTypeToWsglValueType = (type: DataType, components: 1|2|3|4 = 1) => {\n  const mappedType = getWgslMappedType(type, components);\n  return typeof mappedType === 'string' ? mappedType : mappedType[1];\n};\n\nexport const createTensorShapeVariables = (dims: readonly number[]): ProgramUniform[] =>\n    dims.length === 0 ? [] : [{type: 'uint32', data: dims}, {type: 'uint32', data: ShapeUtil.computeStrides(dims)}];\n\n/**\n * A helper function to get maximum vector size for specified data length\n * @param size\n */\nexport const getMaxComponents = (size: number) => {\n  // we cannot use vec3 type since it has alignment of 16 bytes\n  if (size % 4 === 0) {\n    return 4;\n  } else if (size % 2 === 0) {\n    return 2;\n  }\n\n  return 1;\n};\n\n/**\n * A helper function that initializes variable as a scalar or vector. e.g. f32(0) or vec4f(0,0,0,0)\n * @param dataType\n * @param components\n * @param value\n */\nexport const fillVector = (dataType = 'f32', components?: number, value = '0') => {\n  if (!components || components === 1) {\n    return `${dataType}(${value})`;\n  }\n\n  return `vec${components}<${dataType}>(${value})`;\n};\n\n/**\n * A helper function that casts value or vector to f32\n * @param dataType\n * @param components\n * @param value\n */\nexport const castToF32 = (dataType: string, components: number, value: string) => {\n  if (dataType === 'f32') {\n    return value;\n  }\n  if (components === 1) {\n    return `f32(${value})`;\n  }\n\n  return `vec${components}f(${value})`;\n};\n\n/**\n * A helper function that returns scalar or sums all components of a vector\n * @param name\n * @param components\n */\nexport const sumVector = (name: string, components: number) => {\n  if (components === 4) {\n    return `(${name}.x + ${name}.y + ${name}.z + ${name}.w)`;\n  } else if (components === 2) {\n    return `(${name}.x + ${name}.y)`;\n  } else if (components === 3) {\n    return `(${name}.x + ${name}.y + ${name}.z)`;\n  }\n\n  return name;\n};\n\n/**\n * A helper function to get a IndicesHelper for a given input or output.\n *\n * @param name - the name of the input or output.\n * @param tensorType - the tensor type of the input or output.\n * @param shapeOrRank - the tensor shape or the rank of the input or output.\n * @param isInput - whether the helper is for an input or an output.\n * @param components - indicates the number of components of each element. 1 for scalar, 2 for vec2, 3 for vec3, 4 for\n *    vec4.\n */\nconst createIndicesHelper =\n    (name: string, tensorType: number, shapeOrRank: number|readonly number[], isInput: boolean,\n     components: 1|2|3|4): IndicesHelper => {\n      const useUniform = typeof shapeOrRank === 'number';\n      const rank = useUniform ? shapeOrRank : shapeOrRank.length;\n      const rankIdentity = [...new Array(rank).keys()];\n      const indicesType = rank < 2 ? 'u32' : rank <= 4 ? `vec${rank}<u32>` : `array<u32, ${rank}>`;\n      const mappedType = getWgslMappedType(tensorType, components);\n      const valueType = typeof mappedType === 'string' ? mappedType : mappedType[1];\n      const storageType = typeof mappedType === 'string' ? mappedType : mappedType[0];\n      const type = {indices: indicesType, value: valueType, storage: storageType, tensor: tensorType};\n\n      const normalizeDim = (dim: number|string): string => typeof dim === 'string' ? dim : `${dim}u`;\n\n      const implementationUsed = {\n        offsetToIndices: false,\n        indicesToOffset: false,\n        broadcastedIndicesToOffset: false,\n        set: false,\n        setByIndices: false,\n        get: false,\n        getByIndices: false,\n      };\n\n      const uniformPrefix = useUniform ? 'uniforms.' : '';\n      const shape = `${uniformPrefix}${name}_shape`;\n      const strides = `${uniformPrefix}${name}_strides`;\n      let o2iSnippet = '';\n      for (let i = 0; i < rank - 1; i++) {\n        o2iSnippet += `\n    let dim${i} = current / ${strides}[${i}];\n    let rest${i} = current % ${strides}[${i}];\n    indices[${i}] = dim${i};\n    current = rest${i};\n    `;\n      }\n      o2iSnippet += `indices[${rank - 1}] = current;`;\n\n      const offsetToIndicesImplementation = rank < 2 ? '' : `\n  fn o2i_${name}(offset: u32) -> ${type.indices} {\n    var indices: ${type.indices};\n    var current = offset;\n    ${o2iSnippet}\n    return indices;\n  }`;\n\n      const offsetToIndices = (varOffset: string) => {\n        implementationUsed.offsetToIndices = true;\n        return rank < 2 ? varOffset : `o2i_${name}(${varOffset})`;\n      };\n\n      const offsets: string[] = [];\n      if (rank >= 2) {\n        for (let i = rank - 1; i >= 0; i--) {\n          offsets.push(`${strides}[${i}] * (indices[${i}])`);\n        }\n      }\n\n      const indicesToOffsetImplementation = rank < 2 ? '' : `\n  fn i2o_${name}(indices: ${type.indices}) -> u32 {\n    return ${offsets.join('+')};\n  }`;\n\n      const indicesToOffset = (varIndices: string) => {\n        implementationUsed.indicesToOffset = true;\n        return rank < 2 ? varIndices : `i2o_${name}(${varIndices})`;\n      };\n\n      const indices = (...init: ReadonlyArray<number|string>) =>\n          rank === 0 ? '0u' : `${type.indices}(${init.map(normalizeDim).join(',')})`;\n\n      const indicesGet = (varIndices: string, idx: number|string) => {\n        if (rank < 2) {\n          return `${varIndices}`;\n        } else {\n          return `${varIndices}[${idx}]`;\n        }\n      };\n\n      const indicesSet = (varIndices: string, idx: number|string, value: string) => {\n        if (rank < 2) {\n          return `${varIndices}=${value};`;\n        } else {\n          return `${varIndices}[${idx}]=${value};`;\n        }\n      };\n\n      const broadcastedIndicesToOffsetImplementation: {[key: string]: string} = {};\n      const broadcastedIndicesToOffset = (varIndices: string, output: IndicesHelper) => {\n        implementationUsed.broadcastedIndicesToOffset = true;\n        const implKey = `${output.name}broadcastedIndicesTo${name}Offset`;\n        if (implKey in broadcastedIndicesToOffsetImplementation) {\n          return `${implKey}(${varIndices})`;\n        }\n        const offsets = [];\n        for (let i = rank - 1; i >= 0; i--) {\n          const idx = output.indicesGet('outputIndices', i + output.rank - rank);\n          offsets.push(`${indicesGet(strides, i)} * (${idx} % ${indicesGet(shape, i)})`);\n        }\n        broadcastedIndicesToOffsetImplementation[implKey] =\n            `fn ${implKey}(outputIndices: ${output.type.indices}) -> u32 {\n             return ${offsets.length > 0 ? offsets.join('+') : '0u'};\n           }`;\n\n        return `${implKey}(${varIndices})`;\n      };\n\n      const setByOffset = (offset: number|string, value: string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]=${value};`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), select(0u, 0xFFFFFFFFu, ${value} < 0));`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `${name}[${offset}]=vec2<u32>(u32(${value}), 0u);`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `${name}[${offset}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${value}));`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByOffset = (offset: number|string) => (() => {\n        if (type.storage === type.value) {\n          return `${name}[${offset}]`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'i32') {\n          // int64, components === 1\n          return `i32(${name}[${offset}].x)`;\n        } else if (type.storage === 'vec2<u32>' && type.value === 'u32') {\n          // uint64, components === 1\n          return `u32(${name}[${offset}].x)`;\n        } else if (type.storage === 'u32' && type.value === 'vec4<bool>') {\n          // bool, components === 4\n          return `vec4<bool>(bool(${name}[${offset}] & 0xFFu), bool(${name}[${offset}] & 0xFF00u), bool(${name}[${\n              offset}] & 0xFF0000u), bool(${name}[${offset}] & 0xFF000000u))`;\n        } else {\n          throw new Error(`not supported combination of storage type ${type.storage} and value type ${type.value} yet`);\n        }\n      })();\n\n      const getByIndicesImplementation = rank < 2 ? '' : `\n  fn get_${name}ByIndices(indices: ${type.indices}) -> ${valueType} {\n    return ${getByOffset(`i2o_${name}(indices)`)};\n  }`;\n\n      const getImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn get_${name}(${functionParams}) -> ${valueType} {\n    return get_${name}ByIndices(${indices(dimsParams)});\n  }`;\n      })();\n\n      const get = (...indices: ReadonlyArray<number|string>) => {\n        if (indices.length !== rank) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n\n        const normalizedIndices = indices.map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return getByOffset('0u');\n        } else if (rank === 1) {\n          return getByOffset(normalizedIndices[0]);\n        } else {\n          implementationUsed.get = true;\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}(${normalizedIndices})`;\n        }\n      };\n\n      const getByIndices = (varIndices: string) => {\n        if (rank < 2) {\n          return getByOffset(varIndices);\n        } else {\n          implementationUsed.getByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `get_${name}ByIndices(${varIndices})`;\n        }\n      };\n\n      const setByIndicesImplementation = rank < 2 ? '' : `\n  fn set_${name}ByIndices(indices: ${type.indices}, value: ${valueType}) {\n    ${setByOffset(`i2o_${name}(indices)`, 'value')}\n  }`;\n\n      const setImplementation = rank < 2 ? '' : (() => {\n        const functionParams = rankIdentity.map(i => `d${i}: u32`).join(', ');\n        const dimsParams = rankIdentity.map(i => `d${i}`).join(', ');\n        return `\n  fn set_${name}(${functionParams}, value: ${valueType}) {\n    set_${name}ByIndices(${indices(dimsParams)}, value);\n  }`;\n      })();\n\n      const set = (...indicesAndValue: ReadonlyArray<number|string>) => {\n        if (indicesAndValue.length !== rank + 1) {\n          throw new Error(`indices length must be ${rank}`);\n        }\n        const value = indicesAndValue[rank];\n        if (typeof value !== 'string') {\n          throw new Error('value must be string');\n        }\n\n        const normalizedIndices = indicesAndValue.slice(0, rank).map(normalizeDim).join(',');\n\n        if (rank === 0) {\n          return setByOffset('0u', value);\n        } else if (rank === 1) {\n          return setByOffset(normalizedIndices[0], value);\n        } else {\n          implementationUsed.set = true;\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}(${normalizedIndices}, ${value})`;\n        }\n      };\n\n      const setByIndices = (varIndices: string, value: string) => {\n        if (rank < 2) {\n          return setByOffset(varIndices, value);\n        } else {\n          implementationUsed.setByIndices = true;\n          implementationUsed.indicesToOffset = true;\n          return `set_${name}ByIndices(${varIndices}, ${value});`;\n        }\n      };\n\n      const impl = () => {\n        const impls = [];\n        if (!useUniform) {\n          impls.push(`const ${shape} = ${type.indices}(${shapeOrRank.join(',')});`);\n          impls.push(`const ${strides} = ${type.indices}(${ShapeUtil.computeStrides(shapeOrRank).join(',')});`);\n        }\n        if (implementationUsed.offsetToIndices) {\n          impls.push(offsetToIndicesImplementation);\n        }\n        if (implementationUsed.indicesToOffset) {\n          impls.push(indicesToOffsetImplementation);\n        }\n        if (implementationUsed.broadcastedIndicesToOffset) {\n          Object.values(broadcastedIndicesToOffsetImplementation).forEach(impl => impls.push(impl));\n        }\n        if (implementationUsed.set) {\n          impls.push(setImplementation);\n        }\n        if (implementationUsed.setByIndices) {\n          impls.push(setByIndicesImplementation);\n        }\n        if (implementationUsed.get) {\n          impls.push(getImplementation);\n        }\n        if (implementationUsed.getByIndices) {\n          impls.push(getByIndicesImplementation);\n        }\n        return impls.join('\\n');\n      };\n\n      return {\n        impl,\n        type,\n        offsetToIndices,\n        indicesToOffset,\n        broadcastedIndicesToOffset,\n        indices,\n        indicesGet,\n        indicesSet,\n        set,\n        setByOffset,\n        setByIndices,\n        get,\n        getByOffset,\n        getByIndices,\n        // isVec4,\n        usage: isInput ? 'input' : 'output',\n        name,\n        strides,\n        shape,\n        rank\n      };\n    };\n\n/**\n * Create a IndicesHelper for an input.\n *\n * @param name - the name of the input.\n * @param type - the tensor type of the input.\n * @param shapeOrRank - the tensor shape or the rank of the input.\n * @param components - the number of components of the input. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the input.\n */\nexport const inputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, true, components);\n\n/**\n * Create a IndicesHelper for an output.\n *\n * @param name - the name of the output.\n * @param type - the tensor type of the output.\n * @param shapeOrRank - the tensor shape or the rank of the output.\n * @param components - the number of components of the output. available values are 1, 2, 3, 4. default is 1.\n * @returns an IndicesHelper for the output.\n */\nexport const outputVariable =\n    (name: string, type: number, shapeOrRank: number|readonly number[], components: 1|2|3|4 = 1): IndicesHelper =>\n        createIndicesHelper(name, type, shapeOrRank, false, components);\n\n/**\n * A ShaderHelper is a helper class for generating WGSL code.\n */\nexport interface ShaderHelper {\n  /**\n   * A helper function to generate the start of main function in WGSL source code.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param workgroupSize - an optional workgroup size. default is WORKGROUP_SIZE.\n   */\n  mainStart(workgroupSize?: number|[number, number, number]): string;\n\n  /**\n   * A helper function to generate the code snippet for guarding against out-of-bounds size.\n   *\n   * @example\n   * const getShaderSource = (shaderHelper: ShaderHelper) => `\n   *  ...\n   *\n   *  ${shaderHelper.mainStart()}\n   *    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n   *\n   *    // your code here inside main() function\n   *    ...\n   *  }\n   * `;\n   *\n   * @param size - the size of the data to guard against. can be a number or a string (WGSL `u32` expression).\n   */\n  guardAgainstOutOfBoundsWorkgroupSizes(size: unknown): string;\n\n  /**\n   * A helper function to generate the code snippet for declaring multiple inputs or outputs.\n   *\n   * @param variables - an array of IndicesHelper for the variables.\n   */\n  declareVariables(...variables: IndicesHelper[]): string;\n\n  /**\n   * A helper function to register one uniform. Can be called multiple times to register multiple uniforms.\n   */\n  registerUniform(name: string, type: string): ShaderHelper;\n}\n\nclass ShaderHelperImpl implements ShaderHelper {\n  constructor(private normalizedDispatchGroup: [number, number, number]) {}\n\n  guardAgainstOutOfBoundsWorkgroupSizes(size: number|string): string {\n    // Guard against out-of-bounds work group sizes\n    const sizeInCode = typeof size === 'number' ? `${size}u` : size;\n    return `if (global_idx >= ${sizeInCode}) { return; }`;\n  }\n\n  mainStart(workgroupSize: number|[number, number, number] = WORKGROUP_SIZE) {\n    const workgroupSizeX = typeof workgroupSize === 'number' ? workgroupSize : workgroupSize[0];\n    const workgroupSizeY = typeof workgroupSize === 'number' ? 1 : workgroupSize[1];\n    const workgroupSizeZ = typeof workgroupSize === 'number' ? 1 : workgroupSize[2];\n\n    const is1DimensionDispatch = this.normalizedDispatchGroup[1] === 1 && this.normalizedDispatchGroup[2] === 1;\n    const paramList = is1DimensionDispatch ? `@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>` :\n                                             `@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>`;\n    const globalIdxDefinition = is1DimensionDispatch ?\n        'let global_idx = global_id.x;' :\n        `let global_idx = (workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n          workgroup_id.y * num_workgroups[0] + workgroup_id.x) * ${\n            workgroupSizeX * workgroupSizeY * workgroupSizeZ}u + local_index;`;\n\n    return `@compute @workgroup_size(${workgroupSizeX}, ${workgroupSizeY}, ${workgroupSizeZ})\n  fn main(${paramList}) {\n    ${globalIdxDefinition}\n  `;\n  }\n\n  private declareVariable(variable: IndicesHelper, bindingIndex: number): string {\n    this.indicesHelpers.push(variable);\n    if (variable.rank !== 0) {\n      if (variable.shape.startsWith('uniforms.')) {\n        this.uniforms.push({name: variable.shape.replace('uniforms.', ''), type: variable.type.indices});\n      }\n      if (variable.strides.startsWith('uniforms.')) {\n        this.uniforms.push({name: variable.strides.replace('uniforms.', ''), type: variable.type.indices});\n      }\n    }\n    const access = variable.usage === 'input' ? 'read' : 'read_write';\n    const storageType = variable.type.storage;\n    return `@group(0) @binding(${bindingIndex}) var<storage, ${access}> ${variable.name}: array<${storageType}>;`;\n  }\n\n  declareVariables(...variables: IndicesHelper[]): string {\n    return variables.map(v => this.declareVariable(v, this.variableIndex++)).join('\\n');\n  }\n\n  registerUniform(name: string, type: string): ShaderHelper {\n    this.uniforms.push({name, type});\n    return this;\n  }\n\n  private indicesHelpers: IndicesHelper[] = [];\n  private uniforms: Array<{name: string; type: string}> = [];\n  private uniformDeclaration(): string {\n    if (this.uniforms.length === 0) {\n      return '';\n    }\n\n    const uniformSnippets: string[] = [];\n    for (const {name, type} of this.uniforms) {\n      uniformSnippets.push(`${name}:${type}`);\n    }\n\n    return `\n      struct Uniforms { ${uniformSnippets.join(', ')} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`;\n  }\n  private variableIndex = 0;\n\n  /**\n   * Get additional implementation that needs to be added to the shader source.\n   */\n  get additionalImplementations(): string {\n    return this.uniformDeclaration() + this.indicesHelpers.map(i => i.impl()).join('\\n');\n  }\n}\n\nexport const createShaderHelper = (dispatchGroup: [number, number, number]) => new ShaderHelperImpl(dispatchGroup);\n\n/**\n * This function comes from https://github.com/tensorflow/tfjs/blob/master/tfjs-core/src/ops/broadcast_util.ts#L18-L40\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport const getBroadcastDims = (inShape: readonly number[], outShape: readonly number[]): number[] => {\n  const inRank = inShape.length;\n  const dims: number[] = [];\n  for (let i = 0; i < inRank; i++) {\n    const dim = inRank - 1 - i;\n    const a = inShape[dim] || 1;\n    const b = outShape[outShape.length - 1 - i] || 1;\n    if (b > 1 && a === 1) {\n      dims.unshift(dim);\n    }\n  }\n  return dims;\n};\n\n// TODO: remove this limitation once >4D dims are supported by uniform.\nexport const enableShapesUniforms = (rank: number): boolean => rank <= 4;\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface TransposeAttributes extends AttributeWithCacheKey {\n  readonly perm: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Transpose requires 1 input.');\n  }\n};\n\nconst getAdjustedPerm = (inputRank: number, perm: number[]): number[] =>\n    (perm && perm.length !== inputRank) ? [...(new Array(inputRank).keys())].reverse() : perm;\n\nconst getOutputShape = (inputShape: readonly number[], perm: number[]): readonly number[] =>\n    ShapeUtil.sortBasedOnPerm(inputShape, getAdjustedPerm(inputShape.length, perm));\n\nconst permFunctionBody = (perm: number[], rank: number, input: IndicesHelper, output: IndicesHelper): string => {\n  const reverseFunc = [];\n  reverseFunc.push(`fn perm(i: ${output.type.indices}) -> ${input.type.indices} {\n    var a: ${input.type.indices};`);\n  for (let i = 0; i < rank; ++i) {\n    reverseFunc.push(input.indicesSet('a', perm[i], `i[${i}]`));\n  }\n  reverseFunc.push('return a;}');\n  return reverseFunc.join('\\n');\n};\n\nexport const createTransposeProgramInfo = (inputTensor: TensorView, permAttr: number[]): ProgramInfo => {\n  const inputDataType = inputTensor.dataType;\n  const inputRank = inputTensor.dims.length;\n  const perm = getAdjustedPerm(inputRank, permAttr);\n  const useShapesUniforms = enableShapesUniforms(inputRank);\n  const outputShape = getOutputShape(inputTensor.dims, perm);\n  const outShapeOrRank = useShapesUniforms ? outputShape.length : outputShape;\n  const inShapeOrRank = useShapesUniforms ? inputRank : inputTensor.dims;\n  const output = outputVariable('output', inputDataType, outShapeOrRank);\n  const input = inputVariable('a', inputDataType, inShapeOrRank);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.registerUniform('output_size', 'u32').declareVariables(input, output)}\n\n  ${permFunctionBody(perm, inputRank, input, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.output_size')}\n\n    let indices = ${output.offsetToIndices('global_idx')};\n    let aIndices = perm(indices);\n\n    ${output.setByOffset('global_idx', input.getByIndices('aIndices'))}\n  }`;\n  return {\n    name: 'Transpose',\n    shaderCache: {hint: `${permAttr}`, inputDependencies: useShapesUniforms ? ['rank'] : ['dims']},\n    getRunData: (inputs) => {\n      const outputSize = ShapeUtil.size(outputShape);\n      return {\n        outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n        dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        programUniforms: useShapesUniforms ?\n            [\n              {type: 'uint32', data: outputSize},\n              ...createTensorShapeVariables(inputs[0].dims),\n              ...createTensorShapeVariables(outputShape),\n            ] :\n            [\n              {type: 'uint32', data: outputSize},\n            ],\n      };\n    },\n    getShaderSource,\n  };\n};\n\nexport const transpose = (context: ComputeContext, attributes: TransposeAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createTransposeProgramInfo(context.inputs[0], attributes.perm));\n};\n\nexport const parseTransposeAttributes = (attributes: Record<string, unknown>): TransposeAttributes =>\n    createAttributeWithCacheKey({perm: attributes.perm as number[]});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {createReduceAttributesFromInputs, ReduceAttributes} from './reduce';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst reduceOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate * candidate',\n  logSumExp: 'bestValue + exp(candidate)',\n  l1: 'bestValue + abs(candidate)',\n  l2: 'bestValue + candidate * candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceSharedOps: {[key: string]: string} = {\n  max: 'select(bestValue, candidate, candidate > bestValue)',\n  min: 'select(bestValue, candidate, candidate < bestValue)',\n  mean: 'bestValue + candidate',\n  sum: 'bestValue + candidate',\n  prod: 'bestValue * candidate',\n  sumSquare: 'bestValue + candidate',\n  logSumExp: 'bestValue + candidate',\n  l1: 'bestValue + candidate',\n  l2: 'bestValue + candidate',\n  logSum: 'bestValue + candidate'\n};\n\nconst reduceInitValues: {[key: string]: string} = {\n  max: '_A[offset]',\n  min: '_A[offset]',\n  mean: '0',\n  sum: '0',\n  prod: '1',\n  sumSquare: '0',\n  logSumExp: '0',\n  l1: '0',\n  l2: '0',\n  logSum: '0'\n};\n\nconst reduceOutputValues: {[key: string]: string} = {\n  max: 'bestValue',\n  min: 'bestValue',\n  sum: 'bestValue',\n  prod: 'bestValue',\n  sumSquare: 'bestValue',\n  logSumExp: 'log(bestValue)',\n  l1: 'bestValue',\n  l2: 'sqrt(bestValue)',\n  logSum: 'log(bestValue)'\n};\n\nconst getInnerMostAxes = (numInnerAxes: number, rank: number): number[] => {\n  const res = [];\n  for (let i = rank - numInnerAxes; i < rank; ++i) {\n    res.push(i);\n  }\n  return res;\n};\n\nconst computeOutAndReduceShapes = (shape: readonly number[], axes: readonly number[]): [number[], number[]] => {\n  const outputShape = [];\n  const rank = shape.length;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      outputShape.push(shape[dim]);\n    }\n  }\n  const reduceShape = axes.map(dim => shape[dim]);\n  return [outputShape, reduceShape];\n};\n\nconst expandShapeToKeepDim = (shape: number[], axes: number[]): number[] => {\n  const rank = shape.length + axes.length;\n  const expandShape = [];\n  let shapeIdx = 0;\n  for (let dim = 0; dim < rank; dim++) {\n    if (axes.indexOf(dim) === -1) {\n      expandShape.push(shape[shapeIdx++]);\n    } else {\n      expandShape.push(1);\n    }\n  }\n  return expandShape;\n};\n\nconst areAxesInnerMostDims = (axes: number[], rank: number): boolean => {\n  for (let i = 0; i < axes.length; ++i) {\n    if (axes[axes.length - i - 1] !== rank - 1 - i) {\n      return false;\n    }\n  }\n  return true;\n};\n\nconst getAxesPermutation = (axes: number[], rank: number): number[] => {\n  const res = [];\n  if (!areAxesInnerMostDims(axes, rank)) {\n    for (let i = 0; i < rank; ++i) {\n      if (axes.indexOf(i) === -1) {\n        res.push(i);\n      }\n    }\n    axes.forEach(axis => res.push(axis));\n  }\n  return res;\n};\n\nexport const createReduceSharedProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceType: string,\n     outputDataType: DataType, outputShape: number[], reduceShape: number[]): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const reduceSize = ShapeUtil.size(reduceShape);\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n\n      const workgroupSize = 32;\n\n      const sharedMemorySnippet = `\n          var<workgroup> aBestValues : array<${output.type.storage}, ${workgroupSize}>;\n       `;\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.registerUniform('reduceSize', 'u32').declareVariables(input, output)}\n        ${sharedMemorySnippet}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${shaderHelper.mainStart(workgroupSize)}\n          let local_idx = local_id.x;\n\n          let outputIndex = global_idx / ${workgroupSize};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${output.type.storage}(${reduceInitValues[reduceType]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${workgroupSize}) {\n           let candidate = ${output.type.storage}(${input.getByOffset('offset + k')});\n           bestValue = ${reduceOps[reduceType]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${workgroupSize}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${reduceSharedOps[reduceType]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${\n          output.setByOffset(\n              'outputIndex',\n              `${\n                  reduceType === 'mean' ? `bestValue / ${output.type.storage}(uniforms.reduceSize)` :\n                                          `${reduceOutputValues[reduceType]}`}`)};\n         }\n        }`;\n\n      // One work group is responsible for only one element of output.\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: outputSize},\n          programUniforms: [{type: 'uint32', data: reduceSize}]\n        }),\n      };\n    };\n\nconst reduceCommon =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes,\n     reduceType: 'sum'|'sumSquare'|'prod'|'min'|'max'|'mean'|'logSumExp'|'l1'|'l2'|'logSum'): void => {\n      const updatedAttributes: ReduceAttributes =\n          context.inputs.length === 1 ? attributes : createReduceAttributesFromInputs(context.inputs, attributes);\n\n      let updatedAxes = updatedAttributes.axes;\n      if (updatedAxes.length === 0 && !updatedAttributes.noopWithEmptyAxes) {\n        updatedAxes = context.inputs[0].dims.map((s, i) => i);\n      }\n      const normalizeAxes = ShapeUtil.normalizeAxes(updatedAxes, context.inputs[0].dims.length);\n\n      let axes = normalizeAxes;\n      let input = context.inputs[0];\n      const permutedAxes = getAxesPermutation(axes, context.inputs[0].dims.length);\n      if (permutedAxes.length > 0) {\n        input = context.compute(\n            createTransposeProgramInfo(context.inputs[0], permutedAxes), {inputs: [0], outputs: [-1]})[0];\n        axes = getInnerMostAxes(axes.length, input.dims.length);\n      }\n\n      const [outputShape, reduceShape] = computeOutAndReduceShapes(input.dims, axes);\n      let finalOutputShape = outputShape;\n      if (updatedAttributes.keepDims) {\n        finalOutputShape = expandShapeToKeepDim(outputShape, normalizeAxes);\n      }\n\n      context.compute(\n          createReduceSharedProgramInfo(\n              name, {hint: updatedAttributes.cacheKey, inputDependencies: ['type']}, [input], reduceType,\n              context.inputs[0].dataType, finalOutputShape, reduceShape),\n          {inputs: [input]});\n    };\n\nexport const reduceMeanShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMeanShared', attributes, 'mean');\n};\n\nexport const reduceL1Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL1Shared', attributes, 'l1');\n};\n\nexport const reduceL2Shared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceL2Shared', attributes, 'l2');\n};\n\nexport const reduceLogSumExpShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumExpShared', attributes, 'logSumExp');\n};\n\nexport const reduceMaxShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMaxShared', attributes, 'max');\n};\n\nexport const reduceMinShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceMinShared', attributes, 'min');\n};\n\nexport const reduceProdShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceProdShared', attributes, 'prod');\n};\n\nexport const reduceSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumShared', attributes, 'sum');\n};\n\nexport const reduceSumSquareShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceSumSquareShared', attributes, 'sumSquare');\n};\n\nexport const reduceLogSumShared = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  reduceCommon(context, 'ReduceLogSumShared', attributes, 'logSum');\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramShaderCacheInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\nimport {reduceL1Shared, reduceL2Shared, reduceLogSumExpShared, reduceLogSumShared, reduceMaxShared, reduceMeanShared, reduceMinShared, reduceProdShared, reduceSumShared, reduceSumSquareShared} from './reduce-shared';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('Reduce op requires 1 or 2 inputs.');\n  }\n\n  if (inputs.length === 2 && inputs[1].dims.length !== 1) {\n    throw new Error('Invalid axes input dims.');\n  }\n};\n\nexport interface ReduceAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  noopWithEmptyAxes: boolean;\n  axes: number[];\n}\n\nexport type ReduceOp =\n    (input: IndicesHelper, output: IndicesHelper,\n     axes: readonly number[]) => [string, string, string, string, ...string[]];\n\nconst noOp: ReduceOp = (input) => ['', '', `var value = ${input.getByOffset('inputOffset')};`, ''];\nexport const createReduceProgramInfo =\n    (name: string, shaderCache: ProgramShaderCacheInfo, inputs: readonly TensorView[], reduceOp: ReduceOp,\n     axesInput: number[], outputDataType: DataType, keepDims = false, noopWithEmptyAxes = false): ProgramInfo => {\n      const outputShape: number[] = [];\n      const inputShape = inputs[0].dims;\n\n      const axes = ShapeUtil.normalizeAxes(axesInput, inputs[0].dims.length);\n      const reduceOnAllAxes = !noopWithEmptyAxes && axes.length === 0;\n      inputShape.forEach((d, i) => {\n        if (reduceOnAllAxes || axes.indexOf(i) >= 0) {\n          if (keepDims) {\n            outputShape.push(1);\n          }  // else { // skip this axis}\n        } else {\n          outputShape.push(d);\n        }\n      });\n\n      const idxCopy: string[] = [];  // copy output indexes to input indexes\n\n      const input = inputVariable('_A', inputs[0].dataType, inputShape);\n      const output = outputVariable('output', outputDataType, outputShape);\n      const ops = reduceOp(input, output, axes);\n      const inputOffsetAssignment = `inputOffset = ${input.indicesToOffset('inputIndices')};`;\n      const initinputOffsetLet = `let ${inputOffsetAssignment};`;\n      const initinputOffsetVar = `var ${inputOffsetAssignment};`;\n      const initinputOffset = (ops[1] === '') ? '' : initinputOffsetVar;\n      let reduceOps = ((ops[1] === '') ? initinputOffsetLet : inputOffsetAssignment) + '\\n' + ops[2];\n\n      for (let k = 0, l = 0; k < inputs[0].dims.length; k++) {\n        // if this axis is reduced\n        if (reduceOnAllAxes || axes.indexOf(k) >= 0) {\n          if (keepDims) {\n            l++;\n          }\n          // loop over the d-th axis\n          reduceOps = `for(var j${k}: u32 = 0; j${k} < ${inputs[0].dims[k]}; j${k}++) {\n                ${ops[2].includes('lastIndex') ? `let lastIndex = j${k};` : ''}\n                ${input.indicesSet('inputIndices', k, `j${k}`)}\n                ${reduceOps}\n              }`;\n        } else {\n          idxCopy.push(`${input.indicesSet('inputIndices', k, output.indicesGet('outputIndices', l))};`);\n          l++;\n        }\n      }\n\n      const outputSize = ShapeUtil.size(outputShape);\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(input, output)}\n\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n          var inputIndices: ${input.type.indices};\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n\n          ${idxCopy.join('\\n')}\n          ${ops[0]}       // init ops for reduce max/min\n          ${initinputOffset}\n          ${ops[1]}\n          ${reduceOps}\n          ${ops[3]}\n          ${ops.length === 4 ? output.setByOffset('global_idx', 'value') : ops.slice(4).join('\\n')}\n        }`;\n\n      return {\n        name,\n        shaderCache,\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n      };\n    };\n\nexport const createReduceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: ReduceAttributes): ReduceAttributes => {\n      const axes: number[] = [];\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => axes.push(Number(v)));\n      }\n      return createAttributeWithCacheKey(\n          {axes, keepDims: attributes.keepDims, noopWithEmptyAxes: attributes.noopWithEmptyAxes});\n    };\n\nconst runReduceProgram =\n    (context: ComputeContext, name: string, attributes: ReduceAttributes, reduceOp: ReduceOp): void => {\n      const inputs = context.inputs;\n      const updatedAttributes: ReduceAttributes =\n          inputs.length === 1 ? attributes : createReduceAttributesFromInputs(inputs, attributes);\n\n      context.compute(\n          createReduceProgramInfo(\n              name, {hint: updatedAttributes.cacheKey}, [inputs[0]],\n              updatedAttributes.noopWithEmptyAxes && updatedAttributes.axes.length === 0 ? noOp : reduceOp,\n              updatedAttributes.axes, inputs[0].dataType, updatedAttributes.keepDims,\n              updatedAttributes.noopWithEmptyAxes),\n          {inputs: [0]});\n    };\n\nconst reduceLogSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSum', attributes, reduceOp);\n};\n\nconst reduceL1Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += abs(${input.getByOffset('inputOffset')});`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceL1', attributes, reduceOp);\n};\n\nconst reduceL2Naive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += (t * t);`,\n       'value = sqrt(value);',\n  ];\n  runReduceProgram(context, 'ReduceL2', attributes, reduceOp);\n};\n\nconst reduceLogSumExpNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += exp(${input.getByOffset('inputOffset')});`,\n       'value = log(value);',\n  ];\n  runReduceProgram(context, 'ReduceLogSumExp', attributes, reduceOp);\n};\n\nconst reduceMaxNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(input.indicesSet('inputIndices', k, 0));\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = max(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMax', attributes, reduceOp);\n};\n\nconst reduceMeanNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output, axes) => {\n    let size = 1.0;\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        // TODO: this depends on the input dims. If we want to use uniform, this need to be updated.\n        size *= context.inputs[0].dims[k];\n      }\n    }\n\n    return [\n      'var sum = f32(0);',\n      '',\n      `sum += f32(${input.getByOffset('inputOffset')});`,\n      `let value = ${output.type.value}(sum / ${size});`,\n    ];\n  };\n  runReduceProgram(context, 'ReduceMean', attributes, reduceOp);\n};\n\nconst reduceMinNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, _output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n\n    return [\n      `${idxZero.join('\\n')}`,\n      `var value = ${input.getByOffset('inputOffset')};`,\n      `value = min(value, ${input.getByOffset('inputOffset')});`,\n      '',\n    ];\n  };\n  runReduceProgram(context, 'ReduceMin', attributes, reduceOp);\n};\n\nconst reduceProdNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(1);`,\n       '',\n       `value *= ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceProd', attributes, reduceOp);\n};\n\nconst reduceSumNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var value = ${output.type.storage}(0);`,\n       '',\n       `value += ${input.getByOffset('inputOffset')};`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSum', attributes, reduceOp);\n};\n\nconst reduceSumSquareNaive = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  validateInputs(context.inputs);\n  const reduceOp: ReduceOp = (input, output) =>\n      [`var t = ${output.type.value}(0); var value = ${output.type.value}(0);`,\n       '',\n       `t = ${input.getByOffset('inputOffset')}; value += t * t;`,\n       '',\n  ];\n  runReduceProgram(context, 'ReduceSumSquare', attributes, reduceOp);\n};\n\nconst useNaiveReduceMethod =\n    (shape: readonly number[], axes: readonly number[], noopWithEmptyAxes: boolean): boolean => {\n      if (axes.length === 0) {\n        return noopWithEmptyAxes ? true : false;\n      }\n\n      let outputSize = 1;\n      let reduceSize = 1;\n      for (let dim = 0; dim < axes.length; dim++) {\n        if (axes.indexOf(dim) === -1) {\n          outputSize *= shape[dim];\n        } else {\n          reduceSize *= shape[dim];\n        }\n      }\n\n      // The condition data is very rough, although considering the count of Execution Unit (EU), the potential\n      // work groups in a EU and the counts of loops in the naive and shared methods, also doing experiments\n      // on some machines.\n      return reduceSize < 32 && outputSize > 1024 ? true : false;\n    };\n\nexport const reduceMean = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMeanNaive(context, attributes);\n  } else {\n    reduceMeanShared(context, attributes);\n  }\n};\n\nexport const reduceL1 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL1Naive(context, attributes);\n  } else {\n    reduceL1Shared(context, attributes);\n  }\n};\n\nexport const reduceL2 = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceL2Naive(context, attributes);\n  } else {\n    reduceL2Shared(context, attributes);\n  }\n};\n\nexport const reduceLogSumExp = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumExpNaive(context, attributes);\n  } else {\n    reduceLogSumExpShared(context, attributes);\n  }\n};\n\nexport const reduceMax = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMaxNaive(context, attributes);\n  } else {\n    reduceMaxShared(context, attributes);\n  }\n};\n\nexport const reduceMin = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceMinNaive(context, attributes);\n  } else {\n    reduceMinShared(context, attributes);\n  }\n};\n\nexport const reduceProd = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceProdNaive(context, attributes);\n  } else {\n    reduceProdShared(context, attributes);\n  }\n};\n\nexport const reduceSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumNaive(context, attributes);\n  } else {\n    reduceSumShared(context, attributes);\n  }\n};\n\nexport const reduceSumSquare = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceSumSquareNaive(context, attributes);\n  } else {\n    reduceSumSquareShared(context, attributes);\n  }\n};\n\nexport const reduceLogSum = (context: ComputeContext, attributes: ReduceAttributes): void => {\n  if (useNaiveReduceMethod(context.inputs[0].dims, attributes.axes, attributes.noopWithEmptyAxes)) {\n    reduceLogSumNaive(context, attributes);\n  } else {\n    reduceLogSumShared(context, attributes);\n  }\n};\n\nexport const parseReduceAttributes = (attributes: Record<string, unknown>): ReduceAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ReduceAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createReduceProgramInfo, ReduceOp} from './reduce';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length === 0 || inputs.length > 2) {\n    throw new Error('ArgMinMaxOp op requires 1 or 2 inputs.');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Invalid input type.');\n  }\n};\n\nexport interface ArgMinMaxAttributes extends AttributeWithCacheKey {\n  keepDims: boolean;\n  axis: number;\n  selectLastIndex: number;\n}\n\nconst createArgMinMaxAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: ArgMinMaxAttributes): ArgMinMaxAttributes =>\n        createAttributeWithCacheKey(\n            {axis: attributes.axis, keepDims: attributes.keepDims, selectLastIndex: attributes.selectLastIndex});\n\nexport const argMin = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '<=' : '<'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  const updatedAttributes: ArgMinMaxAttributes =\n      context.inputs.length === 1 ? attributes : createArgMinMaxAttributesFromInputs(context.inputs, attributes);\n  context.compute(\n      createReduceProgramInfo(\n          'ArgMin', {hint: updatedAttributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [updatedAttributes.axis],\n          DataType.int64, updatedAttributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const argMax = (context: ComputeContext, attributes: ArgMinMaxAttributes): void => {\n  validateInputs(context.inputs);\n  const argMinMaxOp: ReduceOp = (input, output, axes) => {\n    const idxZero = [];\n    for (let k = 0; k < input.rank; k++) {\n      if (axes.indexOf(k) >= 0 || axes.length === 0) {\n        idxZero.push(`inputIndices[${k}] = 0;`);  // first element\n      }\n    }\n    return [\n      `${idxZero.join('\\n')}`, `var value = ${input.getByOffset('inputOffset')};\\nvar bestIndex : i32 = 0;`,\n      `if (${input.getByOffset('inputOffset')} ${attributes.selectLastIndex > 0 ? '>=' : '>'} value) {\n         value = ${input.getByOffset('inputOffset')};\n         bestIndex = i32(lastIndex);\n       }`,\n      '', output.setByOffset('global_idx', 'bestIndex')\n    ];\n  };\n\n  const updatedAttributes: ArgMinMaxAttributes =\n      context.inputs.length === 1 ? attributes : createArgMinMaxAttributesFromInputs(context.inputs, attributes);\n  context.compute(\n      createReduceProgramInfo(\n          'argMax', {hint: updatedAttributes.cacheKey}, [context.inputs[0]], argMinMaxOp, [updatedAttributes.axis],\n          DataType.int64, updatedAttributes.keepDims),\n      {inputs: [0]});\n};\n\nexport const parseArgMinMaxAttributes = (attributes: Record<string, unknown>): ArgMinMaxAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<ArgMinMaxAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![320, 640, 1280].includes(inputs[0].dims[2])) {\n    throw new Error('number of channels should be 320, 640 or 1280');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasAddProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims;\n\n  const channels = inputs[0].dims[2];\n  // since channel number can be only 320/640/1280, it's always divisable by 4\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, outputShape, 4);\n  const bias = inputVariable('bias', dataType, [channels], 4);\n  const residual = inputVariable('residual', dataType, outputShape, 4);\n  const output = outputVariable('output', dataType, outputShape, 4);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const channels = ${channels}u / 4;\n  ${shaderHelper.declareVariables(input, bias, residual, output)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let value = ${input.getByOffset('global_idx')}\n      + ${bias.getByOffset('global_idx % channels')} + ${residual.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n\n  return {\n    name: 'BiasAdd',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasAdd = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasAddProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {MAX_CLIP, MIN_CLIP, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\ntype BuiltinFunctionName = string;\ntype ElementwiseCustomExpression = (expression: string) => string;\ntype ElementwiseFunctionCall = BuiltinFunctionName|ElementwiseCustomExpression;\n\nconst createElementwiseProgramShader =\n    (shaderHelper: ShaderHelper, datasize: number, inputDataType: number, outputDataType: number,\n     funcCall: ElementwiseFunctionCall, additionalImplementation?: string): string => {\n      const vecSize = Math.ceil(datasize / 4);\n\n      let expression = '';\n      if (typeof funcCall === 'string') {\n        expression = `${funcCall}(a)`;\n      } else {\n        expression = funcCall('a');\n      }\n\n      const input = inputVariable('inputData', inputDataType, [vecSize], 4);\n      const output = outputVariable('outputData', outputDataType, [vecSize], 4);\n\n      return `\n      ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(input, output)}\n\n  ${additionalImplementation ?? ''}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n\n    let a = ${input.getByOffset('global_idx')};\n    ${output.setByOffset('global_idx', expression)}\n  }`;\n    };\n\nconst createElementwiseProgramInfo =\n    (input: TensorView, name: string, funcCall: ElementwiseFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType: number = input.dataType): ProgramInfo => ({\n      name,\n      shaderCache: {hint: cacheKey, inputDependencies: ['type']},\n      getShaderSource: shaderHelper => createElementwiseProgramShader(\n          shaderHelper, ShapeUtil.size(input.dims), input.dataType, outputDataType, funcCall, additionalImplementation),\n      getRunData: (inputTensors) => ({\n        outputs: [{dims: input.dims, dataType: outputDataType}],\n        dispatchGroup:\n            {x: Math.ceil(ShapeUtil.size(inputTensors[0].dims) / 64 /* workgroup size */ / 4 /* vec size */)},\n        programUniforms: [\n          {type: 'uint32', data: Math.ceil(ShapeUtil.size(input.dims) / 4)},\n        ],\n      })\n    });\n\nexport const abs = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Abs', 'abs'));\n};\n\nexport const acos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acos', 'acos'));\n};\n\nexport const acosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Acosh', 'acosh'));\n};\n\nexport const asin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asin', 'asin'));\n};\n\nexport const asinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Asinh', 'asinh'));\n};\n\nexport const atan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atan', 'atan'));\n};\nexport const atanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Atanh', 'atanh'));\n};\n\nexport interface CastAttributes extends AttributeWithCacheKey {\n  readonly to: number;\n  readonly saturate?: boolean;\n}\n\nexport const parseCastAttributes = (attributes: Record<string, unknown>): CastAttributes =>\n    createAttributeWithCacheKey(attributes as {to: number});\n\n\nexport const cast = (context: ComputeContext, attributes: CastAttributes): void => {\n  let func: ElementwiseFunctionCall;\n  switch (attributes.to) {\n    case DataType.float16:\n      func = 'vec4<f16>';\n      break;\n    case DataType.float:\n      func = 'vec4<f32>';\n      break;\n    case DataType.uint32:\n      func = 'vec4<u32>';\n      break;\n    case DataType.int32:\n      func = 'vec4<i32>';\n      break;\n    case DataType.bool:\n      func = 'vec4<bool>';\n      break;\n    default:\n      throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${attributes.to}`);\n  }\n  context.compute(\n      createElementwiseProgramInfo(context.inputs[0], 'Cast', func, undefined, attributes.cacheKey, attributes.to));\n};\n\nexport interface ClipAttributes extends AttributeWithCacheKey {\n  readonly min: number;\n  readonly max: number;\n}\n\nexport const clipV10 = (context: ComputeContext, attributes: ClipAttributes): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(\n      createElementwiseProgramInfo(\n          context.inputs[0], 'Clip', a => `clamp(${a}, clip_min_, clip_max_)`, `\n    const clip_min_: vec4<${dataType}> = vec4(${dataType}(${attributes.min}));\n    const clip_max_: vec4<${dataType}> = vec4(${dataType}(${attributes.max}));\n`,\n          attributes.cacheKey),\n      {inputs: [0]});\n};\nconst generateClipAttributesFromInputs = (inputs: readonly TensorView[]): ClipAttributes => {\n  const min = (inputs.length >= 2) ? inputs[1].getFloat32Array()[0] : MIN_CLIP;\n  const max = (inputs.length >= 3) ? inputs[2].getFloat32Array()[0] : MAX_CLIP;\n  return createAttributeWithCacheKey({min, max});\n};\n\nexport const clip = (context: ComputeContext): void => {\n  const attributes = generateClipAttributesFromInputs(context.inputs);\n  clipV10(context, attributes);\n};\n\nexport const ceil = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Ceil', 'ceil'));\n};\n\nexport const cos = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cos', 'cos'));\n};\n\nexport const cosh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Cosh', 'cosh'));\n};\n\nexport interface AlphaAttributes extends AttributeWithCacheKey {\n  readonly alpha: number;\n}\n\nexport const parseAlphaAttributes = (attributes: Record<string, unknown>): AlphaAttributes =>\n    createAttributeWithCacheKey(attributes as {alpha: number});\n\nexport const elu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Elu', a => `elu_vf32(${a})`, `\n  const elu_alpha_: f32 = f32(${attributes.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,\n      attributes.cacheKey));\n};\n\nexport const erfImpl = (dataType: string, varType = 'f32') => `\nconst r0: ${varType} = 0.3275911;\nconst r1: ${varType} = 0.254829592;\nconst r2: ${varType} = -0.284496736;\nconst r3: ${varType} = 1.421413741;\nconst r4: ${varType} = -1.453152027;\nconst r5: ${varType} = 1.061405429;\n\nfn erf_vf32(v: ${dataType}) -> ${dataType} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`;\n\nexport const erf = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Erf', a => `erf_vf32(${a})`, erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const exp = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Exp', 'exp'));\n};\n\nexport const floor = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Floor', 'floor'));\n};\n\nexport const gelu = (context: ComputeContext): void => {\n  const dataType = tensorTypeToWsglStorageType(context.inputs[0].dataType);\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Gelu', a => `0.5 * ${a} * (1.0 + erf_vf32(${a} * 0.7071067811865475))`,\n      erfImpl(`vec4<${dataType}>`, dataType)));\n};\n\nexport const leakyRelu = (context: ComputeContext, attributes: AlphaAttributes): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'LeakyRelu', a => `select(leaky_relu_alpha_ * ${a}, ${a}, ${a} >= vec4<f32>(0.0))`,\n      `const leaky_relu_alpha_: f32 = f32(${attributes.alpha});`, attributes.cacheKey));\n};\n\nexport const not = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Not', a => `!${a}`));\n};\n\nexport const neg = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Neg', a => `-${a}`));\n};\n\nexport const reciprocal = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Reciprocal', a => `1.0/${a}`));\n};\n\nexport const relu = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'Relu', a => `select(vec4<f32>(0.0), ${a}, ${a} > vec4<f32>(0.0))`));\n};\n\nexport const sigmoid = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sigmoid', a => `(1.0 / (1.0 + exp(-${a})))`));\n};\n\nexport const sin = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sin', 'sin'));\n};\n\nexport const sinh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sinh', 'sinh'));\n};\n\nexport const sqrt = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Sqrt', 'sqrt'));\n};\n\nexport const tan = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tan', 'tan'));\n};\n\nexport const tanh = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Tanh', 'tanh'));\n};\n\nexport const thresholdedRelu = (context: ComputeContext, attributes: AlphaAttributes): number => {\n  context.compute(createElementwiseProgramInfo(\n      context.inputs[0], 'ThresholdedRelu', a => `select(vec4<f32>(0.0), ${a}, ${a} > thresholded_relu_alpha_)`,\n      `const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${attributes.alpha});`, attributes.cacheKey));\n  return 0;\n};\n\nexport const log = (context: ComputeContext): void => {\n  context.compute(createElementwiseProgramInfo(context.inputs[0], 'Log', 'log'));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {erfImpl} from './unary-op';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (inputs[0].dims.length !== 3) {\n    throw new Error('input should have 3 dimensions');\n  }\n\n  if (![2560, 5120, 10240].includes(inputs[0].dims[2])) {\n    throw new Error('hidden state should be 2560, 5120 or 10240');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('bias is expected to have 1 dimensions');\n  }\n\n  if (inputs[0].dims[2] !== inputs[1].dims[0]) {\n    throw new Error('last dimension of input and bias are not the same');\n  }\n};\n\nconst createBiasSplitGeluProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const outputShape = inputs[0].dims.slice();\n  outputShape[2] = outputShape[2] / 2;\n\n  const input = inputVariable('input', inputs[0].dataType, inputs[0].dims, 4);\n  const bias = inputVariable('bias', inputs[0].dataType, [inputs[0].dims[2]], 4);\n  const output = outputVariable('output', inputs[0].dataType, outputShape, 4);\n\n  const outputSize = ShapeUtil.size(outputShape) / 4;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${inputs[0].dims[2] / 4 / 2}u;\n\n  ${shaderHelper.declareVariables(input, bias, output)}\n\n  ${erfImpl('vec4f')}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${output.setByOffset('global_idx', 'valueLeft * geluRight')}\n  }`;\n\n  return {\n    name: 'BiasSplitGelu',\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const biasSplitGelu = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createBiasSplitGeluProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype BuiltinFunctionName = string;\ntype BinaryCustomExpression = (expressionA: string, expressionB: string) => string;\ntype BinaryFunctionCall = BuiltinFunctionName|BinaryCustomExpression|{\n  scalar: BinaryCustomExpression;\n  vector: BinaryCustomExpression;\n};\n\nconst createBinaryOpProgramShader =\n    (shaderHelper: ShaderHelper, dimsA: readonly number[], dimsB: readonly number[], dimsOutput: readonly number[],\n     vectorize: boolean, doBroadcast: boolean, funcCall: BinaryFunctionCall, typeA: number, typeB: number,\n     typeOutput: number, useShapesUniforms: boolean, additionalImplementation?: string) => {\n      let expressionScalar: BinaryCustomExpression;\n      let expressionVector: BinaryCustomExpression;\n      if (typeof funcCall === 'string') {\n        expressionScalar = expressionVector = (a, b) => `${funcCall}((${a}),(${b}))`;\n      } else if (typeof funcCall === 'function') {\n        expressionScalar = expressionVector = funcCall;\n      } else {\n        expressionScalar = funcCall.scalar;\n        expressionVector = funcCall.vector;\n      }\n\n      const inputAShapeOrRank = useShapesUniforms ? dimsA.length : dimsA;\n      const inputBShapeOrRank = useShapesUniforms ? dimsB.length : dimsB;\n      const outputShapeOrRank = useShapesUniforms ? dimsOutput.length : dimsOutput;\n      const output = outputVariable('outputData', typeOutput, outputShapeOrRank, 4);\n      const a = inputVariable('aData', typeA, inputAShapeOrRank, 4);\n      const b = inputVariable('bData', typeB, inputBShapeOrRank, 4);\n\n      let assignment: string;\n      if (vectorize) {\n        if (doBroadcast) {\n          const isAOneElement = ShapeUtil.size(dimsA) === 1;\n          const isBOneElement = ShapeUtil.size(dimsB) === 1;\n          if (isAOneElement || isBOneElement) {\n            assignment = output.setByOffset(\n                'global_idx',\n                expressionVector(\n                    isAOneElement ? `${a.type.value}(${a.getByOffset('0')}.x)` : a.getByOffset('global_idx'),\n                    isBOneElement ? `${b.type.value}(${b.getByOffset('0')}.x)` : b.getByOffset('global_idx')));\n          } else {\n            assignment = `\n            let outputIndices = ${output.offsetToIndices('global_idx * 4u')};\n            let offsetA = ${a.broadcastedIndicesToOffset('outputIndices', output)};\n            let offsetB = ${b.broadcastedIndicesToOffset('outputIndices', output)};\n            ${\n                output.setByOffset(\n                    'global_idx', expressionVector(a.getByOffset('offsetA / 4u'), b.getByOffset('offsetB / 4u')))}\n          `;\n          }\n        } else {\n          assignment = output.setByOffset(\n              'global_idx', expressionVector(a.getByOffset('global_idx'), b.getByOffset('global_idx')));\n        }\n      } else {\n        if (!doBroadcast) {\n          throw new Error('no necessary to use scalar implementation for element-wise binary op implementation.');\n        }\n\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expressionScalar(expressionA, expressionB)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.registerUniform('vec_size', 'u32').declareVariables(a, b, output)}\n\n        ${additionalImplementation ?? ''}\n\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.vec_size')}\n        ${assignment}\n      }`;\n    };\n\nconst createBinaryOpProgramInfo =\n    (name: string, cacheKey: string, a: TensorView, b: TensorView, funcCall: BinaryFunctionCall,\n     additionalImplementation?: string, outputDataType: number = a.dataType): ProgramInfo => {\n      const isBroadcast = !ShapeUtil.areEqual(a.dims, b.dims);\n      let outputShape = a.dims;\n      let outputSize = ShapeUtil.size(a.dims);\n\n      let vectorize = false;\n\n      // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n      const cacheKeyAux = [isBroadcast];\n      if (isBroadcast) {\n        const calculatedShape = BroadcastUtil.calcShape(a.dims, b.dims, false);\n        if (!calculatedShape) {\n          throw new Error('Can\\'t perform binary op on the given tensors');\n        }\n        outputShape = calculatedShape;\n        outputSize = ShapeUtil.size(outputShape);\n        const isAOneElement = ShapeUtil.size(a.dims) === 1;\n        const isBOneElement = ShapeUtil.size(b.dims) === 1;\n        cacheKeyAux.push(isAOneElement);\n        cacheKeyAux.push(isBOneElement);\n        // check whether vectorize can be enabled\n        let sharedDimension = 1;\n        for (let i = 1; i < outputShape.length; i++) {\n          const dimA = a.dims[a.dims.length - i] ?? 1;\n          const dimB = b.dims[b.dims.length - i] ?? 1;\n          if (dimA === dimB) {\n            sharedDimension *= dimA;\n          } else {\n            break;\n          }\n        }\n        if (sharedDimension % 4 === 0 || isAOneElement || isBOneElement) {\n          vectorize = true;\n        }\n      } else {\n        // element-wise\n        vectorize = true;\n      }\n      cacheKeyAux.push(vectorize);\n      const useShapesUniforms = enableShapesUniforms(a.dims.length) && enableShapesUniforms(b.dims.length) &&\n          enableShapesUniforms(outputShape.length);\n      return {\n        name,\n        shaderCache: {\n          hint: cacheKey + cacheKeyAux.map((x) => x.toString()).join('_'),\n          inputDependencies: useShapesUniforms ? ['rank', 'rank'] : ['dims', 'dims'],\n        },\n        getShaderSource: (shaderHelper) => createBinaryOpProgramShader(\n            shaderHelper, a.dims, b.dims, outputShape, vectorize, isBroadcast, funcCall, a.dataType, b.dataType,\n            outputDataType, useShapesUniforms, additionalImplementation),\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: outputDataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* component size */)},\n          programUniforms: useShapesUniforms ?\n              [\n                {type: 'uint32', data: Math.ceil(ShapeUtil.size(outputShape) / 4)},\n                ...createTensorShapeVariables(a.dims),\n                ...createTensorShapeVariables(b.dims),\n                ...createTensorShapeVariables(outputShape),\n              ] :\n              [\n                {type: 'uint32', data: Math.ceil(ShapeUtil.size(outputShape) / 4)},\n              ],\n        }),\n      };\n    };\n\nconst runBinaryOp =\n    (context: ComputeContext, name: string, funcCall: BinaryFunctionCall, additionalImplementation?: string,\n     cacheKey?: string, outputDataType?: number): void => {\n      context.compute(createBinaryOpProgramInfo(\n          name, cacheKey ?? '', context.inputs[0], context.inputs[1], funcCall, additionalImplementation,\n          outputDataType));\n    };\n\nexport const add = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Add', (a, b) => `${a}+${b}`);\n};\n\nexport const div = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Div', (a, b) => `${a}/${b}`);\n};\n\nexport const equal = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Equal', ({scalar: (a, b) => `u32(${a}==${b})`, vector: (a, b) => `vec4<u32>(${a}==${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const mul = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Mul', (a, b) => `${a}*${b}`);\n};\n\nexport const pow = (context: ComputeContext): void => {\n  const type = inputVariable('input', context.inputs[0].dataType, context.inputs[0].dims).type.value;\n  const roundStr = type === 'i32' ? 'round' : '';\n  runBinaryOp(\n      context, 'Pow', ({scalar: (a, b) => `pow_custom(${a},${b})`, vector: (a, b) => `pow_vector_custom(${a},${b})`}),\n      `\n    fn pow_custom(a : ${type}, b : ${type}) -> ${type} {\n      if (b == ${type}(0.0)) {\n        return ${type}(1.0);\n      } else if (a < ${type}(0.0) && f32(b) != floor(f32(b))) {\n        return ${type}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${type}(1.0), round(f32(abs(b) % ${type}(2.0))) != 1.0) * ${type}(${\n          roundStr}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${type}>, b : vec4<${type}>) -> vec4<${type}> {\n      // TODO: implement vectorized pow\n      return vec4<${type}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `);\n};\n\nexport const sub = (context: ComputeContext): void => {\n  runBinaryOp(context, 'Sub', (a, b) => `${a}-${b}`);\n};\n\nexport const greater = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Greater', ({scalar: (a, b) => `u32(${a}>${b})`, vector: (a, b) => `vec4<u32>(${a}>${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const less = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'Less', ({scalar: (a, b) => `u32(${a}<${b})`, vector: (a, b) => `vec4<u32>(${a}<${b})`}), undefined,\n      undefined, DataType.bool);\n};\n\nexport const greaterOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'GreaterOrEqual', ({scalar: (a, b) => `u32(${a}>=${b})`, vector: (a, b) => `vec4<u32>(${a}>=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n\nexport const lessOrEqual = (context: ComputeContext): void => {\n  runBinaryOp(\n      context, 'LessOrEqual', ({scalar: (a, b) => `u32(${a}<=${b})`, vector: (a, b) => `vec4<u32>(${a}<=${b})`}),\n      undefined, undefined, DataType.bool);\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, ProgramInputTensorInfoDependency, ProgramUniform} from '../types';\n\nimport {createTensorShapeVariables, enableShapesUniforms, IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface ConcatAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n\n  const inputType = inputs[0].dataType;\n  const inputDimensionality = inputs[0].dims.length;\n\n  for (const input of inputs) {\n    // make sure types of all inputs match\n    if (input.dataType !== inputType) {\n      throw new Error('input tensors should be one type');\n    }\n\n    // make sure the dimensionality of all inputs are the same\n    if (input.dims.length !== inputDimensionality) {\n      throw new Error('input tensors should have the same shape');\n    }\n  }\n};\n\nconst calculateInputIndexImpl = (numberOfTensors: number, sizeInConcatAxisStr: string): string => `\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${numberOfTensors}u>(${sizeInConcatAxisStr});\n    for (var i: u32 = 0u; i < ${numberOfTensors}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${numberOfTensors}u;\n  }`;\n\nconst assignOutputData = (inputs: readonly IndicesHelper[], output: IndicesHelper) => {\n  const numberOfTensors = inputs.length;\n\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = output.setByOffset('global_idx', inputs[i].getByIndices('indices'));\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (inputIndex == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (inputIndex == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return codeLines.join('\\n');\n};\n\nconst createConcatProgramInfo = (inputs: readonly TensorView[], axis: number): ProgramInfo => {\n  const inputShape = inputs[0].dims.slice();\n  if (axis >= inputShape.length || axis < (-1 * inputShape.length)) {\n    throw new Error('axis specified for concat doesn\\'t match input dimensionality');\n  }\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  // ensure all of the non-concatenated axes match each other\n  // calculate the shape of the output tensor while we do that\n  const outputShape = inputShape.slice(0);\n  for (let i = 1; i < inputs.length; i++) {\n    const dataNShape = inputs[i].dims.slice();\n    for (let axisIndex = 0; axisIndex < inputShape.length; axisIndex++) {\n      // add to the placeholder for computing output shape\n      if (axisIndex === adjustedAxis) {\n        outputShape[adjustedAxis] += dataNShape[axisIndex];\n      }\n      // ensure all non-cancatenated axes match each other\n      else if (inputShape[axisIndex] !== dataNShape[axisIndex]) {\n        throw new Error('non concat dimensions must match');\n      }\n    }\n  }\n\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const sizeInConcatAxis = new Array<number>(inputs.length);\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  const dataType = inputs[0].dataType;\n\n  let previousSum = 0;\n  const inputDependencies: ProgramInputTensorInfoDependency[] = [];\n  const inputShapeOrRanks = [];\n  const enableInputShapesUniforms = [];\n  const programUniforms: ProgramUniform[] = [{type: 'uint32', data: outputSize}];\n  for (let i = 0; i < inputs.length; ++i) {\n    previousSum += inputs[i].dims[adjustedAxis];\n    sizeInConcatAxis[i] = previousSum;\n    enableInputShapesUniforms.push(enableShapesUniforms(inputs[i].dims.length));\n    inputShapeOrRanks.push(enableInputShapesUniforms[i] ? inputs[i].dims.length : inputs[i].dims);\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputShapeOrRanks[i]);\n    inputDependencies.push(enableInputShapesUniforms[i] ? 'rank' : 'dims');\n    programUniforms.push({type: 'uint32', data: sizeInConcatAxis[i]});\n  }\n  for (let i = 0; i < inputs.length; ++i) {\n    if (enableInputShapesUniforms[i]) {\n      programUniforms.push(...createTensorShapeVariables(inputs[i].dims));\n    }\n  }\n\n  const enableOutputShapesUniforms = enableShapesUniforms(outputShape.length);\n  if (enableOutputShapesUniforms) {\n    programUniforms.push(...createTensorShapeVariables(outputShape));\n  }\n\n  const outputShapeOrRank = enableOutputShapesUniforms ? outputShape.length : outputShape;\n  const output = outputVariable('output', dataType, outputShapeOrRank);\n\n  const indicesAxis = output.indicesGet('indices', adjustedAxis);\n  const sizeInConcatAxisStr =\n      Array.from(Array(sizeInConcatAxis.length).keys()).map(i => `uniforms.sizeInConcatAxis${i}`).join(',');\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  ${(() => {\n    shaderHelper.registerUniform('outputSize', 'u32');\n    for (let i = 0; i < inputs.length; i++) {\n      shaderHelper.registerUniform(`sizeInConcatAxis${i}`, 'u32');\n    }\n    return shaderHelper.declareVariables(...inputVars, output);\n  })()}\n\n  ${calculateInputIndexImpl(sizeInConcatAxis.length, sizeInConcatAxisStr)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes('uniforms.outputSize')}\n\n    var indices = ${output.offsetToIndices('global_idx')};\n\n    let inputIndex = calculateInputIndex(${indicesAxis});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}u>(${sizeInConcatAxisStr});\n      ${indicesAxis} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${assignOutputData(inputVars, output)}\n  }`;\n\n  return {\n    name: 'Concat',\n    shaderCache: {hint: `${axis}`, inputDependencies},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n      programUniforms,\n    }),\n    getShaderSource,\n  };\n};\n\nexport const concat = (context: ComputeContext, attributes: ConcatAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createConcatProgramInfo(context.inputs, attributes.axis));\n};\n\nexport const parseConcatAttributes = (attributes: Record<string, unknown>): ConcatAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {MAX_CLIP, MIN_CLIP} from '../../util';\n\nexport interface InternalActivationAttributes {\n  readonly activation: string;\n  readonly clipMin?: number;\n  readonly clipMax?: number;\n  readonly activationCacheKey: string;\n}\n\nexport const getActivationSnippet = (attributes: InternalActivationAttributes, valueType: string):\n    {activationFunction: string; applyActivation: string} => {\n      switch (attributes.activation) {\n        case 'Relu':\n          return {activationFunction: '', applyActivation: `value = max(value, ${valueType}(0.0));`};\n        case 'Sigmoid':\n          return {\n            activationFunction: '',\n            applyActivation: `value = (${valueType}(1.0) / (${valueType}(1.0) + exp(-value)));`\n          };\n        case 'Clip':\n          return {\n            activationFunction: `const clip_min_=${valueType}(${attributes.clipMin!});const clip_max_=${valueType}(${\n                attributes.clipMax!});`,\n            applyActivation: 'value = clamp(value, clip_min_, clip_max_);'\n          };\n          // TODO: adding other activations that can be fused.\n        default:\n          return {activationFunction: '', applyActivation: ''};\n      }\n    };\n\nexport const parseInternalActivationAttributes =\n    (attributes: Record<string, unknown>|undefined): InternalActivationAttributes => {\n      const activation = attributes?.activation as string || '';\n\n      if (activation === 'Clip') {\n        const [clipMin, clipMax] = attributes?.activation_params as [number, number] || [MIN_CLIP, MAX_CLIP];\n        return {activation, clipMax, clipMin, activationCacheKey: `${activation}:${clipMin},${clipMax}`};\n      }\n      return {activation, activationCacheKey: activation};\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/activation_util.ts\n//\n// modified to fit the needs of the project\n\nexport const typeSnippet = (component: number, dataType: string) => {\n  switch (component) {\n    case 1:\n      return dataType;\n    case 2:\n      return `vec2<${dataType}>`;\n    case 3:\n      return `vec3<${dataType}>`;\n    case 4:\n      return `vec4<${dataType}>`;\n    default:\n      throw new Error(`${component}-component is not supported.`);\n  }\n};\n\nexport const biasSnippet = (hasBias: boolean): string => `\n      ${hasBias ? 'value = value + getBiasByOutputCoords(coords);' : ''}\n      `;\n", "/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-core/src/ops/conv_util.ts\n//\n// modified to fit the needs of the project\n\nexport const utilFunctions = `\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    outShapeStrides.x, outShapeStrides.y, outShapeStrides.z, 1));\n}\n`;\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/matmul_packed_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {getBroadcastDims, IndicesHelper, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {getActivationSnippet, InternalActivationAttributes} from '../fuse-utils';\n\nimport {typeSnippet} from './activation_util';\n\nconst writeDataToSubAVec4Snippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${batchDims ? ', batchIndices' : ''});\n        `;\n  }\n};\n\nconst calculateResultSnippet = (transposeA: boolean, innerElementSize: number) => {\n  if (transposeA) {\n    return `\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${innerElementSize === 3 ? '' : 'let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];'}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached3[i] + acc[i];'}\n        }`;\n  } else {\n    return `\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${innerElementSize === 3 ? '' : 'acc[i] = BCached3 * ACached.w + acc[i];'}\n        }`;\n  }\n};\n\nexport const makeMatMulPackedVec4Source =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32): string => {\n      const tileAOuter = workgroupSize[1] * workPerThread[1];\n      const tileBOuter = workgroupSize[0] * workPerThread[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n      const innerElementSize = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n\n      if (!(((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n             (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n            tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4)) {\n        throw new Error(`If transposeA ${transposeA} is true, innerElementSize ${\n            innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n      Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n  tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${\n            tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${\n            workPerThread[0]} must be 4.`);\n      }\n      return `\nvar<workgroup> mm_Asub: array<array<vec${innerElementSize}<${type}>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${type}>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\nconst rowPerThread = ${workPerThread[1]};\nconst colPerThread = ${workPerThread[0]};\nconst innerElementSize = ${innerElementSize};\nconst tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n  ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(dimInner - 1) / tileInner + 1'};\n  var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n  var acc: array<vec4<${type}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${rowPerThreadB};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${writeDataToSubAVec4Snippet(transposeA, batchDims)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${\n          batchDims ? ', batchIndices' : ''});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${innerElementSize === 3 ? '' : 'let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];'}\n\n          ${calculateResultSnippet(transposeA, innerElementSize)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`;\n    };\n\nconst writeDataToSubASnippet = (transpose: boolean, batchDims?: IndicesHelper) => {\n  if (transpose) {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n\n  } else {\n    return `\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${batchDims ? ', batchIndices' : ''});\n            `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) =>\n    transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' : 'let ACached = mm_Asub[tileRow + innerRow][k];';\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport const makeMatMulPackedSource =\n    (workPerThread: number[], workgroupSize: [number, number, number], type = 'f32', batchDims?: IndicesHelper,\n     transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n     sequentialAccessByThreads = false): string => {\n      const tileAOuter = workPerThread[1] * workgroupSize[1];\n      const tileBOuter = workPerThread[0] * workgroupSize[0];\n      const tileAWidth = transposeA ? tileAOuter : tileInner;\n      const tileAHight = transposeA ? tileInner : tileAOuter;\n\n      if (!(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 &&\n            tileInner % workgroupSize[1] === 0)) {\n        throw new Error(`tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n            workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n            workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n      }\n      const rowPerThreadA = tileAHight / workgroupSize[1];\n      const colPerThreadA = tileAWidth / workgroupSize[0];\n      const rowPerThreadB = tileInner / workgroupSize[1];\n      const matmulSnippet = sequentialAccessByThreads ?\n          `\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n    let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n        for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n          ${writeDataToSubASnippet(transposeA, batchDims)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n            for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${batchDims ? ', batchIndices' : ''});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${type}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${\n              transposeA ? `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n                           `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    ` :\n          `\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\nlet tileRowA = i32(localId.y) * ${rowPerThreadA};\nlet tileColA = i32(localId.x) * ${colPerThreadA};\nlet tileRowB = i32(localId.y) * ${rowPerThreadB};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${writeDataToSubASnippet(transposeA, batchDims)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${batchDims ? ', batchIndices' : ''});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${type}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${readDataFromSubASnippet(transposeA)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;\n\n      return `\n  var<workgroup> mm_Asub : array<array<${type}, ${tileAWidth}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<${type}, ${tileBOuter}>, ${tileInner}>;\n  const rowPerThread = ${workPerThread[1]};\n  const colPerThread = ${workPerThread[0]};\n  const tileInner = ${tileInner};\n\n@compute @workgroup_size(${workgroupSize[0]}, ${workgroupSize[1]}, ${workgroupSize[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    ${batchDims ? `let batchIndices = ${batchDims.offsetToIndices('u32(batch)')};` : ''}\n    let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : '(dimInner - 1) / tileInner + 1'};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc : array<array<${type}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${matmulSnippet}\n  }\n`;\n    };\n\nconst matMulReadWriteFnSource =\n    (component: number, hasBias: boolean, applyActivation: string, variables: IndicesHelper[],\n     batchShapes: Array<readonly number[]>, isChannelsLast = false): string => {\n      const batchAShape = batchShapes[0];\n      const batchBShape = batchShapes[1];\n      const batchShape = batchShapes[2];\n      const batchVariable = variables[0];\n      const aVariable = variables[1];\n      const bVariable = variables[2];\n      const outputVariable = variables[3];\n      const broadCastADims = getBroadcastDims(batchAShape, batchShape);\n      const broadCastBDims = getBroadcastDims(batchBShape, batchShape);\n      const dataType = tensorTypeToWsglStorageType(variables[0].type.tensor);\n      const getAIndices = () => {\n        const aRank = aVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var aIndices: ${aVariable.type.indices};`;\n        for (let i = aRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\naIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastADims.forEach(i => {\n          resStr += `\\naIndices[${i}] = 0;`;\n        });\n        resStr += `\\naIndices[${aRank - 2}] = u32(row);\n                   aIndices[${aRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const getBIndices = () => {\n        const bRank = bVariable.rank;\n        const batchRank = batchVariable.rank;\n        let resStr = `var bIndices: ${bVariable.type.indices};`;\n        for (let i = bRank - 2 - 1, j = batchRank - 1; i >= 0; i--, j--) {\n          resStr += `\\nbIndices[${i}] = ${batchRank > 1 ? `batchIndices[${j}]` : 'batchIndices'};`;\n        }\n        broadCastBDims.forEach(i => {\n          resStr += `\\nbIndices[${i}] = 0;`;\n        });\n        resStr += `\\nbIndices[${bRank - 2}] = u32(row);\n                   bIndices[${bRank - 1}] = u32(colIn);`;\n        return resStr;\n      };\n      const source = `\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < dimAOuter && col < dimInner)\n      {\n        ${getAIndices()}\n        value = ${aVariable.getByIndices('aIndices')};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${batchVariable.type.indices}) -> ${\n          typeSnippet(component, dataType)} {\n      var value = ${typeSnippet(component, dataType)}(0.0);\n      let col = colIn * ${component};\n      if(row < dimInner && col < dimBOuter)\n      {\n        ${getBIndices()}\n        value = ${bVariable.getByIndices('bIndices')};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${typeSnippet(component, dataType)}) {\n      let col = colIn * ${component};\n      if (row < dimAOuter && col < dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${\n          hasBias ?\n              `value = value + ${isChannelsLast ? 'bias[colIn]' : `${typeSnippet(component, dataType)}(bias[row])`};` :\n                                                  ''                                    }\n        ${applyActivation}\n        ${outputVariable.setByIndices('vec3<u32>(coords)', 'value')}\n      }\n    }\n    `;\n      return source;\n    };\n\nexport const createMatmulProgramInfo =\n    (inputs: readonly TensorView[], activationAttributes: InternalActivationAttributes, outputShape: readonly number[],\n     reshapedOutputShape?: readonly number[],\n     isChannelsLast = false /* only used for conv2dByMatMul*/): ProgramInfo => {\n      const aShape = inputs[0].dims;\n      const bShape = inputs[1].dims;\n\n      const outerDimsA = aShape.slice(0, -2);\n      const outerDimsB = bShape.slice(0, -2);\n      const outerDims = reshapedOutputShape ? reshapedOutputShape.slice(0, -2) : outputShape.slice(0, -2);\n      const batchDims = inputVariable('batchDims', inputs[0].dataType, outerDims);\n      const variables = [batchDims];\n      const batchShapes = [outerDimsA, outerDimsB, outerDims];\n      const batchSize = ShapeUtil.size(outerDims);\n\n      const dimAOuter = aShape[aShape.length - 2];\n      const dimInner = aShape[aShape.length - 1];\n      const dimBOuter = bShape[bShape.length - 1];\n      const isVec4 = dimInner % 4 === 0 && dimBOuter % 4 === 0;\n\n      // TODO: fine tune size\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const workgroupSize: [number, number, number] = [8, 8, 1];\n      const dispatch = [\n        Math.ceil(dimBOuter / workgroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dimAOuter / workgroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workgroupSize[2] / elementsPerThread[2])\n      ];\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const components = isVec4 ? 4 : 1;\n      const A = inputVariable('a', inputs[0].dataType, [...outerDimsA, dimAOuter, dimInner / components], components);\n      const B = inputVariable('b', inputs[1].dataType, [...outerDimsB, dimInner, dimBOuter / components], components);\n      const output =\n          outputVariable('result', inputs[0].dataType, [batchSize, dimAOuter, dimBOuter / components], components);\n      variables.push(A);\n      variables.push(B);\n      variables.push(output);\n      const inputVariables = [A, B];\n      const hasBias = inputs.length > 2;\n      const {activationFunction, applyActivation} = getActivationSnippet(activationAttributes, output.type.value);\n      const declareFunctions =\n          matMulReadWriteFnSource(components, hasBias, applyActivation, variables, batchShapes, isChannelsLast);\n      if (hasBias) {\n        const biasComponents = isChannelsLast ? components : 1;\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, inputs[2].dims, biasComponents));\n      }\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const dimAOuter: i32 = ${dimAOuter};\n  const dimBOuter: i32 = ${dimBOuter};\n  const dimInner: i32 = ${dimInner};\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${activationFunction}\n  ${declareFunctions}\n  ${\n          isVec4 ? makeMatMulPackedVec4Source(elementsPerThread, workgroupSize, dataType, batchDims) :\n                   makeMatMulPackedSource(elementsPerThread, workgroupSize, dataType, batchDims)}\n                   ${batchDims.impl()}`;\n      return {\n        name: 'MatMul',\n        shaderCache: {hint: activationAttributes.activationCacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]}\n        }),\n        getShaderSource,\n      };\n    };\n", "/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv2d_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {tensorTypeToWsglStorageType} from '../common';\nimport {ConvAttributes} from '../conv';\nimport {getActivationSnippet} from '../fuse-utils';\n\nimport {biasSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dCommonSnippet =\n    (isChannelsLast: boolean, fitAOuter: boolean, fitBOuter: boolean, fitInner: boolean, addBias = false,\n     attributes: ConvAttributes, innerElementSizeX = 4, innerElementSizeW = 4, innerElementSize = 4,\n     dataType = 'f32'): string => {\n      const getXSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'resData = x[xIndex];';\n          case 3:\n            return `resData = vec3<${dataType}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;\n          case 4:\n            return 'resData = x[xIndex / 4];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return w[row * wShape[3] + colIn];';\n          case 4:\n            return 'return w[row * wShape[3] / 4 + colIn];';\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    ` :\n                                             `\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'xShape[1]' : 'xShape[2]';\n      const xWidth = isChannelsLast ? 'xShape[2]' : 'xShape[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n      const readXSnippet = `\n    let inChannels = wShape[2];\n    let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n    let outRow = ${row} / outWidth;\n    let outCol = ${row} % outWidth;\n\n    let WRow = ${col} / (filterDims[1] * inChannels);\n    let WCol = ${col} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${col} % inChannels;\n    var resData = ${typeSnippet(innerElementSizeX, dataType)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${xHeight} && xCol >= 0 && xCol < ${xWidth}) {\n      ${coordASnippet}\n      let xIndex = getIndexFromCoords4D(coord, xShape);\n      ${getXSnippet(innerElementSizeX)}\n    }\n    return resData;`;\n\n      const sampleX = isChannelsLast ? (fitAOuter && fitInner ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < dimAOuter && col < dimInner) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`) :\n                                       (fitInner && fitBOuter ? `\n    let col = colIn * ${innerElementSizeX};\n    ${readXSnippet}` :\n                                                                `\n    let col = colIn * ${innerElementSizeX};\n    if (row < dimInner && col < dimBOuter) {\n      ${readXSnippet}\n    }\n    return ${typeSnippet(innerElementSizeX, dataType)}(0.0);`);\n\n      const sampleW = `${getWSnippet(innerElementSizeW)}`;\n\n      const resType = typeSnippet(innerElementSize, dataType);\n      const aType =\n          isChannelsLast ? typeSnippet(innerElementSizeX, dataType) : typeSnippet(innerElementSizeW, dataType);\n      const bType =\n          isChannelsLast ? typeSnippet(innerElementSizeW, dataType) : typeSnippet(innerElementSizeX, dataType);\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, resType);\n      const userCode = `\n    ${activationFunction}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${aType} {\n      ${isChannelsLast ? sampleX : sampleW}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${bType} {\n      ${isChannelsLast ? sampleW : sampleX}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${resType}) {\n      let col = colIn * ${innerElementSize};\n      if (row < dimAOuter && col < dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      ${coordResSnippet}\n      ${biasSnippet(addBias)}\n      ${applyActivation}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`;\n      return userCode;\n    };\n\nexport const createConv2DMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes, outputShape: readonly number[], dimAOuter: number,\n     dimBOuter: number, dimInner: number, hasBias: boolean, sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      // TODO: enable vec4 for NCHW\n      const isVec4 = isChannelsLast && (inChannels % 4 === 0 || inChannels % 3 === 0) && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = [8, 8, 1];\n      const elementsPerThread = dimAOuter <= 8 ? [4, 1, 1] : [4, 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv2d_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? (isChannelsLast && inChannels % 4 !== 0 ? 3 : 4) : elementsPerThread[0];\n\n      const tileAOuter = workGroupSize[1] * elementsPerThread[1];\n      const tileBOuter = workGroupSize[0] * elementsPerThread[0];\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n      const fitAOuter = dimAOuter % tileAOuter === 0;\n      const fitBOuter = dimBOuter % tileBOuter === 0;\n      const fitInner = dimInner % tileInner === 0;\n\n      const elementsSize = isVec4 ? [innerElementSize, 4, 4] : [1, 1, 1];\n      const t = tensorTypeToWsglStorageType(inputs[0].dataType);\n\n      const declareInputs = [\n        `@group(0) @binding(0) var<storage, read> x: array<${isVec4 && innerElementSize === 4 ? `vec4<${t}>` : t}>;`,\n        `@group(0) @binding(1) var<storage, read> w: array<${isVec4 ? `vec4<${t}>` : t}>;`\n      ];\n      let declareFunctions = `\n      fn setOutputAtIndex(flatIndex : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        result[flatIndex] = ${isVec4 ? `vec4<${t}>` : t}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${isVec4 ? `vec4<${t}>` : t}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${isVec4 ? '/ 4' : ''}, value);\n      }`;\n      if (hasBias) {\n        declareInputs.push(`@group(0) @binding(2) var<storage, read> bias: array<${isVec4 ? `vec4<${t}>` : t}>;`);\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? `vec4<${t}>` : t} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n\n      return {\n        name: 'Conv2DMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n        }),\n        getShaderSource: () => `\n        ${utilFunctions}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${declareInputs.join('')}\n        @group(0) @binding(${declareInputs.length}) var<storage, read_write> result: array<${\n            isVec4 ? `vec4<${t}>` : t}>;\n        //@group(0) @binding(${declareInputs.length + 1}) var<uniform> uniforms: Uniforms;\n\n        const xShape : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const wShape : vec4<i32> = vec4<i32>(${inputs[1].dims.join(',')});\n        const outShape : vec4<i32> = vec4<i32>(${outputShape.join(',')});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${ShapeUtil.computeStrides(outputShape).slice(0, 3).join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[0]}, ${attributes.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${attributes.pads[0]}, ${attributes.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${\n            conv2dCommonSnippet(\n                isChannelsLast, fitAOuter, fitBOuter, fitInner, hasBias, attributes, elementsSize[0], elementsSize[1],\n                elementsSize[2], t)}\n            ${\n            isVec4 ?\n                makeMatMulPackedVec4Source(elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner) :\n                makeMatMulPackedSource(\n                    elementsPerThread, workGroupSize, t, undefined, !isChannelsLast, tileInner, false, undefined,\n                    sequentialAccessByThreads)}`\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\nimport {calculateOutputShape, ConvAttributes} from './conv';\nimport {getActivationSnippet} from './fuse-utils';\n\n/**\n * naive grouped conv implementation, supports 1d/2d conv\n * @param squeezeOutputShapeFunction - an optional function to squeeze the output shape, only used in conv1d\n */\nexport const createGroupedConvProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      const processBias = hasBias ? 'value += b[output_channel];' : '';\n      const xShape = inputs[0].dims;\n      const wShape = inputs[1].dims;\n      const outputChannelsPerGroup = wShape[0] / attributes.group;\n\n      const isChannelLast = attributes.format === 'NHWC';\n      const outputShape = calculateOutputShape(\n          xShape, wShape, attributes.dilations, attributes.pads, attributes.strides, isChannelLast);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const output = outputVariable('output', inputs[0].dataType, outputShape);\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, output.type.value);\n      const x = inputVariable('x', inputs[0].dataType, xShape);\n      const w = inputVariable('w', inputs[1].dataType, wShape);\n      const inputVars = [x, w];\n      if (hasBias) {\n        inputVars.push(inputVariable('b', inputs[2].dataType, inputs[2].dims));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const strides: vec2<u32> = vec2(${attributes.strides[0]}u, ${attributes.strides[1]}u);\n  const pads: vec2<u32> = vec2(${attributes.pads[0]}u, ${attributes.pads[1]}u);\n\n  ${shaderHelper.declareVariables(...inputVars, output)}\n\n  ${activationFunction}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${isChannelLast ? 3 : 1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${isChannelLast ? 1 : 2}], outputIndices[${\n          isChannelLast ? 2 : 3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${outputChannelsPerGroup}u;\n\n    var value: ${output.type.value} = ${output.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${wShape[1]}u; wInChannel++) {\n      let input_channel = group_id * ${wShape[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${wShape[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${attributes.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${xShape[isChannelLast ? 1 : 2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${wShape[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${attributes.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${xShape[isChannelLast ? 2 : 3]}u) {\n            continue;\n          }\n\n          let xVal = ${\n          isChannelLast ? x.get('batch', 'xHeight', 'xWidth', 'input_channel') :\n                          x.get('batch', 'input_channel', 'xHeight', 'xWidth')};\n          let wVal = ${w.get('output_channel', 'wInChannel', 'wHeight', 'wWidth')};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${processBias}\n    ${applyActivation}\n    ${output.setByOffset('global_idx', 'value')}\n  }`;\n      return {\n        name: 'GroupedConv',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n        }),\n        getShaderSource,\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DMatMulProgramInfo} from './3rd-party/conv2d_mm_webgpu';\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\nimport {createGroupedConvProgramInfo} from './conv-grouped';\nimport {InternalActivationAttributes, parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nexport const calculateOutputShape =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[],\n     adjustPads: readonly number[], strides: readonly number[], isChannelLast: boolean): number[] => {\n      const batchSize = inputShape[0];\n      const inputSpatialShape = inputShape.slice(isChannelLast ? 1 : 2, isChannelLast ? 3 : 4);\n      const spatialRank = inputSpatialShape.length;\n      const outChannels = kernelShape[0];\n      const kernelSpatialShape = kernelShape.slice(2);\n      const dilatedKernelShape = kernelSpatialShape.map((v, i) => v + (v - 1) * (dilations[i] - 1));\n      const inputSpatialShapeWithPad = inputSpatialShape.map((v, i) => v + adjustPads[i] + adjustPads[i + spatialRank]);\n      const outputShape =\n          inputSpatialShapeWithPad.map((v, i) => Math.floor((v - dilatedKernelShape[i] + strides[i]) / strides[i]));\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n      return outputShape;\n    };\n\nexport interface ConvAttributes extends InternalActivationAttributes, AttributeWithCacheKey {\n  readonly autoPad: string;\n  readonly dilations: readonly number[];\n  readonly format: 'NHWC'|'NCHW';\n  readonly group: number;\n  readonly kernelShape: readonly number[];\n  readonly pads: readonly number[];\n  readonly strides: readonly number[];\n  readonly wIsConst: boolean;\n}\n\n// for transposing weight tensor from [M, C/group, KH, KW] to [KH, KW, C/group, M]\nconst weightTransposeAttribute = [2, 3, 1, 0];\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/master/docs/Operators.md#Conv\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support conv 1D and 2D');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[1] * attributes.group;\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[1].dims[0] !== inputs[2].dims[0])) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  // wrong dilations dimension\n  if (attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  // Wrong strides dimension\n  if (attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  if (attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  if (attributes.kernelShape.length !== 0 && attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n};\n\nconst getAdjustedConvAttributes = <T extends ConvAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n  const kernelShape = attributes.kernelShape.slice();\n  // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n  for (let i = 2; i < inputs[1].dims.length; ++i) {\n    if (kernelShape[i - 2] === 0) {\n      kernelShape[i - 2] = inputs[1].dims[i];\n    }\n  }\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPadsBasedOnAutoPad(\n      inputs[0].dims, attributes.strides, attributes.dilations, kernelShape, pads, attributes.format === 'NHWC',\n      attributes.autoPad);\n\n  // always return a new object so does not modify the original attributes\n  const newAttributes: T = Object.assign({}, attributes);\n  Object.assign(newAttributes, {kernelShape, pads, cacheKey: attributes.cacheKey});\n  return newAttributes;\n};\n\nexport const parseConvAttributes = (attributes: Record<string, unknown>): ConvAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad = ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernel_shape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.w_is_const as () => boolean)();\n\n  return createAttributeWithCacheKey(\n      {autoPad, format, dilations, group, kernelShape, pads, strides, wIsConst, ...activationAttributes});\n};\n\nconst conv2d = (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvAttributes): void => {\n  const adjustedAttributes = getAdjustedConvAttributes(attributes, inputs);\n\n  // check attributes\n\n  // const hasPreluActivationWeights = false; /* TODO: add support for prelu activation weights */\n  if (attributes.group !== 1) {\n    context.compute(createGroupedConvProgramInfo(inputs, adjustedAttributes));\n    return;\n  }\n\n  const isChannelsLast = attributes.format === 'NHWC';\n  const hasBias = inputs.length === 3;\n  const inputHeight = inputs[0].dims[isChannelsLast ? 1 : 2];\n  const inputWidth = inputs[0].dims[isChannelsLast ? 2 : 3];\n  const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n  const weightHeight = inputs[1].dims[2];\n  const weightWidth = inputs[1].dims[3];\n\n  const outputShape = calculateOutputShape(\n      inputs[0].dims, inputs[1].dims, attributes.dilations, adjustedAttributes.pads, attributes.strides,\n      isChannelsLast);\n  const outHeight = outputShape[isChannelsLast ? 1 : 2];\n  const outWidth = outputShape[isChannelsLast ? 2 : 3];\n  const outChannels = outputShape[isChannelsLast ? 3 : 1];\n\n  const sameSize = isChannelsLast && weightHeight === inputHeight && weightWidth === inputWidth &&\n      attributes.pads[0] === 0 && attributes.pads[1] === 0;\n  if (sameSize ||\n      (weightHeight === 1 && weightWidth === 1 && attributes.dilations[0] === 1 && attributes.dilations[1] === 1 &&\n       attributes.strides[0] === 1 && attributes.strides[1] === 1 && attributes.pads[0] === 0 &&\n       attributes.pads[1] === 0)) {\n    // conv2dByMatMul\n    const batch = outputShape[0];\n    let xReshaped, wReshaped, matmulOutputShape;\n    const matmulInputs = [];\n    if (isChannelsLast) {\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n      if (sameSize) {\n        const sharedDim = inputHeight * inputWidth * inputChannels;\n        xReshaped = inputs[0].reshape([1, batch, sharedDim]);\n        wReshaped = transposedWeight.reshape([1, sharedDim, outChannels]);\n        matmulOutputShape = [1, batch, outChannels];\n      } else {\n        xReshaped = inputs[0].reshape([batch, inputHeight * inputWidth, inputChannels]);\n        wReshaped = transposedWeight.reshape([1, inputChannels, outChannels]);\n        matmulOutputShape = [batch, outHeight * outWidth, outChannels];\n      }\n      matmulInputs.push(xReshaped);\n      matmulInputs.push(wReshaped);\n    } else {\n      xReshaped = inputs[0].reshape([batch, inputChannels, inputHeight * inputWidth]);\n      wReshaped = inputs[1].reshape([1, outChannels, inputChannels]);\n      matmulOutputShape = [batch, outChannels, outHeight * outWidth];\n      matmulInputs.push(wReshaped);\n      matmulInputs.push(xReshaped);\n    }\n    if (hasBias) {\n      matmulInputs.push(inputs[2]);\n    }\n    context.compute(\n        createMatmulProgramInfo(matmulInputs, adjustedAttributes, outputShape, matmulOutputShape, isChannelsLast),\n        {inputs: matmulInputs});\n    return;\n  }\n\n  // TODO: implement conv2dWithIm2Col()\n\n  const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n  // STEP.1: transpose weight\n  const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n      context.compute(\n          createTransposeProgramInfo(inputs[1], weightTransposeAttribute),\n          {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n  if (attributes.wIsConst && !context.kernelCustomData.wT) {\n    context.kernelCustomData.wT = transposedWeight;\n  }\n\n  // STEP.2: prepare reshaped inputs\n  const convInputs = [inputs[0], transposedWeight];\n  if (hasBias) {\n    convInputs.push(inputs[2]);\n  }\n\n  // STEP.3: compute matmul\n  const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n  const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n  const dimInner = weightHeight * weightWidth * inputChannels;\n  context.compute(\n      createConv2DMatMulProgramInfo(\n          convInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n          sequentialAccessByThreads),\n      {inputs: convInputs});\n};\n\nconst conv1d = (context: ComputeContext, attributes: ConvAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (context.inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  const pads = [0, attributes.pads[0], 0, attributes.pads[1]];\n  const strides = [1].concat(attributes.strides);\n  const dilations = [1].concat(attributes.dilations);\n  const kernelShape = [1].concat(attributes.kernelShape);\n  const adjustedAttributes = getAdjustedConvAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createGroupedConvProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] : []));\n};\n\nexport const conv = (context: ComputeContext, attributes: ConvAttributes): void => {\n  validateInputs(context.inputs, attributes);  // currently will fail if not conv1D/2D\n  if (context.inputs[0].dims.length === 3) {\n    conv1d(context, attributes);\n  } else {\n    conv2d(context, context.inputs, attributes);\n  }\n};\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_mm_webgpu.ts\n//\n// modified to fit the needs of the project\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {ConvTransposeAttributes} from '../conv-transpose';\nimport {getActivationSnippet} from '../fuse-utils';\n\nimport {biasSnippet, typeSnippet} from './activation_util';\nimport {utilFunctions} from './conv_util';\nimport {makeMatMulPackedSource, makeMatMulPackedVec4Source} from './matmul_packed_webgpu';\n\nconst conv2dTransposeCommonSnippet =\n    (isChannelsLast: boolean, addBias = false, attributes: ConvTransposeAttributes, innerElementSize = 4): string => {\n      const type = typeSnippet(innerElementSize, 'f32');\n      const getWSnippet = (innerElementSize: number) => {\n        switch (innerElementSize) {\n          case 1:\n            return 'return W[getIndexFromCoords4D(coord, wShape)];';\n          case 4:\n            return `\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;\n          default:\n            throw new Error(`innerElementSize ${innerElementSize} is not supported.`);\n        }\n      };\n      const coordASnippet = isChannelsLast ? `\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      ` :\n                                             `\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `;\n\n      const coordResSnippet = isChannelsLast ? `\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ` :\n                                               `\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `;\n\n      const xHeight = isChannelsLast ? 'outBackprop[1]' : 'outBackprop[2]';\n      const xWidth = isChannelsLast ? 'outBackprop[2]' : 'outBackprop[3]';\n      const row = isChannelsLast ? 'row' : 'col';\n      const col = isChannelsLast ? 'col' : 'row';\n\n      const readASnippet = `\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      let outRow = ${row} / outWidth;\n      let outCol = ${row} % outWidth;\n\n      let WRow = ${col} / (filterDims[1] * inChannels);\n      let WCol = ${col} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${xHeight}) || fract(xR) > 0.0) {\n        return ${type}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${xWidth}) || fract(xC) > 0.0) {\n        return ${type}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${col} % inChannels;\n      ${coordASnippet}\n      return x[getIndexFromCoords4D(coord, xShape)/${innerElementSize}];`;\n\n      const sampleA = isChannelsLast ? `\n      let col = colIn * ${innerElementSize};\n      if (row < dimAOuter && col < dimInner) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);` :\n                                       `\n      let col = colIn * ${innerElementSize};\n      if (row < dimInner && col < dimBOuter) {\n        ${readASnippet}\n      }\n      return ${type}(0.0);`;\n\n      const sampleW = `\n      let col = colIn * ${innerElementSize};\n      let inChannels = ${isChannelsLast ? 'outBackprop[3]' : 'outBackprop[1]'};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${\n          isChannelsLast ? 'row < dimInner && col < dimBOuter' :\n                           'row < dimInner && col < dimAOuter'}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${getWSnippet(innerElementSize)}\n      }\n      return ${type}(0.0);\n      `;\n\n      const {activationFunction, applyActivation} = getActivationSnippet(attributes, type);\n      const userCode = `\n      ${activationFunction}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleA : sampleW}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${type} {\n    ${isChannelsLast ? sampleW : sampleA}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${type}) {\n    let col = colIn * ${innerElementSize};\n    if (row < dimAOuter && col < dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${isChannelsLast ? 'outShape[2]' : 'outShape[3]'};\n      ${coordResSnippet}\n      ${biasSnippet(addBias)}\n      ${applyActivation}\n      result[getIndexFromCoords4D(coords, outShape)/${innerElementSize}] = value;\n    }\n  }`;\n      return userCode;\n    };\n\nexport const createConv2DTransposeMatMulProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes, outputShape: readonly number[],\n     dimAOuter: number, dimBOuter: number, dimInner: number, hasBias: boolean,\n     sequentialAccessByThreads: boolean): ProgramInfo => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const inChannels = isChannelsLast ? inputs[0].dims[3] : inputs[0].dims[1];\n      const batchSize = outputShape[0];\n      const outWidth = isChannelsLast ? outputShape[2] : outputShape[3];\n      const outHeight = isChannelsLast ? outputShape[1] : outputShape[2];\n      const outChannels = isChannelsLast ? outputShape[3] : outputShape[1];\n      const isVec4 =\n          isChannelsLast ? inChannels % 4 === 0 && outChannels % 4 === 0 : outWidth % 4 === 0 && outChannels % 4 === 0;\n\n      // TODO: fine tune size\n      const dispatchX = isChannelsLast ? outChannels : outWidth * outHeight;\n      const dispatchY = isChannelsLast ? outWidth * outHeight : outChannels;\n      const workGroupSize: [number, number, number] = isVec4 ?\n          [8, 8, 1] :\n          [(dispatchX <= 4 || dispatchY <= 4) ? 4 : 16, dispatchX > 4 && dispatchY <= 4 ? 4 : 16, 1];\n      const elementsPerThread =\n          isVec4 ? [4, 4, 1] : [dispatchX <= 4 ? 1 : 4, dispatchX > 4 && dispatchY <= 4 ? 1 : 4, 1];\n      const dispatch = [\n        Math.ceil(dispatchX / workGroupSize[0] / elementsPerThread[0]),\n        Math.ceil(dispatchY / workGroupSize[1] / elementsPerThread[1]),\n        Math.ceil(batchSize / workGroupSize[2] / elementsPerThread[2])\n      ];\n\n      LOG_DEBUG('verbose', () => `[conv_backprop_mm_webgpu] dispatch = ${dispatch}`);\n\n      const innerElementSize = isVec4 ? 4 : 1;\n      const tileInner = Math.max(workGroupSize[0] * innerElementSize, workGroupSize[1]);\n\n\n      const declareInputs = [\n        `@group(0) @binding(0) var<storage, read> x: array<${isVec4 ? 'vec4<f32>' : 'f32'}>;`,\n        '@group(0) @binding(1) var<storage, read> W: array<f32>;'\n      ];\n      let declareFunctions = '';\n      if (hasBias) {\n        declareInputs.push(`@group(0) @binding(2) var<storage, read> bias: array<${isVec4 ? 'vec4<f32>' : 'f32'}>;`);\n        declareFunctions += `\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${isVec4 ? 'vec4<f32>' : 'f32'} {\n          return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n        }`;\n      }\n      return {\n        name: 'Conv2DTransposeMatMul',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]}\n        }),\n        getShaderSource: () => `\n        ${utilFunctions}\n        ${declareInputs.join('\\n')}\n        @group(0) @binding(${declareInputs.length}) var<storage, read_write> result: array<${\n            isVec4 ? 'vec4<f32>' : 'f32'}>;\n        const outBackprop : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const xShape : vec4<i32> = vec4<i32>(${inputs[0].dims.join(',')});\n        const wShape : vec4<i32> = vec4<i32>(${inputs[1].dims.join(',')});\n        const outShape : vec4<i32> = vec4<i32>(${outputShape.join(',')});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${ShapeUtil.computeStrides(outputShape).slice(0, 3).join(',')});\n        const filterDims : vec2<i32> = vec2<i32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n            attributes.kernelShape[isChannelsLast ? 2 : 3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${\n            attributes.dilations[0] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n              ${\n            attributes.dilations[1] <= 1 ?\n                0 :\n                (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${\n            attributes.pads[0] + attributes.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${\n            attributes.pads[1] + attributes.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${attributes.strides[0]}, ${attributes.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n        const dimAOuter : i32 = ${dimAOuter};\n        const dimBOuter : i32 = ${dimBOuter};\n        const dimInner : i32 = ${dimInner};\n        ${declareFunctions}\n        ${conv2dTransposeCommonSnippet(isChannelsLast, hasBias, attributes, innerElementSize)}\n        ${\n            isVec4 ? makeMatMulPackedVec4Source(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner) :\n                     makeMatMulPackedSource(\n                         elementsPerThread, workGroupSize, 'f32', undefined, !isChannelsLast, tileInner, false,\n                         undefined, sequentialAccessByThreads)}`\n      };\n    };\n", "/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// sampled from [@tensorflow/tfjs] tfjs-backend-webgpu/src/conv_backprop_webgpu.ts\n\nimport {LOG_DEBUG} from '../../../log';\nimport {TensorView} from '../../../tensor-view';\nimport {ShapeUtil} from '../../../util';\nimport {ProgramInfo} from '../../types';\nimport {inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from '../common';\nimport {ConvTransposeAttributes} from '../conv-transpose';\n\nconst createConvTranspose2DOpProgramShaderSource =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     outputShape: readonly number[], hasBias: boolean, is1DimensionDispatch: boolean, isVec4 = false,\n     dataType: string): string => {\n      const isChannelsLast = attributes.format === 'NHWC';\n      const rowDim = isChannelsLast ? 1 : 2;\n      const colDim = isChannelsLast ? 2 : 3;\n      const channelDim = isChannelsLast ? 3 : 1;\n      const outputSize = ShapeUtil.size(outputShape);\n      const workPerThread = isVec4 ? 2 : 1;\n      const group = attributes.group;\n      const wShape = inputs[1].dims;\n      const inputChannelsPerGroup = wShape[0] / group;\n      const outputChannelsPerGroup = wShape[1];\n\n      let declareFunctions = `\n  fn setOutputAtIndex(flatIndex : u32, value : ${isVec4 ? `vec4<${dataType}>` : dataType}) {\n    result[flatIndex] = ${isVec4 ? `vec4<${dataType}>` : dataType}(value);\n  }`;\n      if (hasBias) {\n        declareFunctions += `\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${isVec4 ? `vec4<${dataType}>` : dataType} {\n      return bias[coords.${isChannelsLast ? 'w' : 'y'}${isVec4 ? '/ 4' : ''}];\n    }`;\n      }\n      const components = isVec4 ? 4 : 1;\n      const w = inputVariable('W', inputs[1].dataType, inputs[1].dims, components);\n      const dy = inputVariable('Dy', inputs[0].dataType, inputs[0].dims, components);\n      const inputVariables = [dy, w];\n      if (hasBias) {\n        inputVariables.push(inputVariable('bias', inputs[2].dataType, [outputShape[channelDim]], components));\n      }\n      const output = outputVariable('result', inputs[0].dataType, outputShape, components);\n      const codeSnippet4 = `{\n        let batch: u32 = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} / outShape[1];\n        let r = ${is1DimensionDispatch ? 'global_id.z' : 'workgroup_id.z'} % outShape[1];\n        let c = ${is1DimensionDispatch ? 'global_id.y' : 'workgroup_id.y'} * ${workPerThread};\n        let d1: u32 = ${is1DimensionDispatch ? 'global_id.x' : 'workgroup_id.x'} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${dataType}>, ${workPerThread}>;\n        for (var i = 0; i < ${workPerThread}; i++) {\n          dotProd[i] = vec4<${dataType}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${dataType}(dyCorner.x) + ${dataType}(wR)) / ${dataType}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${dataType}(dyCorner.y) + ${dataType}(wC)) / ${dataType}(strides.y);\n            let dyC2 = (${dataType}(dyCorner.y) + 1.0 + ${dataType}(wC)) / ${dataType}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${dataType}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n\n                dotProd[1] = dotProd[1] + vec4<${dataType}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${channelDim}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1', 'd2')};\n                let wValue1 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 1', 'd2')};\n                let wValue2 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 2', 'd2')};\n                let wValue3 = ${w.get('u32(wRPerm)', 'u32(wCPerm)', 'd1 + 3', 'd2')};\n\n                var xValue = ${dy.get('batch', 'idyR', 'idyC2', 'd2')};\n                let tmpval = vec4<${dataType}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${workPerThread}; i = i + 1) {\n          let value = dotProd[i] + ${hasBias ? 'bias[c+i]' : '0.0'};\n          ${output.set('batch', 'r', 'c + i', 'd1', 'value')};\n        }\n      }`;\n      const codeSnippet = `\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let batch = ${output.indicesGet('outputIndices', 0)};\n          let d1 = ${output.indicesGet('outputIndices', channelDim)};\n          let r = ${output.indicesGet('outputIndices', rowDim)};\n          let c = ${output.indicesGet('outputIndices', colDim)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${outputChannelsPerGroup};\n          let wOutChannel = d1 - groupId * ${outputChannelsPerGroup};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${dataType}(dyRCorner) + ${dataType}(wR)) / ${dataType}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${dataType}(outBackprop[${rowDim}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${dataType}(dyCCorner) + ${dataType}(wC)) / ${dataType}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${dataType}(outBackprop[${colDim}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${inputChannelsPerGroup};\n              for (var d2: u32 = 0; d2 < ${inputChannelsPerGroup}; d2 = d2 + 1) {\n                let xValue = ${\n          isChannelsLast ? dy.get('batch', 'idyR', 'idyC', 'inputChannel') :\n                           dy.get('batch', 'inputChannel', 'idyR', 'idyC')};\n                let wValue = ${w.get('inputChannel', 'wOutChannel', 'u32(wRPerm)', 'u32(wCPerm)')};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${hasBias ? 'bias[d1]' : '0.0'};\n          ${output.setByOffset('global_idx', 'value')};\n        `;\n\n      return `\n  ${shaderHelper.declareVariables(...inputVariables, output)}\n  ${declareFunctions}\n  const outShape : vec4<u32> = vec4<u32>(${outputShape.join(',')});\n  const outBackprop : vec4<u32> = vec4<u32>(${inputs[0].dims.join(',')});\n  const strides : vec2<u32> = vec2<u32>(${attributes.strides[0]}, ${attributes.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${attributes.kernelShape[isChannelsLast ? 1 : 2]}, ${\n          attributes.kernelShape[isChannelsLast ? 2 : 3]});\n  const dilations : vec2<u32> = vec2<u32>(${attributes.dilations[0]}, ${attributes.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${\n          attributes.dilations[0] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 1 : 2] - 1) * (attributes.dilations[0] - 1)},\n          ${\n          attributes.dilations[1] <= 1 ?\n              0 :\n              (attributes.kernelShape[isChannelsLast ? 2 : 3] - 1) * (attributes.dilations[1] - 1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${attributes.pads[0] + attributes.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${attributes.pads[1] + attributes.pads[3]})/2);\n    ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)};\n  ${isVec4 ? codeSnippet4 : codeSnippet}}`;\n    };\n\nexport const createConvTranspose2DProgramInfo =\n    (inputs: readonly TensorView[], attributes: ConvTransposeAttributes,\n     squeezeOutputShapeFunction?: (shape: readonly number[]) => number[]): ProgramInfo => {\n      const hasBias = inputs.length > 2;\n      // const isChannelsLast = attributes.format === 'NHWC';\n      const outputShape = attributes.outputShape;\n      const outputSize = ShapeUtil.size(outputShape);\n\n      // const inChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n      // TODO Enable isVec4 for performance\n      // Disabled due to weight matrix layout issue\n      // const isVec4 = attributes.group === 1 && isChannelsLast && inChannels % 4 === 0 && outChannels % 4 === 0;\n      const dispatch = [\n        Math.ceil(outputSize / 64),\n        1,\n        1,\n      ];\n      LOG_DEBUG('verbose', () => `[conv2d_backprop_webgpu] dispatch = ${dispatch}`);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      return {\n        name: 'ConvTranspose2D',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          dispatchGroup: {x: dispatch[0], y: dispatch[1], z: dispatch[2]},\n          outputs: [{\n            dims: squeezeOutputShapeFunction ? squeezeOutputShapeFunction(outputShape) : outputShape,\n            dataType: inputs[0].dataType\n          }]\n        }),\n        getShaderSource: (shaderHelper: ShaderHelper) => createConvTranspose2DOpProgramShaderSource(\n            shaderHelper, inputs, attributes, outputShape, hasBias, dispatch[1] === 1 && dispatch[2] === 1, false,\n            dataType),\n      };\n    };\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext} from '../types';\n\nimport {createConv2DTransposeMatMulProgramInfo} from './3rd-party/conv_backprop_mm_webgpu';\nimport {createConvTranspose2DProgramInfo} from './3rd-party/conv_backprop_webgpu';\nimport {ConvAttributes} from './conv';\nimport {parseInternalActivationAttributes} from './fuse-utils';\nimport {createTransposeProgramInfo} from './transpose';\n\nconst computeTotalPad =\n    (inDim: number, stride: number, adj: number, kernel: number, dilation: number, outSize: number) =>\n        (inDim - 1) * stride + adj + (kernel - 1) * dilation + 1 - outSize;\n\nconst distributePadding = (totalPad: number, autoPad: string, pads: number[], head: number, tail: number) => {\n  const smallPad = Math.floor(totalPad / 2);\n  if (autoPad === 'SAME_UPPER') {\n    pads[head] = smallPad;\n    pads[tail] = totalPad - smallPad;\n  } else if (autoPad === 'SAME_LOWER') {\n    pads[head] = totalPad - smallPad;\n    pads[tail] = smallPad;\n  }\n};\n\nconst calculateOutputShapeAndPads =\n    (inputShape: readonly number[], kernelShape: readonly number[], dilations: readonly number[], autoPad: string,\n     group: number, pads: number[], strides: readonly number[], isChannelLast: boolean, outputPadding: number[],\n     outputShape: number[]) => {\n      const spatialRank = inputShape.length - 2;\n      const updateOutputShape = outputShape.length === 0;\n      if (outputPadding.length === 0) {\n        for (let i = 0; i < spatialRank; ++i) {\n          outputPadding.push(0);\n        }\n      }\n      const batchSize = inputShape[0];\n      const outChannels = kernelShape[isChannelLast ? 3 : 1] * group;\n      for (let i = 0, j = inputShape.length - spatialRank - (isChannelLast ? 1 : 0); i < spatialRank; ++i, ++j) {\n        const inSize = inputShape[j];\n        const outSize = updateOutputShape ? inSize * strides[i] : outputShape[i];\n        const totalPad = computeTotalPad(inSize, strides[i], pads[i], kernelShape[j], dilations[i], outSize);\n        distributePadding(totalPad, autoPad, pads, i, i + spatialRank);\n        if (updateOutputShape) {\n          outputShape.push(\n              strides[i] * (inSize - 1) + outputPadding[i] + (kernelShape[j] - 1) * dilations[i] + 1 - pads[i] -\n              pads[i + spatialRank]);\n        }\n      }\n      outputShape.splice(0, 0, batchSize);\n      outputShape.splice(isChannelLast ? 3 : 1, 0, outChannels);\n    };\n\nexport interface ConvTransposeAttributes extends ConvAttributes {\n  readonly outputPadding: readonly number[];\n  readonly outputShape: readonly number[];\n}\n\n\nconst getAdjustedConvTransposeAttributes =\n    <T extends ConvTransposeAttributes>(attributes: T, inputs: readonly TensorView[]): T => {\n      const kernelShape = attributes.kernelShape.slice();\n      // if kernelShape is not specified in the attributes of this op, infer it from the weight tensor dims\n      if (attributes.kernelShape.length === 0 || attributes.kernelShape.reduce((a, b) => a * b, 1) === 0) {\n        kernelShape.length = 0;\n        for (let i = 2; i < inputs[1].dims.length; ++i) {\n          kernelShape.push(inputs[1].dims[i]);\n        }\n      }\n      const isChannelsLast = attributes.format === 'NHWC';\n      kernelShape.splice(0, 0, inputs[1].dims[0]);\n      kernelShape.splice(isChannelsLast ? 3 : 1, 0, inputs[1].dims[1]);\n\n      const pads = attributes.pads.slice();\n      const outputShape = attributes.outputShape.slice();\n      const outputPadding = attributes.outputPadding.slice();\n      const inputShape = inputs[0].dims;\n      let dilations = attributes.dilations.slice();\n      if (dilations.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        dilations = new Array(spatialRank).fill(1);\n      }\n      let strides = attributes.strides.slice();\n      if (strides.reduce((a, b) => a + b, 0) === 0) {\n        const spatialRank = inputs[0].dims.length - 2;\n        strides = new Array(spatialRank).fill(1);\n      }\n      // If outputShape is not specified in the attributes of this op, infer it from the parameters\n      // Similarly, automatically infer pads if not specified\n      calculateOutputShapeAndPads(\n          inputShape, kernelShape, dilations, attributes.autoPad, attributes.group, pads, strides, isChannelsLast,\n          outputPadding, outputShape);\n\n      // always return a new object so does not modify the original attributes\n      const newAttributes: T = Object.assign({}, attributes);\n      const cacheKey = attributes.cacheKey + [\n        kernelShape.join('n,'), pads.join(','), strides.join(','), outputPadding.join(','), outputShape.join(','),\n        dilations.join(',')\n      ].join('_');\n      Object.assign(newAttributes, {kernelShape, pads, outputPadding, outputShape, dilations, strides, cacheKey});\n      return newAttributes;\n    };\n\nexport const parseConvTransposeAttributes = (attributes: Record<string, unknown>): ConvTransposeAttributes => {\n  const activationAttributes = parseInternalActivationAttributes(attributes);\n  // TODO : Make this generic enough to compute default attributes for multi-dimensional conv\n  const format = attributes.format as 'NHWC' | 'NCHW';\n  const autoPad =\n      ['NOTSET', 'VALID', 'SAME_UPPER',\n       'SAME_LOWER'][typeof attributes.autoPad == 'undefined' ? 0 : attributes.autoPad as number];\n  const dilations = attributes.dilations as [number, number];\n  const group = attributes.group as number;\n  const kernelShape = attributes.kernelShape as [number, number];\n  const pads = attributes.pads as [number, number, number, number];\n  const strides = attributes.strides as [number, number];\n  const wIsConst = (attributes.wIsConst as () => boolean)();\n  const outputPadding = attributes.outputPadding as [number, number, number, number];\n  const outputShape = attributes.outputShape as [number, number];\n  return createAttributeWithCacheKey({\n    autoPad,\n    format,\n    dilations,\n    group,\n    kernelShape,\n    outputPadding,\n    outputShape,\n    pads,\n    strides,\n    wIsConst,\n    ...activationAttributes\n  });\n};\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n  // Refer to the below link for all input checks\n  // https://github.com/onnx/onnx/blob/main/docs/Operators.md#ConvTranspose\n  if (!inputs || (inputs.length !== 2 && inputs.length !== 3)) {\n    throw new Error('Conv requires 2 or 3 inputs');\n  }\n\n  // TODO : Need to add support for multi-dimensional conv\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('currently only support 2-dimensional conv');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error('filter does not have same dimension as input');\n  }\n\n  // FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\n  const dataChannel = inputs[0].dims[attributes.format === 'NHWC' ? inputs[0].dims.length - 1 : 1];\n  const filterInChannel = inputs[1].dims[0];\n  if (dataChannel !== filterInChannel) {\n    throw new Error('FILTER_IN_CHANNEL should be equal to DATA_CHANNEL');\n  }\n\n  const featureMaps = inputs[1].dims[1] * attributes.group;\n\n  // if bias is provided it should be 1D and the number of elements should be equal to the number of feature maps\n  if (inputs.length === 3 && (inputs[2].dims.length !== 1 || inputs[2].dims[0] !== featureMaps)) {\n    throw new Error('invalid bias');\n  }\n\n  const spatialRank = inputs[0].dims.length - 2;\n  const dilationsSet = attributes.dilations.reduce((a, b) => a + b, 0) > 0;\n  // wrong dilations dimension\n  if (dilationsSet && attributes.dilations.length !== spatialRank) {\n    throw new Error(`dilations should be ${spatialRank}D`);\n  }\n\n  const stridesSet = attributes.strides.reduce((a, b) => a + b, 0) > 0;\n  // Wrong strides dimension\n  if (stridesSet && attributes.strides.length !== spatialRank) {\n    throw new Error(`strides should be ${spatialRank}D`);\n  }\n\n  // Wrong pads dimension\n  const padsSet = attributes.pads.reduce((a, b) => a + b, 0) > 0;\n  if (padsSet && attributes.pads.length !== spatialRank * 2) {\n    throw new Error(`pads should be ${spatialRank * 2}D`);\n  }\n\n  // Wrong output padding dimension\n  if (attributes.outputPadding.length !== spatialRank && attributes.outputPadding.length !== 0) {\n    throw new Error(`output_padding should be ${spatialRank}D`);\n  }\n\n  // if kernelShape is specified, it's data length must be 2 less than dims length of the weights tensor\n  // (the first 2 dims are batch_size and channels)\n  const kernelShapeSet = attributes.kernelShape.reduce((a, b) => a + b, 0) > 0;\n  if (kernelShapeSet && attributes.kernelShape.length !== 0 &&\n      attributes.kernelShape.length !== inputs[1].dims.length - 2) {\n    throw new Error('invalid kernel shape');\n  }\n\n  // as with kernelShape, must have same number of spatial dims as input\n  if (attributes.outputShape.length !== 0 && attributes.outputShape.length !== inputs[0].dims.length - 2) {\n    throw new Error('invalid output shape');\n  }\n};\n\n// for transposing weight tensor from [C, M/group, KH, KW] to [KH, KW, M/group, C]\nconst weightTransposePerm = [2, 3, 1, 0];\n\nconst convTranspose2d =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: ConvTransposeAttributes): void => {\n      const adjustedAttributes = getAdjustedConvTransposeAttributes(attributes, inputs);\n      const isChannelsLast = attributes.format === 'NHWC';\n      const hasBias = inputs.length === 3;\n      if (adjustedAttributes.group !== 1) {\n        context.compute(createConvTranspose2DProgramInfo(inputs, adjustedAttributes));\n        return;\n      }\n      const outputShape = adjustedAttributes.outputShape;\n      const outHeight = outputShape[isChannelsLast ? 1 : 2];\n      const outWidth = outputShape[isChannelsLast ? 2 : 3];\n      const outChannels = outputShape[isChannelsLast ? 3 : 1];\n      const weightHeight = inputs[1].dims[2];\n      const weightWidth = inputs[1].dims[3];\n      const inputChannels = inputs[0].dims[isChannelsLast ? 3 : 1];\n\n      const dimAOuter = isChannelsLast ? outHeight * outWidth : outChannels;\n      const dimBOuter = isChannelsLast ? outChannels : outHeight * outWidth;\n      const dimInner = weightHeight * weightWidth * inputChannels;\n\n      const sequentialAccessByThreads = /* backend.adapterInfo.isIntel() */ true;\n\n\n      // STEP.1: transpose weight\n      const transposedWeight = (context.kernelCustomData.wT as TensorView | undefined) ??\n          context.compute(\n              createTransposeProgramInfo(inputs[1], weightTransposePerm),\n              {inputs: [1], outputs: [attributes.wIsConst ? -2 : -1]})[0];\n      if (attributes.wIsConst && !context.kernelCustomData.wT) {\n        context.kernelCustomData.wT = transposedWeight;\n      }\n\n      // STEP.2: prepare reshaped inputs\n      const convTransposeInputs = [inputs[0], transposedWeight];\n      if (hasBias) {\n        if (!isChannelsLast && inputs[2].dims.length === 1) {\n          convTransposeInputs.push(inputs[2].reshape([inputs[2].dims[0], 1, 1]));\n        } else {\n          convTransposeInputs.push(inputs[2]);\n        }\n      }\n\n      // STEP.3: compute matmul\n      context.compute(\n          createConv2DTransposeMatMulProgramInfo(\n              convTransposeInputs, adjustedAttributes, outputShape, dimAOuter, dimBOuter, dimInner, hasBias,\n              sequentialAccessByThreads),\n          {inputs: convTransposeInputs});\n    };\n\nconst convTranspose1d = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  // extend the input to 2D by adding H dimension\n  const isChannelLast = attributes.format === 'NHWC';\n\n  const inputs = [\n    context.inputs[0].reshape(\n        isChannelLast ?\n            // [N, W, C] -> [N, H=1, W, C]\n            [context.inputs[0].dims[0], 1, context.inputs[0].dims[1], context.inputs[0].dims[2]] :\n            // [N, C, W] -> [N, C, H=1, W]\n            [context.inputs[0].dims[0], context.inputs[0].dims[1], 1, context.inputs[0].dims[2]]),\n    //[FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kW] -> [FILTER_OUT_CHANNEL, FILTER_IN_CHANNEL, kH=1, kW]\n    context.inputs[1].reshape([context.inputs[1].dims[0], context.inputs[1].dims[1], 1, context.inputs[1].dims[2]])\n  ];\n  if (inputs.length === 3) {\n    inputs.push(context.inputs[2]);\n  }\n  let kernelShape = attributes.kernelShape;\n  if (kernelShape.length === 0 || kernelShape[0] === 0) {\n    kernelShape = [context.inputs[1].dims[2]];\n  }\n  let dilations = attributes.dilations;\n  if (dilations.length === 0 || dilations[0] === 0) {\n    dilations = [1];\n  }\n  let strides = attributes.strides;\n  if (strides.length === 0 || strides[0] === 0) {\n    strides = [1];\n  }\n  let pads = attributes.pads;\n  if (pads.length === 0) {\n    pads = [0, 0];\n  }\n  pads = [0, pads[0], 0, pads[1]];\n  strides = [1].concat(strides);\n  dilations = [1].concat(dilations);\n  kernelShape = [1].concat(kernelShape);\n  const adjustedAttributes =\n      getAdjustedConvTransposeAttributes({...attributes, pads, strides, dilations, kernelShape}, inputs);\n  context.compute(createConvTranspose2DProgramInfo(\n      inputs, adjustedAttributes,\n      outputShape => isChannelLast ? [outputShape[0], outputShape[2], outputShape[3]] :\n                                     [outputShape[0], outputShape[1], outputShape[3]]));\n};\n\nexport const convTranspose = (context: ComputeContext, attributes: ConvTransposeAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  if (context.inputs[0].dims.length === 3) {\n    convTranspose1d(context, attributes);\n  } else {\n    convTranspose2d(context, context.inputs, attributes);\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface EinsumAttributes extends AttributeWithCacheKey {\n  readonly equation: string;\n}\n// The equation attribute value is a string which consists of left hand side (LHS) and optionally right hand side (RHS)\n// separated by '->'. Ex. \"ij,jk -> ik\" expresses matrix multiplication\n//     \"ij->ji\" expresses matrix transpose\n//      \"ii->i\" diagonal elements of a square matrix\n// LHS consists of a sequence of terms separated by commas. Each term corresponds to an input variable.\n// Each symbol corresponds to a dimension in the input variable. The symbol can be either a letter, 'a' to 'z' or 'A' to\n// 'Z' or '...' to represent arbitrary dimensions.\n\nconst symbolPattern =\n    '[a-zA-Z]|\\\\.\\\\.\\\\.';  // The pattern each symbol in each term in the symbolic equation should match\nconst termPattern = '(' + symbolPattern + ')+';   // The pattern each term in the symbolic equation should match\nconst termPatternOnly = '^' + termPattern + '$';  // The patterns only matchs a term begin to end.\nconst lhsPattern = '(' + termPattern + ',)*' + termPattern;  // The pattern the LHS should match\nconst lhsPatternOnly = '^' + lhsPattern + '$';               // The patterns only matchs a LHS begin to end.\n\ninterface SymbolInfo {\n  count: number;           // Symbol corresponding to a dimmension of an input\n  inputIndices: number[];  // Number of input variables the symbol corresponds to\n  dimValue: number;        // Number of dimensions the symbol corresponds to\n}\n\nclass EinsumTerm {\n  constructor(inputIndex = -1) {\n    this.symbolToIndices = new Map<string, number[]>();\n    this.inputIndex = inputIndex;\n  }\n\n  // Add a symbol to the term\n  addSymbol(symbol: string, index: number) {\n    let value = this.symbolToIndices.get(symbol);\n    if (value === undefined) {\n      value = [index];\n    } else {\n      value.push(index);\n    }\n    this.symbolToIndices.set(symbol, value);\n  }\n\n  symbolToIndices: Map<string, number[]>;  // Map from symbol to dimensions of the input corresponding to the term\n  inputIndex: number;                      // -1 for output and 0, 1, 2, ... for inputs\n}\n\nclass EinsumEquation {\n  constructor(inputs: readonly TensorView[], public readonly equation: string) {\n    this.hasEllipsis = false;\n    this.symbolToInfo = new Map<string, SymbolInfo>();\n    this.lhs = new Array<EinsumTerm>();\n    this.outputDims = [];\n    // As rhs needs to be updated allow using let instead of const for both lhs and rhs.\n    // eslint-disable-next-line prefer-const\n    let [lhs, rhs] = equation.includes('->') ? equation.split('->', 2) : [equation, ''];\n    if (!lhs.match(RegExp(lhsPatternOnly))) {\n      throw new Error('Invalid LHS term');\n    }\n    const inputTerms = lhs.split(',');\n    inputTerms.forEach((inputTerm, index) => {\n      const dims = inputs[index].dims.slice();\n      if (!inputTerm.match(RegExp(termPatternOnly))) {\n        throw new Error('Invalid LHS term');\n      }\n      const einsumTerm = this.processTerm(inputTerm, true, dims, index);\n      this.lhs.push(einsumTerm);\n    });\n\n    // Initialize the RHS if not specified\n    if (rhs === '') {\n      // Construct RHS from LHS terms/symbols\n      rhs += [...this.symbolToInfo.entries()]\n                 .filter(([sym, info]) => (info.count === 1 || sym === '...'))\n                 .map(([sym]) => sym)\n                 .join('');\n    } else {\n      if (!rhs.match(RegExp(termPattern))) {\n        throw new Error('Invalid RHS');\n      }\n    }\n\n    // Compute output dims\n    const rhsSymbols = rhs.match(RegExp(symbolPattern, 'g'));\n    rhsSymbols?.forEach((symbol) => {\n      if (symbol === '...') {\n        this.outputDims = this.outputDims.concat(this.ellipsisDims);\n      } else {\n        const info = this.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid RHS symbol');\n        }\n        this.outputDims.push(info.dimValue);\n      }\n    });\n    this.rhs = this.processTerm(rhs, true, this.outputDims);\n  }  // End of EinsumEqation constructor\n\n  // Add a symbol to the equation\n  addSymbol(symbol: string, dimValue: number, inputIndex: number) {\n    let info = this.symbolToInfo.get(symbol);\n    if (info !== undefined) {\n      if (info.dimValue !== dimValue && info.count !== 1) {\n        throw new Error('Dimension mismatch');\n      } else {\n        info.count++;\n        info.inputIndices.push(inputIndex);\n      }\n    } else {\n      info = {count: 1, dimValue, inputIndices: [inputIndex]};\n    }\n    this.symbolToInfo.set(symbol, info);\n  }\n\n  // Process one input/output term\n  processTerm(term: string, isInput: boolean, dims: readonly number[], index = -1): EinsumTerm {\n    const rank = dims.length;\n    let ellipsis = false;\n    let ellipsisDims = [];\n    let nextDim = 0;\n    // For output empty string is allowed because the output may be reduced to a scalar value\n    if (!term.match(RegExp(termPatternOnly)) && (!isInput && term !== '')) {\n      throw new Error('Invalid LHS term');\n    }\n    const indexSymbols = term.match(RegExp(symbolPattern, 'g'));\n    const einsumTerm = new EinsumTerm(index);\n    // symbol can be either a lettre, 'a' to 'z' or 'A' to 'Z', or '...'\n    indexSymbols?.forEach((symbol: string, i: number) => {\n      if (symbol === '...') {\n        if (ellipsis) {\n          throw new Error('Only one ellipsis is allowed per input term');\n        }\n        ellipsis = true;\n        const ellipsisDimLength = rank - indexSymbols.length + 1;\n        if (ellipsisDimLength < 0) {\n          throw new Error('Ellipsis out of bounds');\n        }\n        ellipsisDims = dims.slice(nextDim, nextDim + ellipsisDimLength);\n        if (this.hasEllipsis) {\n          if (this.ellipsisDims.length !== ellipsisDims.length ||\n              this.ellipsisDims.toString() !== ellipsisDims.toString()) {\n            throw new Error('Ellipsis dimensions mismatch');\n          }\n        } else if (isInput) {\n          this.hasEllipsis = true;\n          this.ellipsisDims = ellipsisDims;\n        } else {\n          throw new Error('Ellipsis must be specified in the LHS');\n        }\n        // Add '0', '1', '2', '3', '4', etc to represent ellipsis dimensions to avoid special handling\n        for (let j = 0; j < ellipsisDims.length; j++) {\n          const symbol = String.fromCharCode('0'.charCodeAt(0) + i);\n          einsumTerm.addSymbol(symbol, i + j);\n          this.addSymbol(symbol, dims[nextDim++], index);\n        }\n      } else {\n        einsumTerm.addSymbol(symbol, i);\n        this.addSymbol(symbol, dims[nextDim++], index);\n      }\n    });\n    return einsumTerm;\n  }\n\n  symbolToInfo: Map<string, SymbolInfo>;  // All symbols in the equation\n  hasEllipsis: boolean;                   // The equation has ellipsis or not\n  ellipsisDims: number[];                 // The dimensions of the equation ellipsis corresponds to.\n  lhs: EinsumTerm[];                      // Terms on the left-hand side of the equation\n  rhs: EinsumTerm;                        // Term on the right-hand side of the equation\n  outputDims: number[];                   // Output dimensions of the equation\n}  // End of class EinsumEquation\n\nconst createEinsumProgramInfo = (inputs: readonly TensorView[], einsumEquation: EinsumEquation): ProgramInfo => {\n  const dataType = inputs[0].dataType;\n  const inputVars = new Array<IndicesHelper>(inputs.length);\n  for (let i = 0; i < inputs.length; ++i) {\n    inputVars[i] = inputVariable(`input${i}`, dataType, inputs[i].dims);\n  }\n  const outputShape = einsumEquation.outputDims;\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', dataType, outputShape);\n  const idxCopy: string[] = [];\n  const rhsSymbols = Array.from(einsumEquation.rhs.symbolToIndices.keys());\n  const initProd = 'var prod = 1.0;';\n  const initSum = 'var sum = 0.0;';\n  const updateSum = 'sum += prod;';\n  const reduceOpsSetIndices: string[] = [];\n  const reduceOpsLoopHeaders: string[] = [];\n  const reduceOpsLoopFooters: string[] = [];\n  const reduceOpCompute: string[] = [];\n  const isReduceOpsWithoutLoop = einsumEquation.symbolToInfo.size === rhsSymbols.length;\n  einsumEquation.symbolToInfo.forEach((info, symbol) => {\n    if (rhsSymbols.includes(symbol)) {\n      const outputIndex = rhsSymbols.indexOf(symbol);\n      einsumEquation.lhs.forEach((term, i) => {\n        if (info.inputIndices.includes(i)) {\n          const indices = term.symbolToIndices.get(symbol);\n          if (indices === undefined) {\n            throw new Error('Invalid symbol error');\n          }\n          indices.forEach((index) => {\n            idxCopy.push(`${\n                inputVars[i].indicesSet(`input${i}Indices`, index, output.indicesGet('outputIndices', outputIndex))}`);\n          });\n        }\n      });\n    } else {\n      einsumEquation.lhs.forEach((term, i) => {\n        const info = einsumEquation.symbolToInfo.get(symbol);\n        if (info === undefined) {\n          throw new Error('Invalid symbol error');\n        }\n        if (info.inputIndices.includes(i)) {\n          const indices = term.symbolToIndices.get(symbol);\n          if (indices === undefined) {\n            throw new Error('Invalid symbol error');\n          }\n          indices.forEach((index) => {\n            reduceOpsSetIndices.push(`${inputVars[i].indicesSet(`input${i}Indices`, index, `${symbol}`)}`);\n          });\n          reduceOpCompute.push(`prod *= ${inputVars[i].getByIndices(`input${i}Indices`)};`);\n        }\n      });\n      reduceOpsLoopHeaders.push(`for(var ${symbol}: u32 = 0; ${symbol} < ${\n          einsumEquation.symbolToInfo.get(symbol)?.dimValue}; ${symbol}++) {`);\n      reduceOpsLoopFooters.push('}');\n    }\n  });\n  const reduceOps = isReduceOpsWithoutLoop ?\n      [\n        ...idxCopy,\n        `let sum = ${inputVars.map((inputVar, i) => inputVar.getByIndices(`input${i}Indices`)).join(' * ')};`\n      ] :\n      [\n        ...idxCopy,\n        initSum,\n        ...reduceOpsLoopHeaders,\n        ...reduceOpsSetIndices,\n        initProd,\n        ...reduceOpCompute,\n        updateSum,\n        ...reduceOpsLoopFooters,\n      ];\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(...inputVars, output)}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        var outputIndices = ${output.offsetToIndices('global_idx')};\n        ${inputVars.map((inputVar, i) => `var input${i}Indices: ${inputVars[i].type.indices};`).join('\\n')}\n        ${reduceOps.join('\\n')};\n        ${output.setByOffset('global_idx', 'sum')};\n      }`;\n  return {\n    name: 'Einsum',\n    shaderCache: {hint: einsumEquation.equation},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const einsum = (context: ComputeContext, attributes: EinsumAttributes): void => {\n  const einsumEquation = new EinsumEquation(context.inputs, attributes.equation);\n  context.compute(createEinsumProgramInfo(context.inputs, einsumEquation));\n};\n\nexport const parseEinsumAttributes = (attributes: Record<string, unknown>): EinsumAttributes => {\n  const equation = (attributes.equation as string).replace(/\\s+/g, '');\n  return createAttributeWithCacheKey({equation});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Expand requires 2 input.');\n  }\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n\n  let shapeIndex = shape.length < inputShape.length ? 0 : shape.length - inputShape.length;\n  let inputShapeIndex = inputShape.length < shape.length ? 0 : inputShape.length - shape.length;\n  for (; shapeIndex < shape.length && inputShapeIndex < inputShape.length; ++shapeIndex, ++inputShapeIndex) {\n    if (shape[shapeIndex] !== inputShape[inputShapeIndex] && shape[shapeIndex] !== 1 &&\n        inputShape[inputShapeIndex] !== 1) {\n      throw new Error('Expand requires shape to be broadcastable to input');\n    }\n  }\n};\n\nconst getAdjustedShape = (shape1: readonly number[], shape2: readonly number[]): number[] => {\n  const diff = shape1.length - shape2.length;\n  const shape: number[] = [];\n  for (let i = 0; i < diff; ++i) {\n    shape.push(shape1[i]);\n  }\n  for (let i = 0; i < shape2.length; ++i) {\n    shape.push(shape2[i] === 1 ? shape1[i + diff] : shape2[i]);\n  }\n  return shape;\n};\n\nconst calculateOutputShape = (inputShape: readonly number[], shape: readonly number[]): number[] =>\n    (inputShape.length > shape.length) ? getAdjustedShape(inputShape, shape) : getAdjustedShape(shape, inputShape);\n\n\nconst createExpandProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const shape = Array.from(inputs[1].getBigInt64Array(), Number);\n  const outputShape: number[] = calculateOutputShape(inputShape, shape);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape);\n  const output = outputVariable('output', dataType, outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const inputShape = ${input.indices(...inputShape)};\n  ${shaderHelper.declareVariables(input, output)}\n  ${shaderHelper.mainStart()}\n  ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n    let outputIndices = ${output.offsetToIndices('global_idx')};\n    var inputIndices: ${input.type.indices};\n    for (var i = 0; i < ${inputShape.length}; i++) {\n      if (${input.indicesGet('inputShape', 'i')} == 1) {\n        ${input.indicesSet('inputIndices', 'i', 0)}\n      } else {\n        ${\n      input.indicesSet(\n          'inputIndices', 'i', output.indicesGet('outputIndices', `i + ${outputShape.length - inputShape.length}`))}\n      }\n    }\n    ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n  }`;\n  return {\n    name: 'Expand',\n    shaderCache: {hint: `${outputShape}`},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    })\n  };\n};\n\nexport const expand = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createExpandProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Gather requires 2 inputs.');\n  }\n};\n\nconst createGatherProgramInfo = (inputs: readonly TensorView[], attributes: GatherAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const indicesShape = inputs[1].dims;\n\n  const inputRank = inputShape.length;\n  const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n\n  const outputShape = inputShape.slice(0);\n  outputShape.splice(axis, 1, ...indicesShape);\n\n  const axisDimLimit = inputShape[axis];\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const data = inputVariable('data', inputs[0].dataType, inputs[0].dims);\n  const indices = inputVariable('inputIndices', inputs[1].dataType, inputs[1].dims);\n  const output = outputVariable('output', inputs[0].dataType, outputShape);\n  const calcDataIndices = (): string => {\n    const indicesRank = indicesShape.length;\n    let calcStr = `var indicesIndices  = ${indices.type.indices}(0);`;\n    for (let i = 0; i < indicesRank; i++) {\n      calcStr += `${indicesRank > 1 ? `indicesIndices[${i}]` : 'indicesIndices'} = ${\n          outputShape.length > 1 ? `outputIndices[${axis + i}]` : 'outputIndices'};`;\n    }\n    calcStr += `\n        var idx = ${indices.getByIndices('indicesIndices')};\n        if (idx < 0) {\n          idx = idx + ${axisDimLimit};\n        }\n        var dataIndices = ${data.type.indices}(0);\n      `;\n    for (let i = 0, j = 0; i < inputRank; i++) {\n      if (i === axis) {\n        calcStr += `${inputRank > 1 ? `dataIndices[${i}]` : 'dataIndices'} = u32(idx);`;\n        j += indicesRank;\n      } else {\n        calcStr += `${inputRank > 1 ? `dataIndices[${i}]` : 'dataIndices'} = ${\n            outputShape.length > 1 ? `outputIndices[${j}]` : 'outputIndices'};`;\n        j++;\n      }\n    }\n    return calcStr;\n  };\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(data, indices, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        let outputIndices = ${output.offsetToIndices('global_idx')};\n        ${calcDataIndices()};\n        let value = ${data.getByIndices('dataIndices')};\n        ${output.setByOffset('global_idx', 'value')};\n      }`;\n  return {\n    name: 'Gather',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [\n        {dims: outputShape, dataType: inputs[0].dataType},\n      ],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const parseGatherAttributes = (attributes: Record<string, unknown>): GatherAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gather = (context: ComputeContext, attributes: GatherAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface GatherElementsAttributes extends AttributeWithCacheKey {\n  axis: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('GatherElements requires 2 inputs.');\n  }\n\n  if (inputs[0].dims.length < 1) {\n    throw new Error('GatherElements requires that the data input be rank >= 1.');\n  }\n\n  if (inputs[0].dims.length !== inputs[1].dims.length) {\n    throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`);\n  }\n};\n\nconst createGatherElementsProgramInfo =\n    (inputs: readonly TensorView[], attributes: GatherElementsAttributes): ProgramInfo => {\n      const inputShape = inputs[0].dims;\n      const inputOutputDataType = inputs[0].dataType;\n      const inputRank = inputShape.length;\n      const inputStrides = ShapeUtil.computeStrides(inputShape);\n      const inputSize = ShapeUtil.size(inputShape);\n\n      const indicesShape = inputs[1].dims;\n      const indicesDataType = inputs[1].dataType;\n      const indicesSize = ShapeUtil.size(indicesShape);\n\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, inputRank);\n      const axisDimLimit = inputShape[axis];\n\n      const outputShape = indicesShape.slice(0);\n      const outputSize = ShapeUtil.size(outputShape);\n\n      const input = inputVariable('input', inputOutputDataType, inputShape);\n      const indices = inputVariable('indices', indicesDataType, [indicesSize]);\n      const output = outputVariable('output', inputOutputDataType, outputShape);\n\n\n      // int64 indices would be treated as little endian i32 with assumption they fall in i32 limits\n      // That assumption is safe as it's not possible to allocate >2gb buffer for input tensor\n      // Input data will be treated as u32 or two u32 for 8-byte tensors\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputStrides = array<u32, ${inputStrides.length}>(${inputStrides.map(i => `${i}u`).join(',')});\n      ${shaderHelper.declareVariables(input, indices, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n\n      var idx = ${indices.getByOffset('global_idx')};\n      if (idx < 0) {\n        idx = idx + ${axisDimLimit};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        if (i == ${axis}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${output.indicesGet('outputIndices', 'i')} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${inputSize}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;\n\n      return {\n        name: 'GatherElements',\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        }),\n        getShaderSource,\n      };\n    };\n\nexport const parseGatherElementsAttributes = (attributes: Record<string, unknown>): GatherElementsAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n\nexport const gatherElements = (context: ComputeContext, attributes: GatherElementsAttributes): void => {\n  const inputs = context.inputs;\n  validateInputs(inputs);\n  context.compute(createGatherElementsProgramInfo(context.inputs, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {GemmUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs) {\n    throw new Error('Input is missing');\n  }\n  if (inputs.length < 2 || inputs.length > 3) {\n    throw new Error('Invaid input number.');\n  }\n\n  // 'C' can be of dimensionality 0, 1 or 2 only\n  if (inputs.length === 3 && inputs[2].dims.length > 2) {\n    throw new Error('Invalid input shape of C');\n  }\n\n  if ((inputs[0].dataType !== inputs[1].dataType) ||\n      (inputs.length === 3 && inputs[0].dataType !== inputs[2].dataType)) {\n    throw new Error('Input types are mismatched');\n  }\n};\n\nexport interface GemmAttributes extends AttributeWithCacheKey {\n  transA: boolean;\n  transB: boolean;\n  alpha: number;\n  beta: number;\n}\n\nconst offsetC = (m: number, n: number, dims: readonly number[]): string => {\n  if (dims.length === 0) {\n    return '0u';\n  }\n\n  const broadcastM = (dims.length === 1 && m !== 1) || (dims.length === 2 && dims[0] !== m);\n  const broadcastN = dims[dims.length - 1] !== n;\n\n  let offset = '0u';\n  if (!broadcastM) {\n    offset += `+ m * ${dims[dims.length - 1]}u`;\n  }\n  if (!broadcastN) {\n    offset += '+n';\n  }\n\n  return offset;\n};\n\nconst createGemmProgramInfo = (inputs: readonly TensorView[], attributes: GemmAttributes): ProgramInfo => {\n  const aShape = inputs[0].dims.slice();\n  const bShape = inputs[1].dims.slice();\n  const [M, N, K] = GemmUtil.getShapeOfGemmResult(\n      aShape, attributes.transA, bShape, attributes.transB, inputs.length === 3 ? inputs[2].dims : undefined);\n  const outputShape = [M, N];\n  if (!outputShape) {\n    throw new Error('Can\\'t use gemm on the given tensors');\n  }\n  const outputSize = ShapeUtil.size(outputShape);\n  let line = '';\n  if (attributes.transA && attributes.transB) {\n    line = 'value += a[k * M + m] * b[n * K + k];';\n  } else if (attributes.transA && !attributes.transB) {\n    line = 'value += a[k * M + m] * b[k * N + n];';\n  } else if (!attributes.transA && attributes.transB) {\n    line = 'value += a[m * K + k] * b[n * K + k];';\n  } else if (!attributes.transA && !attributes.transB) {\n    line = 'value += a[m * K + k] * b[k * N + n];';\n  }\n\n  const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n  const calculateAlpha = attributes.alpha === 1 ? '' : 'value *= alpha;';\n  const calculateC = inputs.length === 3 ? `value += beta * c[${offsetC(M, N, inputs[2].dims)}];` : '';\n  const inputStorageBuffersDeclarations = [\n    `@group(0) @binding(0) var<storage, read> a : array<${dataType}>;`,\n    `@group(0) @binding(1) var<storage, read> b : array<${dataType}>;`\n  ];\n  if (inputs.length === 3) {\n    inputStorageBuffersDeclarations.push(`@group(0) @binding(2) var<storage, read> c : array<${dataType}>;`);\n  }\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const M: u32 = ${M}u;\n  const N: u32 = ${N}u;\n  const K: u32 = ${K}u;\n  const alpha = ${dataType}(${attributes.alpha});\n  const beta = ${dataType}(${attributes.beta});\n\n  ${inputStorageBuffersDeclarations.join('\\n')}\n  @group(0) @binding(${inputs.length}) var<storage, read_write> output : array<${dataType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${dataType}(0);\n    for (var k: u32 = 0u; k<${K}u; k++) {\n      ${line}\n    }\n\n    ${calculateAlpha}\n    ${calculateC}\n    output[global_id.x] = value;\n\n  }`;\n  return {\n    name: 'Gemm',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n    }),\n    getShaderSource,\n  };\n};\n\nexport const gemm = (context: ComputeContext, attributes: GemmAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createGemmProgramInfo(context.inputs, attributes));\n};\n\nexport const parseGemmAttributes = (attributes: Record<string, unknown>): GemmAttributes =>\n    createAttributeWithCacheKey(attributes as Omit<GemmAttributes, keyof AttributeWithCacheKey>);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, tensorTypeToWsglStorageType} from './common';\n\nexport interface InstanceNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n  format: 'NHWC'|'NCHW';\n}\n\nconst metadata = {\n  name: 'InstanceNormalization'\n};\n\nconst createInstanceNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: InstanceNormAttributes): ProgramInfo => {\n      const xShape = inputs[0].dims;\n\n      const outputShape = xShape;\n      const axis = 2;\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n      const C = xShape[1];\n      const x = inputVariable('x', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const scale = inputVariable('scale', inputs[1].dataType, inputs[1].dims);\n      const bias = inputVariable('bias', inputs[2].dataType, inputs[2].dims);\n      const output = outputVariable('output', inputs[0].dataType, [xShape[0], xShape[1], normSize]);\n      const variables = [x, scale, bias, output];\n      const dataType = x.type.value;\n      const workgroupSize = 64;\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n\n  const C: u32 = ${C};\n  const normSize: u32 = ${normSize};\n  const epsilon: f32 = ${attributes.epsilon};\n  var<workgroup> meanShared : ${dataType};\n  var<workgroup> squaredNormShared : ${dataType};\n  var<workgroup> workgroupShared : array<${dataType}, ${workgroupSize}>;\n  const workgroupSize = ${workgroupSize}u;\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart(workgroupSize)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${dataType} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${x.get('batch', 'channel', 'h')};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${dataType}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${x.get('batch', 'channel', 'h')} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${dataType}(normSize) + epsilon);\n    let channelScale = invStdDev * ${scale.getByOffset('channel')};\n    let channelShift = ${bias.getByOffset('channel')} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${x.get('batch', 'channel', 'h')} * channelScale + channelShift;\n      ${output.set('batch', 'channel', 'h', 'value')};\n    }\n  }`;\n      return {\n        ...metadata,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [\n            {dims: outputShape, dataType: inputs[0].dataType},\n          ],\n          dispatchGroup: {x: normCount}\n        }),\n        getShaderSource,\n      };\n    };\n\nconst computeMean =\n    (context: ComputeContext, input: TensorView, scale: TensorView, bias: TensorView, n: number, h: number, c: number,\n     epsilon: number) => {\n      const components = getMaxComponents(c);\n      const inputHelper = inputVariable('input', input.dataType, input.dims, components);\n      const scaleHelper = inputVariable('scale', scale.dataType, scale.dims, components);\n      const biasHelper = inputVariable('bias', bias.dataType, bias.dims, components);\n\n      const WG = 64;\n      // we will store channel scale and channel shift in [2, components] matrix\n      // or in vec2 when components == 1\n      const outputType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n      const sumCastType = components === 1 ? 'f32' : `vec${components}f`;\n      const setOutputValue = (var1: string, var2: string) => `${outputType}(${var1}, ${var2})`;\n      const unitsOfWork = n * c / components;\n      const wgSize = Math.ceil(h / WG);\n\n      const getMeanShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${h};\n  const C: u32 = ${c / components};\n  const imageSize: u32 = ${h * c / components};\n\n  ${shaderHelper.declareVariables(inputHelper)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${outputType}>;\n\n  ${shaderHelper.mainStart(WG)}\n    let currentImageNumber = global_idx / ${WG} / C;\n    let currentChannelNumber = (global_idx / ${WG}) % C;\n    let wgId = global_idx % ${WG};\n    let wgOffset = wgId * ${wgSize};\n    if (wgOffset >= H) {\n        return;\n    }\n    let wgMax = min(wgOffset + ${wgSize}, H);\n\n    let offset = currentImageNumber * imageSize + currentChannelNumber;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${sumCastType}(input[offset + i * C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${setOutputValue('sum', 'squaredSum')};\n  }`;\n\n      const meanValues = context.compute(\n          {\n            name: 'InstanceNormComputeMean',\n            shaderCache: {hint: JSON.stringify({components, n, h, c})},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, WG, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: n * c / components},\n            }),\n            getShaderSource: getMeanShaderSource,\n          },\n          {inputs: [input], outputs: [-1]})[0];\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${h};\n  const C: u32 = ${c / components};\n  const imageSize: u32 = ${WG * c / components};\n  const epsilon: f32 = ${epsilon};\n\n  @group(0) @binding(0) var<storage, read> input : array<${outputType}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${scaleHelper.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${biasHelper.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${outputType}>;\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(unitsOfWork)}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    let offset = currentImageNumber * imageSize;\n    var sum = ${fillVector('f32', components)};\n    var squaredSum = ${fillVector('f32', components)};\n    for (var i: u32 = 0; i < ${WG}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${WG}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(H);\n    squaredSum = squaredSum / f32(H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + epsilon);\n    let channelScale = invStdDev * ${sumCastType}(scale[currentChannelNumber]);\n    let channelShift = ${sumCastType}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${setOutputValue('channelScale', 'channelShift')};\n  }`;\n\n      return context.compute(\n          {\n            name: 'InstanceNormComputeChannelScaleShift',\n            shaderCache: {hint: JSON.stringify({components, n, h, c, epsilon})},\n            getRunData: () => ({\n              outputs: [\n                {dims: [n, c, 2], dataType: DataType.float},\n              ],\n              dispatchGroup: {x: Math.ceil(unitsOfWork / 64 /* workgroup size */)},\n            }),\n            getShaderSource,\n          },\n          {inputs: [meanValues, scale, bias], outputs: [-1]})[0];\n    };\n\nconst createInstanceNormNHWCProgramInfo =\n    (context: ComputeContext, inputs: readonly TensorView[], attributes: InstanceNormAttributes) => {\n      const xShape = inputs[0].dims;\n      const outputShape = xShape;\n      const N = xShape[0];\n      const C = xShape[xShape.length - 1];\n      const H = ShapeUtil.sizeFromDimension(xShape, 1) / C;\n\n      const components = getMaxComponents(C);\n      const outputSize = ShapeUtil.size(outputShape) / components;\n      const inputHelper = inputVariable('input', inputs[0].dataType, inputs[0].dims, components);\n      const outputHelper = outputVariable('output', inputs[0].dataType, outputShape, components);\n\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const scaleType = components === 1 ? 'vec2f' : `mat2x${components}f`;\n      const scaleCastType = components === 1 ? dataType : `vec${components}<${dataType}>`;\n      // first compute mean\n      const channelScaleShift = computeMean(context, inputs[0], inputs[1], inputs[2], N, H, C, attributes.epsilon);\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const H: u32 = ${H};\n  const C: u32 = ${C / components};\n\n  @group(0) @binding(0) var<storage, read> input : array<${inputHelper.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${scaleType}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${outputHelper.type.storage}>;\n\n  ${shaderHelper.mainStart()}\n    let currentImageNumber = global_idx / (C * H);\n    let currentChannelNumber = global_idx % C;\n\n    let scaleOffset = currentImageNumber * C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${scaleCastType}(scale[0]), ${scaleCastType}(scale[1]));\n  }`;\n      context.compute(\n          {\n            name: 'InstanceNormalization',\n            shaderCache: {hint: `${attributes.cacheKey}`},\n            getRunData: () => ({\n              outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n              dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n            }),\n            getShaderSource,\n          },\n          {inputs: [inputs[0], channelScaleShift]});\n    };\n\nexport const parseInstanceNormAttributes = (attributes: InstanceNormAttributes): InstanceNormAttributes =>\n    createAttributeWithCacheKey({epsilon: attributes.epsilon, format: attributes.format});\n\nexport const instanceNorm = (context: ComputeContext, attributes: InstanceNormAttributes): void => {\n  if (attributes.format === 'NHWC') {\n    createInstanceNormNHWCProgramInfo(context, context.inputs, attributes);\n  } else {\n    context.compute(createInstanceNormProgramInfo(context.inputs, attributes));\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType,} from './common';\n\nexport interface LayerNormAttributes extends AttributeWithCacheKey {\n  axis: number;\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 2) {\n    throw new Error('layerNorm requires at least 2 inputs.');\n  }\n};\n\nconst createLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: LayerNormAttributes, outputCount: number): ProgramInfo => {\n      const xShape = inputs[0].dims;\n      const scale = inputs[1];\n      const bias = inputs[2];\n\n      const outputShape = xShape;\n      const axis = ShapeUtil.normalizeAxis(attributes.axis, xShape.length);\n      const normCount = ShapeUtil.sizeToDimension(xShape, axis);\n      const normSize = ShapeUtil.sizeFromDimension(xShape, axis);\n\n      const scaleSize = ShapeUtil.size(scale.dims);\n      const biasSize = bias ? ShapeUtil.size(bias.dims) : 0;\n      if (scaleSize !== normSize || (bias && biasSize !== normSize)) {\n        throw new Error(`Size of X.shape()[axis:] == ${normSize}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${scaleSize} and bias size of ${biasSize}`);\n      }\n\n      const meanInvStdDevDim = [];\n      for (let i = 0; i < xShape.length; ++i) {\n        if (i < axis) {\n          meanInvStdDevDim.push(xShape[i]);\n        } else {\n          meanInvStdDevDim.push(1);\n        }\n      }\n\n      const components = getMaxComponents(normSize);\n      const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n      const variables = [\n        inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n        inputVariable('scale', scale.dataType, scale.dims, components),\n      ];\n      if (bias) {\n        variables.push(inputVariable('bias', bias.dataType, bias.dims, components));\n      }\n      variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n\n      const hasMeanDataOutput = outputCount > 1;\n      const hasInvStdOutput = outputCount > 2;\n\n      if (hasMeanDataOutput) {\n        variables.push(outputVariable('meanDataOutput', DataType.float, meanInvStdDevDim));\n      }\n      if (hasInvStdOutput) {\n        variables.push(outputVariable('invStdOutput', DataType.float, meanInvStdDevDim));\n      }\n\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n  const normSize: f32 = ${normSize};\n  const normSizeVectorized: u32 = ${normSize / components};\n  const epsilon: f32 = ${attributes.epsilon};\n\n  ${shaderHelper.declareVariables(...variables)}\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(normCount)}\n    let offset = global_idx * normSizeVectorized;\n    var meanVector = ${fillVector('f32', components)};\n    var meanSquareVector = ${fillVector('f32', components)};\n\n    for (var h: u32 = 0u; h < normSizeVectorized; h++) {\n      let value = ${castToF32(dataType, components, 'x[h + offset]')};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${sumVector('meanVector', components)} / normSize;\n    let meanSquare = sqrt(${sumVector('meanSquareVector', components)} \n      / normSize - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSizeVectorized; j++) {\n      let f32input = ${castToF32(dataType, components, 'x[j + offset]')};\n      let f32scale = ${castToF32(dataType, components, 'scale[j]')};\n      output[j + offset] = ${variables[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${bias ? `+ ${castToF32(dataType, components, 'bias[j]')}` : ''}\n      );\n    }\n\n    ${hasMeanDataOutput ? 'meanDataOutput[global_idx] = mean' : ''};\n    ${hasInvStdOutput ? 'invStdOutput[global_idx] = 1 / meanSquare' : ''};\n  }`;\n      const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n      if (hasMeanDataOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n      if (hasInvStdOutput) {\n        outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n      }\n\n      return {\n        name: 'LayerNormalization',\n        shaderCache: {hint: `${attributes.cacheKey}|${outputCount}|${inputs.length}`},\n        getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(normCount / 64 /* workgroup size */)}}),\n        getShaderSource,\n      };\n    };\n\nexport const parseLayerNormAttributes = (attributes: LayerNormAttributes): LayerNormAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis, epsilon: attributes.epsilon});\n\nexport const layerNorm = (context: ComputeContext, attributes: LayerNormAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createLayerNormProgramInfo(context.inputs, attributes, context.outputCount));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil} from '../../util';\nimport {ComputeContext} from '../types';\n\nimport {createMatmulProgramInfo} from './3rd-party/matmul_packed_webgpu';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('MatMul requires 2 inputs.');\n  }\n\n  if (inputs[0].dims[inputs[0].dims.length - 1] !== inputs[1].dims[inputs[1].dims.length - 2]) {\n    throw new Error('shared dimension does not match.');\n  }\n};\n\nexport const matMul = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  const outputShape = BroadcastUtil.calcShape(context.inputs[0].dims, context.inputs[1].dims, true);\n  if (!outputShape) {\n    throw new Error('Can\\'t use matmul on the given tensors');\n  }\n  context.compute(createMatmulProgramInfo(context.inputs, {activation: '', activationCacheKey: ''}, outputShape));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface PadAttributes extends AttributeWithCacheKey {\n  // 0-constant, 1-reflect, 2-edge, 3-wrap\n  readonly mode: number;\n  readonly value: number;\n  readonly pads: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('Too few inputs');\n  }\n  if (inputs[0].dataType !== DataType.float) {\n    throw new Error('Input type must be float.');\n  }\n\n  if (inputs.length >= 2) {\n    let validPads = inputs[0].dims.length * 2 === inputs[1].dims[0];\n    if (inputs.length === 4) {\n      validPads = inputs[3].dims[0] * 2 === inputs[1].dims[0];\n    }\n    if (!validPads) {\n      throw new Error('The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].');\n    }\n  }\n};\n\nconst getPadConstant =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[], dataType: string, constantValue: number): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n            k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${inputDims[i]}) {\n              break;\n            }\n            offset += k * ${inputStrides[i]};\n        `;\n      }\n\n      return `\n          value = ${dataType}(${constantValue});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${block}\n            value = x[offset];\n          }\n      `;\n    };\n\nconst getPadReflect =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2 * (inputDims[i] - 1)};\n                  k = k % _2n_1;\n                  if(k >= ${inputDims[i]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadEdge =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${inputDims[i]}) {\n                  k = ${inputDims[i] - 1};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadWrap =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], pads: number[]): string => {\n      const inputRank = inputDims.length;\n\n      let block = '';\n      for (let i = inputRank - 1; i >= 0; --i) {\n        block += `\n                k = i32(${output.indicesGet('indices', i)}) - ${pads[i]};\n                if (k < 0)  {\n                  k += ${inputDims[i]};\n                }\n                if (k >= ${inputDims[i]}) {\n                  k -= ${inputDims[i]};\n                }\n                offset += k * ${inputStrides[i]};\n            `;\n      }\n\n      return `\n              var offset = 0;\n              var k = 0;\n              ${block}\n              value = x[offset];\n          `;\n    };\n\nconst getPadSnippet =\n    (output: IndicesHelper, outputDims: readonly number[], inputDims: readonly number[],\n     inputStrides: readonly number[], attributes: PadAttributes, dataType: string): string => {\n      switch (attributes.mode) {\n        case 0:\n          return getPadConstant(\n              output, outputDims, inputDims, inputStrides, attributes.pads, dataType, attributes.value);\n        case 1:\n          return getPadReflect(output, outputDims, inputDims, inputStrides, attributes.pads);\n        case 2:\n          return getPadEdge(output, outputDims, inputDims, inputStrides, attributes.pads);\n        case 3:\n          return getPadWrap(output, outputDims, inputDims, inputStrides, attributes.pads);\n        default:\n          throw new Error('Invalid mode');\n      }\n    };\n\nconst generatePadCode =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], attributes: PadAttributes, dataType: string):\n        string => {\n          const inputDims = inputs[0].dims;\n          const outputDims = ShapeUtil.padShape(inputDims.slice(), attributes.pads);\n          const outputSize = ShapeUtil.size(outputDims);\n          const inputStrides = ShapeUtil.computeStrides(inputDims);\n\n          const output = outputVariable('output', inputs[0].dataType, outputDims);\n          const input = inputVariable('x', inputs[0].dataType, inputDims);\n\n          const padSnippet = getPadSnippet(output, outputDims, inputDims, inputStrides, attributes, dataType);\n          const padCode = `\n              ${shaderHelper.declareVariables(input, output)}\n              ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n\n              var value = ${dataType}(0);\n              ${padSnippet}\n              output[global_idx] = value;\n          }`;\n          return padCode;\n        };\n\nconst createPadProgramInfo = (inputs: readonly TensorView[], attributes: PadAttributes): ProgramInfo => {\n  const outputShape = ShapeUtil.padShape(inputs[0].dims.slice(), attributes.pads);\n  return {\n    name: 'Pad',\n    shaderCache: {hint: attributes.cacheKey},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n    }),\n    getShaderSource: shaderHelper => generatePadCode(shaderHelper, inputs, attributes, 'f32'),\n  };\n};\n\nconst createPadAttributesFromInputs = (inputs: readonly TensorView[], attributes: PadAttributes): PadAttributes => {\n  if (inputs.length > 1) {\n    const bigInt64Pads = inputs[1].getBigInt64Array();\n    const value = (inputs.length >= 3 && inputs[2].data) ? inputs[2].getFloat32Array()[0] : 0.0;\n\n    const inputRank = inputs[0].dims.length;\n    const updatePads = new Int32Array(2 * inputRank).fill(0);\n    if (inputs.length >= 4) {\n      const axes = inputs[3].getBigInt64Array();\n      for (let i = 0; i < axes.length; i++) {\n        updatePads[Number(axes[i])] = Number(bigInt64Pads[i]);\n        updatePads[Number(axes[i]) + inputRank] = Number(bigInt64Pads[i + axes.length]);\n      }\n    } else {\n      bigInt64Pads.forEach((v, i) => updatePads[Number(i)] = (Number(v)));\n    }\n\n    const pads: number[] = [];\n    updatePads.forEach(v => pads.push(v));\n\n    return createAttributeWithCacheKey({mode: attributes.mode, value, pads});\n  } else {\n    return attributes;\n  }\n};\n\nexport const pad = (context: ComputeContext, attributes: PadAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes = createPadAttributesFromInputs(context.inputs, attributes);\n  context.compute(createPadProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parsePadAttributes = (attributes: Record<string, unknown>): PadAttributes => {\n  const mode = attributes.mode as number;\n  const value = attributes.value as number;\n  const pads = attributes.pads as number[];\n  return createAttributeWithCacheKey({mode, value, pads});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {PoolConvUtil, ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\n// TODO: support:\n// - ceil_mode                 \"test_maxpool_2d_ceil\"\n// - storage_order             \"test_maxpool_with_argmax_2d_precomputed_strides\"\n// - [MaxPool] dilations       \"test_maxpool_2d_dilations\"\n// - [MaxPool] output[1]       \"test_maxpool_with_argmax_2d_precomputed_pads\"\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Pool ops requires 1 input.');\n  }\n  if (inputs[0].dims.length !== 4 && inputs[0].dims.length !== 3) {\n    throw new Error('Pool ops supports 1-D or 2-D inputs only for now.');\n  }\n};\n\nconst getAdjustedPoolAttributesAndOutputShape = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    input: TensorView, attributes: AttributeType, isGlobalOperator: boolean): [AttributeType, number[]] => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputShapeAsChannelFirst = input.dims.slice();\n  if (isChannelsLast) {\n    inputShapeAsChannelFirst.splice(1, 0, inputShapeAsChannelFirst.pop()!);  // Move channel to the second position.\n  }\n  const hasDilations = Object.hasOwnProperty.call(attributes, 'dilations');\n  const kernelShape = attributes.kernelShape.slice();\n  const strides = attributes.strides.slice();\n  const dilations: number[] = hasDilations ? (attributes as MaxPoolAttributes).dilations.slice() : [];\n  const pads = attributes.pads.slice();\n  PoolConvUtil.adjustPoolAttributes(isGlobalOperator, inputShapeAsChannelFirst, kernelShape, strides, dilations, pads);\n\n  const outputShapeAsChannelFirst = PoolConvUtil.computePoolOutputShape(\n      isGlobalOperator, inputShapeAsChannelFirst, strides, dilations, kernelShape, pads, attributes.autoPad);\n\n  const newAttributes = Object.assign({}, attributes);\n  if (hasDilations) {\n    Object.assign(newAttributes, {kernelShape, strides, pads, dilations, cacheKey: attributes.cacheKey});\n  } else {\n    Object.assign(newAttributes, {kernelShape, strides, pads, cacheKey: attributes.cacheKey});\n  }\n  const outputShapeAsChannelLast = outputShapeAsChannelFirst.slice();\n  outputShapeAsChannelLast.push(outputShapeAsChannelLast.splice(1, 1)[0]);\n  return [newAttributes, isChannelsLast ? outputShapeAsChannelLast : outputShapeAsChannelFirst];\n};\n\nconst generatePoolingCode = <AttributeType extends AveragePoolAttributes|MaxPoolAttributes>(\n    shaderHelper: ShaderHelper, x: IndicesHelper, xShape: readonly number[], outputShape: readonly number[],\n    attributes: AttributeType, op1: string, op2: string, start: string): string => {\n  const isChannelsLast = attributes.format === 'NHWC';\n  const inputDims = xShape;\n  const dataType = x.type.value;\n  const rank = inputDims.length;\n  const outputSize = ShapeUtil.size(outputShape);\n  const output = outputVariable('output', x.type.tensor, outputShape);\n\n  if (attributes.kernelShape.length <= 2) {\n    const kw = attributes.kernelShape[attributes.kernelShape.length - 1];\n    const sw = attributes.strides[attributes.strides.length - 1];\n    const pwStart = attributes.pads[attributes.pads.length / 2 - 1];\n    const pwEnd = attributes.pads[attributes.pads.length - 1];\n    const dimIdxW = rank - (isChannelsLast ? 2 : 1);\n    let codeW = '';\n    let codeH = '';\n    let codeHEnd = '';\n    if (pwStart + pwEnd !== 0) {\n      codeW = `\n                for (var i: u32 = 0u; i < ${kw}u; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                  if (xIndices[${dimIdxW}] < 0 || xIndices[${dimIdxW}] >= ${inputDims[dimIdxW]}) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    } else {\n      codeW = `\n                for (var i: u32 = 0u; i < ${kw}u; i++) {\n                  xIndices[${dimIdxW}] = indices[${dimIdxW}] * ${sw} - ${pwStart} + i;\n                  let x_val = x[${x.indicesToOffset('xIndices')}];\n                  ${op1}\n                }`;\n    }\n\n    if (attributes.kernelShape.length === 2) {\n      const kh = attributes.kernelShape[attributes.kernelShape.length - 2];\n      const sh = attributes.strides[attributes.strides.length - 2];\n      const phStart = attributes.pads[attributes.pads.length / 2 - 2];\n      const phEnd = attributes.pads[attributes.pads.length - 2];\n      const dimIdxH = rank - (isChannelsLast ? 3 : 2);\n      const dimH = inputDims[dimIdxH];\n      if (phStart + phEnd !== 0) {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                  if (xIndices[${dimIdxH}] < 0 || xIndices[${dimIdxH}] >= ${dimH}) {\n                    pad+= ${kw};\n                    continue;\n                  }\n              `;\n      } else {\n        codeH = `\n                for (var j: u32 = 0u; j < ${kh}u; j++) {\n                  xIndices[${dimIdxH}] = indices[${dimIdxH}] * ${sh} - ${phStart} + j;\n                `;\n      }\n      codeHEnd = `\n              }\n            `;\n    }\n\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              var xIndices = ${output.offsetToIndices('global_idx')};\n\n              var value: ${dataType} = ${dataType}(${start});\n              var pad = 0;\n              ${codeH}\n              ${codeW}\n              ${codeHEnd}\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  } else {\n    if (isChannelsLast) {\n      throw new Error('Pooling with kernelShape.length > 2 is not supported for NHWC format.');\n    }\n    const kernelSize = ShapeUtil.size(attributes.kernelShape);\n    const kernelStrides = ShapeUtil.computeStrides(attributes.kernelShape);\n    const stridesRank = kernelStrides.length;\n    const padsRank = attributes.pads.length;\n    const hasPads = attributes.pads.reduce((sum, cur) => sum + cur);\n    let padCode = '';\n    if (hasPads) {\n      padCode = `\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${x.indicesToOffset('xIndices')}];\n                ${op1}\n              }`;\n    } else {\n      padCode = `\n              }\n              let x_val = x[${x.indicesToOffset('xIndices')}];\n              ${op1}\n            `;\n    }\n    const poolingCode = `\n            ${shaderHelper.declareVariables(x, output)}\n\n            const pads = array<u32, ${padsRank}>(${attributes.pads.map(i => `${i}u`).join(',')});\n            const inputDims = array<u32, ${rank}>(${inputDims.map(i => `${i}u`).join(',')});\n            const kernelStrides = array<u32, ${stridesRank}>(${kernelStrides.map(i => `${i}u`).join(',')});\n            const strides = array<u32, ${stridesRank}>(${attributes.strides.map(i => `${i}u`).join(',')});\n\n            ${shaderHelper.mainStart()}\n              ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n\n              let indices = ${output.offsetToIndices('global_idx')};\n              let xIndices = ${output.offsetToIndices('global_idx')};\n\n              var offsets: array<u32, ${stridesRank}>;\n\n              var value = ${output.type.value}(${start});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${kernelSize}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${stridesRank - 1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${stridesRank - 1}] = offset;\n\n                isPad = false;\n                for (var j = ${rank - stridesRank}u; j < ${rank}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${rank - stridesRank}u]\n                    + offsets[j - ${rank - stridesRank}u] - pads[j - 2u];\n                  ${padCode}\n              }\n              ${op2}\n\n              output[global_idx] = value;\n            }`;\n    return poolingCode;\n  }\n};\n\nexport interface FormatAttributes {\n  readonly format: 'NHWC'|'NCHW';\n}\n\nexport interface PoolCommonAttributes extends FormatAttributes {\n  readonly autoPad: string;\n  readonly ceilMode: number;\n  readonly kernelShape: readonly number[];\n  readonly strides: readonly number[];\n  readonly pads: readonly number[];\n}\n\nconst parsePoolCommonAttributes = (attributes: Record<string, unknown>): PoolCommonAttributes => ({\n  format: attributes.format as FormatAttributes['format'],\n  autoPad: ['NOTSET', 'VALID', 'SAME_UPPER', 'SAME_LOWER'][attributes.auto_pad as number],\n  ceilMode: attributes.ceil_mode as number,\n  kernelShape: attributes.kernel_shape as [number, number],\n  strides: attributes.strides as [number, number],\n  pads: attributes.pads as [number, number, number, number]\n});\n\nexport interface AveragePoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly countIncludePad: boolean;\n}\n\nconst createAveragePoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: AveragePoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const kernelSize = ShapeUtil.size(adjustedAttributes.kernelShape);\n\n      const x = inputVariable('x', input.dataType, input.dims);\n      const dataType = x.type.value;\n\n      const op1 = 'value += x_val;';\n      let op2 = '';\n      if (adjustedAttributes.countIncludePad) {\n        op2 += `value /= ${dataType}(${kernelSize});`;\n      } else {\n        op2 += `value /= ${dataType}(${kernelSize} - pad);`;\n      }\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '0.0'),\n      };\n    };\n\nexport const parseAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const countIncludePad = (attributes.count_include_pad as number) === 0 ? false : true;\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode'\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for AveragePool');\n  }\n\n  return createAttributeWithCacheKey({countIncludePad, ...attr});\n};\n\nexport const averagePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('AveragePool', context.inputs[0], false, attributes));\n};\n\nconst globalPoolAttributes = {\n  autoPad: '',\n  ceilMode: 0,\n  countIncludePad: false,\n  kernelShape: [],\n  strides: [],\n  pads: [],\n  storageOrder: 0,\n  dilations: [],\n  cacheKey: ''\n};\n\nexport const parseGlobalAveragePoolAttributes = (attributes: Record<string, unknown>): AveragePoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalAveragePool = (context: ComputeContext, attributes: AveragePoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createAveragePoolProgramInfo('GlobalAveragePool', context.inputs[0], true, attributes));\n};\n\nexport interface MaxPoolAttributes extends PoolCommonAttributes, AttributeWithCacheKey {\n  readonly storageOrder: number;\n  readonly dilations: number[];\n}\n\nconst createMaxPoolProgramInfo =\n    (name: string, input: TensorView, isGlobalOperator: boolean, attributes: MaxPoolAttributes): ProgramInfo => {\n      const [adjustedAttributes, outputShape] =\n          getAdjustedPoolAttributesAndOutputShape(input, attributes, isGlobalOperator);\n      const op1 = `\n      value = max(x_val, value);\n    `;\n      const op2 = '';\n      const x = inputVariable('x', input.dataType, input.dims);\n      return {\n        name,\n        shaderCache: {hint: attributes.cacheKey},\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: input.dataType}],\n          dispatchGroup: {x: Math.ceil(ShapeUtil.size(outputShape) / 64 /* workgroup size */)}\n        }),\n        getShaderSource: shaderHelper =>\n            generatePoolingCode(shaderHelper, x, input.dims, outputShape, adjustedAttributes, op1, op2, '-1e5'),\n      };\n    };\n\nexport const maxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('MaxPool', context.inputs[0], false, attributes));\n};\n\nexport const parseMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const storageOrder = attributes.storage_order as number;\n  const dilations = attributes.dilations as [number, number];\n\n  const attr = parsePoolCommonAttributes(attributes);\n  // TODO: support attribute 'ceil_mode' and 'storage_order'\n  if (storageOrder !== 0) {\n    throw new Error('column major storage order is not yet supported for MaxPool');\n  }\n  if (attr.ceilMode !== 0) {\n    throw new Error('using ceil() in shape computation is not yet supported for MaxPool');\n  }\n\n  return createAttributeWithCacheKey({storageOrder, dilations, ...attr});\n};\n\nexport const parseGlobalMaxPoolAttributes = (attributes: Record<string, unknown>): MaxPoolAttributes => {\n  const format = attributes.format as FormatAttributes['format'];\n  return {format, ...globalPoolAttributes, cacheKey: format};\n};\n\nexport const globalMaxPool = (context: ComputeContext, attributes: MaxPoolAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createMaxPoolProgramInfo('GlobalMaxPool', context.inputs[0], true, attributes));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {env} from 'onnxruntime-common';\n\nimport {DataType} from '../../../wasm-common';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {outputVariable, ShaderHelper} from './common';\n\nconst validateInputsContent = (start: number, limit: number, delta: number): void => {\n  const sameStartLimit = start === limit;\n  const increasingRangeNegativeStep = start < limit && delta < 0;\n  const decreasingRangePositiveStep = start > limit && delta > 0;\n\n  if (sameStartLimit || increasingRangeNegativeStep || decreasingRangePositiveStep) {\n    throw new Error('Range these inputs\\' contents are invalid.');\n  }\n};\n\nconst createRangeProgramInfo = (start: number, limit: number, delta: number, dataType: DataType): ProgramInfo => {\n  const numElements = Math.abs(Math.ceil((limit - start) / delta));\n  const outputShape: number[] = [numElements];\n  const outputSize = numElements;\n\n  const output = outputVariable('output', dataType, outputShape);\n  const wgslType = output.type.storage;\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n        ${shaderHelper.declareVariables(output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        output[global_idx] = ${wgslType}(${start}) + ${wgslType}(global_idx) * ${wgslType}(${delta});\n      }`;\n  return {\n    name: 'Range',\n    shaderCache: {hint: [start, limit, delta].map(x => x.toString()).join('_')},\n    getShaderSource,\n    getRunData: () => (\n        {outputs: [{dims: outputShape, dataType}],\n         dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}})\n  };\n};\n\nexport const range = (context: ComputeContext): void => {\n  let start = 0;\n  let limit = 0;\n  let delta = 0;\n  if (context.inputs[0].dataType === DataType.int32) {\n    start = context.inputs[0].getInt32Array()[0];\n    limit = context.inputs[1].getInt32Array()[0];\n    delta = context.inputs[2].getInt32Array()[0];\n  } else if (context.inputs[0].dataType === DataType.float) {\n    start = context.inputs[0].getFloat32Array()[0];\n    limit = context.inputs[1].getFloat32Array()[0];\n    delta = context.inputs[2].getFloat32Array()[0];\n  }\n  if (env.webgpu.validateInputContent) {\n    validateInputsContent(start, limit, delta);\n  }\n\n  context.compute(createRangeProgramInfo(start, limit, delta, context.inputs[0].dataType), {inputs: []});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\ntype CoordinateTransformMode = 'half_pixel'|'asymmetric'|'pytorch_half_pixel'|'tf_half_pixel_for_nn'|'align_corners'|\n    'tf_crop_and_resize'|'half_pixel_symmetric';\n\ntype KeepAspectRatioPolicy = 'stretch'|'not_smaller'|'not_larger';\n\ntype Mode = 'nearest'|'linear'|'cubic';\n\ntype NearestMode = 'round_prefer_floor'|'round_prefer_ceil'|'floor'|'ceil'|'simple';\n\nexport interface ResizeAttributes extends AttributeWithCacheKey {\n  antialias: number;\n  axes: number[];\n  coordinateTransformMode: CoordinateTransformMode;\n  cubicCoeffA: number;\n  excludeOutside: boolean;\n  extrapolationValue: number;\n  keepAspectRatioPolicy: KeepAspectRatioPolicy;\n  mode: Mode;\n  nearestMode: NearestMode;\n}\n\nconst validateScales = (scales: number[], attributes: ResizeAttributes): void => {\n  scales.every((value) => value > 0 || (() => {\n                            throw new Error('Resize requires scales input values to be positive');\n                          }));\n  // Check scales dims based on mode: LINEAR, CUBIC\n  if (scales.length > 0) {\n    if (attributes.mode === 'linear') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for linear mode');\n      }\n    } else if (attributes.mode === 'cubic') {\n      if (!(scales.length === 2 || (scales.length === 4 && scales[0] === 1 && scales[1] === 1) ||\n            (scales.length === 4 && scales[0] === 1 && scales[3] === 1))) {\n        throw new Error('Resize requires scales input size to be 2 or 4 for cubic mode');\n      }\n    }\n  }\n};\n\nconst updateScales = (scales: readonly number[], axes: readonly number[], rank: number): number[] => {\n  axes.every((value) => value >= 0 && value < rank || (() => {\n                          throw new Error('Resize requires axes input values to be positive and less than rank');\n                        }));\n  const newScales = new Array(rank).fill(1.0);\n  axes.forEach((value, index) => newScales[value] = scales[index]);\n  return newScales;\n};\n\nconst validateInputs =\n    (inputs: readonly TensorView[], attributes: ResizeAttributes, opsetVersion: number, scales: number[],\n     sizes: number[], roi: number[]): void => {\n      const [roiInputIndex, scalesInputIndex, sizesInputIndex] =\n          (opsetVersion > 10) ? [1, 2, 3] : [-1, (inputs.length > 1) ? 1 : -1, -1];\n      const rank = inputs[0].dims.length;\n      if (roiInputIndex > 0 && inputs.length > roiInputIndex && inputs[roiInputIndex].dims.length > 0) {\n        inputs[roiInputIndex].getFloat32Array().forEach((value) => roi.push(value));\n\n      } else if (attributes.coordinateTransformMode === 'tf_crop_and_resize') {\n        throw new Error('Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize');\n      }\n\n      if (scalesInputIndex > 0 && inputs.length > scalesInputIndex && inputs[scalesInputIndex].dims.length > 0) {\n        inputs[scalesInputIndex].getFloat32Array().forEach((value) => scales.push(value));\n        if (scales.length !== 0 &&\n            (scales.length !== rank && (opsetVersion >= 18 && scales.length !== attributes.axes.length))) {\n          throw new Error(\n              'Resize requires scales input size to be same as input rank or axes size for opset 18 and up');\n        }\n        validateScales(scales, attributes);\n        if (attributes.axes.length > 0) {\n          updateScales(scales, attributes.axes, rank).forEach((value, index) => scales[index] = value);\n        }\n      }\n      if (sizesInputIndex > 0 && inputs.length > sizesInputIndex) {\n        inputs[sizesInputIndex].getBigInt64Array().forEach((value) => sizes.push(Number(value)));\n        if (sizes.length !== rank || (opsetVersion >= 18 && sizes.length === attributes.axes.length)) {\n          throw new Error('Resize requires sizes input size to be same as input rank or axes size for opset 18 and up');\n        }\n      }\n\n      if (attributes.axes.length > 0) {\n        if (scales.length !== attributes.axes.length) {\n          throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');\n        }\n        if (sizes.length !== attributes.axes.length) {\n          throw new Error(\n              'Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified');\n        }\n      }\n      if (typeof scales !== 'undefined' && typeof sizes !== 'undefined' && scales.length > 0 && sizes.length > rank) {\n        throw new Error('Resize requires only of scales or sizes to be specified');\n      }\n    };\n\nconst getOriginalCoordinateFromResizedCoordinate = (coordinateTransferMode: CoordinateTransformMode): string =>\n    'fn getOriginalCoordinateFromResizedCoordinate(xResized: f32, xScale: f32, lengthResized: f32,\\\n    lengthOriginal: f32, roiStart: f32, roiEnd: f32) -> f32 { ' +\n    (() => {\n      switch (coordinateTransferMode) {\n        case 'asymmetric':\n          return 'return xResized / xScale;';\n        case 'pytorch_half_pixel':\n          return 'if (lengthResized > 1) { \\\n                    return (xResized + 0.5) / xScale - 0.5; \\\n                  } else { \\\n                    return 0.0; \\\n                  }';\n        case 'tf_half_pixel_for_nn':\n          return 'return (xResized + 0.5) / xScale;';\n        case 'align_corners':\n          return 'if (lengthResized == 1) { \\\n                    return 0.0; \\\n                  } else { \\\n                    return xResized * (lengthOriginal - 1) / (lengthResized - 1); \\\n                  }';\n        case 'tf_crop_and_resize':\n          return 'if (lengthResized > 1) { \\\n                    return roiStart * (lengthOriginal - 1) + \\\n                          (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1); \\\n                  } else { \\\n                    return 0.5 * (roiStart + roiEnd) * f32(lengthOriginal - 1); \\\n                  }';\n        case 'half_pixel_symmetric':\n          return [\n            'const outputWidth = xScale * lengthResized;', 'const adjustment = lengthResized / outputWidth;',\n            'const center = lengthOriginal / 2;', 'const offset = center * (1 - adjustment);',\n            'return offset + ((xResized + 0.5) / xScale) - 0.5;'\n          ].join('\\n');\n        case 'half_pixel':\n          return 'return ((xResized + 0.5) / xScale) - 0.5;';\n        default:\n          throw new Error(`Coordinate transform mode ${coordinateTransferMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst getNearestPixelFromOriginal = (nearestMode: NearestMode, opsetVersion: number): string =>\n    'fn getNearestPixelFromOriginal(xOriginal: f32, isDownSample: bool) -> f32 {' + (() => {\n      switch (nearestMode) {\n        case 'round_prefer_ceil':\n          return 'if (fract(xOriginal) == 0.5) { \\\n            return ceil(xOriginal); \\\n          } else { \\\n            return round(xOriginal); \\\n          }';\n        case 'floor':\n          return 'return floor(xOriginal);';\n        case 'ceil':\n          return 'return ceil(xOriginal);';\n        case 'round_prefer_floor':\n          return 'if (fract(xOriginal) == 0.5) { \\\n                    return floor(xOriginal); \\\n                  } else { \\\n                    return round(xOriginal); \\\n                  }';\n        case 'simple':\n        default:\n          if (opsetVersion < 11) {\n            return 'if (isDownSample) \\\n                    { \\\n                      return ceil(xOriginal); \\\n                    } else { \\\n                      return xOriginal; \\\n                    }';\n          }\n          throw new Error(`Nearest mode ${nearestMode} is not supported`);\n      }\n    })() +\n    '}';\n\nconst updateRoI = (roi: readonly number[], axes: readonly number[], rank: number): number[] => {\n  const roiTmp = new Array(rank).fill(0).concat(new Array(rank).fill(1));\n  const roiLocal = roi.length === 0 ? roiTmp : roi.slice();\n  if (axes.length > 0) {\n    axes.forEach((v, i) => {\n      roiTmp[v] = roiLocal[i];\n      roiTmp[i + rank] = roiLocal[axes.length + i];\n    });\n    return roiTmp;\n  }\n  return roiLocal;\n};\n\nconst initOutputShape =\n    (inputShape: readonly number[], scales: readonly number[], sizes: readonly number[], axes: readonly number[]):\n        number[] => {\n          let outputShape: number[] = [];\n          if (sizes.length > 0) {\n            if (axes.length > 0) {\n              inputShape.forEach((v) => outputShape.push(v));\n              if (Math.max(...axes) > inputShape.length) {\n                throw new Error('axes is out of bound');\n              }\n              axes.forEach((v, i) => outputShape[v] = sizes[i]);\n            } else {\n              sizes.forEach((v) => outputShape.push(v));\n            }\n          } else {\n            if (scales.length === 0) {\n              throw new Error('Resize requires either scales or sizes.');\n            } else {\n              outputShape = inputShape.map((value, index) => Math.round(value * scales[index]));\n            }\n          }\n          return outputShape;\n        };\n\nconst adjustOutputShape =\n    (inputShape: readonly number[], outputShape: readonly number[], scales: number[], attributes: ResizeAttributes):\n        number[] => {\n          const scaleInPolicy = (() => {\n            switch (attributes.keepAspectRatioPolicy) {\n              case 'not_larger':\n                return attributes.axes.length > 0 ? Math.min(...attributes.axes.map(i => scales[i]), Number.MAX_VALUE) :\n                                                    Math.min(...scales, Number.MAX_VALUE);\n              case 'not_smaller':\n                return attributes.axes.length > 0 ? Math.max(...attributes.axes.map(i => scales[i]), Number.MIN_VALUE) :\n                                                    Math.max(...scales, Number.MIN_VALUE);\n              default:\n                throw new Error(`Keep aspect ratio policy ${attributes.keepAspectRatioPolicy} is not supported`);\n            }\n          })();\n          scales.fill(1.0, 0, scales.length);\n          const adjustedOutputShape = inputShape.slice();\n          if (attributes.axes.length > 0) {\n            attributes.axes.forEach((v) => scales[v] = scaleInPolicy);\n            attributes.axes.forEach((v) => adjustedOutputShape[v] = Math.round(inputShape[v] * scales[v]));\n          } else {\n            scales.fill(scaleInPolicy, 0, scales.length);\n            adjustedOutputShape.forEach((v, i) => adjustedOutputShape[i] = Math.round(v * scales[i]));\n          }\n          return adjustedOutputShape;\n        };\n\nconst calculateOriginalIndicesFromOutputIndices =\n    (output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[], scales: readonly number[],\n     roi: readonly number[]): string => `\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> array<f32, ${\n        outputShape.length}> {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n      const scales = array<f32, ${scales.length}>(${scales.map(i => `${i}f`).join(',')});\n      const roi = array<f32, ${roi.length}>(${roi.map(i => `${i}f`).join(',')});\n      var originalIndices: array<f32, ${outputShape.length}>;\n      for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = f32(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${inputShape.length}]);\n        }\n      }\n      return originalIndices;\n    }`;\n\nconst calculateInputIndicesFromOutputIndices =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], useExtrapolation: boolean): string => `\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n        const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n        const outputShape = array<u32, ${outputShape.length}>(${outputShape.map(i => `${i}u`).join(',')});\n        const scales = array<f32, ${scales.length}>(${scales.map(i => `${i}f`).join(',')});\n        const roi = array<f32, ${roi.length}>(${roi.map(i => `${i}f`).join(',')});\n        var inputIndices: ${input.type.indices};\n        for (var i:u32 = 0; i < ${outputShape.length}; i++) {\n          var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                    f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${inputShape.length}]);\n            if (!${useExtrapolation} || (original_idx >= 0 && original_idx < f32(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (f32(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${input.indicesSet('inputIndices', 'i', 'inputIndex')}\n        }\n        return inputIndices;\n    }`;\n\nconst checkInputIndices = (input: IndicesHelper, inputShape: readonly number[]): string => `\n    fn checkInputIndices(inputIndices: ${input.type.indices}) -> bool {\n      const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n      for (var i:u32 = 0; i < ${inputShape.length}; i++) {\n        var inputIndex = ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`;\n\nconst bilinearInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], useExtrapolation: boolean, extrapolationValue: number): string => {\n      const [batchIdx, heightIdx, widthIdx, channelIdx] =\n          inputShape.length === 2 ? [-1, 0, 1, -1] : (scales[1] === 1.0 ? [0, 2, 3, 1] : [0, 1, 2, 3]);\n      return `\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> f32 {\n      var inputIndices: ${input.type.indices};\n      inputIndices[${heightIdx}] = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      inputIndices[${widthIdx}] = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      if (${inputShape.length} > 2) {\n        inputIndices[${channelIdx}] = channel;\n        inputIndices[${batchIdx}] = batch;\n      };\n      return input[${input.indicesToOffset('inputIndices')}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${output.type.indices}) -> f32 {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:f32 = originalIndices[${heightIdx}];\n      var col:f32 = originalIndices[${widthIdx}];\n      if (${useExtrapolation} && (row < 0 || row > (${inputShape[heightIdx]} - 1) || col < 0 || col > ${\n          inputShape[widthIdx]} - 1)) {\n        return ${extrapolationValue};\n      }\n      row = max(0, min(row, ${inputShape[heightIdx]} - 1));\n      col = max(0, min(col, ${inputShape[widthIdx]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${inputShape.length > 2}) {\n        channel = u32(originalIndices[${channelIdx}]);\n        batch = u32(originalIndices[${batchIdx}]);\n      }\n      var x11: f32 = getInputValue(batch, channel, row1, col1);\n      var x12: f32 = getInputValue(batch, channel, row1, col2);\n      var x21: f32 = getInputValue(batch, channel, row2, col1);\n      var x22: f32 = getInputValue(batch, channel, row2, col2);\n      var dx1: f32 = row - f32(row1);\n      var dx2: f32 = f32(row2 ) - row;\n      var dy1 = col - f32(col1);\n      var dy2 = f32(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`;\n    };\n\nconst bicubicInterpolation =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[],\n     scales: readonly number[], roi: readonly number[], cubicCoeffA: number, useExtrapolation: boolean,\n     extrapolationValue: number, excludeOutside: boolean): string => {\n      const [heightIdx, widthIdx] = inputShape.length === 2 ? [0, 1] : (scales[1] === 1.0) ? [2, 3] : [1, 2];\n\n      const createCubicInterpolationFunction = (idx: number): string => {\n        const direction = idx === heightIdx ? 'row' : 'col';\n        return `\n      fn ${direction}CubicInterpolation(inputIndices: ${input.type.indices}, outputIndices: ${\n            output.type.indices}) -> f32 {\n        var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : `outputIndices[${idx}]`};\n        var originalIdx: f32 = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), ${scales[idx]},\n        f32(${outputShape[idx]}), f32(${inputShape[idx]}), ${roi[idx]}, ${roi[idx]} + ${inputShape.length});\n        var fractOriginalIdx: f32 = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${useExtrapolation} && (originalIdx < 0 || originalIdx > (${inputShape[idx]} - 1))) {\n          return ${extrapolationValue};\n        }\n        var data: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${direction}: f32 = originalIdx + f32(i);\n          if (${direction} < 0 || ${direction} >= ${inputShape[idx]}) {\n            if (${excludeOutside}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${useExtrapolation}) {\n              return ${extrapolationValue};\n            } else {\n              ${direction} = max(0, min(${direction}, ${inputShape[idx]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${input.type.indices} = inputIndices;\n          inputIndicesCopy[${idx}] = u32(${direction});\n          data[i + 1] = ${idx === heightIdx ? `input[${input.indicesToOffset('inputIndicesCopy')}];` : `\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`;\n      };\n\n      return `\n    ${createCubicInterpolationFunction(heightIdx)};\n    ${createCubicInterpolationFunction(widthIdx)};\n  fn getCubicInterpolationCoefs(s: f32) -> array<f32, 4> {\n    var absS = abs(s);\n    var coeffs: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: f32 = 1.0 - absS;\n    var twoMinusAbsS: f32 = 2.0 - absS;\n    var onePlusAbsS: f32 = 1.0 + absS;\n    coeffs[0] = ((${cubicCoeffA} * onePlusAbsS - 5 * ${cubicCoeffA}) * onePlusAbsS + 8 * ${\n          cubicCoeffA}) * onePlusAbsS - 4 * ${cubicCoeffA};\n    coeffs[1] = ((${cubicCoeffA} + 2) * absS - (${cubicCoeffA} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${cubicCoeffA} + 2) * oneMinusAbsS - (${cubicCoeffA} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${cubicCoeffA} * twoMinusAbsS - 5 * ${cubicCoeffA}) * twoMinusAbsS + 8 * ${\n          cubicCoeffA}) * twoMinusAbsS - 4 * ${cubicCoeffA};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<f32, 4>, coefs: array<f32, 4>) -> f32 {\n    var coefsSum: f32 = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${output.type.indices}) -> f32 {\n    var inputIndices: ${input.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `;\n    };\n\nconst createResizeProgramInfo =\n    (inputTensor: TensorView, attributes: ResizeAttributes, opsetVersion: number, scalesInput: readonly number[],\n     sizes: readonly number[], roiInput: readonly number[]): ProgramInfo => {\n      const inputShape = inputTensor.dims;\n      const roi = updateRoI(roiInput, attributes.axes, inputShape.length);\n\n      let outputShape = initOutputShape(inputShape, scalesInput, sizes, attributes.axes);\n      let scales = scalesInput.slice();\n      if (scalesInput.length === 0) {\n        scales = inputShape.map((value, index) => value === 0 ? 1.0 : outputShape[index] / value);\n        if (attributes.keepAspectRatioPolicy !== 'stretch') {\n          outputShape = adjustOutputShape(inputShape, outputShape, scales, attributes);\n        }\n      }\n      const output = outputVariable('output', inputTensor.dataType, outputShape);\n      const input = inputVariable('input', inputTensor.dataType, inputShape);\n      const outputSize = ShapeUtil.size(outputShape);\n      const noScale = inputShape.length === outputShape.length && inputShape.every((d, i) => d === outputShape[i]);\n      const useExtrapolation = attributes.coordinateTransformMode === 'tf_crop_and_resize';\n      const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${noScale ? '' : `\n      ${getOriginalCoordinateFromResizedCoordinate(attributes.coordinateTransformMode)};\n      ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `\n              ${checkInputIndices(input, inputShape)};\n              ${getNearestPixelFromOriginal(attributes.nearestMode, opsetVersion)};\n              ${\n                calculateInputIndicesFromOutputIndices(\n                    input, output, inputShape, outputShape, scales, roi, useExtrapolation)};\n              `;\n          case 'linear':\n            return `\n              ${calculateOriginalIndicesFromOutputIndices(output, inputShape, outputShape, scales, roi)};\n              ${\n                bilinearInterpolation(\n                    input, output, inputShape, outputShape, scales, useExtrapolation, attributes.extrapolationValue)};\n              `;\n          case 'cubic':\n            return `\n            ${\n                bicubicInterpolation(\n                    input, output, inputShape, outputShape, scales, roi, attributes.cubicCoeffA, useExtrapolation,\n                    attributes.extrapolationValue, attributes.excludeOutside)};\n            `;\n          default:\n            throw Error('Invalid resize mode');\n        }\n      })()};\n      `}\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n        ${noScale ? 'output[global_idx] = input[global_idx];' : `\n        let outputIndices = ${output.offsetToIndices('global_idx')};\n        var inputIndices: ${input.type.indices};\n        ${(() => {\n        switch (attributes.mode) {\n          case 'nearest':\n            return `inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                if (checkInputIndices(inputIndices)) {\n                  output[global_idx] = input[${input.indicesToOffset('inputIndices')}];\n                } else {\n                  output[global_idx] = ${attributes.extrapolationValue};\n                }`;\n          case 'linear':\n            return 'output[global_idx] = bilinearInterpolation(outputIndices);';\n          case 'cubic':\n            return 'output[global_idx] = bicubicInterpolation(outputIndices);';\n          default:\n            throw Error(`Unsupported resize mode: ${attributes.mode}`);\n        }\n      })()};\n        `}\n      }`;\n\n      return {\n        name: 'Resize',\n        shaderCache: {\n          hint: `${attributes.cacheKey}|${opsetVersion}|${scales.length > 0 ? scales : ''}|${\n              sizes.length > 0 ? sizes : ''}|${noScale}`\n        },\n        getShaderSource,\n        getRunData: () => ({\n          outputs: [{dims: outputShape, dataType: inputTensor.dataType}],\n          dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)}\n        })\n      };\n    };\n\nconst getOpsetVersionFromCustomDataBuffer = (context: ComputeContext): number => {\n  const customDataBuffer = context.customDataBuffer;\n  const customDataBuffer32 = new Uint32Array(customDataBuffer, customDataBuffer.byteOffset, 1);\n  const opsetVersion = customDataBuffer32[0];\n  return opsetVersion;\n};\n\nexport const resize = (context: ComputeContext, attributes: ResizeAttributes): void => {\n  const scales: number[] = [];\n  const sizes: number[] = [];\n  const roi: number[] = [];\n  const opsetVersion = getOpsetVersionFromCustomDataBuffer(context);\n  validateInputs(context.inputs, attributes, opsetVersion, scales, sizes, roi);\n  context.compute(\n      createResizeProgramInfo(context.inputs[0], attributes, opsetVersion, scales, sizes, roi), {inputs: [0]});\n};\n\nexport const parseResizeAttributes = (attributes: Record<string, unknown>): ResizeAttributes => {\n  const antialias = attributes.antialias as number;\n  const axes = attributes.axes as number[];\n  const coordinateTransformMode: CoordinateTransformMode =\n      attributes.coordinateTransformMode as CoordinateTransformMode;\n  const cubicCoeffA = attributes.cubicCoeffA as number;\n  const excludeOutside = attributes.excludeOutside as number !== 0;\n  const extrapolationValue = attributes.extrapolationValue as number;\n  const keepAspectRatioPolicy: KeepAspectRatioPolicy = attributes.keepAspectRatioPolicy as KeepAspectRatioPolicy;\n  const mode: Mode = attributes.mode as Mode;\n  // If nearestMode is not specified, use simple mode.\n  const nearestMode: NearestMode = (attributes.nearestMode === '' ? 'simple' : attributes.nearestMode) as NearestMode;\n  return createAttributeWithCacheKey({\n    antialias,\n    axes,\n    coordinateTransformMode,\n    cubicCoeffA,\n    excludeOutside,\n    extrapolationValue,\n    keepAspectRatioPolicy,\n    mode,\n    nearestMode\n  });\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {castToF32, fillVector, getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType,} from './common';\n\nexport interface SkipLayerNormAttributes extends AttributeWithCacheKey {\n  epsilon: number;\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 3) {\n    throw new Error('layerNorm requires at least 3 inputs.');\n  }\n\n  const input: TensorView = inputs[0];\n  const skip: TensorView = inputs[1];\n  const gamma: TensorView = inputs[2];\n\n  if (input.dataType !== skip.dataType || input.dataType !== gamma.dataType) {\n    throw new Error('All inputs must have the same data type');\n  }\n\n  if (input.dims.length !== 3 && input.dims.length !== 2) {\n    throw new Error('Input must be 2D or 3D');\n  }\n\n  if (skip.dims.length !== 3 && skip.dims.length !== 2) {\n    throw new Error('Skip must be 2D or 3D');\n  }\n\n  const hiddenSize = input.dims[input.dims.length - 1];\n  const sequenceLength = input.dims[input.dims.length - 2];\n  if (skip.dims[skip.dims.length - 1] !== hiddenSize) {\n    throw new Error('Skip must have the same hidden size as input');\n  }\n  if (skip.dims[skip.dims.length - 2] !== sequenceLength) {\n    throw new Error('Skip must have the same sequence length as input');\n  }\n\n  if (gamma.dims.length !== 1) {\n    throw new Error('Gamma must be 1D');\n  }\n  if (gamma.dims[gamma.dims.length - 1] !== hiddenSize) {\n    throw new Error('Gamma must have the same hidden size as input');\n  }\n  if (inputs.length > 3) {\n    const beta: TensorView = inputs[3];\n    if (beta.dims.length !== 1) {\n      throw new Error('Beta must be 1D');\n    }\n    if (beta.dims[beta.dims.length - 1] !== hiddenSize) {\n      throw new Error('Beta must have the same hidden size as input');\n    }\n  }\n\n  if (inputs.length > 4) {\n    const bias: TensorView = inputs[4];\n    if (bias.dims.length !== 1) {\n      throw new Error('Bias must be 1D');\n    }\n    if (bias.dims[bias.dims.length - 1] !== hiddenSize) {\n      throw new Error('Bias must have the same hidden size as input');\n    }\n  }\n};\n\nconst createSkipLayerNormProgramInfo =\n    (inputs: readonly TensorView[], attributes: SkipLayerNormAttributes, outputCount: number, isTraining: boolean):\n        ProgramInfo => {\n          const inputShape = inputs[0].dims;\n          const inputSize = ShapeUtil.size(inputShape);\n          const outputShape = inputShape;\n          const outputSize = inputSize;\n          const hiddenSize = inputShape.slice(-1)[0];\n          const meanInvStdDevDim = isTraining ? inputShape.slice(0, -1).concat(1) : [];\n          const hasBetaInput = inputs.length > 3;\n          const hasBiasInput = inputs.length > 4;\n          const hasMeanOutput = isTraining && outputCount > 1;\n          const hasInvStdDevOutput = isTraining && outputCount > 2;\n          const hasInputSkipBiasSumOutput = outputCount > 3;\n\n          const components = getMaxComponents(hiddenSize);\n          const variables = [\n            inputVariable('x', inputs[0].dataType, inputs[0].dims, components),\n            inputVariable('skip', inputs[1].dataType, inputs[1].dims, components),\n            inputVariable('gamma', inputs[2].dataType, inputs[2].dims, components),\n          ];\n          if (hasBetaInput) {\n            variables.push(inputVariable('beta', inputs[3].dataType, inputs[3].dims, components));\n          }\n          if (hasBiasInput) {\n            variables.push(inputVariable('bias', inputs[4].dataType, inputs[4].dims, components));\n          }\n          variables.push(outputVariable('output', inputs[0].dataType, outputShape, components));\n          if (hasMeanOutput) {\n            variables.push(outputVariable('meanOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInvStdDevOutput) {\n            variables.push(outputVariable('invStdOutput', DataType.float, meanInvStdDevDim));\n          }\n          if (hasInputSkipBiasSumOutput) {\n            variables.push(outputVariable('inputSkipBiasSum', inputs[0].dataType, outputShape, components));\n          }\n          const dataType = tensorTypeToWsglStorageType(inputs[0].dataType);\n          const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const hiddenSize: f32 = ${hiddenSize};\n      const hiddenSizeVectorized: u32 = ${hiddenSize / components};\n      const epsilon: f32 = ${attributes.epsilon};\n\n      ${shaderHelper.declareVariables(...variables)}\n\n      ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize / hiddenSize)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${fillVector('f32', components)};\n        var squareSum = ${fillVector('f32', components)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${hasBiasInput ? 'bias[i]' : '0.0'};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${hasInputSkipBiasSumOutput ? 'inputSkipBiasSum[offset + i] = value;' : ''}\n          output[offset + i] = value;\n          let f32Value = ${castToF32(dataType, components, 'value')};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${sumVector('sum', components)} / hiddenSize;\n        let variance = sqrt(${sumVector('squareSum', components)} / hiddenSize - mean * mean + epsilon);\n        ${hasMeanOutput ? 'meanOutput[global_idx] = mean;' : ''}\n        ${hasInvStdDevOutput ? 'invStdOutput[global_idx] = 1.0 / variance;' : ''}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${dataType}(mean)) / ${dataType}(variance) * gamma[i]\n           + ${hasBetaInput ? 'beta[i]' : '0.0'};\n        }\n      }`;\n          const outputs = [{dims: outputShape, dataType: inputs[0].dataType}];\n          if (outputCount > 1) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 2) {\n            outputs.push({dims: meanInvStdDevDim, dataType: DataType.float});\n          }\n          if (outputCount > 3) {\n            outputs.push({dims: inputShape, dataType: inputs[0].dataType});\n          }\n\n          return {\n            name: 'SkipLayerNormalization',\n            shaderCache: {hint: attributes.cacheKey},\n            getShaderSource,\n            getRunData: () => ({outputs, dispatchGroup: {x: Math.ceil(outputSize / hiddenSize / 64)}}),\n          };\n        };\n\nexport const skipLayerNorm = (context: ComputeContext, attributes: SkipLayerNormAttributes): void => {\n  // TODO: initialize isTraining from ComputeContext\n  const isTraining = false;\n  validateInputs(context.inputs);\n  // Mean and InvStdDev are only used in training mode and are not required for inference.\n  // They are added here for completeness only.\n  const outputs = [0];\n  if (context.outputCount > 1) {\n    outputs.push(isTraining ? 1 : -3);\n  }\n  if (context.outputCount > 2) {\n    outputs.push(isTraining ? 2 : -3);\n  }\n  if (context.outputCount > 3) {\n    outputs.push(3);\n  }\n  context.compute(\n      createSkipLayerNormProgramInfo(context.inputs, attributes, context.outputCount, isTraining), {outputs});\n};\n\nexport const parseSkipLayerNormAttributes = (attributes: Record<string, unknown>): SkipLayerNormAttributes => {\n  const epsilon = attributes.epsilon as number;\n  return createAttributeWithCacheKey({epsilon});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, TensorInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface SliceAttributes extends AttributeWithCacheKey {\n  readonly starts: number[];\n  readonly ends: number[];\n  readonly axes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[], attributes: SliceAttributes): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n  if (attributes.axes.length !== 0) {\n    if (attributes.axes.length !== attributes.starts.length || attributes.axes.length !== attributes.ends.length) {\n      throw new Error('axes, starts and ends must have the same length');\n    }\n  } else if (attributes.starts.length !== attributes.ends.length) {\n    throw new Error('starts and ends must have the same length');\n  }\n  inputs.slice(1).forEach((_, idx) => {\n    if (inputs[idx + 1].dataType !== DataType.int32 && inputs[idx + 1].dataType !== DataType.int64) {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  });\n};\n\nconst readInput = (inputs: readonly TensorView[], idx: number): number[] => {\n  const input: number[] = [];\n  if (inputs.length > idx) {\n    if (inputs[idx].dataType === DataType.int64) {\n      inputs[idx].getBigInt64Array().forEach(v => input.push(Number(v)));\n    } else if (inputs[idx].dataType === DataType.int32) {\n      inputs[idx].getInt32Array().forEach(v => input.push(Number(v)));\n    } else {\n      throw new Error(`Input ${idx} must be an array of int32 or int64`);\n    }\n  }\n  return input;\n};\n\nconst createSliceAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SliceAttributes): SliceAttributes => {\n      if (inputs.length > 1) {\n        const starts: number[] = readInput(inputs, 1);\n        const ends: number[] = readInput(inputs, 2);\n        let axes: number[] = readInput(inputs, 3);\n        if (axes.length === 0) {\n          axes = [...Array(inputs[0].dims.length).keys()];\n        }\n        return createAttributeWithCacheKey({starts, ends, axes});\n      } else {\n        return attributes;\n      }\n    };\n\nconst fixStartEndValues =\n    (value: number, index: number, inputShape: readonly number[], axes: readonly number[], steps: readonly number[]):\n        number => {\n          let newValue = value;\n          if (value < 0) {\n            newValue += inputShape[axes[index]];\n          }\n          if (steps[index] < 0) {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]] - 1));\n          } else {\n            return Math.max(0, Math.min(newValue, inputShape[axes[index]]));\n          }\n        };\n\nconst calculateInputIndicesImpl =\n    (input: IndicesHelper, output: IndicesHelper, inputShape: readonly number[], outputShape: readonly number[]):\n        string => `fn calculateInputIndices(outputIndices: ${output.type.indices}) -> ${input.type.indices} {\n          var inputIndices: ${input.type.indices};\n          var carry = 0u;\n          for (var i = ${inputShape.length}; i >= 0; i--) {\n            var outputIndex = ${outputShape.length === 1 ? 'outputIndices' : 'outputIndices[i]'};\n            var inputIndex = outputIndex * steps[i] + starts[i] + carry;\n            carry = inputIndex / inputShape[i];\n            inputIndex = inputIndex % inputShape[i];\n            if (signs[i] < 0) {\n              inputIndex = inputShape[i] - inputIndex - 1u + starts[i];\n            }\n            ${inputShape.length === 1 ? 'inputIndices' : 'inputIndices[i]'} = inputIndex;\n          }\n          return inputIndices;\n      }`;\n\nconst createSliceProgramInfo = (inputs: readonly TensorView[], attributes: SliceAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const axes = (attributes.axes.length > 0) ? ShapeUtil.normalizeAxes(attributes.axes, inputShape.length) :\n                                              [...Array(inputShape.length).keys()];\n  let steps = readInput(inputs, 4);\n  steps.forEach((step) => step !== 0 || (() => {\n                            throw new Error('step cannot be 0');\n                          }));\n  if (steps.length === 0) {\n    steps = Array(axes.length).fill(1);\n  }\n  const starts = attributes.starts.map((start, i) => fixStartEndValues(start, i, inputShape, axes, steps));\n\n  const ends = attributes.ends.map((end, i) => fixStartEndValues(end, i, inputShape, axes, steps));\n\n  if (axes.length !== inputShape.length) {\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (!axes.includes(i)) {\n        starts.splice(i, 0, 0);\n        ends.splice(i, 0, inputShape[i]);\n        steps.splice(i, 0, 1);\n      }\n    }\n  }\n  const signs = steps.map(step => Math.sign(step));\n  // Convert negative steps to positive steps and reverse starts and ends\n  steps.forEach((step, i, array) => {\n    if (step < 0) {\n      const numSteps = (ends[i] - starts[i]) / step;\n      const newEnd = starts[i];\n      const newStart = newEnd + numSteps * steps[i];\n      starts[i] = newStart;\n      ends[i] = newEnd;\n      array[i] = -step;\n    }\n  });\n\n  const outputShape = inputShape.slice(0);\n  axes.forEach((axis, _) => {\n    outputShape[axis] = Math.ceil((ends[axis] - starts[axis]) / steps[axis]);\n  });\n\n  const outputTensorInfo: TensorInfo = {dims: outputShape, dataType: inputs[0].dataType};\n\n  const output = outputVariable('output', inputs[0].dataType, outputShape);\n  const input = inputVariable('input', inputs[0].dataType, inputShape);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      ${shaderHelper.declareVariables(input, output)}\n        const signs = array<i32, ${signs.length}>(${signs.map(i => `${i}i`).join(',')});\n        const starts = array<u32, ${starts.length}>(${starts.map(i => `${i}u`).join(',')});\n        const ends = array<u32, ${ends.length}>(${ends.map(i => `${i}u`).join(',')});\n        const steps = array<u32, ${steps.length}>(${steps.map(i => `${i}u`).join(',')});\n        const inputShape = array<u32, ${inputShape.length}>(${inputShape.map(i => `${i}u`).join(',')});\n\n        ${calculateInputIndicesImpl(input, output, inputShape, outputShape)}\n        ${shaderHelper.mainStart()}\n          ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n          let outputIndices = ${output.offsetToIndices('global_idx')};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n      }`;\n  return {\n    name: 'Slice',\n    shaderCache: {hint: `${attributes.cacheKey}|${inputs[4]?.dims ?? ''}`},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: [outputTensorInfo],\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n    })\n  };\n};\n\nexport const slice = (context: ComputeContext, attributes: SliceAttributes): void => {\n  validateInputs(context.inputs, attributes);\n  const updatedAttributes = createSliceAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSliceProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n  // if (ShapeUtil.size(program.outputs[0].dims) > 0) {\n  //   context.compute(programInfoLoader, {inputs: [0]});\n  // } else {\n  //   // TODO: support empty output\n  //   throw new Error('slice: output size is 0');\n  // }\n};\n\nexport const parseSliceAttributes = (attributes: Record<string, unknown>): SliceAttributes => {\n  const starts = attributes.starts as number[];\n  const ends = attributes.ends as number[];\n  const axes = attributes.axes as number[];\n  return createAttributeWithCacheKey({starts, ends, axes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// TODO: this is the same naive implementation we use for reduce that has\n// performance limitations when the reduced axis is long. Need to add\n// a optimized codepath for this.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {getMaxComponents, inputVariable, outputVariable, ShaderHelper, sumVector, tensorTypeToWsglStorageType} from './common';\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 1) {\n    throw new Error('Softmax op requires 1 input.');\n  }\n};\n\nexport interface SoftmaxAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n}\n\nconst createSoftmaxProgramInfo = (input: TensorView, attributes: SoftmaxAttributes): ProgramInfo => {\n  const shape = input.dims;\n  const outputSize = ShapeUtil.size(shape);\n  const WG = 64;\n  let axis = attributes.axis;\n  if (axis < 0) {\n    axis = shape.length + axis;\n  }\n  if (axis < shape.length - 1) {\n    throw new Error('softmax only supports last axis for now.');\n  }\n\n  const cols = shape[axis];\n  const rows = outputSize / cols;\n  const components = getMaxComponents(cols);\n  const packedCols = cols / components;\n\n  const maxVector = (name: string, components: number) => {\n    if (components === 4) {\n      return `max(max(${name}.x, ${name}.y), max(${name}.z, ${name}.w))`;\n    } else if (components === 2) {\n      return `max(${name}.x, ${name}.y)`;\n    } else if (components === 3) {\n      return `max(max(${name}.x, ${name}.y), ${name}.z)`;\n    }\n\n    return name;\n  };\n  const x = inputVariable('x', input.dataType, input.dims, components);\n  const output = outputVariable('result', input.dataType, input.dims, components);\n  const valueType = x.type.value;\n  // 6.2.4 in wgsl spec\n  const threadMaxDecl = tensorTypeToWsglStorageType(input.dataType) === 'f32' ?\n      `var threadMax = ${valueType}(-3.402823e+38f);` :\n      `var threadMax = ${valueType}(-65504.0h);`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      var<workgroup> rowMaxShared : ${valueType};\n      var<workgroup> rowSumShared : ${valueType};\n      var<workgroup> threadShared : array<${valueType}, ${WG}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${valueType} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${valueType}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${shaderHelper.registerUniform('packedCols', 'i32').declareVariables(x, output)}\n      ${shaderHelper.mainStart()}\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${WG};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${threadMaxDecl}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${valueType}(${maxVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${valueType}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${valueType}(${sumVector('threadShared[0]', components)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;\n  return {\n    name: 'Softmax',\n    shaderCache: {hint: `${components}`, inputDependencies: ['type']},\n    getRunData: () => ({\n      outputs: [{dims: shape, dataType: input.dataType}],\n      dispatchGroup: {x: rows},\n      programUniforms: [{type: 'uint32', data: packedCols}]\n    }),\n    getShaderSource,\n  };\n};\n\nexport const softmax = (context: ComputeContext, attributes: SoftmaxAttributes): void => {\n  validateInputs(context.inputs);\n  context.compute(createSoftmaxProgramInfo(context.inputs[0], attributes));\n};\n\nexport const parseSoftmaxAttributes = (attributes: Record<string, unknown>): SoftmaxAttributes =>\n    createAttributeWithCacheKey({axis: attributes.axis as number});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {AttributeWithCacheKey, createAttributeWithCacheKey} from '../attribute-with-cache-key';\nimport {ComputeContext, ProgramInfo, TensorInfo} from '../types';\n\nimport {IndicesHelper, inputVariable, outputVariable, ShaderHelper} from './common';\n\nexport interface SplitAttributes extends AttributeWithCacheKey {\n  readonly axis: number;\n  readonly numOutputs: number;\n  readonly splitSizes: number[];\n}\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length < 1) {\n    throw new Error('too few inputs');\n  }\n};\n\nconst createSplitAttributesFromInputs =\n    (inputs: readonly TensorView[], attributes: SplitAttributes): SplitAttributes => {\n      const splitSizes: number[] = [];\n      let numOutputs: number = attributes.numOutputs;\n      if (inputs[1].dims[0] > 0) {\n        inputs[1].getBigInt64Array().forEach(v => splitSizes.push(Number(v)));\n        numOutputs = splitSizes.length;\n      }\n      return createAttributeWithCacheKey({numOutputs, axis: attributes.axis, splitSizes});\n    };\n\nconst calculateOutputIndexImpl = (numberOfTensors: number): string => `\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${numberOfTensors}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${numberOfTensors}u;\n}`;\nconst writeBufferDataImpl = (outputs: readonly IndicesHelper[]) => {\n  const numberOfTensors = outputs.length;\n  const codeLines: string[] = [];\n  for (let i = 0; i < numberOfTensors; ++i) {\n    const returnSnippet = outputs[i].setByIndices('indices', 'input[global_idx]');\n    if (numberOfTensors === 1) {\n      codeLines.push(returnSnippet);\n    } else if (i === 0) {\n      codeLines.push(`if (outputNumber == ${i}u) { ${returnSnippet} }`);\n    } else if (i === numberOfTensors - 1) {\n      codeLines.push(`else { ${returnSnippet} }`);\n    } else {\n      codeLines.push(`else if (outputNumber == ${i}) { ${returnSnippet} }`);\n    }\n  }\n  return `\n      fn writeBufferData(outputNumber: u32, indices: ${outputs[0].type.indices}, global_idx: u32) {\n        ${codeLines.join('\\n')}\n      }`;\n};\n\nconst createSplitProgramInfo = (inputs: readonly TensorView[], attributes: SplitAttributes): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const inputSize = ShapeUtil.size(inputShape);\n  const dataType = inputs[0].dataType;\n  const rank = inputShape.length;\n  const axis = attributes.axis;\n  const adjustedAxis = (axis < 0) ? inputShape.length + axis : axis;\n  const outputs = new Array<IndicesHelper>(attributes.numOutputs);\n  const input = inputVariable('input', dataType, inputShape);\n  const sizeInConcatAxis = new Array<number>(attributes.numOutputs);\n  const outputsTensorInfo: TensorInfo[] = [];\n  const outputShapes: number[][] = [];\n  let previousSum = 0;\n  for (let i = 0; i < attributes.numOutputs; i++) {\n    previousSum += attributes.splitSizes[i];\n    sizeInConcatAxis[i] = previousSum;\n    const outputShape = inputShape.slice();\n    outputShape[attributes.axis] = attributes.splitSizes[i];\n    outputShapes.push(outputShape);\n    outputs[i] = outputVariable(`output${i}`, dataType, outputShapes[i]);\n    outputsTensorInfo.push({dims: outputShapes[i], dataType: inputs[0].dataType});\n  }\n  const indicesAxis = rank < 2 ? 'indices' : `indices[${adjustedAxis}]`;\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n  ${shaderHelper.declareVariables(input, ...outputs)}\n  const sizeInConcatAxis = array<u32, ${sizeInConcatAxis.length}>(${sizeInConcatAxis.map(i => `${i}u`).join(',')});\n  ${calculateOutputIndexImpl(sizeInConcatAxis.length)}\n  ${writeBufferDataImpl(outputs)}\n\n  ${shaderHelper.mainStart()}\n    ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(inputSize)}\n\n    var indices = ${input.offsetToIndices('global_idx')};\n    let outputNumber = calculateOutputIndex(${indicesAxis});\n    if (outputNumber != 0) {\n        ${indicesAxis} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;\n  return {\n    name: 'Split',\n    shaderCache: {hint: attributes.cacheKey},\n    getShaderSource,\n    getRunData: () => ({\n      outputs: outputsTensorInfo,\n      dispatchGroup: {x: Math.ceil(inputSize / 64 /* workgroup size */)},\n    })\n  };\n};\n\nexport const split = (context: ComputeContext, attributes: SplitAttributes): void => {\n  validateInputs(context.inputs);\n  const updatedAttributes =\n      context.inputs.length === 1 ? attributes : createSplitAttributesFromInputs(context.inputs, attributes);\n  context.compute(createSplitProgramInfo(context.inputs, updatedAttributes), {inputs: [0]});\n};\n\nexport const parseSplitAttributes = (attributes: Record<string, unknown>): SplitAttributes => {\n  const axis = attributes.axis as number;\n  const splitSizes: number[] = attributes.splitSizes as number[];\n  const numOutputs = attributes.numOutputs as number < 0 ? splitSizes.length : attributes.numOutputs as number;\n  if (numOutputs !== splitSizes.length) {\n    throw new Error('numOutputs and splitSizes lengh must be equal');\n  }\n  return createAttributeWithCacheKey({axis, numOutputs, splitSizes});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst getRepeats = (repeatsTensorView: TensorView): readonly number[] =>\n    Array.from(repeatsTensorView.getBigInt64Array(), Number);\n\n\nconst validateInputs = (inputs: readonly TensorView[]): void => {\n  if (!inputs || inputs.length !== 2) {\n    throw new Error('Tile requires 2 inputs.');\n  }\n\n  if (inputs[0].dataType !== DataType.float && inputs[0].dataType !== DataType.int32 &&\n      inputs[0].dataType !== DataType.uint32) {\n    throw new Error('Tile only support float, int32, and uint32 data types');\n  }\n\n  if (inputs[1].dataType !== DataType.int64) {\n    throw new Error('Tile `repeats` input should be of int64 data type');\n  }\n\n  if (inputs[1].dims.length !== 1) {\n    throw new Error('Tile `repeats` input should be 1-D');\n  }\n\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n\n  if (repeats.length !== inputs[0].dims.length) {\n    throw new Error('Tile `repeats` input should have same number of elements as rank of input data tensor');\n  }\n};\n\nconst getOutputShape = (inputShape: readonly number[], repeats: readonly number[]): readonly number[] => {\n  const outputShape: number[] = [];\n\n  for (let i = 0; i < inputShape.length; ++i) {\n    outputShape.push(inputShape[i] * repeats[i]);\n  }\n\n  return outputShape;\n};\n\nexport const createTileProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const inputShape = inputs[0].dims;\n  const repeats: readonly number[] = getRepeats(inputs[1]);\n  const outputShape = getOutputShape(inputShape, repeats);\n  const outputSize = ShapeUtil.size(outputShape);\n\n  const dataType = inputs[0].dataType;\n  const input = inputVariable('input', dataType, inputShape);\n  const output = outputVariable('output', dataType, outputShape);\n\n  const getShaderSource = (shaderHelper: ShaderHelper) => `\n      const inputShape = ${input.indices(...inputShape)};\n      ${shaderHelper.declareVariables(input, output)}\n      ${shaderHelper.mainStart()}\n      ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(outputSize)}\n      let outputIndices = ${output.offsetToIndices('global_idx')};\n      var inputIndices: ${input.type.indices};\n      for (var i = 0; i < ${inputShape.length}; i++) {\n        let inputDimValue = ${output.indicesGet('outputIndices', 'i')}  % ${input.indicesGet('inputShape', 'i')};\n\n        ${input.indicesSet('inputIndices', 'i', 'inputDimValue')}\n      }\n      ${output.setByOffset('global_idx', input.getByIndices('inputIndices'))}\n    }`;\n\n  return {\n    name: 'Tile',\n    shaderCache: {hint: `${repeats}`},\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: inputs[0].dataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */)},\n    }),\n    getShaderSource,\n  };\n};\n\nexport const tile = (context: ComputeContext): void => {\n  validateInputs(context.inputs);\n  context.compute(createTileProgramInfo(context.inputs), {inputs: [0]});\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {DataType} from '../../../wasm-common';\nimport {TensorView} from '../../tensor-view';\nimport {BroadcastUtil, ShapeUtil} from '../../util';\nimport {ComputeContext, ProgramInfo} from '../types';\n\nimport {inputVariable, outputVariable, ShaderHelper} from './common';\n\nconst createWhereOpProgramShader =\n    (shaderHelper: ShaderHelper, inputs: readonly TensorView[], dimsOutput: readonly number[], isBroadcast: boolean,\n     typeOutput: number) => {\n      const outputSize = ShapeUtil.size(dimsOutput);\n      const vecSize = Math.ceil(outputSize / 4);\n\n      const output = outputVariable('outputData', typeOutput, dimsOutput, 4);\n      const a = inputVariable('aData', inputs[1].dataType, inputs[1].dims, 4);\n      const b = inputVariable('bData', inputs[2].dataType, inputs[2].dims, 4);\n      const c = inputVariable('cData', inputs[0].dataType, inputs[0].dims, 4);\n\n      let assignment: string;\n      const expression = (a: string, b: string, c: string) => `select(${b}, ${a}, ${c})`;\n      if (!isBroadcast) {\n        assignment = output.setByOffset(\n            'global_idx',\n            expression(a.getByOffset('global_idx'), b.getByOffset('global_idx'), c.getByOffset('global_idx')));\n      } else {\n        const singleAssignment = (resStr: string, x: number, typeCast = '') => {\n          const expressionA = `aData[indexA${x}][componentA${x}]`;\n          const expressionB = `bData[indexB${x}][componentB${x}]`;\n          // eslint-disable-next-line no-bitwise\n          const expressionC = `bool(cData[indexC${x}] & ${0xff000000 >>> ((3 - x) * 8)}u)`;\n          return `\n            let outputIndices${x} = ${output.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${a.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetB${x} = ${b.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let offsetC${x} = ${c.broadcastedIndicesToOffset(`outputIndices${x}`, output)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let indexC${x} = offsetC${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${resStr}[${x}] = ${typeCast}(${expression(expressionA, expressionB, expressionC)});\n          `;\n        };\n        if (typeOutput === DataType.bool) {\n          assignment = `\n            var data = vec4<u32>(0);\n            ${singleAssignment('data', 0, 'u32')}\n            ${singleAssignment('data', 1, 'u32')}\n            ${singleAssignment('data', 2, 'u32')}\n            ${singleAssignment('data', 3, 'u32')}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`;\n        } else {\n          assignment = `\n            ${singleAssignment('outputData[global_idx]', 0)}\n            ${singleAssignment('outputData[global_idx]', 1)}\n            ${singleAssignment('outputData[global_idx]', 2)}\n            ${singleAssignment('outputData[global_idx]', 3)}\n          `;\n        }\n      }\n\n      return `\n        ${shaderHelper.declareVariables(c, a, b, output)}\n        ${shaderHelper.mainStart()}\n        ${shaderHelper.guardAgainstOutOfBoundsWorkgroupSizes(vecSize)}\n        ${assignment}\n      }`;\n    };\n\nconst createWhereOpProgramInfo = (inputs: readonly TensorView[]): ProgramInfo => {\n  const dimsA = inputs[1].dims;\n  const dimsB = inputs[2].dims;\n  const dimsC = inputs[0].dims;\n  const outputDataType = inputs[1].dataType;\n\n  const isBroadcast = !(ShapeUtil.areEqual(dimsA, dimsB) && ShapeUtil.areEqual(dimsB, dimsC));\n  let outputShape = dimsA;\n  let outputSize = ShapeUtil.size(dimsA);\n  // TODO: deal with zero-sized tensors (eg. dims=[1,0])\n\n  if (isBroadcast) {\n    const calculatedShape = BroadcastUtil.calcShape(BroadcastUtil.calcShape(dimsA, dimsB, false)!, dimsC, false);\n    if (!calculatedShape) {\n      throw new Error('Can\\'t perform where op on the given tensors');\n    }\n    outputShape = calculatedShape;\n    outputSize = ShapeUtil.size(outputShape);\n  }\n\n  return {\n    name: 'Where',\n    getShaderSource: (shaderHelper) =>\n        createWhereOpProgramShader(shaderHelper, inputs, outputShape, isBroadcast, outputDataType),\n    getRunData: () => ({\n      outputs: [{dims: outputShape, dataType: outputDataType}],\n      dispatchGroup: {x: Math.ceil(outputSize / 64 /* workgroup size */ / 4 /* vec size */)}\n    }),\n  };\n};\n\nexport const where = (context: ComputeContext): void => {\n  context.compute(createWhereOpProgramInfo(context.inputs));\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {argMax, argMin, parseArgMinMaxAttributes} from './ops/argminmax';\nimport {biasAdd} from './ops/bias-add';\nimport {biasSplitGelu} from './ops/bias-split-gelu';\nimport * as binaryOps from './ops/binary-op';\nimport {concat, parseConcatAttributes} from './ops/concat';\nimport {conv, parseConvAttributes} from './ops/conv';\nimport {convTranspose, parseConvTransposeAttributes} from './ops/conv-transpose';\nimport {einsum, parseEinsumAttributes} from './ops/einsum';\nimport {expand} from './ops/expand';\nimport {gather, parseGatherAttributes} from './ops/gather';\nimport {gatherElements, parseGatherElementsAttributes} from './ops/gather-elements';\nimport {gemm, parseGemmAttributes} from './ops/gemm';\nimport {instanceNorm, parseInstanceNormAttributes} from './ops/instance-norm';\nimport {layerNorm, parseLayerNormAttributes} from './ops/layer-norm';\nimport {matMul} from './ops/matmul';\nimport {pad, parsePadAttributes} from './ops/pad';\nimport * as pool from './ops/pool';\nimport {range} from './ops/range';\nimport {parseReduceAttributes, reduceL1, reduceL2, reduceLogSum, reduceLogSumExp, reduceMax, reduceMean, reduceMin, reduceProd, reduceSum, reduceSumSquare} from './ops/reduce';\nimport {parseResizeAttributes, resize} from './ops/resize';\nimport {parseSkipLayerNormAttributes, skipLayerNorm} from './ops/skip-layer-norm';\nimport {parseSliceAttributes, slice} from './ops/slice';\nimport {parseSoftmaxAttributes, softmax} from './ops/softmax';\nimport {parseSplitAttributes, split} from './ops/split';\nimport {tile} from './ops/tile';\nimport {parseTransposeAttributes, transpose} from './ops/transpose';\nimport * as unaryOps from './ops/unary-op';\nimport {where} from './ops/where';\nimport {ComputeContext} from './types';\n\nexport type RunFunction = (context: ComputeContext, attribute?: unknown) => void;\nexport type ParseAttributeFunction = (attributeRaw: unknown) => unknown;\nexport type OperatorImplementation = [RunFunction]|[RunFunction, ParseAttributeFunction];\n\nexport const WEBGPU_OP_RESOLVE_RULES: Map<string, OperatorImplementation> = new Map([\n  ['Abs', [unaryOps.abs]],\n  ['Acos', [unaryOps.acos]],\n  ['Acosh', [unaryOps.acosh]],\n  ['Add', [binaryOps.add]],\n  ['ArgMax', [argMax, parseArgMinMaxAttributes]],\n  ['ArgMin', [argMin, parseArgMinMaxAttributes]],\n  ['Asin', [unaryOps.asin]],\n  ['Asinh', [unaryOps.asinh]],\n  ['Atan', [unaryOps.atan]],\n  ['Atanh', [unaryOps.atanh]],\n  // TODO: support new attributes for AveragePool-10\n  ['AveragePool', [pool.averagePool, pool.parseAveragePoolAttributes]],\n  ['BiasAdd', [biasAdd]],\n  ['BiasSplitGelu', [biasSplitGelu]],\n  ['Cast', [unaryOps.cast, unaryOps.parseCastAttributes]],\n  ['Ceil', [unaryOps.ceil]],\n  ['ClipV10', [unaryOps.clipV10]],\n  ['Clip', [unaryOps.clip]],\n  ['Concat', [concat, parseConcatAttributes]],\n  ['Conv', [conv, parseConvAttributes]],\n  ['ConvTranspose', [convTranspose, parseConvTransposeAttributes]],\n  ['Cos', [unaryOps.cos]],\n  ['Cosh', [unaryOps.cosh]],\n  ['Div', [binaryOps.div]],\n  ['Einsum', [einsum, parseEinsumAttributes]],\n  ['Elu', [unaryOps.elu, unaryOps.parseAlphaAttributes]],\n  ['Equal', [binaryOps.equal]],\n  ['Erf', [unaryOps.erf]],\n  ['Exp', [unaryOps.exp]],\n  ['Expand', [expand]],\n  ['Floor', [unaryOps.floor]],\n  ['FusedConv', [conv, parseConvAttributes]],\n  ['Gather', [gather, parseGatherAttributes]],\n  ['GatherElements', [gatherElements, parseGatherElementsAttributes]],\n  ['Gelu', [unaryOps.gelu]],\n  ['Gemm', [gemm, parseGemmAttributes]],\n  ['GlobalAveragePool', [pool.globalAveragePool, pool.parseGlobalAveragePoolAttributes]],\n  ['GlobalMaxPool', [pool.globalMaxPool, pool.parseGlobalMaxPoolAttributes]],\n  ['Greater', [binaryOps.greater]],\n  ['GreaterOrEqual', [binaryOps.greaterOrEqual]],\n  ['InstanceNormalization', [instanceNorm, parseInstanceNormAttributes]],\n  ['LayerNormalization', [layerNorm, parseLayerNormAttributes]],\n  ['LeakyRelu', [unaryOps.leakyRelu, unaryOps.parseAlphaAttributes]],\n  ['Less', [binaryOps.less]],\n  ['LessOrEqual', [binaryOps.lessOrEqual]],\n  ['Log', [unaryOps.log]],\n  ['MatMul', [matMul]],\n  // TODO: support new attributes for MaxPool-8 and MaxPool-10\n  ['MaxPool', [pool.maxPool, pool.parseMaxPoolAttributes]],\n  ['Mul', [binaryOps.mul]],\n  ['Neg', [unaryOps.neg]],\n  ['Not', [unaryOps.not]],\n  ['Pad', [pad, parsePadAttributes]],\n  ['Pow', [binaryOps.pow]],\n  ['Range', [range]],\n  ['Reciprocal', [unaryOps.reciprocal]],\n  ['ReduceMin', [reduceMin, parseReduceAttributes]],\n  ['ReduceMean', [reduceMean, parseReduceAttributes]],\n  ['ReduceMax', [reduceMax, parseReduceAttributes]],\n  ['ReduceSum', [reduceSum, parseReduceAttributes]],\n  ['ReduceProd', [reduceProd, parseReduceAttributes]],\n  ['ReduceL1', [reduceL1, parseReduceAttributes]],\n  ['ReduceL2', [reduceL2, parseReduceAttributes]],\n  ['ReduceLogSum', [reduceLogSum, parseReduceAttributes]],\n  ['ReduceLogSumExp', [reduceLogSumExp, parseReduceAttributes]],\n  ['ReduceSumSquare', [reduceSumSquare, parseReduceAttributes]],\n  ['Relu', [unaryOps.relu]],\n  ['Resize', [resize, parseResizeAttributes]],\n  ['Sigmoid', [unaryOps.sigmoid]],\n  ['Sin', [unaryOps.sin]],\n  ['Sinh', [unaryOps.sinh]],\n  ['Slice', [slice, parseSliceAttributes]],\n  ['SkipLayerNormalization', [skipLayerNorm, parseSkipLayerNormAttributes]],\n  ['Split', [split, parseSplitAttributes]],\n  ['Sqrt', [unaryOps.sqrt]],\n  ['Softmax', [softmax, parseSoftmaxAttributes]],\n  ['Sub', [binaryOps.sub]],\n  ['Tan', [unaryOps.tan]],\n  ['Tanh', [unaryOps.tanh]],\n  ['ThresholdedRelu', [unaryOps.thresholdedRelu, unaryOps.parseAlphaAttributes]],\n  ['Tile', [tile]],\n  ['Transpose', [transpose, parseTransposeAttributes]],\n  ['Where', [where]],\n]);\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {tensorDataTypeEnumToString} from '../../wasm-common';\nimport {WebGpuBackend} from '../backend-webgpu';\nimport {LOG_DEBUG} from '../log';\nimport {TensorView} from '../tensor-view';\n\nimport {createShaderHelper} from './ops/common';\nimport {Artifact, GpuData, ProgramInfo} from './types';\n\n/**\n * ProgramManager is the main class behind running computations\n * It builds ProgramInfo's into Artifacts\n * It compiles given ProgramInfo's into WebGL Prorams (cached as Artifacts)\n * Uses the artifact to run the computation by calling Draw on\n * the WebGL drawing buffer\n * ProgramManager automatically maps (binds) input variables to their\n * corresponding Location's in the binary program\n */\nexport class ProgramManager {\n  repo: Map<unknown, Artifact>;  // this should be per-session object\n  attributesBound: boolean;\n\n  constructor(private backend: WebGpuBackend) {\n    this.repo = new Map();\n    this.attributesBound = false;\n  }\n  getArtifact(key: unknown): Artifact|undefined {\n    return this.repo.get(key);\n  }\n  setArtifact(key: unknown, artifact: Artifact): void {\n    this.repo.set(key, artifact);\n  }\n  run(buildArtifact: Artifact, inputTensorViews: readonly TensorView[], outputTensorViews: readonly TensorView[],\n      inputs: GpuData[], outputs: GpuData[], dispatchGroup: [number, number, number],\n      uniformBufferBinding: GPUBindingResource|undefined): void {\n    const device = this.backend.device;\n\n    const computePassEncoder = this.backend.getComputePassEncoder();\n    computePassEncoder.setPipeline(buildArtifact.computePipeline);\n    const entries = [];\n    for (const input of inputs) {\n      entries.push({binding: entries.length, resource: {buffer: input.buffer}});\n    }\n    for (const output of outputs) {\n      entries.push({binding: entries.length, resource: {buffer: output.buffer}});\n    }\n    if (uniformBufferBinding) {\n      entries.push({binding: entries.length, resource: uniformBufferBinding});\n    }\n    const bindGroup = device.createBindGroup(\n        {layout: buildArtifact.computePipeline.getBindGroupLayout(0), entries, label: buildArtifact.programInfo.name});\n    computePassEncoder.setBindGroup(0, bindGroup);\n\n    computePassEncoder.dispatchWorkgroups(...dispatchGroup);\n\n    this.backend.pendingDispatchNumber++;\n\n    if (this.backend.isQueryEnabled()) {\n      if (typeof this.backend.queryData === 'undefined') {\n        this.backend.queryData = this.backend.gpuDataManager.create(\n            // eslint-disable-next-line no-bitwise\n            this.backend.querySetCount * 8, GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE);\n      }\n      const syncData = this.backend.gpuDataManager.create(\n          // eslint-disable-next-line no-bitwise\n          this.backend.querySetCount * 8, GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST);\n\n      this.backend.endComputePass();\n      this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet!, 0, 2, this.backend.queryData.buffer, 0);\n      this.backend.getCommandEncoder().copyBufferToBuffer(\n          this.backend.queryData.buffer, 0, syncData.buffer, 0, this.backend.querySetCount * 8);\n      this.backend.flush();\n\n      const kernelId = this.backend.currentKernelId!;\n      const kernelInfo = this.backend.kernels.get(kernelId)!;\n      const kernelName = `[${kernelInfo[0]}] ${kernelInfo[1]}`;\n\n      void syncData.buffer.mapAsync(GPUMapMode.READ).then(() => {\n        const mappedData = new BigUint64Array(syncData.buffer.getMappedRange());\n        const startTimeU64 = mappedData[0];\n        const endTimeU64 = mappedData[1];\n\n        syncData.buffer.unmap();\n\n        if (typeof this.backend.queryTimeBase === 'undefined') {\n          this.backend.queryTimeBase = startTimeU64;\n        }\n\n        const startTime = Number(startTimeU64 - this.backend.queryTimeBase);\n        const endTime = Number(endTimeU64 - this.backend.queryTimeBase);\n\n        if (!Number.isSafeInteger(startTime) || !Number.isSafeInteger(endTime)) {\n          throw new RangeError('incorrect timestamp range');\n        }\n\n        this.backend.gpuDataManager.release(syncData.id);\n        let inputShapes = '';\n        inputTensorViews.forEach((value, i) => {\n          inputShapes += `input[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        let outputShapes = '';\n        outputTensorViews.forEach((value, i) => {\n          outputShapes += `output[${i}]: [${value.dims}] | ${tensorDataTypeEnumToString(value.dataType)}, `;\n        });\n        // eslint-disable-next-line no-console\n        console.log(`[profiling] kernel \"${kernelId}|${kernelName}\" ${inputShapes}${outputShapes}execution time: ${\n            endTime - startTime} ns`);\n      });\n    }\n\n    if (this.backend.pendingDispatchNumber >= 16) {\n      this.backend.flush();\n    }\n  }\n  dispose(): void {\n    // this.repo.forEach(a => this.glContext.deleteProgram(a.program));\n  }\n  build(programInfo: ProgramInfo, normalizedDispatchGroupSize: [number, number, number]): Artifact {\n    const device = this.backend.device;\n    const extensions: string[] = [];\n    if (device.features.has('shader-f16')) {\n      extensions.push('enable f16;');\n    }\n    const shaderHelper = createShaderHelper(normalizedDispatchGroupSize);\n    const userCode = programInfo.getShaderSource(shaderHelper);\n    const code = `${extensions.join('\\n')}\\n${shaderHelper.additionalImplementations}\\n${userCode}`;\n    const shaderModule = device.createShaderModule({code, label: programInfo.name});\n    LOG_DEBUG('verbose', () => `[WebGPU] ${programInfo.name} shader code: ${code}`);\n\n    const computePipeline = device.createComputePipeline(\n        {compute: {module: shaderModule, entryPoint: 'main'}, layout: 'auto', label: programInfo.name});\n\n    return {programInfo, computePipeline};\n  }\n\n  normalizeDispatchGroupSize(dispatchGroup: ReturnType<ProgramInfo['getRunData']>['dispatchGroup']):\n      [number, number, number] {\n    const x = typeof dispatchGroup === 'number' ? dispatchGroup : dispatchGroup.x;\n    const y = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.y || 1);\n    const z = typeof dispatchGroup === 'number' ? 1 : (dispatchGroup.z || 1);\n    const limitPerDimension = this.backend.device.limits.maxComputeWorkgroupsPerDimension;\n    if (x <= limitPerDimension && y <= limitPerDimension && z <= limitPerDimension) {\n      return [x, y, z];\n    }\n    const size = x * y * z;\n    let dispatchAverage = Math.ceil(Math.sqrt(size));\n    if (dispatchAverage > limitPerDimension) {\n      dispatchAverage = Math.ceil(Math.cbrt(size));\n      if (dispatchAverage > limitPerDimension) {\n        throw new Error('Total dispatch size exceeds WebGPU maximum.');\n      }\n      return [dispatchAverage, dispatchAverage, dispatchAverage];\n    } else {\n      return [dispatchAverage, dispatchAverage, 1];\n    }\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, Tensor} from 'onnxruntime-common';\n\nimport {configureLogger, LOG_DEBUG} from './log';\nimport {createView, TensorView} from './tensor-view';\nimport {createGpuDataManager, downloadGpuData, GpuDataManager} from './webgpu/gpu-data-manager';\nimport {RunFunction, WEBGPU_OP_RESOLVE_RULES} from './webgpu/op-resolve-rules';\nimport {ProgramManager} from './webgpu/program-manager';\nimport {ComputeContext, GpuData, ProgramInfo, ProgramInputTensorInfoDependency} from './webgpu/types';\n\nconst getProgramInputTensorInfoDependencyKey =\n    (inputTensors: readonly TensorView[], inputDependencies: readonly ProgramInputTensorInfoDependency[]): string => {\n      if (inputDependencies.length !== inputTensors.length) {\n        throw new Error(`inputDependencies length ${inputDependencies.length} is not equal to inputTensors length ${\n            inputTensors.length}.`);\n      }\n\n      const inputInfos: string[] = [];\n      for (let i = 0; i < inputTensors.length; ++i) {\n        const type = inputTensors[i].dataType;\n        switch (inputDependencies[i]) {\n          case 'none': {\n            inputInfos.push('');\n            break;\n          }\n          case 'type': {\n            inputInfos.push(`${type}`);\n            break;\n          }\n          case 'rank': {\n            const rank = inputTensors[i].dims.length;\n            inputInfos.push(`${type};${rank}`);\n            break;\n          }\n          case 'dims': {\n            const dims = inputTensors[i].dims.join(',');\n            inputInfos.push(`${type};${dims}`);\n            break;\n          }\n          default:\n            throw new Error(`unsupported input dependency: ${inputDependencies[i]}`);\n        }\n      }\n\n      return inputInfos.join('|');\n    };\n\n/**\n * get a unique key representing the program from the program info, input shapes and types.\n *\n * @returns a unique key is a shorter string than the shader source, which contains all the information to identify a\n * program. if the key is the same, the program shader source should be the same, so we can reuse the program.\n *\n */\nconst getProgramInfoUniqueKey =\n    (programInfo: ProgramInfo, inputTensors: readonly TensorView[], is1DimensionDispatch: boolean): string => {\n      // final key format:\n      // <PROGRAM_NAME>[<PROGRAM_CUSTOM_CACHE_HINT>]:is1DimensionDispatch:<INPUTS_INFO_0>|<INPUTS_INFO_1>|...\n      let key = programInfo.name;\n      if (programInfo.shaderCache?.hint) {\n        key += '[' + programInfo.shaderCache.hint + ']';\n      }\n      key += ':' + is1DimensionDispatch +\n          `:${\n                 getProgramInputTensorInfoDependencyKey(\n                     inputTensors,\n                     programInfo.shaderCache?.inputDependencies ??\n                         new Array<ProgramInputTensorInfoDependency>(inputTensors.length).fill('dims'))}`;\n      return key;\n    };\n\n/**\n * this class is designed to store status and being used as a singleton for JSEP. It will be passed to jsepInit() as\n * the first parameter so that it is stored for future use.\n */\nexport class WebGpuBackend {\n  device: GPUDevice;\n  /**\n   * an instance of GpuDataManager to manage a GpuDataId -> GpuBuffer mapping\n   */\n  gpuDataManager: GpuDataManager;\n  /**\n   * an instance of ProgramManager to build and run WebGPU compute shader program, and manage a ProgramKey -> Program\n   * artifacts mapping\n   */\n  programManager: ProgramManager;\n\n  /**\n   * representing the kernel ID of which is currently being computed (CPU code perspective).\n   * `null` means no kernel is being computed.\n   * only one kernel can be computed at a moment.\n   */\n  currentKernelId: number|null = null;\n  /**\n   * a list of temporary GPU data for the current kernel. should release when the kernel done computation.\n   */\n  private temporaryData: GpuData[];\n  /**\n   * a KernelID -> a GPU data list, which stores persistent GPU data owned by the specific kernel.\n   */\n  private kernelPersistentData: Map<number, GpuData[]>;\n  /**\n   * a KernelID -> a custom data, which stores custom data owned by the specific kernel.\n   */\n  private kernelCustomData: Map<number, {[key: string]: unknown}>;\n  /**\n   * get the custom data of the current kernel\n   */\n  get currentKernelCustomData(): {[key: string]: unknown} {\n    if (this.currentKernelId === null) {\n      throw new Error('currentKernelCustomData(): currentKernelId is null. (should not happen)');\n    }\n\n    let data = this.kernelCustomData.get(this.currentKernelId);\n    if (!data) {\n      data = {};\n      this.kernelCustomData.set(this.currentKernelId, data);\n    }\n\n    return data;\n  }\n\n  /**\n   * a KernelID -> kernel info mapping. value is\n   * [ op_type, name, run function, [optional] preprocess_attribute_once function ]\n   */\n  kernels: Map<number, [string, string, RunFunction, [((attribute: unknown) => unknown) | undefined, unknown]]>;\n\n  private commandEncoder: GPUCommandEncoder|null = null;\n  private computePassEncoder: GPUComputePassEncoder|null = null;\n  pendingDispatchNumber = 0;\n\n  queryData?: GpuData;\n  querySet?: GPUQuerySet;\n  querySetCount = 2;\n  queryTimeBase?: bigint;\n\n  env: Env;\n\n  /**\n   * a SessionID -> a Map of (InputOutputIndex -> [ID, GPUBuffer]) mapping.\n   */\n  sessionExternalDataMapping: Map<number, Map<number, [number, GPUBuffer]>> = new Map();\n\n  async initialize(env: Env): Promise<void> {\n    if (!navigator.gpu) {\n      // WebGPU is not available.\n      throw new Error('WebGpuBackend: WebGPU is not available.');\n    }\n\n    const adapter = await navigator.gpu.requestAdapter();\n    if (!adapter) {\n      throw new Error('WebGpuBackend: Failed to get GPU adapter.');\n    }\n\n    this.env = env;\n    const requiredFeatures: GPUFeatureName[] = [];\n    const deviceDescriptor: GPUDeviceDescriptor = {\n      requiredLimits: {\n        maxComputeWorkgroupStorageSize: adapter.limits.maxComputeWorkgroupStorageSize,\n        maxComputeWorkgroupsPerDimension: adapter.limits.maxComputeWorkgroupsPerDimension,\n        maxStorageBufferBindingSize: adapter.limits.maxStorageBufferBindingSize,\n        maxBufferSize: adapter.limits.maxBufferSize,\n        maxComputeInvocationsPerWorkgroup: adapter.limits.maxComputeInvocationsPerWorkgroup,\n        maxComputeWorkgroupSizeX: adapter.limits.maxComputeWorkgroupSizeX,\n        maxComputeWorkgroupSizeY: adapter.limits.maxComputeWorkgroupSizeY,\n        maxComputeWorkgroupSizeZ: adapter.limits.maxComputeWorkgroupSizeZ,\n      },\n      requiredFeatures,\n    };\n\n    if (adapter.features.has('timestamp-query')) {\n      requiredFeatures.push('timestamp-query');\n    }\n    if (adapter.features.has('shader-f16')) {\n      requiredFeatures.push('shader-f16');\n    }\n\n    this.device = await adapter.requestDevice(deviceDescriptor);\n    this.gpuDataManager = createGpuDataManager(this);\n    this.programManager = new ProgramManager(this);\n    this.kernels = new Map();\n    this.kernelPersistentData = new Map();\n    this.kernelCustomData = new Map();\n\n    // set up flags for logger\n    configureLogger(env.logLevel!, !!env.debug);\n\n    // TODO: set up flags\n\n    this.device.onuncapturederror = ev => {\n      if (ev.error instanceof GPUValidationError) {\n        // eslint-disable-next-line no-console\n        console.error(`An uncaught WebGPU validation error was raised: ${ev.error.message}`);\n      }\n    };\n\n    Object.defineProperty(this.env.webgpu, 'device', {value: this.device});\n  }\n\n  dispose(): void {\n    if (typeof this.querySet !== 'undefined') {\n      this.querySet.destroy();\n    }\n    this.gpuDataManager.dispose();\n  }\n\n  getCommandEncoder(): GPUCommandEncoder {\n    if (!this.commandEncoder) {\n      this.commandEncoder = this.device.createCommandEncoder();\n    }\n    return this.commandEncoder;\n  }\n\n  getComputePassEncoder(): GPUComputePassEncoder {\n    if (!this.computePassEncoder) {\n      const computePassDescriptor: GPUComputePassDescriptor = {};\n      if (this.isQueryEnabled()) {\n        if (typeof this.querySet === 'undefined') {\n          this.querySet = this.device.createQuerySet({\n            type: 'timestamp',\n            count: this.querySetCount,\n          });\n        }\n        computePassDescriptor.timestampWrites = {\n          querySet: this.querySet,\n          beginningOfPassWriteIndex: 0,\n          endOfPassWriteIndex: 1,\n        };\n      }\n\n      this.computePassEncoder = this.getCommandEncoder().beginComputePass(computePassDescriptor);\n    }\n    return this.computePassEncoder;\n  }\n\n  endComputePass(): void {\n    if (this.computePassEncoder) {\n      this.computePassEncoder.end();\n      this.computePassEncoder = null;\n    }\n  }\n\n  flush(): void {\n    if (this.commandEncoder) {\n      this.endComputePass();\n      this.device.queue.submit([this.getCommandEncoder().finish()]);\n      this.gpuDataManager.refreshPendingBuffers();\n      this.commandEncoder = null;\n      this.pendingDispatchNumber = 0;\n    }\n  }\n\n  isQueryEnabled(): boolean {\n    if (this.device.features.has('timestamp-query') && this.env.webgpu.profilingMode === 'default') {\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  /**\n   * run a WebGPU program.\n   * @param program a ProgramInfo instance\n   * @param inputTensorViews a TensorView array. each element represents a value already exists in GPU.\n   * @param outputIndices an indices array. each element can be either -1 (temporary data), -2 (persistent data) or an\n   * index to the kernel's output.\n   * @param createKernelOutput a callback function that create a value to kernel's output with the given index\n   * @param createIntermediateOutput a callback function that create a value as a intermediate value, either temporary\n   * or persistent (owned by the current kernel)\n   * @returns a TensorView array representing the result.\n   */\n  run(program: ProgramInfo, inputTensorViews: readonly TensorView[], outputIndices: readonly number[],\n      createKernelOutput: (index: number, dataType: number, dims: readonly number[]) => TensorView,\n      createIntermediateOutput: (dataType: number, dims: readonly number[]) => TensorView): TensorView[] {\n    // create info for inputs\n    const inputDatas: GpuData[] = [];\n    for (let i = 0; i < inputTensorViews.length; ++i) {\n      const gpuData = this.gpuDataManager.get(inputTensorViews[i].data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for input: ${inputTensorViews[i].data}`);\n      }\n      inputDatas[i] = gpuData;\n    }\n\n    const {outputs, dispatchGroup, programUniforms} = program.getRunData(inputTensorViews);\n\n    // check output indices\n    const validatedOutputIndices = outputIndices.length === 0 ? outputs.map((_, i) => i) : outputIndices;\n    if (validatedOutputIndices.length !== outputs.length) {\n      throw new Error(`Output size ${validatedOutputIndices.length} must be equal to ${outputs.length}.`);\n    }\n\n    // create info for outputs\n    const outputTensorViews: TensorView[] = [];\n    const outputDatas: GpuData[] = [];\n    for (let i = 0; i < outputs.length; ++i) {\n      // value -1 and -2 are used for creating temporary and persistent outputs.\n      // value -3 is used for placeholder output. So -3, -2, -1 and 0, 1, 2, ... are valid\n      // output indices. see type definition of ComputeContextInputsOutputsMapping for more details.\n      if (!Number.isInteger(validatedOutputIndices[i]) || validatedOutputIndices[i] < -3 ||\n          validatedOutputIndices[i] >= outputs.length) {\n        throw new Error(`Invalid output index: ${validatedOutputIndices[i]}`);\n      }\n      if (validatedOutputIndices[i] === -3) {\n        continue;\n      }\n      const isTemporary = validatedOutputIndices[i] === -1;\n      const isPersistent = validatedOutputIndices[i] === -2;\n      const tensorView = (isTemporary || isPersistent) ?\n          createIntermediateOutput(outputs[i].dataType, outputs[i].dims) :\n          createKernelOutput(validatedOutputIndices[i], outputs[i].dataType, outputs[i].dims);\n      const gpuData = this.gpuDataManager.get(tensorView.data);\n      if (!gpuData) {\n        throw new Error(`no GPU data for output: ${tensorView.data}`);\n      }\n      if (isTemporary) {\n        this.temporaryData.push(gpuData);\n      }\n      if (isPersistent) {\n        let persistentData = this.kernelPersistentData.get(this.currentKernelId!);\n        if (!persistentData) {\n          persistentData = [];\n          this.kernelPersistentData.set(this.currentKernelId!, persistentData);\n        }\n        persistentData.push(gpuData);\n      }\n      outputTensorViews.push(tensorView);\n      outputDatas.push(gpuData);\n    }\n\n\n    // load uniforms\n    // TODO: add cache for uniform (is it necessary?)\n    //\n    let uniformBufferBinding: GPUBindingResource|undefined;\n    if (programUniforms) {\n      let currentOffset = 0;\n      let preLength = 0;\n      const offsets: number[] = [];\n      let maxAlignmentOfField = 1;\n      programUniforms.forEach(v => {\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (data.length === 0) {\n          return;\n        }\n        // https://www.w3.org/TR/WGSL/#alignof\n        let baseAlignment: number;\n        switch (data.length) {\n          case 1:\n            baseAlignment = 4;\n            break;\n          case 2:\n            baseAlignment = 8;\n            break;\n          case 3:\n            baseAlignment = 16;\n            break;\n          case 4:\n            baseAlignment = 16;\n            break;\n          case 5:\n            baseAlignment = 16;\n            break;\n          case 6:\n            baseAlignment = 16;\n            break;\n          default:\n            throw new Error(`unsupported data length: ${data.length}`);\n        }\n\n        if (preLength === 5 || preLength === 6) {\n          baseAlignment = 16;\n        }\n        if (baseAlignment > maxAlignmentOfField) {\n          maxAlignmentOfField = baseAlignment;\n        }\n        currentOffset = Math.ceil(currentOffset / baseAlignment) * baseAlignment;\n        preLength = data.length;\n        offsets.push(currentOffset);\n        currentOffset += data.length * 4;\n      });\n\n      currentOffset = Math.ceil(currentOffset / maxAlignmentOfField) * maxAlignmentOfField;\n      const arrayBuffer = new ArrayBuffer(currentOffset);\n      programUniforms.forEach((v, i) => {\n        const offset = offsets[i];\n        const data = typeof v.data === 'number' ? [v.data] : v.data;\n        if (v.type === 'int32') {\n          new Int32Array(arrayBuffer, offset, data.length).set(data);\n        } else if (v.type === 'uint32') {\n          new Uint32Array(arrayBuffer, offset, data.length).set(data);\n        } else {\n          new Float32Array(arrayBuffer, offset, data.length).set(data);\n        }\n      });\n\n      const uniformBufferData =\n          // eslint-disable-next-line no-bitwise\n          this.gpuDataManager.create(currentOffset, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);\n      this.device.queue.writeBuffer(uniformBufferData.buffer, 0, arrayBuffer, 0, currentOffset);\n      this.gpuDataManager.release(uniformBufferData.id);\n      uniformBufferBinding = {offset: 0, size: currentOffset, buffer: uniformBufferData.buffer};\n    }\n\n    const normalizedDispatchGroup = this.programManager.normalizeDispatchGroupSize(dispatchGroup);\n    const is1DimensionDispatch = normalizedDispatchGroup[1] === 1 && normalizedDispatchGroup[2] === 1;\n    // get program info\n    const key = getProgramInfoUniqueKey(program, inputTensorViews, is1DimensionDispatch);\n    let artifact = this.programManager.getArtifact(key);\n    if (!artifact) {\n      artifact = this.programManager.build(program, normalizedDispatchGroup);\n      this.programManager.setArtifact(key, artifact);\n    }\n\n    LOG_DEBUG(\n        'info',\n        () => `[ProgramManager] run \"${program.name}\" (key=${key}) with ${normalizedDispatchGroup[0]}x${\n            normalizedDispatchGroup[1]}x${normalizedDispatchGroup[2]}`);\n    this.programManager.run(\n        artifact, inputTensorViews, outputTensorViews, inputDatas, outputDatas, normalizedDispatchGroup,\n        uniformBufferBinding);\n\n    return outputTensorViews;\n  }\n\n  upload(gpuDataId: number, data: Uint8Array): void {\n    this.gpuDataManager.upload(gpuDataId, data);\n  }\n\n  memcpy(src: number, dst: number): void {\n    this.gpuDataManager.memcpy(src, dst);\n  }\n\n  async download(gpuDataId: number, getTargetBuffer: () => Uint8Array): Promise<void> {\n    // the underlying buffer may be changed after the async function is called. so we use a getter function to make sure\n    // the buffer is up-to-date.\n    await this.gpuDataManager.download(gpuDataId, getTargetBuffer);\n  }\n\n  alloc(size: number): number {\n    return this.gpuDataManager.create(size).id;\n  }\n\n  free(ptr: number): number {\n    return this.gpuDataManager.release(ptr);\n  }\n\n  createKernel(opType: string, kernelId: number, attribute: unknown, nodeName: string): void {\n    const op = WEBGPU_OP_RESOLVE_RULES.get(opType);\n    if (!op) {\n      throw new Error(`kernel not implemented: ${opType}`);\n    }\n\n    this.kernels.set(kernelId, [opType, nodeName, op[0], [op[1], attribute]]);\n  }\n\n  releaseKernel(kernelId: number): void {\n    const persistentData = this.kernelPersistentData.get(kernelId);\n    if (persistentData) {\n      for (const data of persistentData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.kernelPersistentData.delete(kernelId);\n    }\n\n    this.kernelCustomData.delete(kernelId);\n    this.kernels.delete(kernelId);\n  }\n\n  computeKernel(kernelId: number, context: ComputeContext, errors: Array<Promise<string|null>>): number {\n    const kernel = this.kernels.get(kernelId);\n    if (!kernel) {\n      throw new Error(`kernel not created: ${kernelId}`);\n    }\n    const [opType, nodeName, kernelEntry, attributes] = kernel;\n    if (this.currentKernelId !== null) {\n      throw new Error(`kernel \"[${opType}] ${nodeName}\" is not allowed to be called recursively`);\n    }\n    this.currentKernelId = kernelId;\n\n    // parse attributes if necessary\n    if (attributes[0]) {\n      attributes[1] = attributes[0](attributes[1]);\n      attributes[0] = undefined;\n    }\n\n    LOG_DEBUG('info', () => `[WebGPU] Start to run kernel \"[${opType}] ${nodeName}\"...`);\n\n    const useErrorScope = this.env.debug;\n\n    this.temporaryData = [];\n    try {\n      if (useErrorScope) {\n        this.device.pushErrorScope('validation');\n      }\n\n      kernelEntry(context, attributes[1]);\n      return 0;  // ORT_OK\n    } catch (e) {\n      errors.push(Promise.resolve(`[WebGPU] Kernel \"[${opType}] ${nodeName}\" failed. ${e}`));\n      return 1;  // ORT_FAIL\n    } finally {\n      if (useErrorScope) {\n        errors.push(this.device.popErrorScope().then(\n            err => err ? `GPU validation error for kernel \"[${opType}] ${nodeName}\": ${err.message}` : null));\n      }\n\n      for (const data of this.temporaryData) {\n        this.gpuDataManager.release(data.id);\n      }\n      this.temporaryData = [];\n      this.currentKernelId = null;\n    }\n  }\n\n  // #region external buffer\n  registerBuffer(sessionId: number, index: number, buffer: GPUBuffer, size: number): number {\n    let sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (!sessionInputOutputMapping) {\n      sessionInputOutputMapping = new Map();\n      this.sessionExternalDataMapping.set(sessionId, sessionInputOutputMapping);\n    }\n\n    const previousBuffer = sessionInputOutputMapping.get(index);\n    const id = this.gpuDataManager.registerExternalBuffer(buffer, size, previousBuffer?.[1]);\n    sessionInputOutputMapping.set(index, [id, buffer]);\n    return id;\n  }\n  unregisterBuffers(sessionId: number): void {\n    const sessionInputOutputMapping = this.sessionExternalDataMapping.get(sessionId);\n    if (sessionInputOutputMapping) {\n      sessionInputOutputMapping.forEach(bufferInfo => this.gpuDataManager.unregisterExternalBuffer(bufferInfo[1]));\n      this.sessionExternalDataMapping.delete(sessionId);\n    }\n  }\n  getBuffer(gpuDataId: number): GPUBuffer {\n    const gpuData = this.gpuDataManager.get(gpuDataId);\n    if (!gpuData) {\n      throw new Error(`no GPU data for buffer: ${gpuDataId}`);\n    }\n    return gpuData.buffer;\n  }\n  createDownloader(gpuBuffer: GPUBuffer, size: number, type: Tensor.GpuBufferDataTypes):\n      () => Promise<Tensor.DataType> {\n    return async () => {\n      const data = await downloadGpuData(this, gpuBuffer, size);\n      return createView(data.buffer, type);\n    };\n  }\n  // #endregion\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env} from 'onnxruntime-common';\n\nimport {OrtWasmModule} from '../binding/ort-wasm';\nimport {DataType, getTensorElementSize} from '../wasm-common';\n\nimport {WebGpuBackend} from './backend-webgpu';\nimport {LOG_DEBUG} from './log';\nimport {TensorView} from './tensor-view';\nimport {ShapeUtil} from './util';\nimport {ComputeContext, ComputeContextInputsOutputsMapping, ProgramInfo} from './webgpu/types';\n\n/* eslint-disable no-bitwise */\n\nclass TensorViewImpl implements TensorView {\n  constructor(\n      private module: OrtWasmModule, public readonly dataType: number, public readonly data: number,\n      public readonly dims: readonly number[]) {}\n\n  getFloat32Array(): Float32Array {\n    if (this.dataType !== DataType.float) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Float32Array() :\n                                new Float32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getBigInt64Array(): BigInt64Array {\n    if (this.dataType !== DataType.int64) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new BigInt64Array() :\n                                new BigInt64Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  getInt32Array(): Int32Array {\n    if (this.dataType !== DataType.int32) {\n      throw new Error('Invalid data type');\n    }\n    const elementCount = ShapeUtil.size(this.dims);\n    return elementCount === 0 ? new Int32Array() : new Int32Array(this.module.HEAP8.buffer, this.data, elementCount);\n  }\n\n  reshape(newDims: readonly number[]): TensorView {\n    if (ShapeUtil.size(newDims) !== ShapeUtil.size(this.dims)) {\n      throw new Error('Invalid new shape');\n    }\n    return new TensorViewImpl(this.module, this.dataType, this.data, newDims);\n  }\n}\n\nclass ComputeContextImpl implements ComputeContext {\n  readonly opKernelContext: number;\n  readonly inputs: readonly TensorView[];\n  readonly outputCount: number;\n  get kernelCustomData(): {[key: string]: unknown} {\n    return this.backend.currentKernelCustomData;\n  }\n  get customDataBuffer(): Uint8Array {\n    return this.module.HEAPU8.subarray(this.customDataOffset, this.customDataOffset + this.customDataSize);\n  }\n  private customDataOffset = 0;\n  private customDataSize = 0;\n  constructor(private module: OrtWasmModule, private backend: WebGpuBackend, contextDataOffset: number) {\n    const heapU32 = module.HEAPU32;\n\n    // extract context data\n    let dataIndex = (contextDataOffset >> 2);\n    this.opKernelContext = heapU32[dataIndex++];\n    const inputCount = heapU32[dataIndex++];\n    this.outputCount = heapU32[dataIndex++];\n    this.customDataOffset = heapU32[dataIndex++];\n    this.customDataSize = heapU32[dataIndex++];\n\n    const inputs: TensorView[] = [];\n    for (let i = 0; i < inputCount; i++) {\n      const dataType = heapU32[dataIndex++];\n      const data = heapU32[dataIndex++];\n      const dim = heapU32[dataIndex++];\n      const dims: number[] = [];\n      for (let d = 0; d < dim; d++) {\n        dims.push(heapU32[dataIndex++]);\n      }\n      inputs.push(new TensorViewImpl(module, dataType, data, dims));\n    }\n    this.inputs = inputs;\n  }\n\n  compute(program: ProgramInfo, inputsOutputsMapping?: ComputeContextInputsOutputsMapping): TensorView[] {\n    // prepare inputs. inputs should always be valid data.\n    const mappedInputs =\n        inputsOutputsMapping?.inputs?.map(i => typeof i === 'number' ? this.inputs[i] : i) ?? this.inputs;\n    // prepare outputs.\n    const outputIndices = inputsOutputsMapping?.outputs ?? [];\n    const createKernelOutput = (index: number, dataType: number, dims: readonly number[]): TensorView =>\n        new TensorViewImpl(this.module, dataType, this.output(index, dims), dims);\n    const createTemporaryOutput = (dataType: number, dims: readonly number[]): TensorView => {\n      const elementSize = getTensorElementSize(dataType);\n      if (!elementSize) {\n        throw new Error(`Unsupported data type: ${dataType}`);\n      }\n      const bufferSize = elementSize * ShapeUtil.size(dims);\n      return new TensorViewImpl(this.module, dataType, this.backend.gpuDataManager.create(bufferSize).id, dims);\n    };\n    return this.backend.run(program, mappedInputs, outputIndices, createKernelOutput, createTemporaryOutput);\n  }\n\n  output(index: number, dims: readonly number[]): number {\n    const stack = this.module.stackSave();\n    try {\n      const data = this.module.stackAlloc((1 + dims.length) * 4 /* sizeof(size_t) */);\n      let offset = data >> 2;\n      this.module.HEAPU32[offset++] = dims.length;\n      for (let i = 0; i < dims.length; i++) {\n        this.module.HEAPU32[offset++] = dims[i];\n      }\n      return this.module._JsepOutput(this.opKernelContext, index, data);\n    } catch (e) {\n      throw new Error(\n          `Failed to generate kernel's output[${index}] with dims [${dims}]. ` +\n          'If you are running with pre-allocated output, please make sure the output type/dims are correct. ' +\n          `Error: ${e}`);\n    } finally {\n      this.module.stackRestore(stack);\n    }\n  }\n}\n\nexport const init = async(module: OrtWasmModule, env: Env): Promise<void> => {\n  const init = module.jsepInit;\n  if (init && navigator.gpu) {\n    if (!env.wasm.simd) {\n      throw new Error(\n          'Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP');\n    }\n    const backend = new WebGpuBackend();\n    await backend.initialize(env);\n\n    init(\n        // backend\n        backend,\n\n        // jsepAlloc()\n        (size: number) => backend.alloc(size),\n\n        // jsepFree()\n        (ptr: number) => backend.free(ptr),\n\n        // jsepCopy(src, dst, size, isSourceGpu)\n        (src: number, dst: number, size: number, isSourceGpu = false) => {\n          if (isSourceGpu) {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyGpuToGpu: src=${src}, dst=${dst}, size=${size}`);\n            backend.memcpy(src, dst);\n          } else {\n            LOG_DEBUG('verbose', () => `[WebGPU] jsepCopyCpuToGpu: dataOffset=${src}, gpuDataId=${dst}, size=${size}`);\n            const data = module.HEAPU8.subarray(src, src + size);\n            backend.upload(dst, data);\n          }\n        },\n\n        // jsepCopyAsync(src, dst, size)\n        async(gpuDataId: number, dataOffset: number, size: number):\n            Promise<void> => {\n              LOG_DEBUG(\n                  'verbose',\n                  () => `[WebGPU] jsepCopyGpuToCpu: gpuDataId=${gpuDataId}, dataOffset=${dataOffset}, size=${size}`);\n\n              await backend.download(gpuDataId, () => module.HEAPU8.subarray(dataOffset, dataOffset + size));\n            },\n\n        // jsepCreateKernel\n        (name: string, kernel: number, attribute: unknown) => backend.createKernel(\n            name, kernel, attribute,\n            env.debug || env.webgpu.profilingMode === 'default' ? module.UTF8ToString(module._JsepGetNodeName(kernel)) :\n                                                                  `${kernel}`),\n\n        // jsepReleaseKernel\n        (kernel: number) => backend.releaseKernel(kernel),\n\n        // jsepRun\n        (kernel: number, contextDataOffset: number, sessionHandle: number, errors: Array<Promise<string|null>>) => {\n          LOG_DEBUG(\n              'verbose',\n              () => `[WebGPU] jsepRun: sessionHandle=${sessionHandle}, kernel=${kernel}, contextDataOffset=${\n                  contextDataOffset}`);\n          const context = new ComputeContextImpl(module, backend, contextDataOffset);\n          return backend.computeKernel(kernel, context, errors);\n        });\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, InferenceSession, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport {setRunOptions} from './run-options';\nimport {setSessionOptions} from './session-options';\nimport {dataLocationStringToEnum, getTensorElementSize, isGpuBufferSupportedType, logLevelStringToEnum, tensorDataTypeEnumToString, tensorDataTypeStringToEnum, tensorTypeToTypedArrayConstructor} from './wasm-common';\nimport {getInstance} from './wasm-factory';\nimport {allocWasmString, checkLastError} from './wasm-utils';\n\nlet ortEnvInitialized = false;\n\n/**\n * get the input/output count of the session.\n * @param sessionHandle the handle representing the session. should be non-zero.\n * @returns a tuple including 2 numbers, representing the input count and output count.\n */\nconst getSessionInputOutputCount = (sessionHandle: number): [number, number] => {\n  const wasm = getInstance();\n  const stack = wasm.stackSave();\n  try {\n    const dataOffset = wasm.stackAlloc(8);\n    const errorCode = wasm._OrtGetInputOutputCount(sessionHandle, dataOffset, dataOffset + 4);\n    if (errorCode !== 0) {\n      checkLastError('Can\\'t get session input/output count.');\n    }\n    return [wasm.HEAP32[dataOffset / 4], wasm.HEAP32[dataOffset / 4 + 1]];\n  } finally {\n    wasm.stackRestore(stack);\n  }\n};\n\n/**\n * initialize ORT environment.\n * @param numThreads SetGlobalIntraOpNumThreads(numThreads)\n * @param loggingLevel CreateEnv(static_cast<OrtLoggingLevel>(logging_level))\n */\nconst initOrt = (numThreads: number, loggingLevel: number): void => {\n  const errorCode = getInstance()._OrtInit(numThreads, loggingLevel);\n  if (errorCode !== 0) {\n    checkLastError('Can\\'t initialize onnxruntime.');\n  }\n};\n\n/**\n * intialize runtime environment.\n * @param env passed in the environment config object.\n */\nexport const initRuntime = async(env: Env): Promise<void> => {\n  // init ORT\n  initOrt(env.wasm.numThreads!, logLevelStringToEnum(env.logLevel));\n\n  if (!BUILD_DEFS.DISABLE_WEBGPU) {\n    // init JSEP if available\n\n    // eslint-disable-next-line @typescript-eslint/no-require-imports, @typescript-eslint/no-var-requires\n    const initJsep = require('./jsep/init').init;\n    await initJsep(getInstance(), env);\n  }\n\n  ortEnvInitialized = true;\n};\n\n/**\n * valid data locations for input/output tensors.\n */\ntype SupportedTensorDataLocationForInputOutput = 'cpu'|'cpu-pinned'|'gpu-buffer';\n\ntype IOBindingState = {\n  /**\n   * the handle of IO binding.\n   */\n  readonly handle: number;\n\n  /**\n   * the preferred location for each output tensor.\n   *\n   * value is one of 'cpu', 'cpu-pinned', 'gpu-buffer'.\n   */\n  readonly outputPreferredLocations: readonly SupportedTensorDataLocationForInputOutput[];\n\n  /**\n   * enum value of the preferred location for each output tensor.\n   */\n  readonly outputPreferredLocationsEncoded: readonly number[];\n};\n\n/**\n *  tuple elements are: InferenceSession ID; inputNamesUTF8Encoded; outputNamesUTF8Encoded; bindingState\n */\ntype SessionMetadata = [\n  inferenceSessionId: number, inputNamesUTF8Encoded: number[], outputNamesUTF8Encoded: number[],\n  bindingState: IOBindingState|null\n];\n\nconst activeSessions = new Map<number, SessionMetadata>();\n\nexport const isOrtEnvInitialized = (): boolean => ortEnvInitialized;\n\n/**\n * allocate the memory and memcpy the model bytes, preparing for creating an instance of InferenceSession.\n * @returns a 2-elements tuple - the pointer and size of the allocated buffer\n */\nexport const createSessionAllocate = (model: Uint8Array): [number, number] => {\n  const wasm = getInstance();\n  const modelDataOffset = wasm._malloc(model.byteLength);\n  if (modelDataOffset === 0) {\n    throw new Error(`Can't create a session. failed to allocate a buffer of size ${model.byteLength}.`);\n  }\n  wasm.HEAPU8.set(model, modelDataOffset);\n  return [modelDataOffset, model.byteLength];\n};\n\n/**\n * create an inference session using the prepared buffer containing the model data.\n * @param modelData a 2-elements tuple containing the pointer and size of the model data buffer.\n * @param options an optional session options object.\n * @returns a 3-elements tuple containing [session handle, input names, output names]\n */\nexport const createSessionFinalize =\n    (modelData: SerializableModeldata, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const wasm = getInstance();\n\n      let sessionHandle = 0;\n      let sessionOptionsHandle = 0;\n      let ioBindingHandle = 0;\n      let allocs: number[] = [];\n      const inputNamesUTF8Encoded = [];\n      const outputNamesUTF8Encoded = [];\n\n      try {\n        [sessionOptionsHandle, allocs] = setSessionOptions(options);\n\n        sessionHandle = wasm._OrtCreateSession(modelData[0], modelData[1], sessionOptionsHandle);\n        if (sessionHandle === 0) {\n          checkLastError('Can\\'t create a session.');\n        }\n\n        const [inputCount, outputCount] = getSessionInputOutputCount(sessionHandle);\n\n        const inputNames = [];\n        const outputNames = [];\n        const outputPreferredLocations: SupportedTensorDataLocationForInputOutput[] = [];\n        for (let i = 0; i < inputCount; i++) {\n          const name = wasm._OrtGetInputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an input name.');\n          }\n          inputNamesUTF8Encoded.push(name);\n          inputNames.push(wasm.UTF8ToString(name));\n        }\n        for (let i = 0; i < outputCount; i++) {\n          const name = wasm._OrtGetOutputName(sessionHandle, i);\n          if (name === 0) {\n            checkLastError('Can\\'t get an output name.');\n          }\n          outputNamesUTF8Encoded.push(name);\n          const nameString = wasm.UTF8ToString(name);\n          outputNames.push(nameString);\n\n          if (!BUILD_DEFS.DISABLE_WEBGPU) {\n            const location = typeof options?.preferredOutputLocation === 'string' ?\n                options.preferredOutputLocation :\n                options?.preferredOutputLocation?.[nameString] ?? 'cpu';\n            if (location !== 'cpu' && location !== 'cpu-pinned' && location !== 'gpu-buffer') {\n              throw new Error(`Not supported preferred output location: ${location}.`);\n            }\n            outputPreferredLocations.push(location);\n          }\n        }\n\n        // use IO binding only when at least one output is preffered to be on GPU.\n        let bindingState: IOBindingState|null = null;\n        if (!BUILD_DEFS.DISABLE_WEBGPU && outputPreferredLocations.some(l => l === 'gpu-buffer')) {\n          ioBindingHandle = wasm._OrtCreateBinding(sessionHandle);\n          if (ioBindingHandle === 0) {\n            checkLastError('Can\\'t create IO binding.');\n          }\n\n          bindingState = {\n            handle: ioBindingHandle,\n            outputPreferredLocations,\n            outputPreferredLocationsEncoded: outputPreferredLocations.map(l => dataLocationStringToEnum(l)),\n          };\n        }\n\n        activeSessions.set(sessionHandle, [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, bindingState]);\n        return [sessionHandle, inputNames, outputNames];\n      } catch (e) {\n        inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n        outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n\n        if (ioBindingHandle !== 0) {\n          wasm._OrtReleaseBinding(ioBindingHandle);\n        }\n\n        if (sessionHandle !== 0) {\n          wasm._OrtReleaseSession(sessionHandle);\n        }\n        throw e;\n      } finally {\n        wasm._free(modelData[0]);\n        if (sessionOptionsHandle !== 0) {\n          wasm._OrtReleaseSessionOptions(sessionOptionsHandle);\n        }\n        allocs.forEach(alloc => wasm._free(alloc));\n      }\n    };\n\n\n/**\n * create an instance of InferenceSession.\n * @returns the metadata of InferenceSession. 0-value handle for failure.\n */\nexport const createSession =\n    (model: Uint8Array, options?: InferenceSession.SessionOptions): SerializableSessionMetadata => {\n      const modelData: SerializableModeldata = createSessionAllocate(model);\n      return createSessionFinalize(modelData, options);\n    };\n\nexport const releaseSession = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot release session. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  if (ioBindingState) {\n    wasm._OrtReleaseBinding(ioBindingState.handle);\n  }\n\n  wasm.jsepUnregisterBuffers?.(sessionId);\n\n  inputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  outputNamesUTF8Encoded.forEach(buf => wasm._OrtFree(buf));\n  wasm._OrtReleaseSession(sessionHandle);\n  activeSessions.delete(sessionId);\n};\n\nexport const prepareInputOutputTensor =\n    (tensor: TensorMetadata|null, tensorHandles: number[], allocs: number[], sessionId: number, index: number):\n        void => {\n          if (!tensor) {\n            tensorHandles.push(0);\n            return;\n          }\n\n          const wasm = getInstance();\n\n          const dataType = tensor[0];\n          const dims = tensor[1];\n          const location = tensor[3];\n\n          let rawData: number;\n          let dataByteLength: number;\n\n          if (dataType === 'string' && location === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n\n          if (location === 'gpu-buffer') {\n            const gpuBuffer = tensor[2].gpuBuffer as GPUBuffer;\n            const elementSizeInBytes = getTensorElementSize(tensorDataTypeStringToEnum(dataType))!;\n            dataByteLength = dims.reduce((a, b) => a * b, 1) * elementSizeInBytes;\n            rawData = wasm.jsepRegisterBuffer(sessionId, index, gpuBuffer, dataByteLength);\n          } else {\n            const data = tensor[2];\n\n            if (Array.isArray(data)) {\n              // string tensor\n              dataByteLength = 4 * data.length;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              let dataIndex = rawData / 4;\n              for (let i = 0; i < data.length; i++) {\n                if (typeof data[i] !== 'string') {\n                  throw new TypeError(`tensor data at index ${i} is not a string`);\n                }\n                wasm.HEAPU32[dataIndex++] = allocWasmString(data[i], allocs);\n              }\n            } else {\n              dataByteLength = data.byteLength;\n              rawData = wasm._malloc(dataByteLength);\n              allocs.push(rawData);\n              wasm.HEAPU8.set(new Uint8Array(data.buffer, data.byteOffset, dataByteLength), rawData);\n            }\n          }\n\n          const stack = wasm.stackSave();\n          const dimsOffset = wasm.stackAlloc(4 * dims.length);\n          try {\n            let dimIndex = dimsOffset / 4;\n            dims.forEach(d => wasm.HEAP32[dimIndex++] = d);\n            const tensor = wasm._OrtCreateTensor(\n                tensorDataTypeStringToEnum(dataType), rawData, dataByteLength, dimsOffset, dims.length,\n                dataLocationStringToEnum(location));\n            if (tensor === 0) {\n              checkLastError(`Can't create tensor for input/output. session=${sessionId}, index=${index}.`);\n            }\n            tensorHandles.push(tensor);\n          } finally {\n            wasm.stackRestore(stack);\n          }\n        };\n\n/**\n * perform inference run\n */\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputTensors: TensorMetadata[], outputIndices: number[],\n    outputTensors: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error(`cannot run inference. invalid session id: ${sessionId}`);\n  }\n  const [sessionHandle, inputNamesUTF8Encoded, outputNamesUTF8Encoded, ioBindingState] = session;\n\n  const inputCount = inputIndices.length;\n  const outputCount = outputIndices.length;\n\n  let runOptionsHandle = 0;\n  let runOptionsAllocs: number[] = [];\n\n  const inputTensorHandles: number[] = [];\n  const outputTensorHandles: number[] = [];\n  const inputOutputAllocs: number[] = [];\n\n  const beforeRunStack = wasm.stackSave();\n  const inputValuesOffset = wasm.stackAlloc(inputCount * 4);\n  const inputNamesOffset = wasm.stackAlloc(inputCount * 4);\n  const outputValuesOffset = wasm.stackAlloc(outputCount * 4);\n  const outputNamesOffset = wasm.stackAlloc(outputCount * 4);\n\n  try {\n    [runOptionsHandle, runOptionsAllocs] = setRunOptions(options);\n\n    // create input tensors\n    for (let i = 0; i < inputCount; i++) {\n      prepareInputOutputTensor(inputTensors[i], inputTensorHandles, inputOutputAllocs, sessionId, inputIndices[i]);\n    }\n\n    // create output tensors\n    for (let i = 0; i < outputCount; i++) {\n      prepareInputOutputTensor(\n          outputTensors[i], outputTensorHandles, inputOutputAllocs, sessionId, inputCount + outputIndices[i]);\n    }\n\n    let inputValuesIndex = inputValuesOffset / 4;\n    let inputNamesIndex = inputNamesOffset / 4;\n    let outputValuesIndex = outputValuesOffset / 4;\n    let outputNamesIndex = outputNamesOffset / 4;\n    for (let i = 0; i < inputCount; i++) {\n      wasm.HEAPU32[inputValuesIndex++] = inputTensorHandles[i];\n      wasm.HEAPU32[inputNamesIndex++] = inputNamesUTF8Encoded[inputIndices[i]];\n    }\n    for (let i = 0; i < outputCount; i++) {\n      wasm.HEAPU32[outputValuesIndex++] = outputTensorHandles[i];\n      wasm.HEAPU32[outputNamesIndex++] = outputNamesUTF8Encoded[outputIndices[i]];\n    }\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      const {handle, outputPreferredLocations, outputPreferredLocationsEncoded} = ioBindingState;\n\n      if (inputNamesUTF8Encoded.length !== inputCount) {\n        throw new Error(`input count from feeds (${\n            inputCount}) is expected to be always equal to model's input count (${inputNamesUTF8Encoded.length}).`);\n      }\n\n      // process inputs\n      for (let i = 0; i < inputCount; i++) {\n        const index = inputIndices[i];\n        const errorCode = await wasm._OrtBindInput(handle, inputNamesUTF8Encoded[index], inputTensorHandles[i]);\n        if (errorCode !== 0) {\n          checkLastError(`Can't bind input[${i}] for session=${sessionId}.`);\n        }\n      }\n\n      // process pre-allocated outputs\n      for (let i = 0; i < outputCount; i++) {\n        const index = outputIndices[i];\n        const location = outputTensors[i]?.[3];  // undefined means output is not pre-allocated.\n\n        if (location) {\n          // output is pre-allocated. bind the tensor.\n          const errorCode = wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], outputTensorHandles[i], 0);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind pre-allocated output[${i}] for session=${sessionId}.`);\n          }\n        } else {\n          // output is not pre-allocated. reset preferred location.\n          const errorCode =\n              wasm._OrtBindOutput(handle, outputNamesUTF8Encoded[index], 0, outputPreferredLocationsEncoded[index]);\n          if (errorCode !== 0) {\n            checkLastError(`Can't bind output[${i}] to ${outputPreferredLocations[i]} for session=${sessionId}.`);\n          }\n        }\n      }\n    }\n\n    let errorCode: number;\n\n    if (!BUILD_DEFS.DISABLE_WEBGPU && ioBindingState) {\n      errorCode = await wasm._OrtRunWithBinding(\n          sessionHandle, ioBindingState.handle, outputCount, outputValuesOffset, runOptionsHandle);\n    } else {\n      errorCode = await wasm._OrtRun(\n          sessionHandle, inputNamesOffset, inputValuesOffset, inputCount, outputNamesOffset, outputCount,\n          outputValuesOffset, runOptionsHandle);\n    }\n\n    if (errorCode !== 0) {\n      checkLastError('failed to call OrtRun().');\n    }\n\n    const output: TensorMetadata[] = [];\n\n    for (let i = 0; i < outputCount; i++) {\n      const tensor = wasm.HEAPU32[outputValuesOffset / 4 + i];\n      if (tensor === outputTensorHandles[i]) {\n        // output tensor is pre-allocated. no need to copy data.\n        output.push(outputTensors[i]!);\n        continue;\n      }\n\n      const beforeGetTensorDataStack = wasm.stackSave();\n      // stack allocate 4 pointer value\n      const tensorDataOffset = wasm.stackAlloc(4 * 4);\n\n      let keepOutputTensor = false;\n      let type: Tensor.Type|undefined, dataOffset = 0;\n      try {\n        const errorCode = wasm._OrtGetTensorData(\n            tensor, tensorDataOffset, tensorDataOffset + 4, tensorDataOffset + 8, tensorDataOffset + 12);\n        if (errorCode !== 0) {\n          checkLastError(`Can't access output tensor data on index ${i}.`);\n        }\n        let tensorDataIndex = tensorDataOffset / 4;\n        const dataType = wasm.HEAPU32[tensorDataIndex++];\n        dataOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsOffset = wasm.HEAPU32[tensorDataIndex++];\n        const dimsLength = wasm.HEAPU32[tensorDataIndex++];\n        const dims = [];\n        for (let i = 0; i < dimsLength; i++) {\n          dims.push(wasm.HEAPU32[dimsOffset / 4 + i]);\n        }\n        wasm._OrtFree(dimsOffset);\n\n        const size = dims.reduce((a, b) => a * b, 1);\n        type = tensorDataTypeEnumToString(dataType);\n\n        const preferredLocation = ioBindingState?.outputPreferredLocations[outputIndices[i]];\n\n        if (type === 'string') {\n          if (preferredLocation === 'gpu-buffer') {\n            throw new Error('String tensor is not supported on GPU.');\n          }\n          const stringData: string[] = [];\n          let dataIndex = dataOffset / 4;\n          for (let i = 0; i < size; i++) {\n            const offset = wasm.HEAPU32[dataIndex++];\n            const maxBytesToRead = i === size - 1 ? undefined : wasm.HEAPU32[dataIndex] - offset;\n            stringData.push(wasm.UTF8ToString(offset, maxBytesToRead));\n          }\n          output.push([type, dims, stringData, 'cpu']);\n        } else {\n          // If a certain output's preferred location is GPU but the tensor is empty, we still need to create a CPU\n          // tensor for it. There is no mapping GPU buffer for an empty tensor.\n          if (preferredLocation === 'gpu-buffer' && size > 0) {\n            const gpuBuffer = wasm.jsepGetBuffer(dataOffset);\n            const elementSize = getTensorElementSize(dataType);\n            if (elementSize === undefined || !isGpuBufferSupportedType(type)) {\n              throw new Error(`Unsupported data type: ${type}`);\n            }\n\n            // do not release the tensor right now. it will be released when user calls tensor.dispose().\n            keepOutputTensor = true;\n\n            output.push([\n              type, dims, {\n                gpuBuffer,\n                download: wasm.jsepCreateDownloader(gpuBuffer, size * elementSize, type),\n                dispose: () => {\n                  wasm._OrtReleaseTensor(tensor);\n                }\n              },\n              'gpu-buffer'\n            ]);\n          } else {\n            const typedArrayConstructor = tensorTypeToTypedArrayConstructor(type);\n            const data = new typedArrayConstructor(size);\n            new Uint8Array(data.buffer, data.byteOffset, data.byteLength)\n                .set(wasm.HEAPU8.subarray(dataOffset, dataOffset + data.byteLength));\n            output.push([type, dims, data, 'cpu']);\n          }\n        }\n      } finally {\n        wasm.stackRestore(beforeGetTensorDataStack);\n        if (type === 'string' && dataOffset) {\n          wasm._free(dataOffset);\n        }\n        if (!keepOutputTensor) {\n          wasm._OrtReleaseTensor(tensor);\n        }\n      }\n    }\n\n    if (ioBindingState) {\n      wasm._OrtClearBoundOutputs(ioBindingState.handle);\n    }\n\n    return output;\n  } finally {\n    wasm.stackRestore(beforeRunStack);\n\n    inputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    outputTensorHandles.forEach(v => wasm._OrtReleaseTensor(v));\n    inputOutputAllocs.forEach(p => wasm._free(p));\n\n    if (runOptionsHandle !== 0) {\n      wasm._OrtReleaseRunOptions(runOptionsHandle);\n    }\n    runOptionsAllocs.forEach(p => wasm._free(p));\n  }\n};\n\n/**\n * end profiling\n */\nexport const endProfiling = (sessionId: number): void => {\n  const wasm = getInstance();\n  const session = activeSessions.get(sessionId);\n  if (!session) {\n    throw new Error('invalid session id');\n  }\n  const sessionHandle = session[0];\n\n  // profile file name is not used yet, but it must be freed.\n  const profileFileName = wasm._OrtEndProfiling(sessionHandle);\n  if (profileFileName === 0) {\n    checkLastError('Can\\'t get an profile file name.');\n  }\n  wasm._OrtFree(profileFileName);\n};\n\nexport const extractTransferableBuffers = (tensors: readonly SerializableTensorMetadata[]): ArrayBufferLike[] => {\n  const buffers: ArrayBufferLike[] = [];\n  for (const tensor of tensors) {\n    const data = tensor[2];\n    if (!Array.isArray(data) && 'buffer' in data) {\n      buffers.push(data.buffer);\n    }\n  }\n  return buffers;\n};\n", "/*!\n * ONNX Runtime Web v1.17.0\n * Copyright (c) Microsoft Corporation. All rights reserved.\n * Licensed under the MIT License.\n */\n\"use strict\";(()=>{var Sn=Object.defineProperty;var ll=Object.getOwnPropertyDescriptor;var cl=Object.getOwnPropertyNames;var dl=Object.prototype.hasOwnProperty;var K=(e,t)=>()=>(e&&(t=e(e=0)),t);var dr=(e,t)=>()=>(t||e((t={exports:{}}).exports,t),t.exports),Vr=(e,t)=>{for(var r in t)Sn(e,r,{get:t[r],enumerable:!0})},pl=(e,t,r,o)=>{if(t&&typeof t==\"object\"||typeof t==\"function\")for(let a of cl(t))!dl.call(e,a)&&a!==r&&Sn(e,a,{get:()=>t[a],enumerable:!(o=ll(t,a))||o.enumerable});return e};var qt=e=>pl(Sn({},\"__esModule\",{value:!0}),e);var Cn={};Vr(Cn,{readFile:()=>fl});var fl,An=K(()=>{fl=void 0});var In={};Vr(In,{join:()=>ml});var ml,Tn=K(()=>{ml=void 0});var Go=dr((No,On)=>{\"use strict\";var Uo=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){var r=t,o,a;r.ready=new Promise((l,m)=>{o=l,a=m}),r.jsepInit=(l,m,y,w,I,U,F,re)=>{r.ab=l,r.Ra=m,r.Ta=y,r.La=w,r.Sa=I,r.xa=U,r.Ua=F,r.Va=re,m=(J,ae,ne)=>(...me)=>{let ye=je,_=ae?.();me=J(...me);let se=ae?.();return _!==se&&(J=se,ne(_),ae=ne=null),je!=ye?rr():me},y=J=>async(...ae)=>{try{if(r.Fa)throw Error(\"Session already started\");let ne=r.Fa={Wa:ae[0],errors:[]},me=await J(...ae);if(r.Fa!==ne)throw Error(\"Session mismatch\");l.flush();let ye=ne.errors;if(0<ye.length){let _=await Promise.all(ye);if(_=_.filter(se=>se),0<_.length)throw Error(_.join(`\n`))}return me}finally{r.Fa=null}},r._OrtRun=y(m(r._OrtRun,()=>r._OrtRun,J=>r._OrtRun=J)),r._OrtRunWithBinding=y(m(r._OrtRunWithBinding,()=>r._OrtRunWithBinding,J=>r._OrtRunWithBinding=J)),r._OrtBindInput=m(r._OrtBindInput,()=>r._OrtBindInput,J=>r._OrtBindInput=J),r.jsepRegisterBuffer=(J,ae,ne,me)=>l.registerBuffer(J,ae,ne,me),r.jsepUnregisterBuffers=J=>{l.unregisterBuffers(J)},r.jsepGetBuffer=J=>l.getBuffer(J),r.jsepCreateDownloader=(J,ae,ne)=>l.createDownloader(J,ae,ne)};var u=Object.assign({},r),i=\"./this.program\",d=(l,m)=>{throw m},f=typeof window==\"object\",h=typeof importScripts==\"function\",c=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",C=\"\",b,$,S;if(c){var x=(An(),qt(Cn)),A=(Tn(),qt(In));C=h?A.dirname(C)+\"/\":__dirname+\"/\",b=(l,m)=>(l=l.startsWith(\"file://\")?new URL(l):A.normalize(l),x.readFileSync(l,m?void 0:\"utf8\")),S=l=>(l=b(l,!0),l.buffer||(l=new Uint8Array(l)),l),$=(l,m,y,w=!0)=>{l=l.startsWith(\"file://\")?new URL(l):A.normalize(l),x.readFile(l,w?void 0:\"utf8\",(I,U)=>{I?y(I):m(w?U.buffer:U)})},!r.thisProgram&&1<process.argv.length&&(i=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),d=(l,m)=>{throw process.exitCode=l,m},r.inspect=()=>\"[Emscripten Module object]\"}else(f||h)&&(h?C=self.location.href:typeof document<\"u\"&&document.currentScript&&(C=document.currentScript.src),e&&(C=e),C.indexOf(\"blob:\")!==0?C=C.substr(0,C.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):C=\"\",b=l=>{var m=new XMLHttpRequest;return m.open(\"GET\",l,!1),m.send(null),m.responseText},h&&(S=l=>{var m=new XMLHttpRequest;return m.open(\"GET\",l,!1),m.responseType=\"arraybuffer\",m.send(null),new Uint8Array(m.response)}),$=(l,m,y)=>{var w=new XMLHttpRequest;w.open(\"GET\",l,!0),w.responseType=\"arraybuffer\",w.onload=()=>{w.status==200||w.status==0&&w.response?m(w.response):y()},w.onerror=y,w.send(null)});var k=r.print||console.log.bind(console),O=r.printErr||console.error.bind(console);Object.assign(r,u),u=null,r.thisProgram&&(i=r.thisProgram),r.quit&&(d=r.quit);var P;r.wasmBinary&&(P=r.wasmBinary);var R=r.noExitRuntime||!0;typeof WebAssembly!=\"object\"&&G(\"no native wasm support detected\");var V,B,W=!1,q,ee,oe,D,te,Ie,Z;function ve(){var l=V.buffer;r.HEAP8=ee=new Int8Array(l),r.HEAP16=new Int16Array(l),r.HEAP32=D=new Int32Array(l),r.HEAPU8=oe=new Uint8Array(l),r.HEAPU16=new Uint16Array(l),r.HEAPU32=te=new Uint32Array(l),r.HEAPF32=Ie=new Float32Array(l),r.HEAPF64=Z=new Float64Array(l)}var Te,be=[],Be=[],Se=[];function Ue(){var l=r.preRun.shift();be.unshift(l)}var qe=0,Ke=null,Ye=null;function G(l){throw r.onAbort&&r.onAbort(l),l=\"Aborted(\"+l+\")\",O(l),W=!0,q=1,l=new WebAssembly.RuntimeError(l+\". Build with -sASSERTIONS for more info.\"),a(l),l}function pe(l){return l.startsWith(\"data:application/octet-stream;base64,\")}var de;if(de=\"ort-wasm-simd.wasm\",!pe(de)){var Ne=de;de=r.locateFile?r.locateFile(Ne,C):C+Ne}function Ge(l){if(l==de&&P)return new Uint8Array(P);if(S)return S(l);throw\"both async and sync fetching of the wasm failed\"}function Ce(l){if(!P&&(f||h)){if(typeof fetch==\"function\"&&!l.startsWith(\"file://\"))return fetch(l,{credentials:\"same-origin\"}).then(m=>{if(!m.ok)throw\"failed to load wasm binary file at '\"+l+\"'\";return m.arrayBuffer()}).catch(()=>Ge(l));if($)return new Promise((m,y)=>{$(l,w=>m(new Uint8Array(w)),y)})}return Promise.resolve().then(()=>Ge(l))}function Pe(l,m,y){return Ce(l).then(w=>WebAssembly.instantiate(w,m)).then(w=>w).then(y,w=>{O(\"failed to asynchronously prepare wasm: \"+w),G(w)})}function vt(l,m){var y=de;return P||typeof WebAssembly.instantiateStreaming!=\"function\"||pe(y)||y.startsWith(\"file://\")||c||typeof fetch!=\"function\"?Pe(y,l,m):fetch(y,{credentials:\"same-origin\"}).then(w=>WebAssembly.instantiateStreaming(w,l).then(m,function(I){return O(\"wasm streaming compile failed: \"+I),O(\"falling back to ArrayBuffer instantiation\"),Pe(y,l,m)}))}var He,zt={916496:l=>{r.xa(\"Abs\",l,void 0)},916547:l=>{r.xa(\"Neg\",l,void 0)},916598:l=>{r.xa(\"Floor\",l,void 0)},916651:l=>{r.xa(\"Ceil\",l,void 0)},916703:l=>{r.xa(\"Reciprocal\",l,void 0)},916761:l=>{r.xa(\"Sqrt\",l,void 0)},916813:l=>{r.xa(\"Exp\",l,void 0)},916864:l=>{r.xa(\"Erf\",l,void 0)},916915:l=>{r.xa(\"Sigmoid\",l,void 0)},916970:l=>{r.xa(\"Log\",l,void 0)},917021:l=>{r.xa(\"Sin\",l,void 0)},917072:l=>{r.xa(\"Cos\",l,void 0)},917123:l=>{r.xa(\"Tan\",l,void 0)},917174:l=>{r.xa(\"Asin\",l,void 0)},917226:l=>{r.xa(\"Acos\",l,void 0)},917278:l=>{r.xa(\"Atan\",l,void 0)},917330:l=>{r.xa(\"Sinh\",l,void 0)},917382:l=>{r.xa(\"Cosh\",l,void 0)},917434:l=>{r.xa(\"Asinh\",l,void 0)},917487:l=>{r.xa(\"Acosh\",l,void 0)},917540:l=>{r.xa(\"Atanh\",l,void 0)},917593:l=>{r.xa(\"Tanh\",l,void 0)},917645:l=>{r.xa(\"Not\",l,void 0)},917696:(l,m,y)=>{r.xa(\"ClipV10\",l,{min:m,max:y})},917768:l=>{r.xa(\"Clip\",l,void 0)},917820:(l,m)=>{r.xa(\"Elu\",l,{alpha:m})},917878:l=>{r.xa(\"Relu\",l,void 0)},917930:(l,m)=>{r.xa(\"LeakyRelu\",l,{alpha:m})},917994:(l,m)=>{r.xa(\"ThresholdedRelu\",l,{alpha:m})},918064:(l,m)=>{r.xa(\"Cast\",l,{to:m})},918122:l=>{r.xa(\"Add\",l,void 0)},918173:l=>{r.xa(\"Sub\",l,void 0)},918224:l=>{r.xa(\"Mul\",l,void 0)},918275:l=>{r.xa(\"Div\",l,void 0)},918326:l=>{r.xa(\"Pow\",l,void 0)},918377:l=>{r.xa(\"Equal\",l,void 0)},918430:l=>{r.xa(\"Greater\",l,void 0)},918485:l=>{r.xa(\"GreaterOrEqual\",l,void 0)},918547:l=>{r.xa(\"Less\",l,void 0)},918599:l=>{r.xa(\"LessOrEqual\",l,void 0)},918658:(l,m,y,w,I)=>{r.xa(\"ReduceMean\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},918822:(l,m,y,w,I)=>{r.xa(\"ReduceMax\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},918985:(l,m,y,w,I)=>{r.xa(\"ReduceMin\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},919148:(l,m,y,w,I)=>{r.xa(\"ReduceProd\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},919312:(l,m,y,w,I)=>{r.xa(\"ReduceSum\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},919475:(l,m,y,w,I)=>{r.xa(\"ReduceL1\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},919637:(l,m,y,w,I)=>{r.xa(\"ReduceL2\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},919799:(l,m,y,w,I)=>{r.xa(\"ReduceLogSum\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},919965:(l,m,y,w,I)=>{r.xa(\"ReduceSumSquare\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},920134:(l,m,y,w,I)=>{r.xa(\"ReduceLogSumExp\",l,{keepDims:!!m,noopWithEmptyAxes:!!y,axes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},920303:l=>{r.xa(\"Where\",l,void 0)},920356:(l,m,y)=>{r.xa(\"Transpose\",l,{perm:m?Array.from(D.subarray(y>>>0,y+m>>>0)):[]})},920469:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye,_,se)=>{r.xa(\"ConvTranspose\",l,{format:J?\"NHWC\":\"NCHW\",autoPad:m,dilations:[y],group:w,kernel_shape:[I],pads:[U,F],strides:[re],wIsConst:()=>!!ee[ae>>>0],outputPadding:ne?Array.from(D.subarray(me>>>0,me+ne>>>0)):[],outputShape:ye?Array.from(D.subarray(_>>>0,_+ye>>>0)):[],activation:De(se)})},920883:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye,_)=>{r.xa(\"ConvTranspose\",l,{format:re?\"NHWC\":\"NCHW\",autoPad:m,dilations:Array.from(D.subarray(y>>>0,y+2>>>0)),group:w,kernelShape:Array.from(D.subarray(I>>>0,I+2>>>0)),pads:Array.from(D.subarray(U>>>0,U+4>>>0)),strides:Array.from(D.subarray(F>>>0,F+2>>>0)),wIsConst:()=>!!ee[J>>>0],outputPadding:0<ae?Array.from(D.subarray(ne>>>0,ne+ae>>>0)):[],outputShape:0<me?Array.from(D.subarray(ye>>>0,ye+me>>>0)):[],activation:De(_)})},921440:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye,_,se)=>{r.xa(\"ConvTranspose\",l,{format:J?\"NHWC\":\"NCHW\",autoPad:m,dilations:[y],group:w,kernel_shape:[I],pads:[U,F],strides:[re],wIsConst:()=>!!ee[ae>>>0],outputPadding:ne?Array.from(D.subarray(me>>>0,me+ne>>>0)):[],outputShape:ye?Array.from(D.subarray(_>>>0,_+ye>>>0)):[],activation:De(se)})},921854:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye,_)=>{r.xa(\"ConvTranspose\",l,{format:re?\"NHWC\":\"NCHW\",autoPad:m,dilations:Array.from(D.subarray(y>>>0,y+2>>>0)),group:w,kernelShape:Array.from(D.subarray(I>>>0,I+2>>>0)),pads:Array.from(D.subarray(U>>>0,U+4>>>0)),strides:Array.from(D.subarray(F>>>0,F+2>>>0)),wIsConst:()=>!!ee[J>>>0],outputPadding:0<ae?Array.from(D.subarray(ne>>>0,ne+ae>>>0)):[],outputShape:0<me?Array.from(D.subarray(ye>>>0,ye+me>>>0)):[],activation:De(_)})},922411:(l,m)=>{r.xa(\"GlobalAveragePool\",l,{format:m?\"NHWC\":\"NCHW\"})},922502:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye,_,se,he)=>{r.xa(\"AveragePool\",l,{format:he?\"NHWC\":\"NCHW\",auto_pad:m,ceil_mode:y,count_include_pad:w,storage_order:I,dilations:[U,F],kernel_shape:[re,J],pads:[ae,ne,me,ye],strides:[_,se]})},922786:(l,m)=>{r.xa(\"GlobalAveragePool\",l,{format:m?\"NHWC\":\"NCHW\"})},922877:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye,_,se,he)=>{r.xa(\"AveragePool\",l,{format:he?\"NHWC\":\"NCHW\",auto_pad:m,ceil_mode:y,count_include_pad:w,storage_order:I,dilations:[U,F],kernel_shape:[re,J],pads:[ae,ne,me,ye],strides:[_,se]})},923161:(l,m)=>{r.xa(\"GlobalMaxPool\",l,{format:m?\"NHWC\":\"NCHW\"})},923248:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye,_,se,he)=>{r.xa(\"MaxPool\",l,{format:he?\"NHWC\":\"NCHW\",auto_pad:m,ceil_mode:y,count_include_pad:w,storage_order:I,dilations:[U,F],kernel_shape:[re,J],pads:[ae,ne,me,ye],strides:[_,se]})},923528:(l,m)=>{r.xa(\"GlobalMaxPool\",l,{format:m?\"NHWC\":\"NCHW\"})},923615:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye,_,se,he)=>{r.xa(\"MaxPool\",l,{format:he?\"NHWC\":\"NCHW\",auto_pad:m,ceil_mode:y,count_include_pad:w,storage_order:I,dilations:[U,F],kernel_shape:[re,J],pads:[ae,ne,me,ye],strides:[_,se]})},923895:(l,m,y,w,I)=>{r.xa(\"Gemm\",l,{alpha:m,beta:y,transA:w,transB:I})},923999:l=>{r.xa(\"MatMul\",l,void 0)},924053:(l,m,y,w)=>{r.xa(\"ArgMax\",l,{keepDims:!!m,selectLastIndex:!!y,axis:w})},924161:(l,m,y,w)=>{r.xa(\"ArgMin\",l,{keepDims:!!m,selectLastIndex:!!y,axis:w})},924269:(l,m)=>{r.xa(\"Softmax\",l,{axis:m})},924332:(l,m)=>{r.xa(\"Concat\",l,{axis:m})},924392:(l,m,y,w,I)=>{r.xa(\"Split\",l,{axis:m,numOutputs:y,splitSizes:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},924537:l=>{r.xa(\"Expand\",l,void 0)},924591:(l,m)=>{r.xa(\"Gather\",l,{axis:Number(m)})},924662:(l,m)=>{r.xa(\"GatherElements\",l,{axis:Number(m)})},924741:(l,m,y,w,I,U,F,re,J,ae,ne)=>{r.xa(\"Resize\",l,{antialias:m,axes:y?Array.from(D.subarray(w>>>0,w+y>>>0)):[],coordinateTransformMode:De(I),cubicCoeffA:U,excludeOutside:F,extrapolationValue:re,keepAspectRatioPolicy:De(J),mode:De(ae),nearestMode:De(ne)})},925092:(l,m,y,w,I,U,F)=>{r.xa(\"Slice\",l,{starts:m?Array.from(D.subarray(y>>>0,y+m>>>0)):[],ends:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[],axes:U?Array.from(D.subarray(F>>>0,F+U>>>0)):[]})},925323:l=>{r.xa(\"Tile\",l,void 0)},925375:(l,m,y)=>{r.xa(\"LayerNormalization\",l,{axis:Number(m),epsilon:Number(y)})},925482:(l,m,y)=>{r.xa(\"InstanceNormalization\",l,{epsilon:m,format:y?\"NHWC\":\"NCHW\"})},925596:(l,m,y)=>{r.xa(\"InstanceNormalization\",l,{epsilon:m,format:y?\"NHWC\":\"NCHW\"})},925710:l=>{r.xa(\"Range\",l,void 0)},925763:(l,m)=>{r.xa(\"Einsum\",l,{equation:De(m)})},925844:(l,m,y,w,I)=>{r.xa(\"Pad\",l,{mode:m,value:y,pads:w?Array.from(D.subarray(I>>>0,I+w>>>0)):[]})},925976:l=>{r.xa(\"Gelu\",l,void 0)},926028:l=>{r.xa(\"BiasAdd\",l,void 0)},926083:l=>{r.xa(\"BiasSplitGelu\",l,void 0)},926144:(l,m)=>{r.xa(\"SkipLayerNormalization\",l,{epsilon:m})},926225:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye)=>{r.xa(\"Conv\",l,{format:J?\"NHWC\":\"NCHW\",auto_pad:m,dilations:[y],group:w,kernel_shape:[I],pads:U?Array.from(D.subarray(F>>>0,F+U>>>0)):[],strides:[re],w_is_const:()=>!!ee[ae>>>0],activation:De(ne),activation_params:me?Array.from(Ie.subarray(ye>>>0,ye+me>>>0)):[]})},926606:(l,m,y,w,I,U,F,re,J,ae,ne,me,ye,_,se,he)=>{r.xa(\"Conv\",l,{format:me?\"NHWC\":\"NCHW\",auto_pad:m,dilations:[y,w],group:I,kernel_shape:[U,F],pads:re?Array.from(D.subarray(J>>>0,J+re>>>0)):[],strides:[ae,ne],w_is_const:()=>!!ee[ye>>>0],activation:De(_),activation_params:se?Array.from(Ie.subarray(he>>>0,he+se>>>0)):[]})},927008:l=>{r.Ua(l)},927042:(l,m)=>r.Va(l,m,r.Fa.Wa,r.Fa.errors),927154:l=>r.Ra(l),927187:l=>r.Ta(l),927219:(l,m,y)=>{r.La(l,m,y,!0)},927258:(l,m,y)=>{r.La(l,m,y)}};function nt(l){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${l})`,this.status=l}var Tt=l=>{for(;0<l.length;)l.shift()(r)};function Ot(l){this.Ka=l-24,this.Pa=function(m){te[this.Ka+4>>2>>>0]=m},this.Oa=function(m){te[this.Ka+8>>2>>>0]=m},this.Ma=function(m,y){this.Na(),this.Pa(m),this.Oa(y)},this.Na=function(){te[this.Ka+16>>2>>>0]=0}}var Kt=0,Xe=0,Yt=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,Et=(l,m,y)=>{m>>>=0;var w=m+y;for(y=m;l[y]&&!(y>=w);)++y;if(16<y-m&&l.buffer&&Yt)return Yt.decode(l.subarray(m,y));for(w=\"\";m<y;){var I=l[m++];if(I&128){var U=l[m++]&63;if((I&224)==192)w+=String.fromCharCode((I&31)<<6|U);else{var F=l[m++]&63;I=(I&240)==224?(I&15)<<12|U<<6|F:(I&7)<<18|U<<12|F<<6|l[m++]&63,65536>I?w+=String.fromCharCode(I):(I-=65536,w+=String.fromCharCode(55296|I>>10,56320|I&1023))}}else w+=String.fromCharCode(I)}return w},De=(l,m)=>(l>>>=0)?Et(oe,l,m):\"\",Vt=l=>{for(var m=0,y=0;y<l.length;++y){var w=l.charCodeAt(y);127>=w?m++:2047>=w?m+=2:55296<=w&&57343>=w?(m+=4,++y):m+=3}return m},Jt=(l,m,y,w)=>{if(y>>>=0,!(0<w))return 0;var I=y;w=y+w-1;for(var U=0;U<l.length;++U){var F=l.charCodeAt(U);if(55296<=F&&57343>=F){var re=l.charCodeAt(++U);F=65536+((F&1023)<<10)|re&1023}if(127>=F){if(y>=w)break;m[y++>>>0]=F}else{if(2047>=F){if(y+1>=w)break;m[y++>>>0]=192|F>>6}else{if(65535>=F){if(y+2>=w)break;m[y++>>>0]=224|F>>12}else{if(y+3>=w)break;m[y++>>>0]=240|F>>18,m[y++>>>0]=128|F>>12&63}m[y++>>>0]=128|F>>6&63}m[y++>>>0]=128|F&63}}return m[y>>>0]=0,y-I},mt=l=>l%4===0&&(l%100!==0||l%400===0),xr=[0,31,60,91,121,152,182,213,244,274,305,335],Ut=[0,31,59,90,120,151,181,212,243,273,304,334],_t=l=>{var m=Vt(l)+1,y=Ft(m);return y&&Jt(l,oe,y,m),y},Pt=[],Xt=(l,m)=>{Pt.length=0;var y;for(m>>=2;y=oe[l++>>>0];)m+=y!=105&m,Pt.push(y==105?D[m>>>0]:Z[m++>>>1]),++m;return Pt},Ze={},Zt=()=>{if(!Nt){var l={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:i||\"./this.program\"},m;for(m in Ze)Ze[m]===void 0?delete l[m]:l[m]=Ze[m];var y=[];for(m in l)y.push(`${m}=${l[m]}`);Nt=y}return Nt},Nt,Ve=[null,[],[]],Qt=[31,29,31,30,31,30,31,31,30,31,30,31],Gt=[31,28,31,30,31,30,31,31,30,31,30,31];function cn(l){var m=Array(Vt(l)+1);return Jt(l,m,0,m.length),m}function le(l,m,y,w){function I(_,se,he){for(_=typeof _==\"number\"?_.toString():_||\"\";_.length<se;)_=he[0]+_;return _}function U(_,se){return I(_,se,\"0\")}function F(_,se){function he(Mt){return 0>Mt?-1:0<Mt?1:0}var et;return(et=he(_.getFullYear()-se.getFullYear()))===0&&(et=he(_.getMonth()-se.getMonth()))===0&&(et=he(_.getDate()-se.getDate())),et}function re(_){switch(_.getDay()){case 0:return new Date(_.getFullYear()-1,11,29);case 1:return _;case 2:return new Date(_.getFullYear(),0,3);case 3:return new Date(_.getFullYear(),0,2);case 4:return new Date(_.getFullYear(),0,1);case 5:return new Date(_.getFullYear()-1,11,31);case 6:return new Date(_.getFullYear()-1,11,30)}}function J(_){var se=_.Da;for(_=new Date(new Date(_.Ea+1900,0,1).getTime());0<se;){var he=_.getMonth(),et=(mt(_.getFullYear())?Qt:Gt)[he];if(se>et-_.getDate())se-=et-_.getDate()+1,_.setDate(1),11>he?_.setMonth(he+1):(_.setMonth(0),_.setFullYear(_.getFullYear()+1));else{_.setDate(_.getDate()+se);break}}return he=new Date(_.getFullYear()+1,0,4),se=re(new Date(_.getFullYear(),0,4)),he=re(he),0>=F(se,_)?0>=F(he,_)?_.getFullYear()+1:_.getFullYear():_.getFullYear()-1}l>>>=0,m>>>=0,y>>>=0,w>>>=0;var ae=D[w+40>>2>>>0];w={Za:D[w>>2>>>0],Ya:D[w+4>>2>>>0],Ga:D[w+8>>2>>>0],Ja:D[w+12>>2>>>0],Ha:D[w+16>>2>>>0],Ea:D[w+20>>2>>>0],Ca:D[w+24>>2>>>0],Da:D[w+28>>2>>>0],bb:D[w+32>>2>>>0],Xa:D[w+36>>2>>>0],$a:ae?De(ae):\"\"},y=De(y),ae={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var ne in ae)y=y.replace(new RegExp(ne,\"g\"),ae[ne]);var me=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),ye=\"January February March April May June July August September October November December\".split(\" \");ae={\"%a\":_=>me[_.Ca].substring(0,3),\"%A\":_=>me[_.Ca],\"%b\":_=>ye[_.Ha].substring(0,3),\"%B\":_=>ye[_.Ha],\"%C\":_=>U((_.Ea+1900)/100|0,2),\"%d\":_=>U(_.Ja,2),\"%e\":_=>I(_.Ja,2,\" \"),\"%g\":_=>J(_).toString().substring(2),\"%G\":_=>J(_),\"%H\":_=>U(_.Ga,2),\"%I\":_=>(_=_.Ga,_==0?_=12:12<_&&(_-=12),U(_,2)),\"%j\":_=>{for(var se=0,he=0;he<=_.Ha-1;se+=(mt(_.Ea+1900)?Qt:Gt)[he++]);return U(_.Ja+se,3)},\"%m\":_=>U(_.Ha+1,2),\"%M\":_=>U(_.Ya,2),\"%n\":()=>`\n`,\"%p\":_=>0<=_.Ga&&12>_.Ga?\"AM\":\"PM\",\"%S\":_=>U(_.Za,2),\"%t\":()=>\"\t\",\"%u\":_=>_.Ca||7,\"%U\":_=>U(Math.floor((_.Da+7-_.Ca)/7),2),\"%V\":_=>{var se=Math.floor((_.Da+7-(_.Ca+6)%7)/7);if(2>=(_.Ca+371-_.Da-2)%7&&se++,se)se==53&&(he=(_.Ca+371-_.Da)%7,he==4||he==3&&mt(_.Ea)||(se=1));else{se=52;var he=(_.Ca+7-_.Da-1)%7;(he==4||he==5&&mt(_.Ea%400-1))&&se++}return U(se,2)},\"%w\":_=>_.Ca,\"%W\":_=>U(Math.floor((_.Da+7-(_.Ca+6)%7)/7),2),\"%y\":_=>(_.Ea+1900).toString().substring(2),\"%Y\":_=>_.Ea+1900,\"%z\":_=>{_=_.Xa;var se=0<=_;return _=Math.abs(_)/60,(se?\"+\":\"-\")+(\"0000\"+(_/60*100+_%60)).slice(-4)},\"%Z\":_=>_.$a,\"%%\":()=>\"%\"},y=y.replace(/%%/g,\"\\0\\0\");for(ne in ae)y.includes(ne)&&(y=y.replace(new RegExp(ne,\"g\"),ae[ne](w)));return y=y.replace(/\\0\\0/g,\"%\"),ne=cn(y),ne.length>m?0:(ee.set(ne,l>>>0),ne.length-1)}function ht(l){try{l()}catch(m){G(m)}}function Sr(l){var m={},y;for(y in l)(function(w){var I=l[w];m[w]=typeof I==\"function\"?function(){Rt.push(w);try{return I.apply(null,arguments)}finally{W||(Rt.pop()===w||G(),je&&ot===1&&Rt.length===0&&(ot=0,ht(Ht),typeof Fibers<\"u\"&&Fibers.cb()))}}:I})(y);return m}var ot=0,je=null,Cr=0,Rt=[],er={},tr={},Ar=0,$t=null,Ir=[];function rr(){return new Promise((l,m)=>{$t={resolve:l,reject:m}})}function Tr(){var l=Ft(65548),m=l+12;te[l>>2>>>0]=m,te[l+4>>2>>>0]=m+65536,m=Rt[0];var y=er[m];return y===void 0&&(y=Ar++,er[m]=y,tr[y]=m),D[l+8>>2>>>0]=y,l}function Or(l){if(!W){if(ot===0){var m=!1,y=!1;l((w=0)=>{if(!W&&(Cr=w,m=!0,y)){ot=2,ht(()=>Pr(je)),typeof Browser<\"u\"&&Browser.Ia.Qa&&Browser.Ia.resume(),w=!1;try{var I=(0,B[tr[D[je+8>>2>>>0]]])()}catch(re){I=re,w=!0}var U=!1;if(!je){var F=$t;F&&($t=null,(w?F.reject:F.resolve)(I),U=!0)}if(w&&!U)throw I}}),y=!0,m||(ot=1,je=Tr(),typeof Browser<\"u\"&&Browser.Ia.Qa&&Browser.Ia.pause(),ht(()=>Lt(je)))}else ot===2?(ot=0,ht(Qe),ar(je),je=null,Ir.forEach(w=>{if(!W)try{if(w(),!R)try{q=q=w=q,R||(r.onExit&&r.onExit(w),W=!0),d(w,new nt(w))}catch(I){I instanceof nt||I==\"unwind\"||d(1,I)}}catch(I){I instanceof nt||I==\"unwind\"||d(1,I)}})):G(`invalid state: ${ot}`);return Cr}}function Er(l){return Or(m=>{l().then(m)})}var gt=[],yt=void 0,nr=[];function or(l,m){if(!yt){yt=new WeakMap;var y=Te.length;if(yt)for(var w=0;w<0+y;w++){var I=w,U=gt[I];U||(I>=gt.length&&(gt.length=I+1),gt[I]=U=Te.get(I)),(I=U)&&yt.set(I,w)}}if(y=yt.get(l)||0)return y;if(nr.length)y=nr.pop();else{try{Te.grow(1)}catch(re){throw re instanceof RangeError?\"Unable to grow wasm table. Set ALLOW_TABLE_GROWTH.\":re}y=Te.length-1}try{w=y,Te.set(w,l),gt[w]=Te.get(w)}catch(re){if(!(re instanceof TypeError))throw re;if(typeof WebAssembly.Function==\"function\"){w=WebAssembly.Function,I={i:\"i32\",j:\"i64\",f:\"f32\",d:\"f64\",p:\"i32\"},U={parameters:[],results:m[0]==\"v\"?[]:[I[m[0]]]};for(var F=1;F<m.length;++F)U.parameters.push(I[m[F]]);m=new w(U,l)}else{for(w=[1],I=m.slice(0,1),m=m.slice(1),U={i:127,p:127,j:126,f:125,d:124},w.push(96),F=m.length,128>F?w.push(F):w.push(F%128|128,F>>7),F=0;F<m.length;++F)w.push(U[m[F]]);I==\"v\"?w.push(0):w.push(1,U[I]),m=[0,97,115,109,1,0,0,0,1],I=w.length,128>I?m.push(I):m.push(I%128|128,I>>7),m.push.apply(m,w),m.push(2,7,1,1,101,1,102,0,0,7,5,1,1,102,0,0),m=new WebAssembly.Module(new Uint8Array(m)),m=new WebAssembly.Instance(m,{e:{f:l}}).exports.f}w=y,Te.set(w,m),gt[w]=Te.get(w)}return yt.set(l,y),y}var _r={n:function(l,m,y){return Er(async()=>{await r.Sa(l,m,y)})},a:function(l,m,y){throw l>>>=0,new Ot(l).Ma(m>>>0,y>>>0),Kt=l,Xe++,Kt},g:function(){return 0},J:function(){},z:function(){},B:function(){},L:function(){return 0},H:function(){},C:function(){},F:function(){},m:function(){},A:function(){},x:function(){},I:function(){},y:function(){},M:()=>!0,q:function(l,m,y){l=m+2097152>>>0<4194305-!!l?(l>>>0)+4294967296*m:NaN,y>>>=0,l=new Date(1e3*l),D[y>>2>>>0]=l.getUTCSeconds(),D[y+4>>2>>>0]=l.getUTCMinutes(),D[y+8>>2>>>0]=l.getUTCHours(),D[y+12>>2>>>0]=l.getUTCDate(),D[y+16>>2>>>0]=l.getUTCMonth(),D[y+20>>2>>>0]=l.getUTCFullYear()-1900,D[y+24>>2>>>0]=l.getUTCDay(),D[y+28>>2>>>0]=(l.getTime()-Date.UTC(l.getUTCFullYear(),0,1,0,0,0,0))/864e5|0},r:function(l,m,y){l=m+2097152>>>0<4194305-!!l?(l>>>0)+4294967296*m:NaN,y>>>=0,l=new Date(1e3*l),D[y>>2>>>0]=l.getSeconds(),D[y+4>>2>>>0]=l.getMinutes(),D[y+8>>2>>>0]=l.getHours(),D[y+12>>2>>>0]=l.getDate(),D[y+16>>2>>>0]=l.getMonth(),D[y+20>>2>>>0]=l.getFullYear()-1900,D[y+24>>2>>>0]=l.getDay(),D[y+28>>2>>>0]=(mt(l.getFullYear())?xr:Ut)[l.getMonth()]+l.getDate()-1|0,D[y+36>>2>>>0]=-(60*l.getTimezoneOffset()),m=new Date(l.getFullYear(),6,1).getTimezoneOffset();var w=new Date(l.getFullYear(),0,1).getTimezoneOffset();D[y+32>>2>>>0]=(m!=w&&l.getTimezoneOffset()==Math.min(w,m))|0},s:function(l){l>>>=0;var m=new Date(D[l+20>>2>>>0]+1900,D[l+16>>2>>>0],D[l+12>>2>>>0],D[l+8>>2>>>0],D[l+4>>2>>>0],D[l>>2>>>0],0),y=D[l+32>>2>>>0],w=m.getTimezoneOffset(),I=new Date(m.getFullYear(),6,1).getTimezoneOffset(),U=new Date(m.getFullYear(),0,1).getTimezoneOffset(),F=Math.min(U,I);return 0>y?D[l+32>>2>>>0]=+(I!=U&&F==w):0<y!=(F==w)&&(I=Math.max(U,I),m.setTime(m.getTime()+6e4*((0<y?F:I)-w))),D[l+24>>2>>>0]=m.getDay(),D[l+28>>2>>>0]=(mt(m.getFullYear())?xr:Ut)[m.getMonth()]+m.getDate()-1|0,D[l>>2>>>0]=m.getSeconds(),D[l+4>>2>>>0]=m.getMinutes(),D[l+8>>2>>>0]=m.getHours(),D[l+12>>2>>>0]=m.getDate(),D[l+16>>2>>>0]=m.getMonth(),D[l+20>>2>>>0]=m.getYear(),l=m.getTime()/1e3,ir((He=l,1<=+Math.abs(He)?0<He?+Math.floor(He/4294967296)>>>0:~~+Math.ceil((He-+(~~He>>>0))/4294967296)>>>0:0)),l>>>0},o:function(){return-52},p:function(){},v:function(l,m,y){function w(J){return(J=J.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?J[1]:\"GMT\"}y>>>=0;var I=new Date().getFullYear(),U=new Date(I,0,1),F=new Date(I,6,1);I=U.getTimezoneOffset();var re=F.getTimezoneOffset();te[l>>>0>>2>>>0]=60*Math.max(I,re),D[m>>>0>>2>>>0]=+(I!=re),l=w(U),m=w(F),l=_t(l),m=_t(m),re<I?(te[y>>2>>>0]=l,te[y+4>>2>>>0]=m):(te[y>>2>>>0]=m,te[y+4>>2>>>0]=l)},e:()=>{G(\"\")},b:function(l,m,y){return l>>>=0,m=Xt(m>>>0,y>>>0),zt[l].apply(null,m)},j:function(l,m,y){return l>>>=0,m=Xt(m>>>0,y>>>0),zt[l].apply(null,m)},h:function(){return Date.now()},w:function(){return 4294901760},c:()=>performance.now(),K:function(l,m,y){return m>>>=0,oe.copyWithin(l>>>0>>>0,m>>>0,m+(y>>>0)>>>0)},u:function(l){l>>>=0;var m=oe.length;if(4294901760<l)return!1;for(var y=1;4>=y;y*=2){var w=m*(1+.2/y);w=Math.min(w,l+100663296);var I=Math;w=Math.max(l,w);e:{I=I.min.call(I,4294901760,w+(65536-w%65536)%65536)-V.buffer.byteLength+65535>>>16;try{V.grow(I),ve();var U=1;break e}catch{}U=void 0}if(U)return!0}return!1},D:function(l,m){l>>>=0,m>>>=0;var y=0;return Zt().forEach(function(w,I){var U=m+y;for(I=te[l+4*I>>2>>>0]=U,U=0;U<w.length;++U)ee[I++>>0>>>0]=w.charCodeAt(U);ee[I>>0>>>0]=0,y+=w.length+1}),0},E:function(l,m){l>>>=0,m>>>=0;var y=Zt();te[l>>2>>>0]=y.length;var w=0;return y.forEach(function(I){w+=I.length+1}),te[m>>2>>>0]=w,0},f:()=>52,l:function(){return 52},t:function(){return 70},k:function(l,m,y,w){m>>>=0,y>>>=0,w>>>=0;for(var I=0,U=0;U<y;U++){var F=te[m>>2>>>0],re=te[m+4>>2>>>0];m+=8;for(var J=0;J<re;J++){var ae=oe[F+J>>>0],ne=Ve[l];ae===0||ae===10?((l===1?k:O)(Et(ne,0)),ne.length=0):ne.push(ae)}I+=re}return te[w>>2>>>0]=I,0},G:le,d:function(l,m,y,w){return le(l>>>0,m>>>0,y>>>0,w>>>0)},i:function(l,m,y,w){let I=Te.length;l=new Uint8Array(oe.slice(l+m,l+y));try{var U=new WebAssembly.Module(l),F=new WebAssembly.Instance(U,{env:{memory:V}}),re;for(re in F.exports)or(F.exports[re]);return I<Te.length?I:w}catch(J){return console.log(J),w}}};(function(){function l(y){if(y=y.exports,y=Sr(y),B=y=dn(y),V=B.N,ve(),Te=B.sa,Be.unshift(B.O),qe--,r.monitorRunDependencies&&r.monitorRunDependencies(qe),qe==0&&(Ke!==null&&(clearInterval(Ke),Ke=null),Ye)){var w=Ye;Ye=null,w()}return y}var m={a:_r};if(qe++,r.monitorRunDependencies&&r.monitorRunDependencies(qe),r.instantiateWasm)try{return r.instantiateWasm(m,l)}catch(y){O(\"Module.instantiateWasm callback failed with error: \"+y),a(y)}return vt(m,function(y){l(y.instance)}).catch(a),{}})(),r._OrtInit=(l,m)=>(r._OrtInit=B.P)(l,m),r._OrtGetLastError=(l,m)=>(r._OrtGetLastError=B.Q)(l,m),r._OrtCreateSessionOptions=(l,m,y,w,I,U,F,re,J,ae)=>(r._OrtCreateSessionOptions=B.R)(l,m,y,w,I,U,F,re,J,ae),r._OrtAppendExecutionProvider=(l,m)=>(r._OrtAppendExecutionProvider=B.S)(l,m),r._OrtAddFreeDimensionOverride=(l,m,y)=>(r._OrtAddFreeDimensionOverride=B.T)(l,m,y),r._OrtAddSessionConfigEntry=(l,m,y)=>(r._OrtAddSessionConfigEntry=B.U)(l,m,y),r._OrtReleaseSessionOptions=l=>(r._OrtReleaseSessionOptions=B.V)(l),r._OrtCreateSession=(l,m,y)=>(r._OrtCreateSession=B.W)(l,m,y),r._OrtReleaseSession=l=>(r._OrtReleaseSession=B.X)(l),r._OrtGetInputOutputCount=(l,m,y)=>(r._OrtGetInputOutputCount=B.Y)(l,m,y),r._OrtGetInputName=(l,m)=>(r._OrtGetInputName=B.Z)(l,m),r._OrtGetOutputName=(l,m)=>(r._OrtGetOutputName=B._)(l,m),r._OrtFree=l=>(r._OrtFree=B.$)(l),r._OrtCreateTensor=(l,m,y,w,I,U)=>(r._OrtCreateTensor=B.aa)(l,m,y,w,I,U),r._OrtGetTensorData=(l,m,y,w,I)=>(r._OrtGetTensorData=B.ba)(l,m,y,w,I),r._OrtReleaseTensor=l=>(r._OrtReleaseTensor=B.ca)(l),r._OrtCreateRunOptions=(l,m,y,w)=>(r._OrtCreateRunOptions=B.da)(l,m,y,w),r._OrtAddRunConfigEntry=(l,m,y)=>(r._OrtAddRunConfigEntry=B.ea)(l,m,y),r._OrtReleaseRunOptions=l=>(r._OrtReleaseRunOptions=B.fa)(l),r._OrtCreateBinding=l=>(r._OrtCreateBinding=B.ga)(l),r._OrtBindInput=(l,m,y)=>(r._OrtBindInput=B.ha)(l,m,y),r._OrtBindOutput=(l,m,y,w)=>(r._OrtBindOutput=B.ia)(l,m,y,w),r._OrtClearBoundOutputs=l=>(r._OrtClearBoundOutputs=B.ja)(l),r._OrtReleaseBinding=l=>(r._OrtReleaseBinding=B.ka)(l),r._OrtRunWithBinding=(l,m,y,w,I)=>(r._OrtRunWithBinding=B.la)(l,m,y,w,I),r._OrtRun=(l,m,y,w,I,U,F,re)=>(r._OrtRun=B.ma)(l,m,y,w,I,U,F,re),r._OrtEndProfiling=l=>(r._OrtEndProfiling=B.na)(l),r._JsepOutput=(l,m,y)=>(r._JsepOutput=B.oa)(l,m,y),r._JsepGetNodeName=l=>(r._JsepGetNodeName=B.pa)(l);var Ft=r._malloc=l=>(Ft=r._malloc=B.qa)(l),ar=r._free=l=>(ar=r._free=B.ra)(l),ir=l=>(ir=B.ta)(l),sr=()=>(sr=B.ua)(),ur=l=>(ur=B.va)(l),Fe=l=>(Fe=B.wa)(l),Lt=l=>(Lt=B.ya)(l),Ht=()=>(Ht=B.za)(),Pr=l=>(Pr=B.Aa)(l),Qe=()=>(Qe=B.Ba)();r.___start_em_js=927291,r.___stop_em_js=928064;function dn(l){l=Object.assign({},l);var m=w=>()=>w()>>>0,y=w=>I=>w(I)>>>0;return l.__errno_location=m(l.__errno_location),l.malloc=y(l.malloc),l.stackSave=m(l.stackSave),l.stackAlloc=y(l.stackAlloc),l}r.stackAlloc=Fe,r.stackSave=sr,r.stackRestore=ur,r.addFunction=or,r.UTF8ToString=De,r.stringToUTF8=(l,m,y)=>Jt(l,oe,m,y),r.lengthBytesUTF8=Vt;var Le;Ye=function l(){Le||lr(),Le||(Ye=l)};function lr(){function l(){if(!Le&&(Le=!0,r.calledRun=!0,!W)){if(Tt(Be),o(r),r.onRuntimeInitialized&&r.onRuntimeInitialized(),r.postRun)for(typeof r.postRun==\"function\"&&(r.postRun=[r.postRun]);r.postRun.length;){var m=r.postRun.shift();Se.unshift(m)}Tt(Se)}}if(!(0<qe)){if(r.preRun)for(typeof r.preRun==\"function\"&&(r.preRun=[r.preRun]);r.preRun.length;)Ue();Tt(be),0<qe||(r.setStatus?(r.setStatus(\"Running...\"),setTimeout(function(){setTimeout(function(){r.setStatus(\"\")},1),l()},1)):l())}}if(r.preInit)for(typeof r.preInit==\"function\"&&(r.preInit=[r.preInit]);0<r.preInit.length;)r.preInit.pop()();return lr(),t.ready}})();typeof No==\"object\"&&typeof On==\"object\"?On.exports=Uo:typeof define==\"function\"&&define.amd&&define([],()=>Uo)});var Fo=dr(()=>{});var Lo=dr(()=>{});var Ho={};Vr(Ho,{cpus:()=>hl});var hl,jo=K(()=>{hl=void 0});var Yo=dr((Ko,En)=>{\"use strict\";var qo=(()=>{var e=typeof document<\"u\"&&document.currentScript?document.currentScript.src:void 0;return typeof __filename<\"u\"&&(e=e||__filename),function(t={}){function r(){return ve.buffer!=Se.buffer&&Ce(),Se}function o(){return ve.buffer!=Se.buffer&&Ce(),Ue}function a(){return ve.buffer!=Se.buffer&&Ce(),qe}function u(){return ve.buffer!=Se.buffer&&Ce(),Ke}function i(){return ve.buffer!=Se.buffer&&Ce(),Ye}function d(){return ve.buffer!=Se.buffer&&Ce(),G}function f(){return ve.buffer!=Se.buffer&&Ce(),pe}function h(){return ve.buffer!=Se.buffer&&Ce(),Ge}var c=t,C,b;c.ready=new Promise((n,s)=>{C=n,b=s}),c.jsepInit=(n,s,p,g,v,T,M,N)=>{c.oc=n,c.Wb=s,c.Yb=p,c.Lb=g,c.Xb=v,c.cb=T,c.Zb=M,c.$b=N,s=(L,j,Q)=>(...ce)=>{let fe=at,E=j?.();ce=L(...ce);let ie=j?.();return E!==ie&&(L=ie,Q(E),j=Q=null),at!=fe?tl():ce},p=L=>async(...j)=>{try{if(c.Cb)throw Error(\"Session already started\");let Q=c.Cb={cc:j[0],errors:[]},ce=await L(...j);if(c.Cb!==Q)throw Error(\"Session mismatch\");n.flush();let fe=Q.errors;if(0<fe.length){let E=await Promise.all(fe);if(E=E.filter(ie=>ie),0<E.length)throw Error(E.join(`\n`))}return ce}finally{c.Cb=null}},c._OrtRun=p(s(c._OrtRun,()=>c._OrtRun,L=>c._OrtRun=L)),c._OrtRunWithBinding=p(s(c._OrtRunWithBinding,()=>c._OrtRunWithBinding,L=>c._OrtRunWithBinding=L)),c._OrtBindInput=s(c._OrtBindInput,()=>c._OrtBindInput,L=>c._OrtBindInput=L),c.jsepRegisterBuffer=(L,j,Q,ce)=>n.registerBuffer(L,j,Q,ce),c.jsepUnregisterBuffers=L=>{n.unregisterBuffers(L)},c.jsepGetBuffer=L=>n.getBuffer(L),c.jsepCreateDownloader=(L,j,Q)=>n.createDownloader(L,j,Q)};var $=Object.assign({},c),S=\"./this.program\",x=(n,s)=>{throw s},A=typeof window==\"object\",k=typeof importScripts==\"function\",O=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\",P=c.ENVIRONMENT_IS_PTHREAD||!1,R=\"\";function V(n){return c.locateFile?c.locateFile(n,R):R+n}var B,W,q;if(O){var ee=(An(),qt(Cn)),oe=(Tn(),qt(In));R=k?oe.dirname(R)+\"/\":__dirname+\"/\",B=(s,p)=>(s=Et(s)?new URL(s):oe.normalize(s),ee.readFileSync(s,p?void 0:\"utf8\")),q=s=>(s=B(s,!0),s.buffer||(s=new Uint8Array(s)),s),W=(s,p,g,v=!0)=>{s=Et(s)?new URL(s):oe.normalize(s),ee.readFile(s,v?void 0:\"utf8\",(T,M)=>{T?g(T):p(v?M.buffer:M)})},!c.thisProgram&&1<process.argv.length&&(S=process.argv[1].replace(/\\\\/g,\"/\")),process.argv.slice(2),x=(s,p)=>{throw process.exitCode=s,p},c.inspect=()=>\"[Emscripten Module object]\";let n;try{n=Fo()}catch(s){throw console.error('The \"worker_threads\" module is not supported in this node.js build - perhaps a newer version is needed?'),s}global.Worker=n.Worker}else(A||k)&&(k?R=self.location.href:typeof document<\"u\"&&document.currentScript&&(R=document.currentScript.src),typeof e<\"u\"&&e&&(R=e),R.indexOf(\"blob:\")!==0?R=R.substr(0,R.replace(/[?#].*/,\"\").lastIndexOf(\"/\")+1):R=\"\",O||(B=n=>{var s=new XMLHttpRequest;return s.open(\"GET\",n,!1),s.send(null),s.responseText},k&&(q=n=>{var s=new XMLHttpRequest;return s.open(\"GET\",n,!1),s.responseType=\"arraybuffer\",s.send(null),new Uint8Array(s.response)}),W=(n,s,p)=>{var g=new XMLHttpRequest;g.open(\"GET\",n,!0),g.responseType=\"arraybuffer\",g.onload=()=>{g.status==200||g.status==0&&g.response?s(g.response):p()},g.onerror=p,g.send(null)}));O&&typeof performance>\"u\"&&(global.performance=Lo().performance);var D=console.log.bind(console),te=console.error.bind(console);O&&(D=(...n)=>ee.writeSync(1,n.join(\" \")+`\n`),te=(...n)=>ee.writeSync(2,n.join(\" \")+`\n`));var Ie=D,Z=te;Object.assign(c,$),$=null,typeof WebAssembly!=\"object\"&&Xe(\"no native wasm support detected\");var ve,Te,be=!1,Be,Se,Ue,qe,Ke,Ye,G,pe,de,Ne,Ge;function Ce(){var n=ve.buffer;c.HEAP8=Se=new Int8Array(n),c.HEAP16=qe=new Int16Array(n),c.HEAPU8=Ue=new Uint8Array(n),c.HEAPU16=Ke=new Uint16Array(n),c.HEAP32=Ye=new Int32Array(n),c.HEAPU32=G=new Uint32Array(n),c.HEAPF32=pe=new Float32Array(n),c.HEAPF64=Ge=new Float64Array(n),c.HEAP64=de=new BigInt64Array(n),c.HEAPU64=Ne=new BigUint64Array(n)}var Pe=16777216;if(5242880<=Pe||Xe(\"INITIAL_MEMORY should be larger than STACK_SIZE, was \"+Pe+\"! (STACK_SIZE=5242880)\"),P)ve=c.wasmMemory;else if(ve=new WebAssembly.Memory({initial:Pe/65536,maximum:65536,shared:!0}),!(ve.buffer instanceof SharedArrayBuffer))throw Z(\"requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag\"),O&&Z(\"(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)\"),Error(\"bad memory\");Ce(),Pe=ve.buffer.byteLength;var vt=[],He=[],zt=[],nt=0,Tt=null,Ot=null;function Kt(){if(nt--,nt==0&&(Tt!==null&&(clearInterval(Tt),Tt=null),Ot)){var n=Ot;Ot=null,n()}}function Xe(n){throw n=\"Aborted(\"+n+\")\",Z(n),be=!0,Be=1,n=new WebAssembly.RuntimeError(n+\". Build with -sASSERTIONS for more info.\"),b(n),n}var Yt=n=>n.startsWith(\"data:application/octet-stream;base64,\"),Et=n=>n.startsWith(\"file://\"),De;De=\"ort-wasm-simd-threaded.wasm\",Yt(De)||(De=V(De));function Vt(n){if(q)return q(n);throw\"both async and sync fetching of the wasm failed\"}function Jt(n){if(A||k){if(typeof fetch==\"function\"&&!Et(n))return fetch(n,{credentials:\"same-origin\"}).then(s=>{if(!s.ok)throw\"failed to load wasm binary file at '\"+n+\"'\";return s.arrayBuffer()}).catch(()=>Vt(n));if(W)return new Promise((s,p)=>{W(n,g=>s(new Uint8Array(g)),p)})}return Promise.resolve().then(()=>Vt(n))}function mt(n,s,p){return Jt(n).then(g=>WebAssembly.instantiate(g,s)).then(g=>g).then(p,g=>{Z(`failed to asynchronously prepare wasm: ${g}`),Xe(g)})}function xr(n,s){var p=De;return typeof WebAssembly.instantiateStreaming!=\"function\"||Yt(p)||Et(p)||O||typeof fetch!=\"function\"?mt(p,n,s):fetch(p,{credentials:\"same-origin\"}).then(g=>WebAssembly.instantiateStreaming(g,n).then(s,function(v){return Z(`wasm streaming compile failed: ${v}`),Z(\"falling back to ArrayBuffer instantiation\"),mt(p,n,s)}))}var Ut={1441368:n=>{c.cb(\"Abs\",n,void 0)},1441419:n=>{c.cb(\"Neg\",n,void 0)},1441470:n=>{c.cb(\"Floor\",n,void 0)},1441523:n=>{c.cb(\"Ceil\",n,void 0)},1441575:n=>{c.cb(\"Reciprocal\",n,void 0)},1441633:n=>{c.cb(\"Sqrt\",n,void 0)},1441685:n=>{c.cb(\"Exp\",n,void 0)},1441736:n=>{c.cb(\"Erf\",n,void 0)},1441787:n=>{c.cb(\"Sigmoid\",n,void 0)},1441842:n=>{c.cb(\"Log\",n,void 0)},1441893:n=>{c.cb(\"Sin\",n,void 0)},1441944:n=>{c.cb(\"Cos\",n,void 0)},1441995:n=>{c.cb(\"Tan\",n,void 0)},1442046:n=>{c.cb(\"Asin\",n,void 0)},1442098:n=>{c.cb(\"Acos\",n,void 0)},1442150:n=>{c.cb(\"Atan\",n,void 0)},1442202:n=>{c.cb(\"Sinh\",n,void 0)},1442254:n=>{c.cb(\"Cosh\",n,void 0)},1442306:n=>{c.cb(\"Asinh\",n,void 0)},1442359:n=>{c.cb(\"Acosh\",n,void 0)},1442412:n=>{c.cb(\"Atanh\",n,void 0)},1442465:n=>{c.cb(\"Tanh\",n,void 0)},1442517:n=>{c.cb(\"Not\",n,void 0)},1442568:(n,s,p)=>{c.cb(\"ClipV10\",n,{min:s,max:p})},1442640:n=>{c.cb(\"Clip\",n,void 0)},1442692:(n,s)=>{c.cb(\"Elu\",n,{alpha:s})},1442750:n=>{c.cb(\"Relu\",n,void 0)},1442802:(n,s)=>{c.cb(\"LeakyRelu\",n,{alpha:s})},1442866:(n,s)=>{c.cb(\"ThresholdedRelu\",n,{alpha:s})},1442936:n=>{c.Zb(n)},1442970:(n,s)=>c.$b(n,s,c.Cb.cc,c.Cb.errors),1443082:(n,s)=>{c.cb(\"Cast\",n,{to:s})},1443140:n=>{c.cb(\"Add\",n,void 0)},1443191:n=>{c.cb(\"Sub\",n,void 0)},1443242:n=>{c.cb(\"Mul\",n,void 0)},1443293:n=>{c.cb(\"Div\",n,void 0)},1443344:n=>{c.cb(\"Pow\",n,void 0)},1443395:n=>{c.cb(\"Equal\",n,void 0)},1443448:n=>{c.cb(\"Greater\",n,void 0)},1443503:n=>{c.cb(\"GreaterOrEqual\",n,void 0)},1443565:n=>{c.cb(\"Less\",n,void 0)},1443617:n=>{c.cb(\"LessOrEqual\",n,void 0)},1443676:(n,s,p,g,v)=>{c.cb(\"ReduceMean\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1443840:(n,s,p,g,v)=>{c.cb(\"ReduceMax\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1444003:(n,s,p,g,v)=>{c.cb(\"ReduceMin\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1444166:(n,s,p,g,v)=>{c.cb(\"ReduceProd\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1444330:(n,s,p,g,v)=>{c.cb(\"ReduceSum\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1444493:(n,s,p,g,v)=>{c.cb(\"ReduceL1\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1444655:(n,s,p,g,v)=>{c.cb(\"ReduceL2\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1444817:(n,s,p,g,v)=>{c.cb(\"ReduceLogSum\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1444983:(n,s,p,g,v)=>{c.cb(\"ReduceSumSquare\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1445152:(n,s,p,g,v)=>{c.cb(\"ReduceLogSumExp\",n,{keepDims:!!s,noopWithEmptyAxes:!!p,axes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1445321:n=>{c.cb(\"Where\",n,void 0)},1445374:(n,s,p)=>{c.cb(\"Transpose\",n,{perm:s?Array.from(i().subarray(p>>>0,p+s>>>0)):[]})},1445487:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe)=>{c.cb(\"Conv\",n,{format:L?\"NHWC\":\"NCHW\",auto_pad:s,dilations:[p],group:g,kernel_shape:[v],pads:T?Array.from(i().subarray(M>>>0,M+T>>>0)):[],strides:[N],w_is_const:()=>!!r()[j>>>0],activation:Ve(Q),activation_params:ce?Array.from(f().subarray(fe>>>0,fe+ce>>>0)):[]})},1445868:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe,E,ie,we)=>{c.cb(\"Conv\",n,{format:ce?\"NHWC\":\"NCHW\",auto_pad:s,dilations:[p,g],group:v,kernel_shape:[T,M],pads:N?Array.from(i().subarray(L>>>0,L+N>>>0)):[],strides:[j,Q],w_is_const:()=>!!r()[fe>>>0],activation:Ve(E),activation_params:ie?Array.from(f().subarray(we>>>0,we+ie>>>0)):[]})},1446270:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe,E,ie)=>{c.cb(\"ConvTranspose\",n,{format:L?\"NHWC\":\"NCHW\",autoPad:s,dilations:[p],group:g,kernel_shape:[v],pads:[T,M],strides:[N],wIsConst:()=>!!r()[j>>>0],outputPadding:Q?Array.from(i().subarray(ce>>>0,ce+Q>>>0)):[],outputShape:fe?Array.from(i().subarray(E>>>0,E+fe>>>0)):[],activation:Ve(ie)})},1446684:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe,E)=>{c.cb(\"ConvTranspose\",n,{format:N?\"NHWC\":\"NCHW\",autoPad:s,dilations:Array.from(i().subarray(p>>>0,p+2>>>0)),group:g,kernelShape:Array.from(i().subarray(v>>>0,v+2>>>0)),pads:Array.from(i().subarray(T>>>0,T+4>>>0)),strides:Array.from(i().subarray(M>>>0,M+2>>>0)),wIsConst:()=>!!r()[L>>>0],outputPadding:0<j?Array.from(i().subarray(Q>>>0,Q+j>>>0)):[],outputShape:0<ce?Array.from(i().subarray(fe>>>0,fe+ce>>>0)):[],activation:Ve(E)})},1447241:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe,E,ie)=>{c.cb(\"ConvTranspose\",n,{format:L?\"NHWC\":\"NCHW\",autoPad:s,dilations:[p],group:g,kernel_shape:[v],pads:[T,M],strides:[N],wIsConst:()=>!!r()[j>>>0],outputPadding:Q?Array.from(i().subarray(ce>>>0,ce+Q>>>0)):[],outputShape:fe?Array.from(i().subarray(E>>>0,E+fe>>>0)):[],activation:Ve(ie)})},1447655:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe,E)=>{c.cb(\"ConvTranspose\",n,{format:N?\"NHWC\":\"NCHW\",autoPad:s,dilations:Array.from(i().subarray(p>>>0,p+2>>>0)),group:g,kernelShape:Array.from(i().subarray(v>>>0,v+2>>>0)),pads:Array.from(i().subarray(T>>>0,T+4>>>0)),strides:Array.from(i().subarray(M>>>0,M+2>>>0)),wIsConst:()=>!!r()[L>>>0],outputPadding:0<j?Array.from(i().subarray(Q>>>0,Q+j>>>0)):[],outputShape:0<ce?Array.from(i().subarray(fe>>>0,fe+ce>>>0)):[],activation:Ve(E)})},1448212:(n,s)=>{c.cb(\"GlobalAveragePool\",n,{format:s?\"NHWC\":\"NCHW\"})},1448303:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe,E,ie,we)=>{c.cb(\"AveragePool\",n,{format:we?\"NHWC\":\"NCHW\",auto_pad:s,ceil_mode:p,count_include_pad:g,storage_order:v,dilations:[T,M],kernel_shape:[N,L],pads:[j,Q,ce,fe],strides:[E,ie]})},1448587:(n,s)=>{c.cb(\"GlobalAveragePool\",n,{format:s?\"NHWC\":\"NCHW\"})},1448678:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe,E,ie,we)=>{c.cb(\"AveragePool\",n,{format:we?\"NHWC\":\"NCHW\",auto_pad:s,ceil_mode:p,count_include_pad:g,storage_order:v,dilations:[T,M],kernel_shape:[N,L],pads:[j,Q,ce,fe],strides:[E,ie]})},1448962:(n,s)=>{c.cb(\"GlobalMaxPool\",n,{format:s?\"NHWC\":\"NCHW\"})},1449049:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe,E,ie,we)=>{c.cb(\"MaxPool\",n,{format:we?\"NHWC\":\"NCHW\",auto_pad:s,ceil_mode:p,count_include_pad:g,storage_order:v,dilations:[T,M],kernel_shape:[N,L],pads:[j,Q,ce,fe],strides:[E,ie]})},1449329:(n,s)=>{c.cb(\"GlobalMaxPool\",n,{format:s?\"NHWC\":\"NCHW\"})},1449416:(n,s,p,g,v,T,M,N,L,j,Q,ce,fe,E,ie,we)=>{c.cb(\"MaxPool\",n,{format:we?\"NHWC\":\"NCHW\",auto_pad:s,ceil_mode:p,count_include_pad:g,storage_order:v,dilations:[T,M],kernel_shape:[N,L],pads:[j,Q,ce,fe],strides:[E,ie]})},1449696:(n,s,p,g,v)=>{c.cb(\"Gemm\",n,{alpha:s,beta:p,transA:g,transB:v})},1449800:n=>{c.cb(\"MatMul\",n,void 0)},1449854:(n,s,p,g)=>{c.cb(\"ArgMax\",n,{keepDims:!!s,selectLastIndex:!!p,axis:g})},1449962:(n,s,p,g)=>{c.cb(\"ArgMin\",n,{keepDims:!!s,selectLastIndex:!!p,axis:g})},1450070:(n,s)=>{c.cb(\"Softmax\",n,{axis:s})},1450133:(n,s)=>{c.cb(\"Concat\",n,{axis:s})},1450193:(n,s,p,g,v)=>{c.cb(\"Split\",n,{axis:s,numOutputs:p,splitSizes:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1450338:n=>{c.cb(\"Expand\",n,void 0)},1450392:(n,s)=>{c.cb(\"Gather\",n,{axis:Number(s)})},1450463:(n,s)=>{c.cb(\"GatherElements\",n,{axis:Number(s)})},1450542:(n,s,p,g,v,T,M,N,L,j,Q)=>{c.cb(\"Resize\",n,{antialias:s,axes:p?Array.from(i().subarray(g>>>0,g+p>>>0)):[],coordinateTransformMode:Ve(v),cubicCoeffA:T,excludeOutside:M,extrapolationValue:N,keepAspectRatioPolicy:Ve(L),mode:Ve(j),nearestMode:Ve(Q)})},1450893:(n,s,p,g,v,T,M)=>{c.cb(\"Slice\",n,{starts:s?Array.from(i().subarray(p>>>0,p+s>>>0)):[],ends:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[],axes:T?Array.from(i().subarray(M>>>0,M+T>>>0)):[]})},1451124:n=>{c.cb(\"Tile\",n,void 0)},1451176:(n,s,p)=>{c.cb(\"LayerNormalization\",n,{axis:Number(s),epsilon:Number(p)})},1451283:(n,s,p)=>{c.cb(\"InstanceNormalization\",n,{epsilon:s,format:p?\"NHWC\":\"NCHW\"})},1451397:(n,s,p)=>{c.cb(\"InstanceNormalization\",n,{epsilon:s,format:p?\"NHWC\":\"NCHW\"})},1451511:n=>{c.cb(\"Range\",n,void 0)},1451564:(n,s)=>{c.cb(\"Einsum\",n,{equation:Ve(s)})},1451645:(n,s,p,g,v)=>{c.cb(\"Pad\",n,{mode:s,value:p,pads:g?Array.from(i().subarray(v>>>0,v+g>>>0)):[]})},1451777:n=>{c.cb(\"Gelu\",n,void 0)},1451829:n=>{c.cb(\"BiasAdd\",n,void 0)},1451884:n=>{c.cb(\"BiasSplitGelu\",n,void 0)},1451945:(n,s)=>{c.cb(\"SkipLayerNormalization\",n,{epsilon:s})},1452026:n=>c.Wb(n),1452059:n=>c.Yb(n),1452091:(n,s,p)=>{c.Lb(n,s,p,!0)},1452130:(n,s,p)=>{c.Lb(n,s,p)}};function _t(n){this.name=\"ExitStatus\",this.message=`Program terminated with exit(${n})`,this.status=n}var Pt=n=>{n.terminate(),n.onmessage=()=>{}},Xt=n=>{if(le.zb.length==0){var s=V(\"ort-wasm-simd-threaded.worker.js\");s=new Worker(s),le.zb.push(s),le.ac(le.zb[0])}if(s=le.zb.pop(),!s)return 6;le.wb.push(s),le.nb[n.vb]=s,s.vb=n.vb;var p={cmd:\"run\",start_routine:n.dc,arg:n.Rb,pthread_ptr:n.vb};return O&&s.unref(),s.postMessage(p,n.kc),0},Ze=0,Zt=typeof TextDecoder<\"u\"?new TextDecoder(\"utf8\"):void 0,Nt=(n,s,p)=>{s>>>=0;var g=s+p;for(p=s;n[p]&&!(p>=g);)++p;if(16<p-s&&n.buffer&&Zt)return Zt.decode(n.buffer instanceof SharedArrayBuffer?n.slice(s,p):n.subarray(s,p));for(g=\"\";s<p;){var v=n[s++];if(v&128){var T=n[s++]&63;if((v&224)==192)g+=String.fromCharCode((v&31)<<6|T);else{var M=n[s++]&63;v=(v&240)==224?(v&15)<<12|T<<6|M:(v&7)<<18|T<<12|M<<6|n[s++]&63,65536>v?g+=String.fromCharCode(v):(v-=65536,g+=String.fromCharCode(55296|v>>10,56320|v&1023))}}else g+=String.fromCharCode(v)}return g},Ve=(n,s)=>(n>>>=0)?Nt(o(),n,s):\"\";function Qt(n){if(P)return Oe(0,1,n);Be=n,0<Ze||(le.ec(),be=!0),x(n,new _t(n))}var Gt=n=>{if(Be=n,P)throw Sr(n),\"unwind\";Qt(n)};function cn(){vt.unshift(()=>{nt++,Kt()})}var le={zb:[],wb:[],Qb:[],nb:{},Fb(){P?(le.receiveObjectTransfer=le.bc,le.threadInitTLS=le.Pb,le.setExitStatus=le.Ob):cn()},Ob:n=>{Be=n},pc:[\"$terminateWorker\"],ec:()=>{for(var n of le.wb)Pt(n);for(n of le.zb)Pt(n);le.zb=[],le.wb=[],le.nb=[]},Nb:n=>{var s=n.vb;delete le.nb[s],le.zb.push(n),le.wb.splice(le.wb.indexOf(n),1),n.vb=0,wn(s)},bc(){},Pb(){le.Qb.forEach(n=>n())},ac:n=>new Promise(s=>{n.onmessage=T=>{T=T.data;var M=T.cmd;if(T.targetThread&&T.targetThread!=Dr()){var N=le.nb[T.targetThread];N?N.postMessage(T,T.transferList):Z(`Internal error! Worker sent a message \"${M}\" to target pthread ${T.targetThread}, but that thread no longer exists!`)}else M===\"checkMailbox\"?Mt():M===\"spawnThread\"?Xt(T):M===\"cleanupThread\"?((T=le.nb[T.thread])||Xe(),le.Nb(T)):M===\"killThread\"?(T=T.thread,M=le.nb[T],delete le.nb[T],Pt(M),wn(T),le.wb.splice(le.wb.indexOf(M),1),M.vb=0):M===\"cancelThread\"?le.nb[T.thread].postMessage({cmd:\"cancel\"}):M===\"loaded\"?(n.loaded=!0,s(n)):M===\"alert\"?alert(`Thread ${T.threadId}: ${T.text}`):T.target===\"setimmediate\"?n.postMessage(T):M===\"callHandler\"?c[T.handler](...T.args):M&&Z(`worker sent an unknown command ${M}`)},n.onerror=T=>{throw Z(`worker sent an error! ${T.filename}:${T.lineno}: ${T.message}`),T},O&&(n.on(\"message\",T=>n.onmessage({data:T})),n.on(\"error\",T=>n.onerror(T)));var p=[],g=[],v;for(v of g)c.hasOwnProperty(v)&&p.push(v);n.postMessage({cmd:\"load\",handlers:p,urlOrBlob:c.mainScriptUrlOrBlob||e,wasmMemory:ve,wasmModule:Te})})};c.PThread=le;var ht=n=>{for(;0<n.length;)n.shift()(c)};c.establishStackSpace=()=>{var n=Dr(),s=d()[n+52>>>2>>>0];n=d()[n+56>>>2>>>0],Ro(s,s-n),Wr(s)};function Sr(n){if(P)return Oe(1,0,n);Gt(n)}c.invokeEntryPoint=(n,s)=>{n=Mo.apply(null,[n,s]),0<Ze?le.Ob(n):vn(n)};function ot(n){this.Ab=n-24,this.lc=function(s){d()[this.Ab+4>>>2>>>0]=s},this.Ib=function(s){d()[this.Ab+8>>>2>>>0]=s},this.Fb=function(s,p){this.Hb(),this.lc(s),this.Ib(p)},this.Hb=function(){d()[this.Ab+16>>>2>>>0]=0}}var je=0,Cr=0;function Rt(n,s,p,g){return P?Oe(2,1,n,s,p,g):er(n,s,p,g)}function er(n,s,p,g){if(n>>>=0,s>>>=0,p>>>=0,g>>>=0,typeof SharedArrayBuffer>\"u\")return Z(\"Current environment does not support SharedArrayBuffer, pthreads are not available!\"),6;var v=[];return P&&v.length===0?Rt(n,s,p,g):(n={dc:p,vb:n,Rb:g,kc:v},P?(n.nc=\"spawnThread\",postMessage(n,v),0):Xt(n))}function tr(n,s,p){return P?Oe(3,1,n,s,p):0}function Ar(n,s){if(P)return Oe(4,1,n,s)}var $t=n=>{for(var s=0,p=0;p<n.length;++p){var g=n.charCodeAt(p);127>=g?s++:2047>=g?s+=2:55296<=g&&57343>=g?(s+=4,++p):s+=3}return s},Ir=(n,s,p,g)=>{if(p>>>=0,!(0<g))return 0;var v=p;g=p+g-1;for(var T=0;T<n.length;++T){var M=n.charCodeAt(T);if(55296<=M&&57343>=M){var N=n.charCodeAt(++T);M=65536+((M&1023)<<10)|N&1023}if(127>=M){if(p>=g)break;s[p++>>>0]=M}else{if(2047>=M){if(p+1>=g)break;s[p++>>>0]=192|M>>6}else{if(65535>=M){if(p+2>=g)break;s[p++>>>0]=224|M>>12}else{if(p+3>=g)break;s[p++>>>0]=240|M>>18,s[p++>>>0]=128|M>>12&63}s[p++>>>0]=128|M>>6&63}s[p++>>>0]=128|M&63}}return s[p>>>0]=0,p-v},rr=(n,s,p)=>Ir(n,o(),s,p);function Tr(n,s){if(P)return Oe(5,1,n,s)}function Or(n,s,p){if(P)return Oe(6,1,n,s,p)}function Er(n,s,p){return P?Oe(7,1,n,s,p):0}function gt(n,s){if(P)return Oe(8,1,n,s)}function yt(n,s,p){if(P)return Oe(9,1,n,s,p)}function nr(n,s,p,g){if(P)return Oe(10,1,n,s,p,g)}function or(n,s,p,g){if(P)return Oe(11,1,n,s,p,g)}function _r(n,s,p,g){if(P)return Oe(12,1,n,s,p,g)}function Ft(n){if(P)return Oe(13,1,n)}function ar(n,s){if(P)return Oe(14,1,n,s)}function ir(n,s,p){if(P)return Oe(15,1,n,s,p)}var sr=n=>{if(n===null)return\"null\";var s=typeof n;return s===\"object\"||s===\"array\"||s===\"function\"?n.toString():\"\"+n},ur,Fe=n=>{for(var s=\"\";o()[n>>>0];)s+=ur[o()[n++>>>0]];return s},Lt={},Ht={},Pr={},Qe;function dn(n,s,p={}){var g=s.name;if(!n)throw new Qe(`type \"${g}\" must have a positive integer typeid pointer`);if(Ht.hasOwnProperty(n)){if(p.Ub)return;throw new Qe(`Cannot register type '${g}' twice`)}Ht[n]=s,delete Pr[n],Lt.hasOwnProperty(n)&&(s=Lt[n],delete Lt[n],s.forEach(v=>v()))}function Le(n,s,p={}){if(!(\"argPackAdvance\"in s))throw new TypeError(\"registerType registeredInstance requires argPackAdvance\");dn(n,s,p)}var lr=(n,s,p)=>{switch(s){case 1:return p?g=>r()[g>>>0>>>0]:g=>o()[g>>>0>>>0];case 2:return p?g=>a()[g>>>1>>>0]:g=>u()[g>>>1>>>0];case 4:return p?g=>i()[g>>>2>>>0]:g=>d()[g>>>2>>>0];case 8:return p?g=>de[g>>>3]:g=>Ne[g>>>3];default:throw new TypeError(`invalid integer width (${s}): ${n}`)}};function l(){this.ub=[void 0],this.Kb=[]}var m=new l;function y(n){n>>>=0,n>=m.Ab&&--m.get(n).Mb===0&&m.Ib(n)}var w=n=>{if(!n)throw new Qe(\"Cannot use deleted val. handle = \"+n);return m.get(n).value},I=n=>{switch(n){case void 0:return 1;case null:return 2;case!0:return 3;case!1:return 4;default:return m.Hb({Mb:1,value:n})}};function U(n){return this.fromWireType(i()[n>>>2>>>0])}var F=(n,s)=>{switch(s){case 4:return function(p){return this.fromWireType(f()[p>>>2>>>0])};case 8:return function(p){return this.fromWireType(h()[p>>>3>>>0])};default:throw new TypeError(`invalid float width (${s}): ${n}`)}};function re(n){return this.fromWireType(d()[n>>>2>>>0])}var J=typeof TextDecoder<\"u\"?new TextDecoder(\"utf-16le\"):void 0,ae=(n,s)=>{for(var p=n>>1,g=p+s/2;!(p>=g)&&u()[p>>>0];)++p;if(p<<=1,32<p-n&&J)return J.decode(o().slice(n,p));for(p=\"\",g=0;!(g>=s/2);++g){var v=a()[n+2*g>>>1>>>0];if(v==0)break;p+=String.fromCharCode(v)}return p},ne=(n,s,p)=>{if(p===void 0&&(p=2147483647),2>p)return 0;p-=2;var g=s;p=p<2*n.length?p/2:n.length;for(var v=0;v<p;++v){var T=n.charCodeAt(v);a()[s>>>1>>>0]=T,s+=2}return a()[s>>>1>>>0]=0,s-g},me=n=>2*n.length,ye=(n,s)=>{for(var p=0,g=\"\";!(p>=s/4);){var v=i()[n+4*p>>>2>>>0];if(v==0)break;++p,65536<=v?(v-=65536,g+=String.fromCharCode(55296|v>>10,56320|v&1023)):g+=String.fromCharCode(v)}return g},_=(n,s,p)=>{if(s>>>=0,p===void 0&&(p=2147483647),4>p)return 0;var g=s;p=g+p-4;for(var v=0;v<n.length;++v){var T=n.charCodeAt(v);if(55296<=T&&57343>=T){var M=n.charCodeAt(++v);T=65536+((T&1023)<<10)|M&1023}if(i()[s>>>2>>>0]=T,s+=4,s+4>p)break}return i()[s>>>2>>>0]=0,s-g},se=n=>{for(var s=0,p=0;p<n.length;++p){var g=n.charCodeAt(p);55296<=g&&57343>=g&&++p,s+=4}return s},he=n=>{if(!be)try{if(n(),!(0<Ze))try{P?vn(Be):Gt(Be)}catch(s){s instanceof _t||s==\"unwind\"||x(1,s)}}catch(s){s instanceof _t||s==\"unwind\"||x(1,s)}};function et(n){n>>>=0,typeof Atomics.mc==\"function\"&&(Atomics.mc(i(),n>>>2,n).value.then(Mt),n+=128,Atomics.store(i(),n>>>2,1))}c.__emscripten_thread_mailbox_await=et;var Mt=()=>{var n=Dr();n&&(et(n),he(()=>Po()))};c.checkMailbox=Mt;var Gu=n=>{var s=$n();return n=n(),Wr(s),n};function Oe(n,s){var p=arguments.length-2,g=arguments;return Gu(()=>{for(var v=2*p,T=xn(8*v),M=T>>>3,N=0;N<p;N++){var L=g[2+N];typeof L==\"bigint\"?(de[M+2*N]=1n,de[M+2*N+1]=L):(de[M+2*N]=0n,h()[M+2*N+1>>>0]=L)}return _o(n,v,T,s)})}var pn=[],Rr=(n,s)=>{var p=Ht[n];if(p===void 0)throw n=Oo(n),p=Fe(n),it(n),new Qe(s+\" has unknown type \"+p);return p},Fu={},fn=n=>{var s=Fu[n];return s===void 0?Fe(n):s},mn=[],oo=()=>typeof globalThis==\"object\"?globalThis:Function(\"return this\")(),Lu=n=>{var s=mn.length;return mn.push(n),s},Hu=(n,s)=>{for(var p=Array(n),g=0;g<n;++g)p[g]=Rr(d()[s+4*g>>>2>>>0],\"parameter \"+g);return p},ao=n=>{if(n===void 0)return\"_unknown\";n=n.replace(/[^a-zA-Z0-9_]/g,\"$\");var s=n.charCodeAt(0);return 48<=s&&57>=s?`_${n}`:n};function ju(n,s){return n=ao(n),{[n]:function(){return s.apply(this,arguments)}}[n]}function qu(n){var s=Function;if(!(s instanceof Function))throw new TypeError(`new_ called with constructor type ${typeof s} which is not a function`);var p=ju(s.name||\"unknownFunctionName\",function(){});return p.prototype=s.prototype,p=new p,n=s.apply(p,n),n instanceof Object?n:p}var Ku=n=>{for(var s=\"\",p=0;p<n;++p)s+=(p!==0?\", \":\"\")+\"arg\"+p;var g=\"return function emval_allocator_\"+n+`(constructor, argTypes, args) {\n  var HEAPU32 = getMemory();\n`;for(p=0;p<n;++p)g+=\"var argType\"+p+\" = requireRegisteredType(HEAPU32[((argTypes)>>>2)], 'parameter \"+p+`');\nvar arg`+p+\" = argType\"+p+`.readValueFromPointer(args);\nargs += argType`+p+`['argPackAdvance'];\nargTypes += 4;\n`;return new Function(\"requireRegisteredType\",\"Module\",\"valueToHandle\",\"getMemory\",g+(\"var obj = new constructor(\"+s+`);\nreturn valueToHandle(obj);\n}\n`))(Rr,c,I,()=>d())},io={},jt=n=>n%4===0&&(n%100!==0||n%400===0),so=[0,31,60,91,121,152,182,213,244,274,305,335],uo=[0,31,59,90,120,151,181,212,243,273,304,334];function lo(n,s,p,g,v,T,M){return P?Oe(16,1,n,s,p,g,v,T,M):-52}function co(n,s,p,g,v,T){if(P)return Oe(17,1,n,s,p,g,v,T)}var po=n=>{var s=$t(n)+1,p=cr(s);return p&&rr(n,p,s),p},hn=[],fo=(n,s)=>{hn.length=0;for(var p;p=o()[n++>>>0];){var g=p!=105;g&=p!=112,s+=g&&s%8?4:0,hn.push(p==112?d()[s>>>2>>>0]:p==106?de[s>>>3]:p==105?i()[s>>>2>>>0]:h()[s>>>3>>>0]),s+=g?8:4}return hn},gn={},mo=()=>{if(!yn){var n={USER:\"web_user\",LOGNAME:\"web_user\",PATH:\"/\",PWD:\"/\",HOME:\"/home/web_user\",LANG:(typeof navigator==\"object\"&&navigator.languages&&navigator.languages[0]||\"C\").replace(\"-\",\"_\")+\".UTF-8\",_:S||\"./this.program\"},s;for(s in gn)gn[s]===void 0?delete n[s]:n[s]=gn[s];var p=[];for(s in n)p.push(`${s}=${n[s]}`);yn=p}return yn},yn;function ho(n,s){if(P)return Oe(18,1,n,s);n>>>=0,s>>>=0;var p=0;return mo().forEach((g,v)=>{var T=s+p;for(v=d()[n+4*v>>>2>>>0]=T,T=0;T<g.length;++T)r()[v++>>>0>>>0]=g.charCodeAt(T);r()[v>>>0>>>0]=0,p+=g.length+1}),0}function go(n,s){if(P)return Oe(19,1,n,s);n>>>=0,s>>>=0;var p=mo();d()[n>>>2>>>0]=p.length;var g=0;return p.forEach(v=>g+=v.length+1),d()[s>>>2>>>0]=g,0}function yo(n){return P?Oe(20,1,n):52}function bo(n,s,p,g){return P?Oe(21,1,n,s,p,g):52}function wo(n,s,p,g){return P?Oe(22,1,n,s,p,g):70}var Yu=[null,[],[]];function vo(n,s,p,g){if(P)return Oe(23,1,n,s,p,g);s>>>=0,p>>>=0,g>>>=0;for(var v=0,T=0;T<p;T++){var M=d()[s>>>2>>>0],N=d()[s+4>>>2>>>0];s+=8;for(var L=0;L<N;L++){var j=o()[M+L>>>0],Q=Yu[n];j===0||j===10?((n===1?Ie:Z)(Nt(Q,0)),Q.length=0):Q.push(j)}v+=N}return d()[g>>>2>>>0]=v,0}var $o=[31,29,31,30,31,30,31,31,30,31,30,31],xo=[31,28,31,30,31,30,31,31,30,31,30,31];function Ju(n){var s=Array($t(n)+1);return Ir(n,s,0,s.length),s}var Xu=(n,s)=>{r().set(n,s>>>0)};function So(n,s,p,g){function v(E,ie,we){for(E=typeof E==\"number\"?E.toString():E||\"\";E.length<ie;)E=we[0]+E;return E}function T(E,ie){return v(E,ie,\"0\")}function M(E,ie){function we(Vo){return 0>Vo?-1:0<Vo?1:0}var kt;return(kt=we(E.getFullYear()-ie.getFullYear()))===0&&(kt=we(E.getMonth()-ie.getMonth()))===0&&(kt=we(E.getDate()-ie.getDate())),kt}function N(E){switch(E.getDay()){case 0:return new Date(E.getFullYear()-1,11,29);case 1:return E;case 2:return new Date(E.getFullYear(),0,3);case 3:return new Date(E.getFullYear(),0,2);case 4:return new Date(E.getFullYear(),0,1);case 5:return new Date(E.getFullYear()-1,11,31);case 6:return new Date(E.getFullYear()-1,11,30)}}function L(E){var ie=E.xb;for(E=new Date(new Date(E.yb+1900,0,1).getTime());0<ie;){var we=E.getMonth(),kt=(jt(E.getFullYear())?$o:xo)[we];if(ie>kt-E.getDate())ie-=kt-E.getDate()+1,E.setDate(1),11>we?E.setMonth(we+1):(E.setMonth(0),E.setFullYear(E.getFullYear()+1));else{E.setDate(E.getDate()+ie);break}}return we=new Date(E.getFullYear()+1,0,4),ie=N(new Date(E.getFullYear(),0,4)),we=N(we),0>=M(ie,E)?0>=M(we,E)?E.getFullYear()+1:E.getFullYear():E.getFullYear()-1}n>>>=0,s>>>=0,p>>>=0,g>>>=0;var j=d()[g+40>>>2>>>0];g={ic:i()[g>>>2>>>0],hc:i()[g+4>>>2>>>0],Db:i()[g+8>>>2>>>0],Jb:i()[g+12>>>2>>>0],Eb:i()[g+16>>>2>>>0],yb:i()[g+20>>>2>>>0],tb:i()[g+24>>>2>>>0],xb:i()[g+28>>>2>>>0],qc:i()[g+32>>>2>>>0],fc:i()[g+36>>>2>>>0],jc:j?Ve(j):\"\"},p=Ve(p),j={\"%c\":\"%a %b %d %H:%M:%S %Y\",\"%D\":\"%m/%d/%y\",\"%F\":\"%Y-%m-%d\",\"%h\":\"%b\",\"%r\":\"%I:%M:%S %p\",\"%R\":\"%H:%M\",\"%T\":\"%H:%M:%S\",\"%x\":\"%m/%d/%y\",\"%X\":\"%H:%M:%S\",\"%Ec\":\"%c\",\"%EC\":\"%C\",\"%Ex\":\"%m/%d/%y\",\"%EX\":\"%H:%M:%S\",\"%Ey\":\"%y\",\"%EY\":\"%Y\",\"%Od\":\"%d\",\"%Oe\":\"%e\",\"%OH\":\"%H\",\"%OI\":\"%I\",\"%Om\":\"%m\",\"%OM\":\"%M\",\"%OS\":\"%S\",\"%Ou\":\"%u\",\"%OU\":\"%U\",\"%OV\":\"%V\",\"%Ow\":\"%w\",\"%OW\":\"%W\",\"%Oy\":\"%y\"};for(var Q in j)p=p.replace(new RegExp(Q,\"g\"),j[Q]);var ce=\"Sunday Monday Tuesday Wednesday Thursday Friday Saturday\".split(\" \"),fe=\"January February March April May June July August September October November December\".split(\" \");j={\"%a\":E=>ce[E.tb].substring(0,3),\"%A\":E=>ce[E.tb],\"%b\":E=>fe[E.Eb].substring(0,3),\"%B\":E=>fe[E.Eb],\"%C\":E=>T((E.yb+1900)/100|0,2),\"%d\":E=>T(E.Jb,2),\"%e\":E=>v(E.Jb,2,\" \"),\"%g\":E=>L(E).toString().substring(2),\"%G\":E=>L(E),\"%H\":E=>T(E.Db,2),\"%I\":E=>(E=E.Db,E==0?E=12:12<E&&(E-=12),T(E,2)),\"%j\":E=>{for(var ie=0,we=0;we<=E.Eb-1;ie+=(jt(E.yb+1900)?$o:xo)[we++]);return T(E.Jb+ie,3)},\"%m\":E=>T(E.Eb+1,2),\"%M\":E=>T(E.hc,2),\"%n\":()=>`\n`,\"%p\":E=>0<=E.Db&&12>E.Db?\"AM\":\"PM\",\"%S\":E=>T(E.ic,2),\"%t\":()=>\"\t\",\"%u\":E=>E.tb||7,\"%U\":E=>T(Math.floor((E.xb+7-E.tb)/7),2),\"%V\":E=>{var ie=Math.floor((E.xb+7-(E.tb+6)%7)/7);if(2>=(E.tb+371-E.xb-2)%7&&ie++,ie)ie==53&&(we=(E.tb+371-E.xb)%7,we==4||we==3&&jt(E.yb)||(ie=1));else{ie=52;var we=(E.tb+7-E.xb-1)%7;(we==4||we==5&&jt(E.yb%400-1))&&ie++}return T(ie,2)},\"%w\":E=>E.tb,\"%W\":E=>T(Math.floor((E.xb+7-(E.tb+6)%7)/7),2),\"%y\":E=>(E.yb+1900).toString().substring(2),\"%Y\":E=>E.yb+1900,\"%z\":E=>{E=E.fc;var ie=0<=E;return E=Math.abs(E)/60,(ie?\"+\":\"-\")+(\"0000\"+(E/60*100+E%60)).slice(-4)},\"%Z\":E=>E.jc,\"%%\":()=>\"%\"},p=p.replace(/%%/g,\"\\0\\0\");for(Q in j)p.includes(Q)&&(p=p.replace(new RegExp(Q,\"g\"),j[Q](g)));return p=p.replace(/\\0\\0/g,\"%\"),Q=Ju(p),Q.length>s?0:(Xu(Q,n),Q.length-1)}var Mr=n=>{try{n()}catch(s){Xe(s)}};function Zu(){var n=X,s={},p;for(p in n)(function(g){var v=n[g];s[g]=typeof v==\"function\"?function(){kr.push(g);try{return v.apply(null,arguments)}finally{be||(kr.pop()===g||Xe(),at&&xt===1&&kr.length===0&&(xt=0,Ze+=1,Mr(Bo),typeof Fibers<\"u\"&&Fibers.rc()))}}:v})(p);return s}var xt=0,at=null,Co=0,kr=[],Ao={},Io={},Qu=0,bn=null,el=[];function tl(){return new Promise((n,s)=>{bn={resolve:n,reject:s}})}function rl(){var n=cr(65548),s=n+12;d()[n>>>2>>>0]=s,d()[n+4>>>2>>>0]=s+65536,s=kr[0];var p=Ao[s];return p===void 0&&(p=Qu++,Ao[s]=p,Io[p]=s),s=p,i()[n+8>>>2>>>0]=s,n}function nl(){var n=i()[at+8>>>2>>>0];return n=X[Io[n]],--Ze,n()}function ol(n){if(!be){if(xt===0){var s=!1,p=!1;n((g=0)=>{if(!be&&(Co=g,s=!0,p)){xt=2,Mr(()=>Do(at)),typeof Browser<\"u\"&&Browser.Gb.Tb&&Browser.Gb.resume(),g=!1;try{var v=nl()}catch(N){v=N,g=!0}var T=!1;if(!at){var M=bn;M&&(bn=null,(g?M.reject:M.resolve)(v),T=!0)}if(g&&!T)throw v}}),p=!0,s||(xt=1,at=rl(),typeof Browser<\"u\"&&Browser.Gb.Tb&&Browser.Gb.pause(),Mr(()=>ko(at)))}else xt===2?(xt=0,Mr(Wo),it(at),at=null,el.forEach(g=>he(g))):Xe(`invalid state: ${xt}`);return Co}}function al(n){return ol(s=>{n().then(s)})}le.Fb();for(var To=Array(256),Br=0;256>Br;++Br)To[Br]=String.fromCharCode(Br);ur=To,Qe=c.BindingError=class extends Error{constructor(n){super(n),this.name=\"BindingError\"}},c.InternalError=class extends Error{constructor(n){super(n),this.name=\"InternalError\"}},Object.assign(l.prototype,{get(n){return this.ub[n]},has(n){return this.ub[n]!==void 0},Hb(n){var s=this.Kb.pop()||this.ub.length;return this.ub[s]=n,s},Ib(n){this.ub[n]=void 0,this.Kb.push(n)}}),m.ub.push({value:void 0},{value:null},{value:!0},{value:!1}),m.Ab=m.ub.length,c.count_emval_handles=()=>{for(var n=0,s=m.Ab;s<m.ub.length;++s)m.ub[s]!==void 0&&++n;return n};var il=[Qt,Sr,Rt,tr,Ar,Tr,Or,Er,gt,yt,nr,or,_r,Ft,ar,ir,lo,co,ho,go,yo,bo,wo,vo],sl={ta:function(n,s,p){return al(async()=>{await c.Xb(n,s,p)})},b:function(n,s,p){throw n>>>=0,new ot(n).Fb(s>>>0,p>>>0),je=n,Cr++,je},fa:function(n){Eo(n>>>0,!k,1,!A,131072,!1),le.Pb()},D:function(n){n>>>=0,P?postMessage({cmd:\"cleanupThread\",thread:n}):((n=le.nb[n])||Xe(),le.Nb(n))},X:er,u:tr,la:Ar,T:Tr,V:Or,M:Er,ja:gt,ca:yt,ia:nr,F:or,U:_r,R:Ft,ka:ar,S:ir,I:function(n,s,p,g,v){n>>>=0,s>>>=0,p>>>=0,s=Fe(s);var T=s.indexOf(\"u\")!=-1;T&&(v=(1n<<64n)-1n),Le(n,{name:s,fromWireType:M=>M,toWireType:function(M,N){if(typeof N!=\"bigint\"&&typeof N!=\"number\")throw new TypeError(`Cannot convert \"${sr(N)}\" to ${this.name}`);if(N<g||N>v)throw new TypeError(`Passing a number \"${sr(N)}\" from JS side to C/C++ side to an argument of type \"${s}\", which is outside the valid range [${g}, ${v}]!`);return N},argPackAdvance:8,readValueFromPointer:lr(s,p,!T),Bb:null})},ra:function(n,s,p,g){n>>>=0,s=Fe(s>>>0),Le(n,{name:s,fromWireType:function(v){return!!v},toWireType:function(v,T){return T?p:g},argPackAdvance:8,readValueFromPointer:function(v){return this.fromWireType(o()[v>>>0])},Bb:null})},qa:function(n,s){n>>>=0,s=Fe(s>>>0),Le(n,{name:s,fromWireType:p=>{var g=w(p);return y(p),g},toWireType:(p,g)=>I(g),argPackAdvance:8,readValueFromPointer:U,Bb:null})},H:function(n,s,p){n>>>=0,p>>>=0,s=Fe(s>>>0),Le(n,{name:s,fromWireType:g=>g,toWireType:(g,v)=>v,argPackAdvance:8,readValueFromPointer:F(s,p),Bb:null})},w:function(n,s,p,g,v){if(n>>>=0,p>>>=0,s=Fe(s>>>0),v===-1&&(v=4294967295),v=N=>N,g===0){var T=32-8*p;v=N=>N<<T>>>T}var M=s.includes(\"unsigned\")?function(N,L){return L>>>0}:function(N,L){return L};Le(n,{name:s,fromWireType:v,toWireType:M,argPackAdvance:8,readValueFromPointer:lr(s,p,g!==0),Bb:null})},p:function(n,s,p){function g(T){var M=d()[T>>>2>>>0];return T=d()[T+4>>>2>>>0],new v(r().buffer,T,M)}n>>>=0;var v=[Int8Array,Uint8Array,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array,BigInt64Array,BigUint64Array][s];p=Fe(p>>>0),Le(n,{name:p,fromWireType:g,argPackAdvance:8,readValueFromPointer:g},{Ub:!0})},J:function(n,s){n>>>=0,s=Fe(s>>>0);var p=s===\"std::string\";Le(n,{name:s,fromWireType:function(g){var v=d()[g>>>2>>>0],T=g+4;if(p)for(var M=T,N=0;N<=v;++N){var L=T+N;if(N==v||o()[L>>>0]==0){if(M=Ve(M,L-M),j===void 0)var j=M;else j+=String.fromCharCode(0),j+=M;M=L+1}}else{for(j=Array(v),N=0;N<v;++N)j[N]=String.fromCharCode(o()[T+N>>>0]);j=j.join(\"\")}return it(g),j},toWireType:function(g,v){v instanceof ArrayBuffer&&(v=new Uint8Array(v));var T=typeof v==\"string\";if(!(T||v instanceof Uint8Array||v instanceof Uint8ClampedArray||v instanceof Int8Array))throw new Qe(\"Cannot pass non-string to std::string\");var M=p&&T?$t(v):v.length,N=cr(4+M+1),L=N+4;if(d()[N>>>2>>>0]=M,p&&T)rr(v,L,M+1);else if(T)for(T=0;T<M;++T){var j=v.charCodeAt(T);if(255<j)throw it(L),new Qe(\"String has UTF-16 code units that do not fit in 8 bits\");o()[L+T>>>0]=j}else for(T=0;T<M;++T)o()[L+T>>>0]=v[T];return g!==null&&g.push(it,N),N},argPackAdvance:8,readValueFromPointer:re,Bb(g){it(g)}})},B:function(n,s,p){if(n>>>=0,s>>>=0,p>>>=0,p=Fe(p),s===2)var g=ae,v=ne,T=me,M=()=>u(),N=1;else s===4&&(g=ye,v=_,T=se,M=()=>d(),N=2);Le(n,{name:p,fromWireType:L=>{for(var j=d()[L>>>2>>>0],Q=M(),ce,fe=L+4,E=0;E<=j;++E){var ie=L+4+E*s;(E==j||Q[ie>>>N]==0)&&(fe=g(fe,ie-fe),ce===void 0?ce=fe:(ce+=String.fromCharCode(0),ce+=fe),fe=ie+s)}return it(L),ce},toWireType:(L,j)=>{if(typeof j!=\"string\")throw new Qe(`Cannot pass non-string to C++ string type ${p}`);var Q=T(j),ce=cr(4+Q+s);return d()[ce>>>2]=Q>>N,v(j,ce+4,Q+s),L!==null&&L.push(it,ce),ce},argPackAdvance:8,readValueFromPointer:U,Bb(L){it(L)}})},sa:function(n,s){n>>>=0,s=Fe(s>>>0),Le(n,{Vb:!0,name:s,argPackAdvance:0,fromWireType:()=>{},toWireType:()=>{}})},oa:()=>!0,P:function(n,s){n>>>=0,n==s>>>0?setTimeout(()=>Mt()):P?postMessage({targetThread:n,cmd:\"checkMailbox\"}):(n=le.nb[n])&&n.postMessage({cmd:\"checkMailbox\"})},Y:function(n,s,p,g){s>>>=0,p/=2,pn.length=p,g=g>>>0>>>3;for(var v=0;v<p;v++)pn[v]=de[g+2*v]?de[g+2*v+1]:h()[g+2*v+1>>>0];return n=0>n?Ut[-n-1]:il[n],le.Sb=s,s=n.apply(null,pn),le.Sb=0,s},ea:et,na:function(n){O&&le.nb[n>>>0].ref()},v:function(n,s,p){s>>>=0,p>>>=0,n=w(n>>>0),s=Rr(s,\"emval::as\");var g=[],v=I(g);return d()[p>>>2>>>0]=v,s.toWireType(g,n)},l:function(n,s,p,g,v){p>>>=0,g>>>=0,v>>>=0,n=mn[n>>>0],s=w(s>>>0),p=fn(p);var T=[];return n=n(s,p,T,v),T.length&&(d()[g>>>2>>>0]=I(T)),n},c:y,L:function(n,s){return s>>>=0,n=w(n>>>0),s=w(s),n==s},q:function(n){return n>>>=0,n===0?I(oo()):(n=fn(n),I(oo()[n]))},k:function(n,s){s=Hu(n,s>>>0);var p=s.shift();n--;for(var g=[\"retType\"],v=[p],T=\"\",M=0;M<n;++M)T+=(M!==0?\", \":\"\")+\"arg\"+M,g.push(\"argType\"+M),v.push(s[M]);M=p.name+\"_$\"+s.map(j=>j.name).join(\"_\")+\"$\";var N=\"return function \"+ao(\"methodCaller_\"+M)+`(handle, name, destructors, args) {\n`,L=0;for(M=0;M<n;++M)N+=\"    var arg\"+M+\" = argType\"+M+\".readValueFromPointer(args\"+(L?\"+\"+L:\"\")+`);\n`,L+=s[M].argPackAdvance;for(N+=\"    var rv = handle[name](\"+T+`);\n`,M=0;M<n;++M)s[M].deleteObject&&(N+=\"    argType\"+M+\".deleteObject(arg\"+M+`);\n`);return p.Vb||(N+=`    return retType.toWireType(destructors, rv);\n`),g.push(N+`};\n`),n=qu(g).apply(null,v),Lu(n)},t:function(n,s){return s>>>=0,n=w(n>>>0),s=w(s),I(n[s])},h:function(n){n>>>=0,4<n&&(m.get(n).Mb+=1)},r:function(n,s,p,g){p>>>=0,g>>>=0,n=w(n>>>0);var v=io[s];return v||(v=Ku(s),io[s]=v),v(n,p,g)},x:function(){return I([])},m:function(n){n=w(n>>>0);for(var s=Array(n.length),p=0;p<n.length;p++)s[p]=n[p];return I(s)},e:function(n){return I(fn(n>>>0))},j:function(){return I({})},i:function(n){n>>>=0;for(var s=w(n);s.length;){var p=s.pop();s.pop()(p)}y(n)},g:function(n,s,p){s>>>=0,p>>>=0,n=w(n>>>0),s=w(s),p=w(p),n[s]=p},d:function(n,s){return s>>>=0,n=Rr(n>>>0,\"_emval_take_value\"),n=n.readValueFromPointer(s),I(n)},$:function(n,s){n=-9007199254740992>n||9007199254740992<n?NaN:Number(n),s>>>=0,n=new Date(1e3*n),i()[s>>>2>>>0]=n.getUTCSeconds(),i()[s+4>>>2>>>0]=n.getUTCMinutes(),i()[s+8>>>2>>>0]=n.getUTCHours(),i()[s+12>>>2>>>0]=n.getUTCDate(),i()[s+16>>>2>>>0]=n.getUTCMonth(),i()[s+20>>>2>>>0]=n.getUTCFullYear()-1900,i()[s+24>>>2>>>0]=n.getUTCDay(),n=(n.getTime()-Date.UTC(n.getUTCFullYear(),0,1,0,0,0,0))/864e5|0,i()[s+28>>>2>>>0]=n},aa:function(n,s){n=-9007199254740992>n||9007199254740992<n?NaN:Number(n),s>>>=0,n=new Date(1e3*n),i()[s>>>2>>>0]=n.getSeconds(),i()[s+4>>>2>>>0]=n.getMinutes(),i()[s+8>>>2>>>0]=n.getHours(),i()[s+12>>>2>>>0]=n.getDate(),i()[s+16>>>2>>>0]=n.getMonth(),i()[s+20>>>2>>>0]=n.getFullYear()-1900,i()[s+24>>>2>>>0]=n.getDay();var p=(jt(n.getFullYear())?so:uo)[n.getMonth()]+n.getDate()-1|0;i()[s+28>>>2>>>0]=p,i()[s+36>>>2>>>0]=-(60*n.getTimezoneOffset()),p=new Date(n.getFullYear(),6,1).getTimezoneOffset();var g=new Date(n.getFullYear(),0,1).getTimezoneOffset();n=(p!=g&&n.getTimezoneOffset()==Math.min(g,p))|0,i()[s+32>>>2>>>0]=n},ba:function(n){n>>>=0;var s=new Date(i()[n+20>>>2>>>0]+1900,i()[n+16>>>2>>>0],i()[n+12>>>2>>>0],i()[n+8>>>2>>>0],i()[n+4>>>2>>>0],i()[n>>>2>>>0],0),p=i()[n+32>>>2>>>0],g=s.getTimezoneOffset(),v=new Date(s.getFullYear(),6,1).getTimezoneOffset(),T=new Date(s.getFullYear(),0,1).getTimezoneOffset(),M=Math.min(T,v);return 0>p?i()[n+32>>>2>>>0]=+(v!=T&&M==g):0<p!=(M==g)&&(v=Math.max(T,v),s.setTime(s.getTime()+6e4*((0<p?M:v)-g))),i()[n+24>>>2>>>0]=s.getDay(),p=(jt(s.getFullYear())?so:uo)[s.getMonth()]+s.getDate()-1|0,i()[n+28>>>2>>>0]=p,i()[n>>>2>>>0]=s.getSeconds(),i()[n+4>>>2>>>0]=s.getMinutes(),i()[n+8>>>2>>>0]=s.getHours(),i()[n+12>>>2>>>0]=s.getDate(),i()[n+16>>>2>>>0]=s.getMonth(),i()[n+20>>>2>>>0]=s.getYear(),BigInt(s.getTime()/1e3)},Z:lo,_:co,O:function(n,s,p){function g(j){return(j=j.toTimeString().match(/\\(([A-Za-z ]+)\\)$/))?j[1]:\"GMT\"}n>>>=0,s>>>=0,p>>>=0;var v=new Date().getFullYear(),T=new Date(v,0,1),M=new Date(v,6,1);v=T.getTimezoneOffset();var N=M.getTimezoneOffset(),L=Math.max(v,N);d()[n>>>2>>>0]=60*L,i()[s>>>2>>>0]=+(v!=N),n=g(T),s=g(M),n=po(n),s=po(s),N<v?(d()[p>>>2>>>0]=n,d()[p+4>>>2>>>0]=s):(d()[p>>>2>>>0]=s,d()[p+4>>>2>>>0]=n)},o:()=>{Xe(\"\")},f:function(n,s,p){return n>>>=0,s=fo(s>>>0,p>>>0),Ut[n].apply(null,s)},K:function(n,s,p){return n>>>=0,s=fo(s>>>0,p>>>0),Ut[n].apply(null,s)},E:()=>{},G:()=>Date.now(),ma:()=>{throw Ze+=1,\"unwind\"},Q:function(){return 4294901760},n:()=>performance.timeOrigin+performance.now(),z:()=>O?(jo(),qt(Ho)).cpus().length:navigator.hardwareConcurrency,N:function(n){n>>>=0;var s=o().length;if(n<=s||4294901760<n)return!1;for(var p=1;4>=p;p*=2){var g=s*(1+.2/p);g=Math.min(g,n+100663296);var v=Math;g=Math.max(n,g);e:{v=(v.min.call(v,4294901760,g+(65536-g%65536)%65536)-ve.buffer.byteLength+65535)/65536;try{ve.grow(v),Ce();var T=1;break e}catch{}T=void 0}if(T)return!0}return!1},ga:ho,ha:go,W:Gt,y:yo,C:bo,da:wo,A:vo,a:ve||c.wasmMemory,pa:So,s:function(n,s,p,g){return So(n>>>0,s>>>0,p>>>0,g>>>0)}},X=function(){var n={a:sl};return nt++,xr(n,function(s){var p=s.module;X=s.instance.exports,X=Zu(),X=ul(),le.Qb.push(X.$a),He.unshift(X.ua),Te=p,Kt()}).catch(b),{}}();c._OrtInit=(n,s)=>(c._OrtInit=X.va)(n,s),c._OrtGetLastError=(n,s)=>(c._OrtGetLastError=X.wa)(n,s),c._OrtCreateSessionOptions=(n,s,p,g,v,T,M,N,L,j)=>(c._OrtCreateSessionOptions=X.xa)(n,s,p,g,v,T,M,N,L,j),c._OrtAppendExecutionProvider=(n,s)=>(c._OrtAppendExecutionProvider=X.ya)(n,s),c._OrtAddFreeDimensionOverride=(n,s,p)=>(c._OrtAddFreeDimensionOverride=X.za)(n,s,p),c._OrtAddSessionConfigEntry=(n,s,p)=>(c._OrtAddSessionConfigEntry=X.Aa)(n,s,p),c._OrtReleaseSessionOptions=n=>(c._OrtReleaseSessionOptions=X.Ba)(n),c._OrtCreateSession=(n,s,p)=>(c._OrtCreateSession=X.Ca)(n,s,p),c._OrtReleaseSession=n=>(c._OrtReleaseSession=X.Da)(n),c._OrtGetInputOutputCount=(n,s,p)=>(c._OrtGetInputOutputCount=X.Ea)(n,s,p),c._OrtGetInputName=(n,s)=>(c._OrtGetInputName=X.Fa)(n,s),c._OrtGetOutputName=(n,s)=>(c._OrtGetOutputName=X.Ga)(n,s),c._OrtFree=n=>(c._OrtFree=X.Ha)(n),c._OrtCreateTensor=(n,s,p,g,v,T)=>(c._OrtCreateTensor=X.Ia)(n,s,p,g,v,T),c._OrtGetTensorData=(n,s,p,g,v)=>(c._OrtGetTensorData=X.Ja)(n,s,p,g,v),c._OrtReleaseTensor=n=>(c._OrtReleaseTensor=X.Ka)(n),c._OrtCreateRunOptions=(n,s,p,g)=>(c._OrtCreateRunOptions=X.La)(n,s,p,g),c._OrtAddRunConfigEntry=(n,s,p)=>(c._OrtAddRunConfigEntry=X.Ma)(n,s,p),c._OrtReleaseRunOptions=n=>(c._OrtReleaseRunOptions=X.Na)(n),c._OrtCreateBinding=n=>(c._OrtCreateBinding=X.Oa)(n),c._OrtBindInput=(n,s,p)=>(c._OrtBindInput=X.Pa)(n,s,p),c._OrtBindOutput=(n,s,p,g)=>(c._OrtBindOutput=X.Qa)(n,s,p,g),c._OrtClearBoundOutputs=n=>(c._OrtClearBoundOutputs=X.Ra)(n),c._OrtReleaseBinding=n=>(c._OrtReleaseBinding=X.Sa)(n),c._OrtRunWithBinding=(n,s,p,g,v)=>(c._OrtRunWithBinding=X.Ta)(n,s,p,g,v),c._OrtRun=(n,s,p,g,v,T,M,N)=>(c._OrtRun=X.Ua)(n,s,p,g,v,T,M,N),c._OrtEndProfiling=n=>(c._OrtEndProfiling=X.Va)(n),c._JsepOutput=(n,s,p)=>(c._JsepOutput=X.Wa)(n,s,p),c._JsepGetNodeName=n=>(c._JsepGetNodeName=X.Xa)(n);var Dr=c._pthread_self=()=>(Dr=c._pthread_self=X.Ya)(),cr=c._malloc=n=>(cr=c._malloc=X.Za)(n),it=c._free=n=>(it=c._free=X._a)(n);c.__emscripten_tls_init=()=>(c.__emscripten_tls_init=X.$a)();var Oo=n=>(Oo=X.ab)(n);c.__embind_initialize_bindings=()=>(c.__embind_initialize_bindings=X.bb)();var Eo=c.__emscripten_thread_init=(n,s,p,g,v,T)=>(Eo=c.__emscripten_thread_init=X.db)(n,s,p,g,v,T);c.__emscripten_thread_crashed=()=>(c.__emscripten_thread_crashed=X.eb)();var _o=(n,s,p,g)=>(_o=X.fb)(n,s,p,g),wn=n=>(wn=X.gb)(n),vn=c.__emscripten_thread_exit=n=>(vn=c.__emscripten_thread_exit=X.hb)(n),Po=c.__emscripten_check_mailbox=()=>(Po=c.__emscripten_check_mailbox=X.ib)(),Ro=(n,s)=>(Ro=X.jb)(n,s),$n=()=>($n=X.kb)(),Wr=n=>(Wr=X.lb)(n),xn=n=>(xn=X.mb)(n),Mo=c.dynCall_ii=(n,s)=>(Mo=c.dynCall_ii=X.ob)(n,s),ko=n=>(ko=X.pb)(n),Bo=()=>(Bo=X.qb)(),Do=n=>(Do=X.rb)(n),Wo=()=>(Wo=X.sb)();c.___start_em_js=1452163,c.___stop_em_js=1452324;function ul(){var n=X;n=Object.assign({},n);var s=g=>()=>g()>>>0,p=g=>v=>g(v)>>>0;return n.__errno_location=s(n.__errno_location),n.Ya=s(n.Ya),n.Za=p(n.Za),n.ab=p(n.ab),n.kb=s(n.kb),n.mb=p(n.mb),n}c.wasmMemory=ve,c.stackAlloc=xn,c.stackSave=$n,c.stackRestore=Wr,c.keepRuntimeAlive=()=>0<Ze,c.UTF8ToString=Ve,c.stringToUTF8=rr,c.lengthBytesUTF8=$t,c.ExitStatus=_t,c.PThread=le;var zr;Ot=function n(){zr||zo(),zr||(Ot=n)};function zo(){0<nt||(P?(C(c),P||ht(He),startWorker(c)):(ht(vt),0<nt||zr||(zr=!0,c.calledRun=!0,be||(P||ht(He),C(c),P||ht(zt)))))}return zo(),t.ready}})();typeof Ko==\"object\"&&typeof En==\"object\"?En.exports=qo:typeof define==\"function\"&&define.amd&&define([],()=>qo)});var Jo=dr((rp,gl)=>{gl.exports='\"use strict\";var Module={},ENVIRONMENT_IS_NODE=typeof process==\"object\"&&typeof process.versions==\"object\"&&typeof process.versions.node==\"string\";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require(\"worker_threads\"),parentPort=nodeWorkerThreads.parentPort;parentPort.on(\"message\",e=>onmessage({data:e}));var fs=require(\"fs\");Object.assign(global,{self:global,require,Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:e=>(0,eval)(fs.readFileSync(e,\"utf8\")+\"//# sourceURL=\"+e),postMessage:e=>parentPort.postMessage(e),performance:global.performance||{now:Date.now}})}var initializedJS=!1;function threadPrintErr(){var e=Array.prototype.slice.call(arguments).join(\" \");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,e+`\\n`);return}console.error(e)}function threadAlert(){var e=Array.prototype.slice.call(arguments).join(\" \");postMessage({cmd:\"alert\",text:e,threadId:Module._pthread_self()})}var err=threadPrintErr;self.alert=threadAlert,Module.instantiateWasm=(e,t)=>{var a=Module.wasmModule;Module.wasmModule=null;var r=new WebAssembly.Instance(a,e);return t(r)},self.onunhandledrejection=e=>{throw e.reason??e};function handleMessage(e){try{if(e.data.cmd===\"load\"){let a=[];self.onmessage=r=>a.push(r),self.startWorker=r=>{Module=r,postMessage({cmd:\"loaded\"});for(let s of a)handleMessage(s);self.onmessage=handleMessage},Module.wasmModule=e.data.wasmModule;for(const r of e.data.handlers)Module[r]=(...s)=>{postMessage({cmd:\"callHandler\",handler:r,args:s})};if(Module.wasmMemory=e.data.wasmMemory,Module.buffer=Module.wasmMemory.buffer,Module.ENVIRONMENT_IS_PTHREAD=!0,typeof e.data.urlOrBlob==\"string\")importScripts(e.data.urlOrBlob);else{var t=URL.createObjectURL(e.data.urlOrBlob);importScripts(t),URL.revokeObjectURL(t)}ortWasmThreaded(Module)}else if(e.data.cmd===\"run\"){Module.__emscripten_thread_init(e.data.pthread_ptr,0,0,1),Module.__emscripten_thread_mailbox_await(e.data.pthread_ptr),Module.establishStackSpace(),Module.PThread.receiveObjectTransfer(e.data),Module.PThread.threadInitTLS(),initializedJS||(initializedJS=!0);try{Module.invokeEntryPoint(e.data.start_routine,e.data.arg)}catch(a){if(a!=\"unwind\")throw a}}else e.data.cmd===\"cancel\"?Module._pthread_self()&&Module.__emscripten_thread_exit(-1):e.data.target===\"setimmediate\"||(e.data.cmd===\"checkMailbox\"?initializedJS&&Module.checkMailbox():e.data.cmd&&(err(\"worker.js received unknown command \"+e.data.cmd),err(e.data)))}catch(a){throw Module.__emscripten_thread_crashed&&Module.__emscripten_thread_crashed(),a}}self.onmessage=handleMessage;\\n'});var Rn,fr,mr,Nr,hr,ra,Mn,We=K(()=>{\"use strict\";Rn=e=>{switch(e){case\"int8\":return 3;case\"uint8\":return 2;case\"bool\":return 9;case\"int16\":return 5;case\"uint16\":return 4;case\"int32\":return 6;case\"uint32\":return 12;case\"float16\":return 10;case\"float32\":return 1;case\"float64\":return 11;case\"string\":return 8;case\"int64\":return 7;case\"uint64\":return 13;default:throw new Error(`unsupported data type: ${e}`)}},fr=e=>{switch(e){case 3:return\"int8\";case 2:return\"uint8\";case 9:return\"bool\";case 5:return\"int16\";case 4:return\"uint16\";case 6:return\"int32\";case 12:return\"uint32\";case 10:return\"float16\";case 1:return\"float32\";case 11:return\"float64\";case 8:return\"string\";case 7:return\"int64\";case 13:return\"uint64\";default:throw new Error(`unsupported data type: ${e}`)}},mr=e=>[void 0,4,1,1,2,2,4,8,void 0,1,2,8,4,8,void 0,void 0,void 0][e],Nr=e=>{switch(e){case\"float16\":return Uint16Array;case\"float32\":return Float32Array;case\"uint8\":return Uint8Array;case\"int8\":return Int8Array;case\"uint16\":return Uint16Array;case\"int16\":return Int16Array;case\"int32\":return Int32Array;case\"bool\":return Uint8Array;case\"float64\":return Float64Array;case\"uint32\":return Uint32Array;case\"int64\":return BigInt64Array;case\"uint64\":return BigUint64Array;default:throw new Error(`unsupported type: ${e}`)}},hr=e=>{switch(e){case\"verbose\":return 0;case\"info\":return 1;case\"warning\":return 2;case\"error\":return 3;case\"fatal\":return 4;default:throw new Error(`unsupported logging level: ${e}`)}},ra=e=>e===\"float32\"||e===\"int32\"||e===\"int64\"||e===\"bool\"||e===\"float16\"||e===\"uint32\",Mn=e=>{switch(e){case\"none\":return 0;case\"cpu\":return 1;case\"cpu-pinned\":return 2;case\"texture\":return 3;case\"gpu-buffer\":return 4;default:throw new Error(`unsupported data location: ${e}`)}}});var Al,Il,na,oa,aa,Tl,Ee,St=K(()=>{\"use strict\";We();Al=[\"V\",\"I\",\"W\",\"E\",\"F\"],Il=(e,t)=>{console.log(`[${Al[e]},${new Date().toISOString()}]${t}`)},aa=(e,t)=>{na=e,oa=t},Tl=(e,t)=>{let r=hr(e),o=hr(na);r>=o&&Il(r,typeof t==\"function\"?t():t)},Ee=(...e)=>{oa&&Tl(...e)}});var ia,sa=K(()=>{\"use strict\";We();ia=(e,t)=>new(Nr(t))(e)});var ua=K(()=>{\"use strict\"});var Gr,Ol,la,Bn,kn,ca,da=K(()=>{\"use strict\";St();ua();Gr=e=>Math.ceil(e/16)*16,Ol=1,la=()=>Ol++,Bn=async(e,t,r,o)=>{let a=Gr(r),u=e.device.createBuffer({size:a,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ});try{let i=e.getCommandEncoder();e.endComputePass(),i.copyBufferToBuffer(t,0,u,0,a),e.flush(),await u.mapAsync(GPUMapMode.READ);let d=u.getMappedRange();if(o){let f=o();return f.set(new Uint8Array(d,0,r)),f}else return new Uint8Array(d.slice(0,r))}finally{u.destroy()}},kn=class{constructor(t){this.backend=t;this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.buffersForUploadingPending=[],this.buffersPending=[],this.externalBuffers=new Map}upload(t,r){let o=r.buffer,a=r.byteOffset,u=r.byteLength,i=Gr(u),d=this.storageCache.get(t);if(!d)throw new Error(\"gpu data for uploading does not exist\");if(d.originalSize!==u)throw new Error(`inconsistent data size. gpu data size=${d.originalSize}, data size=${u}`);let f=this.backend.device.createBuffer({mappedAtCreation:!0,size:i,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC}),h=f.getMappedRange();new Uint8Array(h).set(new Uint8Array(o,a,u)),f.unmap();let c=this.backend.getCommandEncoder();this.backend.endComputePass(),c.copyBufferToBuffer(f,0,d.gpuData.buffer,0,i),Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.upload(id=${t})`),this.buffersForUploadingPending.push(f)}memcpy(t,r){let o=this.storageCache.get(t);if(!o)throw new Error(\"source gpu data for memcpy does not exist\");let a=this.storageCache.get(r);if(!a)throw new Error(\"destination gpu data for memcpy does not exist\");if(o.originalSize!==a.originalSize)throw new Error(\"inconsistent source and destination gpu data size\");let u=Gr(o.originalSize),i=this.backend.getCommandEncoder();this.backend.endComputePass(),i.copyBufferToBuffer(o.gpuData.buffer,0,a.gpuData.buffer,0,u)}registerExternalBuffer(t,r,o){let a;if(o){if(a=this.externalBuffers.get(o),a===void 0)throw new Error(\"previous buffer is not registered\");if(t===o)return Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${a}, buffer is the same, skip.`),a;this.externalBuffers.delete(o)}else a=la();return this.storageCache.set(a,{gpuData:{id:a,type:0,buffer:t},originalSize:r}),this.externalBuffers.set(t,a),Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${r}) => id=${a}, registered.`),a}unregisterExternalBuffer(t){let r=this.externalBuffers.get(t);r!==void 0&&(this.storageCache.delete(r),this.externalBuffers.delete(t),Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${r}`))}create(t,r=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){let o=Gr(t),a,u=(r&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE,i=(r&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM;if(u||i){let f=u?this.freeBuffers:this.freeUniformBuffers,h=f.get(o);h||(h=[],f.set(o,h)),h.length>0?a=h.pop():a=this.backend.device.createBuffer({size:o,usage:r})}else a=this.backend.device.createBuffer({size:o,usage:r});let d={id:la(),type:0,buffer:a};return this.storageCache.set(d.id,{gpuData:d,originalSize:t}),Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.create(size=${t}) => id=${d.id}`),d}get(t){return this.storageCache.get(t)?.gpuData}release(t){let r=this.storageCache.get(t);if(!r)throw new Error(\"releasing data does not exist\");return Ee(\"verbose\",()=>`[WebGPU] GpuDataManager.release(id=${t}), gpuDataId=${r.gpuData.id}`),this.storageCache.delete(t),this.buffersPending.push(r.gpuData.buffer),r.originalSize}async download(t,r){let o=this.storageCache.get(t);if(!o)throw new Error(\"data does not exist\");await Bn(this.backend,o.gpuData.buffer,o.originalSize,r)}refreshPendingBuffers(){for(let t of this.buffersForUploadingPending)t.destroy();this.buffersForUploadingPending=[];for(let t of this.buffersPending)(t.usage&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE?this.freeBuffers.get(t.size).push(t):(t.usage&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM?this.freeUniformBuffers.get(t.size).push(t):t.destroy();this.buffersPending=[]}dispose(){this.freeBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.freeUniformBuffers.forEach(t=>{t.forEach(r=>{r.destroy()})}),this.storageCache.forEach(t=>{t.gpuData.buffer.destroy()}),this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map}},ca=(...e)=>new kn(...e)});var Dn,ue,Me=K(()=>{\"use strict\";Dn=class{constructor(t){Object.assign(this,t)}get cacheKey(){return this._cacheKey||(this._cacheKey=Object.getOwnPropertyNames(this).sort().map(t=>`${this[t]}`).join(\";\")),this._cacheKey}},ue=e=>new Dn(e)});var Wn,st,z,Bt,Fr,Lr,Hr,ge=K(()=>{\"use strict\";Wn=class{static calcMatMulShape(t,r){return t[1]!==r[0]?void 0:[t[0],r[1]]}},st=class{static calcShape(t,r,o=!1){let a=t.length,u=r.length;if(a===0)return r;if(u===0)return t;let i=Math.max(t.length,r.length),d=new Array(i);if(o){if(a<2||u<2)return;let f=Wn.calcMatMulShape([t[a-2],t[a-1]],[r[u-2],r[u-1]]);if(f===void 0)return;[d[i-2],d[i-1]]=f}for(let f=o?3:1;f<=i;f++){let h=a-f<0?1:t[a-f],c=u-f<0?1:r[u-f];if(h!==c&&h>1&&c>1)return;d[i-f]=Math.max(h,c)}return d}static isValidBroadcast(t,r){let o=t.length,a=r.length;if(o>a)return!1;for(let u=1;u<=o;u++)if(t[o-u]!==1&&t[o-u]!==r[a-u])return!1;return!0}},z=class e{static size(t){return e.getSizeFromDimensionRange(t,0,t.length)}static sizeFromDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeFromDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,r,t.length)}static sizeToDimension(t,r){if(r<0||r>t.length)throw new Error(`invalid dimension of ${r} for sizeToDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,0,r)}static getSizeFromDimensionRange(t,r,o){let a=1;for(let u=r;u<o;u++){if(t[u]<0)throw new Error(\"cannot get valid size from specified dimension range. Most likely the range contains negative values in them.\");a*=t[u]}return a}static computeStrides(t){let r=t.length;if(r===0)return[];if(r===1)return[1];let o=new Array(r);o[r-1]=1,o[r-2]=t[r-1];for(let a=r-3;a>=0;--a)o[a]=o[a+1]*t[a+1];return o}static normalizeAxis(t,r){if(t<-r&&t>=r)throw new Error(\"unsupported axis for this operation.\");return t<0?t+r:t}static normalizeAxes(t,r){return t.map(o=>this.normalizeAxis(o,r??t.length))}static sortBasedOnPerm(t,r){return r?r.map(o=>t[o]):t.slice().reverse()}static padShape(t,r){let o=t.length;return t.map((a,u)=>a+r[u]+r[u+o])}static areEqual(t,r){return t.length!==r.length?!1:t.every((o,a)=>o===r[a])}},Bt=class e{static adjustPoolAttributes(t,r,o,a,u,i){if(!t&&o.length!==r.length-2)throw new Error(\"length of specified kernel shapes should be 2 less than length of input dimensions\");if(t)for(let d=0;d<r.length-2;d++)d>=o.length?o.push(r[d+2]):o[d]=r[d+2];for(let d=0;d<o.length;d++)if(d<a.length){if(a[d]<0)throw new Error(\"strides should be greater than or equal to 1\")}else a.push(1);for(let d=0;d<o.length;d++)if(d<u.length){if(u[d]<0)throw new Error(\"dilations should be greater than or equal to 1\")}else u.push(1);for(let d=0;d<o.length*2;d++)if(d<i.length){if(i[d]<0)throw new Error(\"pad should be greater than or equal to 1\")}else i.push(0);for(let d=0;d<o.length;d++){if(o[d]<=0)throw new Error(\"kernel shapes need to be greater than 0\");if(i[d]>=o[d]||i[d+o.length]>=o[d])throw new Error(\"pads should be smaller than kernel\")}}static adjustPadsBasedOnAutoPad(t,r,o,a,u,i,d){if(d){if(u.length!==2*(t.length-2))throw new Error(\"length of pads should be twice the length of data dimensions\");if(r.length!==t.length-2)throw new Error(\"length of strides should be the length of data dimensions\");if(a.length!==t.length-2)throw new Error(\"length of kernel shapes should be the length of data dimensions\");for(let f=0;f<t.length-2;f++)e.adjustPadAndReturnShape(t[f+(i?1:2)],r[f],o[f],a[f],u,f,f+t.length-2,d)}}static computePoolOutputShape(t,r,o,a,u,i,d){if(r.length<=0)throw new Error(\"input shape must be of size greater than 0\");let f=[r[0],r[1]];return e.computeShapeHelper(t,r,f,o,a,u,i,d),f}static computeConvOutputShape(t,r,o,a,u,i,d){if(t.length<=0||r.length<=0)throw new Error(\"invalid input tensor dims or invalid filter tensor dims\");let f=[t[0],r[0]];return e.computeShapeHelper(!1,t,f,o,a,u,i,d),f}static computeShapeHelper(t,r,o,a,u,i,d,f){if(t)for(let h=0;h<r.length-2;h++)o.push(1);else for(let h=0;h<r.length-2;h++)o.push(e.adjustPadAndReturnShape(r[h+2],a[h],u[h],i[h],d,h,h+r.length-2,f))}static adjustPadAndReturnShape(t,r,o,a,u,i,d,f){let h=o*(a-1)+1;if(f&&f!==\"NOTSET\")switch(f){case\"VALID\":return u[i]=0,u[d]=0,Math.floor((t-h)/r+1);case\"SAME_LOWER\":case\"SAME_UPPER\":if(o!==1)throw new Error(\"Dilation not supported for SAME_UPPER or SAME_LOWER\");{let C=((t+r-1)/r-1)*r+a-t;return u[i]=Math.floor(f===\"SAME_LOWER\"?(C+1)/2:C/2),u[d]=C-u[i],Math.floor((t+C-a)/r+1)}default:throw new Error(\"Unsupported AutoPad type\")}else return Math.floor((t+u[i]+u[d]-h)/r+1)}},Fr=class{static getShapeOfGemmResult(t,r,o,a,u){if(t.length!==2||o.length!==2)throw new Error(\"shape need to be of size 2\");let i,d,f;r?(i=t[1],d=t[0]):(i=t[0],d=t[1]);let h=-1;if(a?(f=o[0],h=1):(f=o[1],h=0),o[h]!==d)throw new Error(\"dimension mismatch\");if(i<=0||f<=0||d<=0)throw new Error(\"invalid shape specified\");if(u&&!st.isValidBroadcast(u,[i,f]))throw new Error(\"gemm: invalid bias shape for broadcast\");return[i,f,d]}},Lr=-34028234663852886e22,Hr=34028234663852886e22});var El,pa,ke,ut,bt,tt,Dt,Ct,fa,H,Y,zn,ma,Vn,wt,$e=K(()=>{\"use strict\";We();ge();El=64,pa=(e,t)=>{if(t===3)throw new Error(\"vec3 has same alignment as vec4, use vec4 instead\");switch(e){case 10:return t>1?`vec${t}<f16>`:\"f16\";case 1:return t>1?`vec${t}<f32>`:\"f32\";case 6:return t>1?`vec${t}<i32>`:\"i32\";case 12:return t>1?`vec${t}<u32>`:\"u32\";case 7:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"i32\"];case 13:if(t>1)throw new Error(\"currently not supported vecX of uint64 yet\");return[\"vec2<u32>\",\"u32\"];case 9:if(t!==4)throw new Error(\"bool must be vec4\");return[\"u32\",\"vec4<bool>\"];default:throw new Error(`Unknown data type: ${e}`)}},ke=(e,t=1)=>{let r=pa(e,t);return typeof r==\"string\"?r:r[0]},ut=e=>e.length===0?[]:[{type:\"uint32\",data:e},{type:\"uint32\",data:z.computeStrides(e)}],bt=e=>e%4===0?4:e%2===0?2:1,tt=(e=\"f32\",t,r=\"0\")=>!t||t===1?`${e}(${r})`:`vec${t}<${e}>(${r})`,Dt=(e,t,r)=>e===\"f32\"?r:t===1?`f32(${r})`:`vec${t}f(${r})`,Ct=(e,t)=>t===4?`(${e}.x + ${e}.y + ${e}.z + ${e}.w)`:t===2?`(${e}.x + ${e}.y)`:t===3?`(${e}.x + ${e}.y + ${e}.z)`:e,fa=(e,t,r,o,a)=>{let u=typeof r==\"number\",i=u?r:r.length,d=[...new Array(i).keys()],f=i<2?\"u32\":i<=4?`vec${i}<u32>`:`array<u32, ${i}>`,h=pa(t,a),c=typeof h==\"string\"?h:h[1],C=typeof h==\"string\"?h:h[0],b={indices:f,value:c,storage:C,tensor:t},$=G=>typeof G==\"string\"?G:`${G}u`,S={offsetToIndices:!1,indicesToOffset:!1,broadcastedIndicesToOffset:!1,set:!1,setByIndices:!1,get:!1,getByIndices:!1},x=u?\"uniforms.\":\"\",A=`${x}${e}_shape`,k=`${x}${e}_strides`,O=\"\";for(let G=0;G<i-1;G++)O+=`\n    let dim${G} = current / ${k}[${G}];\n    let rest${G} = current % ${k}[${G}];\n    indices[${G}] = dim${G};\n    current = rest${G};\n    `;O+=`indices[${i-1}] = current;`;let P=i<2?\"\":`\n  fn o2i_${e}(offset: u32) -> ${b.indices} {\n    var indices: ${b.indices};\n    var current = offset;\n    ${O}\n    return indices;\n  }`,R=G=>(S.offsetToIndices=!0,i<2?G:`o2i_${e}(${G})`),V=[];if(i>=2)for(let G=i-1;G>=0;G--)V.push(`${k}[${G}] * (indices[${G}])`);let B=i<2?\"\":`\n  fn i2o_${e}(indices: ${b.indices}) -> u32 {\n    return ${V.join(\"+\")};\n  }`,W=G=>(S.indicesToOffset=!0,i<2?G:`i2o_${e}(${G})`),q=(...G)=>i===0?\"0u\":`${b.indices}(${G.map($).join(\",\")})`,ee=(G,pe)=>i<2?`${G}`:`${G}[${pe}]`,oe=(G,pe,de)=>i<2?`${G}=${de};`:`${G}[${pe}]=${de};`,D={},te=(G,pe)=>{S.broadcastedIndicesToOffset=!0;let de=`${pe.name}broadcastedIndicesTo${e}Offset`;if(de in D)return`${de}(${G})`;let Ne=[];for(let Ge=i-1;Ge>=0;Ge--){let Ce=pe.indicesGet(\"outputIndices\",Ge+pe.rank-i);Ne.push(`${ee(k,Ge)} * (${Ce} % ${ee(A,Ge)})`)}return D[de]=`fn ${de}(outputIndices: ${pe.type.indices}) -> u32 {\n             return ${Ne.length>0?Ne.join(\"+\"):\"0u\"};\n           }`,`${de}(${G})`},Ie=(G,pe)=>(()=>{if(b.storage===b.value)return`${e}[${G}]=${pe};`;if(b.storage===\"vec2<u32>\"&&b.value===\"i32\")return`${e}[${G}]=vec2<u32>(u32(${pe}), select(0u, 0xFFFFFFFFu, ${pe} < 0));`;if(b.storage===\"vec2<u32>\"&&b.value===\"u32\")return`${e}[${G}]=vec2<u32>(u32(${pe}), 0u);`;if(b.storage===\"u32\"&&b.value===\"vec4<bool>\")return`${e}[${G}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${pe}));`;throw new Error(`not supported combination of storage type ${b.storage} and value type ${b.value} yet`)})(),Z=G=>(()=>{if(b.storage===b.value)return`${e}[${G}]`;if(b.storage===\"vec2<u32>\"&&b.value===\"i32\")return`i32(${e}[${G}].x)`;if(b.storage===\"vec2<u32>\"&&b.value===\"u32\")return`u32(${e}[${G}].x)`;if(b.storage===\"u32\"&&b.value===\"vec4<bool>\")return`vec4<bool>(bool(${e}[${G}] & 0xFFu), bool(${e}[${G}] & 0xFF00u), bool(${e}[${G}] & 0xFF0000u), bool(${e}[${G}] & 0xFF000000u))`;throw new Error(`not supported combination of storage type ${b.storage} and value type ${b.value} yet`)})(),ve=i<2?\"\":`\n  fn get_${e}ByIndices(indices: ${b.indices}) -> ${c} {\n    return ${Z(`i2o_${e}(indices)`)};\n  }`,Te=i<2?\"\":(()=>{let G=d.map(de=>`d${de}: u32`).join(\", \"),pe=d.map(de=>`d${de}`).join(\", \");return`\n  fn get_${e}(${G}) -> ${c} {\n    return get_${e}ByIndices(${q(pe)});\n  }`})(),be=(...G)=>{if(G.length!==i)throw new Error(`indices length must be ${i}`);let pe=G.map($).join(\",\");return i===0?Z(\"0u\"):i===1?Z(pe[0]):(S.get=!0,S.getByIndices=!0,S.indicesToOffset=!0,`get_${e}(${pe})`)},Be=G=>i<2?Z(G):(S.getByIndices=!0,S.indicesToOffset=!0,`get_${e}ByIndices(${G})`),Se=i<2?\"\":`\n  fn set_${e}ByIndices(indices: ${b.indices}, value: ${c}) {\n    ${Ie(`i2o_${e}(indices)`,\"value\")}\n  }`,Ue=i<2?\"\":(()=>{let G=d.map(de=>`d${de}: u32`).join(\", \"),pe=d.map(de=>`d${de}`).join(\", \");return`\n  fn set_${e}(${G}, value: ${c}) {\n    set_${e}ByIndices(${q(pe)}, value);\n  }`})();return{impl:()=>{let G=[];return u||(G.push(`const ${A} = ${b.indices}(${r.join(\",\")});`),G.push(`const ${k} = ${b.indices}(${z.computeStrides(r).join(\",\")});`)),S.offsetToIndices&&G.push(P),S.indicesToOffset&&G.push(B),S.broadcastedIndicesToOffset&&Object.values(D).forEach(pe=>G.push(pe)),S.set&&G.push(Ue),S.setByIndices&&G.push(Se),S.get&&G.push(Te),S.getByIndices&&G.push(ve),G.join(`\n`)},type:b,offsetToIndices:R,indicesToOffset:W,broadcastedIndicesToOffset:te,indices:q,indicesGet:ee,indicesSet:oe,set:(...G)=>{if(G.length!==i+1)throw new Error(`indices length must be ${i}`);let pe=G[i];if(typeof pe!=\"string\")throw new Error(\"value must be string\");let de=G.slice(0,i).map($).join(\",\");return i===0?Ie(\"0u\",pe):i===1?Ie(de[0],pe):(S.set=!0,S.setByIndices=!0,S.indicesToOffset=!0,`set_${e}(${de}, ${pe})`)},setByOffset:Ie,setByIndices:(G,pe)=>i<2?Ie(G,pe):(S.setByIndices=!0,S.indicesToOffset=!0,`set_${e}ByIndices(${G}, ${pe});`),get:be,getByOffset:Z,getByIndices:Be,usage:o?\"input\":\"output\",name:e,strides:k,shape:A,rank:i}},H=(e,t,r,o=1)=>fa(e,t,r,!0,o),Y=(e,t,r,o=1)=>fa(e,t,r,!1,o),zn=class{constructor(t){this.normalizedDispatchGroup=t;this.indicesHelpers=[];this.uniforms=[];this.variableIndex=0}guardAgainstOutOfBoundsWorkgroupSizes(t){return`if (global_idx >= ${typeof t==\"number\"?`${t}u`:t}) { return; }`}mainStart(t=El){let r=typeof t==\"number\"?t:t[0],o=typeof t==\"number\"?1:t[1],a=typeof t==\"number\"?1:t[2],u=this.normalizedDispatchGroup[1]===1&&this.normalizedDispatchGroup[2]===1,i=u?`@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(local_invocation_id) local_id : vec3<u32>`:`@builtin(local_invocation_index) local_index : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>`,d=u?\"let global_idx = global_id.x;\":`let global_idx = (workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n          workgroup_id.y * num_workgroups[0] + workgroup_id.x) * ${r*o*a}u + local_index;`;return`@compute @workgroup_size(${r}, ${o}, ${a})\n  fn main(${i}) {\n    ${d}\n  `}declareVariable(t,r){this.indicesHelpers.push(t),t.rank!==0&&(t.shape.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.shape.replace(\"uniforms.\",\"\"),type:t.type.indices}),t.strides.startsWith(\"uniforms.\")&&this.uniforms.push({name:t.strides.replace(\"uniforms.\",\"\"),type:t.type.indices}));let o=t.usage===\"input\"?\"read\":\"read_write\",a=t.type.storage;return`@group(0) @binding(${r}) var<storage, ${o}> ${t.name}: array<${a}>;`}declareVariables(...t){return t.map(r=>this.declareVariable(r,this.variableIndex++)).join(`\n`)}registerUniform(t,r){return this.uniforms.push({name:t,type:r}),this}uniformDeclaration(){if(this.uniforms.length===0)return\"\";let t=[];for(let{name:r,type:o}of this.uniforms)t.push(`${r}:${o}`);return`\n      struct Uniforms { ${t.join(\", \")} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`}get additionalImplementations(){return this.uniformDeclaration()+this.indicesHelpers.map(t=>t.impl()).join(`\n`)}},ma=e=>new zn(e),Vn=(e,t)=>{let r=e.length,o=[];for(let a=0;a<r;a++){let u=r-1-a,i=e[u]||1;(t[t.length-1-a]||1)>1&&i===1&&o.unshift(u)}return o},wt=e=>e<=4});var _l,ha,Pl,Rl,At,ga,ya,gr=K(()=>{\"use strict\";ge();Me();$e();_l=e=>{if(!e||e.length!==1)throw new Error(\"Transpose requires 1 input.\")},ha=(e,t)=>t&&t.length!==e?[...new Array(e).keys()].reverse():t,Pl=(e,t)=>z.sortBasedOnPerm(e,ha(e.length,t)),Rl=(e,t,r,o)=>{let a=[];a.push(`fn perm(i: ${o.type.indices}) -> ${r.type.indices} {\n    var a: ${r.type.indices};`);for(let u=0;u<t;++u)a.push(r.indicesSet(\"a\",e[u],`i[${u}]`));return a.push(\"return a;}\"),a.join(`\n`)},At=(e,t)=>{let r=e.dataType,o=e.dims.length,a=ha(o,t),u=wt(o),i=Pl(e.dims,a),d=u?i.length:i,f=u?o:e.dims,h=Y(\"output\",r,d),c=H(\"a\",r,f),C=b=>`\n  ${b.registerUniform(\"output_size\",\"u32\").declareVariables(c,h)}\n\n  ${Rl(a,o,c,h)}\n\n  ${b.mainStart()}\n    ${b.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.output_size\")}\n\n    let indices = ${h.offsetToIndices(\"global_idx\")};\n    let aIndices = perm(indices);\n\n    ${h.setByOffset(\"global_idx\",c.getByIndices(\"aIndices\"))}\n  }`;return{name:\"Transpose\",shaderCache:{hint:`${t}`,inputDependencies:u?[\"rank\"]:[\"dims\"]},getRunData:b=>{let $=z.size(i);return{outputs:[{dims:i,dataType:b[0].dataType}],dispatchGroup:{x:Math.ceil($/64)},programUniforms:u?[{type:\"uint32\",data:$},...ut(b[0].dims),...ut(i)]:[{type:\"uint32\",data:$}]}},getShaderSource:C}},ga=(e,t)=>{_l(e.inputs),e.compute(At(e.inputs[0],t.perm))},ya=e=>ue({perm:e.perm})});var Ml,kl,Bl,Dl,Wl,zl,Vl,Ul,Nl,Gl,lt,ba,wa,va,$a,xa,Sa,Ca,Aa,Ia,Ta,Oa=K(()=>{\"use strict\";ge();$e();jr();gr();Ml={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate * candidate\",logSumExp:\"bestValue + exp(candidate)\",l1:\"bestValue + abs(candidate)\",l2:\"bestValue + candidate * candidate\",logSum:\"bestValue + candidate\"},kl={max:\"select(bestValue, candidate, candidate > bestValue)\",min:\"select(bestValue, candidate, candidate < bestValue)\",mean:\"bestValue + candidate\",sum:\"bestValue + candidate\",prod:\"bestValue * candidate\",sumSquare:\"bestValue + candidate\",logSumExp:\"bestValue + candidate\",l1:\"bestValue + candidate\",l2:\"bestValue + candidate\",logSum:\"bestValue + candidate\"},Bl={max:\"_A[offset]\",min:\"_A[offset]\",mean:\"0\",sum:\"0\",prod:\"1\",sumSquare:\"0\",logSumExp:\"0\",l1:\"0\",l2:\"0\",logSum:\"0\"},Dl={max:\"bestValue\",min:\"bestValue\",sum:\"bestValue\",prod:\"bestValue\",sumSquare:\"bestValue\",logSumExp:\"log(bestValue)\",l1:\"bestValue\",l2:\"sqrt(bestValue)\",logSum:\"log(bestValue)\"},Wl=(e,t)=>{let r=[];for(let o=t-e;o<t;++o)r.push(o);return r},zl=(e,t)=>{let r=[],o=e.length;for(let u=0;u<o;u++)t.indexOf(u)===-1&&r.push(e[u]);let a=t.map(u=>e[u]);return[r,a]},Vl=(e,t)=>{let r=e.length+t.length,o=[],a=0;for(let u=0;u<r;u++)t.indexOf(u)===-1?o.push(e[a++]):o.push(1);return o},Ul=(e,t)=>{for(let r=0;r<e.length;++r)if(e[e.length-r-1]!==t-1-r)return!1;return!0},Nl=(e,t)=>{let r=[];if(!Ul(e,t)){for(let o=0;o<t;++o)e.indexOf(o)===-1&&r.push(o);e.forEach(o=>r.push(o))}return r},Gl=(e,t,r,o,a,u,i)=>{let d=r[0].dims,f=z.size(u),h=z.size(i),c=H(\"_A\",r[0].dataType,d),C=Y(\"output\",a,u),b=32,$=`\n          var<workgroup> aBestValues : array<${C.type.storage}, ${b}>;\n       `;return{name:e,shaderCache:t,getShaderSource:x=>`\n        ${x.registerUniform(\"reduceSize\",\"u32\").declareVariables(c,C)}\n        ${$}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${x.mainStart(b)}\n          let local_idx = local_id.x;\n\n          let outputIndex = global_idx / ${b};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = ${C.type.storage}(${Bl[o]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${b}) {\n           let candidate = ${C.type.storage}(${c.getByOffset(\"offset + k\")});\n           bestValue = ${Ml[o]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${b}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${kl[o]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${C.setByOffset(\"outputIndex\",`${o===\"mean\"?`bestValue / ${C.type.storage}(uniforms.reduceSize)`:`${Dl[o]}`}`)};\n         }\n        }`,getRunData:()=>({outputs:[{dims:u,dataType:a}],dispatchGroup:{x:f},programUniforms:[{type:\"uint32\",data:h}]})}},lt=(e,t,r,o)=>{let a=e.inputs.length===1?r:Un(e.inputs,r),u=a.axes;u.length===0&&!a.noopWithEmptyAxes&&(u=e.inputs[0].dims.map(($,S)=>S));let i=z.normalizeAxes(u,e.inputs[0].dims.length),d=i,f=e.inputs[0],h=Nl(d,e.inputs[0].dims.length);h.length>0&&(f=e.compute(At(e.inputs[0],h),{inputs:[0],outputs:[-1]})[0],d=Wl(d.length,f.dims.length));let[c,C]=zl(f.dims,d),b=c;a.keepDims&&(b=Vl(c,i)),e.compute(Gl(t,{hint:a.cacheKey,inputDependencies:[\"type\"]},[f],o,e.inputs[0].dataType,b,C),{inputs:[f]})},ba=(e,t)=>{lt(e,\"ReduceMeanShared\",t,\"mean\")},wa=(e,t)=>{lt(e,\"ReduceL1Shared\",t,\"l1\")},va=(e,t)=>{lt(e,\"ReduceL2Shared\",t,\"l2\")},$a=(e,t)=>{lt(e,\"ReduceLogSumExpShared\",t,\"logSumExp\")},xa=(e,t)=>{lt(e,\"ReduceMaxShared\",t,\"max\")},Sa=(e,t)=>{lt(e,\"ReduceMinShared\",t,\"min\")},Ca=(e,t)=>{lt(e,\"ReduceProdShared\",t,\"prod\")},Aa=(e,t)=>{lt(e,\"ReduceSumShared\",t,\"sum\")},Ia=(e,t)=>{lt(e,\"ReduceSumSquareShared\",t,\"sumSquare\")},Ta=(e,t)=>{lt(e,\"ReduceLogSumShared\",t,\"logSum\")}});var ct,Fl,qr,Un,dt,Ll,Hl,jl,ql,Kl,Yl,Jl,Xl,Zl,Ql,pt,Ea,_a,Pa,Ra,Ma,ka,Ba,Da,Wa,za,rt,jr=K(()=>{\"use strict\";ge();Me();$e();Oa();ct=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"Reduce op requires 1 or 2 inputs.\");if(e.length===2&&e[1].dims.length!==1)throw new Error(\"Invalid axes input dims.\")},Fl=e=>[\"\",\"\",`var value = ${e.getByOffset(\"inputOffset\")};`,\"\"],qr=(e,t,r,o,a,u,i=!1,d=!1)=>{let f=[],h=r[0].dims,c=z.normalizeAxes(a,r[0].dims.length),C=!d&&c.length===0;h.forEach((W,q)=>{C||c.indexOf(q)>=0?i&&f.push(1):f.push(W)});let b=[],$=H(\"_A\",r[0].dataType,h),S=Y(\"output\",u,f),x=o($,S,c),A=`inputOffset = ${$.indicesToOffset(\"inputIndices\")};`,k=`let ${A};`,O=`var ${A};`,P=x[1]===\"\"?\"\":O,R=(x[1]===\"\"?k:A)+`\n`+x[2];for(let W=0,q=0;W<r[0].dims.length;W++)C||c.indexOf(W)>=0?(i&&q++,R=`for(var j${W}: u32 = 0; j${W} < ${r[0].dims[W]}; j${W}++) {\n                ${x[2].includes(\"lastIndex\")?`let lastIndex = j${W};`:\"\"}\n                ${$.indicesSet(\"inputIndices\",W,`j${W}`)}\n                ${R}\n              }`):(b.push(`${$.indicesSet(\"inputIndices\",W,S.indicesGet(\"outputIndices\",q))};`),q++);let V=z.size(f);return{name:e,shaderCache:t,getShaderSource:W=>`\n        ${W.declareVariables($,S)}\n\n        ${W.mainStart()}\n          ${W.guardAgainstOutOfBoundsWorkgroupSizes(V)}\n          var inputIndices: ${$.type.indices};\n          let outputIndices = ${S.offsetToIndices(\"global_idx\")};\n\n          ${b.join(`\n`)}\n          ${x[0]}       // init ops for reduce max/min\n          ${P}\n          ${x[1]}\n          ${R}\n          ${x[3]}\n          ${x.length===4?S.setByOffset(\"global_idx\",\"value\"):x.slice(4).join(`\n`)}\n        }`,getRunData:()=>({outputs:[{dims:f,dataType:u}],dispatchGroup:{x:Math.ceil(V/64)}})}},Un=(e,t)=>{let r=[];return e[1].dims[0]>0&&e[1].getBigInt64Array().forEach(o=>r.push(Number(o))),ue({axes:r,keepDims:t.keepDims,noopWithEmptyAxes:t.noopWithEmptyAxes})},dt=(e,t,r,o)=>{let a=e.inputs,u=a.length===1?r:Un(a,r);e.compute(qr(t,{hint:u.cacheKey},[a[0]],u.noopWithEmptyAxes&&u.axes.length===0?Fl:o,u.axes,a[0].dataType,u.keepDims,u.noopWithEmptyAxes),{inputs:[0]})},Ll=(e,t)=>{ct(e.inputs),dt(e,\"ReduceLogSum\",t,(o,a)=>[`var value = ${a.type.storage}(0);`,\"\",`value += ${o.getByOffset(\"inputOffset\")};`,\"value = log(value);\"])},Hl=(e,t)=>{ct(e.inputs),dt(e,\"ReduceL1\",t,(o,a)=>[`var value = ${a.type.storage}(0);`,\"\",`value += abs(${o.getByOffset(\"inputOffset\")});`,\"\"])},jl=(e,t)=>{ct(e.inputs),dt(e,\"ReduceL2\",t,(o,a)=>[`var t = ${a.type.value}(0); var value = ${a.type.value}(0);`,\"\",`t = ${o.getByOffset(\"inputOffset\")}; value += (t * t);`,\"value = sqrt(value);\"])},ql=(e,t)=>{ct(e.inputs),dt(e,\"ReduceLogSumExp\",t,(o,a)=>[`var value = ${a.type.storage}(0);`,\"\",`value += exp(${o.getByOffset(\"inputOffset\")});`,\"value = log(value);\"])},Kl=(e,t)=>{ct(e.inputs),dt(e,\"ReduceMax\",t,(o,a,u)=>{let i=[];for(let d=0;d<o.rank;d++)(u.indexOf(d)>=0||u.length===0)&&i.push(o.indicesSet(\"inputIndices\",d,0));return[`${i.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};`,`value = max(value, ${o.getByOffset(\"inputOffset\")});`,\"\"]})},Yl=(e,t)=>{ct(e.inputs),dt(e,\"ReduceMean\",t,(o,a,u)=>{let i=1;for(let d=0;d<o.rank;d++)(u.indexOf(d)>=0||u.length===0)&&(i*=e.inputs[0].dims[d]);return[\"var sum = f32(0);\",\"\",`sum += f32(${o.getByOffset(\"inputOffset\")});`,`let value = ${a.type.value}(sum / ${i});`]})},Jl=(e,t)=>{ct(e.inputs),dt(e,\"ReduceMin\",t,(o,a,u)=>{let i=[];for(let d=0;d<o.rank;d++)(u.indexOf(d)>=0||u.length===0)&&i.push(`inputIndices[${d}] = 0;`);return[`${i.join(`\n`)}`,`var value = ${o.getByOffset(\"inputOffset\")};`,`value = min(value, ${o.getByOffset(\"inputOffset\")});`,\"\"]})},Xl=(e,t)=>{ct(e.inputs),dt(e,\"ReduceProd\",t,(o,a)=>[`var value = ${a.type.storage}(1);`,\"\",`value *= ${o.getByOffset(\"inputOffset\")};`,\"\"])},Zl=(e,t)=>{ct(e.inputs),dt(e,\"ReduceSum\",t,(o,a)=>[`var value = ${a.type.storage}(0);`,\"\",`value += ${o.getByOffset(\"inputOffset\")};`,\"\"])},Ql=(e,t)=>{ct(e.inputs),dt(e,\"ReduceSumSquare\",t,(o,a)=>[`var t = ${a.type.value}(0); var value = ${a.type.value}(0);`,\"\",`t = ${o.getByOffset(\"inputOffset\")}; value += t * t;`,\"\"])},pt=(e,t,r)=>{if(t.length===0)return!!r;let o=1,a=1;for(let u=0;u<t.length;u++)t.indexOf(u)===-1?o*=e[u]:a*=e[u];return a<32&&o>1024},Ea=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Yl(e,t):ba(e,t)},_a=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Hl(e,t):wa(e,t)},Pa=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?jl(e,t):va(e,t)},Ra=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?ql(e,t):$a(e,t)},Ma=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Kl(e,t):xa(e,t)},ka=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Jl(e,t):Sa(e,t)},Ba=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Xl(e,t):Ca(e,t)},Da=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Zl(e,t):Aa(e,t)},Wa=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Ql(e,t):Ia(e,t)},za=(e,t)=>{pt(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Ll(e,t):Ta(e,t)},rt=e=>ue(e)});var Va,Ua,Na,Ga,Nn,Fa=K(()=>{\"use strict\";We();Me();jr();Va=e=>{if(!e||e.length===0||e.length>2)throw new Error(\"ArgMinMaxOp op requires 1 or 2 inputs.\");if(e[0].dataType!==1)throw new Error(\"Invalid input type.\")},Ua=(e,t)=>ue({axis:t.axis,keepDims:t.keepDims,selectLastIndex:t.selectLastIndex}),Na=(e,t)=>{Va(e.inputs);let r=(a,u,i)=>{let d=[];for(let f=0;f<a.rank;f++)(i.indexOf(f)>=0||i.length===0)&&d.push(`inputIndices[${f}] = 0;`);return[`${d.join(`\n`)}`,`var value = ${a.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${a.getByOffset(\"inputOffset\")} ${t.selectLastIndex>0?\"<=\":\"<\"} value) {\n         value = ${a.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",u.setByOffset(\"global_idx\",\"bestIndex\")]},o=e.inputs.length===1?t:Ua(e.inputs,t);e.compute(qr(\"ArgMin\",{hint:o.cacheKey},[e.inputs[0]],r,[o.axis],7,o.keepDims),{inputs:[0]})},Ga=(e,t)=>{Va(e.inputs);let r=(a,u,i)=>{let d=[];for(let f=0;f<a.rank;f++)(i.indexOf(f)>=0||i.length===0)&&d.push(`inputIndices[${f}] = 0;`);return[`${d.join(`\n`)}`,`var value = ${a.getByOffset(\"inputOffset\")};\nvar bestIndex : i32 = 0;`,`if (${a.getByOffset(\"inputOffset\")} ${t.selectLastIndex>0?\">=\":\">\"} value) {\n         value = ${a.getByOffset(\"inputOffset\")};\n         bestIndex = i32(lastIndex);\n       }`,\"\",u.setByOffset(\"global_idx\",\"bestIndex\")]},o=e.inputs.length===1?t:Ua(e.inputs,t);e.compute(qr(\"argMax\",{hint:o.cacheKey},[e.inputs[0]],r,[o.axis],7,o.keepDims),{inputs:[0]})},Nn=e=>ue(e)});var ec,tc,La,Ha=K(()=>{\"use strict\";ge();$e();ec=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![320,640,1280].includes(e[0].dims[2]))throw new Error(\"number of channels should be 320, 640 or 1280\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},tc=e=>{let t=e[0].dims,r=e[0].dims[2],o=z.size(t)/4,a=e[0].dataType,u=H(\"input\",a,t,4),i=H(\"bias\",a,[r],4),d=H(\"residual\",a,t,4),f=Y(\"output\",a,t,4);return{name:\"BiasAdd\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(o/64)}}),getShaderSource:c=>`\n  const channels = ${r}u / 4;\n  ${c.declareVariables(u,i,d,f)}\n\n  ${c.mainStart()}\n    ${c.guardAgainstOutOfBoundsWorkgroupSizes(o)}\n    let value = ${u.getByOffset(\"global_idx\")}\n      + ${i.getByOffset(\"global_idx % channels\")} + ${d.getByOffset(\"global_idx\")};\n    ${f.setByOffset(\"global_idx\",\"value\")}\n  }`}},La=e=>{ec(e.inputs),e.compute(tc(e.inputs))}});var rc,xe,ja,qa,Ka,Ya,Ja,Xa,Za,Qa,ei,Gn,nc,ti,ri,ni,oi,Kr,ai,Yr,ii,si,ui,li,ci,di,pi,fi,mi,hi,gi,yi,bi,wi,vi,$i,xi,Fn=K(()=>{\"use strict\";We();ge();Me();$e();rc=(e,t,r,o,a,u)=>{let i=Math.ceil(t/4),d=\"\";typeof a==\"string\"?d=`${a}(a)`:d=a(\"a\");let f=H(\"inputData\",r,[i],4),h=Y(\"outputData\",o,[i],4);return`\n      ${e.registerUniform(\"vec_size\",\"u32\").declareVariables(f,h)}\n\n  ${u??\"\"}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n\n    let a = ${f.getByOffset(\"global_idx\")};\n    ${h.setByOffset(\"global_idx\",d)}\n  }`},xe=(e,t,r,o,a,u=e.dataType)=>({name:t,shaderCache:{hint:a,inputDependencies:[\"type\"]},getShaderSource:i=>rc(i,z.size(e.dims),e.dataType,u,r,o),getRunData:i=>({outputs:[{dims:e.dims,dataType:u}],dispatchGroup:{x:Math.ceil(z.size(i[0].dims)/64/4)},programUniforms:[{type:\"uint32\",data:Math.ceil(z.size(e.dims)/4)}]})}),ja=e=>{e.compute(xe(e.inputs[0],\"Abs\",\"abs\"))},qa=e=>{e.compute(xe(e.inputs[0],\"Acos\",\"acos\"))},Ka=e=>{e.compute(xe(e.inputs[0],\"Acosh\",\"acosh\"))},Ya=e=>{e.compute(xe(e.inputs[0],\"Asin\",\"asin\"))},Ja=e=>{e.compute(xe(e.inputs[0],\"Asinh\",\"asinh\"))},Xa=e=>{e.compute(xe(e.inputs[0],\"Atan\",\"atan\"))},Za=e=>{e.compute(xe(e.inputs[0],\"Atanh\",\"atanh\"))},Qa=e=>ue(e),ei=(e,t)=>{let r;switch(t.to){case 10:r=\"vec4<f16>\";break;case 1:r=\"vec4<f32>\";break;case 12:r=\"vec4<u32>\";break;case 6:r=\"vec4<i32>\";break;case 9:r=\"vec4<bool>\";break;default:throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${t.to}`)}e.compute(xe(e.inputs[0],\"Cast\",r,void 0,t.cacheKey,t.to))},Gn=(e,t)=>{let r=ke(e.inputs[0].dataType);e.compute(xe(e.inputs[0],\"Clip\",o=>`clamp(${o}, clip_min_, clip_max_)`,`\n    const clip_min_: vec4<${r}> = vec4(${r}(${t.min}));\n    const clip_max_: vec4<${r}> = vec4(${r}(${t.max}));\n`,t.cacheKey),{inputs:[0]})},nc=e=>{let t=e.length>=2?e[1].getFloat32Array()[0]:Lr,r=e.length>=3?e[2].getFloat32Array()[0]:Hr;return ue({min:t,max:r})},ti=e=>{let t=nc(e.inputs);Gn(e,t)},ri=e=>{e.compute(xe(e.inputs[0],\"Ceil\",\"ceil\"))},ni=e=>{e.compute(xe(e.inputs[0],\"Cos\",\"cos\"))},oi=e=>{e.compute(xe(e.inputs[0],\"Cosh\",\"cosh\"))},Kr=e=>ue(e),ai=(e,t)=>{e.compute(xe(e.inputs[0],\"Elu\",r=>`elu_vf32(${r})`,`\n  const elu_alpha_: f32 = f32(${t.alpha});\n\n  fn elu_f32(a: f32) -> f32 {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<f32>) -> vec4<f32> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,t.cacheKey))},Yr=(e,t=\"f32\")=>`\nconst r0: ${t} = 0.3275911;\nconst r1: ${t} = 0.254829592;\nconst r2: ${t} = -0.284496736;\nconst r3: ${t} = 1.421413741;\nconst r4: ${t} = -1.453152027;\nconst r5: ${t} = 1.061405429;\n\nfn erf_vf32(v: ${e}) -> ${e} {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`,ii=e=>{let t=ke(e.inputs[0].dataType);e.compute(xe(e.inputs[0],\"Erf\",r=>`erf_vf32(${r})`,Yr(`vec4<${t}>`,t)))},si=e=>{e.compute(xe(e.inputs[0],\"Exp\",\"exp\"))},ui=e=>{e.compute(xe(e.inputs[0],\"Floor\",\"floor\"))},li=e=>{let t=ke(e.inputs[0].dataType);e.compute(xe(e.inputs[0],\"Gelu\",r=>`0.5 * ${r} * (1.0 + erf_vf32(${r} * 0.7071067811865475))`,Yr(`vec4<${t}>`,t)))},ci=(e,t)=>{e.compute(xe(e.inputs[0],\"LeakyRelu\",r=>`select(leaky_relu_alpha_ * ${r}, ${r}, ${r} >= vec4<f32>(0.0))`,`const leaky_relu_alpha_: f32 = f32(${t.alpha});`,t.cacheKey))},di=e=>{e.compute(xe(e.inputs[0],\"Not\",t=>`!${t}`))},pi=e=>{e.compute(xe(e.inputs[0],\"Neg\",t=>`-${t}`))},fi=e=>{e.compute(xe(e.inputs[0],\"Reciprocal\",t=>`1.0/${t}`))},mi=e=>{e.compute(xe(e.inputs[0],\"Relu\",t=>`select(vec4<f32>(0.0), ${t}, ${t} > vec4<f32>(0.0))`))},hi=e=>{e.compute(xe(e.inputs[0],\"Sigmoid\",t=>`(1.0 / (1.0 + exp(-${t})))`))},gi=e=>{e.compute(xe(e.inputs[0],\"Sin\",\"sin\"))},yi=e=>{e.compute(xe(e.inputs[0],\"Sinh\",\"sinh\"))},bi=e=>{e.compute(xe(e.inputs[0],\"Sqrt\",\"sqrt\"))},wi=e=>{e.compute(xe(e.inputs[0],\"Tan\",\"tan\"))},vi=e=>{e.compute(xe(e.inputs[0],\"Tanh\",\"tanh\"))},$i=(e,t)=>(e.compute(xe(e.inputs[0],\"ThresholdedRelu\",r=>`select(vec4<f32>(0.0), ${r}, ${r} > thresholded_relu_alpha_)`,`const thresholded_relu_alpha_: vec4<f32> = vec4<f32>(${t.alpha});`,t.cacheKey)),0),xi=e=>{e.compute(xe(e.inputs[0],\"Log\",\"log\"))}});var ac,ic,Si,Ci=K(()=>{\"use strict\";ge();$e();Fn();ac=e=>{if(e[0].dims.length!==3)throw new Error(\"input should have 3 dimensions\");if(![2560,5120,10240].includes(e[0].dims[2]))throw new Error(\"hidden state should be 2560, 5120 or 10240\");if(e[1].dims.length!==1)throw new Error(\"bias is expected to have 1 dimensions\");if(e[0].dims[2]!==e[1].dims[0])throw new Error(\"last dimension of input and bias are not the same\")},ic=e=>{let t=e[0].dims.slice();t[2]=t[2]/2;let r=H(\"input\",e[0].dataType,e[0].dims,4),o=H(\"bias\",e[0].dataType,[e[0].dims[2]],4),a=Y(\"output\",e[0].dataType,t,4),u=z.size(t)/4;return{name:\"BiasSplitGelu\",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(u/64)}}),getShaderSource:d=>`\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${e[0].dims[2]/4/2}u;\n\n  ${d.declareVariables(r,o,a)}\n\n  ${Yr(\"vec4f\")}\n\n  ${d.mainStart()}\n    ${d.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${a.setByOffset(\"global_idx\",\"valueLeft * geluRight\")}\n  }`}},Si=e=>{ac(e.inputs),e.compute(ic(e.inputs))}});var sc,uc,ft,Ai,Ii,Ti,Oi,Ei,_i,Pi,Ri,Mi,ki,Bi=K(()=>{\"use strict\";We();ge();$e();sc=(e,t,r,o,a,u,i,d,f,h,c,C)=>{let b,$;typeof i==\"string\"?b=$=(V,B)=>`${i}((${V}),(${B}))`:typeof i==\"function\"?b=$=i:(b=i.scalar,$=i.vector);let S=c?t.length:t,x=c?r.length:r,A=c?o.length:o,k=Y(\"outputData\",h,A,4),O=H(\"aData\",d,S,4),P=H(\"bData\",f,x,4),R;if(a)if(u){let V=z.size(t)===1,B=z.size(r)===1;V||B?R=k.setByOffset(\"global_idx\",$(V?`${O.type.value}(${O.getByOffset(\"0\")}.x)`:O.getByOffset(\"global_idx\"),B?`${P.type.value}(${P.getByOffset(\"0\")}.x)`:P.getByOffset(\"global_idx\"))):R=`\n            let outputIndices = ${k.offsetToIndices(\"global_idx * 4u\")};\n            let offsetA = ${O.broadcastedIndicesToOffset(\"outputIndices\",k)};\n            let offsetB = ${P.broadcastedIndicesToOffset(\"outputIndices\",k)};\n            ${k.setByOffset(\"global_idx\",$(O.getByOffset(\"offsetA / 4u\"),P.getByOffset(\"offsetB / 4u\")))}\n          `}else R=k.setByOffset(\"global_idx\",$(O.getByOffset(\"global_idx\"),P.getByOffset(\"global_idx\")));else{if(!u)throw new Error(\"no necessary to use scalar implementation for element-wise binary op implementation.\");let V=(B,W,q=\"\")=>{let ee=`aData[indexA${W}][componentA${W}]`,oe=`bData[indexB${W}][componentB${W}]`;return`\n            let outputIndices${W} = ${k.offsetToIndices(`global_idx * 4u + ${W}u`)};\n            let offsetA${W} = ${O.broadcastedIndicesToOffset(`outputIndices${W}`,k)};\n            let offsetB${W} = ${P.broadcastedIndicesToOffset(`outputIndices${W}`,k)};\n            let indexA${W} = offsetA${W} / 4u;\n            let indexB${W} = offsetB${W} / 4u;\n            let componentA${W} = offsetA${W} % 4u;\n            let componentB${W} = offsetB${W} % 4u;\n            ${B}[${W}] = ${q}(${b(ee,oe)});\n          `};h===9?R=`\n            var data = vec4<u32>(0);\n            ${V(\"data\",0,\"u32\")}\n            ${V(\"data\",1,\"u32\")}\n            ${V(\"data\",2,\"u32\")}\n            ${V(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:R=`\n            ${V(\"outputData[global_idx]\",0)}\n            ${V(\"outputData[global_idx]\",1)}\n            ${V(\"outputData[global_idx]\",2)}\n            ${V(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.registerUniform(\"vec_size\",\"u32\").declareVariables(O,P,k)}\n\n        ${C??\"\"}\n\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.vec_size\")}\n        ${R}\n      }`},uc=(e,t,r,o,a,u,i=r.dataType)=>{let d=!z.areEqual(r.dims,o.dims),f=r.dims,h=z.size(r.dims),c=!1,C=[d];if(d){let $=st.calcShape(r.dims,o.dims,!1);if(!$)throw new Error(\"Can't perform binary op on the given tensors\");f=$,h=z.size(f);let S=z.size(r.dims)===1,x=z.size(o.dims)===1;C.push(S),C.push(x);let A=1;for(let k=1;k<f.length;k++){let O=r.dims[r.dims.length-k]??1,P=o.dims[o.dims.length-k]??1;if(O===P)A*=O;else break}(A%4===0||S||x)&&(c=!0)}else c=!0;C.push(c);let b=wt(r.dims.length)&&wt(o.dims.length)&&wt(f.length);return{name:e,shaderCache:{hint:t+C.map($=>$.toString()).join(\"_\"),inputDependencies:b?[\"rank\",\"rank\"]:[\"dims\",\"dims\"]},getShaderSource:$=>sc($,r.dims,o.dims,f,c,d,a,r.dataType,o.dataType,i,b,u),getRunData:()=>({outputs:[{dims:f,dataType:i}],dispatchGroup:{x:Math.ceil(h/64/4)},programUniforms:b?[{type:\"uint32\",data:Math.ceil(z.size(f)/4)},...ut(r.dims),...ut(o.dims),...ut(f)]:[{type:\"uint32\",data:Math.ceil(z.size(f)/4)}]})}},ft=(e,t,r,o,a,u)=>{e.compute(uc(t,a??\"\",e.inputs[0],e.inputs[1],r,o,u))},Ai=e=>{ft(e,\"Add\",(t,r)=>`${t}+${r}`)},Ii=e=>{ft(e,\"Div\",(t,r)=>`${t}/${r}`)},Ti=e=>{ft(e,\"Equal\",{scalar:(t,r)=>`u32(${t}==${r})`,vector:(t,r)=>`vec4<u32>(${t}==${r})`},void 0,void 0,9)},Oi=e=>{ft(e,\"Mul\",(t,r)=>`${t}*${r}`)},Ei=e=>{let t=H(\"input\",e.inputs[0].dataType,e.inputs[0].dims).type.value;ft(e,\"Pow\",{scalar:(o,a)=>`pow_custom(${o},${a})`,vector:(o,a)=>`pow_vector_custom(${o},${a})`},`\n    fn pow_custom(a : ${t}, b : ${t}) -> ${t} {\n      if (b == ${t}(0.0)) {\n        return ${t}(1.0);\n      } else if (a < ${t}(0.0) && f32(b) != floor(f32(b))) {\n        return ${t}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${t}(1.0), round(f32(abs(b) % ${t}(2.0))) != 1.0) * ${t}(${t===\"i32\"?\"round\":\"\"}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${t}>, b : vec4<${t}>) -> vec4<${t}> {\n      // TODO: implement vectorized pow\n      return vec4<${t}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `)},_i=e=>{ft(e,\"Sub\",(t,r)=>`${t}-${r}`)},Pi=e=>{ft(e,\"Greater\",{scalar:(t,r)=>`u32(${t}>${r})`,vector:(t,r)=>`vec4<u32>(${t}>${r})`},void 0,void 0,9)},Ri=e=>{ft(e,\"Less\",{scalar:(t,r)=>`u32(${t}<${r})`,vector:(t,r)=>`vec4<u32>(${t}<${r})`},void 0,void 0,9)},Mi=e=>{ft(e,\"GreaterOrEqual\",{scalar:(t,r)=>`u32(${t}>=${r})`,vector:(t,r)=>`vec4<u32>(${t}>=${r})`},void 0,void 0,9)},ki=e=>{ft(e,\"LessOrEqual\",{scalar:(t,r)=>`u32(${t}<=${r})`,vector:(t,r)=>`vec4<u32>(${t}<=${r})`},void 0,void 0,9)}});var cc,dc,pc,fc,Di,Wi,zi=K(()=>{\"use strict\";ge();Me();$e();cc=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\");let t=e[0].dataType,r=e[0].dims.length;for(let o of e){if(o.dataType!==t)throw new Error(\"input tensors should be one type\");if(o.dims.length!==r)throw new Error(\"input tensors should have the same shape\")}},dc=(e,t)=>`\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${e}u>(${t});\n    for (var i: u32 = 0u; i < ${e}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${e}u;\n  }`,pc=(e,t)=>{let r=e.length,o=[];for(let a=0;a<r;++a){let u=t.setByOffset(\"global_idx\",e[a].getByIndices(\"indices\"));r===1?o.push(u):a===0?o.push(`if (inputIndex == ${a}u) { ${u} }`):a===r-1?o.push(`else { ${u} }`):o.push(`else if (inputIndex == ${a}) { ${u} }`)}return o.join(`\n`)},fc=(e,t)=>{let r=e[0].dims.slice();if(t>=r.length||t<-1*r.length)throw new Error(\"axis specified for concat doesn't match input dimensionality\");let o=t<0?r.length+t:t,a=r.slice(0);for(let R=1;R<e.length;R++){let V=e[R].dims.slice();for(let B=0;B<r.length;B++)if(B===o)a[o]+=V[B];else if(r[B]!==V[B])throw new Error(\"non concat dimensions must match\")}let u=z.size(a),i=new Array(e.length),d=new Array(e.length),f=e[0].dataType,h=0,c=[],C=[],b=[],$=[{type:\"uint32\",data:u}];for(let R=0;R<e.length;++R)h+=e[R].dims[o],i[R]=h,b.push(wt(e[R].dims.length)),C.push(b[R]?e[R].dims.length:e[R].dims),d[R]=H(`input${R}`,f,C[R]),c.push(b[R]?\"rank\":\"dims\"),$.push({type:\"uint32\",data:i[R]});for(let R=0;R<e.length;++R)b[R]&&$.push(...ut(e[R].dims));let S=wt(a.length);S&&$.push(...ut(a));let x=S?a.length:a,A=Y(\"output\",f,x),k=A.indicesGet(\"indices\",o),O=Array.from(Array(i.length).keys()).map(R=>`uniforms.sizeInConcatAxis${R}`).join(\",\"),P=R=>`\n\n  ${(()=>{R.registerUniform(\"outputSize\",\"u32\");for(let V=0;V<e.length;V++)R.registerUniform(`sizeInConcatAxis${V}`,\"u32\");return R.declareVariables(...d,A)})()}\n\n  ${dc(i.length,O)}\n\n  ${R.mainStart()}\n    ${R.guardAgainstOutOfBoundsWorkgroupSizes(\"uniforms.outputSize\")}\n\n    var indices = ${A.offsetToIndices(\"global_idx\")};\n\n    let inputIndex = calculateInputIndex(${k});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${i.length}u>(${O});\n      ${k} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${pc(d,A)}\n  }`;return{name:\"Concat\",shaderCache:{hint:`${t}`,inputDependencies:c},getRunData:()=>({outputs:[{dims:a,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:$}),getShaderSource:P}},Di=(e,t)=>{cc(e.inputs),e.compute(fc(e.inputs,t.axis))},Wi=e=>ue({axis:e.axis})});var It,Jr,Wt=K(()=>{\"use strict\";ge();It=(e,t)=>{switch(e.activation){case\"Relu\":return{activationFunction:\"\",applyActivation:`value = max(value, ${t}(0.0));`};case\"Sigmoid\":return{activationFunction:\"\",applyActivation:`value = (${t}(1.0) / (${t}(1.0) + exp(-value)));`};case\"Clip\":return{activationFunction:`const clip_min_=${t}(${e.clipMin});const clip_max_=${t}(${e.clipMax});`,applyActivation:\"value = clamp(value, clip_min_, clip_max_);\"};default:return{activationFunction:\"\",applyActivation:\"\"}}},Jr=e=>{let t=e?.activation||\"\";if(t===\"Clip\"){let[r,o]=e?.activation_params||[Lr,Hr];return{activation:t,clipMax:o,clipMin:r,activationCacheKey:`${t}:${r},${o}`}}return{activation:t,activationCacheKey:t}}});var ze,Xr,Zr=K(()=>{\"use strict\";ze=(e,t)=>{switch(e){case 1:return t;case 2:return`vec2<${t}>`;case 3:return`vec3<${t}>`;case 4:return`vec4<${t}>`;default:throw new Error(`${e}-component is not supported.`)}},Xr=e=>`\n      ${e?\"value = value + getBiasByOutputCoords(coords);\":\"\"}\n      `});var Qr,Ln=K(()=>{\"use strict\";Qr=`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    outShapeStrides.x, outShapeStrides.y, outShapeStrides.z, 1));\n}\n`});var mc,hc,yr,Vi,gc,br,yc,en,wr=K(()=>{\"use strict\";ge();$e();Wt();Zr();mc=(e,t)=>e?`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `:`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${t?\", batchIndices\":\"\"});\n        `,hc=(e,t)=>e?`\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${t===3?\"\":\"let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];\"}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached3[i] + acc[i];\"}\n        }`:`\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${t===3?\"\":\"acc[i] = BCached3 * ACached.w + acc[i];\"}\n        }`,yr=(e,t,r=\"f32\",o,a=!1,u=32,i=!1,d=32)=>{let f=t[1]*e[1],h=t[0]*e[0],c=a?f:u,C=a?u:f,b=c/t[0],$=u/t[1];if(!((a&&b===4&&e[1]===4||!a&&(b===3||b===4))&&c%t[0]===0&&u%t[1]===0&&e[0]===4))throw new Error(`If transposeA ${a} is true, innerElementSize ${b} and workPerThread[1] ${e[1]} must be 4.\n      Otherwise, innerElementSize ${b} must be 3 or 4.\n  tileAWidth ${c} must be divisible by workgroupSize[0]${t[0]}. tileInner ${u} must be divisible by workgroupSize[1] ${t[1]}. colPerThread ${e[0]} must be 4.`);return`\nvar<workgroup> mm_Asub: array<array<vec${b}<${r}>, ${c/b}>, ${C}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${r}>, ${h/e[0]}>, ${u}>;\n\nconst rowPerThread = ${e[1]};\nconst colPerThread = ${e[0]};\nconst innerElementSize = ${b};\nconst tileInner = ${u};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${i?\"0\":\"i32(globalId.z)\"};\n  ${o?`let batchIndices = ${o.offsetToIndices(\"u32(batch)\")};`:\"\"}\n  let globalRowStart = i32(workgroupId.y) * ${f};\n\n  let numTiles = ${i?`${Math.ceil(d/u)}`:\"(dimInner - 1) / tileInner + 1\"};\n  var kStart = ${i?`i32(globalId.z) * ${d}`:\"0\"};\n\n  var acc: array<vec4<${r}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${$};\n  for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${mc(a,o)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${$}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${o?\", batchIndices\":\"\"});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${b===3?\"\":\"let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];\"}\n\n          ${hc(a,b)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`},Vi=(e,t)=>e?`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${t?\", batchIndices\":\"\"});\n            `:`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${t?\", batchIndices\":\"\"});\n            `,gc=e=>e?\"let ACached = mm_Asub[k][tileRow + innerRow];\":\"let ACached = mm_Asub[tileRow + innerRow][k];\",br=(e,t,r=\"f32\",o,a=!1,u=32,i=!1,d=32,f=!1)=>{let h=e[1]*t[1],c=e[0]*t[0],C=a?h:u,b=a?u:h;if(!(b%t[1]===0&&C%t[0]===0&&u%t[1]===0))throw new Error(`tileAHight ${b} must be divisible by workgroupSize[1]${t[1]}, tileAWidth ${C} must be divisible by workgroupSize[0]${t[0]}, tileInner ${u} must be divisible by workgroupSize[1]${t[1]}`);let $=b/t[1],S=C/t[0],x=u/t[1],A=f?`\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${h};\n    let globalColStart = i32(workgroupId.x) * ${c};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < numTiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${b}; inputRow = inputRow + ${t[1]}) {\n        for (var inputCol = localCol; inputCol < ${C}; inputCol = inputCol + ${t[0]}) {\n          ${Vi(a,o)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${u}; inputRow = inputRow + ${t[1]}) {\n            for (var inputCol = localCol; inputCol < ${c}; inputCol = inputCol + ${t[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${o?\", batchIndices\":\"\"});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${r}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${t[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${a?`mm_Asub[k][localRow + innerRow * ${t[1]}];`:`mm_Asub[localRow + innerRow * ${t[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${t[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${t[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    `:`\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${h};\n\nlet tileRowA = i32(localId.y) * ${$};\nlet tileColA = i32(localId.x) * ${S};\nlet tileRowB = i32(localId.y) * ${x};\n// Loop over shared dimension.\nfor (var t = 0; t < numTiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${$}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${S}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${Vi(a,o)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${x}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${o?\", batchIndices\":\"\"});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${r}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${gc(a)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;return`\n  var<workgroup> mm_Asub : array<array<${r}, ${C}>, ${b}>;\n  var<workgroup> mm_Bsub : array<array<${r}, ${c}>, ${u}>;\n  const rowPerThread = ${e[1]};\n  const colPerThread = ${e[0]};\n  const tileInner = ${u};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${i?\"0\":\"i32(globalId.z)\"};\n    ${o?`let batchIndices = ${o.offsetToIndices(\"u32(batch)\")};`:\"\"}\n    let numTiles = ${i?`${Math.ceil(d/u)}`:\"(dimInner - 1) / tileInner + 1\"};\n    var kStart = ${i?`i32(globalId.z) * ${d}`:\"0\"};\n\n    var acc : array<array<${r}, colPerThread>, rowPerThread>;\n\n    // Without this initialization strange values show up in acc.\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = 0.0;\n      }\n    }\n    ${A}\n  }\n`},yc=(e,t,r,o,a,u=!1)=>{let i=a[0],d=a[1],f=a[2],h=o[0],c=o[1],C=o[2],b=o[3],$=Vn(i,f),S=Vn(d,f),x=ke(o[0].type.tensor),A=()=>{let P=c.rank,R=h.rank,V=`var aIndices: ${c.type.indices};`;for(let B=P-2-1,W=R-1;B>=0;B--,W--)V+=`\naIndices[${B}] = ${R>1?`batchIndices[${W}]`:\"batchIndices\"};`;return $.forEach(B=>{V+=`\naIndices[${B}] = 0;`}),V+=`\naIndices[${P-2}] = u32(row);\n                   aIndices[${P-1}] = u32(colIn);`,V},k=()=>{let P=C.rank,R=h.rank,V=`var bIndices: ${C.type.indices};`;for(let B=P-2-1,W=R-1;B>=0;B--,W--)V+=`\nbIndices[${B}] = ${R>1?`batchIndices[${W}]`:\"batchIndices\"};`;return S.forEach(B=>{V+=`\nbIndices[${B}] = 0;`}),V+=`\nbIndices[${P-2}] = u32(row);\n                   bIndices[${P-1}] = u32(colIn);`,V};return`\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${h.type.indices}) -> ${ze(e,x)} {\n      var value = ${ze(e,x)}(0.0);\n      let col = colIn * ${e};\n      if(row < dimAOuter && col < dimInner)\n      {\n        ${A()}\n        value = ${c.getByIndices(\"aIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${h.type.indices}) -> ${ze(e,x)} {\n      var value = ${ze(e,x)}(0.0);\n      let col = colIn * ${e};\n      if(row < dimInner && col < dimBOuter)\n      {\n        ${k()}\n        value = ${C.getByIndices(\"bIndices\")};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${ze(e,x)}) {\n      let col = colIn * ${e};\n      if (row < dimAOuter && col < dimBOuter) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${t?`value = value + ${u?\"bias[colIn]\":`${ze(e,x)}(bias[row])`};`:\"\"}\n        ${r}\n        ${b.setByIndices(\"vec3<u32>(coords)\",\"value\")}\n      }\n    }\n    `},en=(e,t,r,o,a=!1)=>{let u=e[0].dims,i=e[1].dims,d=u.slice(0,-2),f=i.slice(0,-2),h=o?o.slice(0,-2):r.slice(0,-2),c=H(\"batchDims\",e[0].dataType,h),C=[c],b=[d,f,h],$=z.size(h),S=u[u.length-2],x=u[u.length-1],A=i[i.length-1],k=x%4===0&&A%4===0,O=S<=8?[4,1,1]:[4,4,1],P=[8,8,1],R=[Math.ceil(A/P[0]/O[0]),Math.ceil(S/P[1]/O[1]),Math.ceil($/P[2]/O[2])],V=ke(e[0].dataType),B=k?4:1,W=H(\"a\",e[0].dataType,[...d,S,x/B],B),q=H(\"b\",e[1].dataType,[...f,x,A/B],B),ee=Y(\"result\",e[0].dataType,[$,S,A/B],B);C.push(W),C.push(q),C.push(ee);let oe=[W,q],D=e.length>2,{activationFunction:te,applyActivation:Ie}=It(t,ee.type.value),Z=yc(B,D,Ie,C,b,a);if(D){let Te=a?B:1;oe.push(H(\"bias\",e[2].dataType,e[2].dims,Te))}let ve=Te=>`\n  const dimAOuter: i32 = ${S};\n  const dimBOuter: i32 = ${A};\n  const dimInner: i32 = ${x};\n  ${Te.declareVariables(...oe,ee)}\n  ${te}\n  ${Z}\n  ${k?yr(O,P,V,c):br(O,P,V,c)}\n                   ${c.impl()}`;return{name:\"MatMul\",shaderCache:{hint:t.activationCacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:R[0],y:R[1],z:R[2]}}),getShaderSource:ve}}});var bc,Ui,Ni=K(()=>{\"use strict\";St();ge();$e();Wt();Zr();Ln();wr();bc=(e,t,r,o,a=!1,u,i=4,d=4,f=4,h=\"f32\")=>{let c=D=>{switch(D){case 1:return\"resData = x[xIndex];\";case 3:return`resData = vec3<${h}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;case 4:return\"resData = x[xIndex / 4];\";default:throw new Error(`innerElementSize ${D} is not supported.`)}},C=D=>{switch(D){case 1:return\"return w[row * wShape[3] + colIn];\";case 4:return\"return w[row * wShape[3] / 4 + colIn];\";default:throw new Error(`innerElementSize ${D} is not supported.`)}},b=e?`\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    `:`\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    `,$=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,S=e?\"xShape[1]\":\"xShape[2]\",x=e?\"xShape[2]\":\"xShape[3]\",A=e?\"row\":\"col\",k=e?\"col\":\"row\",O=`\n    let inChannels = wShape[2];\n    let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n    let outRow = ${A} / outWidth;\n    let outCol = ${A} % outWidth;\n\n    let WRow = ${k} / (filterDims[1] * inChannels);\n    let WCol = ${k} / inChannels % filterDims[1];\n    let xRow = outRow * stride[0] + dilation[0] * WRow - pad[0];\n    let xCol = outCol * stride[1] + dilation[1] * WCol - pad[1];\n    let xCh = ${k} % inChannels;\n    var resData = ${ze(i,h)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${S} && xCol >= 0 && xCol < ${x}) {\n      ${b}\n      let xIndex = getIndexFromCoords4D(coord, xShape);\n      ${c(i)}\n    }\n    return resData;`,P=e?t&&o?`\n    let col = colIn * ${i};\n    ${O}`:`\n    let col = colIn * ${i};\n    if (row < dimAOuter && col < dimInner) {\n      ${O}\n    }\n    return ${ze(i,h)}(0.0);`:o&&r?`\n    let col = colIn * ${i};\n    ${O}`:`\n    let col = colIn * ${i};\n    if (row < dimInner && col < dimBOuter) {\n      ${O}\n    }\n    return ${ze(i,h)}(0.0);`,R=`${C(d)}`,V=ze(f,h),B=e?ze(i,h):ze(d,h),W=e?ze(d,h):ze(i,h),{activationFunction:q,applyActivation:ee}=It(u,V);return`\n    ${q}\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${B} {\n      ${e?P:R}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${W} {\n      ${e?R:P}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${V}) {\n      let col = colIn * ${f};\n      if (row < dimAOuter && col < dimBOuter)\n      {\n      var value = valueIn;\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      ${$}\n      ${Xr(a)}\n      ${ee}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`},Ui=(e,t,r,o,a,u,i,d)=>{let f=t.format===\"NHWC\",h=f?e[0].dims[3]:e[0].dims[1],c=r[0],C=f?r[2]:r[3],b=f?r[1]:r[2],$=f?r[3]:r[1],S=f&&(h%4===0||h%3===0)&&$%4===0,x=f?$:C*b,A=f?C*b:$,k=[8,8,1],O=o<=8?[4,1,1]:[4,4,1],P=[Math.ceil(x/k[0]/O[0]),Math.ceil(A/k[1]/O[1]),Math.ceil(c/k[2]/O[2])];Ee(\"verbose\",()=>`[conv2d_mm_webgpu] dispatch = ${P}`);let R=S?f&&h%4!==0?3:4:O[0],V=k[1]*O[1],B=k[0]*O[0],W=Math.max(k[0]*R,k[1]),q=o%V===0,ee=a%B===0,oe=u%W===0,D=S?[R,4,4]:[1,1,1],te=ke(e[0].dataType),Ie=[`@group(0) @binding(0) var<storage, read> x: array<${S&&R===4?`vec4<${te}>`:te}>;`,`@group(0) @binding(1) var<storage, read> w: array<${S?`vec4<${te}>`:te}>;`],Z=`\n      fn setOutputAtIndex(flatIndex : i32, value : ${S?`vec4<${te}>`:te}) {\n        result[flatIndex] = ${S?`vec4<${te}>`:te}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${S?`vec4<${te}>`:te}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${S?\"/ 4\":\"\"}, value);\n      }`;return i&&(Ie.push(`@group(0) @binding(2) var<storage, read> bias: array<${S?`vec4<${te}>`:te}>;`),Z+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${S?`vec4<${te}>`:te} {\n          return bias[coords.${f?\"w\":\"y\"}${S?\"/ 4\":\"\"}];\n        }`),{name:\"Conv2DMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:P[0],y:P[1],z:P[2]}}),getShaderSource:()=>`\n        ${Qr}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${Ie.join(\"\")}\n        @group(0) @binding(${Ie.length}) var<storage, read_write> result: array<${S?`vec4<${te}>`:te}>;\n        //@group(0) @binding(${Ie.length+1}) var<uniform> uniforms: Uniforms;\n\n        const xShape : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const wShape : vec4<i32> = vec4<i32>(${e[1].dims.join(\",\")});\n        const outShape : vec4<i32> = vec4<i32>(${r.join(\",\")});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${z.computeStrides(r).slice(0,3).join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[0]}, ${t.kernelShape[1]});\n        const pad : vec2<i32> = vec2<i32>(${t.pads[0]}, ${t.pads[1]});\n        const stride : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        const dimAOuter : i32 = ${o};\n        const dimBOuter : i32 = ${a};\n        const dimInner : i32 = ${u};\n        ${Z}\n        ${bc(f,q,ee,oe,i,t,D[0],D[1],D[2],te)}\n            ${S?yr(O,k,te,void 0,!f,W):br(O,k,te,void 0,!f,W,!1,void 0,d)}`}}});var Hn,Gi=K(()=>{\"use strict\";ge();$e();qn();Wt();Hn=(e,t,r)=>{let o=e.length>2,a=o?\"value += b[output_channel];\":\"\",u=e[0].dims,i=e[1].dims,d=i[0]/t.group,f=t.format===\"NHWC\",h=jn(u,i,t.dilations,t.pads,t.strides,f),c=z.size(h),C=Y(\"output\",e[0].dataType,h),{activationFunction:b,applyActivation:$}=It(t,C.type.value),S=H(\"x\",e[0].dataType,u),x=H(\"w\",e[1].dataType,i),A=[S,x];o&&A.push(H(\"b\",e[2].dataType,e[2].dims));let k=O=>`\n  const strides: vec2<u32> = vec2(${t.strides[0]}u, ${t.strides[1]}u);\n  const pads: vec2<u32> = vec2(${t.pads[0]}u, ${t.pads[1]}u);\n\n  ${O.declareVariables(...A,C)}\n\n  ${b}\n\n  ${O.mainStart()}\n    ${O.guardAgainstOutOfBoundsWorkgroupSizes(c)}\n\n    let outputIndices = ${C.offsetToIndices(\"global_idx\")};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${f?3:1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${f?1:2}], outputIndices[${f?2:3}]) * strides - pads;\n    let group_id: u32 = output_channel / ${d}u;\n\n    var value: ${C.type.value} = ${C.type.value}(0);\n    for (var wInChannel: u32 = 0u; wInChannel < ${i[1]}u; wInChannel++) {\n      let input_channel = group_id * ${i[1]}u + wInChannel;\n      for (var wHeight: u32 = 0u; wHeight < ${i[2]}u; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * ${t.dilations[0]}u;\n\n        if (xHeight < 0u || xHeight >= ${u[f?1:2]}u) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < ${i[3]}u; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * ${t.dilations[1]}u;\n          if (xWidth < 0u || xWidth >= ${u[f?2:3]}u) {\n            continue;\n          }\n\n          let xVal = ${f?S.get(\"batch\",\"xHeight\",\"xWidth\",\"input_channel\"):S.get(\"batch\",\"input_channel\",\"xHeight\",\"xWidth\")};\n          let wVal = ${x.get(\"output_channel\",\"wInChannel\",\"wHeight\",\"wWidth\")};\n          value += xVal*wVal;\n        }\n      }\n    }\n    ${a}\n    ${$}\n    ${C.setByOffset(\"global_idx\",\"value\")}\n  }`;return{name:\"GroupedConv\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r?r(h):h,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(c/64)}}),getShaderSource:k}}});var jn,Fi,wc,Li,Kn,vc,$c,Yn,qn=K(()=>{\"use strict\";ge();Me();Ni();wr();Gi();Wt();gr();jn=(e,t,r,o,a,u)=>{let i=e[0],d=e.slice(u?1:2,u?3:4),f=d.length,h=t[0],C=t.slice(2).map((S,x)=>S+(S-1)*(r[x]-1)),$=d.map((S,x)=>S+o[x]+o[x+f]).map((S,x)=>Math.floor((S-C[x]+a[x])/a[x]));return $.splice(0,0,i),$.splice(u?3:1,0,h),$},Fi=[2,3,1,0],wc=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support conv 1D and 2D\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],o=e[1].dims[1]*t.group;if(r!==o)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");if(e.length===3&&(e[2].dims.length!==1||e[1].dims[0]!==e[2].dims[0]))throw new Error(\"invalid bias\");let a=e[0].dims.length-2;if(t.dilations.length!==a)throw new Error(`dilations should be ${a}D`);if(t.strides.length!==a)throw new Error(`strides should be ${a}D`);if(t.pads.length!==a*2)throw new Error(`pads should be ${a*2}D`);if(t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\")},Li=(e,t)=>{let r=e.kernelShape.slice();for(let u=2;u<t[1].dims.length;++u)r[u-2]===0&&(r[u-2]=t[1].dims[u]);let o=e.pads.slice();Bt.adjustPadsBasedOnAutoPad(t[0].dims,e.strides,e.dilations,r,o,e.format===\"NHWC\",e.autoPad);let a=Object.assign({},e);return Object.assign(a,{kernelShape:r,pads:o,cacheKey:e.cacheKey}),a},Kn=e=>{let t=Jr(e),r=e.format,o=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],a=e.dilations,u=e.group,i=e.kernel_shape,d=e.pads,f=e.strides,h=e.w_is_const();return ue({autoPad:o,format:r,dilations:a,group:u,kernelShape:i,pads:d,strides:f,wIsConst:h,...t})},vc=(e,t,r)=>{let o=Li(r,t);if(r.group!==1){e.compute(Hn(t,o));return}let a=r.format===\"NHWC\",u=t.length===3,i=t[0].dims[a?1:2],d=t[0].dims[a?2:3],f=t[0].dims[a?3:1],h=t[1].dims[2],c=t[1].dims[3],C=jn(t[0].dims,t[1].dims,r.dilations,o.pads,r.strides,a),b=C[a?1:2],$=C[a?2:3],S=C[a?3:1],x=a&&h===i&&c===d&&r.pads[0]===0&&r.pads[1]===0;if(x||h===1&&c===1&&r.dilations[0]===1&&r.dilations[1]===1&&r.strides[0]===1&&r.strides[1]===1&&r.pads[0]===0&&r.pads[1]===0){let B=C[0],W,q,ee,oe=[];if(a){let D=e.kernelCustomData.wT??e.compute(At(t[1],Fi),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];if(r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=D),x){let te=i*d*f;W=t[0].reshape([1,B,te]),q=D.reshape([1,te,S]),ee=[1,B,S]}else W=t[0].reshape([B,i*d,f]),q=D.reshape([1,f,S]),ee=[B,b*$,S];oe.push(W),oe.push(q)}else W=t[0].reshape([B,f,i*d]),q=t[1].reshape([1,S,f]),ee=[B,S,b*$],oe.push(q),oe.push(W);u&&oe.push(t[2]),e.compute(en(oe,o,C,ee,a),{inputs:oe});return}let A=!0,k=e.kernelCustomData.wT??e.compute(At(t[1],Fi),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=k);let O=[t[0],k];u&&O.push(t[2]);let P=a?b*$:S,R=a?S:b*$,V=h*c*f;e.compute(Ui(O,o,C,P,R,V,u,A),{inputs:O})},$c=(e,t)=>{let r=t.format===\"NHWC\",o=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];e.inputs.length===3&&o.push(e.inputs[2]);let a=[0,t.pads[0],0,t.pads[1]],u=[1].concat(t.strides),i=[1].concat(t.dilations),d=[1].concat(t.kernelShape),f=Li({...t,pads:a,strides:u,dilations:i,kernelShape:d},o);e.compute(Hn(o,f,h=>r?[h[0],h[2],h[3]]:[]))},Yn=(e,t)=>{wc(e.inputs,t),e.inputs[0].dims.length===3?$c(e,t):vc(e,e.inputs,t)}});var xc,Hi,ji=K(()=>{\"use strict\";St();ge();Wt();Zr();Ln();wr();xc=(e,t=!1,r,o=4)=>{let a=ze(o,\"f32\"),u=O=>{switch(O){case 1:return\"return W[getIndexFromCoords4D(coord, wShape)];\";case 4:return`\n            let coord1 = vec4<i32>(coordX, coordY, col + 1, rowInner);\n            let coord2 = vec4<i32>(coordX, coordY, col + 2, rowInner);\n            let coord3 = vec4<i32>(coordX, coordY, col + 3, rowInner);\n            let v0 = W[getIndexFromCoords4D(coord, wShape)];\n            let v1 = W[getIndexFromCoords4D(coord1, wShape)];\n            let v2 = W[getIndexFromCoords4D(coord2, wShape)];\n            let v3 = W[getIndexFromCoords4D(coord3, wShape)];\n            return vec4<f32>(v0, v1, v2, v3);\n            `;default:throw new Error(`innerElementSize ${O} is not supported.`)}},i=e?`\n      let coord = vec4<i32>(batch, iXR, iXC, xCh);\n      `:`\n      let coord = vec4<i32>(batch, xCh, iXR, iXC);\n      `,d=e?`\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    `:`\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    `,f=e?\"outBackprop[1]\":\"outBackprop[2]\",h=e?\"outBackprop[2]\":\"outBackprop[3]\",c=e?\"row\":\"col\",C=e?\"col\":\"row\",b=`\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      let outRow = ${c} / outWidth;\n      let outCol = ${c} % outWidth;\n\n      let WRow = ${C} / (filterDims[1] * inChannels);\n      let WCol = ${C} / inChannels % filterDims[1];\n      let xR = f32(outRow - pads[0] + dilation[0] * WRow) / f32(strides[0]);\n      let xC = f32(outCol - pads[1] + dilation[1] * WCol) / f32(strides[1]);\n      if (xR < 0.0 || xR >= f32(${f}) || fract(xR) > 0.0) {\n        return ${a}(0.0);\n      }\n      if (xC < 0.0 || xC >= f32(${h}) || fract(xC) > 0.0) {\n        return ${a}(0.0);\n      }\n      let iXR = i32(xR);\n      let iXC = i32(xC);\n      let xCh = ${C} % inChannels;\n      ${i}\n      return x[getIndexFromCoords4D(coord, xShape)/${o}];`,$=e?`\n      let col = colIn * ${o};\n      if (row < dimAOuter && col < dimInner) {\n        ${b}\n      }\n      return ${a}(0.0);`:`\n      let col = colIn * ${o};\n      if (row < dimInner && col < dimBOuter) {\n        ${b}\n      }\n      return ${a}(0.0);`,S=`\n      let col = colIn * ${o};\n      let inChannels = ${e?\"outBackprop[3]\":\"outBackprop[1]\"};\n      let coordX = filterDims.x - 1 - row / (filterDims[1] * inChannels);\n      let coordY = filterDims.y - 1 - (row / inChannels) % filterDims[1];\n      if (${e?\"row < dimInner && col < dimBOuter\":\"row < dimInner && col < dimAOuter\"}  && coordX >= 0 && coordY >= 0) {\n        let rowInner = row % inChannels;\n        let coord = vec4<i32>(coordX, coordY, col, rowInner);\n        ${u(o)}\n      }\n      return ${a}(0.0);\n      `,{activationFunction:x,applyActivation:A}=It(r,a);return`\n      ${x}\n  fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${a} {\n    ${e?$:S}\n  }\n\n  fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${a} {\n    ${e?S:$}\n  }\n\n  fn mm_write(batch: i32, row : i32, colIn : i32, valueInput : ${a}) {\n    let col = colIn * ${o};\n    if (row < dimAOuter && col < dimBOuter) {\n      var value = valueInput;\n      let outWidth = ${e?\"outShape[2]\":\"outShape[3]\"};\n      ${d}\n      ${Xr(t)}\n      ${A}\n      result[getIndexFromCoords4D(coords, outShape)/${o}] = value;\n    }\n  }`},Hi=(e,t,r,o,a,u,i,d)=>{let f=t.format===\"NHWC\",h=f?e[0].dims[3]:e[0].dims[1],c=r[0],C=f?r[2]:r[3],b=f?r[1]:r[2],$=f?r[3]:r[1],S=f?h%4===0&&$%4===0:C%4===0&&$%4===0,x=f?$:C*b,A=f?C*b:$,k=S?[8,8,1]:[x<=4||A<=4?4:16,x>4&&A<=4?4:16,1],O=S?[4,4,1]:[x<=4?1:4,x>4&&A<=4?1:4,1],P=[Math.ceil(x/k[0]/O[0]),Math.ceil(A/k[1]/O[1]),Math.ceil(c/k[2]/O[2])];Ee(\"verbose\",()=>`[conv_backprop_mm_webgpu] dispatch = ${P}`);let R=S?4:1,V=Math.max(k[0]*R,k[1]),B=[`@group(0) @binding(0) var<storage, read> x: array<${S?\"vec4<f32>\":\"f32\"}>;`,\"@group(0) @binding(1) var<storage, read> W: array<f32>;\"],W=\"\";return i&&(B.push(`@group(0) @binding(2) var<storage, read> bias: array<${S?\"vec4<f32>\":\"f32\"}>;`),W+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${S?\"vec4<f32>\":\"f32\"} {\n          return bias[coords.${f?\"w\":\"y\"}${S?\"/ 4\":\"\"}];\n        }`),{name:\"Conv2DTransposeMatMul\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:P[0],y:P[1],z:P[2]}}),getShaderSource:()=>`\n        ${Qr}\n        ${B.join(`\n`)}\n        @group(0) @binding(${B.length}) var<storage, read_write> result: array<${S?\"vec4<f32>\":\"f32\"}>;\n        const outBackprop : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const xShape : vec4<i32> = vec4<i32>(${e[0].dims.join(\",\")});\n        const wShape : vec4<i32> = vec4<i32>(${e[1].dims.join(\",\")});\n        const outShape : vec4<i32> = vec4<i32>(${r.join(\",\")});\n        const outShapeStrides : vec3<i32> = vec3<i32>(${z.computeStrides(r).slice(0,3).join(\",\")});\n        const filterDims : vec2<i32> = vec2<i32>(${t.kernelShape[f?1:2]}, ${t.kernelShape[f?2:3]});\n        const effectiveFilterDims : vec2<i32> = filterDims + vec2<i32>(\n              ${t.dilations[0]<=1?0:(t.kernelShape[f?1:2]-1)*(t.dilations[0]-1)},\n              ${t.dilations[1]<=1?0:(t.kernelShape[f?2:3]-1)*(t.dilations[1]-1)});\n        const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${t.pads[0]+t.pads[2]})/2,\n                                         i32(effectiveFilterDims[1]) - 1 - (${t.pads[1]+t.pads[3]})/2);\n        const strides : vec2<i32> = vec2<i32>(${t.strides[0]}, ${t.strides[1]});\n        const dilation : vec2<i32> = vec2<i32>(${t.dilations[0]}, ${t.dilations[1]});\n        const dimAOuter : i32 = ${o};\n        const dimBOuter : i32 = ${a};\n        const dimInner : i32 = ${u};\n        ${W}\n        ${xc(f,i,t,R)}\n        ${S?yr(O,k,\"f32\",void 0,!f,V):br(O,k,\"f32\",void 0,!f,V,!1,void 0,d)}`}}});var Sc,Jn,qi=K(()=>{\"use strict\";St();ge();$e();Sc=(e,t,r,o,a,u,i=!1,d)=>{let f=r.format===\"NHWC\",h=f?1:2,c=f?2:3,C=f?3:1,b=z.size(o),$=i?2:1,S=r.group,x=t[1].dims,A=x[0]/S,k=x[1],O=`\n  fn setOutputAtIndex(flatIndex : u32, value : ${i?`vec4<${d}>`:d}) {\n    result[flatIndex] = ${i?`vec4<${d}>`:d}(value);\n  }`;a&&(O+=`\n    fn getBiasByOutputCoords(coords : vec4<u32>) -> ${i?`vec4<${d}>`:d} {\n      return bias[coords.${f?\"w\":\"y\"}${i?\"/ 4\":\"\"}];\n    }`);let P=i?4:1,R=H(\"W\",t[1].dataType,t[1].dims,P),V=H(\"Dy\",t[0].dataType,t[0].dims,P),B=[V,R];a&&B.push(H(\"bias\",t[2].dataType,[o[C]],P));let W=Y(\"result\",t[0].dataType,o,P),q=`{\n        let batch: u32 = ${u?\"global_id.z\":\"workgroup_id.z\"} / outShape[1];\n        let r = ${u?\"global_id.z\":\"workgroup_id.z\"} % outShape[1];\n        let c = ${u?\"global_id.y\":\"workgroup_id.y\"} * ${$};\n        let d1: u32 = ${u?\"global_id.x\":\"workgroup_id.x\"} * 4;\n\n        let dyCorner = vec2<i32>(i32(r), i32(c)) - vec2<i32>(pads);\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        var dotProd: array<vec4<${d}>, ${$}>;\n        for (var i = 0; i < ${$}; i++) {\n          dotProd[i] = vec4<${d}>(0.0);\n        }\n        for (var wR: u32 = 0; wR < filterDims[0]; wR = wR + 1) {\n          var dyR = (${d}(dyCorner.x) + ${d}(wR)) / ${d}(strides.x);\n          let wRPerm = filterDims[0] - 1 - wR;\n          if (dyR < 0.0 || dyR >= ${d}(outBackprop[1]) ||\n              fract(dyR) > 0.0 || wRPerm < 0) {\n            continue;\n          }\n          let idyR: u32 = u32(dyR);\n\n          for (var wC: u32 = 0; wC < filterDims[1]; wC = wC + 1) {\n            let dyC = (${d}(dyCorner.y) + ${d}(wC)) / ${d}(strides.y);\n            let dyC2 = (${d}(dyCorner.y) + 1.0 + ${d}(wC)) / ${d}(strides.y);\n            let wCPerm = filterDims[1] - 1 - wC;\n            if (wCPerm < 0) {\n              continue;\n            }\n            var bDyCVal = true;\n            var bDyCVal2 = true;\n            if (dyC < 0.0 || dyC >= ${d}(outBackprop[2]) ||\n                fract(dyC) > 0.0) {\n              bDyCVal = false;\n            }\n            if (dyC2 < 0.0 || dyC2 >= ${d}(outBackprop[2]) ||\n                fract(dyC2) > 0.0) {\n              bDyCVal2 = false;\n            }\n\n            let idyC: u32 = u32(dyC);\n            let idyC2: u32 = u32(dyC2);\n            if (bDyCVal && bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2 :u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${V.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n\n                xValue =  ${V.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n\n                dotProd[1] = dotProd[1] + vec4<${d}>(dot(xValue, wValue0),\n                                                    dot(xValue, wValue1),\n                                                    dot(xValue, wValue2),\n                                                    dot(xValue, wValue3));\n              }\n            } else if (bDyCVal) {\n              let d2Length = outBackprop[${C}];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${V.get(\"batch\",\"idyR\",\"idyC\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[0] = dotProd[0] + tmpval;\n              }\n            } else if (bDyCVal2) {\n              let d2Length = outBackprop[3];\n              for (var d2: u32 = 0; d2 < d2Length; d2 = d2 + 4) {\n                let wValue0 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1\",\"d2\")};\n                let wValue1 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 1\",\"d2\")};\n                let wValue2 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 2\",\"d2\")};\n                let wValue3 = ${R.get(\"u32(wRPerm)\",\"u32(wCPerm)\",\"d1 + 3\",\"d2\")};\n\n                var xValue = ${V.get(\"batch\",\"idyR\",\"idyC2\",\"d2\")};\n                let tmpval = vec4<${d}>(dot(xValue, wValue0),\n                                      dot(xValue, wValue1),\n                                      dot(xValue, wValue2),\n                                      dot(xValue, wValue3));\n                dotProd[1] = dotProd[1] + tmpval;\n              }\n            }\n          }\n        }\n\n        for (var i: u32 = 0; i < ${$}; i = i + 1) {\n          let value = dotProd[i] + ${a?\"bias[c+i]\":\"0.0\"};\n          ${W.set(\"batch\",\"r\",\"c + i\",\"d1\",\"value\")};\n        }\n      }`,ee=`\n          let outputIndices = ${W.offsetToIndices(\"global_idx\")};\n          let batch = ${W.indicesGet(\"outputIndices\",0)};\n          let d1 = ${W.indicesGet(\"outputIndices\",C)};\n          let r = ${W.indicesGet(\"outputIndices\",h)};\n          let c = ${W.indicesGet(\"outputIndices\",c)};\n          let dyCorner = vec2<i32>(i32(r), i32(c)) - pads;\n          let dyRCorner = dyCorner.x;\n          let dyCCorner = dyCorner.y;\n          let groupId = d1 / ${k};\n          let wOutChannel = d1 - groupId * ${k};\n          // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n          // ? = to be determined. : = across all values in that axis.\n          var dotProd = 0.0;\n          for (var wR: u32 = 0; wR < effectiveFilterDims.x; wR = wR + 1) {\n            if (wR % dilations.x != 0) {\n              continue;\n            }\n            let dyR = (${d}(dyRCorner) + ${d}(wR)) / ${d}(strides[0]);\n            let wRPerm = filterDims.x - 1 - wR / dilations.x;\n            if (dyR < 0.0 || dyR >= ${d}(outBackprop[${h}]) || fract(dyR) > 0.0 ||\n                wRPerm < 0) {\n              continue;\n            }\n            let idyR: u32 = u32(dyR);\n\n            for (var wC: u32 = 0; wC < effectiveFilterDims.y; wC = wC + 1) {\n              if (wC % dilations.y != 0) {\n                continue;\n              }\n              let dyC = (${d}(dyCCorner) + ${d}(wC)) / ${d}(strides.y);\n              let wCPerm = filterDims.y - 1 - wC / dilations.y;\n              if (dyC < 0.0 || dyC >= ${d}(outBackprop[${c}]) ||\n                  fract(dyC) > 0.0 || wCPerm < 0) {\n                continue;\n              }\n              let idyC: u32 = u32(dyC);\n              var inputChannel = groupId * ${A};\n              for (var d2: u32 = 0; d2 < ${A}; d2 = d2 + 1) {\n                let xValue = ${f?V.get(\"batch\",\"idyR\",\"idyC\",\"inputChannel\"):V.get(\"batch\",\"inputChannel\",\"idyR\",\"idyC\")};\n                let wValue = ${R.get(\"inputChannel\",\"wOutChannel\",\"u32(wRPerm)\",\"u32(wCPerm)\")};\n                dotProd = dotProd + xValue * wValue;\n                inputChannel = inputChannel + 1;\n              }\n            }\n          }\n          let value = dotProd + ${a?\"bias[d1]\":\"0.0\"};\n          ${W.setByOffset(\"global_idx\",\"value\")};\n        `;return`\n  ${e.declareVariables(...B,W)}\n  ${O}\n  const outShape : vec4<u32> = vec4<u32>(${o.join(\",\")});\n  const outBackprop : vec4<u32> = vec4<u32>(${t[0].dims.join(\",\")});\n  const strides : vec2<u32> = vec2<u32>(${r.strides[0]}, ${r.strides[1]});\n  const filterDims : vec2<u32> = vec2<u32>(${r.kernelShape[f?1:2]}, ${r.kernelShape[f?2:3]});\n  const dilations : vec2<u32> = vec2<u32>(${r.dilations[0]}, ${r.dilations[1]});\n  const effectiveFilterDims : vec2<u32> = filterDims + vec2<u32>(\n          ${r.dilations[0]<=1?0:(r.kernelShape[f?1:2]-1)*(r.dilations[0]-1)},\n          ${r.dilations[1]<=1?0:(r.kernelShape[f?2:3]-1)*(r.dilations[1]-1)});\n  const pads : vec2<i32> = vec2<i32>(i32(effectiveFilterDims[0]) - 1 - (${r.pads[0]+r.pads[2]})/2,\n                                     i32(effectiveFilterDims[1]) - 1 - (${r.pads[1]+r.pads[3]})/2);\n    ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(b)};\n  ${i?q:ee}}`},Jn=(e,t,r)=>{let o=e.length>2,a=t.outputShape,u=z.size(a),i=[Math.ceil(u/64),1,1];Ee(\"verbose\",()=>`[conv2d_backprop_webgpu] dispatch = ${i}`);let d=ke(e[0].dataType);return{name:\"ConvTranspose2D\",shaderCache:{hint:t.cacheKey},getRunData:()=>({dispatchGroup:{x:i[0],y:i[1],z:i[2]},outputs:[{dims:r?r(a):a,dataType:e[0].dataType}]}),getShaderSource:f=>Sc(f,e,t,a,o,i[1]===1&&i[2]===1,!1,d)}}});var Cc,Ac,Ic,Ki,Yi,Tc,Oc,Ec,_c,Ji,Xi=K(()=>{\"use strict\";Me();ji();qi();Wt();gr();Cc=(e,t,r,o,a,u)=>(e-1)*t+r+(o-1)*a+1-u,Ac=(e,t,r,o,a)=>{let u=Math.floor(e/2);t===\"SAME_UPPER\"?(r[o]=u,r[a]=e-u):t===\"SAME_LOWER\"&&(r[o]=e-u,r[a]=u)},Ic=(e,t,r,o,a,u,i,d,f,h)=>{let c=e.length-2,C=h.length===0;if(f.length===0)for(let S=0;S<c;++S)f.push(0);let b=e[0],$=t[d?3:1]*a;for(let S=0,x=e.length-c-(d?1:0);S<c;++S,++x){let A=e[x],k=C?A*i[S]:h[S],O=Cc(A,i[S],u[S],t[x],r[S],k);Ac(O,o,u,S,S+c),C&&h.push(i[S]*(A-1)+f[S]+(t[x]-1)*r[S]+1-u[S]-u[S+c])}h.splice(0,0,b),h.splice(d?3:1,0,$)},Ki=(e,t)=>{let r=e.kernelShape.slice();if(e.kernelShape.length===0||e.kernelShape.reduce((b,$)=>b*$,1)===0){r.length=0;for(let b=2;b<t[1].dims.length;++b)r.push(t[1].dims[b])}let o=e.format===\"NHWC\";r.splice(0,0,t[1].dims[0]),r.splice(o?3:1,0,t[1].dims[1]);let a=e.pads.slice(),u=e.outputShape.slice(),i=e.outputPadding.slice(),d=t[0].dims,f=e.dilations.slice();if(f.reduce((b,$)=>b+$,0)===0){let b=t[0].dims.length-2;f=new Array(b).fill(1)}let h=e.strides.slice();if(h.reduce((b,$)=>b+$,0)===0){let b=t[0].dims.length-2;h=new Array(b).fill(1)}Ic(d,r,f,e.autoPad,e.group,a,h,o,i,u);let c=Object.assign({},e),C=e.cacheKey+[r.join(\"n,\"),a.join(\",\"),h.join(\",\"),i.join(\",\"),u.join(\",\"),f.join(\",\")].join(\"_\");return Object.assign(c,{kernelShape:r,pads:a,outputPadding:i,outputShape:u,dilations:f,strides:h,cacheKey:C}),c},Yi=e=>{let t=Jr(e),r=e.format,o=[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][typeof e.autoPad>\"u\"?0:e.autoPad],a=e.dilations,u=e.group,i=e.kernelShape,d=e.pads,f=e.strides,h=e.wIsConst(),c=e.outputPadding,C=e.outputShape;return ue({autoPad:o,format:r,dilations:a,group:u,kernelShape:i,outputPadding:c,outputShape:C,pads:d,strides:f,wIsConst:h,...t})},Tc=(e,t)=>{if(!e||e.length!==2&&e.length!==3)throw new Error(\"Conv requires 2 or 3 inputs\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"currently only support 2-dimensional conv\");if(e[0].dims.length!==e[1].dims.length)throw new Error(\"filter does not have same dimension as input\");let r=e[0].dims[t.format===\"NHWC\"?e[0].dims.length-1:1],o=e[1].dims[0];if(r!==o)throw new Error(\"FILTER_IN_CHANNEL should be equal to DATA_CHANNEL\");let a=e[1].dims[1]*t.group;if(e.length===3&&(e[2].dims.length!==1||e[2].dims[0]!==a))throw new Error(\"invalid bias\");let u=e[0].dims.length-2;if(t.dilations.reduce((c,C)=>c+C,0)>0&&t.dilations.length!==u)throw new Error(`dilations should be ${u}D`);if(t.strides.reduce((c,C)=>c+C,0)>0&&t.strides.length!==u)throw new Error(`strides should be ${u}D`);if(t.pads.reduce((c,C)=>c+C,0)>0&&t.pads.length!==u*2)throw new Error(`pads should be ${u*2}D`);if(t.outputPadding.length!==u&&t.outputPadding.length!==0)throw new Error(`output_padding should be ${u}D`);if(t.kernelShape.reduce((c,C)=>c+C,0)>0&&t.kernelShape.length!==0&&t.kernelShape.length!==e[1].dims.length-2)throw new Error(\"invalid kernel shape\");if(t.outputShape.length!==0&&t.outputShape.length!==e[0].dims.length-2)throw new Error(\"invalid output shape\")},Oc=[2,3,1,0],Ec=(e,t,r)=>{let o=Ki(r,t),a=r.format===\"NHWC\",u=t.length===3;if(o.group!==1){e.compute(Jn(t,o));return}let i=o.outputShape,d=i[a?1:2],f=i[a?2:3],h=i[a?3:1],c=t[1].dims[2],C=t[1].dims[3],b=t[0].dims[a?3:1],$=a?d*f:h,S=a?h:d*f,x=c*C*b,A=!0,k=e.kernelCustomData.wT??e.compute(At(t[1],Oc),{inputs:[1],outputs:[r.wIsConst?-2:-1]})[0];r.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=k);let O=[t[0],k];u&&(!a&&t[2].dims.length===1?O.push(t[2].reshape([t[2].dims[0],1,1])):O.push(t[2])),e.compute(Hi(O,o,i,$,S,x,u,A),{inputs:O})},_c=(e,t)=>{let r=t.format===\"NHWC\",o=[e.inputs[0].reshape(r?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];o.length===3&&o.push(e.inputs[2]);let a=t.kernelShape;(a.length===0||a[0]===0)&&(a=[e.inputs[1].dims[2]]);let u=t.dilations;(u.length===0||u[0]===0)&&(u=[1]);let i=t.strides;(i.length===0||i[0]===0)&&(i=[1]);let d=t.pads;d.length===0&&(d=[0,0]),d=[0,d[0],0,d[1]],i=[1].concat(i),u=[1].concat(u),a=[1].concat(a);let f=Ki({...t,pads:d,strides:i,dilations:u,kernelShape:a},o);e.compute(Jn(o,f,h=>r?[h[0],h[2],h[3]]:[h[0],h[1],h[3]]))},Ji=(e,t)=>{Tc(e.inputs,t),e.inputs[0].dims.length===3?_c(e,t):Ec(e,e.inputs,t)}});var Xn,tn,Zi,Pc,Rc,Zn,Qn,Mc,Qi,es,ts=K(()=>{\"use strict\";ge();Me();$e();Xn=\"[a-zA-Z]|\\\\.\\\\.\\\\.\",tn=\"(\"+Xn+\")+\",Zi=\"^\"+tn+\"$\",Pc=\"(\"+tn+\",)*\"+tn,Rc=\"^\"+Pc+\"$\",Zn=class{constructor(t=-1){this.symbolToIndices=new Map,this.inputIndex=t}addSymbol(t,r){let o=this.symbolToIndices.get(t);o===void 0?o=[r]:o.push(r),this.symbolToIndices.set(t,o)}},Qn=class{constructor(t,r){this.equation=r;this.hasEllipsis=!1,this.symbolToInfo=new Map,this.lhs=new Array,this.outputDims=[];let[o,a]=r.includes(\"->\")?r.split(\"->\",2):[r,\"\"];if(!o.match(RegExp(Rc)))throw new Error(\"Invalid LHS term\");if(o.split(\",\").forEach((d,f)=>{let h=t[f].dims.slice();if(!d.match(RegExp(Zi)))throw new Error(\"Invalid LHS term\");let c=this.processTerm(d,!0,h,f);this.lhs.push(c)}),a===\"\")a+=[...this.symbolToInfo.entries()].filter(([d,f])=>f.count===1||d===\"...\").map(([d])=>d).join(\"\");else if(!a.match(RegExp(tn)))throw new Error(\"Invalid RHS\");a.match(RegExp(Xn,\"g\"))?.forEach(d=>{if(d===\"...\")this.outputDims=this.outputDims.concat(this.ellipsisDims);else{let f=this.symbolToInfo.get(d);if(f===void 0)throw new Error(\"Invalid RHS symbol\");this.outputDims.push(f.dimValue)}}),this.rhs=this.processTerm(a,!0,this.outputDims)}addSymbol(t,r,o){let a=this.symbolToInfo.get(t);if(a!==void 0){if(a.dimValue!==r&&a.count!==1)throw new Error(\"Dimension mismatch\");a.count++,a.inputIndices.push(o)}else a={count:1,dimValue:r,inputIndices:[o]};this.symbolToInfo.set(t,a)}processTerm(t,r,o,a=-1){let u=o.length,i=!1,d=[],f=0;if(!t.match(RegExp(Zi))&&!r&&t!==\"\")throw new Error(\"Invalid LHS term\");let h=t.match(RegExp(Xn,\"g\")),c=new Zn(a);return h?.forEach((C,b)=>{if(C===\"...\"){if(i)throw new Error(\"Only one ellipsis is allowed per input term\");i=!0;let $=u-h.length+1;if($<0)throw new Error(\"Ellipsis out of bounds\");if(d=o.slice(f,f+$),this.hasEllipsis){if(this.ellipsisDims.length!==d.length||this.ellipsisDims.toString()!==d.toString())throw new Error(\"Ellipsis dimensions mismatch\")}else if(r)this.hasEllipsis=!0,this.ellipsisDims=d;else throw new Error(\"Ellipsis must be specified in the LHS\");for(let S=0;S<d.length;S++){let x=String.fromCharCode(\"0\".charCodeAt(0)+b);c.addSymbol(x,b+S),this.addSymbol(x,o[f++],a)}}else c.addSymbol(C,b),this.addSymbol(C,o[f++],a)}),c}},Mc=(e,t)=>{let r=e[0].dataType,o=new Array(e.length);for(let P=0;P<e.length;++P)o[P]=H(`input${P}`,r,e[P].dims);let a=t.outputDims,u=z.size(a),i=Y(\"output\",r,a),d=[],f=Array.from(t.rhs.symbolToIndices.keys()),h=\"var prod = 1.0;\",c=\"var sum = 0.0;\",C=\"sum += prod;\",b=[],$=[],S=[],x=[],A=t.symbolToInfo.size===f.length;t.symbolToInfo.forEach((P,R)=>{if(f.includes(R)){let V=f.indexOf(R);t.lhs.forEach((B,W)=>{if(P.inputIndices.includes(W)){let q=B.symbolToIndices.get(R);if(q===void 0)throw new Error(\"Invalid symbol error\");q.forEach(ee=>{d.push(`${o[W].indicesSet(`input${W}Indices`,ee,i.indicesGet(\"outputIndices\",V))}`)})}})}else t.lhs.forEach((V,B)=>{let W=t.symbolToInfo.get(R);if(W===void 0)throw new Error(\"Invalid symbol error\");if(W.inputIndices.includes(B)){let q=V.symbolToIndices.get(R);if(q===void 0)throw new Error(\"Invalid symbol error\");q.forEach(ee=>{b.push(`${o[B].indicesSet(`input${B}Indices`,ee,`${R}`)}`)}),x.push(`prod *= ${o[B].getByIndices(`input${B}Indices`)};`)}}),$.push(`for(var ${R}: u32 = 0; ${R} < ${t.symbolToInfo.get(R)?.dimValue}; ${R}++) {`),S.push(\"}\")});let k=A?[...d,`let sum = ${o.map((P,R)=>P.getByIndices(`input${R}Indices`)).join(\" * \")};`]:[...d,c,...$,...b,h,...x,C,...S],O=P=>`\n      ${P.declareVariables(...o,i)}\n\n      ${P.mainStart()}\n        ${P.guardAgainstOutOfBoundsWorkgroupSizes(u)}\n        var outputIndices = ${i.offsetToIndices(\"global_idx\")};\n        ${o.map((R,V)=>`var input${V}Indices: ${o[V].type.indices};`).join(`\n`)}\n        ${k.join(`\n`)};\n        ${i.setByOffset(\"global_idx\",\"sum\")};\n      }`;return{name:\"Einsum\",shaderCache:{hint:t.equation},getRunData:()=>({outputs:[{dims:a,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(u/64)}}),getShaderSource:O}},Qi=(e,t)=>{let r=new Qn(e.inputs,t.equation);e.compute(Mc(e.inputs,r))},es=e=>{let t=e.equation.replace(/\\s+/g,\"\");return ue({equation:t})}});var kc,rs,Bc,Dc,ns,os=K(()=>{\"use strict\";ge();$e();kc=e=>{if(!e||e.length!==2)throw new Error(\"Expand requires 2 input.\");let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),o=r.length<t.length?0:r.length-t.length,a=t.length<r.length?0:t.length-r.length;for(;o<r.length&&a<t.length;++o,++a)if(r[o]!==t[a]&&r[o]!==1&&t[a]!==1)throw new Error(\"Expand requires shape to be broadcastable to input\")},rs=(e,t)=>{let r=e.length-t.length,o=[];for(let a=0;a<r;++a)o.push(e[a]);for(let a=0;a<t.length;++a)o.push(t[a]===1?e[a+r]:t[a]);return o},Bc=(e,t)=>e.length>t.length?rs(e,t):rs(t,e),Dc=e=>{let t=e[0].dims,r=Array.from(e[1].getBigInt64Array(),Number),o=Bc(t,r),a=z.size(o),u=e[0].dataType,i=H(\"input\",u,t),d=Y(\"output\",u,o),f=h=>`\n  const inputShape = ${i.indices(...t)};\n  ${h.declareVariables(i,d)}\n  ${h.mainStart()}\n  ${h.guardAgainstOutOfBoundsWorkgroupSizes(a)}\n    let outputIndices = ${d.offsetToIndices(\"global_idx\")};\n    var inputIndices: ${i.type.indices};\n    for (var i = 0; i < ${t.length}; i++) {\n      if (${i.indicesGet(\"inputShape\",\"i\")} == 1) {\n        ${i.indicesSet(\"inputIndices\",\"i\",0)}\n      } else {\n        ${i.indicesSet(\"inputIndices\",\"i\",d.indicesGet(\"outputIndices\",`i + ${o.length-t.length}`))}\n      }\n    }\n    ${d.setByOffset(\"global_idx\",i.getByIndices(\"inputIndices\"))}\n  }`;return{name:\"Expand\",shaderCache:{hint:`${o}`},getShaderSource:f,getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)}})}},ns=e=>{kc(e.inputs),e.compute(Dc(e.inputs),{inputs:[0]})}});var Wc,zc,as,is,ss=K(()=>{\"use strict\";ge();Me();$e();Wc=e=>{if(!e||e.length!==2)throw new Error(\"Gather requires 2 inputs.\")},zc=(e,t)=>{let r=e[0].dims,o=e[1].dims,a=r.length,u=z.normalizeAxis(t.axis,a),i=r.slice(0);i.splice(u,1,...o);let d=r[u],f=z.size(i),h=H(\"data\",e[0].dataType,e[0].dims),c=H(\"inputIndices\",e[1].dataType,e[1].dims),C=Y(\"output\",e[0].dataType,i),b=()=>{let S=o.length,x=`var indicesIndices  = ${c.type.indices}(0);`;for(let A=0;A<S;A++)x+=`${S>1?`indicesIndices[${A}]`:\"indicesIndices\"} = ${i.length>1?`outputIndices[${u+A}]`:\"outputIndices\"};`;x+=`\n        var idx = ${c.getByIndices(\"indicesIndices\")};\n        if (idx < 0) {\n          idx = idx + ${d};\n        }\n        var dataIndices = ${h.type.indices}(0);\n      `;for(let A=0,k=0;A<a;A++)A===u?(x+=`${a>1?`dataIndices[${A}]`:\"dataIndices\"} = u32(idx);`,k+=S):(x+=`${a>1?`dataIndices[${A}]`:\"dataIndices\"} = ${i.length>1?`outputIndices[${k}]`:\"outputIndices\"};`,k++);return x},$=S=>`\n      ${S.declareVariables(h,c,C)}\n      ${S.mainStart()}\n        ${S.guardAgainstOutOfBoundsWorkgroupSizes(f)}\n        let outputIndices = ${C.offsetToIndices(\"global_idx\")};\n        ${b()};\n        let value = ${h.getByIndices(\"dataIndices\")};\n        ${C.setByOffset(\"global_idx\",\"value\")};\n      }`;return{name:\"Gather\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:i,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(f/64)}}),getShaderSource:$}},as=e=>ue({axis:e.axis}),is=(e,t)=>{let r=e.inputs;Wc(r),e.compute(zc(e.inputs,t))}});var Vc,Uc,us,ls,cs=K(()=>{\"use strict\";ge();Me();$e();Vc=e=>{if(!e||e.length!==2)throw new Error(\"GatherElements requires 2 inputs.\");if(e[0].dims.length<1)throw new Error(\"GatherElements requires that the data input be rank >= 1.\");if(e[0].dims.length!==e[1].dims.length)throw new Error(`GatherElements requires that the data input and\n                     indices input tensors be of same rank.`)},Uc=(e,t)=>{let r=e[0].dims,o=e[0].dataType,a=r.length,u=z.computeStrides(r),i=z.size(r),d=e[1].dims,f=e[1].dataType,h=z.size(d),c=z.normalizeAxis(t.axis,a),C=r[c],b=d.slice(0),$=z.size(b),S=H(\"input\",o,r),x=H(\"indices\",f,[h]),A=Y(\"output\",o,b),k=O=>`\n      const inputStrides = array<u32, ${u.length}>(${u.map(P=>`${P}u`).join(\",\")});\n      ${O.declareVariables(S,x,A)}\n      ${O.mainStart()}\n      ${O.guardAgainstOutOfBoundsWorkgroupSizes($)}\n\n      let outputIndices = ${A.offsetToIndices(\"global_idx\")};\n\n      var idx = ${x.getByOffset(\"global_idx\")};\n      if (idx < 0) {\n        idx = idx + ${C};\n      }\n\n      var srcOffset = u32(0);\n\n      for (var i = 0; i < ${r.length}; i++) {\n        if (i == ${c}) {\n          srcOffset +=  u32(idx) * inputStrides[i];\n        } else {\n          srcOffset += ${A.indicesGet(\"outputIndices\",\"i\")} * inputStrides[i];\n        }\n      }\n\n      // Should never hit this with valid values in indices\n      // This is a guard against malicious data in the indices input\n      if (srcOffset < 0 || srcOffset >= ${i}) {\n        return;\n      }\n\n      output[global_idx] = input[srcOffset];\n  }`;return{name:\"GatherElements\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:b,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil($/64)}}),getShaderSource:k}},us=e=>ue({axis:e.axis}),ls=(e,t)=>{let r=e.inputs;Vc(r),e.compute(Uc(e.inputs,t))}});var Nc,Gc,Fc,ds,ps,fs=K(()=>{\"use strict\";ge();Me();$e();Nc=e=>{if(!e)throw new Error(\"Input is missing\");if(e.length<2||e.length>3)throw new Error(\"Invaid input number.\");if(e.length===3&&e[2].dims.length>2)throw new Error(\"Invalid input shape of C\");if(e[0].dataType!==e[1].dataType||e.length===3&&e[0].dataType!==e[2].dataType)throw new Error(\"Input types are mismatched\")},Gc=(e,t,r)=>{if(r.length===0)return\"0u\";let o=r.length===1&&e!==1||r.length===2&&r[0]!==e,a=r[r.length-1]!==t,u=\"0u\";return o||(u+=`+ m * ${r[r.length-1]}u`),a||(u+=\"+n\"),u},Fc=(e,t)=>{let r=e[0].dims.slice(),o=e[1].dims.slice(),[a,u,i]=Fr.getShapeOfGemmResult(r,t.transA,o,t.transB,e.length===3?e[2].dims:void 0),d=[a,u];if(!d)throw new Error(\"Can't use gemm on the given tensors\");let f=z.size(d),h=\"\";t.transA&&t.transB?h=\"value += a[k * M + m] * b[n * K + k];\":t.transA&&!t.transB?h=\"value += a[k * M + m] * b[k * N + n];\":!t.transA&&t.transB?h=\"value += a[m * K + k] * b[n * K + k];\":!t.transA&&!t.transB&&(h=\"value += a[m * K + k] * b[k * N + n];\");let c=ke(e[0].dataType),C=t.alpha===1?\"\":\"value *= alpha;\",b=e.length===3?`value += beta * c[${Gc(a,u,e[2].dims)}];`:\"\",$=[`@group(0) @binding(0) var<storage, read> a : array<${c}>;`,`@group(0) @binding(1) var<storage, read> b : array<${c}>;`];e.length===3&&$.push(`@group(0) @binding(2) var<storage, read> c : array<${c}>;`);let S=x=>`\n  const M: u32 = ${a}u;\n  const N: u32 = ${u}u;\n  const K: u32 = ${i}u;\n  const alpha = ${c}(${t.alpha});\n  const beta = ${c}(${t.beta});\n\n  ${$.join(`\n`)}\n  @group(0) @binding(${e.length}) var<storage, read_write> output : array<${c}>;\n\n  ${x.mainStart()}\n    ${x.guardAgainstOutOfBoundsWorkgroupSizes(f)}\n\n    let m = global_id.x / N;\n    let n = global_id.x % N;\n\n    var value = ${c}(0);\n    for (var k: u32 = 0u; k<${i}u; k++) {\n      ${h}\n    }\n\n    ${C}\n    ${b}\n    output[global_id.x] = value;\n\n  }`;return{name:\"Gemm\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:d,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(f/64)}}),getShaderSource:S}},ds=(e,t)=>{Nc(e.inputs),e.compute(Fc(e.inputs,t))},ps=e=>ue(e)});var Lc,Hc,jc,qc,ms,hs,gs=K(()=>{\"use strict\";We();ge();Me();$e();Lc={name:\"InstanceNormalization\"},Hc=(e,t)=>{let r=e[0].dims,o=r,a=2,u=z.sizeToDimension(r,a),i=z.sizeFromDimension(r,a),d=r[1],f=H(\"x\",e[0].dataType,[r[0],r[1],i]),h=H(\"scale\",e[1].dataType,e[1].dims),c=H(\"bias\",e[2].dataType,e[2].dims),C=Y(\"output\",e[0].dataType,[r[0],r[1],i]),b=[f,h,c,C],$=f.type.value,S=64,x=A=>`\n\n  const C: u32 = ${d};\n  const normSize: u32 = ${i};\n  const epsilon: f32 = ${t.epsilon};\n  var<workgroup> meanShared : ${$};\n  var<workgroup> squaredNormShared : ${$};\n  var<workgroup> workgroupShared : array<${$}, ${S}>;\n  const workgroupSize = ${S}u;\n  ${A.declareVariables(...b)}\n  ${A.mainStart(S)}\n    let norm = global_idx / workgroupSize;\n    let batch = norm / C;\n    let channel = norm % C;\n    let localIndex = local_id.x;\n\n    // initialize workgroup memory\n    var initial: ${$} = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      initial = initial + ${f.get(\"batch\",\"channel\",\"h\")};\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the mean of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      meanShared = workgroupShared[0] / ${$}(normSize);\n    }\n    workgroupBarrier();\n\n    // reinitialize workgroup memory.\n    initial = 0;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let deviation =  ${f.get(\"batch\",\"channel\",\"h\")} - meanShared;\n      initial = initial + deviation * deviation;\n    }\n    workgroupShared[localIndex] = initial;\n    workgroupBarrier();\n\n    // Calculate the sum of square of deviation of current channel data.\n    for (var currSize = workgroupSize >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (localIndex < currSize) {\n        workgroupShared[localIndex] = workgroupShared[localIndex] + workgroupShared[localIndex + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (localIndex == 0) {\n      squaredNormShared = workgroupShared[0];\n    }\n    workgroupBarrier();\n\n    let invStdDev = 1 / sqrt(squaredNormShared / ${$}(normSize) + epsilon);\n    let channelScale = invStdDev * ${h.getByOffset(\"channel\")};\n    let channelShift = ${c.getByOffset(\"channel\")} - meanShared * channelScale;\n    for (var h = localIndex; h < normSize; h += workgroupSize) {\n      let value = ${f.get(\"batch\",\"channel\",\"h\")} * channelScale + channelShift;\n      ${C.set(\"batch\",\"channel\",\"h\",\"value\")};\n    }\n  }`;return{...Lc,shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:u}}),getShaderSource:x}},jc=(e,t,r,o,a,u,i,d)=>{let f=bt(i),h=H(\"input\",t.dataType,t.dims,f),c=H(\"scale\",r.dataType,r.dims,f),C=H(\"bias\",o.dataType,o.dims,f),b=64,$=f===1?\"vec2f\":`mat2x${f}f`,S=f===1?\"f32\":`vec${f}f`,x=(V,B)=>`${$}(${V}, ${B})`,A=a*i/f,k=Math.ceil(u/b),O=V=>`\n  const H: u32 = ${u};\n  const C: u32 = ${i/f};\n  const imageSize: u32 = ${u*i/f};\n\n  ${V.declareVariables(h)}\n  @group(0) @binding(1) var<storage, read_write> output : array<${$}>;\n\n  ${V.mainStart(b)}\n    let currentImageNumber = global_idx / ${b} / C;\n    let currentChannelNumber = (global_idx / ${b}) % C;\n    let wgId = global_idx % ${b};\n    let wgOffset = wgId * ${k};\n    if (wgOffset >= H) {\n        return;\n    }\n    let wgMax = min(wgOffset + ${k}, H);\n\n    let offset = currentImageNumber * imageSize + currentChannelNumber;\n    var sum = ${tt(\"f32\",f)};\n    var squaredSum = ${tt(\"f32\",f)};\n    for (var i: u32 = wgOffset; i < wgMax; i++) {\n        let value = ${S}(input[offset + i * C]);\n        sum += value;\n        squaredSum += value * value;\n    }\n    output[global_idx] = ${x(\"sum\",\"squaredSum\")};\n  }`,P=e.compute({name:\"InstanceNormComputeMean\",shaderCache:{hint:JSON.stringify({components:f,n:a,h:u,c:i})},getRunData:()=>({outputs:[{dims:[a,i,b,2],dataType:1}],dispatchGroup:{x:a*i/f}}),getShaderSource:O},{inputs:[t],outputs:[-1]})[0],R=V=>`\n  const H: u32 = ${u};\n  const C: u32 = ${i/f};\n  const imageSize: u32 = ${b*i/f};\n  const epsilon: f32 = ${d};\n\n  @group(0) @binding(0) var<storage, read> input : array<${$}>;\n  @group(0) @binding(1) var<storage, read> scale : array<${c.type.storage}>;\n  @group(0) @binding(2) var<storage, read> bias : array<${C.type.storage}>;\n  @group(0) @binding(3) var<storage, read_write> output : array<${$}>;\n\n  ${V.mainStart()}\n    ${V.guardAgainstOutOfBoundsWorkgroupSizes(A)}\n    let currentImageNumber = global_idx / C;\n    let currentChannelNumber = global_idx % C;\n\n    let offset = currentImageNumber * imageSize;\n    var sum = ${tt(\"f32\",f)};\n    var squaredSum = ${tt(\"f32\",f)};\n    for (var i: u32 = 0; i < ${b}; i++) {\n        let value = input[offset + i + currentChannelNumber * ${b}];\n        sum += value[0];\n        squaredSum += value[1];\n    }\n    sum = sum / f32(H);\n    squaredSum = squaredSum / f32(H);\n    let invStdDev = 1 / sqrt(squaredSum - sum * sum + epsilon);\n    let channelScale = invStdDev * ${S}(scale[currentChannelNumber]);\n    let channelShift = ${S}(bias[currentChannelNumber]) - sum * channelScale;\n\n    output[global_idx] = ${x(\"channelScale\",\"channelShift\")};\n  }`;return e.compute({name:\"InstanceNormComputeChannelScaleShift\",shaderCache:{hint:JSON.stringify({components:f,n:a,h:u,c:i,epsilon:d})},getRunData:()=>({outputs:[{dims:[a,i,2],dataType:1}],dispatchGroup:{x:Math.ceil(A/64)}}),getShaderSource:R},{inputs:[P,r,o],outputs:[-1]})[0]},qc=(e,t,r)=>{let o=t[0].dims,a=o,u=o[0],i=o[o.length-1],d=z.sizeFromDimension(o,1)/i,f=bt(i),h=z.size(a)/f,c=H(\"input\",t[0].dataType,t[0].dims,f),C=Y(\"output\",t[0].dataType,a,f),b=ke(t[0].dataType),$=f===1?\"vec2f\":`mat2x${f}f`,S=f===1?b:`vec${f}<${b}>`,x=jc(e,t[0],t[1],t[2],u,d,i,r.epsilon),A=k=>`\n  const H: u32 = ${d};\n  const C: u32 = ${i/f};\n\n  @group(0) @binding(0) var<storage, read> input : array<${c.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scaleInput : array<${$}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${C.type.storage}>;\n\n  ${k.mainStart()}\n    let currentImageNumber = global_idx / (C * H);\n    let currentChannelNumber = global_idx % C;\n\n    let scaleOffset = currentImageNumber * C + currentChannelNumber;\n    let scale = scaleInput[scaleOffset];\n    output[global_idx] = fma(input[global_idx], ${S}(scale[0]), ${S}(scale[1]));\n  }`;e.compute({name:\"InstanceNormalization\",shaderCache:{hint:`${r.cacheKey}`},getRunData:()=>({outputs:[{dims:a,dataType:t[0].dataType}],dispatchGroup:{x:Math.ceil(h/64)}}),getShaderSource:A},{inputs:[t[0],x]})},ms=e=>ue({epsilon:e.epsilon,format:e.format}),hs=(e,t)=>{t.format===\"NHWC\"?qc(e,e.inputs,t):e.compute(Hc(e.inputs,t))}});var Kc,Yc,ys,bs,ws=K(()=>{\"use strict\";We();ge();Me();$e();Kc=e=>{if(!e||e.length<2)throw new Error(\"layerNorm requires at least 2 inputs.\")},Yc=(e,t,r)=>{let o=e[0].dims,a=e[1],u=e[2],i=o,d=z.normalizeAxis(t.axis,o.length),f=z.sizeToDimension(o,d),h=z.sizeFromDimension(o,d),c=z.size(a.dims),C=u?z.size(u.dims):0;if(c!==h||u&&C!==h)throw new Error(`Size of X.shape()[axis:] == ${h}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${c} and bias size of ${C}`);let b=[];for(let R=0;R<o.length;++R)R<d?b.push(o[R]):b.push(1);let $=bt(h),S=ke(e[0].dataType),x=[H(\"x\",e[0].dataType,e[0].dims,$),H(\"scale\",a.dataType,a.dims,$)];u&&x.push(H(\"bias\",u.dataType,u.dims,$)),x.push(Y(\"output\",e[0].dataType,i,$));let A=r>1,k=r>2;A&&x.push(Y(\"meanDataOutput\",1,b)),k&&x.push(Y(\"invStdOutput\",1,b));let O=R=>`\n  const normSize: f32 = ${h};\n  const normSizeVectorized: u32 = ${h/$};\n  const epsilon: f32 = ${t.epsilon};\n\n  ${R.declareVariables(...x)}\n  ${R.mainStart()}\n    ${R.guardAgainstOutOfBoundsWorkgroupSizes(f)}\n    let offset = global_idx * normSizeVectorized;\n    var meanVector = ${tt(\"f32\",$)};\n    var meanSquareVector = ${tt(\"f32\",$)};\n\n    for (var h: u32 = 0u; h < normSizeVectorized; h++) {\n      let value = ${Dt(S,$,\"x[h + offset]\")};\n      meanVector += value;\n      meanSquareVector += value * value;\n    }\n    let mean = ${Ct(\"meanVector\",$)} / normSize;\n    let meanSquare = sqrt(${Ct(\"meanSquareVector\",$)} \n      / normSize - mean * mean + epsilon);\n\n    for (var j: u32 = 0; j < normSizeVectorized; j++) {\n      let f32input = ${Dt(S,$,\"x[j + offset]\")};\n      let f32scale = ${Dt(S,$,\"scale[j]\")};\n      output[j + offset] = ${x[0].type.value}((f32input - mean) / meanSquare * f32scale\n        ${u?`+ ${Dt(S,$,\"bias[j]\")}`:\"\"}\n      );\n    }\n\n    ${A?\"meanDataOutput[global_idx] = mean\":\"\"};\n    ${k?\"invStdOutput[global_idx] = 1 / meanSquare\":\"\"};\n  }`,P=[{dims:i,dataType:e[0].dataType}];return A&&P.push({dims:b,dataType:1}),k&&P.push({dims:b,dataType:1}),{name:\"LayerNormalization\",shaderCache:{hint:`${t.cacheKey}|${r}|${e.length}`},getRunData:()=>({outputs:P,dispatchGroup:{x:Math.ceil(f/64)}}),getShaderSource:O}},ys=e=>ue({axis:e.axis,epsilon:e.epsilon}),bs=(e,t)=>{Kc(e.inputs),e.compute(Yc(e.inputs,t,e.outputCount))}});var Jc,vs,$s=K(()=>{\"use strict\";ge();wr();Jc=e=>{if(!e||e.length!==2)throw new Error(\"MatMul requires 2 inputs.\");if(e[0].dims[e[0].dims.length-1]!==e[1].dims[e[1].dims.length-2])throw new Error(\"shared dimension does not match.\")},vs=e=>{Jc(e.inputs);let t=st.calcShape(e.inputs[0].dims,e.inputs[1].dims,!0);if(!t)throw new Error(\"Can't use matmul on the given tensors\");e.compute(en(e.inputs,{activation:\"\",activationCacheKey:\"\"},t))}});var Xc,Zc,Qc,ed,td,rd,nd,od,ad,xs,Ss,Cs=K(()=>{\"use strict\";We();ge();Me();$e();Xc=e=>{if(!e||e.length<1)throw new Error(\"Too few inputs\");if(e[0].dataType!==1)throw new Error(\"Input type must be float.\");if(e.length>=2){let t=e[0].dims.length*2===e[1].dims[0];if(e.length===4&&(t=e[3].dims[0]*2===e[1].dims[0]),!t)throw new Error(\"The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].\")}},Zc=(e,t,r,o,a,u,i)=>{let d=r.length,f=\"\";for(let h=d-1;h>=0;--h)f+=`\n            k = i32(${e.indicesGet(\"indices\",h)}) - ${a[h]};\n            if (k < 0) {\n              break;\n            }\n            if (k >= ${r[h]}) {\n              break;\n            }\n            offset += k * ${o[h]};\n        `;return`\n          value = ${u}(${i});\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${f}\n            value = x[offset];\n          }\n      `},Qc=(e,t,r,o,a)=>{let u=r.length,i=\"\";for(let d=u-1;d>=0;--d)i+=`\n                k = i32(${e.indicesGet(\"indices\",d)}) - ${a[d]};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = ${2*(r[d]-1)};\n                  k = k % _2n_1;\n                  if(k >= ${r[d]}) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * ${o[d]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${i}\n              value = x[offset];\n          `},ed=(e,t,r,o,a)=>{let u=r.length,i=\"\";for(let d=u-1;d>=0;--d)i+=`\n                k = i32(${e.indicesGet(\"indices\",d)}) - ${a[d]};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= ${r[d]}) {\n                  k = ${r[d]-1};\n                }\n                offset += k * ${o[d]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${i}\n              value = x[offset];\n          `},td=(e,t,r,o,a)=>{let u=r.length,i=\"\";for(let d=u-1;d>=0;--d)i+=`\n                k = i32(${e.indicesGet(\"indices\",d)}) - ${a[d]};\n                if (k < 0)  {\n                  k += ${r[d]};\n                }\n                if (k >= ${r[d]}) {\n                  k -= ${r[d]};\n                }\n                offset += k * ${o[d]};\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${i}\n              value = x[offset];\n          `},rd=(e,t,r,o,a,u)=>{switch(a.mode){case 0:return Zc(e,t,r,o,a.pads,u,a.value);case 1:return Qc(e,t,r,o,a.pads);case 2:return ed(e,t,r,o,a.pads);case 3:return td(e,t,r,o,a.pads);default:throw new Error(\"Invalid mode\")}},nd=(e,t,r,o)=>{let a=t[0].dims,u=z.padShape(a.slice(),r.pads),i=z.size(u),d=z.computeStrides(a),f=Y(\"output\",t[0].dataType,u),h=H(\"x\",t[0].dataType,a),c=rd(f,u,a,d,r,o);return`\n              ${e.declareVariables(h,f)}\n              ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(i)}\n\n              let indices = ${f.offsetToIndices(\"global_idx\")};\n\n              var value = ${o}(0);\n              ${c}\n              output[global_idx] = value;\n          }`},od=(e,t)=>{let r=z.padShape(e[0].dims.slice(),t.pads);return{name:\"Pad\",shaderCache:{hint:t.cacheKey},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(z.size(r)/64)}}),getShaderSource:o=>nd(o,e,t,\"f32\")}},ad=(e,t)=>{if(e.length>1){let r=e[1].getBigInt64Array(),o=e.length>=3&&e[2].data?e[2].getFloat32Array()[0]:0,a=e[0].dims.length,u=new Int32Array(2*a).fill(0);if(e.length>=4){let d=e[3].getBigInt64Array();for(let f=0;f<d.length;f++)u[Number(d[f])]=Number(r[f]),u[Number(d[f])+a]=Number(r[f+d.length])}else r.forEach((d,f)=>u[Number(f)]=Number(d));let i=[];return u.forEach(d=>i.push(d)),ue({mode:t.mode,value:o,pads:i})}else return t},xs=(e,t)=>{Xc(e.inputs);let r=ad(e.inputs,t);e.compute(od(e.inputs,r),{inputs:[0]})},Ss=e=>{let t=e.mode,r=e.value,o=e.pads;return ue({mode:t,value:r,pads:o})}});var rn,As,Is,Ts,Os,Es,_s,Ps,Rs,Ms,ks,Bs,Ds,Ws,zs,Vs=K(()=>{\"use strict\";ge();Me();$e();rn=e=>{if(!e||e.length!==1)throw new Error(\"Pool ops requires 1 input.\");if(e[0].dims.length!==4&&e[0].dims.length!==3)throw new Error(\"Pool ops supports 1-D or 2-D inputs only for now.\")},As=(e,t,r)=>{let o=t.format===\"NHWC\",a=e.dims.slice();o&&a.splice(1,0,a.pop());let u=Object.hasOwnProperty.call(t,\"dilations\"),i=t.kernelShape.slice(),d=t.strides.slice(),f=u?t.dilations.slice():[],h=t.pads.slice();Bt.adjustPoolAttributes(r,a,i,d,f,h);let c=Bt.computePoolOutputShape(r,a,d,f,i,h,t.autoPad),C=Object.assign({},t);u?Object.assign(C,{kernelShape:i,strides:d,pads:h,dilations:f,cacheKey:t.cacheKey}):Object.assign(C,{kernelShape:i,strides:d,pads:h,cacheKey:t.cacheKey});let b=c.slice();return b.push(b.splice(1,1)[0]),[C,o?b:c]},Is=(e,t,r,o,a,u,i,d)=>{let f=a.format===\"NHWC\",h=r,c=t.type.value,C=h.length,b=z.size(o),$=Y(\"output\",t.type.tensor,o);if(a.kernelShape.length<=2){let S=a.kernelShape[a.kernelShape.length-1],x=a.strides[a.strides.length-1],A=a.pads[a.pads.length/2-1],k=a.pads[a.pads.length-1],O=C-(f?2:1),P=\"\",R=\"\",V=\"\";if(A+k!==0?P=`\n                for (var i: u32 = 0u; i < ${S}u; i++) {\n                  xIndices[${O}] = indices[${O}] * ${x} - ${A} + i;\n                  if (xIndices[${O}] < 0 || xIndices[${O}] >= ${h[O]}) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                  ${u}\n                }`:P=`\n                for (var i: u32 = 0u; i < ${S}u; i++) {\n                  xIndices[${O}] = indices[${O}] * ${x} - ${A} + i;\n                  let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                  ${u}\n                }`,a.kernelShape.length===2){let W=a.kernelShape[a.kernelShape.length-2],q=a.strides[a.strides.length-2],ee=a.pads[a.pads.length/2-2],oe=a.pads[a.pads.length-2],D=C-(f?3:2),te=h[D];ee+oe!==0?R=`\n                for (var j: u32 = 0u; j < ${W}u; j++) {\n                  xIndices[${D}] = indices[${D}] * ${q} - ${ee} + j;\n                  if (xIndices[${D}] < 0 || xIndices[${D}] >= ${te}) {\n                    pad+= ${S};\n                    continue;\n                  }\n              `:R=`\n                for (var j: u32 = 0u; j < ${W}u; j++) {\n                  xIndices[${D}] = indices[${D}] * ${q} - ${ee} + j;\n                `,V=`\n              }\n            `}return`\n            ${e.declareVariables(t,$)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(b)}\n\n              let indices = ${$.offsetToIndices(\"global_idx\")};\n              var xIndices = ${$.offsetToIndices(\"global_idx\")};\n\n              var value: ${c} = ${c}(${d});\n              var pad = 0;\n              ${R}\n              ${P}\n              ${V}\n              ${i}\n\n              output[global_idx] = value;\n            }`}else{if(f)throw new Error(\"Pooling with kernelShape.length > 2 is not supported for NHWC format.\");let S=z.size(a.kernelShape),x=z.computeStrides(a.kernelShape),A=x.length,k=a.pads.length,O=a.pads.reduce((V,B)=>V+B),P=\"\";return O?P=`\n                if (xIndices[j] >= inputDims[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n                ${u}\n              }`:P=`\n              }\n              let x_val = x[${t.indicesToOffset(\"xIndices\")}];\n              ${u}\n            `,`\n            ${e.declareVariables(t,$)}\n\n            const pads = array<u32, ${k}>(${a.pads.map(V=>`${V}u`).join(\",\")});\n            const inputDims = array<u32, ${C}>(${h.map(V=>`${V}u`).join(\",\")});\n            const kernelStrides = array<u32, ${A}>(${x.map(V=>`${V}u`).join(\",\")});\n            const strides = array<u32, ${A}>(${a.strides.map(V=>`${V}u`).join(\",\")});\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes(b)}\n\n              let indices = ${$.offsetToIndices(\"global_idx\")};\n              let xIndices = ${$.offsetToIndices(\"global_idx\")};\n\n              var offsets: array<u32, ${A}>;\n\n              var value = ${$.type.value}(${d});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < ${S}u; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${A-1}u; j++) {\n                  offsets[j] = offset / kernelStrides[j];\n                  offset -= offsets[j] * kernelStrides[j];\n                }\n                offsets[${A-1}] = offset;\n\n                isPad = false;\n                for (var j = ${C-A}u; j < ${C}u; j++) {\n                  xIndices[j] = indices[j] * strides[j - ${C-A}u]\n                    + offsets[j - ${C-A}u] - pads[j - 2u];\n                  ${P}\n              }\n              ${i}\n\n              output[global_idx] = value;\n            }`}},Ts=e=>({format:e.format,autoPad:[\"NOTSET\",\"VALID\",\"SAME_UPPER\",\"SAME_LOWER\"][e.auto_pad],ceilMode:e.ceil_mode,kernelShape:e.kernel_shape,strides:e.strides,pads:e.pads}),Os=(e,t,r,o)=>{let[a,u]=As(t,o,r),i=z.size(a.kernelShape),d=H(\"x\",t.dataType,t.dims),f=d.type.value,h=\"value += x_val;\",c=\"\";return a.countIncludePad?c+=`value /= ${f}(${i});`:c+=`value /= ${f}(${i} - pad);`,{name:e,shaderCache:{hint:o.cacheKey},getRunData:()=>({outputs:[{dims:u,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(z.size(u)/64)}}),getShaderSource:C=>Is(C,d,t.dims,u,a,h,c,\"0.0\")}},Es=e=>{let t=e.count_include_pad!==0,r=Ts(e);if(r.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for AveragePool\");return ue({countIncludePad:t,...r})},_s=(e,t)=>{rn(e.inputs),e.compute(Os(\"AveragePool\",e.inputs[0],!1,t))},Ps={autoPad:\"\",ceilMode:0,countIncludePad:!1,kernelShape:[],strides:[],pads:[],storageOrder:0,dilations:[],cacheKey:\"\"},Rs=e=>{let t=e.format;return{format:t,...Ps,cacheKey:t}},Ms=(e,t)=>{rn(e.inputs),e.compute(Os(\"GlobalAveragePool\",e.inputs[0],!0,t))},ks=(e,t,r,o)=>{let[a,u]=As(t,o,r),i=`\n      value = max(x_val, value);\n    `,d=\"\",f=H(\"x\",t.dataType,t.dims);return{name:e,shaderCache:{hint:o.cacheKey},getRunData:()=>({outputs:[{dims:u,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(z.size(u)/64)}}),getShaderSource:h=>Is(h,f,t.dims,u,a,i,d,\"-1e5\")}},Bs=(e,t)=>{rn(e.inputs),e.compute(ks(\"MaxPool\",e.inputs[0],!1,t))},Ds=e=>{let t=e.storage_order,r=e.dilations,o=Ts(e);if(t!==0)throw new Error(\"column major storage order is not yet supported for MaxPool\");if(o.ceilMode!==0)throw new Error(\"using ceil() in shape computation is not yet supported for MaxPool\");return ue({storageOrder:t,dilations:r,...o})},Ws=e=>{let t=e.format;return{format:t,...Ps,cacheKey:t}},zs=(e,t)=>{rn(e.inputs),e.compute(ks(\"GlobalMaxPool\",e.inputs[0],!0,t))}});var nn=K(()=>{});var Us=K(()=>{nn()});var Ns,Gs=K(()=>{Ns=\"1.17.0\"});var Fs,eo,Ls=K(()=>{Gs();Fs=\"warning\",eo={wasm:{},webgl:{},webgpu:{},versions:{common:Ns},set logLevel(e){if(e!==void 0){if(typeof e!=\"string\"||[\"verbose\",\"info\",\"warning\",\"error\",\"fatal\"].indexOf(e)===-1)throw new Error(`Unsupported logging level: ${e}`);Fs=e}},get logLevel(){return Fs}};Object.defineProperty(eo,\"logLevel\",{enumerable:!0})});var Hs,js=K(()=>{Ls();Hs=eo});var qs=K(()=>{});var Ks=K(()=>{on()});var Js=K(()=>{});var Xs=K(()=>{on()});var on=K(()=>{qs();Ks();Js();Xs()});var an=K(()=>{on()});var Zs=K(()=>{nn();an()});var Qs=K(()=>{Zs()});var eu=K(()=>{});var tu=K(()=>{nn();an()});var ru=K(()=>{tu()});var nu=K(()=>{Us();js();Qs();an();eu();ru()});var ld,cd,ou,au=K(()=>{\"use strict\";nu();We();$e();ld=(e,t,r)=>{let o=e===t,a=e<t&&r<0,u=e>t&&r>0;if(o||a||u)throw new Error(\"Range these inputs' contents are invalid.\")},cd=(e,t,r,o)=>{let a=Math.abs(Math.ceil((t-e)/r)),u=[a],i=a,d=Y(\"output\",o,u),f=d.type.storage,h=c=>`\n        ${c.declareVariables(d)}\n        ${c.mainStart()}\n        ${c.guardAgainstOutOfBoundsWorkgroupSizes(i)}\n        output[global_idx] = ${f}(${e}) + ${f}(global_idx) * ${f}(${r});\n      }`;return{name:\"Range\",shaderCache:{hint:[e,t,r].map(c=>c.toString()).join(\"_\")},getShaderSource:h,getRunData:()=>({outputs:[{dims:u,dataType:o}],dispatchGroup:{x:Math.ceil(i/64)}})}},ou=e=>{let t=0,r=0,o=0;e.inputs[0].dataType===6?(t=e.inputs[0].getInt32Array()[0],r=e.inputs[1].getInt32Array()[0],o=e.inputs[2].getInt32Array()[0]):e.inputs[0].dataType===1&&(t=e.inputs[0].getFloat32Array()[0],r=e.inputs[1].getFloat32Array()[0],o=e.inputs[2].getFloat32Array()[0]),Hs.webgpu.validateInputContent&&ld(t,r,o),e.compute(cd(t,r,o,e.inputs[0].dataType),{inputs:[]})}});var dd,pd,fd,md,hd,gd,yd,bd,wd,vd,$d,xd,Sd,Cd,Ad,iu,su,uu=K(()=>{\"use strict\";ge();Me();$e();dd=(e,t)=>{if(e.every(r=>r>0||(()=>{throw new Error(\"Resize requires scales input values to be positive\")})),e.length>0){if(t.mode===\"linear\"){if(!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for linear mode\")}else if(t.mode===\"cubic\"&&!(e.length===2||e.length===4&&e[0]===1&&e[1]===1||e.length===4&&e[0]===1&&e[3]===1))throw new Error(\"Resize requires scales input size to be 2 or 4 for cubic mode\")}},pd=(e,t,r)=>{t.every(a=>a>=0&&a<r||(()=>{throw new Error(\"Resize requires axes input values to be positive and less than rank\")}));let o=new Array(r).fill(1);return t.forEach((a,u)=>o[a]=e[u]),o},fd=(e,t,r,o,a,u)=>{let[i,d,f]=r>10?[1,2,3]:[-1,e.length>1?1:-1,-1],h=e[0].dims.length;if(i>0&&e.length>i&&e[i].dims.length>0)e[i].getFloat32Array().forEach(c=>u.push(c));else if(t.coordinateTransformMode===\"tf_crop_and_resize\")throw new Error(\"Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize\");if(d>0&&e.length>d&&e[d].dims.length>0){if(e[d].getFloat32Array().forEach(c=>o.push(c)),o.length!==0&&o.length!==h&&r>=18&&o.length!==t.axes.length)throw new Error(\"Resize requires scales input size to be same as input rank or axes size for opset 18 and up\");dd(o,t),t.axes.length>0&&pd(o,t.axes,h).forEach((c,C)=>o[C]=c)}if(f>0&&e.length>f&&(e[f].getBigInt64Array().forEach(c=>a.push(Number(c))),a.length!==h||r>=18&&a.length===t.axes.length))throw new Error(\"Resize requires sizes input size to be same as input rank or axes size for opset 18 and up\");if(t.axes.length>0){if(o.length!==t.axes.length)throw new Error('Resize requires \"scales\" input size to be of axes rank when axes attributes is specified');if(a.length!==t.axes.length)throw new Error('Resize requires \"sizes\" input size to be of rank axes rank when axes attributes is specified')}if(typeof o<\"u\"&&typeof a<\"u\"&&o.length>0&&a.length>h)throw new Error(\"Resize requires only of scales or sizes to be specified\")},md=e=>\"fn getOriginalCoordinateFromResizedCoordinate(xResized: f32, xScale: f32, lengthResized: f32,    lengthOriginal: f32, roiStart: f32, roiEnd: f32) -> f32 { \"+(()=>{switch(e){case\"asymmetric\":return\"return xResized / xScale;\";case\"pytorch_half_pixel\":return\"if (lengthResized > 1) {                     return (xResized + 0.5) / xScale - 0.5;                   } else {                     return 0.0;                   }\";case\"tf_half_pixel_for_nn\":return\"return (xResized + 0.5) / xScale;\";case\"align_corners\":return\"if (lengthResized == 1) {                     return 0.0;                   } else {                     return xResized * (lengthOriginal - 1) / (lengthResized - 1);                   }\";case\"tf_crop_and_resize\":return\"if (lengthResized > 1) {                     return roiStart * (lengthOriginal - 1) +                           (xResized * (roiEnd - roiStart) * (lengthOriginal - 1)) / (lengthResized - 1);                   } else {                     return 0.5 * (roiStart + roiEnd) * f32(lengthOriginal - 1);                   }\";case\"half_pixel_symmetric\":return[\"const outputWidth = xScale * lengthResized;\",\"const adjustment = lengthResized / outputWidth;\",\"const center = lengthOriginal / 2;\",\"const offset = center * (1 - adjustment);\",\"return offset + ((xResized + 0.5) / xScale) - 0.5;\"].join(`\n`);case\"half_pixel\":return\"return ((xResized + 0.5) / xScale) - 0.5;\";default:throw new Error(`Coordinate transform mode ${e} is not supported`)}})()+\"}\",hd=(e,t)=>\"fn getNearestPixelFromOriginal(xOriginal: f32, isDownSample: bool) -> f32 {\"+(()=>{switch(e){case\"round_prefer_ceil\":return\"if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }\";case\"floor\":return\"return floor(xOriginal);\";case\"ceil\":return\"return ceil(xOriginal);\";case\"round_prefer_floor\":return\"if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }\";case\"simple\":default:if(t<11)return\"if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }\";throw new Error(`Nearest mode ${e} is not supported`)}})()+\"}\",gd=(e,t,r)=>{let o=new Array(r).fill(0).concat(new Array(r).fill(1)),a=e.length===0?o:e.slice();return t.length>0?(t.forEach((u,i)=>{o[u]=a[i],o[i+r]=a[t.length+i]}),o):a},yd=(e,t,r,o)=>{let a=[];if(r.length>0)if(o.length>0){if(e.forEach(u=>a.push(u)),Math.max(...o)>e.length)throw new Error(\"axes is out of bound\");o.forEach((u,i)=>a[u]=r[i])}else r.forEach(u=>a.push(u));else{if(t.length===0)throw new Error(\"Resize requires either scales or sizes.\");a=e.map((u,i)=>Math.round(u*t[i]))}return a},bd=(e,t,r,o)=>{let a=(()=>{switch(o.keepAspectRatioPolicy){case\"not_larger\":return o.axes.length>0?Math.min(...o.axes.map(i=>r[i]),Number.MAX_VALUE):Math.min(...r,Number.MAX_VALUE);case\"not_smaller\":return o.axes.length>0?Math.max(...o.axes.map(i=>r[i]),Number.MIN_VALUE):Math.max(...r,Number.MIN_VALUE);default:throw new Error(`Keep aspect ratio policy ${o.keepAspectRatioPolicy} is not supported`)}})();r.fill(1,0,r.length);let u=e.slice();return o.axes.length>0?(o.axes.forEach(i=>r[i]=a),o.axes.forEach(i=>u[i]=Math.round(e[i]*r[i]))):(r.fill(a,0,r.length),u.forEach((i,d)=>u[d]=Math.round(i*r[d]))),u},wd=(e,t,r,o,a)=>`\n    fn calculateOriginalIndicesFromOutputIndices(outputIndices: ${e.type.indices}) -> array<f32, ${r.length}> {\n      const inputShape = array<u32, ${t.length}>(${t.map(u=>`${u}u`).join(\",\")});\n      const outputShape = array<u32, ${r.length}>(${r.map(u=>`${u}u`).join(\",\")});\n      const scales = array<f32, ${o.length}>(${o.map(u=>`${u}f`).join(\",\")});\n      const roi = array<f32, ${a.length}>(${a.map(u=>`${u}f`).join(\",\")});\n      var originalIndices: array<f32, ${r.length}>;\n      for (var i:u32 = 0; i < ${r.length}; i++) {\n        var outputIndex = ${r.length===1?\"outputIndices\":\"outputIndices[i]\"};\n        if (scales[i] == 1.0) {\n          originalIndices[i] = f32(outputIndex);\n        } else {\n          originalIndices[i] = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${t.length}]);\n        }\n      }\n      return originalIndices;\n    }`,vd=(e,t,r,o,a,u,i)=>`\n    fn calculateInputIndicesFromOutputIndices(outputIndices: ${t.type.indices}) -> ${e.type.indices} {\n        const inputShape = array<u32, ${r.length}>(${r.map(d=>`${d}u`).join(\",\")});\n        const outputShape = array<u32, ${o.length}>(${o.map(d=>`${d}u`).join(\",\")});\n        const scales = array<f32, ${a.length}>(${a.map(d=>`${d}f`).join(\",\")});\n        const roi = array<f32, ${u.length}>(${u.map(d=>`${d}f`).join(\",\")});\n        var inputIndices: ${e.type.indices};\n        for (var i:u32 = 0; i < ${o.length}; i++) {\n          var outputIndex = ${o.length===1?\"outputIndices\":\"outputIndices[i]\"};\n          var inputIndex: u32;\n          if (scales[i] == 1.0) {\n            inputIndex = outputIndex;\n          } else {\n            var original_idx = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), scales[i],\n                    f32(outputShape[i]), f32(inputShape[i]), roi[i], roi[i + ${r.length}]);\n            if (!${i} || (original_idx >= 0 && original_idx < f32(inputShape[i]))) {\n              if (original_idx < 0) {\n                inputIndex = 0;\n              } else if (original_idx > (f32(inputShape[i]) - 1)) {\n                inputIndex = inputShape[i] - 1;\n              } else {\n                inputIndex = u32(getNearestPixelFromOriginal(original_idx, scales[i] < 1));\n              }\n            } else {\n              inputIndex = u32(original_idx);\n            }\n          }\n          ${e.indicesSet(\"inputIndices\",\"i\",\"inputIndex\")}\n        }\n        return inputIndices;\n    }`,$d=(e,t)=>`\n    fn checkInputIndices(inputIndices: ${e.type.indices}) -> bool {\n      const inputShape = array<u32, ${t.length}>(${t.map(r=>`${r}u`).join(\",\")});\n      for (var i:u32 = 0; i < ${t.length}; i++) {\n        var inputIndex = ${t.length===1?\"inputIndices\":\"inputIndices[i]\"};\n        if (inputIndex < 0 || inputIndex >= inputShape[i]) {\n          return false;\n        }\n      }\n      return true;\n    }`,xd=(e,t,r,o,a,u,i)=>{let[d,f,h,c]=r.length===2?[-1,0,1,-1]:a[1]===1?[0,2,3,1]:[0,1,2,3];return`\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> f32 {\n      var inputIndices: ${e.type.indices};\n      inputIndices[${f}] = max(0, min(row, ${r[f]} - 1));\n      inputIndices[${h}] = max(0, min(col, ${r[h]} - 1));\n      if (${r.length} > 2) {\n        inputIndices[${c}] = channel;\n        inputIndices[${d}] = batch;\n      };\n      return input[${e.indicesToOffset(\"inputIndices\")}];\n    }\n\n    fn bilinearInterpolation(outputIndices: ${t.type.indices}) -> f32 {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(outputIndices);\n      var row:f32 = originalIndices[${f}];\n      var col:f32 = originalIndices[${h}];\n      if (${u} && (row < 0 || row > (${r[f]} - 1) || col < 0 || col > ${r[h]} - 1)) {\n        return ${i};\n      }\n      row = max(0, min(row, ${r[f]} - 1));\n      col = max(0, min(col, ${r[h]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = 0;\n      var batch: u32 = 0;\n      if (${r.length>2}) {\n        channel = u32(originalIndices[${c}]);\n        batch = u32(originalIndices[${d}]);\n      }\n      var x11: f32 = getInputValue(batch, channel, row1, col1);\n      var x12: f32 = getInputValue(batch, channel, row1, col2);\n      var x21: f32 = getInputValue(batch, channel, row2, col1);\n      var x22: f32 = getInputValue(batch, channel, row2, col2);\n      var dx1: f32 = row - f32(row1);\n      var dx2: f32 = f32(row2 ) - row;\n      var dy1 = col - f32(col1);\n      var dy2 = f32(col2) - col;\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`},Sd=(e,t,r,o,a,u,i,d,f,h)=>{let[c,C]=r.length===2?[0,1]:a[1]===1?[2,3]:[1,2],b=$=>{let S=$===c?\"row\":\"col\";return`\n      fn ${S}CubicInterpolation(inputIndices: ${e.type.indices}, outputIndices: ${t.type.indices}) -> f32 {\n        var outputIndex = ${o.length===1?\"outputIndices\":`outputIndices[${$}]`};\n        var originalIdx: f32 = getOriginalCoordinateFromResizedCoordinate(f32(outputIndex), ${a[$]},\n        f32(${o[$]}), f32(${r[$]}), ${u[$]}, ${u[$]} + ${r.length});\n        var fractOriginalIdx: f32 = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${d} && (originalIdx < 0 || originalIdx > (${r[$]} - 1))) {\n          return ${f};\n        }\n        var data: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${S}: f32 = originalIdx + f32(i);\n          if (${S} < 0 || ${S} >= ${r[$]}) {\n            if (${h}) {\n              coefs[i + 1] = 0.0;\n              continue;\n            } else if (${d}) {\n              return ${f};\n            } else {\n              ${S} = max(0, min(${S}, ${r[$]} - 1));\n            }\n          }\n          var inputIndicesCopy: ${e.type.indices} = inputIndices;\n          inputIndicesCopy[${$}] = u32(${S});\n          data[i + 1] = ${$===c?`input[${e.indicesToOffset(\"inputIndicesCopy\")}];`:`\n                                               rowCubicInterpolation(inputIndicesCopy, outputIndices);`}\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`};return`\n    ${b(c)};\n    ${b(C)};\n  fn getCubicInterpolationCoefs(s: f32) -> array<f32, 4> {\n    var absS = abs(s);\n    var coeffs: array<f32, 4> = array<f32, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: f32 = 1.0 - absS;\n    var twoMinusAbsS: f32 = 2.0 - absS;\n    var onePlusAbsS: f32 = 1.0 + absS;\n    coeffs[0] = ((${i} * onePlusAbsS - 5 * ${i}) * onePlusAbsS + 8 * ${i}) * onePlusAbsS - 4 * ${i};\n    coeffs[1] = ((${i} + 2) * absS - (${i} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${i} + 2) * oneMinusAbsS - (${i} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${i} * twoMinusAbsS - 5 * ${i}) * twoMinusAbsS + 8 * ${i}) * twoMinusAbsS - 4 * ${i};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<f32, 4>, coefs: array<f32, 4>) -> f32 {\n    var coefsSum: f32 = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(outputIndices: ${t.type.indices}) -> f32 {\n    var inputIndices: ${e.type.indices} = outputIndices;\n    return colCubicInterpolation(inputIndices, outputIndices);\n  }\n    `},Cd=(e,t,r,o,a,u)=>{let i=e.dims,d=gd(u,t.axes,i.length),f=yd(i,o,a,t.axes),h=o.slice();o.length===0&&(h=i.map((A,k)=>A===0?1:f[k]/A),t.keepAspectRatioPolicy!==\"stretch\"&&(f=bd(i,f,h,t)));let c=Y(\"output\",e.dataType,f),C=H(\"input\",e.dataType,i),b=z.size(f),$=i.length===f.length&&i.every((A,k)=>A===f[k]),S=t.coordinateTransformMode===\"tf_crop_and_resize\",x=A=>`\n      ${$?\"\":`\n      ${md(t.coordinateTransformMode)};\n      ${(()=>{switch(t.mode){case\"nearest\":return`\n              ${$d(C,i)};\n              ${hd(t.nearestMode,r)};\n              ${vd(C,c,i,f,h,d,S)};\n              `;case\"linear\":return`\n              ${wd(c,i,f,h,d)};\n              ${xd(C,c,i,f,h,S,t.extrapolationValue)};\n              `;case\"cubic\":return`\n            ${Sd(C,c,i,f,h,d,t.cubicCoeffA,S,t.extrapolationValue,t.excludeOutside)};\n            `;default:throw Error(\"Invalid resize mode\")}})()};\n      `}\n      ${A.declareVariables(C,c)}\n      ${A.mainStart()}\n        ${A.guardAgainstOutOfBoundsWorkgroupSizes(b)}\n        ${$?\"output[global_idx] = input[global_idx];\":`\n        let outputIndices = ${c.offsetToIndices(\"global_idx\")};\n        var inputIndices: ${C.type.indices};\n        ${(()=>{switch(t.mode){case\"nearest\":return`inputIndices = calculateInputIndicesFromOutputIndices(outputIndices);\n                if (checkInputIndices(inputIndices)) {\n                  output[global_idx] = input[${C.indicesToOffset(\"inputIndices\")}];\n                } else {\n                  output[global_idx] = ${t.extrapolationValue};\n                }`;case\"linear\":return\"output[global_idx] = bilinearInterpolation(outputIndices);\";case\"cubic\":return\"output[global_idx] = bicubicInterpolation(outputIndices);\";default:throw Error(`Unsupported resize mode: ${t.mode}`)}})()};\n        `}\n      }`;return{name:\"Resize\",shaderCache:{hint:`${t.cacheKey}|${r}|${h.length>0?h:\"\"}|${a.length>0?a:\"\"}|${$}`},getShaderSource:x,getRunData:()=>({outputs:[{dims:f,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(b/64)}})}},Ad=e=>{let t=e.customDataBuffer;return new Uint32Array(t,t.byteOffset,1)[0]},iu=(e,t)=>{let r=[],o=[],a=[],u=Ad(e);fd(e.inputs,t,u,r,o,a),e.compute(Cd(e.inputs[0],t,u,r,o,a),{inputs:[0]})},su=e=>{let t=e.antialias,r=e.axes,o=e.coordinateTransformMode,a=e.cubicCoeffA,u=e.excludeOutside!==0,i=e.extrapolationValue,d=e.keepAspectRatioPolicy,f=e.mode,h=e.nearestMode===\"\"?\"simple\":e.nearestMode;return ue({antialias:t,axes:r,coordinateTransformMode:o,cubicCoeffA:a,excludeOutside:u,extrapolationValue:i,keepAspectRatioPolicy:d,mode:f,nearestMode:h})}});var Id,Td,lu,cu,du=K(()=>{\"use strict\";We();ge();Me();$e();Id=e=>{if(!e||e.length<3)throw new Error(\"layerNorm requires at least 3 inputs.\");let t=e[0],r=e[1],o=e[2];if(t.dataType!==r.dataType||t.dataType!==o.dataType)throw new Error(\"All inputs must have the same data type\");if(t.dims.length!==3&&t.dims.length!==2)throw new Error(\"Input must be 2D or 3D\");if(r.dims.length!==3&&r.dims.length!==2)throw new Error(\"Skip must be 2D or 3D\");let a=t.dims[t.dims.length-1],u=t.dims[t.dims.length-2];if(r.dims[r.dims.length-1]!==a)throw new Error(\"Skip must have the same hidden size as input\");if(r.dims[r.dims.length-2]!==u)throw new Error(\"Skip must have the same sequence length as input\");if(o.dims.length!==1)throw new Error(\"Gamma must be 1D\");if(o.dims[o.dims.length-1]!==a)throw new Error(\"Gamma must have the same hidden size as input\");if(e.length>3){let i=e[3];if(i.dims.length!==1)throw new Error(\"Beta must be 1D\");if(i.dims[i.dims.length-1]!==a)throw new Error(\"Beta must have the same hidden size as input\")}if(e.length>4){let i=e[4];if(i.dims.length!==1)throw new Error(\"Bias must be 1D\");if(i.dims[i.dims.length-1]!==a)throw new Error(\"Bias must have the same hidden size as input\")}},Td=(e,t,r,o)=>{let a=e[0].dims,u=z.size(a),i=a,d=u,f=a.slice(-1)[0],h=o?a.slice(0,-1).concat(1):[],c=e.length>3,C=e.length>4,b=o&&r>1,$=o&&r>2,S=r>3,x=bt(f),A=[H(\"x\",e[0].dataType,e[0].dims,x),H(\"skip\",e[1].dataType,e[1].dims,x),H(\"gamma\",e[2].dataType,e[2].dims,x)];c&&A.push(H(\"beta\",e[3].dataType,e[3].dims,x)),C&&A.push(H(\"bias\",e[4].dataType,e[4].dims,x)),A.push(Y(\"output\",e[0].dataType,i,x)),b&&A.push(Y(\"meanOutput\",1,h)),$&&A.push(Y(\"invStdOutput\",1,h)),S&&A.push(Y(\"inputSkipBiasSum\",e[0].dataType,i,x));let k=ke(e[0].dataType),O=R=>`\n      const hiddenSize: f32 = ${f};\n      const hiddenSizeVectorized: u32 = ${f/x};\n      const epsilon: f32 = ${t.epsilon};\n\n      ${R.declareVariables(...A)}\n\n      ${R.mainStart()}\n        ${R.guardAgainstOutOfBoundsWorkgroupSizes(d/f)}\n        let offset = global_idx * hiddenSizeVectorized;\n        var sum = ${tt(\"f32\",x)};\n        var squareSum = ${tt(\"f32\",x)};\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          let skipValue = skip[offset + i];\n          let biasValue = ${C?\"bias[i]\":\"0.0\"};\n          let inputValue = x[offset + i];\n          let value = inputValue + skipValue + biasValue;\n          ${S?\"inputSkipBiasSum[offset + i] = value;\":\"\"}\n          output[offset + i] = value;\n          let f32Value = ${Dt(k,x,\"value\")};\n          sum += f32Value;\n          squareSum += f32Value * f32Value;\n        }\n        let mean = ${Ct(\"sum\",x)} / hiddenSize;\n        let variance = sqrt(${Ct(\"squareSum\",x)} / hiddenSize - mean * mean + epsilon);\n        ${b?\"meanOutput[global_idx] = mean;\":\"\"}\n        ${$?\"invStdOutput[global_idx] = 1.0 / variance;\":\"\"}\n        for (var i: u32 = 0; i < hiddenSizeVectorized; i++) {\n          output[offset + i] = (output[offset + i] - ${k}(mean)) / ${k}(variance) * gamma[i]\n           + ${c?\"beta[i]\":\"0.0\"};\n        }\n      }`,P=[{dims:i,dataType:e[0].dataType}];return r>1&&P.push({dims:h,dataType:1}),r>2&&P.push({dims:h,dataType:1}),r>3&&P.push({dims:a,dataType:e[0].dataType}),{name:\"SkipLayerNormalization\",shaderCache:{hint:t.cacheKey},getShaderSource:O,getRunData:()=>({outputs:P,dispatchGroup:{x:Math.ceil(d/f/64)}})}},lu=(e,t)=>{Id(e.inputs);let o=[0];e.outputCount>1&&o.push(-3),e.outputCount>2&&o.push(-3),e.outputCount>3&&o.push(3),e.compute(Td(e.inputs,t,e.outputCount,!1),{outputs:o})},cu=e=>{let t=e.epsilon;return ue({epsilon:t})}});var Od,sn,Ed,pu,_d,Pd,fu,mu,hu=K(()=>{\"use strict\";We();ge();Me();$e();Od=(e,t)=>{if(!e||e.length<1)throw new Error(\"too few inputs\");if(t.axes.length!==0){if(t.axes.length!==t.starts.length||t.axes.length!==t.ends.length)throw new Error(\"axes, starts and ends must have the same length\")}else if(t.starts.length!==t.ends.length)throw new Error(\"starts and ends must have the same length\");e.slice(1).forEach((r,o)=>{if(e[o+1].dataType!==6&&e[o+1].dataType!==7)throw new Error(`Input ${o} must be an array of int32 or int64`)})},sn=(e,t)=>{let r=[];if(e.length>t)if(e[t].dataType===7)e[t].getBigInt64Array().forEach(o=>r.push(Number(o)));else if(e[t].dataType===6)e[t].getInt32Array().forEach(o=>r.push(Number(o)));else throw new Error(`Input ${t} must be an array of int32 or int64`);return r},Ed=(e,t)=>{if(e.length>1){let r=sn(e,1),o=sn(e,2),a=sn(e,3);return a.length===0&&(a=[...Array(e[0].dims.length).keys()]),ue({starts:r,ends:o,axes:a})}else return t},pu=(e,t,r,o,a)=>{let u=e;return e<0&&(u+=r[o[t]]),a[t]<0?Math.max(0,Math.min(u,r[o[t]]-1)):Math.max(0,Math.min(u,r[o[t]]))},_d=(e,t,r,o)=>`fn calculateInputIndices(outputIndices: ${t.type.indices}) -> ${e.type.indices} {\n          var inputIndices: ${e.type.indices};\n          var carry = 0u;\n          for (var i = ${r.length}; i >= 0; i--) {\n            var outputIndex = ${o.length===1?\"outputIndices\":\"outputIndices[i]\"};\n            var inputIndex = outputIndex * steps[i] + starts[i] + carry;\n            carry = inputIndex / inputShape[i];\n            inputIndex = inputIndex % inputShape[i];\n            if (signs[i] < 0) {\n              inputIndex = inputShape[i] - inputIndex - 1u + starts[i];\n            }\n            ${r.length===1?\"inputIndices\":\"inputIndices[i]\"} = inputIndex;\n          }\n          return inputIndices;\n      }`,Pd=(e,t)=>{let r=e[0].dims,o=z.size(r),a=t.axes.length>0?z.normalizeAxes(t.axes,r.length):[...Array(r.length).keys()],u=sn(e,4);u.forEach(x=>x!==0||(()=>{throw new Error(\"step cannot be 0\")})),u.length===0&&(u=Array(a.length).fill(1));let i=t.starts.map((x,A)=>pu(x,A,r,a,u)),d=t.ends.map((x,A)=>pu(x,A,r,a,u));if(a.length!==r.length)for(let x=0;x<r.length;++x)a.includes(x)||(i.splice(x,0,0),d.splice(x,0,r[x]),u.splice(x,0,1));let f=u.map(x=>Math.sign(x));u.forEach((x,A,k)=>{if(x<0){let O=(d[A]-i[A])/x,P=i[A],R=P+O*u[A];i[A]=R,d[A]=P,k[A]=-x}});let h=r.slice(0);a.forEach((x,A)=>{h[x]=Math.ceil((d[x]-i[x])/u[x])});let c={dims:h,dataType:e[0].dataType},C=Y(\"output\",e[0].dataType,h),b=H(\"input\",e[0].dataType,r),$=z.size(h),S=x=>`\n      ${x.declareVariables(b,C)}\n        const signs = array<i32, ${f.length}>(${f.map(A=>`${A}i`).join(\",\")});\n        const starts = array<u32, ${i.length}>(${i.map(A=>`${A}u`).join(\",\")});\n        const ends = array<u32, ${d.length}>(${d.map(A=>`${A}u`).join(\",\")});\n        const steps = array<u32, ${u.length}>(${u.map(A=>`${A}u`).join(\",\")});\n        const inputShape = array<u32, ${r.length}>(${r.map(A=>`${A}u`).join(\",\")});\n\n        ${_d(b,C,r,h)}\n        ${x.mainStart()}\n          ${x.guardAgainstOutOfBoundsWorkgroupSizes($)}\n          let outputIndices = ${C.offsetToIndices(\"global_idx\")};\n          let inputIndices = calculateInputIndices(outputIndices);\n          ${C.setByOffset(\"global_idx\",b.getByIndices(\"inputIndices\"))}\n      }`;return{name:\"Slice\",shaderCache:{hint:`${t.cacheKey}|${e[4]?.dims??\"\"}`},getShaderSource:S,getRunData:()=>({outputs:[c],dispatchGroup:{x:Math.ceil(o/64)}})}},fu=(e,t)=>{Od(e.inputs,t);let r=Ed(e.inputs,t);e.compute(Pd(e.inputs,r),{inputs:[0]})},mu=e=>{let t=e.starts,r=e.ends,o=e.axes;return ue({starts:t,ends:r,axes:o})}});var Rd,Md,gu,yu,bu=K(()=>{\"use strict\";ge();Me();$e();Rd=e=>{if(!e||e.length!==1)throw new Error(\"Softmax op requires 1 input.\")},Md=(e,t)=>{let r=e.dims,o=z.size(r),a=64,u=t.axis;if(u<0&&(u=r.length+u),u<r.length-1)throw new Error(\"softmax only supports last axis for now.\");let i=r[u],d=o/i,f=bt(i),h=i/f,c=(A,k)=>k===4?`max(max(${A}.x, ${A}.y), max(${A}.z, ${A}.w))`:k===2?`max(${A}.x, ${A}.y)`:k===3?`max(max(${A}.x, ${A}.y), ${A}.z)`:A,C=H(\"x\",e.dataType,e.dims,f),b=Y(\"result\",e.dataType,e.dims,f),$=C.type.value,S=ke(e.dataType)===\"f32\"?`var threadMax = ${$}(-3.402823e+38f);`:`var threadMax = ${$}(-65504.0h);`,x=A=>`\n      var<workgroup> rowMaxShared : ${$};\n      var<workgroup> rowSumShared : ${$};\n      var<workgroup> threadShared : array<${$}, ${a}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${$} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${$}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${A.registerUniform(\"packedCols\",\"i32\").declareVariables(C,b)}\n      ${A.mainStart()}\n        let gindex = i32(global_id.x);\n        let lindex = i32(local_id.x);\n        const wg = ${a};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${S}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${$}(${c(\"threadShared[0]\",f)});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${$}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${$}(${Ct(\"threadShared[0]\",f)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          setValue(row, col, row_stride, value);\n        }\n      }`;return{name:\"Softmax\",shaderCache:{hint:`${f}`,inputDependencies:[\"type\"]},getRunData:()=>({outputs:[{dims:r,dataType:e.dataType}],dispatchGroup:{x:d},programUniforms:[{type:\"uint32\",data:h}]}),getShaderSource:x}},gu=(e,t)=>{Rd(e.inputs),e.compute(Md(e.inputs[0],t))},yu=e=>ue({axis:e.axis})});var kd,Bd,Dd,Wd,zd,wu,vu,$u=K(()=>{\"use strict\";ge();Me();$e();kd=e=>{if(!e||e.length<1)throw new Error(\"too few inputs\")},Bd=(e,t)=>{let r=[],o=t.numOutputs;return e[1].dims[0]>0&&(e[1].getBigInt64Array().forEach(a=>r.push(Number(a))),o=r.length),ue({numOutputs:o,axis:t.axis,splitSizes:r})},Dd=e=>`\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n    if (index < sizeInConcatAxis[i]) {\n        return i;\n    }\n    }\n    return ${e}u;\n}`,Wd=e=>{let t=e.length,r=[];for(let o=0;o<t;++o){let a=e[o].setByIndices(\"indices\",\"input[global_idx]\");t===1?r.push(a):o===0?r.push(`if (outputNumber == ${o}u) { ${a} }`):o===t-1?r.push(`else { ${a} }`):r.push(`else if (outputNumber == ${o}) { ${a} }`)}return`\n      fn writeBufferData(outputNumber: u32, indices: ${e[0].type.indices}, global_idx: u32) {\n        ${r.join(`\n`)}\n      }`},zd=(e,t)=>{let r=e[0].dims,o=z.size(r),a=e[0].dataType,u=r.length,i=t.axis,d=i<0?r.length+i:i,f=new Array(t.numOutputs),h=H(\"input\",a,r),c=new Array(t.numOutputs),C=[],b=[],$=0;for(let A=0;A<t.numOutputs;A++){$+=t.splitSizes[A],c[A]=$;let k=r.slice();k[t.axis]=t.splitSizes[A],b.push(k),f[A]=Y(`output${A}`,a,b[A]),C.push({dims:b[A],dataType:e[0].dataType})}let S=u<2?\"indices\":`indices[${d}]`,x=A=>`\n  ${A.declareVariables(h,...f)}\n  const sizeInConcatAxis = array<u32, ${c.length}>(${c.map(k=>`${k}u`).join(\",\")});\n  ${Dd(c.length)}\n  ${Wd(f)}\n\n  ${A.mainStart()}\n    ${A.guardAgainstOutOfBoundsWorkgroupSizes(o)}\n\n    var indices = ${h.offsetToIndices(\"global_idx\")};\n    let outputNumber = calculateOutputIndex(${S});\n    if (outputNumber != 0) {\n        ${S} -= sizeInConcatAxis[outputNumber - 1u];\n    }\n    writeBufferData(outputNumber, indices, global_idx);\n  }`;return{name:\"Split\",shaderCache:{hint:t.cacheKey},getShaderSource:x,getRunData:()=>({outputs:C,dispatchGroup:{x:Math.ceil(o/64)}})}},wu=(e,t)=>{kd(e.inputs);let r=e.inputs.length===1?t:Bd(e.inputs,t);e.compute(zd(e.inputs,r),{inputs:[0]})},vu=e=>{let t=e.axis,r=e.splitSizes,o=e.numOutputs<0?r.length:e.numOutputs;if(o!==r.length)throw new Error(\"numOutputs and splitSizes lengh must be equal\");return ue({axis:t,numOutputs:o,splitSizes:r})}});var xu,Vd,Ud,Nd,Su,Cu=K(()=>{\"use strict\";We();ge();$e();xu=e=>Array.from(e.getBigInt64Array(),Number),Vd=e=>{if(!e||e.length!==2)throw new Error(\"Tile requires 2 inputs.\");if(e[0].dataType!==1&&e[0].dataType!==6&&e[0].dataType!==12)throw new Error(\"Tile only support float, int32, and uint32 data types\");if(e[1].dataType!==7)throw new Error(\"Tile `repeats` input should be of int64 data type\");if(e[1].dims.length!==1)throw new Error(\"Tile `repeats` input should be 1-D\");if(xu(e[1]).length!==e[0].dims.length)throw new Error(\"Tile `repeats` input should have same number of elements as rank of input data tensor\")},Ud=(e,t)=>{let r=[];for(let o=0;o<e.length;++o)r.push(e[o]*t[o]);return r},Nd=e=>{let t=e[0].dims,r=xu(e[1]),o=Ud(t,r),a=z.size(o),u=e[0].dataType,i=H(\"input\",u,t),d=Y(\"output\",u,o),f=h=>`\n      const inputShape = ${i.indices(...t)};\n      ${h.declareVariables(i,d)}\n      ${h.mainStart()}\n      ${h.guardAgainstOutOfBoundsWorkgroupSizes(a)}\n      let outputIndices = ${d.offsetToIndices(\"global_idx\")};\n      var inputIndices: ${i.type.indices};\n      for (var i = 0; i < ${t.length}; i++) {\n        let inputDimValue = ${d.indicesGet(\"outputIndices\",\"i\")}  % ${i.indicesGet(\"inputShape\",\"i\")};\n\n        ${i.indicesSet(\"inputIndices\",\"i\",\"inputDimValue\")}\n      }\n      ${d.setByOffset(\"global_idx\",i.getByIndices(\"inputIndices\"))}\n    }`;return{name:\"Tile\",shaderCache:{hint:`${r}`},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)}}),getShaderSource:f}},Su=e=>{Vd(e.inputs),e.compute(Nd(e.inputs),{inputs:[0]})}});var Gd,Fd,Au,Iu=K(()=>{\"use strict\";We();ge();$e();Gd=(e,t,r,o,a)=>{let u=z.size(r),i=Math.ceil(u/4),d=Y(\"outputData\",a,r,4),f=H(\"aData\",t[1].dataType,t[1].dims,4),h=H(\"bData\",t[2].dataType,t[2].dims,4),c=H(\"cData\",t[0].dataType,t[0].dims,4),C,b=($,S,x)=>`select(${S}, ${$}, ${x})`;if(!o)C=d.setByOffset(\"global_idx\",b(f.getByOffset(\"global_idx\"),h.getByOffset(\"global_idx\"),c.getByOffset(\"global_idx\")));else{let $=(S,x,A=\"\")=>{let k=`aData[indexA${x}][componentA${x}]`,O=`bData[indexB${x}][componentB${x}]`,P=`bool(cData[indexC${x}] & ${4278190080>>>(3-x)*8}u)`;return`\n            let outputIndices${x} = ${d.offsetToIndices(`global_idx * 4u + ${x}u`)};\n            let offsetA${x} = ${f.broadcastedIndicesToOffset(`outputIndices${x}`,d)};\n            let offsetB${x} = ${h.broadcastedIndicesToOffset(`outputIndices${x}`,d)};\n            let offsetC${x} = ${c.broadcastedIndicesToOffset(`outputIndices${x}`,d)};\n            let indexA${x} = offsetA${x} / 4u;\n            let indexB${x} = offsetB${x} / 4u;\n            let indexC${x} = offsetC${x} / 4u;\n            let componentA${x} = offsetA${x} % 4u;\n            let componentB${x} = offsetB${x} % 4u;\n            ${S}[${x}] = ${A}(${b(k,O,P)});\n          `};a===9?C=`\n            var data = vec4<u32>(0);\n            ${$(\"data\",0,\"u32\")}\n            ${$(\"data\",1,\"u32\")}\n            ${$(\"data\",2,\"u32\")}\n            ${$(\"data\",3,\"u32\")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:C=`\n            ${$(\"outputData[global_idx]\",0)}\n            ${$(\"outputData[global_idx]\",1)}\n            ${$(\"outputData[global_idx]\",2)}\n            ${$(\"outputData[global_idx]\",3)}\n          `}return`\n        ${e.declareVariables(c,f,h,d)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes(i)}\n        ${C}\n      }`},Fd=e=>{let t=e[1].dims,r=e[2].dims,o=e[0].dims,a=e[1].dataType,u=!(z.areEqual(t,r)&&z.areEqual(r,o)),i=t,d=z.size(t);if(u){let f=st.calcShape(st.calcShape(t,r,!1),o,!1);if(!f)throw new Error(\"Can't perform where op on the given tensors\");i=f,d=z.size(i)}return{name:\"Where\",getShaderSource:f=>Gd(f,e,i,u,a),getRunData:()=>({outputs:[{dims:i,dataType:a}],dispatchGroup:{x:Math.ceil(d/64/4)}})}},Au=e=>{e.compute(Fd(e.inputs))}});var Tu,Ou=K(()=>{\"use strict\";Fa();Ha();Ci();Bi();zi();qn();Xi();ts();os();ss();cs();fs();gs();ws();$s();Cs();Vs();au();jr();uu();du();hu();bu();$u();Cu();gr();Fn();Iu();Tu=new Map([[\"Abs\",[ja]],[\"Acos\",[qa]],[\"Acosh\",[Ka]],[\"Add\",[Ai]],[\"ArgMax\",[Ga,Nn]],[\"ArgMin\",[Na,Nn]],[\"Asin\",[Ya]],[\"Asinh\",[Ja]],[\"Atan\",[Xa]],[\"Atanh\",[Za]],[\"AveragePool\",[_s,Es]],[\"BiasAdd\",[La]],[\"BiasSplitGelu\",[Si]],[\"Cast\",[ei,Qa]],[\"Ceil\",[ri]],[\"ClipV10\",[Gn]],[\"Clip\",[ti]],[\"Concat\",[Di,Wi]],[\"Conv\",[Yn,Kn]],[\"ConvTranspose\",[Ji,Yi]],[\"Cos\",[ni]],[\"Cosh\",[oi]],[\"Div\",[Ii]],[\"Einsum\",[Qi,es]],[\"Elu\",[ai,Kr]],[\"Equal\",[Ti]],[\"Erf\",[ii]],[\"Exp\",[si]],[\"Expand\",[ns]],[\"Floor\",[ui]],[\"FusedConv\",[Yn,Kn]],[\"Gather\",[is,as]],[\"GatherElements\",[ls,us]],[\"Gelu\",[li]],[\"Gemm\",[ds,ps]],[\"GlobalAveragePool\",[Ms,Rs]],[\"GlobalMaxPool\",[zs,Ws]],[\"Greater\",[Pi]],[\"GreaterOrEqual\",[Mi]],[\"InstanceNormalization\",[hs,ms]],[\"LayerNormalization\",[bs,ys]],[\"LeakyRelu\",[ci,Kr]],[\"Less\",[Ri]],[\"LessOrEqual\",[ki]],[\"Log\",[xi]],[\"MatMul\",[vs]],[\"MaxPool\",[Bs,Ds]],[\"Mul\",[Oi]],[\"Neg\",[pi]],[\"Not\",[di]],[\"Pad\",[xs,Ss]],[\"Pow\",[Ei]],[\"Range\",[ou]],[\"Reciprocal\",[fi]],[\"ReduceMin\",[ka,rt]],[\"ReduceMean\",[Ea,rt]],[\"ReduceMax\",[Ma,rt]],[\"ReduceSum\",[Da,rt]],[\"ReduceProd\",[Ba,rt]],[\"ReduceL1\",[_a,rt]],[\"ReduceL2\",[Pa,rt]],[\"ReduceLogSum\",[za,rt]],[\"ReduceLogSumExp\",[Ra,rt]],[\"ReduceSumSquare\",[Wa,rt]],[\"Relu\",[mi]],[\"Resize\",[iu,su]],[\"Sigmoid\",[hi]],[\"Sin\",[gi]],[\"Sinh\",[yi]],[\"Slice\",[fu,mu]],[\"SkipLayerNormalization\",[lu,cu]],[\"Split\",[wu,vu]],[\"Sqrt\",[bi]],[\"Softmax\",[gu,yu]],[\"Sub\",[_i]],[\"Tan\",[wi]],[\"Tanh\",[vi]],[\"ThresholdedRelu\",[$i,Kr]],[\"Tile\",[Su]],[\"Transpose\",[ga,ya]],[\"Where\",[Au]]])});var un,Eu=K(()=>{\"use strict\";We();St();$e();un=class{constructor(t){this.backend=t;this.repo=new Map,this.attributesBound=!1}getArtifact(t){return this.repo.get(t)}setArtifact(t,r){this.repo.set(t,r)}run(t,r,o,a,u,i,d){let f=this.backend.device,h=this.backend.getComputePassEncoder();h.setPipeline(t.computePipeline);let c=[];for(let b of a)c.push({binding:c.length,resource:{buffer:b.buffer}});for(let b of u)c.push({binding:c.length,resource:{buffer:b.buffer}});d&&c.push({binding:c.length,resource:d});let C=f.createBindGroup({layout:t.computePipeline.getBindGroupLayout(0),entries:c,label:t.programInfo.name});if(h.setBindGroup(0,C),h.dispatchWorkgroups(...i),this.backend.pendingDispatchNumber++,this.backend.isQueryEnabled()){typeof this.backend.queryData>\"u\"&&(this.backend.queryData=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.COPY_SRC|GPUBufferUsage.QUERY_RESOLVE));let b=this.backend.gpuDataManager.create(this.backend.querySetCount*8,GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST);this.backend.endComputePass(),this.backend.getCommandEncoder().resolveQuerySet(this.backend.querySet,0,2,this.backend.queryData.buffer,0),this.backend.getCommandEncoder().copyBufferToBuffer(this.backend.queryData.buffer,0,b.buffer,0,this.backend.querySetCount*8),this.backend.flush();let $=this.backend.currentKernelId,S=this.backend.kernels.get($),x=`[${S[0]}] ${S[1]}`;b.buffer.mapAsync(GPUMapMode.READ).then(()=>{let A=new BigUint64Array(b.buffer.getMappedRange()),k=A[0],O=A[1];b.buffer.unmap(),typeof this.backend.queryTimeBase>\"u\"&&(this.backend.queryTimeBase=k);let P=Number(k-this.backend.queryTimeBase),R=Number(O-this.backend.queryTimeBase);if(!Number.isSafeInteger(P)||!Number.isSafeInteger(R))throw new RangeError(\"incorrect timestamp range\");this.backend.gpuDataManager.release(b.id);let V=\"\";r.forEach((W,q)=>{V+=`input[${q}]: [${W.dims}] | ${fr(W.dataType)}, `});let B=\"\";o.forEach((W,q)=>{B+=`output[${q}]: [${W.dims}] | ${fr(W.dataType)}, `}),console.log(`[profiling] kernel \"${$}|${x}\" ${V}${B}execution time: ${R-P} ns`)})}this.backend.pendingDispatchNumber>=16&&this.backend.flush()}dispose(){}build(t,r){let o=this.backend.device,a=[];o.features.has(\"shader-f16\")&&a.push(\"enable f16;\");let u=ma(r),i=t.getShaderSource(u),d=`${a.join(`\n`)}\n${u.additionalImplementations}\n${i}`,f=o.createShaderModule({code:d,label:t.name});Ee(\"verbose\",()=>`[WebGPU] ${t.name} shader code: ${d}`);let h=o.createComputePipeline({compute:{module:f,entryPoint:\"main\"},layout:\"auto\",label:t.name});return{programInfo:t,computePipeline:h}}normalizeDispatchGroupSize(t){let r=typeof t==\"number\"?t:t.x,o=typeof t==\"number\"?1:t.y||1,a=typeof t==\"number\"?1:t.z||1,u=this.backend.device.limits.maxComputeWorkgroupsPerDimension;if(r<=u&&o<=u&&a<=u)return[r,o,a];let i=r*o*a,d=Math.ceil(Math.sqrt(i));if(d>u){if(d=Math.ceil(Math.cbrt(i)),d>u)throw new Error(\"Total dispatch size exceeds WebGPU maximum.\");return[d,d,d]}else return[d,d,1]}}});var Ld,Hd,ln,_u=K(()=>{\"use strict\";St();sa();da();Ou();Eu();Ld=(e,t)=>{if(t.length!==e.length)throw new Error(`inputDependencies length ${t.length} is not equal to inputTensors length ${e.length}.`);let r=[];for(let o=0;o<e.length;++o){let a=e[o].dataType;switch(t[o]){case\"none\":{r.push(\"\");break}case\"type\":{r.push(`${a}`);break}case\"rank\":{let u=e[o].dims.length;r.push(`${a};${u}`);break}case\"dims\":{let u=e[o].dims.join(\",\");r.push(`${a};${u}`);break}default:throw new Error(`unsupported input dependency: ${t[o]}`)}}return r.join(\"|\")},Hd=(e,t,r)=>{let o=e.name;return e.shaderCache?.hint&&(o+=\"[\"+e.shaderCache.hint+\"]\"),o+=\":\"+r+`:${Ld(t,e.shaderCache?.inputDependencies??new Array(t.length).fill(\"dims\"))}`,o},ln=class{constructor(){this.currentKernelId=null;this.commandEncoder=null;this.computePassEncoder=null;this.pendingDispatchNumber=0;this.querySetCount=2;this.sessionExternalDataMapping=new Map}get currentKernelCustomData(){if(this.currentKernelId===null)throw new Error(\"currentKernelCustomData(): currentKernelId is null. (should not happen)\");let t=this.kernelCustomData.get(this.currentKernelId);return t||(t={},this.kernelCustomData.set(this.currentKernelId,t)),t}async initialize(t){if(!navigator.gpu)throw new Error(\"WebGpuBackend: WebGPU is not available.\");let r=await navigator.gpu.requestAdapter();if(!r)throw new Error(\"WebGpuBackend: Failed to get GPU adapter.\");this.env=t;let o=[],a={requiredLimits:{maxComputeWorkgroupStorageSize:r.limits.maxComputeWorkgroupStorageSize,maxComputeWorkgroupsPerDimension:r.limits.maxComputeWorkgroupsPerDimension,maxStorageBufferBindingSize:r.limits.maxStorageBufferBindingSize,maxBufferSize:r.limits.maxBufferSize,maxComputeInvocationsPerWorkgroup:r.limits.maxComputeInvocationsPerWorkgroup,maxComputeWorkgroupSizeX:r.limits.maxComputeWorkgroupSizeX,maxComputeWorkgroupSizeY:r.limits.maxComputeWorkgroupSizeY,maxComputeWorkgroupSizeZ:r.limits.maxComputeWorkgroupSizeZ},requiredFeatures:o};r.features.has(\"timestamp-query\")&&o.push(\"timestamp-query\"),r.features.has(\"shader-f16\")&&o.push(\"shader-f16\"),this.device=await r.requestDevice(a),this.gpuDataManager=ca(this),this.programManager=new un(this),this.kernels=new Map,this.kernelPersistentData=new Map,this.kernelCustomData=new Map,aa(t.logLevel,!!t.debug),this.device.onuncapturederror=u=>{u.error instanceof GPUValidationError&&console.error(`An uncaught WebGPU validation error was raised: ${u.error.message}`)},Object.defineProperty(this.env.webgpu,\"device\",{value:this.device})}dispose(){typeof this.querySet<\"u\"&&this.querySet.destroy(),this.gpuDataManager.dispose()}getCommandEncoder(){return this.commandEncoder||(this.commandEncoder=this.device.createCommandEncoder()),this.commandEncoder}getComputePassEncoder(){if(!this.computePassEncoder){let t={};this.isQueryEnabled()&&(typeof this.querySet>\"u\"&&(this.querySet=this.device.createQuerySet({type:\"timestamp\",count:this.querySetCount})),t.timestampWrites={querySet:this.querySet,beginningOfPassWriteIndex:0,endOfPassWriteIndex:1}),this.computePassEncoder=this.getCommandEncoder().beginComputePass(t)}return this.computePassEncoder}endComputePass(){this.computePassEncoder&&(this.computePassEncoder.end(),this.computePassEncoder=null)}flush(){this.commandEncoder&&(this.endComputePass(),this.device.queue.submit([this.getCommandEncoder().finish()]),this.gpuDataManager.refreshPendingBuffers(),this.commandEncoder=null,this.pendingDispatchNumber=0)}isQueryEnabled(){return!!(this.device.features.has(\"timestamp-query\")&&this.env.webgpu.profilingMode===\"default\")}run(t,r,o,a,u){let i=[];for(let O=0;O<r.length;++O){let P=this.gpuDataManager.get(r[O].data);if(!P)throw new Error(`no GPU data for input: ${r[O].data}`);i[O]=P}let{outputs:d,dispatchGroup:f,programUniforms:h}=t.getRunData(r),c=o.length===0?d.map((O,P)=>P):o;if(c.length!==d.length)throw new Error(`Output size ${c.length} must be equal to ${d.length}.`);let C=[],b=[];for(let O=0;O<d.length;++O){if(!Number.isInteger(c[O])||c[O]<-3||c[O]>=d.length)throw new Error(`Invalid output index: ${c[O]}`);if(c[O]===-3)continue;let P=c[O]===-1,R=c[O]===-2,V=P||R?u(d[O].dataType,d[O].dims):a(c[O],d[O].dataType,d[O].dims),B=this.gpuDataManager.get(V.data);if(!B)throw new Error(`no GPU data for output: ${V.data}`);if(P&&this.temporaryData.push(B),R){let W=this.kernelPersistentData.get(this.currentKernelId);W||(W=[],this.kernelPersistentData.set(this.currentKernelId,W)),W.push(B)}C.push(V),b.push(B)}let $;if(h){let O=0,P=0,R=[],V=1;h.forEach(q=>{let ee=typeof q.data==\"number\"?[q.data]:q.data;if(ee.length===0)return;let oe;switch(ee.length){case 1:oe=4;break;case 2:oe=8;break;case 3:oe=16;break;case 4:oe=16;break;case 5:oe=16;break;case 6:oe=16;break;default:throw new Error(`unsupported data length: ${ee.length}`)}(P===5||P===6)&&(oe=16),oe>V&&(V=oe),O=Math.ceil(O/oe)*oe,P=ee.length,R.push(O),O+=ee.length*4}),O=Math.ceil(O/V)*V;let B=new ArrayBuffer(O);h.forEach((q,ee)=>{let oe=R[ee],D=typeof q.data==\"number\"?[q.data]:q.data;q.type===\"int32\"?new Int32Array(B,oe,D.length).set(D):q.type===\"uint32\"?new Uint32Array(B,oe,D.length).set(D):new Float32Array(B,oe,D.length).set(D)});let W=this.gpuDataManager.create(O,GPUBufferUsage.COPY_DST|GPUBufferUsage.UNIFORM);this.device.queue.writeBuffer(W.buffer,0,B,0,O),this.gpuDataManager.release(W.id),$={offset:0,size:O,buffer:W.buffer}}let S=this.programManager.normalizeDispatchGroupSize(f),x=S[1]===1&&S[2]===1,A=Hd(t,r,x),k=this.programManager.getArtifact(A);return k||(k=this.programManager.build(t,S),this.programManager.setArtifact(A,k)),Ee(\"info\",()=>`[ProgramManager] run \"${t.name}\" (key=${A}) with ${S[0]}x${S[1]}x${S[2]}`),this.programManager.run(k,r,C,i,b,S,$),C}upload(t,r){this.gpuDataManager.upload(t,r)}memcpy(t,r){this.gpuDataManager.memcpy(t,r)}async download(t,r){await this.gpuDataManager.download(t,r)}alloc(t){return this.gpuDataManager.create(t).id}free(t){return this.gpuDataManager.release(t)}createKernel(t,r,o,a){let u=Tu.get(t);if(!u)throw new Error(`kernel not implemented: ${t}`);this.kernels.set(r,[t,a,u[0],[u[1],o]])}releaseKernel(t){let r=this.kernelPersistentData.get(t);if(r){for(let o of r)this.gpuDataManager.release(o.id);this.kernelPersistentData.delete(t)}this.kernelCustomData.delete(t),this.kernels.delete(t)}computeKernel(t,r,o){let a=this.kernels.get(t);if(!a)throw new Error(`kernel not created: ${t}`);let[u,i,d,f]=a;if(this.currentKernelId!==null)throw new Error(`kernel \"[${u}] ${i}\" is not allowed to be called recursively`);this.currentKernelId=t,f[0]&&(f[1]=f[0](f[1]),f[0]=void 0),Ee(\"info\",()=>`[WebGPU] Start to run kernel \"[${u}] ${i}\"...`);let h=this.env.debug;this.temporaryData=[];try{return h&&this.device.pushErrorScope(\"validation\"),d(r,f[1]),0}catch(c){return o.push(Promise.resolve(`[WebGPU] Kernel \"[${u}] ${i}\" failed. ${c}`)),1}finally{h&&o.push(this.device.popErrorScope().then(c=>c?`GPU validation error for kernel \"[${u}] ${i}\": ${c.message}`:null));for(let c of this.temporaryData)this.gpuDataManager.release(c.id);this.temporaryData=[],this.currentKernelId=null}}registerBuffer(t,r,o,a){let u=this.sessionExternalDataMapping.get(t);u||(u=new Map,this.sessionExternalDataMapping.set(t,u));let i=u.get(r),d=this.gpuDataManager.registerExternalBuffer(o,a,i?.[1]);return u.set(r,[d,o]),d}unregisterBuffers(t){let r=this.sessionExternalDataMapping.get(t);r&&(r.forEach(o=>this.gpuDataManager.unregisterExternalBuffer(o[1])),this.sessionExternalDataMapping.delete(t))}getBuffer(t){let r=this.gpuDataManager.get(t);if(!r)throw new Error(`no GPU data for buffer: ${t}`);return r.buffer}createDownloader(t,r,o){return async()=>{let a=await Bn(this,t,r);return ia(a.buffer,o)}}}});var Pu={};Vr(Pu,{init:()=>jd});var vr,to,jd,Ru=K(()=>{\"use strict\";We();_u();St();ge();vr=class e{constructor(t,r,o,a){this.module=t;this.dataType=r;this.data=o;this.dims=a}getFloat32Array(){if(this.dataType!==1)throw new Error(\"Invalid data type\");let t=z.size(this.dims);return t===0?new Float32Array:new Float32Array(this.module.HEAP8.buffer,this.data,t)}getBigInt64Array(){if(this.dataType!==7)throw new Error(\"Invalid data type\");let t=z.size(this.dims);return t===0?new BigInt64Array:new BigInt64Array(this.module.HEAP8.buffer,this.data,t)}getInt32Array(){if(this.dataType!==6)throw new Error(\"Invalid data type\");let t=z.size(this.dims);return t===0?new Int32Array:new Int32Array(this.module.HEAP8.buffer,this.data,t)}reshape(t){if(z.size(t)!==z.size(this.dims))throw new Error(\"Invalid new shape\");return new e(this.module,this.dataType,this.data,t)}},to=class{constructor(t,r,o){this.module=t;this.backend=r;this.customDataOffset=0;this.customDataSize=0;let a=t.HEAPU32,u=o>>2;this.opKernelContext=a[u++];let i=a[u++];this.outputCount=a[u++],this.customDataOffset=a[u++],this.customDataSize=a[u++];let d=[];for(let f=0;f<i;f++){let h=a[u++],c=a[u++],C=a[u++],b=[];for(let $=0;$<C;$++)b.push(a[u++]);d.push(new vr(t,h,c,b))}this.inputs=d}get kernelCustomData(){return this.backend.currentKernelCustomData}get customDataBuffer(){return this.module.HEAPU8.subarray(this.customDataOffset,this.customDataOffset+this.customDataSize)}compute(t,r){let o=r?.inputs?.map(d=>typeof d==\"number\"?this.inputs[d]:d)??this.inputs,a=r?.outputs??[],u=(d,f,h)=>new vr(this.module,f,this.output(d,h),h),i=(d,f)=>{let h=mr(d);if(!h)throw new Error(`Unsupported data type: ${d}`);let c=h*z.size(f);return new vr(this.module,d,this.backend.gpuDataManager.create(c).id,f)};return this.backend.run(t,o,a,u,i)}output(t,r){let o=this.module.stackSave();try{let a=this.module.stackAlloc((1+r.length)*4),u=a>>2;this.module.HEAPU32[u++]=r.length;for(let i=0;i<r.length;i++)this.module.HEAPU32[u++]=r[i];return this.module._JsepOutput(this.opKernelContext,t,a)}catch(a){throw new Error(`Failed to generate kernel's output[${t}] with dims [${r}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${a}`)}finally{this.module.stackRestore(o)}}},jd=async(e,t)=>{let r=e.jsepInit;if(r&&navigator.gpu){if(!t.wasm.simd)throw new Error(\"Not supported for WebGPU=ON and SIMD=OFF. Please set `env.wasm.simd` to true when using WebGPU EP\");let o=new ln;await o.initialize(t),r(o,a=>o.alloc(a),a=>o.free(a),(a,u,i,d=!1)=>{if(d)Ee(\"verbose\",()=>`[WebGPU] jsepCopyGpuToGpu: src=${a}, dst=${u}, size=${i}`),o.memcpy(a,u);else{Ee(\"verbose\",()=>`[WebGPU] jsepCopyCpuToGpu: dataOffset=${a}, gpuDataId=${u}, size=${i}`);let f=e.HEAPU8.subarray(a,a+i);o.upload(u,f)}},async(a,u,i)=>{Ee(\"verbose\",()=>`[WebGPU] jsepCopyGpuToCpu: gpuDataId=${a}, dataOffset=${u}, size=${i}`),await o.download(a,()=>e.HEAPU8.subarray(u,u+i))},(a,u,i)=>o.createKernel(a,u,i,t.debug||t.webgpu.profilingMode===\"default\"?e.UTF8ToString(e._JsepGetNodeName(u)):`${u}`),a=>o.releaseKernel(a),(a,u,i,d)=>{Ee(\"verbose\",()=>`[WebGPU] jsepRun: sessionHandle=${i}, kernel=${a}, contextDataOffset=${u}`);let f=new to(e,o,u);return o.computeKernel(a,f,d)})}}});var Zo;Zo=Go();var yl=Yo(),_n,Pn=!1,Ur=!1,Xo=!1,bl=()=>{try{return typeof SharedArrayBuffer>\"u\"?!1:(typeof MessageChannel<\"u\"&&new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11])))}catch{return!1}},wl=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch{return!1}},vl=(e,t)=>e?t?\"ort-wasm-simd-threaded.wasm\":\"ort-wasm-simd.wasm\":t?\"ort-wasm-threaded.wasm\":\"ort-wasm.wasm\",Qo=async e=>{if(Pn)return Promise.resolve();if(Ur)throw new Error(\"multiple calls to 'initializeWebAssembly()' detected.\");if(Xo)throw new Error(\"previous call to 'initializeWebAssembly()' failed.\");Ur=!0;let t=e.initTimeout,r=e.numThreads,o=e.simd,a=r>1&&bl(),u=o&&wl(),i=e.wasmPaths,d=typeof i==\"string\"?i:void 0,f=vl(u,a),h=typeof i==\"object\"?i[f]:void 0,c=!1,C=[];if(t>0&&C.push(new Promise(b=>{setTimeout(()=>{c=!0,b()},t)})),C.push(new Promise((b,$)=>{let S=a?yl:Zo,x={locateFile:(A,k)=>{if(a&&A.endsWith(\".worker.js\")&&typeof Blob<\"u\")return URL.createObjectURL(new Blob([Jo()],{type:\"text/javascript\"}));if(A.endsWith(\".wasm\")){if(h)return h;let O=d??k;return f===\"ort-wasm-simd.wasm\"?O+\"ort-wasm-simd.jsep.wasm\":f===\"ort-wasm-simd-threaded.wasm\"?O+\"ort-wasm-simd-threaded.jsep.wasm\":O+f}return k+A}};if(a)if(typeof Blob>\"u\")x.mainScriptUrlOrBlob=(void 0)(__dirname,\"ort-wasm-threaded.js\");else{let A=`var ortWasmThreaded=${S.toString()};`;x.mainScriptUrlOrBlob=new Blob([A],{type:\"text/javascript\"})}S(x).then(A=>{Ur=!1,Pn=!0,_n=A,b()},A=>{Ur=!1,Xo=!0,$(A)})})),await Promise.race(C),c)throw new Error(`WebAssembly backend initializing failed due to timeout: ${t}ms`)},_e=()=>{if(Pn&&_n)return _n;throw new Error(\"WebAssembly is not initialized yet.\")};var Re=(e,t)=>{let r=_e(),o=r.lengthBytesUTF8(e)+1,a=r._malloc(o);return r.stringToUTF8(e,a,o),t.push(a),a},pr=(e,t,r,o)=>{if(typeof e==\"object\"&&e!==null){if(r.has(e))throw new Error(\"Circular reference in options\");r.add(e)}Object.entries(e).forEach(([a,u])=>{let i=t?t+a:a;if(typeof u==\"object\")pr(u,i+\".\",r,o);else if(typeof u==\"string\"||typeof u==\"number\")o(i,u.toString());else if(typeof u==\"boolean\")o(i,u?\"1\":\"0\");else throw new Error(`Can't handle extra config type: ${typeof u}`)})},Ae=e=>{let t=_e(),r=t.stackSave();try{let o=t.stackAlloc(8);t._OrtGetLastError(o,o+4);let a=t.HEAP32[o/4],u=t.HEAPU32[o/4+1],i=u?t.UTF8ToString(u):\"\";throw new Error(`${e} ERROR_CODE: ${a}, ERROR_MESSAGE: ${i}`)}finally{t.stackRestore(r)}};var ea=e=>{let t=_e(),r=0,o=[],a=e||{};try{if(e?.logSeverityLevel===void 0)a.logSeverityLevel=2;else if(typeof e.logSeverityLevel!=\"number\"||!Number.isInteger(e.logSeverityLevel)||e.logSeverityLevel<0||e.logSeverityLevel>4)throw new Error(`log serverity level is not valid: ${e.logSeverityLevel}`);if(e?.logVerbosityLevel===void 0)a.logVerbosityLevel=0;else if(typeof e.logVerbosityLevel!=\"number\"||!Number.isInteger(e.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${e.logVerbosityLevel}`);e?.terminate===void 0&&(a.terminate=!1);let u=0;return e?.tag!==void 0&&(u=Re(e.tag,o)),r=t._OrtCreateRunOptions(a.logSeverityLevel,a.logVerbosityLevel,!!a.terminate,u),r===0&&Ae(\"Can't create run options.\"),e?.extra!==void 0&&pr(e.extra,\"\",new WeakSet,(i,d)=>{let f=Re(i,o),h=Re(d,o);t._OrtAddRunConfigEntry(r,f,h)!==0&&Ae(`Can't set a run config entry: ${i} - ${d}.`)}),[r,o]}catch(u){throw r!==0&&t._OrtReleaseRunOptions(r),o.forEach(i=>t._free(i)),u}};var $l=e=>{switch(e){case\"disabled\":return 0;case\"basic\":return 1;case\"extended\":return 2;case\"all\":return 99;default:throw new Error(`unsupported graph optimization level: ${e}`)}},xl=e=>{switch(e){case\"sequential\":return 0;case\"parallel\":return 1;default:throw new Error(`unsupported execution mode: ${e}`)}},Sl=e=>{e.extra||(e.extra={}),e.extra.session||(e.extra.session={});let t=e.extra.session;t.use_ort_model_bytes_directly||(t.use_ort_model_bytes_directly=\"1\"),e.executionProviders&&e.executionProviders.some(r=>(typeof r==\"string\"?r:r.name)===\"webgpu\")&&(e.enableMemPattern=!1)},Cl=(e,t,r)=>{for(let o of t){let a=typeof o==\"string\"?o:o.name;switch(a){case\"xnnpack\":a=\"XNNPACK\";break;case\"webnn\":if(a=\"WEBNN\",typeof o!=\"string\"){let i=o;if(i?.deviceType){let d=Re(\"deviceType\",r),f=Re(i.deviceType,r);_e()._OrtAddSessionConfigEntry(e,d,f)!==0&&Ae(`Can't set a session config entry: 'deviceType' - ${i.deviceType}.`)}if(i?.numThreads){let d=i.numThreads;(typeof d!=\"number\"||!Number.isInteger(d)||d<0)&&(d=0);let f=Re(\"numThreads\",r),h=Re(d.toString(),r);_e()._OrtAddSessionConfigEntry(e,f,h)!==0&&Ae(`Can't set a session config entry: 'numThreads' - ${i.numThreads}.`)}if(i?.powerPreference){let d=Re(\"powerPreference\",r),f=Re(i.powerPreference,r);_e()._OrtAddSessionConfigEntry(e,d,f)!==0&&Ae(`Can't set a session config entry: 'powerPreference' - ${i.powerPreference}.`)}}break;case\"webgpu\":if(a=\"JS\",typeof o!=\"string\"){let i=o;if(i?.preferredLayout){if(i.preferredLayout!==\"NCHW\"&&i.preferredLayout!==\"NHWC\")throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${i.preferredLayout}`);let d=Re(\"preferredLayout\",r),f=Re(i.preferredLayout,r);_e()._OrtAddSessionConfigEntry(e,d,f)!==0&&Ae(`Can't set a session config entry: 'preferredLayout' - ${i.preferredLayout}.`)}}break;case\"wasm\":case\"cpu\":continue;default:throw new Error(`not supported execution provider: ${a}`)}let u=Re(a,r);_e()._OrtAppendExecutionProvider(e,u)!==0&&Ae(`Can't append execution provider: ${a}.`)}},ta=e=>{let t=_e(),r=0,o=[],a=e||{};Sl(a);try{let u=$l(a.graphOptimizationLevel??\"all\"),i=xl(a.executionMode??\"sequential\"),d=typeof a.logId==\"string\"?Re(a.logId,o):0,f=a.logSeverityLevel??2;if(!Number.isInteger(f)||f<0||f>4)throw new Error(`log serverity level is not valid: ${f}`);let h=a.logVerbosityLevel??0;if(!Number.isInteger(h)||h<0||h>4)throw new Error(`log verbosity level is not valid: ${h}`);let c=typeof a.optimizedModelFilePath==\"string\"?Re(a.optimizedModelFilePath,o):0;if(r=t._OrtCreateSessionOptions(u,!!a.enableCpuMemArena,!!a.enableMemPattern,i,!!a.enableProfiling,0,d,f,h,c),r===0&&Ae(\"Can't create session options.\"),a.executionProviders&&Cl(r,a.executionProviders,o),a.freeDimensionOverrides)for(let[C,b]of Object.entries(a.freeDimensionOverrides)){if(typeof C!=\"string\")throw new Error(`free dimension override name must be a string: ${C}`);if(typeof b!=\"number\"||!Number.isInteger(b)||b<0)throw new Error(`free dimension override value must be a non-negative integer: ${b}`);let $=Re(C,o);t._OrtAddFreeDimensionOverride(r,$,b)!==0&&Ae(`Can't set a free dimension override: ${C} - ${b}.`)}return a.extra!==void 0&&pr(a.extra,\"\",new WeakSet,(C,b)=>{let $=Re(C,o),S=Re(b,o);t._OrtAddSessionConfigEntry(r,$,S)!==0&&Ae(`Can't set a session config entry: ${C} - ${b}.`)}),[r,o]}catch(u){throw r!==0&&t._OrtReleaseSessionOptions(r),o.forEach(i=>t._free(i)),u}};We();var ku=!1,qd=e=>{let t=_e(),r=t.stackSave();try{let o=t.stackAlloc(8);return t._OrtGetInputOutputCount(e,o,o+4)!==0&&Ae(\"Can't get session input/output count.\"),[t.HEAP32[o/4],t.HEAP32[o/4+1]]}finally{t.stackRestore(r)}},Kd=(e,t)=>{_e()._OrtInit(e,t)!==0&&Ae(\"Can't initialize onnxruntime.\")},Bu=async e=>{Kd(e.wasm.numThreads,hr(e.logLevel));{let t=(Ru(),qt(Pu)).init;await t(_e(),e)}ku=!0},$r=new Map,Du=()=>ku,ro=e=>{let t=_e(),r=t._malloc(e.byteLength);if(r===0)throw new Error(`Can't create a session. failed to allocate a buffer of size ${e.byteLength}.`);return t.HEAPU8.set(e,r),[r,e.byteLength]},no=(e,t)=>{let r=_e(),o=0,a=0,u=0,i=[],d=[],f=[];try{[a,i]=ta(t),o=r._OrtCreateSession(e[0],e[1],a),o===0&&Ae(\"Can't create a session.\");let[h,c]=qd(o),C=[],b=[],$=[];for(let x=0;x<h;x++){let A=r._OrtGetInputName(o,x);A===0&&Ae(\"Can't get an input name.\"),d.push(A),C.push(r.UTF8ToString(A))}for(let x=0;x<c;x++){let A=r._OrtGetOutputName(o,x);A===0&&Ae(\"Can't get an output name.\"),f.push(A);let k=r.UTF8ToString(A);b.push(k);{let O=typeof t?.preferredOutputLocation==\"string\"?t.preferredOutputLocation:t?.preferredOutputLocation?.[k]??\"cpu\";if(O!==\"cpu\"&&O!==\"cpu-pinned\"&&O!==\"gpu-buffer\")throw new Error(`Not supported preferred output location: ${O}.`);$.push(O)}}let S=null;return $.some(x=>x===\"gpu-buffer\")&&(u=r._OrtCreateBinding(o),u===0&&Ae(\"Can't create IO binding.\"),S={handle:u,outputPreferredLocations:$,outputPreferredLocationsEncoded:$.map(x=>Mn(x))}),$r.set(o,[o,d,f,S]),[o,C,b]}catch(h){throw d.forEach(c=>r._OrtFree(c)),f.forEach(c=>r._OrtFree(c)),u!==0&&r._OrtReleaseBinding(u),o!==0&&r._OrtReleaseSession(o),h}finally{r._free(e[0]),a!==0&&r._OrtReleaseSessionOptions(a),i.forEach(h=>r._free(h))}},Wu=(e,t)=>{let r=ro(e);return no(r,t)},zu=e=>{let t=_e(),r=$r.get(e);if(!r)throw new Error(`cannot release session. invalid session id: ${e}`);let[o,a,u,i]=r;i&&t._OrtReleaseBinding(i.handle),t.jsepUnregisterBuffers?.(e),a.forEach(d=>t._OrtFree(d)),u.forEach(d=>t._OrtFree(d)),t._OrtReleaseSession(o),$r.delete(e)},Mu=(e,t,r,o,a)=>{if(!e){t.push(0);return}let u=_e(),i=e[0],d=e[1],f=e[3],h,c;if(i===\"string\"&&f===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");if(f===\"gpu-buffer\"){let $=e[2].gpuBuffer,S=mr(Rn(i));c=d.reduce((x,A)=>x*A,1)*S,h=u.jsepRegisterBuffer(o,a,$,c)}else{let $=e[2];if(Array.isArray($)){c=4*$.length,h=u._malloc(c),r.push(h);let S=h/4;for(let x=0;x<$.length;x++){if(typeof $[x]!=\"string\")throw new TypeError(`tensor data at index ${x} is not a string`);u.HEAPU32[S++]=Re($[x],r)}}else c=$.byteLength,h=u._malloc(c),r.push(h),u.HEAPU8.set(new Uint8Array($.buffer,$.byteOffset,c),h)}let C=u.stackSave(),b=u.stackAlloc(4*d.length);try{let $=b/4;d.forEach(x=>u.HEAP32[$++]=x);let S=u._OrtCreateTensor(Rn(i),h,c,b,d.length,Mn(f));S===0&&Ae(`Can't create tensor for input/output. session=${o}, index=${a}.`),t.push(S)}finally{u.stackRestore(C)}},Vu=async(e,t,r,o,a,u)=>{let i=_e(),d=$r.get(e);if(!d)throw new Error(`cannot run inference. invalid session id: ${e}`);let[f,h,c,C]=d,b=t.length,$=o.length,S=0,x=[],A=[],k=[],O=[],P=i.stackSave(),R=i.stackAlloc(b*4),V=i.stackAlloc(b*4),B=i.stackAlloc($*4),W=i.stackAlloc($*4);try{[S,x]=ea(u);for(let Z=0;Z<b;Z++)Mu(r[Z],A,O,e,t[Z]);for(let Z=0;Z<$;Z++)Mu(a[Z],k,O,e,b+o[Z]);let q=R/4,ee=V/4,oe=B/4,D=W/4;for(let Z=0;Z<b;Z++)i.HEAPU32[q++]=A[Z],i.HEAPU32[ee++]=h[t[Z]];for(let Z=0;Z<$;Z++)i.HEAPU32[oe++]=k[Z],i.HEAPU32[D++]=c[o[Z]];if(C){let{handle:Z,outputPreferredLocations:ve,outputPreferredLocationsEncoded:Te}=C;if(h.length!==b)throw new Error(`input count from feeds (${b}) is expected to be always equal to model's input count (${h.length}).`);for(let be=0;be<b;be++){let Be=t[be];await i._OrtBindInput(Z,h[Be],A[be])!==0&&Ae(`Can't bind input[${be}] for session=${e}.`)}for(let be=0;be<$;be++){let Be=o[be];a[be]?.[3]?i._OrtBindOutput(Z,c[Be],k[be],0)!==0&&Ae(`Can't bind pre-allocated output[${be}] for session=${e}.`):i._OrtBindOutput(Z,c[Be],0,Te[Be])!==0&&Ae(`Can't bind output[${be}] to ${ve[be]} for session=${e}.`)}}let te;C?te=await i._OrtRunWithBinding(f,C.handle,$,B,S):te=await i._OrtRun(f,V,R,b,W,$,B,S),te!==0&&Ae(\"failed to call OrtRun().\");let Ie=[];for(let Z=0;Z<$;Z++){let ve=i.HEAPU32[B/4+Z];if(ve===k[Z]){Ie.push(a[Z]);continue}let Te=i.stackSave(),be=i.stackAlloc(4*4),Be=!1,Se,Ue=0;try{i._OrtGetTensorData(ve,be,be+4,be+8,be+12)!==0&&Ae(`Can't access output tensor data on index ${Z}.`);let Ke=be/4,Ye=i.HEAPU32[Ke++];Ue=i.HEAPU32[Ke++];let G=i.HEAPU32[Ke++],pe=i.HEAPU32[Ke++],de=[];for(let Ce=0;Ce<pe;Ce++)de.push(i.HEAPU32[G/4+Ce]);i._OrtFree(G);let Ne=de.reduce((Ce,Pe)=>Ce*Pe,1);Se=fr(Ye);let Ge=C?.outputPreferredLocations[o[Z]];if(Se===\"string\"){if(Ge===\"gpu-buffer\")throw new Error(\"String tensor is not supported on GPU.\");let Ce=[],Pe=Ue/4;for(let vt=0;vt<Ne;vt++){let He=i.HEAPU32[Pe++],zt=vt===Ne-1?void 0:i.HEAPU32[Pe]-He;Ce.push(i.UTF8ToString(He,zt))}Ie.push([Se,de,Ce,\"cpu\"])}else if(Ge===\"gpu-buffer\"&&Ne>0){let Ce=i.jsepGetBuffer(Ue),Pe=mr(Ye);if(Pe===void 0||!ra(Se))throw new Error(`Unsupported data type: ${Se}`);Be=!0,Ie.push([Se,de,{gpuBuffer:Ce,download:i.jsepCreateDownloader(Ce,Ne*Pe,Se),dispose:()=>{i._OrtReleaseTensor(ve)}},\"gpu-buffer\"])}else{let Ce=Nr(Se),Pe=new Ce(Ne);new Uint8Array(Pe.buffer,Pe.byteOffset,Pe.byteLength).set(i.HEAPU8.subarray(Ue,Ue+Pe.byteLength)),Ie.push([Se,de,Pe,\"cpu\"])}}finally{i.stackRestore(Te),Se===\"string\"&&Ue&&i._free(Ue),Be||i._OrtReleaseTensor(ve)}}return C&&i._OrtClearBoundOutputs(C.handle),Ie}finally{i.stackRestore(P),A.forEach(q=>i._OrtReleaseTensor(q)),k.forEach(q=>i._OrtReleaseTensor(q)),O.forEach(q=>i._free(q)),S!==0&&i._OrtReleaseRunOptions(S),x.forEach(q=>i._free(q))}},Uu=e=>{let t=_e(),r=$r.get(e);if(!r)throw new Error(\"invalid session id\");let o=r[0],a=t._OrtEndProfiling(o);a===0&&Ae(\"Can't get an profile file name.\"),t._OrtFree(a)},Nu=e=>{let t=[];for(let r of e){let o=r[2];!Array.isArray(o)&&\"buffer\"in o&&t.push(o.buffer)}return t};self.onmessage=e=>{switch(e.data.type){case\"init-wasm\":try{Qo(e.data.in).then(()=>postMessage({type:\"init-wasm\"}),t=>postMessage({type:\"init-wasm\",err:t}))}catch(t){postMessage({type:\"init-wasm\",err:t})}break;case\"init-ort\":try{Bu(e.data.in).then(()=>postMessage({type:\"init-ort\"}),t=>postMessage({type:\"init-ort\",err:t}))}catch(t){postMessage({type:\"init-ort\",err:t})}break;case\"create_allocate\":try{let{model:t}=e.data.in,r=ro(t);postMessage({type:\"create_allocate\",out:r})}catch(t){postMessage({type:\"create_allocate\",err:t})}break;case\"create_finalize\":try{let{modeldata:t,options:r}=e.data.in,o=no(t,r);postMessage({type:\"create_finalize\",out:o})}catch(t){postMessage({type:\"create_finalize\",err:t})}break;case\"create\":try{let{model:t,options:r}=e.data.in,o=Wu(t,r);postMessage({type:\"create\",out:o})}catch(t){postMessage({type:\"create\",err:t})}break;case\"release\":try{let t=e.data.in;zu(t),postMessage({type:\"release\"})}catch(t){postMessage({type:\"release\",err:t})}break;case\"run\":try{let{sessionId:t,inputIndices:r,inputs:o,outputIndices:a,options:u}=e.data.in;Vu(t,r,o,a,u).then(i=>{postMessage({type:\"run\",out:i},Nu(i))},i=>{postMessage({type:\"run\",err:i})})}catch(t){postMessage({type:\"run\",err:t})}break;case\"end-profiling\":try{let t=e.data.in;Uu(t),postMessage({type:\"end-profiling\"})}catch(t){postMessage({type:\"end-profiling\",err:t})}break;case\"is-ort-env-initialized\":try{let t=Du();postMessage({type:\"is-ort-env-initialized\",out:t})}catch(t){postMessage({type:\"is-ort-env-initialized\",err:t})}break;default:}};})();\n/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {Env, env, InferenceSession} from 'onnxruntime-common';\n\nimport {OrtWasmMessage, SerializableModeldata, SerializableSessionMetadata, SerializableTensorMetadata, TensorMetadata} from './proxy-messages';\nimport * as core from './wasm-core-impl';\nimport {initializeWebAssembly} from './wasm-factory';\n\nconst isProxy = (): boolean => !!env.wasm.proxy && typeof document !== 'undefined';\nlet proxyWorker: Worker|undefined;\nlet initializing = false;\nlet initialized = false;\nlet aborted = false;\n\n// resolve; reject\ntype PromiseCallbacks<T = void> = [(result: T) => void, (reason: unknown) => void];\n\nlet initWasmCallbacks: PromiseCallbacks;\nlet initOrtCallbacks: PromiseCallbacks;\nconst createSessionAllocateCallbacks: Array<PromiseCallbacks<SerializableModeldata>> = [];\nconst createSessionFinalizeCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst createSessionCallbacks: Array<PromiseCallbacks<SerializableSessionMetadata>> = [];\nconst releaseSessionCallbacks: Array<PromiseCallbacks<void>> = [];\nconst runCallbacks: Array<PromiseCallbacks<SerializableTensorMetadata[]>> = [];\nconst endProfilingCallbacks: Array<PromiseCallbacks<void>> = [];\nconst isOrtEnvInitializedCallbacks: Array<PromiseCallbacks<boolean>> = [];\n\nconst ensureWorker = (): void => {\n  if (initializing || !initialized || aborted || !proxyWorker) {\n    throw new Error('worker not ready');\n  }\n};\n\nconst onProxyWorkerMessage = (ev: MessageEvent<OrtWasmMessage>): void => {\n  switch (ev.data.type) {\n    case 'init-wasm':\n      initializing = false;\n      if (ev.data.err) {\n        aborted = true;\n        initWasmCallbacks[1](ev.data.err);\n      } else {\n        initialized = true;\n        initWasmCallbacks[0]();\n      }\n      break;\n    case 'init-ort':\n      if (ev.data.err) {\n        initOrtCallbacks[1](ev.data.err);\n      } else {\n        initOrtCallbacks[0]();\n      }\n      break;\n    case 'create_allocate':\n      if (ev.data.err) {\n        createSessionAllocateCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionAllocateCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create_finalize':\n      if (ev.data.err) {\n        createSessionFinalizeCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionFinalizeCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'create':\n      if (ev.data.err) {\n        createSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        createSessionCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'release':\n      if (ev.data.err) {\n        releaseSessionCallbacks.shift()![1](ev.data.err);\n      } else {\n        releaseSessionCallbacks.shift()![0]();\n      }\n      break;\n    case 'run':\n      if (ev.data.err) {\n        runCallbacks.shift()![1](ev.data.err);\n      } else {\n        runCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    case 'end-profiling':\n      if (ev.data.err) {\n        endProfilingCallbacks.shift()![1](ev.data.err);\n      } else {\n        endProfilingCallbacks.shift()![0]();\n      }\n      break;\n    case 'is-ort-env-initialized':\n      if (ev.data.err) {\n        isOrtEnvInitializedCallbacks.shift()![1](ev.data.err);\n      } else {\n        isOrtEnvInitializedCallbacks.shift()![0](ev.data.out!);\n      }\n      break;\n    default:\n  }\n};\n\nconst scriptSrc = typeof document !== 'undefined' ? (document?.currentScript as HTMLScriptElement)?.src : undefined;\n\nexport const initializeWebAssemblyInstance = async(): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    if (initialized) {\n      return;\n    }\n    if (initializing) {\n      throw new Error('multiple calls to \\'initWasm()\\' detected.');\n    }\n    if (aborted) {\n      throw new Error('previous call to \\'initWasm()\\' failed.');\n    }\n\n    initializing = true;\n\n    // overwrite wasm filepaths\n    if (env.wasm.wasmPaths === undefined) {\n      if (scriptSrc && scriptSrc.indexOf('blob:') !== 0) {\n        env.wasm.wasmPaths = scriptSrc.substr(0, +(scriptSrc).lastIndexOf('/') + 1);\n      }\n    }\n\n    return new Promise<void>((resolve, reject) => {\n      proxyWorker?.terminate();\n\n      const workerUrl = URL.createObjectURL(new Blob(\n          [\n            // This require() function is handled by esbuild plugin to load file content as string.\n            // eslint-disable-next-line @typescript-eslint/no-require-imports\n            require('./proxy-worker/main')\n          ],\n          {type: 'text/javascript'}));\n      proxyWorker = new Worker(workerUrl, {name: 'ort-wasm-proxy-worker'});\n      proxyWorker.onerror = (ev: ErrorEvent) => reject(ev);\n      proxyWorker.onmessage = onProxyWorkerMessage;\n      URL.revokeObjectURL(workerUrl);\n      initWasmCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-wasm', in : env.wasm};\n      proxyWorker.postMessage(message);\n    });\n\n  } else {\n    return initializeWebAssembly(env.wasm);\n  }\n};\n\nexport const initializeRuntime = async(env: Env): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      initOrtCallbacks = [resolve, reject];\n      const message: OrtWasmMessage = {type: 'init-ort', in : env};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    await core.initRuntime(env);\n  }\n};\n\nexport const createSessionAllocate = async(model: Uint8Array): Promise<SerializableModeldata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<SerializableModeldata>((resolve, reject) => {\n      createSessionAllocateCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create_allocate', in : {model}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSessionAllocate(model);\n  }\n};\n\nexport const createSessionFinalize = async(modeldata: SerializableModeldata, options?: InferenceSession.SessionOptions):\n    Promise<SerializableSessionMetadata> => {\n      if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n        ensureWorker();\n        return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n          createSessionFinalizeCallbacks.push([resolve, reject]);\n          const message: OrtWasmMessage = {type: 'create_finalize', in : {modeldata, options}};\n          proxyWorker!.postMessage(message);\n        });\n      } else {\n        return core.createSessionFinalize(modeldata, options);\n      }\n    };\n\nexport const createSession =\n    async(model: Uint8Array, options?: InferenceSession.SessionOptions): Promise<SerializableSessionMetadata> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check unsupported options\n    if (options?.preferredOutputLocation) {\n      throw new Error('session option \"preferredOutputLocation\" is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableSessionMetadata>((resolve, reject) => {\n      createSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'create', in : {model, options}};\n      proxyWorker!.postMessage(message, [model.buffer]);\n    });\n  } else {\n    return core.createSession(model, options);\n  }\n};\n\nexport const releaseSession = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      releaseSessionCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'release', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.releaseSession(sessionId);\n  }\n};\n\nexport const run = async(\n    sessionId: number, inputIndices: number[], inputs: TensorMetadata[], outputIndices: number[],\n    outputs: Array<TensorMetadata|null>, options: InferenceSession.RunOptions): Promise<TensorMetadata[]> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    // check inputs location\n    if (inputs.some(t => t[3] !== 'cpu')) {\n      throw new Error('input tensor on GPU is not supported for proxy.');\n    }\n    // check outputs location\n    if (outputs.some(t => t)) {\n      throw new Error('pre-allocated output tensor is not supported for proxy.');\n    }\n    ensureWorker();\n    return new Promise<SerializableTensorMetadata[]>((resolve, reject) => {\n      runCallbacks.push([resolve, reject]);\n      const serializableInputs = inputs as SerializableTensorMetadata[];  // every input is on CPU.\n      const message: OrtWasmMessage =\n          {type: 'run', in : {sessionId, inputIndices, inputs: serializableInputs, outputIndices, options}};\n      proxyWorker!.postMessage(message, core.extractTransferableBuffers(serializableInputs));\n    });\n  } else {\n    return core.run(sessionId, inputIndices, inputs, outputIndices, outputs, options);\n  }\n};\n\nexport const endProfiling = async(sessionId: number): Promise<void> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<void>((resolve, reject) => {\n      endProfilingCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'end-profiling', in : sessionId};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    core.endProfiling(sessionId);\n  }\n};\n\nexport const isOrtEnvInitialized = async(): Promise<boolean> => {\n  if (!BUILD_DEFS.DISABLE_WASM_PROXY && isProxy()) {\n    ensureWorker();\n    return new Promise<boolean>((resolve, reject) => {\n      isOrtEnvInitializedCallbacks.push([resolve, reject]);\n      const message: OrtWasmMessage = {type: 'is-ort-env-initialized'};\n      proxyWorker!.postMessage(message);\n    });\n  } else {\n    return core.isOrtEnvInitialized();\n  }\n};\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {readFile} from 'node:fs/promises';\nimport {env, InferenceSession, InferenceSessionHandler, SessionHandler, Tensor} from 'onnxruntime-common';\n\nimport {SerializableModeldata, TensorMetadata} from './proxy-messages';\nimport {createSession, createSessionAllocate, createSessionFinalize, endProfiling, initializeRuntime, isOrtEnvInitialized, releaseSession, run} from './proxy-wrapper';\nimport {isGpuBufferSupportedType} from './wasm-common';\n\nlet runtimeInitializationPromise: Promise<void>|undefined;\n\nexport const encodeTensorMetadata = (tensor: Tensor, getName: () => string): TensorMetadata => {\n  switch (tensor.location) {\n    case 'cpu':\n      return [tensor.type, tensor.dims, tensor.data, 'cpu'];\n    case 'gpu-buffer':\n      return [tensor.type, tensor.dims, {gpuBuffer: tensor.gpuBuffer}, 'gpu-buffer'];\n    default:\n      throw new Error(`invalid data location: ${tensor.location} for ${getName()}`);\n  }\n};\n\nexport const decodeTensorMetadata = (tensor: TensorMetadata): Tensor => {\n  switch (tensor[3]) {\n    case 'cpu':\n      return new Tensor(tensor[0], tensor[2], tensor[1]);\n    case 'gpu-buffer': {\n      const dataType = tensor[0];\n      if (!isGpuBufferSupportedType(dataType)) {\n        throw new Error(`not supported data type: ${dataType} for deserializing GPU tensor`);\n      }\n      const {gpuBuffer, download, dispose} = tensor[2];\n      return Tensor.fromGpuBuffer(gpuBuffer, {dataType, dims: tensor[1], download, dispose});\n    }\n    default:\n      throw new Error(`invalid data location: ${tensor[3]}`);\n  }\n};\n\nexport class OnnxruntimeWebAssemblySessionHandler implements InferenceSessionHandler {\n  private sessionId: number;\n\n  inputNames: string[];\n  outputNames: string[];\n\n  async createSessionAllocate(path: string): Promise<SerializableModeldata> {\n    // fetch model from url and move to wasm heap. The arraybufffer that held the http\n    // response is freed once we return\n    const response = await fetch(path);\n    if (response.status !== 200) {\n      throw new Error(`failed to load model: ${path}`);\n    }\n    const arrayBuffer = await response.arrayBuffer();\n    return createSessionAllocate(new Uint8Array(arrayBuffer));\n  }\n\n  async loadModel(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions): Promise<void> {\n    if (!(await isOrtEnvInitialized())) {\n      if (!runtimeInitializationPromise) {\n        runtimeInitializationPromise = initializeRuntime(env);\n      }\n      await runtimeInitializationPromise;\n      runtimeInitializationPromise = undefined;\n    }\n\n    if (typeof pathOrBuffer === 'string') {\n      if (typeof process !== 'undefined' && process.versions && process.versions.node) {\n        // node\n        const model = await readFile(pathOrBuffer);\n        [this.sessionId, this.inputNames, this.outputNames] = await createSession(model, options);\n      } else {\n        // browser\n        // fetch model and move to wasm heap.\n        const modelData: SerializableModeldata = await this.createSessionAllocate(pathOrBuffer);\n        // create the session\n        [this.sessionId, this.inputNames, this.outputNames] = await createSessionFinalize(modelData, options);\n      }\n    } else {\n      [this.sessionId, this.inputNames, this.outputNames] = await createSession(pathOrBuffer, options);\n    }\n  }\n\n  async dispose(): Promise<void> {\n    return releaseSession(this.sessionId);\n  }\n\n  async run(feeds: SessionHandler.FeedsType, fetches: SessionHandler.FetchesType, options: InferenceSession.RunOptions):\n      Promise<SessionHandler.ReturnType> {\n    const inputArray: Tensor[] = [];\n    const inputIndices: number[] = [];\n    Object.entries(feeds).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.inputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid input '${name}'`);\n      }\n      inputArray.push(tensor);\n      inputIndices.push(index);\n    });\n\n    const outputArray: Array<Tensor|null> = [];\n    const outputIndices: number[] = [];\n    Object.entries(fetches).forEach(kvp => {\n      const name = kvp[0];\n      const tensor = kvp[1];\n      const index = this.outputNames.indexOf(name);\n      if (index === -1) {\n        throw new Error(`invalid output '${name}'`);\n      }\n      outputArray.push(tensor);\n      outputIndices.push(index);\n    });\n\n    const inputs =\n        inputArray.map((t, i) => encodeTensorMetadata(t, () => `input \"${this.inputNames[inputIndices[i]]}\"`));\n    const outputs = outputArray.map(\n        (t, i) => t ? encodeTensorMetadata(t, () => `output \"${this.outputNames[outputIndices[i]]}\"`) : null);\n\n    const results = await run(this.sessionId, inputIndices, inputs, outputIndices, outputs, options);\n\n    const resultMap: SessionHandler.ReturnType = {};\n    for (let i = 0; i < results.length; i++) {\n      resultMap[this.outputNames[outputIndices[i]]] = outputArray[i] ?? decodeTensorMetadata(results[i]);\n    }\n    return resultMap;\n  }\n\n  startProfiling(): void {\n    // TODO: implement profiling\n  }\n\n  endProfiling(): void {\n    void endProfiling(this.sessionId);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {cpus} from 'node:os';\nimport {Backend, env, InferenceSession, InferenceSessionHandler} from 'onnxruntime-common';\n\nimport {initializeWebAssemblyInstance} from './wasm/proxy-wrapper';\nimport {OnnxruntimeWebAssemblySessionHandler} from './wasm/session-handler-inference';\n\n/**\n * This function initializes all flags for WebAssembly.\n *\n * Those flags are accessible from `ort.env.wasm`. Users are allow to set those flags before the first inference session\n * being created, to override default value.\n */\nexport const initializeFlags = (): void => {\n  if (typeof env.wasm.initTimeout !== 'number' || env.wasm.initTimeout < 0) {\n    env.wasm.initTimeout = 0;\n  }\n\n  if (typeof env.wasm.simd !== 'boolean') {\n    env.wasm.simd = true;\n  }\n\n  if (typeof env.wasm.proxy !== 'boolean') {\n    env.wasm.proxy = false;\n  }\n\n  if (typeof env.wasm.numThreads !== 'number' || !Number.isInteger(env.wasm.numThreads) || env.wasm.numThreads <= 0) {\n    const numCpuLogicalCores = typeof navigator === 'undefined' ? cpus().length : navigator.hardwareConcurrency;\n    env.wasm.numThreads = Math.min(4, Math.ceil((numCpuLogicalCores || 1) / 2));\n  }\n};\n\nexport class OnnxruntimeWebAssemblyBackend implements Backend {\n  async init(): Promise<void> {\n    // populate wasm flags\n    initializeFlags();\n\n    // init wasm\n    await initializeWebAssemblyInstance();\n  }\n  createInferenceSessionHandler(path: string, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  createInferenceSessionHandler(buffer: Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler>;\n  async createInferenceSessionHandler(pathOrBuffer: string|Uint8Array, options?: InferenceSession.SessionOptions):\n      Promise<InferenceSessionHandler> {\n    const handler = new OnnxruntimeWebAssemblySessionHandler();\n    await handler.loadModel(pathOrBuffer, options);\n    return Promise.resolve(handler);\n  }\n}\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\nimport {OnnxruntimeWebAssemblyBackend} from './backend-wasm';\nexport const wasmBackend = new OnnxruntimeWebAssemblyBackend();\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n/* eslint-disable @typescript-eslint/no-var-requires, @typescript-eslint/no-require-imports */\n// We use \"require\" instead of \"import\" here because import statement must be put in top level. Our current code does\n// not allow bundler to tree-shaking code as expected because some codes are treated as having side effects.\n// So we import code inside the if-clause to allow bundler remove the code safely.\n\nexport * from 'onnxruntime-common';\nimport * as ort from 'onnxruntime-common';\nexport default ort;\n\nimport {registerBackend, env} from 'onnxruntime-common';\nimport {version} from './version';\n\nif (!BUILD_DEFS.DISABLE_WEBGL) {\n  const onnxjsBackend = require('./backend-onnxjs').onnxjsBackend;\n  registerBackend('webgl', onnxjsBackend, -10);\n}\n\nif (!BUILD_DEFS.DISABLE_WASM) {\n  const wasmBackend = BUILD_DEFS.DISABLE_TRAINING ? require('./backend-wasm-inference').wasmBackend :\n                                                    require('./backend-wasm-training').wasmBackend;\n  if (!BUILD_DEFS.DISABLE_WEBGPU && typeof navigator !== 'undefined' && navigator.gpu) {\n    registerBackend('webgpu', wasmBackend, 5);\n  }\n  registerBackend('cpu', wasmBackend, 10);\n  registerBackend('wasm', wasmBackend, 10);\n  if (BUILD_DEFS.DISABLE_TRAINING) {\n    registerBackend('xnnpack', wasmBackend, 9);\n    registerBackend('webnn', wasmBackend, 9);\n  }\n}\n\nObject.defineProperty(env.versions, 'web', {value: version, enumerable: true});\n", "// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License.\n\n// This file is generated by /js/scripts/update-version.ts\n// Do not modify file content manually.\n\nexport const version = '1.17.0';\n"],
  "mappings": ";;;;;wgBAAA,IAcMA,GACAC,GAYOC,GA0CAC,GArEbC,GAAAC,EAAA,KAcML,GAAqC,IAAI,IACzCC,GAAqC,CAAA,EAY9BC,GAAkB,CAACI,EAAcC,EAAkBC,IAA0B,CACxF,GAAID,GAAW,OAAOA,EAAQ,MAAS,YAAc,OAAOA,EAAQ,+BAAkC,WAAY,CAChH,IAAME,EAAiBT,GAAS,IAAIM,CAAI,EACxC,GAAIG,IAAmB,OACrBT,GAAS,IAAIM,EAAM,CAAC,QAAAC,EAAS,SAAAC,CAAQ,CAAC,MACjC,IAAIC,EAAe,SAAWD,EAEnC,OACK,GAAIC,EAAe,WAAaD,GACjCC,EAAe,UAAYF,EAC7B,MAAM,IAAI,MAAM,4BAA4BD,CAAI,oBAAoBE,CAAQ,EAAE,EAIlF,GAAIA,GAAY,EAAG,CACjB,IAAME,EAAIT,GAAyB,QAAQK,CAAI,EAC3CI,IAAM,IACRT,GAAyB,OAAOS,EAAG,CAAC,EAGtC,QAASA,EAAI,EAAGA,EAAIT,GAAyB,OAAQS,IACnD,GAAIV,GAAS,IAAIC,GAAyBS,CAAC,CAAC,EAAG,UAAYF,EAAU,CACnEP,GAAyB,OAAOS,EAAG,EAAGJ,CAAI,EAC1C,OAGJL,GAAyB,KAAKK,CAAI,EAEpC,OAGF,MAAM,IAAI,UAAU,qBAAqB,CAC3C,EAUaH,GAAiB,MAAMQ,GAAqD,CACvF,IAAMC,EAAeD,EAAa,SAAW,EAAIV,GAA2BU,EACtEE,EAAS,CAAA,EACf,QAAWC,KAAeF,EAAc,CACtC,IAAMG,EAAcf,GAAS,IAAIc,CAAW,EAC5C,GAAIC,EAAa,CACf,GAAIA,EAAY,YACd,OAAOA,EAAY,QACd,GAAIA,EAAY,QACrB,SAGF,IAAMC,EAAiB,CAAC,CAACD,EAAY,YACrC,GAAI,CACF,OAAKC,IACHD,EAAY,YAAcA,EAAY,QAAQ,KAAI,GAEpD,MAAMA,EAAY,YAClBA,EAAY,YAAc,GACnBA,EAAY,cACZE,EAAG,CACLD,GACHH,EAAO,KAAK,CAAC,KAAMC,EAAa,IAAKG,CAAC,CAAC,EAEzCF,EAAY,QAAU,WAEtB,OAAOA,EAAY,cAKzB,MAAM,IAAI,MAAM,oCAAoCF,EAAO,IAAII,GAAK,IAAIA,EAAE,IAAI,KAAKA,EAAE,GAAG,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE,CAC1G,ICrGA,IAAAC,GAAAC,EAAA,KA2EAC,OC3EA,IAMaC,GANbC,GAAAC,EAAA,KAMaF,GAAU,WCNvB,IAQIG,GAESC,GAVbC,GAAAC,EAAA,KAIAC,KAIIJ,GAAwC,UAE/BC,GAAW,CACtB,KAAM,CAAA,EACN,MAAO,CAAA,EACP,OAAQ,CAAA,EACR,SAAU,CAAC,OAAQI,EAAO,EAE1B,IAAI,SAASC,EAAmB,CAC9B,GAAIA,IAAU,OAGd,IAAI,OAAOA,GAAU,UAAY,CAAC,UAAW,OAAQ,UAAW,QAAS,OAAO,EAAE,QAAQA,CAAK,IAAM,GACnG,MAAM,IAAI,MAAM,8BAA8BA,CAAK,EAAE,EAEvDN,GAAgBM,EAClB,EACA,IAAI,UAAQ,CACV,OAAON,EACT,GAIF,OAAO,eAAeC,GAAK,WAAY,CAAC,WAAY,EAAI,CAAC,IC/BzD,IAmKaM,GAnKbC,GAAAC,EAAA,KAGAC,KAgKaH,GAAWA,KCnKxB,IASaI,GA0FAC,GAnGbC,GAAAC,EAAA,KASaH,GAAkB,CAACI,EAAgBC,IAA4C,CAC1F,IAAMC,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQF,EAAO,KAAK,CAAC,EAC5BE,EAAO,OAASF,EAAO,KAAK,CAAC,EAC7B,IAAMG,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAJ,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,IAEtBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,GAGxB,IAAMM,EAAcL,GAAS,SAAW,OAAYA,EAAQ,OAAS,MAE/DM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EAEpBO,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5B,QAASK,EAAI,EAAGA,EAAIV,EAAQU,IAC1B,QAASC,EAAI,EAAGA,EAAIZ,EAAOY,IAAK,CAC9B,IAAMC,GAAMjB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EU,GAAMlB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EW,GAAMnB,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC1EY,EAAIN,IAAmB,GACzB,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,EAE1EL,EAAgB,UAAY,QAAUc,EAAI,IAAMC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxEjB,EAAgB,SAASa,EAAGD,EAAG,EAAG,CAAC,EAGvC,OAAOb,EAAO,UAAS,MAEvB,OAAM,IAAI,MAAM,2BAA2B,CAE/C,EAKaL,GAAoB,CAACG,EAAgBC,IAAiD,CACjG,IAAME,EAAkB,SAAS,cAAc,QAAQ,EAAE,WAAW,IAAI,EACpEkB,EACJ,GAAIlB,GAAmB,KAAM,CAE3B,IAAIC,EACAC,EACAiB,EACArB,GAAS,eAAiB,QAAaA,EAAQ,eAAiB,QAClEG,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBsB,EAAWtB,EAAO,KAAK,CAAC,IAExBI,EAAQJ,EAAO,KAAK,CAAC,EACrBK,EAASL,EAAO,KAAK,CAAC,EACtBsB,EAAWtB,EAAO,KAAK,CAAC,GAE1B,IAAMM,EAAcL,IAAY,QAAaA,EAAQ,SAAW,OAAYA,EAAQ,OAAkB,MAEhGM,EAAON,GAAS,KAClBO,EACAC,EACAF,IAAS,QAAaA,EAAK,OAAS,OACtCC,EAAW,CAAC,IAAK,IAAK,IAAK,GAAG,EAE1B,OAAQD,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDC,EAAW,CAACD,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,GAAG,EACrDA,EAAK,KAAK,CAAC,IAAM,SACnBC,EAAS,CAAC,EAAID,EAAK,KAAK,CAAC,IAI3BA,IAAS,QAAaA,EAAK,OAAS,OACtCE,EAAW,CAAC,EAAG,EAAG,EAAG,CAAC,EAElB,OAAQF,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,GAEtDE,EAAW,CAACF,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAGA,EAAK,KAAK,CAAC,EAAG,CAAC,EACnDA,EAAK,KAAK,CAAC,IAAM,SACnBE,EAAS,CAAC,EAAIF,EAAK,KAAK,CAAC,IAK/B,IAAMG,EAASL,EAASD,EACxB,GAAIH,IAAY,SACVA,EAAQ,SAAW,QAAcqB,IAAa,GAAKrB,EAAQ,SAAW,QACrEqB,IAAa,GAAMrB,EAAQ,SAAW,OAASA,EAAQ,SAAW,OACrE,MAAM,IAAI,MAAM,+CAAgD,EAKpE,IAAMsB,EAAO,EACTC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACzEhB,EAAiB,EAAGC,EAAiBF,EAAQG,EAAiBH,EAAS,EAAGI,EAAiB,GAG3FR,IAAgB,QAClBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,EAC1BI,EAAiBJ,EAAS,GACjBJ,IAAgB,OACzBK,EAAiB,EACjBC,EAAiBF,EACjBG,EAAiBH,EAAS,GACjBJ,IAAgB,QACzBK,EAAiB,EACjBE,EAAiBH,EACjBE,EAAiBF,EAAS,GAG5BW,EAAQlB,EAAgB,gBAAgBC,EAAOC,CAAM,EAErD,QAASU,EAAI,EAAGA,EAAIV,EAASD,EACxBoB,GAAiBD,EAAME,GAAiBF,EAAMG,GAAiBH,EAAMI,GAAiBJ,EAAMR,IAC/FM,EAAM,KAAKG,CAAa,GAAMxB,EAAO,KAAKW,GAAgB,EAAeF,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKI,CAAa,GAAMzB,EAAO,KAAKY,GAAgB,EAAeH,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKK,CAAa,GAAM1B,EAAO,KAAKa,GAAgB,EAAeJ,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClGa,EAAM,KAAKM,CAAa,EAAIb,IAAmB,GAC3C,KACEd,EAAO,KAAKc,GAAgB,EAAeL,EAAS,CAAC,GAAKD,EAAS,CAAC,MAI5E,OAAM,IAAI,MAAM,2BAA2B,EAE7C,OAAOa,CACT,IC/LA,IAiBaO,GAkFAC,GA8IAC,GAWAC,GASAC,GArQbC,GAAAC,EAAA,KAIAC,KAaaP,GAAiB,CAACQ,EAAqCC,IAA0C,CAC5G,GAAID,IAAW,OACb,MAAM,IAAI,MAAM,8BAA8B,EAEhD,GAAIC,EAAQ,SAAW,QAAaA,EAAQ,QAAU,OACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAM,CAAC,OAAAC,EAAQ,MAAAC,CAAK,EAAIF,EAElBG,EAAOH,EAAQ,MAAQ,CAAC,KAAM,IAAK,KAAM,CAAC,EAC5CI,EACAC,EAEA,OAAQF,EAAK,MAAU,SACzBC,EAAW,CAACD,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDC,EAAW,CAACD,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,GAAG,EAG3E,OAAQA,EAAK,MAAU,SACzBE,EAAW,CAACF,EAAK,KAAMA,EAAK,KAAMA,EAAK,KAAMA,EAAK,IAAI,EAEtDE,EAAW,CAACF,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,EAAGA,EAAK,KAAM,CAAC,GAAK,CAAC,EAG7E,IAAMG,EAAcN,EAAQ,SAAW,OAAYA,EAAQ,OAAS,OAG9DO,EACFP,EAAQ,eAAiB,QAAaA,EAAQ,eAAiB,OAAYA,EAAQ,aAAwB,MACzGQ,EAASP,EAASC,EAClBO,EAAcF,IAAiB,OAAS,IAAI,aAAaC,EAAS,CAAC,EAAI,IAAI,aAAaA,EAAS,CAAC,EAGpGE,EAAO,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EAAGC,EAAgB,EACnFC,EAAiB,EAAGC,EAAiBR,EAAQS,EAAiBT,EAAS,EAAGU,EAAiB,GAG3FZ,IAAgB,QAClBI,EAAO,EACPC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,EAChBC,EAAgB,IAIdP,IAAiB,OACnBW,EAAiBV,EAAS,EACjBD,IAAiB,OAC1BQ,EAAiB,EACjBE,EAAiBT,EACjBQ,EAAiBR,EAAS,GACjBD,IAAiB,QAC1BU,EAAiB,EACjBD,EAAiBR,EACjBO,EAAiBP,EAAS,GAG5B,QAASW,EAAI,EAAGA,EAAIX,EACfW,IAAKR,GAAiBD,EAAMG,GAAiBH,EAAME,GAAiBF,EAAMI,GAAiBJ,EAC9FD,EAAYM,GAAgB,GAAKhB,EAAOY,CAAa,EAAIN,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYO,GAAgB,GAAKjB,EAAOa,CAAa,EAAIP,EAAS,CAAC,GAAKD,EAAS,CAAC,EAClFK,EAAYQ,GAAgB,GAAKlB,EAAOc,CAAa,EAAIR,EAAS,CAAC,GAAKD,EAAS,CAAC,EAC9Ec,IAAmB,IAAMJ,IAAkB,KAC7CL,EAAYS,GAAgB,GAAKnB,EAAOe,CAAa,EAAIT,EAAS,CAAC,GAAKD,EAAS,CAAC,GAOtF,OAFqBG,IAAiB,OAAS,IAAIa,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,EACxD,IAAIkB,GAAO,UAAWX,EAAa,CAAC,EAAG,EAAGR,EAAQC,CAAK,CAAC,CAEzG,EAKaV,GAAkB,MAC3B6B,EACArB,IACyC,CAE3C,IAAMsB,EAAiB,OAAQ,iBAAsB,KAAeD,aAAiB,iBAC/EE,EAAiB,OAAQ,UAAe,KAAeF,aAAiB,UACxEG,EAAgB,OAAQ,YAAiB,KAAeH,aAAiB,YACzEI,EAAW,OAAOJ,GAAU,SAE9BK,EACAC,EAA+C3B,GAAW,CAAA,EAG9D,GAAIsB,EAAgB,CAElB,IAAMM,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAI5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MAMlB,GALIrB,IAAY,QAAaA,EAAQ,gBAAkB,QAAaA,EAAQ,eAAiB,SAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,cAGdA,IAAY,OAAW,CAEzB,GADA2B,EAAwB3B,EACpBA,EAAQ,eAAiB,OAC3B,MAAM,IAAI,MAAM,6DAA6D,EAE7E2B,EAAsB,aAAe,OAEvCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,OAE9ByB,EAAsB,aAAe,OACrCA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAGhC2B,EAAgB,UAAUR,EAAO,EAAG,CAAC,EACrCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,UAEpCsB,EAAgB,CACzB,IAAItB,EACAC,EAiBJ,GAfIF,IAAY,QAAaA,EAAQ,eAAiB,QAAaA,EAAQ,gBAAkB,QAC3FC,EAASD,EAAQ,cACjBE,EAAQF,EAAQ,eAEhBC,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,OAGZrB,IAAY,SACd2B,EAAwB3B,GAE1B2B,EAAsB,OAAS,OAC/BA,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EAE1BF,IAAY,OAAW,CACzB,IAAM8B,EAAa,SAAS,cAAc,QAAQ,EAElDA,EAAW,MAAQ5B,EACnB4B,EAAW,OAAS7B,EAEpB,IAAM4B,EAAkBC,EAAW,WAAW,IAAI,EAElD,GAAID,GAAmB,KACrBA,EAAgB,aAAaR,EAAO,EAAG,CAAC,EACxCK,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,SAEzD,OAAM,IAAI,MAAM,2BAA2B,OAG7CyB,EAAOL,EAAM,aAENG,EAAe,CAExB,GAAIxB,IAAY,OACd,MAAM,IAAI,MAAM,yDAAyD,EAG3E,IAAM4B,EAAS,SAAS,cAAc,QAAQ,EAC9CA,EAAO,MAAQP,EAAM,MACrBO,EAAO,OAASP,EAAM,OACtB,IAAMQ,EAAkBD,EAAO,WAAW,IAAI,EAE9C,GAAIC,GAAmB,KAAM,CAC3B,IAAM5B,EAASoB,EAAM,OACfnB,EAAQmB,EAAM,MACpB,OAAAQ,EAAgB,UAAUR,EAAO,EAAG,EAAGnB,EAAOD,CAAM,EACpDyB,EAAOG,EAAgB,aAAa,EAAG,EAAG3B,EAAOD,CAAM,EAAE,KACzD0B,EAAsB,OAAS1B,EAC/B0B,EAAsB,MAAQzB,EACvBX,GAAemC,EAAMC,CAAqB,MAEjD,OAAM,IAAI,MAAM,2BAA2B,MAExC,IAAIF,EACT,OAAO,IAAI,QAAQ,CAACM,EAASC,IAAU,CACrC,IAAMJ,EAAS,SAAS,cAAc,QAAQ,EACxCK,EAAUL,EAAO,WAAW,IAAI,EACtC,GAAI,CAACP,GAAS,CAACY,EACb,OAAOD,EAAM,EAEf,IAAME,EAAW,IAAI,MACrBA,EAAS,YAAc,YACvBA,EAAS,IAAMb,EACfa,EAAS,OAAS,IAAK,CACrBN,EAAO,MAAQM,EAAS,MACxBN,EAAO,OAASM,EAAS,OACzBD,EAAQ,UAAUC,EAAU,EAAG,EAAGN,EAAO,MAAOA,EAAO,MAAM,EAC7D,IAAMO,EAAMF,EAAQ,aAAa,EAAG,EAAGL,EAAO,MAAOA,EAAO,MAAM,EAElED,EAAsB,OAASC,EAAO,OACtCD,EAAsB,MAAQC,EAAO,MACrCG,EAAQxC,GAAe4C,EAAI,KAAMR,CAAqB,CAAC,CACzD,CACF,CAAC,EAED,MAAM,IAAI,MAAM,gEAAgE,EAGlF,GAAID,IAAS,OACX,OAAOnC,GAAemC,EAAMC,CAAqB,EAEjD,MAAM,IAAI,MAAM,gEAAgE,CAEpF,EAKalC,GAAoB,CAC7B2C,EAAsCpC,IAAgD,CACxF,GAAM,CAAC,MAAAE,EAAO,OAAAD,EAAQ,SAAAoC,EAAU,QAAAC,CAAO,EAAItC,EAErCuC,EAAO,CAAC,EAAGtC,EAAQC,EAAO,CAAC,EACjC,OAAO,IAAIkB,GAAO,CAAC,SAAU,UAAW,KAAM,UAAW,QAAAgB,EAAS,KAAAG,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC5F,EAKa5C,GAAsB,CAC/B8C,EAA0CxC,IAAkD,CAC9F,GAAM,CAAC,SAAAyC,EAAU,KAAAF,EAAM,SAAAF,EAAU,QAAAC,CAAO,EAAItC,EAC5C,OAAO,IAAIoB,GAAO,CAAC,SAAU,aAAc,KAAMqB,GAAY,UAAW,UAAAD,EAAW,KAAAD,EAAM,SAAAF,EAAU,QAAAC,CAAO,CAAC,CAC7G,EAKa3C,GAAyB,CAClC+C,EAAS3C,EAAwCwC,IACjD,IAAInB,GAAO,CAAC,SAAU,aAAc,KAAAsB,EAAM,KAAM3C,EAAQ,KAAMwC,GAAQ,CAACxC,EAAO,MAAM,CAAC,CAAC,ICvQ1F,IAWa4C,GAcAC,GAcTC,GACSC,GAxCbC,GAAAC,EAAA,KAWaL,GAAwC,IAAI,IAA6C,CACpG,CAAC,UAAW,YAAY,EACxB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,SAAS,EAClB,CAAC,SAAU,WAAW,EACtB,CAAC,UAAW,WAAW,EACvB,CAAC,QAAS,UAAU,EACpB,CAAC,QAAS,UAAU,EACpB,CAAC,OAAQ,UAAU,EACnB,CAAC,UAAW,YAAY,EACxB,CAAC,SAAU,WAAW,EACvB,EAGYC,GAAwC,IAAI,IAAkD,CACzG,CAAC,aAAc,SAAS,EACxB,CAAC,WAAY,OAAO,EACpB,CAAC,UAAW,MAAM,EAClB,CAAC,YAAa,QAAQ,EACtB,CAAC,WAAY,OAAO,EACpB,CAAC,WAAY,OAAO,EACpB,CAAC,aAAc,SAAS,EACxB,CAAC,YAAa,QAAQ,EACvB,EAKGC,GAAkB,GACTC,GAAc,IAAK,CAC9B,GAAI,CAACD,GAAiB,CACpBA,GAAkB,GAClB,IAAMI,EAA2B,OAAO,cAAkB,KAAe,OAAO,cAAc,MAAS,WACjGC,EACF,OAAO,eAAmB,KAAe,OAAO,eAAe,MAAS,WAExED,IACFN,GAAsC,IAAI,QAAS,aAAa,EAChEC,GAAsC,IAAI,cAAe,OAAO,GAE9DM,IACFP,GAAsC,IAAI,SAAU,cAAc,EAClEC,GAAsC,IAAI,eAAgB,QAAQ,GAGxE,ICxDA,IAWaO,GAkBAC,GA7BbC,GAAAC,EAAA,KAIAC,KAOaJ,GAAiBK,GAAoC,CAChE,IAAIC,EAAO,EACX,QAASC,EAAI,EAAGA,EAAIF,EAAK,OAAQE,IAAK,CACpC,IAAMC,EAAMH,EAAKE,CAAC,EAClB,GAAI,OAAOC,GAAQ,UAAY,CAAC,OAAO,cAAcA,CAAG,EACtD,MAAM,IAAI,UAAU,QAAQD,CAAC,8BAA8BC,CAAG,EAAE,EAElE,GAAIA,EAAM,EACR,MAAM,IAAI,WAAW,QAAQD,CAAC,0CAA0CC,CAAG,EAAE,EAE/EF,GAAQE,EAEV,OAAOF,CACT,EAKaL,GAAgB,CAACQ,EAAgBJ,IAAmC,CAC/E,OAAQI,EAAO,SAAU,CACvB,IAAK,MACH,OAAO,IAAIC,GAAOD,EAAO,KAAMA,EAAO,KAAMJ,CAAI,EAClD,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,KAAMD,EAAO,KACb,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,UACH,OAAO,IAAIK,GAAO,CAChB,SAAU,UACV,QAASD,EAAO,QAChB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,IAAK,aACH,OAAO,IAAIK,GAAO,CAChB,SAAU,aACV,UAAWD,EAAO,UAClB,KAAMA,EAAO,KACb,KAAAJ,EACD,EACH,QACE,MAAM,IAAI,MAAM,kCAAkCI,EAAO,QAAQ,mBAAmB,EAE1F,ICzDA,IAwBaE,GAxBbC,GAAAC,EAAA,KAGAC,KAEAC,KAEAC,KACAC,KAgBaN,GAAP,KAAa,CAyCjB,YACIO,EAEAC,EAA8EC,EAAwB,CAExGC,GAAW,EAEX,IAAIC,EACAC,EAEJ,GAAI,OAAOL,GAAS,UAAY,aAAcA,EAO5C,OAHA,KAAK,aAAeA,EAAK,SACzBI,EAAOJ,EAAK,KACZK,EAAOL,EAAK,KACJA,EAAK,SAAU,CACrB,IAAK,aAAc,CACjB,IAAMM,EAAgCC,GAAsC,IAAIH,CAAI,EACpF,GAAI,CAACE,EACH,MAAM,IAAI,UAAU,qBAAqBF,CAAI,uCAAuC,EAEtF,GAAI,EAAEJ,EAAK,gBAAgBM,GACzB,MAAM,IAAI,UAAU,4BAA4BA,EAA8B,IAAI,EAAE,EAEtF,KAAK,QAAUN,EAAK,KACpB,MAEF,IAAK,UAAW,CACd,GAAII,IAAS,UACX,MAAM,IAAI,UAAU,qBAAqBA,CAAI,iCAAiC,EAEhF,KAAK,eAAiBJ,EAAK,QAC3B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,IAAK,aAAc,CACjB,GAAKI,IAAS,WAAaA,IAAS,WAAaA,IAAS,SAAWA,IAAS,SAAWA,IAAS,UAC7FA,IAAS,OACZ,MAAM,IAAI,UAAU,qBAAqBA,CAAI,oCAAoC,EAEnF,KAAK,cAAgBJ,EAAK,UAC1B,KAAK,WAAaA,EAAK,SACvB,KAAK,SAAWA,EAAK,QACrB,MAEF,QACE,MAAM,IAAI,MAAM,6CAA6C,KAAK,YAAY,GAAG,MAEhF,CAIL,IAAIQ,EACAC,EAEJ,GAAI,OAAOT,GAAS,SAMlB,GAFAI,EAAOJ,EACPS,EAAYP,EACRF,IAAS,SAAU,CAErB,GAAI,CAAC,MAAM,QAAQC,CAAI,EACrB,MAAM,IAAI,UAAU,gDAAiD,EAIvEO,EAAOP,MACF,CAEL,IAAMS,EAAwBH,GAAsC,IAAIP,CAAI,EAC5E,GAAIU,IAA0B,OAC5B,MAAM,IAAI,UAAU,4BAA4BV,CAAI,GAAG,EAEzD,GAAI,MAAM,QAAQC,CAAI,EAAG,CACvB,GAAID,IAAS,UAIX,MAAM,IAAI,UACN,+FAA+F,EAC1FA,IAAS,UAAYA,IAAS,QAYvCQ,EAAQE,EAA8B,KAAKT,EAAM,MAAM,EAIvDO,EAAQE,EAA8B,KAAKT,CAAI,UAExCA,aAAgBS,EACzBF,EAAOP,MAEP,OAAM,IAAI,UAAU,KAAKG,CAAI,kCAAkCM,CAAqB,EAAE,UAO1FD,EAAYR,EACR,MAAM,QAAQD,CAAI,EAAG,CAEvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qDAAqD,EAE3E,IAAMW,EAAmB,OAAOX,EAAK,CAAC,EACtC,GAAIW,IAAqB,SACvBP,EAAO,SACPI,EAAOR,UACEW,IAAqB,UAC9BP,EAAO,OAIPI,EAAO,WAAW,KAAKR,CAAa,MAEpC,OAAM,IAAI,UAAU,uCAAuCW,CAAgB,GAAG,MAE3E,CAEL,IAAMC,EACFC,GAAsC,IAAIb,EAAK,WAA8C,EACjG,GAAIY,IAAe,OACjB,MAAM,IAAI,UAAU,qCAAqCZ,EAAK,WAAW,GAAG,EAE9EI,EAAOQ,EACPJ,EAAOR,EAKX,GAAIS,IAAc,OAEhBA,EAAY,CAACD,EAAK,MAAM,UACf,CAAC,MAAM,QAAQC,CAAS,EACjC,MAAM,IAAI,UAAU,wCAAyC,EAE/DJ,EAAOI,EAEP,KAAK,QAAUD,EACf,KAAK,aAAe,MAItB,IAAMM,EAAOC,GAAcV,CAAI,EAE/B,GAAI,KAAK,SAAWS,IAAS,KAAK,QAAQ,OACxC,MAAM,IAAI,MAAM,iBAAiBA,CAAI,gCAAgC,KAAK,QAAQ,MAAM,IAAI,EAG9F,KAAK,KAAOV,EACZ,KAAK,KAAOC,EACZ,KAAK,KAAOS,CACd,CAIA,aAAa,UACTE,EACAC,EACoB,CACtB,OAAOC,GAAgBF,EAAOC,CAAO,CACvC,CAEA,OAAO,YACHE,EAA4BF,EAAoC,CAClE,OAAOG,GAAkBD,EAASF,CAAO,CAC3C,CAEA,OAAO,cACHI,EAAgCJ,EAAsC,CACxE,OAAOK,GAAoBD,EAAWJ,CAAO,CAC/C,CAEA,OAAO,iBACHb,EAASmB,EAAwClB,EAAwB,CAC3E,OAAOmB,GAAuBpB,EAAMmB,EAAQlB,CAAI,CAClD,CAKA,UAAUY,EAAgC,CACxC,OAAOQ,GAAgB,KAAMR,CAAO,CACtC,CAEA,YAAYA,EAAkC,CAC5C,OAAOS,GAAkB,KAAMT,CAAO,CACxC,CAgDA,IAAI,MAAI,CAEN,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,QACR,MAAM,IAAI,MACN,gJAC2E,EAEjF,OAAO,KAAK,OACd,CAEA,IAAI,UAAQ,CACV,OAAO,KAAK,YACd,CAEA,IAAI,SAAO,CAET,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,eACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,cACd,CAEA,IAAI,WAAS,CAEX,GADA,KAAK,YAAW,EACZ,CAAC,KAAK,cACR,MAAM,IAAI,MAAM,4CAA4C,EAE9D,OAAO,KAAK,aACd,CAKA,MAAM,QAAQU,EAAqB,CAEjC,OADA,KAAK,YAAW,EACR,KAAK,aAAc,CACzB,IAAK,MACL,IAAK,aACH,OAAO,KAAK,KACd,IAAK,UACL,IAAK,aAAc,CACjB,GAAI,CAAC,KAAK,WACR,MAAM,IAAI,MAAM,qEAAqE,EAEvF,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAE3D,GAAI,CACF,KAAK,cAAgB,GACrB,IAAMnB,EAAO,MAAM,KAAK,WAAU,EAClC,YAAK,WAAa,OAClB,KAAK,aAAe,MACpB,KAAK,QAAUA,EAEXmB,GAAe,KAAK,WACtB,KAAK,SAAQ,EACb,KAAK,SAAW,QAGXnB,UAGP,KAAK,cAAgB,IAGzB,QACE,MAAM,IAAI,MAAM,kCAAkC,KAAK,YAAY,EAAE,EAE3E,CAEA,SAAO,CACL,GAAI,KAAK,cACP,MAAM,IAAI,MAAM,yCAAyC,EAGvD,KAAK,WACP,KAAK,SAAQ,EACb,KAAK,SAAW,QAElB,KAAK,QAAU,OACf,KAAK,eAAiB,OACtB,KAAK,cAAgB,OACrB,KAAK,WAAa,OAClB,KAAK,cAAgB,OAErB,KAAK,aAAe,MACtB,CAKQ,aAAW,CACjB,GAAI,KAAK,eAAiB,OACxB,MAAM,IAAI,MAAM,yBAAyB,CAE7C,CAEA,QAAQH,EAAuB,CAE7B,GADA,KAAK,YAAW,EACZ,KAAK,YAAc,KAAK,SAC1B,MAAM,IAAI,MAAM,iDAAiD,EAEnE,OAAOuB,GAAc,KAAMvB,CAAI,CACjC,KClaF,IAwUawB,GAxUbC,GAAAC,EAAA,KAIAC,KAoUaH,GAASA,KCxUtB,IAeaI,GAfbC,GAAAC,EAAA,KAGAC,KAIAC,KAQaJ,GAAP,MAAOK,CAAgB,CAC3B,YAAoBC,EAAgC,CAClD,KAAK,QAAUA,CACjB,CAGA,MAAM,IAAIC,EAAkBC,EAA+BC,EAAiB,CAC1E,IAAMC,EAA4C,CAAA,EAC9CC,EAAsB,CAAA,EAE1B,GAAI,OAAOJ,GAAU,UAAYA,IAAU,MAAQA,aAAiBK,IAAU,MAAM,QAAQL,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIM,EAAiB,GAErB,GAAI,OAAOL,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBI,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQJ,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DK,EAAiB,GAEjB,QAAWC,KAAQN,EAAM,CACvB,GAAI,OAAOM,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEJ,EAAQI,CAAI,EAAI,KAGlB,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIM,EAAY,GACVC,EAAW,OAAO,oBAAoBR,CAAI,EAChD,QAAWM,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKT,EAA4DM,CAAI,GACvEG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBH,EAAQI,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAON,GAAS,UAAYA,IAAS,KACvCE,EAAUF,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDE,EAAUH,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWM,KAAQ,KAAK,WACtB,GAAI,OAAOP,EAAMO,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBJ,EAAQI,CAAI,EAAI,KAMpB,IAAMI,EAAU,MAAM,KAAK,QAAQ,IAAIX,EAAOG,EAASC,CAAO,EACxDQ,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,CAOA,aAAa,OACTG,EAAyCd,EAA8BC,EACvEc,EAAqB,CAEvB,IAAIC,EACAb,EAA0B,CAAA,EAE9B,GAAI,OAAOW,GAAS,UAElB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7Cc,aAAgB,YAEzB,GADAE,EAAuBF,EACnB,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAGpDc,aAAgB,aACf,OAAO,kBAAsB,KAAeA,aAAgB,kBAAoB,CACnF,IAAMG,EAASH,EACXI,EAAa,EACbC,EAAaL,EAAK,WACtB,GAAI,OAAOd,GAAS,UAAYA,IAAS,KACvCG,EAAUH,UACD,OAAOA,GAAS,SAAU,CAEnC,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,EAAa,GAAKA,GAAcD,EAAO,WACzC,MAAM,IAAI,WAAW,oCAAoCA,EAAO,UAAU,IAAI,EAGhF,GADAE,EAAaL,EAAK,WAAaI,EAC3B,OAAOjB,GAAS,SAAU,CAE5B,GADAkB,EAAalB,EACT,CAAC,OAAO,cAAckB,CAAU,EAClC,MAAM,IAAI,WAAW,kCAAoC,EAE3D,GAAIA,GAAc,GAAKD,EAAaC,EAAaF,EAAO,WACtD,MAAM,IAAI,WAAW,oCAAoCA,EAAO,WAAaC,CAAU,IAAI,EAE7F,GAAI,OAAOH,GAAS,UAAYA,IAAS,KACvCZ,EAAUY,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,UAE7C,OAAOd,EAAS,IACzB,MAAM,IAAI,UAAU,gCAAkC,UAE/C,OAAOD,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,EAEtDgB,EAAuB,IAAI,WAAWC,EAAQC,EAAYC,CAAU,MAEpE,OAAM,IAAI,UAAU,qDAAyD,EAK/E,IAAMC,GADMjB,EAAQ,oBAAsB,CAAA,GACjB,IAAIkB,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAE9DvB,EAAU,MADA,MAAMwB,GAAeF,CAAY,GACnB,8BAA8BJ,EAAsBb,CAAO,EACzF,OAAO,IAAIN,EAAiBC,CAAO,CACrC,CAEA,gBAAc,CACZ,KAAK,QAAQ,eAAc,CAC7B,CACA,cAAY,CACV,KAAK,QAAQ,aAAY,CAC3B,CAEA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,KCrNF,IAqcayB,GArcbC,GAAAC,EAAA,KAGAC,KAkcaH,GAA4CA,KCrczD,IAAAI,GAAAC,EAAA,QCAA,IAgBMC,GAGOC,GAnBbC,GAAAC,EAAA,KAGAC,KAIAC,KASML,GAA0B,gHAGnBC,GAAP,MAAOK,CAAe,CAC1B,YAAoBC,EAA+B,CACjD,KAAK,QAAUA,CACjB,CAGA,IAAI,YAAU,CACZ,OAAO,KAAK,QAAQ,UACtB,CACA,IAAI,aAAW,CACb,OAAO,KAAK,QAAQ,WACtB,CAEA,aAAa,OAAOC,EAA+CC,EAA+B,CAEhG,IAAMC,EAA+BF,EAAgB,WAAa,GAC5DG,EAAoCH,EAAgB,gBAAkB,GACtEI,EAA0BH,GAAkB,CAAA,EAI5CI,GADMD,EAAQ,oBAAsB,CAAA,GACjB,IAAIE,GAAK,OAAOA,GAAM,SAAWA,EAAIA,EAAE,IAAI,EAC9DC,EAAU,MAAMC,GAAeH,CAAY,EACjD,GAAIE,EAAQ,6BAA8B,CACxC,IAAMR,EAAU,MAAMQ,EAAQ,6BAC1BP,EAAgB,gBAAiBA,EAAgB,WAAYE,EAAWC,EAAgBC,CAAO,EACnG,OAAO,IAAIN,EAAgBC,CAAO,MAElC,OAAM,IAAI,MAAMP,EAAe,CAEnC,CAWA,wBAAwBiB,EAAkBC,EAA+BC,EAAiB,CAExF,IAAMC,EAA4C,CAAA,EAC9CR,EAAsB,CAAA,EAE1B,GAAI,OAAOK,GAAU,UAAYA,IAAU,MAAQA,aAAiBI,IAAU,MAAM,QAAQJ,CAAK,EAC/F,MAAM,IAAI,UACN,+FAAiG,EAGvG,IAAIK,EAAiB,GAErB,GAAI,OAAOJ,GAAS,SAAU,CAC5B,GAAIA,IAAS,KACX,MAAM,IAAI,UAAU,yCAAyC,EAE/D,GAAIA,aAAgBG,GAClB,MAAM,IAAI,UAAU,8BAAgC,EAGtD,GAAI,MAAM,QAAQH,CAAI,EAAG,CACvB,GAAIA,EAAK,SAAW,EAClB,MAAM,IAAI,UAAU,qCAAuC,EAE7DI,EAAiB,GAEjB,QAAWC,KAAQL,EAAM,CACvB,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,UAAU,gDAAkD,EAExE,GAAI,KAAK,YAAY,QAAQA,CAAI,IAAM,GACrC,MAAM,IAAI,WAAW,2CAA2CA,CAAI,GAAG,EAEzEH,EAAQG,CAAI,EAAI,KAGlB,GAAI,OAAOJ,GAAS,UAAYA,IAAS,KACvCP,EAAUO,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,MAEjD,CAGL,IAAIK,EAAY,GACVC,EAAW,OAAO,oBAAoBP,CAAI,EAChD,QAAWK,KAAQ,KAAK,YACtB,GAAIE,EAAS,QAAQF,CAAI,IAAM,GAAI,CACjC,IAAMG,EAAKR,EAAmDK,CAAI,GAC9DG,IAAM,MAAQA,aAAaL,MAC7BG,EAAY,GACZF,EAAiB,GACjBF,EAAQG,CAAI,EAAIG,GAKtB,GAAIF,GACF,GAAI,OAAOL,GAAS,UAAYA,IAAS,KACvCP,EAAUO,UACD,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,8BAAgC,OAGtDP,EAAUM,WAGL,OAAOA,EAAS,IACzB,MAAM,IAAI,UAAU,yDAA6D,EAInF,QAAWK,KAAQ,KAAK,WACtB,GAAI,OAAON,EAAMM,CAAI,EAAM,IACzB,MAAM,IAAI,MAAM,UAAUA,CAAI,0BAA0B,EAK5D,GAAID,EACF,QAAWC,KAAQ,KAAK,YACtBH,EAAQG,CAAI,EAAI,KAIpB,MAAO,CAACH,EAASR,CAAO,CAC1B,CASA,uCAAuCe,EAAkC,CACvE,IAAMC,EAA2C,CAAA,EACjD,QAAWC,KAAOF,EAChB,GAAI,OAAO,eAAe,KAAKA,EAASE,CAAG,EAAG,CAC5C,IAAMC,EAASH,EAAQE,CAAG,EACtBC,aAAkBT,GACpBO,EAAYC,CAAG,EAAIC,EAEnBF,EAAYC,CAAG,EAAI,IAAIR,GAAOS,EAAO,KAAMA,EAAO,KAAMA,EAAO,IAAI,EAIzE,OAAOF,CACT,CAIA,MAAM,aAAaX,EAAkBC,EAA+BC,EAAiB,CACnF,GAAM,CAACC,EAASR,CAAO,EAAI,KAAK,wBAAwBK,EAAOC,EAAMC,CAAI,EACnEQ,EAAU,MAAM,KAAK,QAAQ,aAAaV,EAAOG,EAASR,CAAO,EACvE,OAAO,KAAK,uCAAuCe,CAAO,CAC5D,CAEA,MAAM,qBAAqBI,EAAoBC,EAAuB,CACpE,MAAM,IAAI,MAAM,yBAAyB,CAC3C,CAEA,MAAM,wBAAwBA,EAAuB,CACnD,MAAM,IAAI,MAAM,yBAAyB,CAC3C,CAEA,MAAM,SAAO,CACX,OAAO,KAAK,QAAQ,QAAO,CAC7B,KC5LF,IAqIaC,GArIbC,GAAAC,EAAA,KAIAC,KAiIaH,GAA0CA,KCrIvD,IAAAI,GAAA,GAAAC,GAAAD,GAAA,sBAAAE,GAAA,WAAAC,GAAA,oBAAAC,GAAA,QAAAC,GAAA,oBAAAC,KAAA,IAAAC,GAAAC,EAAA,KAmBAC,KACAC,KACAC,KACAC,KACAC,KACAC,OCxBA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,cAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAW,SCAxB,IAAAG,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAW,IAAM,CACnB,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,IAAIC,EAAED,EAAUE,EAAGC,EAAEF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAEE,CAAC,CAAC,EAC1DJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,GAAEN,EAAE,CAACO,EAAEC,GAAEC,KAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,KAAI,EAAEE,GAAEH,EAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,KAAI,EAAE,OAAAK,IAAIC,KAAIP,EAAEO,GAAEL,GAAEI,CAAC,EAAEL,GAAEC,GAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,GAAG,SAASC,KAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,GAAEb,EAAE,GAAG,CAAC,GAAGY,GAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,EAAE,GAAGC,EAAC,EAAE,GAAGZ,EAAE,KAAKa,GAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,GAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,GAAGX,EAAE,QAAQW,CAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,GAAGX,EAAE,mBAAmBW,CAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,GAAGX,EAAE,cAAcW,CAAC,EAAEX,EAAE,mBAAmB,CAACW,EAAEC,GAAEC,GAAEC,KAAIX,EAAE,eAAeQ,EAAEC,GAAEC,GAAEC,EAAC,EAAEd,EAAE,sBAAsBW,GAAG,CAACR,EAAE,kBAAkBQ,CAAC,CAAC,EAAEX,EAAE,cAAcW,GAAGR,EAAE,UAAUQ,CAAC,EAAEX,EAAE,qBAAqB,CAACW,EAAEC,GAAEC,KAAIV,EAAE,iBAAiBQ,EAAEC,GAAEC,EAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAG,iBAAiBC,EAAE,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAa,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE,GAAGC,EAAGC,EAAEC,EAClP,GAAGJ,EAAG,CAAC,IAAIK,EAAG,cAAcC,EAAG,cAAgBL,EAAEF,EAAEO,EAAG,QAAQL,CAAC,EAAE,IAAI,UAAU,IAAIC,EAAG,CAACxB,EAAEC,KAAKD,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAS2B,EAAG,aAAa3B,EAAEC,EAAE,OAAO,MAAM,GAAGyB,EAAE1B,IAAIA,EAAEwB,EAAGxB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAGyB,EAAE,CAACzB,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAEA,EAAE,WAAW,SAAS,EAAE,IAAI,IAAIA,CAAC,EAAE4B,EAAG,UAAU5B,CAAC,EAAE2B,EAAG,SAAS3B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACR,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAG,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAE,CAACnB,EAAEC,IAAI,CAAC,cAAQ,SACtfD,EAAQC,CAAE,EAAEJ,EAAE,QAAQ,IAAI,4BAA4B,MAASuB,GAAIC,KAAEA,EAAEE,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAK5B,IAAa4B,EAAE5B,GAAgB4B,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGC,EAAGxB,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIK,EAAE1B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GACxfwB,EAAE,CAACzB,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,GAAE,IAAI0B,EAAGhC,EAAE,OAAO,QAAQ,IAAI,KAAK,OAAO,EAAEiC,EAAEjC,EAAE,UAAU,QAAQ,MAAM,KAAK,OAAO,EAAE,OAAO,OAAOA,EAAEoB,CAAE,EAAEA,EAAG,KAAKpB,EAAE,cAAcqB,EAAGrB,EAAE,aAAaA,EAAE,OAAOsB,EAAEtB,EAAE,MAAM,IAAIkC,EAAElC,EAAE,aAAakC,EAAElC,EAAE,YAAY,IAAImC,EAAcnC,EAAE,eAAe,GAAa,OAAO,aAAjB,UAA8BoC,EAAE,iCAAiC,EACxe,IAAIC,EAAEC,EAAEC,EAAE,GAAGC,EAAEC,GAAEC,GAAEC,EAAEC,GAAEC,GAAGC,EAAG,SAASC,IAAI,CAAC,IAAI5C,EAAEkC,EAAE,OAAOrC,EAAE,MAAMyC,GAAE,IAAI,UAAUtC,CAAC,EAAEH,EAAE,OAAO,IAAI,WAAWG,CAAC,EAAEH,EAAE,OAAO2C,EAAE,IAAI,WAAWxC,CAAC,EAAEH,EAAE,OAAO0C,GAAE,IAAI,WAAWvC,CAAC,EAAEH,EAAE,QAAQ,IAAI,YAAYG,CAAC,EAAEH,EAAE,QAAQ4C,GAAE,IAAI,YAAYzC,CAAC,EAAEH,EAAE,QAAQ6C,GAAG,IAAI,aAAa1C,CAAC,EAAEH,EAAE,QAAQ8C,EAAG,IAAI,aAAa3C,CAAC,CAAC,CAAC,IAAI6C,GAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAE,SAASC,IAAI,CAAC,IAAIjD,EAAEH,EAAE,OAAO,MAAM,EAAEiD,GAAG,QAAQ9C,CAAC,CAAC,CAAC,IAAIkD,GAAE,EAAEC,GAAG,KAAKC,GAAE,KACrY,SAASnB,EAAEjC,EAAE,CAAC,MAAGH,EAAE,SAAQA,EAAE,QAAQG,CAAC,EAAEA,EAAE,WAAWA,EAAE,IAAI8B,EAAE9B,CAAC,EAAEoC,EAAE,GAAGC,EAAE,EAAErC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAEC,CAAC,EAAQA,CAAE,CAAC,SAASqD,GAAGrD,EAAE,CAAC,OAAOA,EAAE,WAAW,uCAAuC,CAAC,CAAC,IAAIsD,GAAyB,GAAvBA,GAAE,qBAAwB,CAACD,GAAGC,EAAC,EAAE,CAAC,IAAIC,GAAGD,GAAEA,GAAEzD,EAAE,WAAWA,EAAE,WAAW0D,GAAGhC,CAAC,EAAEA,EAAEgC,EAAE,CAAC,SAASC,GAAGxD,EAAE,CAAC,GAAGA,GAAGsD,IAAGvB,EAAE,OAAO,IAAI,WAAWA,CAAC,EAAE,GAAGL,EAAE,OAAOA,EAAE1B,CAAC,EAAE,KAAK,iDAAkD,CACnc,SAASyD,GAAGzD,EAAE,CAAC,GAAG,CAAC+B,IAAIX,GAAIC,GAAG,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACrB,EAAE,WAAW,SAAS,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAIuD,GAAGxD,CAAC,CAAC,EAAE,GAAGyB,EAAE,OAAO,IAAI,QAAQ,CAACxB,EAAEC,IAAI,CAACuB,EAAEzB,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIsD,GAAGxD,CAAC,CAAC,CAAC,CAAC,SAAS0D,GAAG1D,EAAEC,EAAEC,EAAE,CAAC,OAAOuD,GAAGzD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAAC2B,EAAE,0CAA0C3B,CAAC,EAAE8B,EAAE9B,CAAC,CAAC,CAAC,CAAC,CAC1e,SAASwD,GAAG3D,EAAEC,EAAE,CAAC,IAAIC,EAAEoD,GAAE,OAAOvB,GAAe,OAAO,YAAY,sBAA/B,YAAqDsB,GAAGnD,CAAC,GAAGA,EAAE,WAAW,SAAS,GAAGoB,GAAgB,OAAO,OAAnB,WAAyBoC,GAAGxD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA0B,EAAE,kCAAkC1B,CAAC,EAAE0B,EAAE,2CAA2C,EAAS4B,GAAGxD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC9W,IAAI2D,GAAEC,GAAG,CAAC,OAAO7D,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OACxfG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,UAAUG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YAAYG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IACnf,CAACJ,EAAE,GAAG,kBAAkBG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,OAAOD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAC3f,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAC3f,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EACjgB,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,GAAE7B,KAAI,CAAC,EAAE,cAAcC,GACzf,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,GAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAK+B,EAAE,SAAS9B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EACrfE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWmD,GAAEhD,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,EAAC,EAAE,SAAS,IAAI,CAAC,CAAC+B,GAAE7B,KAAI,CAAC,EAAE,cAAcC,GAAE,MAAM,KAAK8B,EAAE,SAAS7B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAK4B,EAAE,SAAS1B,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWkD,GAAE/C,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,GAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKuC,EAAE,SAAStC,IACzf,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKoC,EAAE,SAASnC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAACgC,GAAE9B,IAAI,CAAC,EAAE,cAAc,EAAEC,GAAE,MAAM,KAAK+B,EAAE,SAAS9B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAK6B,EAAE,SAAS5B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAWmD,GAAEhD,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACd,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAEgD,KAAI,CAAClE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO+D,GAAE,OAAO,OAAO,SAAS9D,EAAE,UAAUC,EAAE,kBAAkBC,EACpgB,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAEgD,KAAI,CAAClE,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO+D,GAAE,OAAO,OAAO,SAAS9D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAEgD,KAAI,CAAClE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO+D,GACnf,OAAO,OAAO,SAAS9D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAEgD,KAAI,CAAClE,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO+D,GAAE,OAAO,OAAO,SAAS9D,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,GAAEC,CAAC,EAAE,KAAK,CAACC,GAAEC,GAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAAOG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,OAAOJ,GAAG,CAACH,EAAE,GAAG,SACvfG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAAUG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAC9f,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,KAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKsC,EAAE,SAASrC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwB4D,GAAE1D,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,GAAE,sBAAsBuD,GAAEtD,CAAC,EAAE,KAAKsD,GAAErD,EAAC,EAAE,YAAYqD,GAAEpD,EAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKuC,EAAE,SAAStC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBAC9eG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,OAAOF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS8D,GAAE7D,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKqC,EAAE,SAASpC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOH,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,OAAOA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAC1f,OAAO,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKmC,EAAE,SAASlC,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC+B,GAAE7B,KAAI,CAAC,EAAE,WAAWqD,GAAEpD,EAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAK+B,GAAG,SAAS9B,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAO,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,GAAEC,GAAEC,GAAEC,GAAEE,EAAEC,GAAEgD,KAAI,CAAClE,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOW,GAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAKC,GAAE,MAAM,KAAKiC,EAAE,SAAShC,IACrgB,EAAEA,EAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,GAAEC,EAAC,EAAE,WAAW,IAAI,CAAC,CAAC4B,GAAE1B,KAAI,CAAC,EAAE,WAAWkD,GAAEhD,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAK2B,GAAG,SAASqB,KAAI,EAAEA,GAAEhD,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,OAAOf,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,OAAO,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,OAAOG,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAOA,GAAGH,EAAE,GAAGG,CAAC,EAAE,OAAO,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,OAAO,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,EAAE,SAAS8D,GAAGhE,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAAC,IAAIiE,GAAGjE,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EAC1b,SAASqE,GAAGlE,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACwC,GAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACwC,GAAE,KAAK,GAAG,GAAG,IAAI,CAAC,EAAExC,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACuC,GAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAE,CAAC,CAAC,CACnN,IAAI0B,GAAG,EAAEC,GAAG,EAAEC,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACtE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQqE,GAAG,OAAOA,GAAG,OAAOrE,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GAAG,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EACxgB2D,GAAE,CAAC9D,EAAEC,KAAKD,KAAK,GAAGsE,GAAG/B,GAAEvC,EAAEC,CAAC,EAAE,GAAGsE,GAAGvE,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEuE,GAAG,CAACxE,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,GAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,GAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EACnf,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEqE,GAAEzE,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAW0E,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG5E,GAAG,CAAC,IAAIC,EAAEsE,GAAGvE,CAAC,EAAE,EAAEE,EAAE2E,GAAG5E,CAAC,EAAE,OAAAC,GAAGsE,GAAGxE,EAAEuC,GAAErC,EAAED,CAAC,EAASC,CAAC,EAAE4E,GAAG,CAAC,EAAEC,GAAG,CAAC/E,EAAEC,IAAI,CAAC6E,GAAG,OAAO,EAAE,IAAI5E,EAAE,IAAID,IAAI,EAAEC,EAAEqC,GAAEvC,MAAM,CAAC,GAAGC,GAAQC,GAAL,IAAOD,EAAE6E,GAAG,KAAU5E,GAAL,IAAOsC,EAAEvC,IAAI,CAAC,EAAE0C,EAAG1C,MAAM,CAAC,CAAC,EAAE,EAAEA,EAAE,OAAO6E,EAAE,EAAEE,GAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,GAAG,CAAC,IAAIlF,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IACtf,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAI,gBAAgB,EAAEjB,EAAE,IAAIA,KAAK+E,GAAYA,GAAG/E,CAAC,IAAb,OAAe,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAE+E,GAAG/E,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAEiF,GAAGhF,CAAC,CAAC,OAAOgF,EAAE,EAAEA,GAAGC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAE,SAASC,GAAGtF,EAAE,CAAC,IAAIC,EAAE,MAAMsE,GAAGvE,CAAC,EAAE,CAAC,EAAE,OAAAwE,GAAGxE,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CACvb,SAASsF,GAAGvF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAEgD,GAAE,CAAC,IAAIjD,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAEiD,GAAE,CAAC,EAAEjD,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAASgD,GAAEyB,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAE1B,GAAEjD,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiD0E,GAAE1B,GAAEjD,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuC0E,GAAE1B,GAAEjD,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAU0E,EAAC,CAAC,SAASlF,GAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,EAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAIgD,GAAEjD,EAAE,SAAS,EAAE2E,IAAGhB,GAAE3D,EAAE,YAAY,CAAC,EAAEsE,GAAGC,IAAItB,EAAC,EAAE,GAAGhD,GAAE0E,GAAE3E,EAAE,QAAQ,EAAEC,IAAG0E,GAAE3E,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAGiD,GAAEjD,EAAE,SAASiD,GAAE,CAAC,GAAGjD,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAAgD,GAAE,IAAI,KAAKjD,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,GAAE,IAAI,KAAKO,EAAE,YAAY,EACnf,EAAE,CAAC,CAAC,EAAEiD,GAAExD,GAAEwD,EAAC,EAAS,GAAGzD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEyD,GAAEjD,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,GAAE+B,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGqC,EAAErC,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,GAAG,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGqC,EAAErC,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGM,GAAEqD,GAAErD,EAAC,EAAE,EAAE,EAAEP,EAAE4D,GAAE5D,CAAC,EAAEO,GAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WAAW,KAAK,WAAW,MAAM,KACnf,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,MAAKD,GAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GAAE,GAAG,EAAED,GAAEC,EAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,GAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,UAAU,EACngB,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAEgD,GAAE,EAAEA,IAAGjD,EAAE,GAAG,EAAEC,KAAI0D,GAAE3D,EAAE,GAAG,IAAI,EAAEsE,GAAGC,IAAItB,IAAG,EAAE,CAAC,OAAO1D,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IAAI,CAAC,EAAE,CAAC,EAAE,KAAKA,GAAG,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GACvf,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQgD,IAAGjD,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAKiD,IAAH,GAASA,IAAH,GAAMU,GAAE3D,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAIgD,IAAGjD,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAMiD,IAAH,GAASA,IAAH,GAAMU,GAAE3D,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAAE,IAAIQ,MAAKD,GAAEP,EAAE,SAASQ,EAAC,IAAIR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,GACzgB,GAAG,EAAED,GAAEC,EAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,GAAE4E,GAAGpF,CAAC,EAAKQ,GAAE,OAAOT,EAAS,GAAEqC,GAAE,IAAI5B,GAAEV,IAAI,CAAC,EAASU,GAAE,OAAO,EAAC,CAAC,SAASgF,GAAE1F,EAAE,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACgC,EAAEhC,CAAC,CAAC,CAAC,CAAC,SAAS0F,GAAG3F,EAAE,CAAC,IAAIC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAACwF,GAAE,KAAKzF,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQgC,IAAIwD,GAAE,IAAI,IAAIzF,GAAG8B,EAAE,EAAEpB,IAAOgF,KAAJ,GAAWD,GAAE,SAAN,IAAeC,GAAE,EAAEH,GAAEI,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAE1F,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAAC,IAAI4F,GAAE,EAAEhF,GAAE,KAAKkF,GAAG,EAAEH,GAAE,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAC9c,SAASpF,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACkG,GAAG,CAAC,QAAQnG,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASoG,IAAI,CAAC,IAAIrG,EAAE6E,GAAG,KAAK,EAAE5E,EAAED,EAAE,GAAGyC,GAAEzC,GAAG,IAAI,CAAC,EAAEC,EAAEwC,GAAEzC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAE2F,GAAE,CAAC,EAAE,IAAI1F,EAAE8F,GAAG/F,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAEgG,KAAKF,GAAG/F,CAAC,EAAEC,EAAE+F,GAAG/F,CAAC,EAAED,GAAGuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEE,EAASF,CAAC,CAC5N,SAASsG,GAAGtG,EAAE,CAAC,GAAG,CAACoC,EAAE,CAAC,GAAOyD,KAAJ,EAAM,CAAC,IAAI5F,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACiC,IAAI2D,GAAG5F,EAAEF,EAAE,GAAGC,GAAG,CAAC2F,GAAE,EAAEH,GAAE,IAAIa,GAAG1F,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,KAAK+B,EAAE8D,GAAGzD,EAAE3B,GAAE,GAAG,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,OAAON,GAAE,CAACH,EAAEG,GAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAE6F,GAAG7F,IAAI6F,GAAG,MAAMhG,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAI4F,GAAE,EAAEhF,GAAEwF,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEX,GAAE,IAAIc,GAAG3F,EAAC,CAAC,EAAE,MAAUgF,KAAJ,GAAOA,GAAE,EAAEH,GAAEe,EAAE,EAAEC,GAAG7F,EAAC,EAAEA,GAAE,KAAKuF,GAAG,QAAQjG,GAAG,CAAC,GAAG,CAACiC,EAAE,GAAG,CAAC,GAAGjC,EAAE,EAAE,CAAC6B,EAAc,GAAG,CAACK,EAAEA,EAAElC,EAAEkC,EAAML,IAAkBnC,EAAE,QAAOA,EAAE,OAAOM,CAAC,EAC7hBiC,EAAE,IAAGjB,EAAEhB,EAAE,IAAI6D,GAAG7D,CAAC,CAAC,CAAC,OAAOC,EAAE,CAACA,aAAa4D,IAAc5D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa4D,IAAc5D,GAAV,UAAae,EAAE,EAAEf,CAAC,CAAC,CAAC,CAAC,GAAG6B,EAAE,kBAAkB4D,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAAC,SAASY,GAAG3G,EAAE,CAAC,OAAOsG,GAAGrG,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI2G,GAAE,CAAC,EAAEC,GAAE,OAAOC,GAAG,CAAC,EAC1N,SAASC,GAAG/G,EAAEC,EAAE,CAAC,GAAG,CAAC4G,GAAE,CAACA,GAAE,IAAI,QAAQ,IAAI3G,EAAE2C,GAAE,OAAO,GAAGgE,GAAE,QAAQ1G,EAAE,EAAEA,EAAE,EAAED,EAAEC,IAAI,CAAC,IAAIC,EAAED,EAAME,EAAEuG,GAAExG,CAAC,EAAEC,IAAID,GAAGwG,GAAE,SAASA,GAAE,OAAOxG,EAAE,GAAGwG,GAAExG,CAAC,EAAEC,EAAEwC,GAAE,IAAIzC,CAAC,IAAIA,EAAEC,IAAIwG,GAAE,IAAIzG,EAAED,CAAC,CAAC,CAAC,CAAC,GAAGD,EAAE2G,GAAE,IAAI7G,CAAC,GAAG,EAAE,OAAOE,EAAE,GAAG4G,GAAG,OAAO5G,EAAE4G,GAAG,IAAI,MAAM,CAAC,GAAG,CAACjE,GAAE,KAAK,CAAC,CAAC,OAAOtC,GAAE,CAAC,MAAKA,cAAa,WAAyB,qDAAPA,EAA4D,CAACL,EAAE2C,GAAE,OAAO,CAAC,CAAC,GAAG,CAAC1C,EAAED,EAAE2C,GAAE,IAAI1C,EAAEH,CAAC,EAAE4G,GAAEzG,CAAC,EAAE0C,GAAE,IAAI1C,CAAC,CAAC,OAAOI,GAAE,CAAC,GAAG,EAAEA,cAAa,WAAW,MAAMA,GAAE,GAAe,OAAO,YAAY,UAA/B,WAAwC,CAACJ,EAAE,YAAY,SAC7eC,EAAE,CAAC,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,KAAK,EAAEC,EAAE,CAAC,WAAW,CAAC,EAAE,QAAaJ,EAAE,CAAC,GAAR,IAAU,CAAC,EAAE,CAACG,EAAEH,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQK,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAED,EAAE,WAAW,KAAKD,EAAEH,EAAEK,CAAC,CAAC,CAAC,EAAEL,EAAE,IAAIE,EAAEE,EAAEL,CAAC,CAAC,KAAK,CAAkI,IAAjIG,EAAE,CAAC,CAAC,EAAEC,EAAEH,EAAE,MAAM,EAAE,CAAC,EAAEA,EAAEA,EAAE,MAAM,CAAC,EAAEI,EAAE,CAAC,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,GAAG,EAAEF,EAAE,KAAK,EAAE,EAAEG,EAAEL,EAAE,OAAO,IAAIK,EAAEH,EAAE,KAAKG,CAAC,EAAEH,EAAE,KAAKG,EAAE,IAAI,IAAIA,GAAG,CAAC,EAAMA,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAEH,EAAE,KAAKE,EAAEJ,EAAEK,CAAC,CAAC,CAAC,EAAOF,GAAL,IAAOD,EAAE,KAAK,CAAC,EAAEA,EAAE,KAAK,EAAEE,EAAED,CAAC,CAAC,EAAEH,EAAE,CAAC,EAAE,GAAG,IAAI,IAAI,EAAE,EAAE,EAAE,EAAE,CAAC,EAAEG,EAAED,EAAE,OAAO,IAAIC,EAAEH,EAAE,KAAKG,CAAC,EAAEH,EAAE,KAAKG,EAAE,IAAI,IAAIA,GAAG,CAAC,EAAEH,EAAE,KAAK,MAAMA,EAAEE,CAAC,EAAEF,EAAE,KAAK,EAAE,EAAE,EAAE,EAAE,IAAI,EAAE,IAAI,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,IACjf,EAAE,CAAC,EAAEA,EAAE,IAAI,YAAY,OAAO,IAAI,WAAWA,CAAC,CAAC,EAAEA,EAAG,IAAI,YAAY,SAASA,EAAE,CAAC,EAAE,CAAC,EAAED,CAAC,CAAC,CAAC,EAAG,QAAQ,CAAC,CAACG,EAAED,EAAE2C,GAAE,IAAI1C,EAAEF,CAAC,EAAE2G,GAAEzG,CAAC,EAAE0C,GAAE,IAAI1C,CAAC,CAAC,CAAC,OAAA0G,GAAE,IAAI7G,EAAEE,CAAC,EAASA,CAAC,CACrJ,IAAI8G,GAAG,CAAC,EAAE,SAAShH,EAAEC,EAAEC,EAAE,CAAC,OAAOyG,GAAG,SAAS,CAAC,MAAM9G,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAIkE,GAAGlE,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAEiE,GAAGnE,EAAEoE,KAAWD,EAAG,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,EAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,IAAI,GAAG,EAAE,SAASnE,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EACnfF,EAAE,cAAc,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,YAAY,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,eAAe,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,UAAU,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGF,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACF,EAAEC,EAAE,UAAU,EAAE,QAAQ,CAAC,CAACD,GAAGA,IAAI,GAAG,WAAWC,EAAE,IAAIC,KAAK,EAAEF,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEwC,EAAEtC,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,WAAW,EAAEwC,EAAEtC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,QAAQ,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,SAAS,EAAEwC,EAAEtC,EAAE,IAAI,IAClf,CAAC,EAAEF,EAAE,YAAY,EAAE,KAAKwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,OAAO,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGuE,GAAEzE,EAAE,YAAY,CAAC,EAAE0E,GAAGC,IAAI3E,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAE,GAAGF,EAAE,kBAAkB,GAAGC,EAAG,IAAI,KAAKD,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEwC,EAAEtC,EAAE,IAAI,IAAI,CAAC,GAAGD,GAAGE,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAEF,CAAC,GAAG,CAAC,EAAE,EAAE,SAASD,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,KAAKwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEwC,EAAExC,GAAG,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAC5fG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEsC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAAG,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGqC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,GAAGyE,GAAExE,EAAE,YAAY,CAAC,EAAEyE,GAAGC,IAAI1E,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEuC,EAAExC,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEuC,EAAExC,EAAE,GAAG,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEuC,EAAExC,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAED,EAAEC,EAAE,QAAQ,EAC7f,IAAWgH,IAAIrD,GAAE5D,EAAE,GAAG,CAAC,KAAK,IAAI4D,EAAC,EAAE,EAAEA,GAAE,CAAC,KAAK,MAAMA,GAAE,UAAU,IAAI,EAAE,CAAC,CAAC,CAAC,KAAK,MAAMA,GAAE,EAAE,CAAC,CAACA,KAAI,IAAI,UAAU,IAAI,EAAE,EAAE,EAAE5D,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAM,GAAG,EAAE,EAAE,UAAU,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEK,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACN,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,GAAED,EAAE,kBAAkB,EAAEmC,GAAEzC,IAAI,GAAG,IAAI,CAAC,EAAE,GAAG,KAAK,IAAII,EAAEG,EAAC,EAAEiC,EAAEvC,IAAI,GAAG,IAAI,CAAC,EAAE,EAAOG,GAAGG,IAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAE4E,GAAG5E,CAAC,EAAEC,EAAE2E,GAAG3E,CAAC,EAAEM,GAAEH,GAAGqC,GAAEvC,GAAG,IAAI,CAAC,EAAEF,EAAEyC,GAAEvC,EACnf,GAAG,IAAI,CAAC,EAAED,IAAIwC,GAAEvC,GAAG,IAAI,CAAC,EAAED,EAAEwC,GAAEvC,EAAE,GAAG,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACiC,EAAE,EAAE,CAAC,EAAE,EAAE,SAASjC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE8E,GAAG9E,IAAI,EAAEC,IAAI,CAAC,EAAS2D,GAAG7D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE8E,GAAG9E,IAAI,EAAEC,IAAI,CAAC,EAAS2D,GAAG7D,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO,KAAK,IAAI,CAAC,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,IAAI,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAD,KAAK,EAASsC,GAAE,WAAWvC,IAAI,IAAI,EAAEC,IAAI,EAAEA,GAAGC,IAAI,KAAK,CAAC,CAAC,EAAE,EAAE,SAASF,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAEsC,GAAE,OAAO,GAAG,WAAWvC,EAAE,MAAM,GAAG,QAAQE,EAAE,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KACpfD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,EAAEA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GAAG,MAAMA,EAAE,OAAO,KAAK,EAAE+B,EAAE,OAAO,WAAW,QAAQ,GAAG,GAAG,CAACA,EAAE,KAAK9B,CAAC,EAAEwC,GAAG,EAAE,IAAIvC,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,EAAE,SAASL,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAA+E,GAAG,EAAE,QAAQ,SAAS9E,EAAEC,EAAE,CAAC,IAAIC,EAAEJ,EAAEC,EAAsB,IAApBE,EAAEqC,GAAEzC,EAAE,EAAEI,GAAG,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAEiC,GAAElC,KAAK,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAEiC,GAAElC,GAAG,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,EAAE,EAAE,SAASH,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE+E,GAAG,EAAExC,GAAEzC,GAAG,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQ,SAASE,EAAE,CAACD,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAEqC,GAAExC,GAAG,IAAI,CAAC,EAAEE,EAAS,CAAC,EAAE,EAAE,IACrf,GAAG,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,UAAU,CAAC,MAAO,GAAE,EAAE,EAAE,SAASH,EAAEC,EAAEC,EAAEC,EAAE,CAACF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEmC,GAAExC,GAAG,IAAI,CAAC,EAAEM,GAAEkC,GAAExC,EAAE,GAAG,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,EAAE,EAAEA,EAAED,GAAEC,IAAI,CAAC,IAAIC,GAAE8B,GAAEjC,EAAEE,IAAI,CAAC,EAAEE,GAAEyE,GAAGnF,CAAC,EAAMS,KAAJ,GAAYA,KAAL,KAAaT,IAAJ,EAAM6B,EAAGC,GAAGwC,GAAG5D,GAAE,CAAC,CAAC,EAAEA,GAAE,OAAO,GAAGA,GAAE,KAAKD,EAAC,CAAC,CAACL,GAAGG,EAAC,CAAC,OAAAkC,GAAEtC,GAAG,IAAI,CAAC,EAAEC,EAAS,CAAC,EAAE,EAAEmF,GAAG,EAAE,SAASvF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoF,GAAGvF,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,EAAE,EAAE,SAASH,EAAEC,EAAEC,EAAEC,EAAE,CAAC,IAAMC,EAAEyC,GAAE,OAAO7C,EAAE,IAAI,WAAWuC,GAAE,MAAMvC,EAAEC,EAAED,EAAEE,CAAC,CAAC,EAAE,GAAG,CAAC,IAAIG,EAAE,IAAI,YAAY,OAAOL,CAAC,EAAEM,EAAE,IAAI,YAAY,SAASD,EAAE,CAAC,IAAI,CAAC,OAAO6B,CAAC,CAAC,CAAC,EACxf3B,GAAE,IAAIA,MAAKD,EAAE,QAAQyG,GAAGzG,EAAE,QAAQC,EAAC,CAAC,EAAE,OAAOH,EAAEyC,GAAE,OAAOzC,EAAED,CAAC,OAAOK,EAAE,CAAC,OAAO,QAAQ,IAAIA,CAAC,EAAEL,CAAC,CAAC,CAAC,GAC7F,UAAU,CAAC,SAASH,EAAEE,EAAE,CAA2H,GAA1HA,EAAEA,EAAE,QAAQA,EAAEyF,GAAGzF,CAAC,EAAEiC,EAAEjC,EAAEgH,GAAGhH,CAAC,EAAEgC,EAAEC,EAAE,EAAES,GAAG,EAAEC,GAAEV,EAAE,GAAGY,GAAG,QAAQZ,EAAE,CAAC,EAAEe,KAAIrD,EAAE,wBAAwBA,EAAE,uBAAuBqD,EAAC,EAAQA,IAAH,IAAcC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAG,CAAC,IAAIjD,EAAEiD,GAAEA,GAAE,KAAKjD,EAAE,CAAC,CAAC,OAAOD,CAAC,CAAC,IAAID,EAAE,CAAC,EAAE+G,EAAE,EAA4D,GAA1D9D,KAAIrD,EAAE,wBAAwBA,EAAE,uBAAuBqD,EAAC,EAAKrD,EAAE,gBAAgB,GAAG,CAAC,OAAOA,EAAE,gBAAgBI,EAAED,CAAC,CAAC,OAAOE,EAAE,CAAC4B,EAAE,sDAAsD5B,CAAC,EAAEH,EAAEG,CAAC,CAAC,CAAC,OAAAyD,GAAG1D,EAAE,SAASC,EAAE,CAACF,EAAEE,EAAE,QAAQ,CAAC,CAAC,EAAE,MAAMH,CAAC,EAAQ,CAAC,CAAC,GAAG,EACjeF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,MAAKZ,EAAE,yBAAyBsC,EAAE,GAAGnC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,EAAEC,EAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4BsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0BsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0BsC,EAAE,GAAGnC,CAAC,EAC1fH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwBsC,EAAE,GAAGnC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkBsC,EAAE,GAAGnC,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASsC,EAAE,GAAGnC,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EACheP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsBsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAcsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAesC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBsC,EAAE,IAAInC,CAAC,EACteH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmBsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,MAAKV,EAAE,QAAQsC,EAAE,IAAInC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYsC,EAAE,IAAInC,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBsC,EAAE,IAAInC,CAAC,EACtV,IAAI6E,GAAGhF,EAAE,QAAQG,IAAI6E,GAAGhF,EAAE,QAAQsC,EAAE,IAAInC,CAAC,EAAE0G,GAAG7G,EAAE,MAAMG,IAAI0G,GAAG7G,EAAE,MAAMsC,EAAE,IAAInC,CAAC,EAAEiH,GAAGjH,IAAIiH,GAAG9E,EAAE,IAAInC,CAAC,EAAEmH,GAAG,KAAKA,GAAGhF,EAAE,IAAI,EAAEiF,GAAGpH,IAAIoH,GAAGjF,EAAE,IAAInC,CAAC,EAAEqH,GAAGrH,IAAIqH,GAAGlF,EAAE,IAAInC,CAAC,EAAEwG,GAAGxG,IAAIwG,GAAGrE,EAAE,IAAInC,CAAC,EAAE8F,GAAG,KAAKA,GAAG3D,EAAE,IAAI,EAAEoE,GAAGvG,IAAIuG,GAAGpE,EAAE,IAAInC,CAAC,EAAEyG,GAAG,KAAKA,GAAGtE,EAAE,IAAI,EAAEtC,EAAE,eAAe,OAAOA,EAAE,cAAc,OAAO,SAASqH,GAAGlH,EAAE,CAACA,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,OAAOE,EAAEF,EAAE,MAAM,EAAEA,EAAE,UAAUC,EAAED,EAAE,SAAS,EAAEA,EAAE,WAAWE,EAAEF,EAAE,UAAU,EAASA,CAAC,CAACH,EAAE,WAAWwH,GAC5exH,EAAE,UAAUsH,GAAGtH,EAAE,aAAauH,GAAGvH,EAAE,YAAYkH,GAAGlH,EAAE,aAAaiE,GAAEjE,EAAE,aAAa,CAACG,EAAEC,EAAEC,IAAIsE,GAAGxE,EAAEuC,GAAEtC,EAAEC,CAAC,EAAEL,EAAE,gBAAgB0E,GAAG,IAAI+C,GAAGlE,GAAE,SAASmE,GAAI,CAACD,IAAIE,GAAG,EAAEF,KAAKlE,GAAEmE,EAAG,EACtK,SAASC,IAAI,CAAC,SAASxH,GAAG,CAAC,GAAG,CAACsH,KAAKA,GAAG,GAAGzH,EAAE,UAAU,GAAG,CAACuC,GAAG,CAAiE,GAAhE6B,GAAGlB,EAAE,EAAEjD,EAAGD,CAAC,EAAKA,EAAE,sBAAqBA,EAAE,qBAAqB,EAAKA,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAGA,EAAE,QAAQ,QAAQ,CAAC,IAAII,EAAEJ,EAAE,QAAQ,MAAM,EAAEmD,GAAG,QAAQ/C,CAAC,CAAC,CAACgE,GAAGjB,EAAE,CAAC,CAAC,CAAC,GAAG,EAAE,EAAEE,IAAG,CAAC,GAAGrD,EAAE,OAAO,IAAgB,OAAOA,EAAE,QAArB,aAA8BA,EAAE,OAAO,CAACA,EAAE,MAAM,GAAGA,EAAE,OAAO,QAAQoD,GAAG,EAAEgB,GAAGnB,EAAE,EAAE,EAAEI,KAAIrD,EAAE,WAAWA,EAAE,UAAU,YAAY,EAAE,WAAW,UAAU,CAAC,WAAW,UAAU,CAACA,EAAE,UAAU,EAAE,CAAC,EAAE,CAAC,EAAEG,EAAE,CAAC,EAAE,CAAC,GAAGA,EAAE,EAAE,CAAC,CAC5e,GAAGH,EAAE,QAAQ,IAAgB,OAAOA,EAAE,SAArB,aAA+BA,EAAE,QAAQ,CAACA,EAAE,OAAO,GAAG,EAAEA,EAAE,QAAQ,QAAQA,EAAE,QAAQ,IAAI,EAAE,EAAE,OAAA2H,GAAG,EAGvG5H,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAO,IChF1B,IAAA+H,GAAAC,GAAA,QCAA,IAAAC,GAAAC,GAAA,QCAA,IAAAC,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAAaA,GAAbC,GAAAC,EAAA,KAAaF,GAAO,SCApB,IAAAG,GAAAC,GAAA,CAAAC,GAAAC,KAAA,cACA,IAAIC,IAAmB,IAAM,CAC3B,IAAIC,EAAa,OAAO,SAAa,KAAe,SAAS,cAAgB,SAAS,cAAc,IAAM,OAC1G,OAAI,OAAO,WAAe,MAAaA,EAAaA,GAAc,YAEpE,SAASC,EAAY,CAAC,EAAG,CAEzB,SAASC,GAAG,CAAC,OAAAC,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASD,EAAC,CAAC,SAASE,GAAG,CAAC,OAAAH,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASE,EAAE,CAAC,SAASC,GAAI,CAAC,OAAAL,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASI,EAAE,CAAC,SAASC,GAAI,CAAC,OAAAP,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASM,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAT,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASQ,EAAE,CAAC,SAASC,GAAG,CAAC,OAAAX,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASU,CAAE,CAAC,SAASC,GAAI,CAAC,OAAAb,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASY,EAAE,CAAC,SAASC,GAAI,CAAC,OAAAf,GAAE,QAAQC,GAAE,QAAQC,GAAE,EAASc,EAAE,CAAC,IAAIC,EAAEnB,EAAUoB,EAAGC,EAAGF,EAAE,MAAM,IAAI,QAAQ,CAACG,EAAEC,IAAI,CAACH,EAAGE,EAAED,EAAGE,CAAC,CAAC,EACvbJ,EAAE,SAAS,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACV,EAAE,GAAGG,EAAEH,EAAE,GAAGI,EAAEJ,EAAE,GAAGK,EAAEL,EAAE,GAAGM,EAAEN,EAAE,GAAGO,EAAEP,EAAE,GAAGQ,EAAER,EAAE,GAAGS,EAAET,EAAE,GAAGU,EAAEN,EAAE,CAACO,EAAEC,EAAEC,IAAI,IAAIC,KAAI,CAAC,IAAMC,GAAEC,GAAEC,EAAEL,IAAI,EAAEE,GAAEH,EAAE,GAAGG,EAAC,EAAE,IAAMI,GAAEN,IAAI,EAAE,OAAAK,IAAIC,KAAIP,EAAEO,GAAEL,EAAEI,CAAC,EAAEL,EAAEC,EAAE,MAAaG,IAAGD,GAAEI,GAAG,EAAEL,EAAC,EAAET,EAAEM,GAAG,SAASC,IAAI,CAAC,GAAG,CAAC,GAAGZ,EAAE,GAAG,MAAM,MAAM,yBAAyB,EAAE,IAAMa,EAAEb,EAAE,GAAG,CAAC,GAAGY,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC,EAAEE,GAAE,MAAMH,EAAE,GAAGC,CAAC,EAAE,GAAGZ,EAAE,KAAKa,EAAE,MAAM,MAAM,kBAAkB,EAAEV,EAAE,MAAM,EAAE,IAAMY,GAAEF,EAAE,OAAO,GAAG,EAAEE,GAAE,OAAO,CAAC,IAAIE,EAAE,MAAM,QAAQ,IAAIF,EAAC,EAAmB,GAAjBE,EAAEA,EAAE,OAAOC,IAAGA,EAAC,EAAK,EAAED,EAAE,OAAO,MAAM,MAAMA,EAAE,KAAK;AAAA,CAAI,CAAC,CAAE,CAAC,OAAOH,EAAC,QAAC,CAAQd,EAAE,GACzf,IAAI,CAAC,EAAEA,EAAE,QAAQK,EAAED,EAAEJ,EAAE,QAAQ,IAAIA,EAAE,QAAQW,GAAGX,EAAE,QAAQW,CAAC,CAAC,EAAEX,EAAE,mBAAmBK,EAAED,EAAEJ,EAAE,mBAAmB,IAAIA,EAAE,mBAAmBW,GAAGX,EAAE,mBAAmBW,CAAC,CAAC,EAAEX,EAAE,cAAcI,EAAEJ,EAAE,cAAc,IAAIA,EAAE,cAAcW,GAAGX,EAAE,cAAcW,CAAC,EAAEX,EAAE,mBAAmB,CAACW,EAAEC,EAAEC,EAAEC,KAAIX,EAAE,eAAeQ,EAAEC,EAAEC,EAAEC,EAAC,EAAEd,EAAE,sBAAsBW,GAAG,CAACR,EAAE,kBAAkBQ,CAAC,CAAC,EAAEX,EAAE,cAAcW,GAAGR,EAAE,UAAUQ,CAAC,EAAEX,EAAE,qBAAqB,CAACW,EAAEC,EAAEC,IAAIV,EAAE,iBAAiBQ,EAAEC,EAAEC,CAAC,CAAC,EACtb,IAAIO,EAAG,OAAO,OAAO,CAAC,EAAEpB,CAAC,EAAEqB,EAAG,iBAAiBC,EAAG,CAACnB,EAAEC,IAAI,CAAC,MAAMA,CAAE,EAAEmB,EAAa,OAAO,QAAjB,SAAwBC,EAAc,OAAO,eAAnB,WAAiCC,EAAY,OAAO,SAAjB,UAAoC,OAAO,QAAQ,UAAzB,UAA6C,OAAO,QAAQ,SAAS,MAAlC,SAAuCC,EAAE1B,EAAE,wBAAwB,GAAG2B,EAAE,GAAG,SAASC,EAAGzB,EAAE,CAAC,OAAOH,EAAE,WAAWA,EAAE,WAAWG,EAAEwB,CAAC,EAAEA,EAAExB,CAAC,CAAC,IAAI0B,EAAGC,EAAGC,EAC/U,GAAGN,EAAE,CAAC,IAAIO,GAAG,cAAcC,GAAG,cAAgBN,EAAEH,EAAES,GAAG,QAAQN,CAAC,EAAE,IAAI,UAAU,IAAIE,EAAG,CAACzB,EAAEC,KAAKD,EAAE8B,GAAG9B,CAAC,EAAE,IAAI,IAAIA,CAAC,EAAE6B,GAAG,UAAU7B,CAAC,EAAS4B,GAAG,aAAa5B,EAAEC,EAAE,OAAO,MAAM,GAAG0B,EAAG3B,IAAIA,EAAEyB,EAAGzB,EAAE,EAAE,EAAEA,EAAE,SAASA,EAAE,IAAI,WAAWA,CAAC,GAAUA,GAAG0B,EAAG,CAAC1B,EAAEC,EAAEC,EAAEC,EAAE,KAAK,CAACH,EAAE8B,GAAG9B,CAAC,EAAE,IAAI,IAAIA,CAAC,EAAE6B,GAAG,UAAU7B,CAAC,EAAE4B,GAAG,SAAS5B,EAAEG,EAAE,OAAO,OAAO,CAACC,EAAEC,IAAI,CAACD,EAAEF,EAAEE,CAAC,EAAEH,EAAEE,EAAEE,EAAE,OAAOA,CAAC,CAAC,CAAC,CAAC,EAAE,CAACT,EAAE,aAAa,EAAE,QAAQ,KAAK,SAASqB,EAAG,QAAQ,KAAK,CAAC,EAAE,QAAQ,MAAM,GAAG,GAAG,QAAQ,KAAK,MAAM,CAAC,EAAEC,EAAG,CAAClB,EAAEC,IAAI,CAAC,cAAQ,SAASD,EAAQC,CAAE,EAAEL,EAAE,QAAQ,IACnf,6BAA6B,IAAIG,EAAE,GAAG,CAACA,EAAE,IAAyB,OAAOC,EAAE,CAAC,MAAM,QAAQ,MAAM,yGAAyG,EAAEA,CAAE,CAAC,OAAO,OAAOD,EAAE,MAAM,MAASoB,GAAIC,KAAEA,EAAEG,EAAE,KAAK,SAAS,KAAkB,OAAO,SAApB,KAA8B,SAAS,gBAAgBA,EAAE,SAAS,cAAc,KAAM,OAAO/C,EAAe,KAAeA,IAAc+C,EAAE/C,GAAgB+C,EAAE,QAAQ,OAAO,IAArB,EAAuBA,EAAEA,EAAE,OAAO,EAAEA,EAAE,QAAQ,SAAS,EAAE,EAAE,YAAY,GAAG,EAAE,CAAC,EAAEA,EAAE,GAAGF,IAAII,EAAG1B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAChiBD,EAAE,EAAE,EAAEC,EAAE,KAAK,IAAI,EAASA,EAAE,YAAY,EAAEoB,IAAIO,EAAG5B,GAAG,CAAC,IAAIC,EAAE,IAAI,eAAe,OAAAA,EAAE,KAAK,MAAMD,EAAE,EAAE,EAAEC,EAAE,aAAa,cAAcA,EAAE,KAAK,IAAI,EAAS,IAAI,WAAWA,EAAE,QAAQ,CAAC,GAAG0B,EAAG,CAAC3B,EAAEC,EAAEC,IAAI,CAAC,IAAIC,EAAE,IAAI,eAAeA,EAAE,KAAK,MAAMH,EAAE,EAAE,EAAEG,EAAE,aAAa,cAAcA,EAAE,OAAO,IAAI,CAAMA,EAAE,QAAP,KAAkBA,EAAE,QAAL,GAAaA,EAAE,SAASF,EAAEE,EAAE,QAAQ,EAAED,EAAE,CAAC,EAAEC,EAAE,QAAQD,EAAEC,EAAE,KAAK,IAAI,CAAC,IAAGmB,GAAgB,OAAO,YAApB,MAAkC,OAAO,YAAY,KAAsB,aAAa,IAAIU,EAAG,QAAQ,IAAI,KAAK,OAAO,EAAEC,GAAG,QAAQ,MAAM,KAAK,OAAO,EACjgBX,IAAIU,EAAG,IAAIhC,IAAI6B,GAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,EAAEiC,GAAG,IAAIjC,IAAI6B,GAAG,UAAU,EAAE7B,EAAE,KAAK,GAAG,EAAE;AAAA,CAAI,GAAG,IAAIkC,GAAGF,EAAGG,EAAEF,GAAG,OAAO,OAAOpC,EAAEoB,CAAE,EAAEA,EAAG,KAAe,OAAO,aAAjB,UAA8BmB,GAAE,iCAAiC,EAAE,IAAIxD,GAAEyD,GAAGC,GAAE,GAAGC,GAAE1D,GAAEG,GAAGE,GAAGE,GAAGE,GAAGE,EAAGE,GAAG8C,GAAEC,GAAG7C,GACpP,SAASd,IAAG,CAAC,IAAIkB,EAAEpB,GAAE,OAAOiB,EAAE,MAAMhB,GAAE,IAAI,UAAUmB,CAAC,EAAEH,EAAE,OAAOX,GAAG,IAAI,WAAWc,CAAC,EAAEH,EAAE,OAAOb,GAAG,IAAI,WAAWgB,CAAC,EAAEH,EAAE,QAAQT,GAAG,IAAI,YAAYY,CAAC,EAAEH,EAAE,OAAOP,GAAG,IAAI,WAAWU,CAAC,EAAEH,EAAE,QAAQL,EAAG,IAAI,YAAYQ,CAAC,EAAEH,EAAE,QAAQH,GAAG,IAAI,aAAaM,CAAC,EAAEH,EAAE,QAAQD,GAAG,IAAI,aAAaI,CAAC,EAAEH,EAAE,OAAO2C,GAAE,IAAI,cAAcxC,CAAC,EAAEH,EAAE,QAAQ4C,GAAG,IAAI,eAAezC,CAAC,CAAC,CAAC,IAAI0C,GAAG,SAC7V,GADsW,SAASA,IAAIN,GAAE,wDAAwDM,GAAG,wBAAwB,EACrcnB,EAAE3C,GAAEiB,EAAE,mBAAmBjB,GAAE,IAAI,YAAY,OAAO,CAAC,QAAQ8D,GAAG,MAAM,QAAQ,MAAM,OAAO,EAAE,CAAC,EAAE,EAAE9D,GAAE,kBAAkB,mBAAmB,MAAMuD,EAAE,6NAA6N,EAAEb,GAAGa,EAAE,2GAA2G,EAAE,MAAM,YAAY,EACrfrD,GAAE,EAAE4D,GAAG9D,GAAE,OAAO,WAAW,IAAI+D,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,KAAK,SAASC,IAAI,CAAM,GAALH,KAAWA,IAAH,IAAeC,KAAP,OAAY,cAAcA,EAAE,EAAEA,GAAG,MAAMC,IAAI,CAAC,IAAIhD,EAAEgD,GAAGA,GAAG,KAAKhD,EAAE,CAAC,CAAC,CAAC,SAASoC,GAAEpC,EAAE,CAAC,MAAAA,EAAE,WAAWA,EAAE,IAAImC,EAAEnC,CAAC,EAAEsC,GAAE,GAAGC,GAAE,EAAEvC,EAAE,IAAI,YAAY,aAAaA,EAAE,0CAA0C,EAAED,EAAGC,CAAC,EAAQA,CAAE,CAAC,IAAIkD,GAAGlD,GAAGA,EAAE,WAAW,uCAAuC,EAAE+B,GAAG/B,GAAGA,EAAE,WAAW,SAAS,EAAEmD,GAAGA,GAAG,8BAA8BD,GAAGC,EAAE,IAAIA,GAAG1B,EAAG0B,EAAE,GACpc,SAASC,GAAGpD,EAAE,CAAC,GAAG4B,EAAG,OAAOA,EAAG5B,CAAC,EAAE,KAAK,iDAAkD,CAAC,SAASqD,GAAGrD,EAAE,CAAC,GAAGoB,GAAIC,EAAE,CAAC,GAAe,OAAO,OAAnB,YAA0B,CAACU,GAAG/B,CAAC,EAAE,OAAO,MAAMA,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,CAAC,GAAG,CAACA,EAAE,GAAG,KAAK,uCAAuCD,EAAE,IAAI,OAAOC,EAAE,YAAY,CAAC,CAAC,EAAE,MAAM,IAAImD,GAAGpD,CAAC,CAAC,EAAE,GAAG2B,EAAG,OAAO,IAAI,QAAQ,CAAC1B,EAAEC,IAAI,CAACyB,EAAG3B,EAAEG,GAAGF,EAAE,IAAI,WAAWE,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,QAAQ,QAAQ,EAAE,KAAK,IAAIkD,GAAGpD,CAAC,CAAC,CAAC,CAC5Z,SAASsD,GAAGtD,EAAEC,EAAEC,EAAE,CAAC,OAAOmD,GAAGrD,CAAC,EAAE,KAAKG,GAAG,YAAY,YAAYA,EAAEF,CAAC,CAAC,EAAE,KAAKE,GAAGA,CAAC,EAAE,KAAKD,EAAEC,GAAG,CAACgC,EAAE,0CAA0ChC,CAAC,EAAE,EAAEiC,GAAEjC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASoD,GAAGvD,EAAEC,EAAE,CAAC,IAAIC,EAAEiD,GAAG,OAAkB,OAAO,YAAY,sBAA/B,YAAqDD,GAAGhD,CAAC,GAAG6B,GAAG7B,CAAC,GAAGoB,GAAe,OAAO,OAAnB,WAAyBgC,GAAGpD,EAAEF,EAAEC,CAAC,EAAE,MAAMC,EAAE,CAAC,YAAY,aAAa,CAAC,EAAE,KAAKC,GAAG,YAAY,qBAAqBA,EAAEH,CAAC,EAAE,KAAKC,EAAE,SAASG,EAAE,CAAC,OAAA+B,EAAE,kCAAkC/B,CAAC,EAAE,EAAE+B,EAAE,2CAA2C,EAASmB,GAAGpD,EAAEF,EAAEC,CAAC,CAAC,CAAC,CAAC,CAAC,CAC9e,IAAIuD,GAAG,CAAC,QAAQxD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,aAAaG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAC5f,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,UAAUG,EAAE,CAAC,IAAIC,EAAE,IAAIC,CAAC,CAAC,CAAC,EAAE,QAAQF,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,MAAMG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,YACzeG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,kBAAkBG,EAAE,CAAC,MAAMC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAG,CAACH,EAAE,GAAGG,CAAC,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAIJ,EAAE,GAAGG,EAAEC,EAAEJ,EAAE,GAAG,GAAGA,EAAE,GAAG,MAAM,EAAE,QAAQ,CAACG,EAAEC,IAAI,CAACJ,EAAE,GAAG,OAAOG,EAAE,CAAC,GAAGC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,MAAMG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,iBAAiBG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GACxf,CAACH,EAAE,GAAG,cAAcG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,aAAaG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EACzf,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,YAAYG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,WAAWG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,eAAeG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAChgB,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,kBAAkBG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,kBAAkB,CAAC,CAACC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQH,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,YAAYG,EAAE,CAAC,KAAKC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,KAAI,CAACf,EAAE,GAAG,OAC/eG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,SAASP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,CAAC,EAAE,WAAW,IAAI,CAAC,CAAC5B,EAAE,EAAE8B,IAAI,CAAC,EAAE,WAAWgD,GAAE/C,CAAC,EAAE,kBAAkBC,GAAE,MAAM,KAAKlB,EAAG,EAAE,SAASmB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACX,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE2C,KAAI,CAAC7D,EAAE,GAAG,OAAOG,EAAE,CAAC,OAAOW,GAAE,OAAO,OAAO,SAASV,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAKC,EAAE,MAAM,KAAKlB,EAAE,EAAE,SAASmB,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,QAAQ,CAACE,EAAEC,CAAC,EAAE,WAAW,IAAI,CAAC,CAAC/B,EAAE,EAAEiC,KAAI,CAAC,EAAE,WAAW6C,GAAE3C,CAAC,EAAE,kBAAkBC,GAC/f,MAAM,KAAKtB,EAAG,EAAE,SAASiE,KAAI,EAAEA,GAAE3C,KAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,CAAC,EAAE,SAAS,IAAI,CAAC,CAAC5B,EAAE,EAAE8B,IAAI,CAAC,EAAE,cAAcC,EAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKvB,EAAE,EAAE,SAASyB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAW6C,GAAE1C,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,EAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKZ,EAAE,EAAE,SAASa,IACpf,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKf,EAAE,EAAE,SAASgB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAAC3B,EAAE,EAAE6B,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASuB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAW8C,GAAE3C,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACd,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,KAAI,CAAClB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOQ,EAAE,OAAO,OAAO,QAAQP,EAAE,UAAU,CAACC,CAAC,EAAE,MAAMC,EAAE,aAAa,CAACC,CAAC,EAAE,KAAK,CAACC,EAAEC,CAAC,EAAE,QAAQ,CAACC,CAAC,EAAE,SAAS,IACpf,CAAC,CAAC5B,EAAE,EAAE8B,IAAI,CAAC,EAAE,cAAcC,EAAE,MAAM,KAAKrB,EAAE,EAAE,SAASsB,KAAI,EAAEA,GAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAYE,GAAE,MAAM,KAAKvB,EAAE,EAAE,SAASyB,IAAI,EAAEA,EAAEF,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAW6C,GAAE1C,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,IAAI,CAACjB,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOO,EAAE,OAAO,OAAO,QAAQN,EAAE,UAAU,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,MAAMC,EAAE,YAAY,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,KAAK,MAAM,KAAKf,EAAE,EAAE,SAASgB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,QAAQ,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAE,IAAI,CAAC,CAAC,EAAE,SAAS,IAAI,CAAC,CAAC3B,EAAE,EAAE6B,IAAI,CAAC,EAAE,cAAc,EAAEC,EAAE,MAAM,KAAKpB,EAAE,EAAE,SAASqB,IACpgB,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,YAAY,EAAEE,GAAE,MAAM,KAAKtB,EAAE,EAAE,SAASuB,KAAI,EAAEA,GAAED,KAAI,CAAC,CAAC,EAAE,CAAC,EAAE,WAAW8C,GAAE3C,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACd,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE2C,KAAI,CAAC7D,EAAE,GAAG,cAAcG,EAAE,CAAC,OAAO0D,GAAE,OAAO,OAAO,SAASzD,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,oBAAoBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE2C,KAAI,CAAC7D,EAAE,GAAG,cACjfG,EAAE,CAAC,OAAO0D,GAAE,OAAO,OAAO,SAASzD,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE2C,KAAI,CAAC7D,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO0D,GAAE,OAAO,OAAO,SAASzD,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,IAAI,CAACJ,EAAE,GAAG,gBAAgBG,EAAE,CAAC,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACD,EACxfC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,GAAEC,GAAEE,EAAEC,GAAE2C,KAAI,CAAC7D,EAAE,GAAG,UAAUG,EAAE,CAAC,OAAO0D,GAAE,OAAO,OAAO,SAASzD,EAAE,UAAUC,EAAE,kBAAkBC,EAAE,cAAcC,EAAE,UAAU,CAACC,EAAEC,CAAC,EAAE,aAAa,CAACC,EAAEC,CAAC,EAAE,KAAK,CAACC,EAAEC,EAAEC,GAAEC,EAAC,EAAE,QAAQ,CAACE,EAAEC,EAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACf,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,OAAOG,EAAE,CAAC,MAAMC,EAAE,KAAKC,EAAE,OAAOC,EAAE,OAAOC,CAAC,CAAC,CAAC,EAAE,QAAQJ,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,EAAEC,EAAEC,IAAI,CAACN,EAAE,GAAG,SAASG,EAAE,CAAC,SAAS,CAAC,CAACC,EAAE,gBAAgB,CAAC,CAACC,EAAE,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACH,EAAEC,IAAI,CAACJ,EAAE,GAAG,UAC3eG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAKC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,QAAQG,EAAE,CAAC,KAAKC,EAAE,WAAWC,EAAE,WAAWC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQH,GAAG,CAACH,EAAE,GAAG,SAASG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,IAAI,CAACJ,EAAE,GAAG,iBAAiBG,EAAE,CAAC,KAAK,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACb,EAAE,GAAG,SAASG,EAAE,CAAC,UAAUC,EAAE,KAAKC,EAAE,MAAM,KAAKb,EAAE,EAAE,SAASc,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,wBAAwBuD,GAAErD,CAAC,EAAE,YAAYC,EAAE,eAAeC,EAAE,mBAAmBC,EAChgB,sBAAsBkD,GAAEjD,CAAC,EAAE,KAAKiD,GAAEhD,CAAC,EAAE,YAAYgD,GAAE/C,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACV,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACT,EAAE,GAAG,QAAQG,EAAE,CAAC,OAAOC,EAAE,MAAM,KAAKZ,EAAE,EAAE,SAASa,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,EAAE,KAAKE,EAAE,MAAM,KAAKhB,EAAE,EAAE,SAASiB,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQL,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,qBAAqBG,EAAE,CAAC,KAAK,OAAOC,CAAC,EAAE,QAAQ,OAAOC,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBAAwBG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQ,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAG,wBACjeG,EAAE,CAAC,QAAQC,EAAE,OAAOC,EAAE,OAAO,MAAM,CAAC,CAAC,EAAE,QAAQF,GAAG,CAACH,EAAE,GAAG,QAAQG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,SAASG,EAAE,CAAC,SAASyD,GAAExD,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQ,CAACD,EAAEC,EAAEC,EAAEC,EAAEC,IAAI,CAACP,EAAE,GAAG,MAAMG,EAAE,CAAC,KAAKC,EAAE,MAAMC,EAAE,KAAKC,EAAE,MAAM,KAAKd,EAAE,EAAE,SAASe,IAAI,EAAEA,EAAED,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC,EAAE,QAAQH,GAAG,CAACH,EAAE,GAAG,OAAOG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,UAAUG,EAAE,MAAM,CAAC,EAAE,QAAQA,GAAG,CAACH,EAAE,GAAG,gBAAgBG,EAAE,MAAM,CAAC,EAAE,QAAQ,CAACA,EAAEC,IAAI,CAACJ,EAAE,GAAG,yBAAyBG,EAAE,CAAC,QAAQC,CAAC,CAAC,CAAC,EAAE,QAAQD,GAAGH,EAAE,GAAGG,CAAC,EAAE,QAAQA,GAAGH,EAAE,GAAGG,CAAC,EAAE,QAAQ,CAACA,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EAAEC,EAAEC,EAAE,EAAE,CAAC,EAAE,QAAQ,CAACF,EAAEC,EAAEC,IAAI,CAACL,EAAE,GAAGG,EACvfC,EAAEC,CAAC,CAAC,CAAC,EAAE,SAASyD,GAAG3D,EAAE,CAAC,KAAK,KAAK,aAAa,KAAK,QAAQ,gCAAgCA,CAAC,IAAI,KAAK,OAAOA,CAAC,CAC5G,IAAI4D,GAAG5D,GAAG,CAACA,EAAE,UAAU,EAAEA,EAAE,UAAU,IAAI,CAAC,CAAC,EAAE6D,GAAG7D,GAAG,CAAC,GAAM8D,GAAE,GAAG,QAAR,EAAe,CAAC,IAAI7D,EAAEwB,EAAG,kCAAkC,EAAExB,EAAE,IAAI,OAAOA,CAAC,EAAE6D,GAAE,GAAG,KAAK7D,CAAC,EAAE6D,GAAE,GAAGA,GAAE,GAAG,CAAC,CAAC,CAAC,CAAc,GAAb7D,EAAE6D,GAAE,GAAG,IAAI,EAAK,CAAC7D,EAAE,MAAO,GAAE6D,GAAE,GAAG,KAAK7D,CAAC,EAAE6D,GAAE,GAAG9D,EAAE,EAAE,EAAEC,EAAEA,EAAE,GAAGD,EAAE,GAAG,IAAIE,EAAE,CAAC,IAAI,MAAM,cAAcF,EAAE,GAAG,IAAIA,EAAE,GAAG,YAAYA,EAAE,EAAE,EAAE,OAAAsB,GAAGrB,EAAE,MAAM,EAAEA,EAAE,YAAYC,EAAEF,EAAE,EAAE,EAAS,CAAC,EAAE+D,GAAE,EAAEC,GAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,MAAM,EAAE,OAAOC,GAAG,CAACjE,EAAEC,EAAEC,IAAI,CAACD,KAAK,EAAE,IAAIE,EAAEF,EAAEC,EAAE,IAAIA,EAAED,EAAED,EAAEE,CAAC,GAAG,EAAEA,GAAGC,IAAI,EAAED,EAAE,GAAG,GAAGA,EAAED,GAAGD,EAAE,QAAQgE,GAAG,OAAOA,GAAG,OAAOhE,EAAE,kBACrf,kBAAkBA,EAAE,MAAMC,EAAEC,CAAC,EAAEF,EAAE,SAASC,EAAEC,CAAC,CAAC,EAAE,IAAIC,EAAE,GAAGF,EAAEC,GAAG,CAAC,IAAIE,EAAEJ,EAAEC,GAAG,EAAE,GAAGG,EAAE,IAAI,CAAC,IAAIC,EAAEL,EAAEC,GAAG,EAAE,GAAG,IAASG,EAAE,MAAR,IAAaD,GAAG,OAAO,cAAcC,EAAE,KAAK,EAAEC,CAAC,MAAM,CAAC,IAAIC,EAAEN,EAAEC,GAAG,EAAE,GAAGG,GAAQA,EAAE,MAAR,KAAcA,EAAE,KAAK,GAAGC,GAAG,EAAEC,GAAGF,EAAE,IAAI,GAAGC,GAAG,GAAGC,GAAG,EAAEN,EAAEC,GAAG,EAAE,GAAG,MAAMG,EAAED,GAAG,OAAO,aAAaC,CAAC,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GAAG,GAAG,MAAMA,EAAE,IAAI,EAAE,CAAC,MAAMD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EAAEsD,GAAE,CAACzD,EAAEC,KAAKD,KAAK,GAAGiE,GAAGlF,EAAE,EAAEiB,EAAEC,CAAC,EAAE,GAAG,SAASiE,GAAGlE,EAAE,CAAC,GAAGuB,EAAE,OAAO4C,GAAE,EAAE,EAAEnE,CAAC,EAAEuC,GAAEvC,EAAE,EAAE+D,KAAID,GAAE,GAAG,EAAExB,GAAE,IAAInB,EAAGnB,EAAE,IAAI2D,GAAG3D,CAAC,CAAC,CAAC,CACle,IAAIoE,GAAGpE,GAAG,CAAK,GAAJuC,GAAEvC,EAAKuB,EAAE,MAAM8C,GAAGrE,CAAC,EAAE,SAASkE,GAAGlE,CAAC,CAAC,EAAE,SAASsE,IAAI,CAAC3B,GAAG,QAAQ,IAAI,CAACG,KAAKG,GAAG,CAAC,CAAC,CAAC,CACzF,IAAIa,GAAE,CAAC,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,EAAE,IAAI,CAACvC,GAAGuC,GAAE,sBAAsBA,GAAE,GAAGA,GAAE,cAAcA,GAAE,GAAGA,GAAE,cAAcA,GAAE,IAAIQ,GAAG,CAAC,EAAE,GAAGtE,GAAG,CAACuC,GAAEvC,CAAC,EAAE,GAAG,CAAC,kBAAkB,EAAE,GAAG,IAAI,CAAC,QAAQA,KAAK8D,GAAE,GAAGF,GAAG5D,CAAC,EAAE,IAAIA,KAAK8D,GAAE,GAAGF,GAAG5D,CAAC,EAAE8D,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,EAAEA,GAAE,GAAG,CAAC,CAAC,EAAE,GAAG9D,GAAG,CAAC,IAAIC,EAAED,EAAE,GAAG,OAAO8D,GAAE,GAAG7D,CAAC,EAAE6D,GAAE,GAAG,KAAK9D,CAAC,EAAE8D,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQ9D,CAAC,EAAE,CAAC,EAAEA,EAAE,GAAG,EAAEuE,GAAGtE,CAAC,CAAC,EAAE,IAAI,CAAC,EAAE,IAAI,CAAC6D,GAAE,GAAG,QAAQ9D,GAAGA,EAAE,CAAC,CAAC,EAAE,GAAGA,GAAG,IAAI,QAAQC,GAAG,CAACD,EAAE,UAAUK,GAAG,CAACA,EAAEA,EAAE,KAAK,IAAIC,EAAED,EAAE,IAAI,GAAGA,EAAE,cAAcA,EAAE,cAAcmE,GAAG,EAAE,CAAC,IAAIjE,EAAEuD,GAAE,GAAGzD,EAAE,YAAY,EAAEE,EAAEA,EAAE,YAAYF,EAAEA,EAAE,YAAY,EAClgB8B,EAAE,0CAA0C7B,CAAC,uBAAuBD,EAAE,YAAY,qCAAqC,CAAC,MAA0BC,IAAjB,eAAmBmE,GAAG,EAA0BnE,IAAhB,cAAkBuD,GAAGxD,CAAC,EAA4BC,IAAlB,kBAAqBD,EAAEyD,GAAE,GAAGzD,EAAE,MAAM,IAAI+B,GAAE,EAAE0B,GAAE,GAAGzD,CAAC,GAAyBC,IAAf,cAAiBD,EAAEA,EAAE,OAAOC,EAAEwD,GAAE,GAAGzD,CAAC,EAAE,OAAOyD,GAAE,GAAGzD,CAAC,EAAEuD,GAAGtD,CAAC,EAAEiE,GAAGlE,CAAC,EAAEyD,GAAE,GAAG,OAAOA,GAAE,GAAG,QAAQxD,CAAC,EAAE,CAAC,EAAEA,EAAE,GAAG,GAA2BA,IAAjB,eAAmBwD,GAAE,GAAGzD,EAAE,MAAM,EAAE,YAAY,CAAC,IAAI,QAAQ,CAAC,EAAqBC,IAAX,UAAaN,EAAE,OAAO,GAAGC,EAAED,CAAC,GAAoBM,IAAV,QAAY,MAAM,UAAUD,EAAE,QAAQ,KAAKA,EAAE,IAAI,EAAE,EAClfA,EAAE,SAAnB,eAA0BL,EAAE,YAAYK,CAAC,EAA0BC,IAAhB,cAAkBT,EAAEQ,EAAE,OAAO,EAAE,GAAGA,EAAE,IAAI,EAAOC,GAAG6B,EAAE,kCAAkC7B,CAAC,EAAE,CAAC,EAAEN,EAAE,QAAQK,GAAG,CAAC,MAAA8B,EAAE,yBAA8B9B,EAAE,QAAQ,IAAIA,EAAE,MAAM,KAAKA,EAAE,OAAO,EAAE,EAAQA,CAAE,EAAEiB,IAAItB,EAAE,GAAG,UAAUK,GAAGL,EAAE,UAAU,CAAC,KAAKK,CAAC,CAAC,CAAC,EAAEL,EAAE,GAAG,QAAQK,GAAGL,EAAE,QAAQK,CAAC,CAAC,GAAG,IAAIH,EAAE,CAAC,EAAEC,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKD,EAAEN,EAAE,eAAeO,CAAC,GAAGF,EAAE,KAAKE,CAAC,EAAEJ,EAAE,YAAY,CAAC,IAAI,OAAO,SAASE,EAAE,UAAUL,EAAE,qBAAqBpB,EAAW,WAAWG,GAAE,WAAWyD,EAAE,CAAC,CAAC,CAAC,CAAC,EAC5exC,EAAE,QAAQiE,GAAE,IAAIY,GAAG1E,GAAG,CAAC,KAAK,EAAEA,EAAE,QAAQA,EAAE,MAAM,EAAEH,CAAC,CAAC,EAAEA,EAAE,oBAAoB,IAAI,CAAC,IAAIG,EAAEwE,GAAG,EAAEvE,EAAEV,EAAE,EAAES,EAAE,KAAK,IAAI,CAAC,EAAEA,EAAET,EAAE,EAAES,EAAE,KAAK,IAAI,CAAC,EAAE2E,GAAG1E,EAAEA,EAAED,CAAC,EAAE4E,GAAG3E,CAAC,CAAC,EAAE,SAASoE,GAAGrE,EAAE,CAAC,GAAGuB,EAAE,OAAO4C,GAAE,EAAE,EAAEnE,CAAC,EAAEoE,GAAGpE,CAAC,CAAC,CAACH,EAAE,iBAAiB,CAACG,EAAEC,IAAI,CAACD,EAAE6E,GAAG,MAAM,KAAK,CAAC7E,EAAEC,CAAC,CAAC,EAAE,EAAE8D,GAAED,GAAE,GAAG9D,CAAC,EAAE8E,GAAG9E,CAAC,CAAC,EAAE,SAAS+E,GAAG/E,EAAE,CAAC,KAAK,GAAGA,EAAE,GAAG,KAAK,GAAG,SAASC,EAAE,CAACV,EAAE,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAEU,CAAC,EAAE,KAAK,GAAG,SAASA,EAAE,CAACV,EAAE,EAAE,KAAK,GAAG,IAAI,IAAI,CAAC,EAAEU,CAAC,EAAE,KAAK,GAAG,SAASA,EAAEC,EAAE,CAAC,KAAK,GAAG,EAAE,KAAK,GAAGD,CAAC,EAAE,KAAK,GAAGC,CAAC,CAAC,EAAE,KAAK,GAAG,UAAU,CAACX,EAAE,EAAE,KAAK,GAAG,KAAK,IAAI,CAAC,EAAE,CAAC,CAAC,CAAC,IAAIyF,GAAG,EAAEC,GAAG,EAC7e,SAASC,GAAGlF,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAE4C,GAAE,EAAE,EAAEnE,EAAEC,EAAEC,EAAEC,CAAC,EAAEgF,GAAGnF,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASgF,GAAGnF,EAAEC,EAAEC,EAAEC,EAAE,CAA6B,GAA5BH,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAkB,OAAO,kBAApB,IAAsC,OAAOgC,EAAE,qFAAqF,EAAE,EAAE,IAAI/B,EAAE,CAAC,EAAE,OAAGmB,GAAOnB,EAAE,SAAN,EAAoB8E,GAAGlF,EAAEC,EAAEC,EAAEC,CAAC,GAAEH,EAAE,CAAC,GAAGE,EAAE,GAAGF,EAAE,GAAGG,EAAE,GAAGC,CAAC,EAASmB,GAAGvB,EAAE,GAAG,cAAc,YAAYA,EAAEI,CAAC,EAAE,GAAGyD,GAAG7D,CAAC,EAAC,CAAC,SAASoF,GAAGpF,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAE4C,GAAE,EAAE,EAAEnE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAASmF,GAAGrF,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO4C,GAAE,EAAE,EAAEnE,EAAEC,CAAC,CAAC,CACrc,IAAIqF,GAAGtF,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EAAEH,EAAE,WAAWE,CAAC,EAAE,KAAKC,EAAEF,IAAI,MAAME,EAAEF,GAAG,EAAE,OAAOE,GAAG,OAAOA,GAAGF,GAAG,EAAE,EAAEC,GAAGD,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAEsF,GAAG,CAACvF,EAAEC,EAAEC,EAAEC,IAAI,CAAQ,GAAPD,KAAK,EAAK,EAAE,EAAEC,GAAG,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAED,EAAEC,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEL,EAAE,OAAO,EAAEK,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAWK,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,EAAEP,EAAE,WAAW,EAAEK,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,EAAE,IAAI,CAAC,GAAG,KAAKD,EAAE,CAAC,GAAGJ,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAEI,CAAC,KAAK,CAAC,GAAG,MAAMA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,CAAC,KAAK,CAAC,GAAG,OAAOA,EAAE,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,KAAK,CAAC,GAAGJ,EAAE,GAAGC,EAAE,MAAMF,EAAEC,MAAM,CAAC,EAAE,IAAII,GACpf,GAAGL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,GAAG,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,GAAG,EAAE,EAAE,CAACL,EAAEC,MAAM,CAAC,EAAE,IAAII,EAAE,EAAE,CAAC,CAAC,OAAAL,EAAEC,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEoF,GAAG,CAACxF,EAAEC,EAAEC,IAAIqF,GAAGvF,EAAEjB,EAAE,EAAEkB,EAAEC,CAAC,EAAE,SAASuF,GAAGzF,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO4C,GAAE,EAAE,EAAEnE,EAAEC,CAAC,CAAC,CAAC,SAASyF,GAAG1F,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAO4C,GAAE,EAAE,EAAEnE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAASyF,GAAG3F,EAAEC,EAAEC,EAAE,CAAC,OAAOqB,EAAE4C,GAAE,EAAE,EAAEnE,EAAEC,EAAEC,CAAC,EAAE,CAAC,CAAC,SAAS0F,GAAG5F,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO4C,GAAE,EAAE,EAAEnE,EAAEC,CAAC,CAAC,CAAC,SAAS4F,GAAG7F,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAO4C,GAAE,EAAE,EAAEnE,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS4F,GAAG9F,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS4F,GAAG/F,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAAC,SAAS6F,GAAGhG,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAC7d,SAAS8F,GAAGjG,EAAE,CAAC,GAAGuB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,CAAC,CAAC,CAAC,SAASkG,GAAGlG,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,EAAEC,CAAC,CAAC,CAAC,SAASkG,GAAGnG,EAAEC,EAAEC,EAAE,CAAC,GAAGqB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,EAAEC,EAAEC,CAAC,CAAC,CAAC,IAAIkG,GAAGpG,GAAG,CAAC,GAAUA,IAAP,KAAS,MAAM,OAAO,IAAIC,EAAE,OAAOD,EAAE,OAAiBC,IAAX,UAAwBA,IAAV,SAA0BA,IAAb,WAAeD,EAAE,SAAS,EAAE,GAAGA,CAAC,EAAEqG,GAAGC,GAAEtG,GAAG,CAAC,QAAQC,EAAE,GAAGlB,EAAE,EAAEiB,IAAI,CAAC,GAAGC,GAAGoG,GAAGtH,EAAE,EAAEiB,MAAM,CAAC,CAAC,EAAE,OAAOC,CAAC,EAAEsG,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GACnU,SAASC,GAAG3G,EAAEC,EAAEC,EAAE,CAAC,EAAE,CAAC,IAAIC,EAAEF,EAAE,KAAK,GAAG,CAACD,EAAE,MAAM,IAAI0G,GAAE,SAASvG,CAAC,+CAA+C,EAAE,GAAGqG,GAAG,eAAexG,CAAC,EAAE,CAAC,GAAGE,EAAE,GAAG,OAAO,MAAM,IAAIwG,GAAE,yBAAyBvG,CAAC,SAAS,CAAE,CAACqG,GAAGxG,CAAC,EAAEC,EAAE,OAAOwG,GAAGzG,CAAC,EAAEuG,GAAG,eAAevG,CAAC,IAAIC,EAAEsG,GAAGvG,CAAC,EAAE,OAAOuG,GAAGvG,CAAC,EAAEC,EAAE,QAAQG,GAAGA,EAAE,CAAC,EAAE,CAAC,SAASwG,GAAE5G,EAAEC,EAAEC,EAAE,CAAC,EAAE,CAAC,GAAG,EAAE,mBAAmBD,GAAG,MAAM,IAAI,UAAU,yDAAyD,EAAE0G,GAAG3G,EAAEC,EAAEC,CAAC,CAAC,CACta,IAAI2G,GAAG,CAAC7G,EAAEC,EAAEC,IAAI,CAAC,OAAOD,EAAE,CAAC,IAAK,GAAE,OAAOC,EAAEC,GAAGxB,EAAE,EAAEwB,IAAI,IAAI,CAAC,EAAEA,GAAGpB,EAAE,EAAEoB,IAAI,IAAI,CAAC,EAAE,IAAK,GAAE,OAAOD,EAAEC,GAAGlB,EAAG,EAAEkB,IAAI,IAAI,CAAC,EAAEA,GAAGhB,EAAG,EAAEgB,IAAI,IAAI,CAAC,EAAE,IAAK,GAAE,OAAOD,EAAEC,GAAGd,EAAE,EAAEc,IAAI,IAAI,CAAC,EAAEA,GAAGZ,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAE,IAAK,GAAE,OAAOD,EAAEC,GAAGqC,GAAErC,IAAI,CAAC,EAAEA,GAAGsC,GAAGtC,IAAI,CAAC,EAAE,QAAQ,MAAM,IAAI,UAAU,0BAA0BF,CAAC,MAAMD,CAAC,EAAE,CAAE,CAAC,EAAE,SAAS8G,GAAI,CAAC,KAAK,GAAG,CAAC,MAAM,EAAE,KAAK,GAAG,CAAC,CAAC,CAAC,IAAIC,EAAE,IAAID,EAAG,SAASE,EAAGhH,EAAE,CAACA,KAAK,EAAEA,GAAG+G,EAAE,IAAQ,EAAEA,EAAE,IAAI/G,CAAC,EAAE,KAAf,GAAmB+G,EAAE,GAAG/G,CAAC,CAAC,CACvZ,IAAIiH,EAAEjH,GAAG,CAAC,GAAG,CAACA,EAAE,MAAM,IAAI0G,GAAE,oCAAoC1G,CAAC,EAAE,OAAO+G,EAAE,IAAI/G,CAAC,EAAE,KAAK,EAAEkH,EAAElH,GAAG,CAAC,OAAOA,EAAE,CAAC,KAAK,OAAO,MAAO,GAAE,KAAK,KAAK,MAAO,GAAE,IAAK,GAAG,MAAO,GAAE,IAAK,GAAG,MAAO,GAAE,QAAQ,OAAO+G,EAAE,GAAG,CAAC,GAAG,EAAE,MAAM/G,CAAC,CAAC,CAAC,CAAC,EAAE,SAASmH,EAAGnH,EAAE,CAAC,OAAO,KAAK,aAAaX,EAAE,EAAEW,IAAI,IAAI,CAAC,CAAC,CAAC,CACjR,IAAIoH,EAAG,CAACpH,EAAEC,IAAI,CAAC,OAAOA,EAAE,CAAC,IAAK,GAAE,OAAO,SAASC,EAAE,CAAC,OAAO,KAAK,aAAaT,EAAG,EAAES,IAAI,IAAI,CAAC,CAAC,CAAC,EAAE,IAAK,GAAE,OAAO,SAASA,EAAE,CAAC,OAAO,KAAK,aAAaP,EAAG,EAAEO,IAAI,IAAI,CAAC,CAAC,CAAC,EAAE,QAAQ,MAAM,IAAI,UAAU,wBAAwBD,CAAC,MAAMD,CAAC,EAAE,CAAE,CAAC,EAAE,SAASqH,GAAGrH,EAAE,CAAC,OAAO,KAAK,aAAaT,EAAE,EAAES,IAAI,IAAI,CAAC,CAAC,CAAC,CAC7R,IAAIsH,EAAgB,OAAO,YAApB,IAAgC,IAAI,YAAY,UAAU,EAAE,OAAOC,GAAG,CAACvH,EAAEC,IAAI,CAAY,QAAPC,EAAEF,GAAG,EAAUG,EAAED,EAAED,EAAE,EAAE,EAAEC,GAAGC,IAAIhB,EAAG,EAAEe,IAAI,CAAC,GAAG,EAAEA,EAAQ,GAANA,IAAI,EAAK,GAAGA,EAAEF,GAAGsH,EAAG,OAAOA,EAAG,OAAOvI,EAAE,EAAE,MAAMiB,EAAEE,CAAC,CAAC,EAAO,IAALA,EAAE,GAAOC,EAAE,EAAE,EAAEA,GAAGF,EAAE,GAAG,EAAEE,EAAE,CAAC,IAAIC,EAAEnB,EAAG,EAAEe,EAAE,EAAEG,IAAI,IAAI,CAAC,EAAE,GAAMC,GAAH,EAAK,MAAMF,GAAG,OAAO,aAAaE,CAAC,CAAC,CAAC,OAAOF,CAAC,EAAEsH,GAAG,CAACxH,EAAEC,EAAEC,IAAI,CAA4B,GAAlBA,IAAT,SAAaA,EAAE,YAAe,EAAEA,EAAE,MAAO,GAAEA,GAAG,EAAE,IAAIC,EAAEF,EAAEC,EAAEA,EAAE,EAAEF,EAAE,OAAOE,EAAE,EAAEF,EAAE,OAAO,QAAQI,EAAE,EAAEA,EAAEF,EAAE,EAAEE,EAAE,CAAC,IAAIC,EAAEL,EAAE,WAAWI,CAAC,EAAEnB,EAAG,EAAEgB,IAAI,IAAI,CAAC,EAAEI,EAAEJ,GAAG,CAAC,CAAC,OAAAhB,EAAG,EAAEgB,IAAI,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEsH,GAAGzH,GAAG,EAAEA,EAAE,OAClf0H,GAAG,CAAC1H,EAAEC,IAAI,CAAC,QAAQC,EAAE,EAAEC,EAAE,GAAG,EAAED,GAAGD,EAAE,IAAI,CAAC,IAAIG,EAAEf,EAAE,EAAEW,EAAE,EAAEE,IAAI,IAAI,CAAC,EAAE,GAAME,GAAH,EAAK,MAAM,EAAEF,EAAE,OAAOE,GAAGA,GAAG,MAAMD,GAAG,OAAO,aAAa,MAAMC,GAAG,GAAG,MAAMA,EAAE,IAAI,GAAGD,GAAG,OAAO,aAAaC,CAAC,CAAC,CAAC,OAAOD,CAAC,EAAEwH,EAAG,CAAC3H,EAAEC,EAAEC,IAAI,CAAmC,GAAlCD,KAAK,EAAWC,IAAT,SAAaA,EAAE,YAAe,EAAEA,EAAE,MAAO,GAAE,IAAIC,EAAEF,EAAEC,EAAEC,EAAED,EAAE,EAAE,QAAQE,EAAE,EAAEA,EAAEJ,EAAE,OAAO,EAAEI,EAAE,CAAC,IAAIC,EAAEL,EAAE,WAAWI,CAAC,EAAE,GAAG,OAAOC,GAAG,OAAOA,EAAE,CAAC,IAAIC,EAAEN,EAAE,WAAW,EAAEI,CAAC,EAAEC,EAAE,QAAQA,EAAE,OAAO,IAAIC,EAAE,IAAI,CAAuB,GAAtBjB,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAEI,EAAEJ,GAAG,EAAKA,EAAE,EAAEC,EAAE,KAAK,CAAC,OAAAb,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAE,EAASA,EAAEE,CAAC,EAAEyH,GAAG5H,GAAG,CAAC,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE,CAAC,IAAIC,EACvfH,EAAE,WAAWE,CAAC,EAAE,OAAOC,GAAG,OAAOA,GAAG,EAAED,EAAED,GAAG,CAAC,CAAC,OAAOA,CAAC,EAAE4H,GAAG7H,GAAG,CAAC,GAAG,CAACsC,GAAE,GAAG,CAAC,GAAGtC,EAAE,EAAE,EAAE,EAAE+D,IAAG,GAAG,CAACxC,EAAEuD,GAAGvC,EAAC,EAAE6B,GAAG7B,EAAC,CAAC,OAAOtC,EAAE,CAACA,aAAa0D,IAAc1D,GAAV,UAAakB,EAAG,EAAElB,CAAC,CAAC,CAAC,OAAOA,EAAE,CAACA,aAAa0D,IAAc1D,GAAV,UAAakB,EAAG,EAAElB,CAAC,CAAC,CAAC,EAAE,SAAS6H,GAAG9H,EAAE,CAACA,KAAK,EAAe,OAAO,QAAQ,IAA5B,aAAiC,QAAQ,GAAGX,EAAE,EAAEW,IAAI,EAAEA,CAAC,EAAE,MAAM,KAAKyE,EAAE,EAAEzE,GAAG,IAAI,QAAQ,MAAMX,EAAE,EAAEW,IAAI,EAAE,CAAC,EAAE,CAACH,EAAE,kCAAkCiI,GAAG,IAAIrD,GAAG,IAAI,CAAC,IAAIzE,EAAEwE,GAAG,EAAExE,IAAI8H,GAAG9H,CAAC,EAAE6H,GAAG,IAAIE,GAAG,CAAC,EAAE,EAAElI,EAAE,aAAa4E,GAAG,IAAIuD,GAAGhI,GAAG,CAAC,IAAIC,EAAEgI,GAAG,EAAE,OAAAjI,EAAEA,EAAE,EAAE4E,GAAG3E,CAAC,EAASD,CAAC,EAC7d,SAASmE,GAAEnE,EAAEC,EAAE,CAAC,IAAIC,EAAE,UAAU,OAAO,EAAEC,EAAE,UAAU,OAAO6H,GAAG,IAAI,CAAC,QAAQ5H,EAAE,EAAEF,EAAEG,EAAE6H,GAAG,EAAE9H,CAAC,EAAEE,EAAED,IAAI,EAAEE,EAAE,EAAEA,EAAEL,EAAEK,IAAI,CAAC,IAAIC,EAAEL,EAAE,EAAEI,CAAC,EAAY,OAAOC,GAAjB,UAAoBgC,GAAElC,EAAE,EAAEC,CAAC,EAAE,GAAGiC,GAAElC,EAAE,EAAEC,EAAE,CAAC,EAAEC,IAAIgC,GAAElC,EAAE,EAAEC,CAAC,EAAE,GAAGZ,EAAG,EAAEW,EAAE,EAAEC,EAAE,IAAI,CAAC,EAAEC,EAAE,CAAC,OAAO2H,GAAGnI,EAAEI,EAAEC,EAAEJ,CAAC,CAAC,CAAC,CAAC,CAClO,IAAImI,GAAG,CAAC,EAAEC,GAAG,CAACrI,EAAEC,IAAI,CAAC,IAAIC,EAAEsG,GAAGxG,CAAC,EAAE,GAAYE,IAAT,OAAW,MAAMF,EAAEsI,GAAGtI,CAAC,EAAEE,EAAEoG,GAAEtG,CAAC,EAAEuI,GAAEvI,CAAC,EAAE,IAAI0G,GAAEzG,EAAE,qBAAqBC,CAAC,EAAE,OAAOA,CAAC,EAAEsI,GAAG,CAAC,EAAEC,GAAGzI,GAAG,CAAC,IAAIC,EAAEuI,GAAGxI,CAAC,EAAE,OAAgBC,IAAT,OAAWqG,GAAEtG,CAAC,EAAEC,CAAC,EAAEyI,GAAG,CAAC,EAAEC,GAAG,IAAc,OAAO,YAAjB,SAA4B,WAAW,SAAS,aAAa,EAAE,EAAEC,GAAG5I,GAAG,CAAC,IAAIC,EAAEyI,GAAG,OAAO,OAAAA,GAAG,KAAK1I,CAAC,EAASC,CAAC,EAAE4I,GAAG,CAAC7I,EAAEC,IAAI,CAAC,QAAQC,EAAE,MAAMF,CAAC,EAAEG,EAAE,EAAEA,EAAEH,EAAE,EAAEG,EAAED,EAAEC,CAAC,EAAEkI,GAAG9I,EAAE,EAAEU,EAAE,EAAEE,IAAI,IAAI,CAAC,EAAE,aAAaA,CAAC,EAAE,OAAOD,CAAC,EAAE4I,GAAG9I,GAAG,CAAC,GAAYA,IAAT,OAAW,MAAM,WAAWA,EAAEA,EAAE,QAAQ,iBAAiB,GAAG,EAAE,IAAIC,EAAED,EAAE,WAAW,CAAC,EAAE,MAAO,KAAIC,GAAG,IAAIA,EAAE,IAAID,CAAC,GACtfA,CAAC,EAAE,SAAS+I,GAAG/I,EAAEC,EAAE,CAAC,OAAAD,EAAE8I,GAAG9I,CAAC,EAAQ,CAAC,CAACA,CAAC,EAAE,UAAU,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC,SAASgJ,GAAGhJ,EAAE,CAAC,IAAIC,EAAE,SAAS,GAAG,EAAEA,aAAa,UAAU,MAAM,IAAI,UAAU,qCAAqC,OAAOA,CAAC,0BAA0B,EAAE,IAAIC,EAAE6I,GAAG9I,EAAE,MAAM,sBAAsB,UAAU,CAAC,CAAC,EAAE,OAAAC,EAAE,UAAUD,EAAE,UAAUC,EAAE,IAAIA,EAAEF,EAAEC,EAAE,MAAMC,EAAEF,CAAC,EAASA,aAAa,OAAOA,EAAEE,CAAC,CAC/W,IAAI+I,GAAGjJ,GAAG,CAAC,QAAQC,EAAE,GAAGC,EAAE,EAAEA,EAAEF,EAAE,EAAEE,EAAED,IAAQC,IAAJ,EAAM,KAAK,IAAI,MAAMA,EAAE,IAAIC,EAAE,mCAAmCH,EAAE;AAAA;AAAA,EAAkE,IAAIE,EAAE,EAAEA,EAAEF,EAAE,EAAEE,EAAEC,GAAG,cAAcD,EAAE,kEAAkEA,EAAE;AAAA,SAAeA,EAAE,aAAaA,EAAE;AAAA,iBAAgDA,EAAE;AAAA;AAAA,EAAwC,OAAO,IAAI,SAAS,wBAAwB,SAAS,gBAAgB,YAAYC,GAAG,6BACjeF,EAAE;AAAA;AAAA;AAAA,EAAsC,EAAGoI,GAAGxI,EAAEqH,EAAE,IAAI3H,EAAE,CAAC,CAAC,EAAE2J,GAAG,CAAC,EAAEC,GAAGnJ,GAAOA,EAAE,IAAN,IAAcA,EAAE,MAAN,GAAeA,EAAE,MAAN,GAAWoJ,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAEC,GAAG,CAAC,EAAE,GAAG,GAAG,GAAG,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,IAAI,GAAG,EAAE,SAASC,GAAGtJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOiB,EAAE4C,GAAE,GAAG,EAAEnE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAE,GAAG,CAAC,SAASiJ,GAAGvJ,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGkB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,CAAC,CAC9T,IAAImJ,GAAGxJ,GAAG,CAAC,IAAIC,EAAEqF,GAAGtF,CAAC,EAAE,EAAEE,EAAEuJ,GAAGxJ,CAAC,EAAE,OAAAC,GAAGsF,GAAGxF,EAAEE,EAAED,CAAC,EAASC,CAAC,EAAEwJ,GAAG,CAAC,EAAEC,GAAG,CAAC3J,EAAEC,IAAI,CAACyJ,GAAG,OAAO,EAAE,QAAQxJ,EAAEA,EAAEnB,EAAE,EAAEiB,MAAM,CAAC,GAAG,CAAC,IAAIG,EAAOD,GAAL,IAAOC,GAAQD,GAAL,IAAOD,GAAGE,GAAGF,EAAE,EAAE,EAAE,EAAEyJ,GAAG,KAAUxJ,GAAL,IAAOX,EAAE,EAAEU,IAAI,IAAI,CAAC,EAAOC,GAAL,IAAOsC,GAAEvC,IAAI,CAAC,EAAOC,GAAL,IAAOb,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAEN,EAAG,EAAEM,IAAI,IAAI,CAAC,CAAC,EAAEA,GAAGE,EAAE,EAAE,CAAC,CAAC,OAAOuJ,EAAE,EAAEE,GAAG,CAAC,EAAEC,GAAG,IAAI,CAAC,GAAG,CAACC,GAAG,CAAC,IAAI9J,EAAE,CAAC,KAAK,WAAW,QAAQ,WAAW,KAAK,IAAI,IAAI,IAAI,KAAK,iBAAiB,MAAgB,OAAO,WAAjB,UAA4B,UAAU,WAAW,UAAU,UAAU,CAAC,GAAG,KAAK,QAAQ,IAAI,GAAG,EAAE,SAAS,EAAEkB,GAAI,gBAAgB,EAAEjB,EAAE,IAAIA,KAAK2J,GACtfA,GAAG3J,CAAC,IADqf,OACnf,OAAOD,EAAEC,CAAC,EAAED,EAAEC,CAAC,EAAE2J,GAAG3J,CAAC,EAAE,IAAIC,EAAE,CAAC,EAAE,IAAID,KAAKD,EAAEE,EAAE,KAAK,GAAGD,CAAC,IAAID,EAAEC,CAAC,CAAC,EAAE,EAAE6J,GAAG5J,CAAC,CAAC,OAAO4J,EAAE,EAAEA,GAAG,SAASC,GAAG/J,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE,EAAE,OAAA2J,GAAG,EAAE,QAAQ,CAAC1J,EAAEC,IAAI,CAAC,IAAIC,EAAEJ,EAAEC,EAAyB,IAAvBE,EAAEb,EAAE,EAAES,EAAE,EAAEI,IAAI,IAAI,CAAC,EAAEC,EAAMA,EAAE,EAAEA,EAAEF,EAAE,OAAO,EAAEE,EAAE1B,EAAE,EAAEyB,MAAM,IAAI,CAAC,EAAED,EAAE,WAAWE,CAAC,EAAE1B,EAAE,EAAEyB,IAAI,IAAI,CAAC,EAAE,EAAEF,GAAGC,EAAE,OAAO,CAAC,CAAC,EAAS,CAAC,CAAC,SAAS6J,GAAGhK,EAAEC,EAAE,CAAC,GAAGsB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,EAAEC,CAAC,EAAED,KAAK,EAAEC,KAAK,EAAE,IAAIC,EAAE2J,GAAG,EAAEtK,EAAE,EAAES,IAAI,IAAI,CAAC,EAAEE,EAAE,OAAO,IAAIC,EAAE,EAAE,OAAAD,EAAE,QAAQE,GAAGD,GAAGC,EAAE,OAAO,CAAC,EAAEb,EAAE,EAAEU,IAAI,IAAI,CAAC,EAAEE,EAAS,CAAC,CAAC,SAAS8J,GAAGjK,EAAE,CAAC,OAAOuB,EAAE4C,GAAE,GAAG,EAAEnE,CAAC,EAAE,EAAE,CAC9e,SAASkK,GAAGlK,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAE4C,GAAE,GAAG,EAAEnE,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAAC,SAASgK,GAAGnK,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOoB,EAAE4C,GAAE,GAAG,EAAEnE,EAAEC,EAAEC,EAAEC,CAAC,EAAE,EAAE,CAAC,IAAIiK,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,EAAE,SAASC,GAAGrK,EAAEC,EAAEC,EAAEC,EAAE,CAAC,GAAGoB,EAAE,OAAO4C,GAAE,GAAG,EAAEnE,EAAEC,EAAEC,EAAEC,CAAC,EAAEF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,QAAQC,EAAE,EAAEC,EAAE,EAAEA,EAAEH,EAAEG,IAAI,CAAC,IAAIC,EAAEf,EAAE,EAAEU,IAAI,IAAI,CAAC,EAAEM,EAAEhB,EAAE,EAAEU,EAAE,IAAI,IAAI,CAAC,EAAEA,GAAG,EAAE,QAAQO,EAAE,EAAEA,EAAED,EAAEC,IAAI,CAAC,IAAIC,EAAE1B,EAAE,EAAEuB,EAAEE,IAAI,CAAC,EAAEE,EAAE0J,GAAGpK,CAAC,EAAMS,IAAJ,GAAYA,IAAL,KAAaT,IAAJ,EAAMkC,GAAGC,GAAG8B,GAAGvD,EAAE,CAAC,CAAC,EAAEA,EAAE,OAAO,GAAGA,EAAE,KAAKD,CAAC,CAAC,CAACL,GAAGG,CAAC,CAAC,OAAAhB,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAEC,EAAS,CAAC,CAAC,IAAIkK,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAAEC,GAAG,CAAC,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,GAAG,EAAE,EAChe,SAASC,GAAGxK,EAAE,CAAC,IAAIC,EAAE,MAAMqF,GAAGtF,CAAC,EAAE,CAAC,EAAE,OAAAuF,GAAGvF,EAAEC,EAAE,EAAEA,EAAE,MAAM,EAASA,CAAC,CAAC,IAAIwK,GAAG,CAACzK,EAAEC,IAAI,CAACtB,EAAE,EAAE,IAAIqB,EAAEC,IAAI,CAAC,CAAC,EAC/F,SAASyK,GAAG1K,EAAEC,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEU,EAAEC,GAAE2C,GAAE,CAAC,IAAI5C,EAAY,OAAOA,GAAjB,SAAmBA,EAAE,SAAS,EAAEA,GAAG,GAAGA,EAAE,OAAOC,IAAGD,EAAE4C,GAAE,CAAC,EAAE5C,EAAE,OAAOA,CAAC,CAAC,SAAST,EAAES,EAAEC,GAAE,CAAC,OAAOX,EAAEU,EAAEC,GAAE,GAAG,CAAC,CAAC,SAAST,EAAEQ,EAAEC,GAAE,CAAC,SAAS2C,GAAEiH,GAAG,CAAC,MAAO,GAAEA,GAAG,GAAG,EAAEA,GAAG,EAAE,CAAC,CAAC,IAAIC,GAAE,OAAKA,GAAElH,GAAE5C,EAAE,YAAY,EAAEC,GAAE,YAAY,CAAC,KAAxC,IAAiD6J,GAAElH,GAAE5C,EAAE,SAAS,EAAEC,GAAE,SAAS,CAAC,KAAlC,IAAuC6J,GAAElH,GAAE5C,EAAE,QAAQ,EAAEC,GAAE,QAAQ,CAAC,GAAU6J,EAAC,CAAC,SAASrK,EAAEO,EAAE,CAAC,OAAOA,EAAE,OAAO,EAAE,CAAC,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAOA,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAC5f,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,CAAC,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,EAAE,IAAK,GAAE,OAAO,IAAI,KAAKA,EAAE,YAAY,EAAE,EAAE,GAAG,EAAE,CAAC,CAAC,CAAC,SAASN,EAAEM,EAAE,CAAC,IAAIC,GAAED,EAAE,GAAG,IAAIA,EAAE,IAAI,KAAM,IAAI,KAAKA,EAAE,GAAG,KAAK,EAAE,CAAC,EAAG,QAAQ,CAAC,EAAE,EAAEC,IAAG,CAAC,IAAI2C,GAAE5C,EAAE,SAAS,EAAE8J,IAAGzB,GAAGrI,EAAE,YAAY,CAAC,EAAEwJ,GAAGC,IAAI7G,EAAC,EAAE,GAAG3C,GAAE6J,GAAE9J,EAAE,QAAQ,EAAEC,IAAG6J,GAAE9J,EAAE,QAAQ,EAAE,EAAEA,EAAE,QAAQ,CAAC,EAAE,GAAG4C,GAAE5C,EAAE,SAAS4C,GAAE,CAAC,GAAG5C,EAAE,SAAS,CAAC,EAAEA,EAAE,YAAYA,EAAE,YAAY,EAAE,CAAC,OAAO,CAACA,EAAE,QAAQA,EAAE,QAAQ,EAAEC,EAAC,EAAE,KAAK,CAAC,CAAC,OAAA2C,GAAE,IAAI,KAAK5C,EAAE,YAAY,EAAE,EAAE,EAAE,CAAC,EAAEC,GAAER,EAAE,IAAI,KAAKO,EAAE,YAAY,EACpf,EAAE,CAAC,CAAC,EAAE4C,GAAEnD,EAAEmD,EAAC,EAAS,GAAGpD,EAAES,GAAED,CAAC,EAAE,GAAGR,EAAEoD,GAAE5C,CAAC,EAAEA,EAAE,YAAY,EAAE,EAAEA,EAAE,YAAY,EAAEA,EAAE,YAAY,EAAE,CAAC,CAACd,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIM,EAAElB,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAEA,EAAE,CAAC,GAAGd,EAAE,EAAEc,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,KAAK,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,KAAK,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,KAAK,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,KAAK,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,KAAK,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,KAAK,IAAI,CAAC,EAAE,GAAGd,EAAE,EAAEc,EAAE,KAAK,IAAI,CAAC,EAAE,GAAGM,EAAEgD,GAAEhD,CAAC,EAAE,EAAE,EAAEP,EAAEuD,GAAEvD,CAAC,EAAEO,EAAE,CAAC,KAAK,uBAAuB,KAAK,WAAW,KAAK,WAAW,KAAK,KAAK,KAAK,cAAc,KAAK,QAAQ,KAAK,WAAW,KAAK,WACnf,KAAK,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,WAAW,MAAM,WAAW,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,KAAK,MAAM,IAAI,EAAE,QAAQC,KAAKD,EAAEP,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,EAAE,GAAG,EAAED,EAAEC,CAAC,CAAC,EAAE,IAAIC,GAAE,2DAA2D,MAAM,GAAG,EAAEC,GAAE,wFAAwF,MAAM,GAAG,EAAEH,EAAE,CAAC,KAAKK,GAAGH,GAAEG,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GACzfH,GAAEG,EAAE,EAAE,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,UAAU,EAAE,CAAC,EAAE,KAAKA,GAAGF,GAAEE,EAAE,EAAE,EAAE,KAAKA,GAAGT,GAAGS,EAAE,GAAG,MAAM,IAAI,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,GAAGV,EAAEU,EAAE,GAAG,EAAE,GAAG,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGN,EAAEM,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAKA,IAAIA,EAAEA,EAAE,GAAMA,GAAH,EAAKA,EAAE,GAAG,GAAGA,IAAIA,GAAG,IAAWT,EAAES,EAAE,CAAC,GAAG,KAAKA,GAAG,CAAC,QAAQC,GAAE,EAAE2C,GAAE,EAAEA,IAAG5C,EAAE,GAAG,EAAEC,KAAIoI,GAAGrI,EAAE,GAAG,IAAI,EAAEwJ,GAAGC,IAAI7G,IAAG,EAAE,CAAC,OAAOrD,EAAES,EAAE,GAAGC,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGT,EAAES,EAAE,GAAG,EAAE,CAAC,EAAE,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI;AAAA,EAAK,KAAKA,GAAG,GAAGA,EAAE,IAAI,GAAGA,EAAE,GAAG,KAAK,KAAK,KAAKA,GAAGT,EAAES,EAAE,GAAG,CAAC,EAAE,KAAK,IAAI,IAAK,KAAKA,GAAGA,EAAE,IAAI,EAAE,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,EAAEA,EAAE,IACrf,CAAC,EAAE,CAAC,EAAE,KAAKA,GAAG,CAAC,IAAIC,GAAE,KAAK,OAAOD,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAA8B,GAA5B,IAAIA,EAAE,GAAG,IAAIA,EAAE,GAAG,GAAG,GAAGC,KAAOA,GAAMA,IAAJ,KAAQ2C,IAAG5C,EAAE,GAAG,IAAIA,EAAE,IAAI,EAAK4C,IAAH,GAASA,IAAH,GAAMyF,GAAGrI,EAAE,EAAE,IAAIC,GAAE,QAAQ,CAACA,GAAE,GAAG,IAAI2C,IAAG5C,EAAE,GAAG,EAAEA,EAAE,GAAG,GAAG,GAAM4C,IAAH,GAASA,IAAH,GAAMyF,GAAGrI,EAAE,GAAG,IAAI,CAAC,IAAIC,IAAG,CAAC,OAAOV,EAAEU,GAAE,CAAC,CAAC,EAAE,KAAKD,GAAGA,EAAE,GAAG,KAAKA,GAAGT,EAAE,KAAK,OAAOS,EAAE,GAAG,GAAGA,EAAE,GAAG,GAAG,GAAG,CAAC,EAAE,CAAC,EAAE,KAAKA,IAAIA,EAAE,GAAG,MAAM,SAAS,EAAE,UAAU,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,KAAKA,GAAG,CAACA,EAAEA,EAAE,GAAG,IAAIC,GAAE,GAAGD,EAAE,OAAAA,EAAE,KAAK,IAAIA,CAAC,EAAE,IAAUC,GAAE,IAAI,MAAY,QAAQD,EAAE,GAAG,IAAIA,EAAE,KAAK,MAAM,EAAE,CAAC,EAAE,KAAKA,GAAGA,EAAE,GAAG,KAAK,IAAI,GAAG,EAAEZ,EAAEA,EAAE,QAAQ,MAAM,MAAU,EAC7f,IAAIQ,KAAKD,EAAEP,EAAE,SAASQ,CAAC,IAAIR,EAAEA,EAAE,QAAQ,IAAI,OAAOQ,EAAE,GAAG,EAAED,EAAEC,CAAC,EAAEP,CAAC,CAAC,GAAoC,OAAjCD,EAAEA,EAAE,QAAQ,QAAQ,GAAG,EAAEQ,EAAE8J,GAAGtK,CAAC,EAAKQ,EAAE,OAAOT,EAAS,GAAEwK,GAAG/J,EAAEV,CAAC,EAASU,EAAE,OAAO,EAAC,CAAC,IAAImK,GAAG7K,GAAG,CAAC,GAAG,CAACA,EAAE,CAAC,OAAOC,EAAE,CAACmC,GAAEnC,CAAC,CAAC,CAAC,EAAE,SAAS6K,IAAI,CAAC,IAAI9K,EAAE+K,EAAE9K,EAAE,CAAC,EAAEC,EAAE,IAAIA,KAAKF,GAAG,SAASG,EAAE,CAAC,IAAIC,EAAEJ,EAAEG,CAAC,EAAEF,EAAEE,CAAC,EAAc,OAAOC,GAAnB,WAAqB,UAAU,CAAC4K,GAAG,KAAK7K,CAAC,EAAE,GAAG,CAAC,OAAOC,EAAE,MAAM,KAAK,SAAS,CAAC,QAAC,CAAQkC,KAAI0I,GAAG,IAAI,IAAI7K,GAAGiC,GAAE,EAAEvB,IAAOoK,KAAJ,GAAWD,GAAG,SAAP,IAAgBC,GAAE,EAAElH,IAAG,EAAE8G,GAAGK,EAAE,EAAe,OAAO,OAApB,KAA4B,OAAO,GAAG,GAAG,CAAC,EAAE9K,CAAC,GAAGF,CAAC,EAAE,OAAOD,CAAC,CAC9c,IAAIgL,GAAE,EAAEpK,GAAE,KAAKsK,GAAG,EAAEH,GAAG,CAAC,EAAEI,GAAG,CAAC,EAAEC,GAAG,CAAC,EAAEC,GAAG,EAAEC,GAAG,KAAKC,GAAG,CAAC,EAAE,SAASxK,IAAI,CAAC,OAAO,IAAI,QAAQ,CAAChB,EAAEC,IAAI,CAACsL,GAAG,CAAC,QAAQvL,EAAE,OAAOC,CAAC,CAAC,CAAC,CAAC,CAAC,SAASwL,IAAI,CAAC,IAAIzL,EAAEyJ,GAAG,KAAK,EAAExJ,EAAED,EAAE,GAAGT,EAAE,EAAES,IAAI,IAAI,CAAC,EAAEC,EAAEV,EAAE,EAAES,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,MAAMA,EAAE+K,GAAG,CAAC,EAAE,IAAI9K,EAAEkL,GAAGnL,CAAC,EAAE,OAASC,IAAT,SAAaA,EAAEoL,KAAKF,GAAGnL,CAAC,EAAEC,EAAEmL,GAAGnL,CAAC,EAAED,GAAGA,EAAEC,EAAEb,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAASD,CAAC,CAAC,SAAS0L,IAAI,CAAC,IAAI1L,EAAEX,EAAE,EAAEwB,GAAE,IAAI,IAAI,CAAC,EAAE,OAAAb,EAAE+K,EAAEM,GAAGrL,CAAC,CAAC,EAAE,EAAE+D,GAAS/D,EAAE,CAAC,CAClW,SAAS2L,GAAG3L,EAAE,CAAC,GAAG,CAACsC,GAAE,CAAC,GAAO2I,KAAJ,EAAM,CAAC,IAAIhL,EAAE,GAAGC,EAAE,GAAGF,EAAE,CAACG,EAAE,IAAI,CAAC,GAAG,CAACmC,KAAI6I,GAAGhL,EAAEF,EAAE,GAAGC,GAAG,CAAC+K,GAAE,EAAEJ,GAAG,IAAIe,GAAG/K,EAAC,CAAC,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,OAAO,EAAEV,EAAE,GAAG,GAAG,CAAC,IAAIC,EAAEsL,GAAG,CAAC,OAAOnL,EAAE,CAACH,EAAEG,EAAEJ,EAAE,EAAE,CAAC,IAAIE,EAAE,GAAG,GAAG,CAACQ,GAAE,CAAC,IAAIP,EAAEiL,GAAGjL,IAAIiL,GAAG,MAAMpL,EAAEG,EAAE,OAAOA,EAAE,SAASF,CAAC,EAAEC,EAAE,GAAG,CAAC,GAAGF,GAAG,CAACE,EAAE,MAAMD,CAAE,CAAC,CAAC,EAAEF,EAAE,GAAGD,IAAIgL,GAAE,EAAEpK,GAAE4K,GAAG,EAAe,OAAO,QAApB,KAA6B,QAAQ,GAAG,IAAI,QAAQ,GAAG,MAAM,EAAEZ,GAAG,IAAIgB,GAAGhL,EAAC,CAAC,EAAE,MAAUoK,KAAJ,GAAOA,GAAE,EAAEJ,GAAGiB,EAAE,EAAEvD,GAAE1H,EAAC,EAAEA,GAAE,KAAK2K,GAAG,QAAQrL,GAAG0H,GAAG1H,CAAC,CAAC,GAAGiC,GAAE,kBAAkB6I,EAAC,EAAE,EAAE,OAAOE,EAAE,CAAC,CAC9d,SAAS,GAAGnL,EAAE,CAAC,OAAO2L,GAAG1L,GAAG,CAACD,EAAE,EAAE,KAAKC,CAAC,CAAC,CAAC,CAAC,CAAC6D,GAAE,GAAG,EAAE,QAAQiI,GAAG,MAAM,GAAG,EAAEC,GAAG,EAAE,IAAIA,GAAG,EAAEA,GAAGD,GAAGC,EAAE,EAAE,OAAO,aAAaA,EAAE,EAAE3F,GAAG0F,GAAGrF,GAAE7G,EAAE,aAAa,cAAc,KAAK,CAAC,YAAYG,EAAE,CAAC,MAAMA,CAAC,EAAE,KAAK,KAAK,cAAc,CAAC,EAAEH,EAAE,cAAc,cAAc,KAAK,CAAC,YAAYG,EAAE,CAAC,MAAMA,CAAC,EAAE,KAAK,KAAK,eAAe,CAAC,EAAE,OAAO,OAAO8G,EAAG,UAAU,CAAC,IAAI9G,EAAE,CAAC,OAAO,KAAK,GAAGA,CAAC,CAAC,EAAE,IAAIA,EAAE,CAAC,OAAgB,KAAK,GAAGA,CAAC,IAAlB,MAAmB,EAAE,GAAGA,EAAE,CAAC,IAAIC,EAAE,KAAK,GAAG,IAAI,GAAG,KAAK,GAAG,OAAO,YAAK,GAAGA,CAAC,EAAED,EAASC,CAAC,EAAE,GAAGD,EAAE,CAAC,KAAK,GAAGA,CAAC,EAAE,OAAO,KAAK,GAAG,KAAKA,CAAC,CAAC,CAAC,CAAC,EACjf+G,EAAE,GAAG,KAAK,CAAC,MAAM,MAAM,EAAE,CAAC,MAAM,IAAI,EAAE,CAAC,MAAM,EAAE,EAAE,CAAC,MAAM,EAAE,CAAC,EAAEA,EAAE,GAAGA,EAAE,GAAG,OAAOlH,EAAE,oBAAoB,IAAI,CAAC,QAAQG,EAAE,EAAEC,EAAE8G,EAAE,GAAG9G,EAAE8G,EAAE,GAAG,OAAO,EAAE9G,EAAW8G,EAAE,GAAG9G,CAAC,IAAf,QAAkB,EAAED,EAAE,OAAOA,CAAC,EAC5K,IAAIiM,GAAG,CAAC/H,GAAGG,GAAGa,GAAGE,GAAGC,GAAGI,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGC,GAAGmD,GAAGC,GAAGQ,GAAGC,GAAGC,GAAGC,GAAGC,GAAGE,EAAE,EAAE6B,GAAG,CAAC,GAAG,SAASlM,EAAEC,EAAEC,EAAE,CAAC,OAAO,GAAG,SAAS,CAAC,MAAML,EAAE,GAAGG,EAAEC,EAAEC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAE,CAAC,MAAAF,KAAK,EAAG,IAAI+E,GAAG/E,CAAC,EAAG,GAAGC,IAAI,EAAEC,IAAI,CAAC,EAAE8E,GAAGhF,EAAEiF,KAAWD,EAAG,EAAE,GAAG,SAAShF,EAAE,CAACmM,GAAGnM,IAAI,EAAE,CAACqB,EAAE,EAAE,CAACD,EAAG,OAAO,EAAE,EAAE0C,GAAE,GAAG,CAAC,EAAE,EAAE,SAAS9D,EAAE,CAACA,KAAK,EAAEuB,EAAE,YAAY,CAAC,IAAI,gBAAgB,OAAOvB,CAAC,CAAC,IAAIA,EAAE8D,GAAE,GAAG9D,CAAC,IAAIoC,GAAE,EAAE0B,GAAE,GAAG9D,CAAC,EAAE,EAAE,EAAEmF,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEI,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,GAAGC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAEC,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEC,GAAG,EAAE,SAASnG,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAACJ,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAED,EAAEqG,GAAErG,CAAC,EAAE,IAAII,EAC/eJ,EAAE,QAAQ,GAAG,GADoe,GACleI,IAAID,GAAG,IAAI,KAAK,IAAIwG,GAAE5G,EAAE,CAAC,KAAKC,EAAE,aAAaK,GAAGA,EAAE,WAAW,SAASA,EAAEC,EAAE,CAAC,GAAa,OAAOA,GAAjB,UAA8B,OAAOA,GAAjB,SAAmB,MAAM,IAAI,UAAU,mBAAmB6F,GAAG7F,CAAC,CAAC,QAAQ,KAAK,IAAI,EAAE,EAAE,GAAGA,EAAEJ,GAAGI,EAAEH,EAAE,MAAM,IAAI,UAAU,qBAAqBgG,GAAG7F,CAAC,CAAC,wDAAwDN,CAAC,wCAAwCE,CAAC,KAAKC,CAAC,IAAI,EAAE,OAAOG,CAAC,EAAE,eAAe,EAAE,qBAAqBsG,GAAG5G,EAAEC,EAAE,CAACG,CAAC,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,GAAG,SAASL,EAAEC,EAAEC,EAAEC,EAAE,CAACH,KAAK,EAAEC,EAAEqG,GAAErG,IAAI,CAAC,EAAE2G,GAAE5G,EAAE,CAAC,KAAKC,EAAE,aAAa,SAASG,EAAE,CAAC,MAAM,CAAC,CAACA,CAAC,EACxgB,WAAW,SAASA,EAAEC,EAAE,CAAC,OAAOA,EAAEH,EAAEC,CAAC,EAAE,eAAe,EAAE,qBAAqB,SAASC,EAAE,CAAC,OAAO,KAAK,aAAarB,EAAE,EAAEqB,IAAI,CAAC,CAAC,CAAC,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,GAAG,SAASJ,EAAEC,EAAE,CAACD,KAAK,EAAEC,EAAEqG,GAAErG,IAAI,CAAC,EAAE2G,GAAE5G,EAAE,CAAC,KAAKC,EAAE,aAAaC,GAAG,CAAC,IAAIC,EAAE8G,EAAE/G,CAAC,EAAE,OAAA8G,EAAG9G,CAAC,EAASC,CAAC,EAAE,WAAW,CAACD,EAAEC,IAAI+G,EAAE/G,CAAC,EAAE,eAAe,EAAE,qBAAqBgH,EAAG,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,SAASnH,EAAEC,EAAEC,EAAE,CAACF,KAAK,EAAEE,KAAK,EAAED,EAAEqG,GAAErG,IAAI,CAAC,EAAE2G,GAAE5G,EAAE,CAAC,KAAKC,EAAE,aAAaE,GAAGA,EAAE,WAAW,CAACA,EAAEC,IAAIA,EAAE,eAAe,EAAE,qBAAqBgH,EAAGnH,EAAEC,CAAC,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAC7b,GAD8bJ,KAAK,EAAEE,KAAK,EAAED,EAAEqG,GAAErG,IAAI,CAAC,EAC9eG,IAAL,KAASA,EAAE,YAAYA,EAAEG,GAAGA,EAASJ,IAAJ,EAAM,CAAC,IAAIE,EAAE,GAAG,EAAEH,EAAEE,EAAEG,GAAGA,GAAGF,IAAIA,CAAC,CAAC,IAAIC,EAAEL,EAAE,SAAS,UAAU,EAAE,SAASM,EAAEC,EAAE,CAAC,OAAOA,IAAI,CAAC,EAAE,SAASD,EAAEC,EAAE,CAAC,OAAOA,CAAC,EAAEoG,GAAE5G,EAAE,CAAC,KAAKC,EAAE,aAAaG,EAAE,WAAWE,EAAE,eAAe,EAAE,qBAAqBuG,GAAG5G,EAAEC,EAAMC,IAAJ,CAAK,EAAE,GAAG,IAAI,CAAC,CAAC,EAAE,EAAE,SAASH,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEE,EAAE,CAAC,IAAIC,EAAEf,EAAE,EAAEc,IAAI,IAAI,CAAC,EAAE,OAAAA,EAAEd,EAAE,EAAEc,EAAE,IAAI,IAAI,CAAC,EAAS,IAAID,EAAEzB,EAAE,EAAE,OAAO0B,EAAEC,CAAC,CAAC,CAACN,KAAK,EAAE,IAAII,EAAE,CAAC,UAAU,WAAW,WAAW,YAAY,WAAW,YAAY,aAAa,aAAa,cAAc,cAAc,EAAEH,CAAC,EAAEC,EAAEoG,GAAEpG,IAAI,CAAC,EACrf0G,GAAE5G,EAAE,CAAC,KAAKE,EAAE,aAAaC,EAAE,eAAe,EAAE,qBAAqBA,CAAC,EAAE,CAAC,GAAG,EAAE,CAAC,CAAC,EAAE,EAAE,SAASH,EAAEC,EAAE,CAACD,KAAK,EAAEC,EAAEqG,GAAErG,IAAI,CAAC,EAAE,IAAIC,EAAkBD,IAAhB,cAAkB2G,GAAE5G,EAAE,CAAC,KAAKC,EAAE,aAAa,SAASE,EAAE,CAAC,IAAIC,EAAEb,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAEE,EAAEF,EAAE,EAAE,GAAGD,EAAE,QAAQI,EAAED,EAAEE,EAAE,EAAEA,GAAGH,EAAE,EAAEG,EAAE,CAAC,IAAIC,EAAEH,EAAEE,EAAE,GAAGA,GAAGH,GAAMrB,EAAE,EAAEyB,IAAI,CAAC,GAAZ,EAAc,CAAY,GAAXF,EAAEmD,GAAEnD,EAAEE,EAAEF,CAAC,EAAcG,IAAT,OAAW,IAAIA,EAAEH,OAAOG,GAAG,OAAO,aAAa,CAAC,EAAEA,GAAGH,EAAEA,EAAEE,EAAE,CAAC,CAAC,KAAK,CAAY,IAAXC,EAAE,MAAML,CAAC,EAAMG,EAAE,EAAEA,EAAEH,EAAE,EAAEG,EAAEE,EAAEF,CAAC,EAAE,OAAO,aAAaxB,EAAE,EAAEsB,EAAEE,IAAI,CAAC,CAAC,EAAEE,EAAEA,EAAE,KAAK,EAAE,CAAC,CAAC,OAAA8H,GAAEpI,CAAC,EAASM,CAAC,EAAE,WAAW,SAASN,EAAEC,EAAE,CAACA,aAAa,cAAcA,EAAE,IAAI,WAAWA,CAAC,GAC9f,IAAIC,EAAY,OAAOD,GAAjB,SAAmB,GAAG,EAAEC,GAAGD,aAAa,YAAYA,aAAa,mBAAmBA,aAAa,WAAW,MAAM,IAAIsG,GAAE,uCAAuC,EAAE,IAAIpG,EAAEJ,GAAGG,EAAEiF,GAAGlF,CAAC,EAAEA,EAAE,OAAWG,EAAEkJ,GAAG,EAAEnJ,EAAE,CAAC,EAAEE,EAAED,EAAE,EAAmB,GAAjBhB,EAAE,EAAEgB,IAAI,IAAI,CAAC,EAAED,EAAKJ,GAAGG,EAAEmF,GAAGpF,EAAEI,EAAEF,EAAE,CAAC,UAAUD,EAAE,IAAIA,EAAE,EAAEA,EAAEC,EAAE,EAAED,EAAE,CAAC,IAAII,EAAEL,EAAE,WAAWC,CAAC,EAAE,GAAG,IAAII,EAAE,MAAM8H,GAAE/H,CAAC,EAAE,IAAIkG,GAAE,wDAAwD,EAAE3H,EAAE,EAAEyB,EAAEH,IAAI,CAAC,EAAEI,CAAC,KAAM,KAAIJ,EAAE,EAAEA,EAAEC,EAAE,EAAED,EAAEtB,EAAE,EAAEyB,EAAEH,IAAI,CAAC,EAAED,EAAEC,CAAC,EAAE,OAAOF,IAAP,MAAUA,EAAE,KAAKoI,GAAEhI,CAAC,EAASA,CAAC,EAAE,eAAe,EAAE,qBAAqB8G,GAC7f,GAAGlH,EAAE,CAACoI,GAAEpI,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASH,EAAEC,EAAEC,EAAE,CAA6B,GAA5BF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEA,EAAEoG,GAAEpG,CAAC,EAASD,IAAJ,EAAO,IAAIE,EAAEoH,GAAOnH,EAAEoH,GAAOnH,EAAEoH,GAAOnH,EAAE,IAAInB,EAAG,EAAMoB,EAAE,OAAWN,IAAJ,IAAQE,EAAEuH,GAAGtH,EAAEuH,EAAGtH,EAAEuH,GAAGtH,EAAE,IAAIf,EAAE,EAAEgB,EAAE,GAAGqG,GAAE5G,EAAE,CAAC,KAAKE,EAAE,aAAaM,GAAG,CAAC,QAAQC,EAAElB,EAAE,EAAEiB,IAAI,IAAI,CAAC,EAAEE,EAAEJ,EAAE,EAAEK,GAAEC,GAAEJ,EAAE,EAAEM,EAAE,EAAEA,GAAGL,EAAE,EAAEK,EAAE,CAAC,IAAIC,GAAEP,EAAE,EAAEM,EAAEb,GAAKa,GAAGL,GAAMC,EAAEK,KAAIR,CAAC,GAAV,KAAYK,GAAET,EAAES,GAAEG,GAAEH,EAAC,EAAWD,KAAT,OAAWA,GAAEC,IAAGD,IAAG,OAAO,aAAa,CAAC,EAAEA,IAAGC,IAAGA,GAAEG,GAAEd,EAAC,CAAC,OAAAsI,GAAE/H,CAAC,EAASG,EAAC,EAAE,WAAW,CAACH,EAAEC,IAAI,CAAC,GAAa,OAAOA,GAAjB,SAAmB,MAAM,IAAIiG,GAAE,6CAA6CxG,CAAC,EAAE,EAAE,IAAIQ,EAAEL,EAAEI,CAAC,EAAEE,GAAE8I,GAAG,EAAE/I,EAAET,CAAC,EAAE,OAAAV,EAAE,EAAEoB,KAAI,CAAC,EAAED,GAClfH,EAAEH,EAAEK,EAAEE,GAAE,EAAED,EAAET,CAAC,EAASO,IAAP,MAAUA,EAAE,KAAK+H,GAAE5H,EAAC,EAASA,EAAC,EAAE,eAAe,EAAE,qBAAqBwG,EAAG,GAAG3G,EAAE,CAAC+H,GAAE/H,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,SAASR,EAAEC,EAAE,CAACD,KAAK,EAAEC,EAAEqG,GAAErG,IAAI,CAAC,EAAE2G,GAAE5G,EAAE,CAAC,GAAG,GAAG,KAAKC,EAAE,eAAe,EAAE,aAAa,IAAI,CAAC,EAAE,WAAW,IAAI,CAAC,CAAC,CAAC,CAAC,EAAE,GAAG,IAAI,GAAG,EAAE,SAASD,EAAEC,EAAE,CAACD,KAAK,EAAEA,GAAGC,IAAI,EAAE,WAAW,IAAIwE,GAAG,CAAC,EAAElD,EAAE,YAAY,CAAC,aAAavB,EAAE,IAAI,cAAc,CAAC,GAAGA,EAAE8D,GAAE,GAAG9D,CAAC,IAAIA,EAAE,YAAY,CAAC,IAAI,cAAc,CAAC,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAEC,EAAE,CAACF,KAAK,EAAEC,GAAG,EAAEkI,GAAG,OAAOlI,EAAEC,EAAEA,IAAI,IAAI,EAAE,QAAQC,EAAE,EAAEA,EAAEF,EAAEE,IAAIgI,GAAGhI,CAAC,EAAEoC,GAAErC,EAAE,EAAEC,CAAC,EAAEoC,GAAErC,EAAE,EAAEC,EAAE,CAAC,EAAET,EAAG,EAAEQ,EAAE,EAAEC,EAAE,IAAI,CAAC,EAAE,OAAAJ,EAAE,EACpfA,EAAEwD,GAAG,CAACxD,EAAE,CAAC,EAAEiM,GAAGjM,CAAC,EAAE8D,GAAE,GAAG7D,EAAEA,EAAED,EAAE,MAAM,KAAKoI,EAAE,EAAEtE,GAAE,GAAG,EAAS7D,CAAC,EAAE,GAAG6H,GAAG,GAAG,SAAS9H,EAAE,CAACsB,GAAGwC,GAAE,GAAG9D,IAAI,CAAC,EAAE,IAAI,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAEF,EAAEiH,EAAEjH,IAAI,CAAC,EAAEC,EAAEoI,GAAGpI,EAAE,WAAW,EAAE,IAAIE,EAAE,CAAC,EAAEC,EAAE8G,EAAE/G,CAAC,EAAE,OAAAZ,EAAE,EAAEW,IAAI,IAAI,CAAC,EAAEE,EAASH,EAAE,WAAWE,EAAEH,CAAC,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAEC,EAAEC,EAAE,CAACF,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAEJ,EAAE0I,GAAG1I,IAAI,CAAC,EAAEC,EAAEgH,EAAEhH,IAAI,CAAC,EAAEC,EAAEuI,GAAGvI,CAAC,EAAE,IAAIG,EAAE,CAAC,EAAE,OAAAL,EAAEA,EAAEC,EAAEC,EAAEG,EAAED,CAAC,EAAEC,EAAE,SAASd,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAE+G,EAAE7G,CAAC,GAAUL,CAAC,EAAE,EAAEgH,EAAG,EAAE,SAAShH,EAAEC,EAAE,CAAC,OAAAA,KAAK,EAAED,EAAEiH,EAAEjH,IAAI,CAAC,EAAEC,EAAEgH,EAAEhH,CAAC,EAASD,GAAGC,CAAC,EAAE,EAAE,SAASD,EAAE,CAAQ,OAAPA,KAAK,EAASA,IAAJ,EAAakH,EAAEyB,GAAG,CAAC,GAAE3I,EAAEyI,GAAGzI,CAAC,EAASkH,EAAEyB,GAAG,EAAE3I,CAAC,CAAC,EAAC,EAAE,EAAE,SAASA,EACzfC,EAAE,CAACA,EAAE4I,GAAG7I,EAAEC,IAAI,CAAC,EAAE,IAAIC,EAAED,EAAE,MAAM,EAAED,IAAI,QAAQG,EAAE,CAAC,SAAS,EAAEC,EAAE,CAACF,CAAC,EAAEG,EAAE,GAAGC,EAAE,EAAEA,EAAEN,EAAE,EAAEM,EAAED,IAAQC,IAAJ,EAAM,KAAK,IAAI,MAAMA,EAAEH,EAAE,KAAK,UAAUG,CAAC,EAAEF,EAAE,KAAKH,EAAEK,CAAC,CAAC,EAAEA,EAAEJ,EAAE,KAAK,KAAKD,EAAE,IAAIQ,GAAGA,EAAE,IAAI,EAAE,KAAK,GAAG,EAAE,IAAI,IAAIF,EAAE,mBAAmBuI,GAAG,gBAAgBxI,CAAC,EAAE;AAAA,EAAwCE,EAAE,EAAE,IAAIF,EAAE,EAAEA,EAAEN,EAAE,EAAEM,EAAEC,GAAG,cAAcD,EAAE,aAAaA,EAAE,8BAA8BE,EAAE,IAAIA,EAAE,IAAI;AAAA,EAAOA,GAAGP,EAAEK,CAAC,EAAE,eAAwD,IAAzCC,GAAG,6BAA6BF,EAAE;AAAA,EAAWC,EAAE,EAAEA,EAAEN,EAAE,EAAEM,EAAEL,EAAEK,CAAC,EAAE,eAAeC,GAAG,cAAcD,EAAE,oBAChfA,EAAE;AAAA,GAAQ,OAAAJ,EAAE,KAAKK,GAAG;AAAA,GAAqDJ,EAAE,KAAKI,EAAE;AAAA,CAAM,EAAEP,EAAEgJ,GAAG7I,CAAC,EAAE,MAAM,KAAKC,CAAC,EAASwI,GAAG5I,CAAC,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAE,CAAC,OAAAA,KAAK,EAAED,EAAEiH,EAAEjH,IAAI,CAAC,EAAEC,EAAEgH,EAAEhH,CAAC,EAASiH,EAAElH,EAAEC,CAAC,CAAC,CAAC,EAAE,EAAE,SAASD,EAAE,CAACA,KAAK,EAAE,EAAEA,IAAI+G,EAAE,IAAI/G,CAAC,EAAE,IAAI,EAAE,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAEH,EAAEiH,EAAEjH,IAAI,CAAC,EAAE,IAAII,EAAE8I,GAAGjJ,CAAC,EAAE,OAAAG,IAAIA,EAAE6I,GAAGhJ,CAAC,EAAEiJ,GAAGjJ,CAAC,EAAEG,GAAUA,EAAEJ,EAAEE,EAAEC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,OAAO+G,EAAE,CAAC,CAAC,CAAC,EAAE,EAAE,SAASlH,EAAE,CAACA,EAAEiH,EAAEjH,IAAI,CAAC,EAAE,QAAQC,EAAE,MAAMD,EAAE,MAAM,EAAEE,EAAE,EAAEA,EAAEF,EAAE,OAAOE,IAAID,EAAEC,CAAC,EAAEF,EAAEE,CAAC,EAAE,OAAOgH,EAAEjH,CAAC,CAAC,EAAE,EAAE,SAASD,EAAE,CAAC,OAAOkH,EAAEuB,GAAGzI,IAAI,CAAC,CAAC,CAAC,EAAE,EAAE,UAAU,CAAC,OAAOkH,EAAE,CAAC,CAAC,CAAC,EACtf,EAAE,SAASlH,EAAE,CAACA,KAAK,EAAE,QAAQC,EAAEgH,EAAEjH,CAAC,EAAEC,EAAE,QAAQ,CAAC,IAAIC,EAAED,EAAE,IAAI,EAAEA,EAAE,IAAI,EAAEC,CAAC,CAAC,CAAC8G,EAAGhH,CAAC,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAEC,EAAE,CAACD,KAAK,EAAEC,KAAK,EAAEF,EAAEiH,EAAEjH,IAAI,CAAC,EAAEC,EAAEgH,EAAEhH,CAAC,EAAEC,EAAE+G,EAAE/G,CAAC,EAAEF,EAAEC,CAAC,EAAEC,CAAC,EAAE,EAAE,SAASF,EAAEC,EAAE,CAAC,OAAAA,KAAK,EAAED,EAAEqI,GAAGrI,IAAI,EAAE,mBAAmB,EAAEA,EAAEA,EAAE,qBAAqBC,CAAC,EAASiH,EAAElH,CAAC,CAAC,EAAE,EAAE,SAASA,EAAEC,EAAE,CAACD,EAAE,kBAAkBA,GAAG,iBAAiBA,EAAE,IAAI,OAAOA,CAAC,EAAEC,KAAK,EAAED,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEX,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAED,EAAE,cAAc,EAAEX,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAED,EAAE,cAAc,EAAEX,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAED,EAAE,YAAY,EAAEX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,EAAE,WAAW,EAAEX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,EAAE,YAAY,EACvfX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,EAAE,eAAe,EAAE,KAAKX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,EAAE,UAAU,EAAEA,GAAGA,EAAE,QAAQ,EAAE,KAAK,IAAIA,EAAE,eAAe,EAAE,EAAE,EAAE,EAAE,EAAE,EAAE,CAAC,GAAG,MAAM,EAAEX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,CAAC,EAAE,GAAG,SAASA,EAAEC,EAAE,CAACD,EAAE,kBAAkBA,GAAG,iBAAiBA,EAAE,IAAI,OAAOA,CAAC,EAAEC,KAAK,EAAED,EAAE,IAAI,KAAK,IAAIA,CAAC,EAAEX,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAED,EAAE,WAAW,EAAEX,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAED,EAAE,WAAW,EAAEX,EAAE,EAAEY,EAAE,IAAI,IAAI,CAAC,EAAED,EAAE,SAAS,EAAEX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,EAAE,QAAQ,EAAEX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,EAAE,SAAS,EAAEX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,EAAE,YAAY,EAAE,KAAKX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,EAAE,OAAO,EAAE,IAAIE,GAAGiJ,GAAGnJ,EAAE,YAAY,CAAC,EACxfoJ,GAAGC,IAAIrJ,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEX,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAEC,EAAEb,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAE,EAAE,GAAGD,EAAE,kBAAkB,GAAGE,EAAG,IAAI,KAAKF,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAE,IAAIG,EAAG,IAAI,KAAKH,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEA,GAAGE,GAAGC,GAAGH,EAAE,kBAAkB,GAAG,KAAK,IAAIG,EAAED,CAAC,GAAG,EAAEb,EAAE,EAAEY,EAAE,KAAK,IAAI,CAAC,EAAED,CAAC,EAAE,GAAG,SAASA,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAE,IAAI,KAAKZ,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAE,KAAKX,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEX,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEX,EAAE,EAAEW,IAAI,IAAI,CAAC,EAAE,CAAC,EAAEE,EAAEb,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAEG,EAAEF,EAAE,kBAAkB,EAAEG,EAAG,IAAI,KAAKH,EAAE,YAAY,EACvf,EAAE,CAAC,EAAG,kBAAkB,EAAEI,EAAG,IAAI,KAAKJ,EAAE,YAAY,EAAE,EAAE,CAAC,EAAG,kBAAkB,EAAEK,EAAE,KAAK,IAAID,EAAED,CAAC,EAAE,SAAEF,EAAEb,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAE,EAAOI,GAAGC,GAAGC,GAAGH,GAAG,EAAED,IAAII,GAAGH,KAAKC,EAAE,KAAK,IAAIC,EAAED,CAAC,EAAEH,EAAE,QAAQA,EAAE,QAAQ,EAAE,MAAM,EAAEC,EAAEI,EAAEF,GAAGD,EAAE,GAAGd,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAEC,EAAE,OAAO,EAAEC,GAAGiJ,GAAGlJ,EAAE,YAAY,CAAC,EAAEmJ,GAAGC,IAAIpJ,EAAE,SAAS,CAAC,EAAEA,EAAE,QAAQ,EAAE,EAAE,EAAEZ,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAEE,EAAEb,EAAE,EAAEW,IAAI,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,WAAW,EAAEZ,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEZ,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAAEZ,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAEC,EAAE,SAAS,EAAEZ,EAAE,EAAEW,EAAE,KAAK,IAAI,CAAC,EAAEC,EAAE,QAAQ,EAC5e,OAAOA,EAAE,QAAQ,EAAE,GAAG,CAAC,EAAE,EAAEqJ,GAAG,EAAEC,GAAG,EAAE,SAASvJ,EAAEC,EAAEC,EAAE,CAAC,SAASC,EAAEM,EAAE,CAAC,OAAOA,EAAEA,EAAE,aAAa,EAAE,MAAM,mBAAmB,GAAGA,EAAE,CAAC,EAAE,KAAK,CAACT,KAAK,EAAEC,KAAK,EAAEC,KAAK,EAAE,IAAIE,EAAG,IAAI,OAAM,YAAY,EAAEC,EAAE,IAAI,KAAKD,EAAE,EAAE,CAAC,EAAEE,EAAE,IAAI,KAAKF,EAAE,EAAE,CAAC,EAAEA,EAAEC,EAAE,kBAAkB,EAAE,IAAIE,EAAED,EAAE,kBAAkB,EAAEE,EAAE,KAAK,IAAIJ,EAAEG,CAAC,EAAEhB,EAAE,EAAES,IAAI,IAAI,CAAC,EAAE,GAAGQ,EAAEnB,EAAE,EAAEY,IAAI,IAAI,CAAC,EAAE,EAAOG,GAAGG,GAAGP,EAAEG,EAAEE,CAAC,EAAEJ,EAAEE,EAAEG,CAAC,EAAEN,EAAEwJ,GAAGxJ,CAAC,EAAEC,EAAEuJ,GAAGvJ,CAAC,EAAEM,EAAEH,GAAGb,EAAE,EAAEW,IAAI,IAAI,CAAC,EAAEF,EAAET,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAED,IAAIV,EAAE,EAAEW,IAAI,IAAI,CAAC,EAAED,EAAEV,EAAE,EAAEW,EAAE,IAAI,IAAI,CAAC,EAAEF,EAAE,EAAE,EAAE,IAAI,CAACoC,GAAE,EAAE,CAAC,EAAE,EAAE,SAASpC,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE0J,GAAG1J,IAClf,EAAEC,IAAI,CAAC,EAASsD,GAAGxD,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,SAASD,EAAEC,EAAEC,EAAE,CAAC,OAAAF,KAAK,EAAEC,EAAE0J,GAAG1J,IAAI,EAAEC,IAAI,CAAC,EAASsD,GAAGxD,CAAC,EAAE,MAAM,KAAKC,CAAC,CAAC,EAAE,EAAE,IAAI,CAAC,EAAE,EAAE,IAAI,KAAK,IAAI,EAAE,GAAG,IAAI,CAAC,MAAA8D,IAAG,EAAO,QAAS,EAAE,EAAE,UAAU,CAAC,MAAO,WAAU,EAAE,EAAE,IAAI,YAAY,WAAW,YAAY,IAAI,EAAE,EAAE,IAAIzC,EAAE,cAAc,KAAK,EAAE,OAAO,UAAU,oBAAoB,EAAE,SAAStB,EAAE,CAACA,KAAK,EAAE,IAAIC,EAAElB,EAAE,EAAE,OAAO,GAAGiB,GAAGC,GAAG,WAAWD,EAAE,MAAM,GAAG,QAAQE,EAAE,EAAE,GAAGA,EAAEA,GAAG,EAAE,CAAC,IAAIC,EAAEF,GAAG,EAAE,GAAGC,GAAGC,EAAE,KAAK,IAAIA,EAAEH,EAAE,SAAS,EAAE,IAAII,EAAE,KAAKD,EAAE,KAAK,IAAIH,EAAEG,CAAC,EAAEH,EAAE,CAACI,GAAGA,EAAE,IAAI,KAAKA,EAAE,WAAWD,GACnf,MAAMA,EAAE,OAAO,KAAK,EAAEvB,GAAE,OAAO,WAAW,OAAO,MAAM,GAAG,CAACA,GAAE,KAAKwB,CAAC,EAAEtB,GAAE,EAAE,IAAIuB,EAAE,EAAE,MAAML,CAAC,MAAS,CAAC,CAACK,EAAE,MAAM,CAAC,GAAGA,EAAE,MAAM,EAAE,CAAC,MAAM,EAAE,EAAE,GAAG0J,GAAG,GAAGC,GAAG,EAAE5F,GAAG,EAAE6F,GAAG,EAAEC,GAAG,GAAGC,GAAG,EAAEE,GAAG,EAAEzL,IAAGiB,EAAE,WAAW,GAAG6K,GAAG,EAAE,SAAS1K,EAAEC,EAAEC,EAAEC,EAAE,CAAC,OAAOuK,GAAG1K,IAAI,EAAEC,IAAI,EAAEC,IAAI,EAAEC,IAAI,CAAC,CAAC,CAAC,EAAE4K,EAAE,UAAU,CAAC,IAAI/K,EAAE,CAAC,EAAEkM,EAAE,EAAE,OAAApJ,KAAKS,GAAGvD,EAAE,SAASC,EAAE,CAAC,IAAIC,EAAED,EAAE,OAAO8K,EAAE9K,EAAE,SAAS,QAAQ8K,EAAED,GAAG,EAAEC,EAAEqB,GAAG,EAAEtI,GAAE,GAAG,KAAKiH,EAAE,EAAE,EAAEnI,GAAG,QAAQmI,EAAE,EAAE,EAAE1I,GAAGnC,EAAE+C,GAAG,CAAC,CAAC,EAAE,MAAMlD,CAAE,EAAQ,CAAC,CAAC,EAAE,EAAEF,EAAE,SAAS,CAACG,EAAEC,KAAKJ,EAAE,SAASkL,EAAE,IAAI/K,EAAEC,CAAC,EACxcJ,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBkL,EAAE,IAAI/K,EAAEC,CAAC,EAAEJ,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKZ,EAAE,yBAAyBkL,EAAE,IAAI/K,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEZ,EAAE,4BAA4B,CAACG,EAAEC,KAAKJ,EAAE,4BAA4BkL,EAAE,IAAI/K,EAAEC,CAAC,EAAEJ,EAAE,6BAA6B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,6BAA6BkL,EAAE,IAAI/K,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0B,CAACG,EAAEC,EAAEC,KAAKL,EAAE,0BAA0BkL,EAAE,IAAI/K,EAAEC,EAAEC,CAAC,EAAEL,EAAE,0BAA0BG,IAAIH,EAAE,0BAA0BkL,EAAE,IAAI/K,CAAC,EACxdH,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,kBAAkBkL,EAAE,IAAI/K,EAAEC,EAAEC,CAAC,EAAEL,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBkL,EAAE,IAAI/K,CAAC,EAAEH,EAAE,wBAAwB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,wBAAwBkL,EAAE,IAAI/K,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiB,CAACG,EAAEC,KAAKJ,EAAE,iBAAiBkL,EAAE,IAAI/K,EAAEC,CAAC,EAAEJ,EAAE,kBAAkB,CAACG,EAAEC,KAAKJ,EAAE,kBAAkBkL,EAAE,IAAI/K,EAAEC,CAAC,EAAEJ,EAAE,SAASG,IAAIH,EAAE,SAASkL,EAAE,IAAI/K,CAAC,EAAEH,EAAE,iBAAiB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKR,EAAE,iBAAiBkL,EAAE,IAAI/K,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,kBAAkB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,kBAAkBkL,EAAE,IAAI/K,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EACteP,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBkL,EAAE,IAAI/K,CAAC,EAAEH,EAAE,qBAAqB,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,qBAAqBkL,EAAE,IAAI/K,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsB,CAACG,EAAEC,EAAEC,KAAKL,EAAE,sBAAsBkL,EAAE,IAAI/K,EAAEC,EAAEC,CAAC,EAAEL,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBkL,EAAE,IAAI/K,CAAC,EAAEH,EAAE,kBAAkBG,IAAIH,EAAE,kBAAkBkL,EAAE,IAAI/K,CAAC,EAAEH,EAAE,cAAc,CAACG,EAAEC,EAAEC,KAAKL,EAAE,cAAckL,EAAE,IAAI/K,EAAEC,EAAEC,CAAC,EAAEL,EAAE,eAAe,CAACG,EAAEC,EAAEC,EAAEC,KAAKN,EAAE,eAAekL,EAAE,IAAI/K,EAAEC,EAAEC,EAAEC,CAAC,EAAEN,EAAE,sBAAsBG,IAAIH,EAAE,sBAAsBkL,EAAE,IAAI/K,CAAC,EACteH,EAAE,mBAAmBG,IAAIH,EAAE,mBAAmBkL,EAAE,IAAI/K,CAAC,EAAEH,EAAE,mBAAmB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,KAAKP,EAAE,mBAAmBkL,EAAE,IAAI/K,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEP,EAAE,QAAQ,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAKV,EAAE,QAAQkL,EAAE,IAAI/K,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAEV,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBkL,EAAE,IAAI/K,CAAC,EAAEH,EAAE,YAAY,CAACG,EAAEC,EAAEC,KAAKL,EAAE,YAAYkL,EAAE,IAAI/K,EAAEC,EAAEC,CAAC,EAAEL,EAAE,iBAAiBG,IAAIH,EAAE,iBAAiBkL,EAAE,IAAI/K,CAAC,EAAE,IAAIwE,GAAG3E,EAAE,cAAc,KAAK2E,GAAG3E,EAAE,cAAckL,EAAE,IAAI,EAAEtB,GAAG5J,EAAE,QAAQG,IAAIyJ,GAAG5J,EAAE,QAAQkL,EAAE,IAAI/K,CAAC,EAAEuI,GAAE1I,EAAE,MAAMG,IAAIuI,GAAE1I,EAAE,MAAMkL,EAAE,IAAI/K,CAAC,EACrdH,EAAE,sBAAsB,KAAKA,EAAE,sBAAsBkL,EAAE,IAAI,EAAE,IAAIzC,GAAGtI,IAAIsI,GAAGyC,EAAE,IAAI/K,CAAC,EAAEH,EAAE,6BAA6B,KAAKA,EAAE,6BAA6BkL,EAAE,IAAI,EAAE,IAAIoB,GAAGtM,EAAE,yBAAyB,CAACG,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,KAAK8L,GAAGtM,EAAE,yBAAyBkL,EAAE,IAAI/K,EAAEC,EAAEC,EAAEC,EAAEC,EAAEC,CAAC,EAAER,EAAE,4BAA4B,KAAKA,EAAE,4BAA4BkL,EAAE,IAAI,EACzU,IAAI5C,GAAG,CAACnI,EAAEC,EAAEC,EAAEC,KAAKgI,GAAG4C,EAAE,IAAI/K,EAAEC,EAAEC,EAAEC,CAAC,EAAEoE,GAAGvE,IAAIuE,GAAGwG,EAAE,IAAI/K,CAAC,EAAE8E,GAAGjF,EAAE,yBAAyBG,IAAI8E,GAAGjF,EAAE,yBAAyBkL,EAAE,IAAI/K,CAAC,EAAE+H,GAAGlI,EAAE,2BAA2B,KAAKkI,GAAGlI,EAAE,2BAA2BkL,EAAE,IAAI,EAAEpG,GAAG,CAAC3E,EAAEC,KAAK0E,GAAGoG,EAAE,IAAI/K,EAAEC,CAAC,EAAEgI,GAAG,KAAKA,GAAG8C,EAAE,IAAI,EAAEnG,GAAG5E,IAAI4E,GAAGmG,EAAE,IAAI/K,CAAC,EAAEkI,GAAGlI,IAAIkI,GAAG6C,EAAE,IAAI/K,CAAC,EAAE6E,GAAGhF,EAAE,WAAW,CAACG,EAAEC,KAAK4E,GAAGhF,EAAE,WAAWkL,EAAE,IAAI/K,EAAEC,CAAC,EAAE4L,GAAG7L,IAAI6L,GAAGd,EAAE,IAAI/K,CAAC,EAAEkL,GAAG,KAAKA,GAAGH,EAAE,IAAI,EAAEa,GAAG5L,IAAI4L,GAAGb,EAAE,IAAI/K,CAAC,EAAE8L,GAAG,KAAKA,GAAGf,EAAE,IAAI,EAAElL,EAAE,eAAe,QAAQA,EAAE,cAAc,QACxc,SAASuM,IAAI,CAAC,IAAIpM,EAAE+K,EAAE/K,EAAE,OAAO,OAAO,CAAC,EAAEA,CAAC,EAAE,IAAIC,EAAEE,GAAG,IAAIA,EAAE,IAAI,EAAED,EAAEC,GAAGC,GAAGD,EAAEC,CAAC,IAAI,EAAE,OAAAJ,EAAE,iBAAiBC,EAAED,EAAE,gBAAgB,EAAEA,EAAE,GAAGC,EAAED,EAAE,EAAE,EAAEA,EAAE,GAAGE,EAAEF,EAAE,EAAE,EAAEA,EAAE,GAAGE,EAAEF,EAAE,EAAE,EAAEA,EAAE,GAAGC,EAAED,EAAE,EAAE,EAAEA,EAAE,GAAGE,EAAEF,EAAE,EAAE,EAASA,CAAC,CAACH,EAAE,WAAWjB,GAAEiB,EAAE,WAAWqI,GAAGrI,EAAE,UAAUoI,GAAGpI,EAAE,aAAa+E,GAAG/E,EAAE,iBAAiB,IAAI,EAAEkE,GAAElE,EAAE,aAAa4D,GAAE5D,EAAE,aAAa2F,GAAG3F,EAAE,gBAAgByF,GAAGzF,EAAE,WAAW8D,GAAG9D,EAAE,QAAQiE,GAAE,IAAIuI,GAAGrJ,GAAG,SAASsJ,GAAI,CAACD,IAAIE,GAAG,EAAEF,KAAKrJ,GAAGsJ,EAAG,EACha,SAASC,IAAI,CAAC,EAAEzJ,KAAKvB,GAAGzB,EAAGD,CAAC,EAAE0B,GAAGmD,GAAG9B,EAAE,EAAE,YAAY/C,CAAC,IAAI6E,GAAG/B,EAAE,EAAE,EAAEG,IAAIuJ,KAAKA,GAAG,GAAGxM,EAAE,UAAU,GAAGyC,KAAIf,GAAGmD,GAAG9B,EAAE,EAAE9C,EAAGD,CAAC,EAAE0B,GAAGmD,GAAG7B,EAAE,KAAK,CAAC,OAAA0J,GAAG,EAG5H7N,EAAU,KACnB,CAGA,GAAG,EACC,OAAOJ,IAAY,UAAY,OAAOC,IAAW,SACnDA,GAAO,QAAUC,GACV,OAAO,QAAW,YAAc,OAAO,KAC9C,OAAO,CAAC,EAAG,IAAMA,EAAe,IC/GlC,IAAAgO,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,0/ECAA,IAUIC,GASEC,GAMFC,GACAC,GACAC,GACAC,GAEEC,GAwBAC,GAyBAC,GAWOC,GA8GAC,GAxMbC,GAAAC,EAAA,kBAeEZ,GACmE,KAG/DC,GAE2B,KAK7BE,GAAc,GACdC,GAAe,GACfC,GAAU,GAERC,GAAyB,IAAe,CAC5C,GAAI,CAEF,OAAI,OAAO,kBAAsB,IACxB,IAKL,OAAO,eAAmB,KAC5B,IAAI,eAAe,EAAE,MAAM,YAAY,IAAI,kBAAkB,CAAC,CAAC,EAK1D,YAAY,SAAS,IAAI,WAAW,CACzC,EAAG,GAAI,IAAK,IAAK,EAAG,EAAI,EAAI,EAAG,EAAG,EAAG,EAAI,GAAI,EAAK,EAAI,EAAG,EAAG,EAAI,EAAG,EACnE,EAAG,EAAI,EAAK,EAAK,EAAG,GAAI,GAAI,EAAG,EAAG,EAAG,GAAI,EAAI,IAAK,GAAI,EAAG,EAAG,GAAI,EAClE,CAAC,CAAC,EACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,IAAe,CACrC,GAAI,CAeF,OAAO,YAAY,SAAS,IAAI,WAAW,CACzC,EAAK,GAAI,IAAK,IAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,GAAI,GAAI,EAAK,GAAK,EAAG,GAAI,EACvF,IAAK,GAAI,IAAK,GAAK,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAI,EAAI,IAAK,IAAK,EAAG,GAAI,EACzF,CAAC,CAAC,CACJ,MAAY,CACV,MAAO,EACT,CACF,EAEMC,GAAkB,CAACK,EAAkBC,IACrCD,EAIKC,EAAa,8BAAgC,qBAE7CA,EAAa,yBAA2B,gBAItCL,GAAwB,MAAMM,GAA+C,CACxF,GAAIZ,GACF,OAAO,QAAQ,QAAQ,EAEzB,GAAIC,GACF,MAAM,IAAI,MAAM,uDAAyD,EAE3E,GAAIC,GACF,MAAM,IAAI,MAAM,oDAAsD,EAGxED,GAAe,GAGf,IAAMY,EAAUD,EAAM,YAChBE,EAAaF,EAAM,WACnBG,EAAOH,EAAM,KAEbD,EAAaG,EAAa,GAAKX,GAAuB,EACtDO,EAAUK,GAAQX,GAAgB,EAElCY,EAAYJ,EAAM,UAClBK,EAAqB,OAAOD,GAAc,SAAWA,EAAY,OACjEE,EAAeb,GAAgBK,EAASC,CAAU,EAClDQ,EAAmB,OAAOH,GAAc,SAAWA,EAAUE,CAAY,EAAI,OAE/EE,EAAY,GAEVC,EAA8B,CAAC,EA6ErC,GA1EIR,EAAU,GACZQ,EAAM,KAAK,IAAI,QAASC,GAAY,CAClC,WAAW,IAAM,CACfF,EAAY,GACZE,EAAQ,CACV,EAAGT,CAAO,CACZ,CAAC,CAAC,EAIJQ,EAAM,KAAK,IAAI,QAAQ,CAACC,EAASC,IAAW,CAC1C,IAAMC,EAAUb,EAAab,GAAyBD,GAChD4B,EAAiC,CACrC,WAAY,CAACC,EAAkBC,IAA4B,CACzD,GAAuChB,GAAce,EAAS,SAAS,YAAY,GAC/E,OAAO,KAAS,IAClB,OAAO,IAAI,gBAAgB,IAAI,KAC3B,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAGhC,GAAIA,EAAS,SAAS,OAAO,EAAG,CAC9B,GAAIP,EACF,OAAOA,EAGT,IAAMS,EAASX,GAAsBU,EAGnC,OAAIT,IAAiB,qBACZU,EAAS,0BACPV,IAAiB,8BACnBU,EAAS,mCAIbA,EAASV,CAClB,CAEA,OAAOS,EAAkBD,CAC3B,CACF,EAEA,GAAuCf,EACrC,GAAI,OAAO,KAAS,IAClBc,EAAO,oBAA2B,SAAK,UAAW,sBAAsB,MACnE,CACL,IAAMI,EAAmB,uBAAuBL,EAAQ,SAAS,CAAC,IAClEC,EAAO,oBAAsB,IAAI,KAAK,CAACI,CAAgB,EAAG,CAAC,KAAM,iBAAiB,CAAC,CACrF,CAGFL,EAAQC,CAAM,EAAE,KAEZK,GAAU,CACR7B,GAAe,GACfD,GAAc,GACdD,GAAO+B,EACPR,EAAQ,CACV,EAECS,GAAS,CACR9B,GAAe,GACfC,GAAU,GACVqB,EAAOQ,CAAI,CACb,CAAC,CACP,CAAC,CAAC,EAEF,MAAM,QAAQ,KAAKV,CAAK,EAEpBD,EACF,MAAM,IAAI,MAAM,2DAA2DP,CAAO,IAAI,CAE1F,EAEaN,GAAc,IAAqB,CAC9C,GAAIP,IAAeD,GACjB,OAAOA,GAGT,MAAM,IAAI,MAAM,qCAAqC,CACvD,IC9MA,IAKaiC,GAeAC,GA6BAC,GAjDbC,GAAAC,EAAA,kBAGAC,KAEaL,GAAkB,CAACM,EAAcC,IAA6B,CACzE,IAAMC,EAAOC,GAAY,EAEnBC,EAAaF,EAAK,gBAAgBF,CAAI,EAAI,EAC1CK,EAAaH,EAAK,QAAQE,CAAU,EAC1C,OAAAF,EAAK,aAAaF,EAAMK,EAAYD,CAAU,EAC9CH,EAAO,KAAKI,CAAU,EAEfA,CACT,EAMaV,GACT,CAACW,EAAkCC,EAAgBC,EAClDC,IAAuC,CACtC,GAAI,OAAOH,GAAW,UAAYA,IAAY,KAAM,CAClD,GAAIE,EAAK,IAAIF,CAAO,EAClB,MAAM,IAAI,MAAM,+BAA+B,EAE/CE,EAAK,IAAIF,CAAO,CAEpB,CAEA,OAAO,QAAQA,CAAO,EAAE,QAAQ,CAAC,CAACI,EAAKC,CAAK,IAAM,CAChD,IAAMC,EAAQL,EAAUA,EAASG,EAAMA,EACvC,GAAI,OAAOC,GAAU,SACnBhB,GAAoBgB,EAAkCC,EAAO,IAAKJ,EAAMC,CAAO,UACtE,OAAOE,GAAU,UAAY,OAAOA,GAAU,SACvDF,EAAQG,EAAMD,EAAM,SAAS,CAAC,UACrB,OAAOA,GAAU,UAC1BF,EAAQG,EAAOD,EAAS,IAAM,GAAG,MAEjC,OAAM,IAAI,MAAM,mCAAmC,OAAOA,CAAK,EAAE,CAErE,CAAC,CACH,EAMSf,GAAkBiB,GAA0B,CACvD,IAAMX,EAAOC,GAAY,EAEnBW,EAAQZ,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMa,EAAeb,EAAK,WAAW,CAAC,EACtCA,EAAK,iBAAiBa,EAAcA,EAAe,CAAC,EACpD,IAAMC,EAAYd,EAAK,OAAOa,EAAe,CAAC,EACxCE,EAAsBf,EAAK,QAAQa,EAAe,EAAI,CAAC,EACvDG,EAAeD,EAAsBf,EAAK,aAAae,CAAmB,EAAI,GACpF,MAAM,IAAI,MAAM,GAAGJ,CAAO,gBAAgBG,CAAS,oBAAoBE,CAAY,EAAE,CACvF,QAAE,CACAhB,EAAK,aAAaY,CAAK,CACzB,CACF,IC/DA,IAQaK,GARbC,GAAAC,EAAA,kBAKAC,KACAC,KAEaJ,GAAiBK,GAA6D,CACzF,IAAMC,EAAOC,GAAY,EACrBC,EAAmB,EACjBC,EAAmB,CAAC,EAEpBC,EAA0CL,GAAW,CAAC,EAE5D,GAAI,CACF,GAAIA,GAAS,mBAAqB,OAChCK,EAAW,iBAAmB,UAE5B,OAAOL,EAAQ,kBAAqB,UAAY,CAAC,OAAO,UAAUA,EAAQ,gBAAgB,GAC1FA,EAAQ,iBAAmB,GAAKA,EAAQ,iBAAmB,EAC7D,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,gBAAgB,EAAE,EAGjF,GAAIA,GAAS,oBAAsB,OACjCK,EAAW,kBAAoB,UACtB,OAAOL,EAAQ,mBAAsB,UAAY,CAAC,OAAO,UAAUA,EAAQ,iBAAiB,EACrG,MAAM,IAAI,MAAM,qCAAqCA,EAAQ,iBAAiB,EAAE,EAG9EA,GAAS,YAAc,SACzBK,EAAW,UAAY,IAGzB,IAAIC,EAAgB,EACpB,OAAIN,GAAS,MAAQ,SACnBM,EAAgBC,GAAgBP,EAAQ,IAAKI,CAAM,GAGrDD,EAAmBF,EAAK,qBACpBI,EAAW,iBAAmBA,EAAW,kBAAoB,CAAC,CAACA,EAAW,UAAYC,CAAa,EACnGH,IAAqB,GACvBK,GAAe,2BAA4B,EAGzCR,GAAS,QAAU,QACrBS,GAAoBT,EAAQ,MAAO,GAAI,IAAI,QAAoC,CAACU,EAAKC,IAAU,CAC7F,IAAMC,EAAgBL,GAAgBG,EAAKN,CAAM,EAC3CS,EAAkBN,GAAgBI,EAAOP,CAAM,EAEjDH,EAAK,sBAAsBE,EAAkBS,EAAeC,CAAe,IAAM,GACnFL,GAAe,iCAAiCE,CAAG,MAAMC,CAAK,GAAG,CAErE,CAAC,EAGI,CAACR,EAAkBC,CAAM,CAClC,OAASU,EAAG,CACV,MAAIX,IAAqB,GACvBF,EAAK,sBAAsBE,CAAgB,EAE7CC,EAAO,QAAQW,GAASd,EAAK,MAAMc,CAAK,CAAC,EACnCD,CACR,CACF,IChEA,IAQME,GAeAC,GAWAC,GAoBAC,GA+EOC,GArIbC,GAAAC,EAAA,kBAKAC,KACAC,KAEMR,GAA4BS,GAAmD,CACnF,OAAQA,EAAwB,CAC9B,IAAK,WACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,IAAK,MACH,MAAO,IACT,QACE,MAAM,IAAI,MAAM,yCAAyCA,CAAsB,EAAE,CACrF,CACF,EAEMR,GAAoBS,GAAmD,CAC3E,OAAQA,EAAe,CACrB,IAAK,aACH,MAAO,GACT,IAAK,WACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,+BAA+BA,CAAa,EAAE,CAClE,CACF,EAEMR,GAAwBS,GAAmD,CAC1EA,EAAQ,QACXA,EAAQ,MAAQ,CAAC,GAEdA,EAAQ,MAAM,UACjBA,EAAQ,MAAM,QAAU,CAAC,GAE3B,IAAMC,EAAUD,EAAQ,MAAM,QACzBC,EAAQ,+BAEXA,EAAQ,6BAA+B,KAIrCD,EAAQ,oBACRA,EAAQ,mBAAmB,KAAKE,IAAO,OAAOA,GAAO,SAAWA,EAAKA,EAAG,QAAU,QAAQ,IAC5FF,EAAQ,iBAAmB,GAE/B,EAEMR,GACF,CAACW,EAA8BC,EAC9BC,IAA2B,CAC1B,QAAWH,KAAME,EAAoB,CACnC,IAAIE,EAAS,OAAOJ,GAAO,SAAWA,EAAKA,EAAG,KAG9C,OAAQI,EAAQ,CACd,IAAK,UACHA,EAAS,UACT,MACF,IAAK,QAEH,GADAA,EAAS,QACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMK,EAAeL,EACrB,GAAIK,GAAc,WAAY,CAC5B,IAAMC,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBF,EAAa,WAAYF,CAAM,EACnEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,WAAY,CAC5B,IAAIM,EAAaN,EAAa,YAE1B,OAAOM,GAAc,UAAY,CAAC,OAAO,UAAUA,CAAU,GAAKA,EAAa,KACjFA,EAAa,GAEf,IAAML,EAAgBC,GAAgB,aAAcJ,CAAM,EACpDK,EAAkBD,GAAgBI,EAAW,SAAS,EAAGR,CAAM,EACjEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GAAe,oDAAoDL,EAAa,UAAU,GAAG,CAEjG,CACA,GAAIA,GAAc,gBAAiB,CACjC,IAAMC,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBF,EAAa,gBAAiBF,CAAM,EACxEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDL,EAAa,eAAe,GAAG,CAEhG,CACF,CACA,MACF,IAAK,SAEH,GADAD,EAAS,KACL,OAAOJ,GAAO,SAAU,CAC1B,IAAMY,EAAgBZ,EACtB,GAAIY,GAAe,gBAAiB,CAClC,GAAIA,EAAc,kBAAoB,QAAUA,EAAc,kBAAoB,OAChF,MAAM,IAAI,MAAM,oDAAoDA,EAAc,eAAe,EAAE,EAErG,IAAMN,EAAgBC,GAAgB,kBAAmBJ,CAAM,EACzDK,EAAkBD,GAAgBK,EAAc,gBAAiBT,CAAM,EACzEM,GAAY,EAAE,0BAA0BR,EAAsBK,EAAeE,CAAe,IAC5F,GACFE,GACI,yDAAyDE,EAAc,eAAe,GAAG,CAEjG,CACF,CACA,MACF,IAAK,OACL,IAAK,MACH,SACF,QACE,MAAM,IAAI,MAAM,qCAAqCR,CAAM,EAAE,CACjE,CAEA,IAAMS,EAAmBN,GAAgBH,EAAQD,CAAM,EACnDM,GAAY,EAAE,4BAA4BR,EAAsBY,CAAgB,IAAM,GACxFH,GAAe,oCAAoCN,CAAM,GAAG,CAEhE,CACF,EAESb,GAAqBO,GAAkE,CAClG,IAAMgB,EAAOL,GAAY,EACrBR,EAAuB,EACrBE,EAAmB,CAAC,EAEpBY,EAAkDjB,GAAW,CAAC,EACpET,GAAqB0B,CAAc,EAEnC,GAAI,CACF,IAAMnB,EAAyBT,GAAyB4B,EAAe,wBAA0B,KAAK,EAChGlB,EAAgBT,GAAiB2B,EAAe,eAAiB,YAAY,EAC7EC,EACF,OAAOD,EAAe,OAAU,SAAWR,GAAgBQ,EAAe,MAAOZ,CAAM,EAAI,EAEzFc,EAAmBF,EAAe,kBAAoB,EAC5D,GAAI,CAAC,OAAO,UAAUE,CAAgB,GAAKA,EAAmB,GAAKA,EAAmB,EACpF,MAAM,IAAI,MAAM,qCAAqCA,CAAgB,EAAE,EAGzE,IAAMC,EAAoBH,EAAe,mBAAqB,EAC9D,GAAI,CAAC,OAAO,UAAUG,CAAiB,GAAKA,EAAoB,GAAKA,EAAoB,EACvF,MAAM,IAAI,MAAM,qCAAqCA,CAAiB,EAAE,EAG1E,IAAMC,EAA+B,OAAOJ,EAAe,wBAA2B,SAClFR,GAAgBQ,EAAe,uBAAwBZ,CAAM,EAC7D,EAcJ,GAZAF,EAAuBa,EAAK,yBACxBlB,EAAwB,CAAC,CAACmB,EAAe,kBAAmB,CAAC,CAACA,EAAe,iBAAkBlB,EAC/F,CAAC,CAACkB,EAAe,gBAAiB,EAAGC,EAAiBC,EAAkBC,EACxEC,CAA4B,EAC5BlB,IAAyB,GAC3BS,GAAe,+BAAgC,EAG7CK,EAAe,oBACjBzB,GAAsBW,EAAsBc,EAAe,mBAAoBZ,CAAM,EAGnFY,EAAe,uBACjB,OAAW,CAACK,EAAMC,CAAK,IAAK,OAAO,QAAQN,EAAe,sBAAsB,EAAG,CACjF,GAAI,OAAOK,GAAS,SAClB,MAAM,IAAI,MAAM,kDAAkDA,CAAI,EAAE,EAE1E,GAAI,OAAOC,GAAU,UAAY,CAAC,OAAO,UAAUA,CAAK,GAAKA,EAAQ,EACnE,MAAM,IAAI,MAAM,iEAAiEA,CAAK,EAAE,EAE1F,IAAMC,EAAaf,GAAgBa,EAAMjB,CAAM,EAC3CW,EAAK,6BAA6Bb,EAAsBqB,EAAYD,CAAK,IAAM,GACjFX,GAAe,wCAAwCU,CAAI,MAAMC,CAAK,GAAG,CAE7E,CAGF,OAAIN,EAAe,QAAU,QAC3BQ,GAAoBR,EAAe,MAAO,GAAI,IAAI,QAAoC,CAACS,EAAKH,IAAU,CACpG,IAAMf,EAAgBC,GAAgBiB,EAAKrB,CAAM,EAC3CK,EAAkBD,GAAgBc,EAAOlB,CAAM,EAEjDW,EAAK,0BAA0Bb,EAAsBK,EAAeE,CAAe,IAAM,GAC3FE,GAAe,qCAAqCc,CAAG,MAAMH,CAAK,GAAG,CAEzE,CAAC,EAGI,CAACpB,EAAsBE,CAAM,CACtC,OAASsB,EAAG,CACV,MAAIxB,IAAyB,GAC3Ba,EAAK,0BAA0Bb,CAAoB,EAErDE,EAAO,QAAQuB,GAASZ,EAAK,MAAMY,CAAK,CAAC,EACnCD,CACR,CACF,IC/MA,IAiCaE,GAqCAC,GAsCAC,GAMAC,GAoCAC,GAoBAC,GAMAC,GAhLbC,GAAAC,EAAA,kBAiCaR,GAA8BS,GAA2B,CACpE,OAAQA,EAAM,CACZ,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IACT,IAAK,UACH,MAAO,IACT,IAAK,UACH,MAAO,GACT,IAAK,UACH,MAAO,IACT,IAAK,SACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,SACH,MAAO,IAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,CACpD,CACF,EAKaR,GAA8BS,GAAqC,CAC9E,OAAQA,EAAW,CACjB,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,OACT,IAAK,GACH,MAAO,QACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,UACT,IAAK,IACH,MAAO,UACT,IAAK,GACH,MAAO,SACT,IAAK,GACH,MAAO,QACT,IAAK,IACH,MAAO,SAET,QACE,MAAM,IAAI,MAAM,0BAA0BA,CAAS,EAAE,CACzD,CACF,EAMaR,GAAwBS,GACpB,CAAC,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,EAAG,EAAG,EAAG,EAAG,EAAG,OAAW,OAAW,MAAS,EAAEA,CAAQ,EAKxGR,GAAqCM,GAEoD,CAChG,OAAQA,EAAM,CACZ,IAAK,UACH,OAAO,YACT,IAAK,UACH,OAAO,aACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,UACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,WACT,IAAK,QACH,OAAO,WACT,IAAK,OACH,OAAO,WACT,IAAK,UACH,OAAO,aACT,IAAK,SACH,OAAO,YACT,IAAK,QACH,OAAO,cACT,IAAK,SACH,OAAO,eACT,QACE,MAAM,IAAI,MAAM,qBAAqBA,CAAI,EAAE,CAC/C,CACF,EAKSL,GAAwBQ,GAAkE,CACrG,OAAQA,EAAU,CAChB,IAAK,UACH,MAAO,GACT,IAAK,OACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,IAAK,QACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,EAKaP,GAA4BI,GAAyDA,IAAS,WACvGA,IAAS,SAAWA,IAAS,SAAWA,IAAS,QAAUA,IAAS,WAAaA,IAAS,SAKjFH,GAA4BO,GAA0C,CACjF,OAAQA,EAAU,CAChB,IAAK,OACH,MAAO,GACT,IAAK,MACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,IAAK,UACH,MAAO,GACT,IAAK,aACH,MAAO,GACT,QACE,MAAM,IAAI,MAAM,8BAA8BA,CAAQ,EAAE,CAC5D,CACF,IC/LA,IAYMC,GAEAC,GAKFC,GACAC,GAESC,GAQAC,GAWAC,GAzCbC,GAAAC,EAAA,kBAKAC,KAOMT,GAAiB,CAAC,IAAK,IAAK,IAAK,IAAK,GAAG,EAEzCC,GAAQ,CAACS,EAAeC,IAA0B,CAEtD,QAAQ,IAAI,IAAIX,GAAeU,CAAK,CAAC,IAAI,IAAI,KAAK,EAAE,YAAY,CAAC,IAAIC,CAAO,EAAE,CAChF,EAKaP,GAAkB,CAACQ,EAA2BC,IAA0B,CACnFX,GAAiBU,EACjBT,GAAQU,CACV,EAKaR,GAAM,CAACS,EAAoBC,IAAuB,CAC7D,IAAMC,EAAeC,GAAqBH,CAAQ,EAC5CI,EAAcD,GAAqBf,EAAc,EACnDc,GAAgBE,GAClBjB,GAAMe,EAAc,OAAOD,GAAQ,WAAaA,EAAI,EAAIA,CAAG,CAE/D,EAKaT,GAAwB,IAAIa,IAAiC,CACpEhB,IACFE,GAAI,GAAGc,CAAI,CAEf,IC7CA,IAOaC,GAPbC,GAAAC,EAAA,kBAKAC,KAEaH,GAAa,CAACI,EAAyBC,IAE5C,IAAKC,GAAkCD,CAAI,GAAGD,CAAU,ICThE,IAAAG,GAAAC,EAAA,oBCAA,IA2EMC,GAEFC,GACEC,GAYOC,GAkCPC,GAoOOC,GAhWbC,GAAAC,EAAA,kBAIAC,KAEAC,KAqEMT,GAA4BU,GAAiB,KAAK,KAAKA,EAAO,EAAE,EAAI,GAEtET,GAAO,EACLC,GAAqB,IAAMD,KAYpBE,GACT,MAAMQ,EAAwBC,EAAsBC,EAAsBC,IAC/C,CACrB,IAAMC,EAAaf,GAAyBa,CAAY,EAClDG,EAAgBL,EAAQ,OAAO,aAEjC,CAAC,KAAMI,EAAY,MAAO,eAAe,SAAW,eAAe,QAAQ,CAAC,EAChF,GAAI,CACF,IAAME,EAAiBN,EAAQ,kBAAkB,EACjDA,EAAQ,eAAe,EACvBM,EAAe,mBACXL,EAA+B,EAAuBI,EACtD,EAA4BD,CAChC,EACAJ,EAAQ,MAAM,EAEd,MAAMK,EAAc,SAAS,WAAW,IAAI,EAE5C,IAAME,EAAcF,EAAc,eAAe,EACjD,GAAIF,EAAiB,CAEnB,IAAMK,EAAeL,EAAgB,EACrC,OAAAK,EAAa,IAAI,IAAI,WAAWD,EAAa,EAAGL,CAAY,CAAC,EACtDM,CACT,KAGE,QAAO,IAAI,WAAWD,EAAY,MAAM,EAAGL,CAAY,CAAC,CAE5D,QAAE,CACAG,EAAc,QAAQ,CACxB,CACF,EAEFZ,GAAN,KAAmD,CAiBjD,YAAoBO,EAAwB,CAAxB,aAAAA,EAClB,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,IAC9B,KAAK,2BAA6B,CAAC,EACnC,KAAK,eAAiB,CAAC,EACvB,KAAK,gBAAkB,IAAI,GAC7B,CAEA,OAAOS,EAAeC,EAAwB,CAC5C,IAAMC,EAAiBD,EAAK,OACtBE,EAAYF,EAAK,WACjBG,EAAYH,EAAK,WACjBX,EAAOV,GAAyBwB,CAAS,EAGzCC,EAAe,KAAK,aAAa,IAAIL,CAAE,EAC7C,GAAI,CAACK,EACH,MAAM,IAAI,MAAM,uCAAuC,EAEzD,GAAIA,EAAa,eAAiBD,EAChC,MAAM,IAAI,MAAM,yCAAyCC,EAAa,YAAY,eAAeD,CAAS,EAAE,EAI9G,IAAME,EAAwB,KAAK,QAAQ,OAAO,aAE9C,CAAC,iBAAkB,GAAM,KAAAhB,EAAM,MAAO,eAAe,UAAY,eAAe,QAAQ,CAAC,EAGvFQ,EAAcQ,EAAsB,eAAe,EACzD,IAAI,WAAWR,CAAW,EAAE,IAAI,IAAI,WAAWI,EAAgBC,EAAWC,CAAS,CAAC,EACpFE,EAAsB,MAAM,EAI5B,IAAMT,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBAAmBS,EAAuB,EAAGD,EAAa,QAAQ,OAAQ,EAAGf,CAAI,EAEhGiB,GAAU,UAAW,IAAM,qCAAqCP,CAAE,GAAG,EAErE,KAAK,2BAA2B,KAAKM,CAAqB,CAC5D,CAEA,OAAOE,EAAqBC,EAAgC,CAE1D,IAAMC,EAAqB,KAAK,aAAa,IAAIF,CAAQ,EACzD,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,IAAMC,EAA0B,KAAK,aAAa,IAAIF,CAAa,EACnE,GAAI,CAACE,EACH,MAAM,IAAI,MAAM,gDAAgD,EAElE,GAAID,EAAmB,eAAiBC,EAAwB,aAC9D,MAAM,IAAI,MAAM,mDAAmD,EAErE,IAAMrB,EAAOV,GAAyB8B,EAAmB,YAAY,EAG/Db,EAAiB,KAAK,QAAQ,kBAAkB,EACtD,KAAK,QAAQ,eAAe,EAC5BA,EAAe,mBACXa,EAAmB,QAAQ,OAAQ,EAAGC,EAAwB,QAAQ,OAAQ,EAAGrB,CAAI,CAC3F,CAEA,uBAAuBsB,EAAmBnB,EAAsBoB,EAAoC,CAClG,IAAIb,EACJ,GAAIa,EAAgB,CAElB,GADAb,EAAK,KAAK,gBAAgB,IAAIa,CAAc,EACxCb,IAAO,OACT,MAAM,IAAI,MAAM,mCAAmC,EAErD,GAAIY,IAAWC,EACb,OAAAN,GACI,UACA,IAAM,uDAAuDd,CAAY,WACrEO,CAAE,6BAA6B,EAChCA,EAET,KAAK,gBAAgB,OAAOa,CAAc,CAC5C,MACEb,EAAKlB,GAAmB,EAG1B,YAAK,aAAa,IAAIkB,EAAI,CAAC,QAAS,CAAC,GAAAA,EAAI,OAA2B,OAAAY,CAAM,EAAG,aAAAnB,CAAY,CAAC,EAC1F,KAAK,gBAAgB,IAAImB,EAAQZ,CAAE,EACnCO,GACI,UACA,IAAM,uDAAuDd,CAAY,WAAWO,CAAE,eAAe,EAClGA,CACT,CAEA,yBAAyBY,EAAyB,CAChD,IAAMZ,EAAK,KAAK,gBAAgB,IAAIY,CAAM,EACtCZ,IAAO,SACT,KAAK,aAAa,OAAOA,CAAE,EAC3B,KAAK,gBAAgB,OAAOY,CAAM,EAClCL,GAAU,UAAW,IAAM,4DAA4DP,CAAE,EAAE,EAE/F,CAGA,OAAOV,EAAcwB,EAAQ,eAAe,QAAU,eAAe,SAAW,eAAe,SAAmB,CAChH,IAAMnB,EAAaf,GAAyBU,CAAI,EAE5CE,EAGEuB,GAAaD,EAAQ,eAAe,WAAa,eAAe,QAEhEE,GAAaF,EAAQ,eAAe,WAAa,eAAe,QACtE,GAAIC,GAAaC,EAAW,CAC1B,IAAMC,EAAcF,EAAY,KAAK,YAAc,KAAK,mBACpDG,EAAUD,EAAY,IAAItB,CAAU,EACnCuB,IACHA,EAAU,CAAC,EACXD,EAAY,IAAItB,EAAYuB,CAAO,GAEjCA,EAAQ,OAAS,EACnB1B,EAAY0B,EAAQ,IAAI,EAGxB1B,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,CAE1E,MAEEtB,EAAY,KAAK,QAAQ,OAAO,aAAa,CAAC,KAAMG,EAAY,MAAAmB,CAAK,CAAC,EAGxE,IAAMK,EAAU,CAAC,GAAIrC,GAAmB,EAAG,OAA2B,OAAQU,CAAS,EACvF,YAAK,aAAa,IAAI2B,EAAQ,GAAI,CAAC,QAAAA,EAAS,aAAc7B,CAAI,CAAC,EAE/DiB,GAAU,UAAW,IAAM,uCAAuCjB,CAAI,WAAW6B,EAAQ,EAAE,EAAE,EACtFA,CACT,CAEA,IAAInB,EAAkC,CACpC,OAAO,KAAK,aAAa,IAAIA,CAAE,GAAG,OACpC,CAEA,QAAQA,EAAuB,CAC7B,IAAMoB,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,+BAA+B,EAGjD,OAAAb,GAAU,UAAW,IAAM,sCAAsCP,CAAE,gBAAgBoB,EAAW,QAAQ,EAAE,EAAE,EAE1G,KAAK,aAAa,OAAOpB,CAAE,EAC3B,KAAK,eAAe,KAAKoB,EAAW,QAAQ,MAAM,EAG3CA,EAAW,YACpB,CAEA,MAAM,SAASpB,EAAeN,EAAkD,CAC9E,IAAM0B,EAAa,KAAK,aAAa,IAAIpB,CAAE,EAC3C,GAAI,CAACoB,EACH,MAAM,IAAI,MAAM,qBAAqB,EAGvC,MAAMrC,GAAgB,KAAK,QAASqC,EAAW,QAAQ,OAAQA,EAAW,aAAc1B,CAAe,CACzG,CAEA,uBAA8B,CAC5B,QAAWkB,KAAU,KAAK,2BAExBA,EAAO,QAAQ,EAEjB,KAAK,2BAA6B,CAAC,EACnC,QAAWA,KAAU,KAAK,gBAEnBA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAE7D,KAAK,YAAY,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,GAEpCA,EAAO,MAAQ,eAAe,WAAa,eAAe,QAEpE,KAAK,mBAAmB,IAAIA,EAAO,IAAI,EAAG,KAAKA,CAAM,EAErDA,EAAO,QAAQ,EAGnB,KAAK,eAAiB,CAAC,CACzB,CAEA,SAAU,CACR,KAAK,YAAY,QAASM,GAAY,CACpCA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EACD,KAAK,mBAAmB,QAASM,GAAY,CAC3CA,EAAQ,QAAQN,GAAU,CACxBA,EAAO,QAAQ,CACjB,CAAC,CACH,CAAC,EAED,KAAK,aAAa,QAASS,GAAY,CACrCA,EAAQ,QAAQ,OAAO,QAAQ,CACjC,CAAC,EAED,KAAK,aAAe,IAAI,IACxB,KAAK,YAAc,IAAI,IACvB,KAAK,mBAAqB,IAAI,GAChC,CACF,EAEapC,GAAuB,IAAIqC,IACpC,IAAItC,GAAmB,GAAGsC,CAAI,ICjWlC,IAGMC,GAsBOC,GAzBbC,GAAAC,EAAA,kBAGMH,GAAN,KAAgC,CAC9B,YAAYI,EAAoC,CAC9C,OAAO,OAAO,KAAMA,CAAS,CAC/B,CAGA,IAAW,UAAmB,CAC5B,OAAK,KAAK,YACR,KAAK,UACD,OAAO,oBAAoB,IAAI,EAAE,KAAK,EAAE,IAAIC,GAAQ,GAAI,KAAiCA,CAAI,CAAC,EAAE,EAAE,KAAK,GAAG,GAEzG,KAAK,SACd,CACF,EASaJ,GAAkEG,GAC3E,IAAIJ,GAA0BI,CAAS,IC1B3C,IAKaE,GAaAC,GAoEAC,EAiHAC,GA0MAC,GAkDAC,GACAC,GApcbC,GAAAC,EAAA,kBAKaR,GAAN,KAAiB,CAOtB,OAAO,gBAAgBS,EAAqBC,EAAiD,CAC3F,OAAQD,EAAE,CAAC,IAAMC,EAAE,CAAC,EAAK,OAAY,CAACD,EAAE,CAAC,EAAGC,EAAE,CAAC,CAAC,CAClD,CACF,EAGaT,GAAN,KAAoB,CAQzB,OAAO,UAAUU,EAA0BC,EAA0BC,EAAW,GAAoC,CAClH,IAAMC,EAAQH,EAAM,OACdI,EAAQH,EAAM,OACpB,GAAIE,IAAU,EACZ,OAAOF,EAET,GAAIG,IAAU,EACZ,OAAOJ,EAET,IAAMK,EAAQ,KAAK,IAAIL,EAAM,OAAQC,EAAM,MAAM,EAC3CK,EAAQ,IAAI,MAAcD,CAAK,EAGrC,GAAIH,EAAU,CACZ,GAAIC,EAAQ,GAAKC,EAAQ,EACvB,OAEF,IAAMG,EACFlB,GAAW,gBAAgB,CAACW,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,EAAG,CAACF,EAAMG,EAAQ,CAAC,EAAGH,EAAMG,EAAQ,CAAC,CAAC,CAAC,EACzG,GAAIG,IAAiB,OACnB,OAEF,CAACD,EAAMD,EAAQ,CAAC,EAAGC,EAAMD,EAAQ,CAAC,CAAC,EAAIE,CACzC,CAEA,QAASC,EAAIN,EAAW,EAAI,EAAGM,GAAKH,EAAOG,IAAK,CAC9C,IAAMC,EAAON,EAAQK,EAAI,EAAI,EAAIR,EAAMG,EAAQK,CAAC,EAC1CE,EAAON,EAAQI,EAAI,EAAI,EAAIP,EAAMG,EAAQI,CAAC,EAEhD,GAAIC,IAASC,GAAQD,EAAO,GAAKC,EAAO,EACtC,OAEFJ,EAAMD,EAAQG,CAAC,EAAI,KAAK,IAAIC,EAAMC,CAAI,CACxC,CAEA,OAAOJ,CACT,CAOA,OAAO,iBAAiBK,EAA0BC,EAAwC,CAExF,IAAMC,EAAYF,EAAM,OAClBG,EAAYF,EAAW,OAC7B,GAAIC,EAAYC,EACd,MAAO,GAET,QAASN,EAAI,EAAGA,GAAKK,EAAWL,IAC9B,GAAIG,EAAME,EAAYL,CAAC,IAAM,GAAKG,EAAME,EAAYL,CAAC,IAAMI,EAAWE,EAAYN,CAAC,EACjF,MAAO,GAGX,MAAO,EACT,CACF,EAGajB,EAAN,MAAMwB,CAAU,CAIrB,OAAO,KAAKC,EAAiC,CAC3C,OAAOD,EAAU,0BAA0BC,EAAM,EAAGA,EAAK,MAAM,CACjE,CAKA,OAAO,kBAAkBA,EAAyBC,EAAsB,CACtE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,wCAAwCD,EAAK,MAAM,cAAc,EAE/G,OAAOD,EAAU,0BAA0BC,EAAMC,EAAMD,EAAK,MAAM,CACpE,CAKA,OAAO,gBAAgBA,EAAyBC,EAAsB,CACpE,GAAIA,EAAO,GAAKA,EAAOD,EAAK,OAC1B,MAAM,IAAI,MAAM,wBAAwBC,CAAI,sCAAsCD,EAAK,MAAM,cAAc,EAE7G,OAAOD,EAAU,0BAA0BC,EAAM,EAAGC,CAAI,CAC1D,CAKA,OAAO,0BAA0BD,EAAyBE,EAAeC,EAAqB,CAC5F,IAAIC,EAAO,EACX,QAASZ,EAAIU,EAAOV,EAAIW,EAAKX,IAAK,CAGhC,GAAIQ,EAAKR,CAAC,EAAI,EACZ,MAAM,IAAI,MAEN,+GAA+G,EAErHY,GAAQJ,EAAKR,CAAC,CAChB,CACA,OAAOY,CACT,CAEA,OAAO,eAAeJ,EAA4C,CAChE,IAAMK,EAAOL,EAAK,OAClB,GAAIK,IAAS,EACX,MAAO,CAAC,EACH,GAAIA,IAAS,EAClB,MAAO,CAAC,CAAC,EAEX,IAAMC,EAAU,IAAI,MAAMD,CAAI,EAC9BC,EAAQD,EAAO,CAAC,EAAI,EACpBC,EAAQD,EAAO,CAAC,EAAIL,EAAKK,EAAO,CAAC,EACjC,QAASb,EAAIa,EAAO,EAAGb,GAAK,EAAG,EAAEA,EAC/Bc,EAAQd,CAAC,EAAIc,EAAQd,EAAI,CAAC,EAAIQ,EAAKR,EAAI,CAAC,EAE1C,OAAOc,CACT,CAKA,OAAO,cAAcL,EAAcM,EAA4B,CAC7D,GAAIN,EAAO,CAACM,GAAcN,GAAQM,EAChC,MAAM,IAAI,MAAM,sCAAsC,EAExD,OAAON,EAAO,EAAIA,EAAOM,EAAaN,CACxC,CAEA,OAAO,cAAcO,EAAyBD,EAA+B,CAC3E,OAAOC,EAAK,IAAIC,GAAK,KAAK,cAAcA,EAAGF,GAAcC,EAAK,MAAM,CAAC,CACvE,CAQA,OAAO,gBAAgB1B,EAAsB4B,EAA6C,CACxF,OAAIA,EACKA,EAAK,IAAKC,GAAM7B,EAAE6B,CAAC,CAAC,EAEpB7B,EAAE,MAAM,EAAE,QAAQ,CAE7B,CAOA,OAAO,SAASkB,EAAyBY,EAA2C,CAClF,IAAMP,EAAOL,EAAK,OAClB,OAAOA,EAAK,IAAI,CAACW,EAAGnB,IAAMmB,EAAIC,EAAIpB,CAAC,EAAIoB,EAAIpB,EAAIa,CAAI,CAAC,CACtD,CAOA,OAAO,SAASQ,EAA2BC,EAAoC,CAC7E,OAAID,EAAO,SAAWC,EAAO,OACpB,GAEFD,EAAO,MAAM,CAACF,EAAGnB,IAAMmB,IAAMG,EAAOtB,CAAC,CAAC,CAC/C,CACF,EAEahB,GAAN,MAAMuC,CAAa,CAUxB,OAAO,qBACHC,EAA2BC,EAA8BC,EAAuBZ,EAChFa,EAAqBC,EAAsB,CAC7C,GAAI,CAACJ,GAAoBE,EAAY,SAAWD,EAAU,OAAS,EACjE,MAAM,IAAI,MAAM,oFAAoF,EAGtG,GAAID,EAEF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IACxCA,GAAOH,EAAY,OACrBA,EAAY,KAAKD,EAAUI,EAAM,CAAC,CAAC,EAEnCH,EAAYG,CAAG,EAAIJ,EAAUI,EAAM,CAAC,EAM1C,QAASA,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMf,EAAQ,QAChB,GAAIA,EAAQe,CAAG,EAAI,EACjB,MAAM,IAAI,MAAM,8CAA8C,OAGhEf,EAAQ,KAAK,CAAC,EAKlB,QAASe,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAC1C,GAAIA,EAAMF,EAAU,QAClB,GAAIA,EAAUE,CAAG,EAAI,EACnB,MAAM,IAAI,MAAM,gDAAgD,OAGlEF,EAAU,KAAK,CAAC,EAKpB,QAASE,EAAM,EAAGA,EAAMH,EAAY,OAAS,EAAGG,IAC9C,GAAIA,EAAMD,EAAK,QACb,GAAIA,EAAKC,CAAG,EAAI,EACd,MAAM,IAAI,MAAM,0CAA0C,OAG5DD,EAAK,KAAK,CAAC,EAKf,QAASC,EAAM,EAAGA,EAAMH,EAAY,OAAQG,IAAO,CACjD,GAAIH,EAAYG,CAAG,GAAK,EACtB,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAID,EAAKC,CAAG,GAAKH,EAAYG,CAAG,GAAKD,EAAKC,EAAMH,EAAY,MAAM,GAAKA,EAAYG,CAAG,EACpF,MAAM,IAAI,MAAM,oCAAoC,CAExD,CACF,CAGA,OAAO,yBACHJ,EAA8BX,EAA4Ba,EAC1DD,EAAgCE,EAAgBE,EAAwBC,EAAwB,CAClG,GAAKA,EAIL,IAAIH,EAAK,SAAW,GAAKH,EAAU,OAAS,GAC1C,MAAM,IAAI,MAAM,8DAA8D,EAGhF,GAAIX,EAAQ,SAAYW,EAAU,OAAS,EACzC,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIC,EAAY,SAAYD,EAAU,OAAS,EAC7C,MAAM,IAAI,MAAM,iEAAiE,EAGnF,QAASI,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CN,EAAa,wBACTE,EAAUI,GAAOC,EAAgB,EAAI,EAAE,EAAGhB,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAChGA,EAAMJ,EAAU,OAAS,EAAGM,CAAO,EAE3C,CAaA,OAAO,uBACHP,EAA2BC,EAA8BX,EAAmBa,EAC5ED,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,EACtB,MAAM,IAAI,MAAM,4CAA4C,EAI9D,IAAMO,EAAa,CAACP,EAAU,CAAC,EAAGA,EAAU,CAAC,CAAC,EAE9C,OAAAF,EAAa,mBACTC,EAAkBC,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACpFC,CACT,CAYA,OAAO,uBACHP,EAA8BQ,EAA+BnB,EAAmBa,EAChFD,EAAuBE,EAAgBG,EAA4B,CACrE,GAAIN,EAAU,QAAU,GAAKQ,EAAW,QAAU,EAChD,MAAM,IAAI,MAAM,yDAAyD,EAI3E,IAAMD,EAAa,CAACP,EAAU,CAAC,EAAGQ,EAAW,CAAC,CAAC,EAE/C,OAAAV,EAAa,mBAAmB,GAAOE,EAAWO,EAAYlB,EAASa,EAAWD,EAAaE,EAAMG,CAAO,EACrGC,CACT,CAKA,OAAe,mBACXR,EAA2BC,EAA8BO,EAAsBlB,EAC/Ea,EAA8BD,EAAgCE,EAAgBG,EAAkB,CAClG,GAAIP,EACF,QAASK,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAK,CAAC,MAGnB,SAASH,EAAM,EAAGA,EAAMJ,EAAU,OAAS,EAAGI,IAC5CG,EAAW,KAAKT,EAAa,wBACzBE,EAAUI,EAAM,CAAC,EAAGf,EAAQe,CAAG,EAAGF,EAAUE,CAAG,EAAGH,EAAYG,CAAG,EAAGD,EAAMC,EAAKA,EAAMJ,EAAU,OAAS,EACxGM,CAAO,CAAC,CAGlB,CAIA,OAAe,wBACXG,EAAgBC,EAAgBC,EAAkBC,EAAgBT,EAAgBU,EAClFC,EAAsBR,EAA0B,CAClD,IAAMS,EAAUJ,GAAYC,EAAS,GAAK,EAC1C,GAAIN,GAAWA,IAAY,SACzB,OAAQA,EAAS,CACf,IAAK,QACH,OAAAH,EAAKU,CAAY,EAAI,EACrBV,EAAKW,CAAY,EAAI,EACd,KAAK,OAAQL,EAASM,GAAWL,EAAU,CAAC,EACrD,IAAK,aACL,IAAK,aACH,GAAIC,IAAa,EACf,MAAM,IAAI,MAAM,qDAAqD,EAChE,CAEL,IAAMK,IADoBP,EAASC,EAAS,GAAKA,EACX,GAAKA,EAASE,EAASH,EAC7D,OAAAN,EAAKU,CAAY,EACgB,KAAK,MAAjCP,IAAY,cAA4BU,EAAY,GAAK,EAAgBA,EAAY,CAA3B,EAC/Db,EAAKW,CAAY,EAAIE,EAAYb,EAAKU,CAAY,EAC3C,KAAK,OAAQJ,EAASO,EAAYJ,GAAUF,EAAU,CAAC,CAChE,CACF,QACE,MAAM,IAAI,MAAM,0BAA0B,CAC9C,KAEA,QAAO,KAAK,OAAQD,EAASN,EAAKU,CAAY,EAAIV,EAAKW,CAAY,EAAIC,GAAWL,EAAU,CAAC,CAEjG,CACF,EAEalD,GAAN,KAAe,CAIpB,OAAO,qBACHyD,EAA8BC,EAAoBC,EAA+BC,EACjFC,EAAkD,CACpD,GAAIJ,EAAU,SAAW,GAAKE,EAAW,SAAW,EAClD,MAAM,IAAI,MAAM,4BAA4B,EAG9C,IAAIG,EACAC,EACAC,EAEAN,GACFI,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,IAEfK,EAAIL,EAAU,CAAC,EACfM,EAAIN,EAAU,CAAC,GAGjB,IAAIQ,EAAO,GAUX,GARIL,GACFI,EAAIL,EAAW,CAAC,EAChBM,EAAO,IAEPD,EAAIL,EAAW,CAAC,EAChBM,EAAO,GAGLN,EAAWM,CAAI,IAAMF,EACvB,MAAM,IAAI,MAAM,oBAAoB,EAGtC,GAAID,GAAK,GAAKE,GAAK,GAAKD,GAAK,EAC3B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIF,GAAa,CAAChE,GAAc,iBAAiBgE,EAAW,CAACC,EAAGE,CAAC,CAAC,EAChE,MAAM,IAAI,MAAM,wCAAwC,EAG1D,MAAO,CAACF,EAAGE,EAAGD,CAAC,CACjB,CACF,EAGa9D,GAAW,sBACXC,GAAW,uBCpcxB,IAiBagE,GAqMPC,GAoCOC,GAUAC,GAOAC,GAiBAC,GAcAC,GAgBAC,GAsBPC,GAuSOC,EAaAC,EAyDPC,GAkFOC,GAYAC,GAeAC,GA1yBbC,GAAAC,EAAA,kBAGAC,KACAC,KAaalB,GAAiB,GAqMxBC,GAAoB,CAACkB,EAAcC,IAAiD,CACxF,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,OAAQD,EAAM,CACZ,QACE,OAAOC,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,QACE,OAAOA,EAAa,EAAI,MAAMA,CAAU,QAAU,MACpD,OACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,QACE,GAAIA,EAAa,EACf,MAAM,IAAI,MAAM,4CAA4C,EAE9D,MAAO,CAAC,YAAa,KAAK,EAC5B,OACE,GAAIA,IAAe,EACjB,MAAM,IAAI,MAAM,mBAAmB,EAErC,MAAO,CAAC,MAAO,YAAY,EAE7B,QACE,MAAM,IAAI,MAAM,sBAAsBD,CAAI,EAAE,CAChD,CACF,EAEajB,GAA8B,CAACiB,EAAgBC,EAAsB,IAAM,CACtF,IAAMC,EAAapB,GAAkBkB,EAAMC,CAAU,EACrD,OAAO,OAAOC,GAAe,SAAWA,EAAaA,EAAW,CAAC,CACnE,EAOalB,GAA8BmB,GACvCA,EAAK,SAAW,EAAI,CAAC,EAAI,CAAC,CAAC,KAAM,SAAU,KAAMA,CAAI,EAAG,CAAC,KAAM,SAAU,KAAMC,EAAU,eAAeD,CAAI,CAAC,CAAC,EAMrGlB,GAAoBoB,GAE3BA,EAAO,IAAM,EACR,EACEA,EAAO,IAAM,EACf,EAGF,EASInB,GAAa,CAACoB,EAAW,MAAOL,EAAqBM,EAAQ,MACpE,CAACN,GAAcA,IAAe,EACzB,GAAGK,CAAQ,IAAIC,CAAK,IAGtB,MAAMN,CAAU,IAAIK,CAAQ,KAAKC,CAAK,IASlCpB,GAAY,CAACmB,EAAkBL,EAAoBM,IAC1DD,IAAa,MACRC,EAELN,IAAe,EACV,OAAOM,CAAK,IAGd,MAAMN,CAAU,KAAKM,CAAK,IAQtBnB,GAAY,CAACoB,EAAcP,IAClCA,IAAe,EACV,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAC1CP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,MAClBP,IAAe,EACjB,IAAIO,CAAI,QAAQA,CAAI,QAAQA,CAAI,MAGlCA,EAaHnB,GACF,CAACmB,EAAcC,EAAoBC,EAAuCC,EACzEV,IAAuC,CACtC,IAAMW,EAAa,OAAOF,GAAgB,SACpCG,EAAOD,EAAaF,EAAcA,EAAY,OAC9CI,EAAe,CAAC,GAAG,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAC,EACzCE,EAAcF,EAAO,EAAI,MAAQA,GAAQ,EAAI,MAAMA,CAAI,QAAU,cAAcA,CAAI,IACnFX,EAAapB,GAAkB2B,EAAYR,CAAU,EACrDe,EAAY,OAAOd,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACtEe,EAAc,OAAOf,GAAe,SAAWA,EAAaA,EAAW,CAAC,EACxEF,EAAO,CAAC,QAASe,EAAa,MAAOC,EAAW,QAASC,EAAa,OAAQR,CAAU,EAExFS,EAAgBC,GAA+B,OAAOA,GAAQ,SAAWA,EAAM,GAAGA,CAAG,IAErFC,EAAqB,CACzB,gBAAiB,GACjB,gBAAiB,GACjB,2BAA4B,GAC5B,IAAK,GACL,aAAc,GACd,IAAK,GACL,aAAc,EAChB,EAEMC,EAAgBT,EAAa,YAAc,GAC3CU,EAAQ,GAAGD,CAAa,GAAGb,CAAI,SAC/Be,EAAU,GAAGF,CAAa,GAAGb,CAAI,WACnCgB,EAAa,GACjB,QAASC,EAAI,EAAGA,EAAIZ,EAAO,EAAGY,IAC5BD,GAAc;AAAA,aACTC,CAAC,gBAAgBF,CAAO,IAAIE,CAAC;AAAA,cAC5BA,CAAC,gBAAgBF,CAAO,IAAIE,CAAC;AAAA,cAC7BA,CAAC,UAAUA,CAAC;AAAA,oBACNA,CAAC;AAAA,MAGfD,GAAc,WAAWX,EAAO,CAAC,eAEjC,IAAMa,EAAgCb,EAAO,EAAI,GAAK;AAAA,WACjDL,CAAI,oBAAoBR,EAAK,OAAO;AAAA,mBAC5BA,EAAK,OAAO;AAAA;AAAA,MAEzBwB,CAAU;AAAA;AAAA,KAIJG,EAAmBC,IACvBR,EAAmB,gBAAkB,GAC9BP,EAAO,EAAIe,EAAY,OAAOpB,CAAI,IAAIoB,CAAS,KAGlDC,EAAoB,CAAC,EAC3B,GAAIhB,GAAQ,EACV,QAASY,EAAIZ,EAAO,EAAGY,GAAK,EAAGA,IAC7BI,EAAQ,KAAK,GAAGN,CAAO,IAAIE,CAAC,gBAAgBA,CAAC,IAAI,EAIrD,IAAMK,EAAgCjB,EAAO,EAAI,GAAK;AAAA,WACjDL,CAAI,aAAaR,EAAK,OAAO;AAAA,aAC3B6B,EAAQ,KAAK,GAAG,CAAC;AAAA,KAGlBE,EAAmBC,IACvBZ,EAAmB,gBAAkB,GAC9BP,EAAO,EAAImB,EAAa,OAAOxB,CAAI,IAAIwB,CAAU,KAGpDC,EAAU,IAAIC,IAChBrB,IAAS,EAAI,KAAO,GAAGb,EAAK,OAAO,IAAIkC,EAAK,IAAIhB,CAAY,EAAE,KAAK,GAAG,CAAC,IAErEiB,GAAa,CAACH,EAAoBI,KAClCvB,EAAO,EACF,GAAGmB,CAAU,GAEb,GAAGA,CAAU,IAAII,EAAG,IAIzBC,GAAa,CAACL,EAAoBI,GAAoB7B,KACtDM,EAAO,EACF,GAAGmB,CAAU,IAAIzB,EAAK,IAEtB,GAAGyB,CAAU,IAAII,EAAG,KAAK7B,EAAK,IAInC+B,EAAoE,CAAC,EACrEC,GAA6B,CAACP,EAAoBQ,KAA0B,CAChFpB,EAAmB,2BAA6B,GAChD,IAAMqB,GAAU,GAAGD,GAAO,IAAI,uBAAuBhC,CAAI,SACzD,GAAIiC,MAAWH,EACb,MAAO,GAAGG,EAAO,IAAIT,CAAU,IAEjC,IAAMH,GAAU,CAAC,EACjB,QAASJ,GAAIZ,EAAO,EAAGY,IAAK,EAAGA,KAAK,CAClC,IAAMW,GAAMI,GAAO,WAAW,gBAAiBf,GAAIe,GAAO,KAAO3B,CAAI,EACrEgB,GAAQ,KAAK,GAAGM,GAAWZ,EAASE,EAAC,CAAC,OAAOW,EAAG,MAAMD,GAAWb,EAAOG,EAAC,CAAC,GAAG,CAC/E,CACA,OAAAa,EAAyCG,EAAO,EAC5C,MAAMA,EAAO,mBAAmBD,GAAO,KAAK,OAAO;AAAA,sBACzCX,GAAQ,OAAS,EAAIA,GAAQ,KAAK,GAAG,EAAI,IAAI;AAAA,cAGpD,GAAGY,EAAO,IAAIT,CAAU,GACjC,EAEMU,GAAc,CAACC,EAAuBpC,MAAmB,IAAM,CACnE,GAAIP,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAImC,CAAM,KAAKpC,EAAK,IAC7B,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAImC,CAAM,mBAAmBpC,EAAK,8BAA8BA,EAAK,UAC9E,GAAIP,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,GAAGQ,CAAI,IAAImC,CAAM,mBAAmBpC,EAAK,UAC3C,GAAIP,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,GAAGQ,CAAI,IAAImC,CAAM,8DAA8DpC,EAAK,MAE3F,MAAM,IAAI,MAAM,6CAA6CP,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG4C,EAAeD,IAA2B,IAAM,CACpD,GAAI3C,EAAK,UAAYA,EAAK,MACxB,MAAO,GAAGQ,CAAI,IAAImC,CAAM,IACnB,GAAI3C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAImC,CAAM,OACvB,GAAI3C,EAAK,UAAY,aAAeA,EAAK,QAAU,MAExD,MAAO,OAAOQ,CAAI,IAAImC,CAAM,OACvB,GAAI3C,EAAK,UAAY,OAASA,EAAK,QAAU,aAElD,MAAO,mBAAmBQ,CAAI,IAAImC,CAAM,oBAAoBnC,CAAI,IAAImC,CAAM,sBAAsBnC,CAAI,IAChGmC,CAAM,wBAAwBnC,CAAI,IAAImC,CAAM,oBAEhD,MAAM,IAAI,MAAM,6CAA6C3C,EAAK,OAAO,mBAAmBA,EAAK,KAAK,MAAM,CAEhH,GAAG,EAEG6C,GAA6BhC,EAAO,EAAI,GAAK;AAAA,WAC9CL,CAAI,sBAAsBR,EAAK,OAAO,QAAQgB,CAAS;AAAA,aACrD4B,EAAY,OAAOpC,CAAI,WAAW,CAAC;AAAA,KAGpCsC,GAAoBjC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,EAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,GAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJjB,CAAI,IAAIuC,CAAc,QAAQ/B,CAAS;AAAA,iBACjCR,CAAI,aAAayB,EAAQe,EAAU,CAAC;AAAA,IAE/C,GAAG,EAEGC,GAAM,IAAIhB,IAA0C,CACxD,GAAIA,EAAQ,SAAWpB,EACrB,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAGlD,IAAMqC,GAAoBjB,EAAQ,IAAIf,CAAY,EAAE,KAAK,GAAG,EAE5D,OAAIL,IAAS,EACJ+B,EAAY,IAAI,EACd/B,IAAS,EACX+B,EAAYM,GAAkB,CAAC,CAAC,GAEvC9B,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,IAAI0C,EAAiB,IAE3C,EAEMC,GAAgBnB,GAChBnB,EAAO,EACF+B,EAAYZ,CAAU,GAE7BZ,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,aAAawB,CAAU,KAIvCoB,GAA6BvC,EAAO,EAAI,GAAK;AAAA,WAC9CL,CAAI,sBAAsBR,EAAK,OAAO,YAAYgB,CAAS;AAAA,MAChE0B,GAAY,OAAOlC,CAAI,YAAa,OAAO,CAAC;AAAA,KAGtC6C,GAAoBxC,EAAO,EAAI,IAAM,IAAM,CAC/C,IAAMkC,EAAiBjC,EAAa,IAAIW,IAAK,IAAIA,EAAC,OAAO,EAAE,KAAK,IAAI,EAC9DuB,GAAalC,EAAa,IAAIW,IAAK,IAAIA,EAAC,EAAE,EAAE,KAAK,IAAI,EAC3D,MAAO;AAAA,WACJjB,CAAI,IAAIuC,CAAc,YAAY/B,CAAS;AAAA,UAC5CR,CAAI,aAAayB,EAAQe,EAAU,CAAC;AAAA,IAExC,GAAG,EAiEH,MAAO,CACL,KA/BW,IAAM,CACjB,IAAMM,EAAQ,CAAC,EACf,OAAK1C,IACH0C,EAAM,KAAK,SAAShC,CAAK,MAAMtB,EAAK,OAAO,IAAIU,EAAY,KAAK,GAAG,CAAC,IAAI,EACxE4C,EAAM,KAAK,SAAS/B,CAAO,MAAMvB,EAAK,OAAO,IAAII,EAAU,eAAeM,CAAW,EAAE,KAAK,GAAG,CAAC,IAAI,GAElGU,EAAmB,iBACrBkC,EAAM,KAAK5B,CAA6B,EAEtCN,EAAmB,iBACrBkC,EAAM,KAAKxB,CAA6B,EAEtCV,EAAmB,4BACrB,OAAO,OAAOkB,CAAwC,EAAE,QAAQiB,IAAQD,EAAM,KAAKC,EAAI,CAAC,EAEtFnC,EAAmB,KACrBkC,EAAM,KAAKD,EAAiB,EAE1BjC,EAAmB,cACrBkC,EAAM,KAAKF,EAA0B,EAEnChC,EAAmB,KACrBkC,EAAM,KAAKR,EAAiB,EAE1B1B,EAAmB,cACrBkC,EAAM,KAAKT,EAA0B,EAEhCS,EAAM,KAAK;AAAA,CAAI,CACxB,EAIE,KAAAtD,EACA,gBAAA2B,EACA,gBAAAI,EACA,2BAAAQ,GACA,QAAAN,EACA,WAAAE,GACA,WAAAE,GACA,IAxEU,IAAImB,IAAkD,CAChE,GAAIA,EAAgB,SAAW3C,EAAO,EACpC,MAAM,IAAI,MAAM,0BAA0BA,CAAI,EAAE,EAElD,IAAMN,GAAQiD,EAAgB3C,CAAI,EAClC,GAAI,OAAON,IAAU,SACnB,MAAM,IAAI,MAAM,sBAAsB,EAGxC,IAAM2C,GAAoBM,EAAgB,MAAM,EAAG3C,CAAI,EAAE,IAAIK,CAAY,EAAE,KAAK,GAAG,EAEnF,OAAIL,IAAS,EACJ6B,GAAY,KAAMnC,EAAK,EACrBM,IAAS,EACX6B,GAAYQ,GAAkB,CAAC,EAAG3C,EAAK,GAE9Ca,EAAmB,IAAM,GACzBA,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,IAAI0C,EAAiB,KAAK3C,EAAK,IAErD,EAoDE,YAAAmC,GACA,aAnDmB,CAACV,EAAoBzB,KACpCM,EAAO,EACF6B,GAAYV,EAAYzB,EAAK,GAEpCa,EAAmB,aAAe,GAClCA,EAAmB,gBAAkB,GAC9B,OAAOZ,CAAI,aAAawB,CAAU,KAAKzB,EAAK,MA8CrD,IAAA0C,GACA,YAAAL,EACA,aAAAO,GAEA,MAAOxC,EAAU,QAAU,SAC3B,KAAAH,EACA,QAAAe,EACA,MAAAD,EACA,KAAAT,CACF,CACF,EAWSvB,EACT,CAACkB,EAAcR,EAAcU,EAAuCT,EAAsB,IACtFZ,GAAoBmB,EAAMR,EAAMU,EAAa,GAAMT,CAAU,EAWxDV,EACT,CAACiB,EAAcR,EAAcU,EAAuCT,EAAsB,IACtFZ,GAAoBmB,EAAMR,EAAMU,EAAa,GAAOT,CAAU,EAuDhET,GAAN,KAA+C,CAC7C,YAAoBiE,EAAmD,CAAnD,6BAAAA,EAuDpB,KAAQ,eAAkC,CAAC,EAC3C,KAAQ,SAAgD,CAAC,EAezD,KAAQ,cAAgB,CAvEgD,CAExE,sCAAsCpD,EAA6B,CAGjE,MAAO,qBADY,OAAOA,GAAS,SAAW,GAAGA,CAAI,IAAMA,CACrB,eACxC,CAEA,UAAUqD,EAAiD7E,GAAgB,CACzE,IAAM8E,EAAiB,OAAOD,GAAkB,SAAWA,EAAgBA,EAAc,CAAC,EACpFE,EAAiB,OAAOF,GAAkB,SAAW,EAAIA,EAAc,CAAC,EACxEG,EAAiB,OAAOH,GAAkB,SAAW,EAAIA,EAAc,CAAC,EAExEI,EAAuB,KAAK,wBAAwB,CAAC,IAAM,GAAK,KAAK,wBAAwB,CAAC,IAAM,EACpGC,EAAYD,EAAuB;AAAA,wDAEA;AAAA;AAAA,yDAGnCE,EAAsBF,EACxB,gCACA;AAAA,mEAEIH,EAAiBC,EAAiBC,CAAc,mBAExD,MAAO,4BAA4BF,CAAc,KAAKC,CAAc,KAAKC,CAAc;AAAA,YAC/EE,CAAS;AAAA,MACfC,CAAmB;AAAA,GAEvB,CAEQ,gBAAgBC,EAAyBC,EAA8B,CAC7E,KAAK,eAAe,KAAKD,CAAQ,EAC7BA,EAAS,OAAS,IAChBA,EAAS,MAAM,WAAW,WAAW,GACvC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,MAAM,QAAQ,YAAa,EAAE,EAAG,KAAMA,EAAS,KAAK,OAAO,CAAC,EAE7FA,EAAS,QAAQ,WAAW,WAAW,GACzC,KAAK,SAAS,KAAK,CAAC,KAAMA,EAAS,QAAQ,QAAQ,YAAa,EAAE,EAAG,KAAMA,EAAS,KAAK,OAAO,CAAC,GAGrG,IAAME,EAASF,EAAS,QAAU,QAAU,OAAS,aAC/ChD,EAAcgD,EAAS,KAAK,QAClC,MAAO,sBAAsBC,CAAY,kBAAkBC,CAAM,KAAKF,EAAS,IAAI,WAAWhD,CAAW,IAC3G,CAEA,oBAAoBmD,EAAoC,CACtD,OAAOA,EAAU,IAAIC,GAAK,KAAK,gBAAgBA,EAAG,KAAK,eAAe,CAAC,EAAE,KAAK;AAAA,CAAI,CACpF,CAEA,gBAAgB7D,EAAcR,EAA4B,CACxD,YAAK,SAAS,KAAK,CAAC,KAAAQ,EAAM,KAAAR,CAAI,CAAC,EACxB,IACT,CAIQ,oBAA6B,CACnC,GAAI,KAAK,SAAS,SAAW,EAC3B,MAAO,GAGT,IAAMsE,EAA4B,CAAC,EACnC,OAAW,CAAC,KAAA9D,EAAM,KAAAR,CAAI,IAAK,KAAK,SAC9BsE,EAAgB,KAAK,GAAG9D,CAAI,IAAIR,CAAI,EAAE,EAGxC,MAAO;AAAA,0BACesE,EAAgB,KAAK,IAAI,CAAC;AAAA,2BACzB,KAAK,aAAa,oCAC3C,CAMA,IAAI,2BAAoC,CACtC,OAAO,KAAK,mBAAmB,EAAI,KAAK,eAAe,IAAI7C,GAAKA,EAAE,KAAK,CAAC,EAAE,KAAK;AAAA,CAAI,CACrF,CACF,EAEahC,GAAsB8E,GAA4C,IAAI/E,GAAiB+E,CAAa,EAYpG7E,GAAmB,CAAC8E,EAA4BC,IAA0C,CACrG,IAAMC,EAASF,EAAQ,OACjBrE,EAAiB,CAAC,EACxB,QAASsB,EAAI,EAAGA,EAAIiD,EAAQjD,IAAK,CAC/B,IAAMN,EAAMuD,EAAS,EAAIjD,EACnBkD,EAAIH,EAAQrD,CAAG,GAAK,GAChBsD,EAASA,EAAS,OAAS,EAAIhD,CAAC,GAAK,GACvC,GAAKkD,IAAM,GACjBxE,EAAK,QAAQgB,CAAG,CAEpB,CACA,OAAOhB,CACT,EAGaR,GAAwBkB,GAA0BA,GAAQ,IC1yBvE,IAcM+D,GAMAC,GAGAC,GAGAC,GAWOC,GA+CAC,GAKAC,GAzFbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,6BAA6B,CAEjD,EAEMX,GAAkB,CAACY,EAAmBC,IACvCA,GAAQA,EAAK,SAAWD,EAAa,CAAC,GAAI,IAAI,MAAMA,CAAS,EAAE,KAAK,CAAE,EAAE,QAAQ,EAAIC,EAEnFZ,GAAiB,CAACa,EAA+BD,IACnDE,EAAU,gBAAgBD,EAAYd,GAAgBc,EAAW,OAAQD,CAAI,CAAC,EAE5EX,GAAmB,CAACW,EAAgBG,EAAcC,EAAsBC,IAAkC,CAC9G,IAAMC,EAAc,CAAC,EACrBA,EAAY,KAAK,cAAcD,EAAO,KAAK,OAAO,QAAQD,EAAM,KAAK,OAAO;AAAA,aACjEA,EAAM,KAAK,OAAO,GAAG,EAChC,QAASG,EAAI,EAAGA,EAAIJ,EAAM,EAAEI,EAC1BD,EAAY,KAAKF,EAAM,WAAW,IAAKJ,EAAKO,CAAC,EAAG,KAAKA,CAAC,GAAG,CAAC,EAE5D,OAAAD,EAAY,KAAK,YAAY,EACtBA,EAAY,KAAK;AAAA,CAAI,CAC9B,EAEahB,GAA6B,CAACkB,EAAyBC,IAAoC,CACtG,IAAMC,EAAgBF,EAAY,SAC5BT,EAAYS,EAAY,KAAK,OAC7BR,EAAOb,GAAgBY,EAAWU,CAAQ,EAC1CE,EAAoBC,GAAqBb,CAAS,EAClDc,EAAczB,GAAeoB,EAAY,KAAMR,CAAI,EACnDc,EAAiBH,EAAoBE,EAAY,OAASA,EAC1DE,EAAgBJ,EAAoBZ,EAAYS,EAAY,KAC5DH,EAASW,EAAe,SAAUN,EAAeI,CAAc,EAC/DV,EAAQa,EAAc,IAAKP,EAAeK,CAAa,EAEvDG,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,gBAAgB,cAAe,KAAK,EAAE,iBAAiBf,EAAOC,CAAM,CAAC;AAAA;AAAA,IAElFhB,GAAiBW,EAAMD,EAAWK,EAAOC,CAAM,CAAC;AAAA;AAAA,IAEhDc,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,sBAAsB,CAAC;AAAA;AAAA,oBAE5Dd,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA;AAAA,MAGlDA,EAAO,YAAY,aAAcD,EAAM,aAAa,UAAU,CAAC,CAAC;AAAA,KAEpE,MAAO,CACL,KAAM,YACN,YAAa,CAAC,KAAM,GAAGK,CAAQ,GAAI,kBAAmBE,EAAoB,CAAC,MAAM,EAAI,CAAC,MAAM,CAAC,EAC7F,WAAab,GAAW,CACtB,IAAMsB,EAAalB,EAAU,KAAKW,CAAW,EAC7C,MAAO,CACL,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUf,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,EAClE,gBAAiBT,EACb,CACE,CAAC,KAAM,SAAU,KAAMS,CAAU,EACjC,GAAGC,GAA2BvB,EAAO,CAAC,EAAE,IAAI,EAC5C,GAAGuB,GAA2BR,CAAW,CAC3C,EACA,CACE,CAAC,KAAM,SAAU,KAAMO,CAAU,CACnC,CACN,CACF,EACA,gBAAAF,CACF,CACF,EAEa3B,GAAY,CAAC+B,EAAyBC,IAA0C,CAC3FrC,GAAeoC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQhC,GAA2BgC,EAAQ,OAAO,CAAC,EAAGC,EAAW,IAAI,CAAC,CAChF,EAEa/B,GAA4B+B,GACrCC,GAA4B,CAAC,KAAMD,EAAW,IAAgB,CAAC,IC1FnE,IAYME,GAaAC,GAaAC,GAaAC,GAYAC,GAQAC,GAYAC,GAcAC,GASAC,GAaOC,GA0EPC,GAkCOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAvQbC,GAAAC,EAAA,kBAKAC,KAGAC,KACAC,KACAC,KAEM1B,GAAqC,CACzC,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,oCACX,UAAW,6BACX,GAAI,6BACJ,GAAI,oCACJ,OAAQ,uBACV,EAEMC,GAA2C,CAC/C,IAAK,sDACL,IAAK,sDACL,KAAM,wBACN,IAAK,wBACL,KAAM,wBACN,UAAW,wBACX,UAAW,wBACX,GAAI,wBACJ,GAAI,wBACJ,OAAQ,uBACV,EAEMC,GAA4C,CAChD,IAAK,aACL,IAAK,aACL,KAAM,IACN,IAAK,IACL,KAAM,IACN,UAAW,IACX,UAAW,IACX,GAAI,IACJ,GAAI,IACJ,OAAQ,GACV,EAEMC,GAA8C,CAClD,IAAK,YACL,IAAK,YACL,IAAK,YACL,KAAM,YACN,UAAW,YACX,UAAW,iBACX,GAAI,YACJ,GAAI,kBACJ,OAAQ,gBACV,EAEMC,GAAmB,CAACuB,EAAsBC,IAA2B,CACzE,IAAMC,EAAM,CAAC,EACb,QAASC,EAAIF,EAAOD,EAAcG,EAAIF,EAAM,EAAEE,EAC5CD,EAAI,KAAKC,CAAC,EAEZ,OAAOD,CACT,EAEMxB,GAA4B,CAAC0B,EAA0BC,IAAkD,CAC7G,IAAMC,EAAc,CAAC,EACfL,EAAOG,EAAM,OACnB,QAASG,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,IACxBD,EAAY,KAAKF,EAAMG,CAAG,CAAC,EAG/B,IAAMC,EAAcH,EAAK,IAAIE,GAAOH,EAAMG,CAAG,CAAC,EAC9C,MAAO,CAACD,EAAaE,CAAW,CAClC,EAEM7B,GAAuB,CAACyB,EAAiBC,IAA6B,CAC1E,IAAMJ,EAAOG,EAAM,OAASC,EAAK,OAC3BI,EAAc,CAAC,EACjBC,EAAW,EACf,QAASH,EAAM,EAAGA,EAAMN,EAAMM,IACxBF,EAAK,QAAQE,CAAG,IAAM,GACxBE,EAAY,KAAKL,EAAMM,GAAU,CAAC,EAElCD,EAAY,KAAK,CAAC,EAGtB,OAAOA,CACT,EAEM7B,GAAuB,CAACyB,EAAgBJ,IAA0B,CACtE,QAASE,EAAI,EAAGA,EAAIE,EAAK,OAAQ,EAAEF,EACjC,GAAIE,EAAKA,EAAK,OAASF,EAAI,CAAC,IAAMF,EAAO,EAAIE,EAC3C,MAAO,GAGX,MAAO,EACT,EAEMtB,GAAqB,CAACwB,EAAgBJ,IAA2B,CACrE,IAAMC,EAAM,CAAC,EACb,GAAI,CAACtB,GAAqByB,EAAMJ,CAAI,EAAG,CACrC,QAASE,EAAI,EAAGA,EAAIF,EAAM,EAAEE,EACtBE,EAAK,QAAQF,CAAC,IAAM,IACtBD,EAAI,KAAKC,CAAC,EAGdE,EAAK,QAAQM,GAAQT,EAAI,KAAKS,CAAI,CAAC,CACrC,CACA,OAAOT,CACT,EAEapB,GACT,CAAC8B,EAAcC,EAAqCC,EAA+BC,EAClFC,EAA0BV,EAAuBE,IAAuC,CACvF,IAAMS,EAAaH,EAAO,CAAC,EAAE,KAEvBI,EAAaC,EAAU,KAAKb,CAAW,EACvCc,EAAaD,EAAU,KAAKX,CAAW,EAEvCa,EAAQC,EAAc,KAAMR,EAAO,CAAC,EAAE,SAAUG,CAAU,EAC1DM,EAASC,EAAe,SAAUR,EAAgBV,CAAW,EAE7DmB,EAAgB,GAEhBC,EAAsB;AAAA,+CACaH,EAAO,KAAK,OAAO,KAAKE,CAAa;AAAA,SAgD9E,MAAO,CACL,KAAAb,EACA,YAAAC,EACA,gBAhDuBc,GAA+B;AAAA,UACpDA,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBN,EAAOE,CAAM,CAAC;AAAA,UACjFG,CAAmB;AAAA;AAAA;AAAA;AAAA,WAIlBC,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA;AAAA,2CAGLA,CAAa;AAAA;AAAA;AAAA,4BAG5BF,EAAO,KAAK,OAAO,IAAIhD,GAAiBwC,CAAU,CAAC;AAAA;AAAA,wDAEvBU,CAAa;AAAA,6BACxCF,EAAO,KAAK,OAAO,IAAIF,EAAM,YAAY,YAAY,CAAC;AAAA,yBAC1DhD,GAAU0C,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,wCAKNU,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0BAM3BnD,GAAgByC,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAS3CQ,EAAO,YACH,cACA,GACIR,IAAe,OAAS,eAAeQ,EAAO,KAAK,OAAO,wBAClC,GAAG/C,GAAmBuC,CAAU,CAAC,EAAE,EAAE,CAAC;AAAA;AAAA,WASxE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUU,CAAc,CAAC,EACvD,cAAe,CAAC,EAAGE,CAAU,EAC7B,gBAAiB,CAAC,CAAC,KAAM,SAAU,KAAME,CAAU,CAAC,CACtD,EACF,CACF,EAEErC,GACF,CAAC6C,EAAyBhB,EAAciB,EACvCd,IAAiG,CAChG,IAAMe,EACFF,EAAQ,OAAO,SAAW,EAAIC,EAAaE,GAAiCH,EAAQ,OAAQC,CAAU,EAEtGG,EAAcF,EAAkB,KAChCE,EAAY,SAAW,GAAK,CAACF,EAAkB,oBACjDE,EAAcJ,EAAQ,OAAO,CAAC,EAAE,KAAK,IAAI,CAACK,EAAG9B,IAAMA,CAAC,GAEtD,IAAM+B,EAAgBf,EAAU,cAAca,EAAaJ,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EAEpFvB,EAAO6B,EACPb,EAAQO,EAAQ,OAAO,CAAC,EACtBO,EAAetD,GAAmBwB,EAAMuB,EAAQ,OAAO,CAAC,EAAE,KAAK,MAAM,EACvEO,EAAa,OAAS,IACxBd,EAAQO,EAAQ,QACZQ,GAA2BR,EAAQ,OAAO,CAAC,EAAGO,CAAY,EAAG,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EAChG9B,EAAO5B,GAAiB4B,EAAK,OAAQgB,EAAM,KAAK,MAAM,GAGxD,GAAM,CAACf,EAAaE,CAAW,EAAI9B,GAA0B2C,EAAM,KAAMhB,CAAI,EACzEgC,EAAmB/B,EACnBwB,EAAkB,WACpBO,EAAmB1D,GAAqB2B,EAAa4B,CAAa,GAGpEN,EAAQ,QACJ9C,GACI8B,EAAM,CAAC,KAAMkB,EAAkB,SAAU,kBAAmB,CAAC,MAAM,CAAC,EAAG,CAACT,CAAK,EAAGN,EAChFa,EAAQ,OAAO,CAAC,EAAE,SAAUS,EAAkB7B,CAAW,EAC7D,CAAC,OAAQ,CAACa,CAAK,CAAC,CAAC,CACvB,EAESrC,GAAmB,CAAC4C,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEa5C,GAAiB,CAAC2C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa3C,GAAiB,CAAC0C,EAAyBC,IAAuC,CAC7F9C,GAAa6C,EAAS,iBAAkBC,EAAY,IAAI,CAC1D,EAEa1C,GAAwB,CAACyC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEazC,GAAkB,CAACwC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEaxC,GAAkB,CAACuC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEavC,GAAmB,CAACsC,EAAyBC,IAAuC,CAC/F9C,GAAa6C,EAAS,mBAAoBC,EAAY,MAAM,CAC9D,EAEatC,GAAkB,CAACqC,EAAyBC,IAAuC,CAC9F9C,GAAa6C,EAAS,kBAAmBC,EAAY,KAAK,CAC5D,EAEarC,GAAwB,CAACoC,EAAyBC,IAAuC,CACpG9C,GAAa6C,EAAS,wBAAyBC,EAAY,WAAW,CACxE,EAEapC,GAAqB,CAACmC,EAAyBC,IAAuC,CACjG9C,GAAa6C,EAAS,qBAAsBC,EAAY,QAAQ,CAClE,ICzQA,IAYMS,GAoBAC,GACOC,GA4EAC,GAUPC,GAeAC,GAWAC,GAWAC,GAWAC,GAWAC,GAoBAC,GAqBAC,GAoBAC,GAWAC,GAWAC,GAWAC,GAsBOC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAQAC,GAtXbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KACAC,KAEMhC,GAAkBiC,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,0BAA0B,CAE9C,EAYMhC,GAAkBiC,GAAU,CAAC,GAAI,GAAI,eAAeA,EAAM,YAAY,aAAa,CAAC,IAAK,EAAE,EACpFhC,GACT,CAACiC,EAAcC,EAAqCH,EAA+BI,EAClFC,EAAqBC,EAA0BC,EAAW,GAAOC,EAAoB,KAAuB,CAC3G,IAAMC,EAAwB,CAAC,EACzBC,EAAaV,EAAO,CAAC,EAAE,KAEvBW,EAAOC,EAAU,cAAcP,EAAWL,EAAO,CAAC,EAAE,KAAK,MAAM,EAC/Da,EAAkB,CAACL,GAAqBG,EAAK,SAAW,EAC9DD,EAAW,QAAQ,CAACI,EAAGC,IAAM,CACvBF,GAAmBF,EAAK,QAAQI,CAAC,GAAK,EACpCR,GACFE,EAAY,KAAK,CAAC,EAGpBA,EAAY,KAAKK,CAAC,CAEtB,CAAC,EAED,IAAME,EAAoB,CAAC,EAErBf,EAAQgB,EAAc,KAAMjB,EAAO,CAAC,EAAE,SAAUU,CAAU,EAC1DQ,EAASC,EAAe,SAAUb,EAAgBG,CAAW,EAC7DW,EAAMhB,EAASH,EAAOiB,EAAQP,CAAI,EAClCU,EAAwB,iBAAiBpB,EAAM,gBAAgB,cAAc,CAAC,IAC9EqB,EAAqB,OAAOD,CAAqB,IACjDE,EAAqB,OAAOF,CAAqB,IACjDG,EAAmBJ,EAAI,CAAC,IAAM,GAAM,GAAKG,EAC3CE,GAAcL,EAAI,CAAC,IAAM,GAAME,EAAqBD,GAAyB;AAAA,EAAOD,EAAI,CAAC,EAE7F,QAASM,EAAI,EAAGC,EAAI,EAAGD,EAAI1B,EAAO,CAAC,EAAE,KAAK,OAAQ0B,IAE5Cb,GAAmBF,EAAK,QAAQe,CAAC,GAAK,GACpCnB,GACFoB,IAGFF,EAAY,YAAYC,CAAC,eAAeA,CAAC,MAAM1B,EAAO,CAAC,EAAE,KAAK0B,CAAC,CAAC,MAAMA,CAAC;AAAA,kBAC/DN,EAAI,CAAC,EAAE,SAAS,WAAW,EAAI,oBAAoBM,CAAC,IAAM,EAAE;AAAA,kBAC5DzB,EAAM,WAAW,eAAgByB,EAAG,IAAIA,CAAC,EAAE,CAAC;AAAA,kBAC5CD,CAAS;AAAA,mBAGjBT,EAAQ,KAAK,GAAGf,EAAM,WAAW,eAAgByB,EAAGR,EAAO,WAAW,gBAAiBS,CAAC,CAAC,CAAC,GAAG,EAC7FA,KAIJ,IAAMC,EAAahB,EAAU,KAAKH,CAAW,EAkB7C,MAAO,CACL,KAAAP,EACA,YAAAC,EACA,gBApBuB0B,GAA+B;AAAA,UACpDA,EAAa,iBAAiB5B,EAAOiB,CAAM,CAAC;AAAA;AAAA,UAE5CW,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsCD,CAAU,CAAC;AAAA,8BAC5C3B,EAAM,KAAK,OAAO;AAAA,gCAChBiB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDF,EAAQ,KAAK;AAAA,CAAI,CAAC;AAAA,YAClBI,EAAI,CAAC,CAAC;AAAA,YACNI,CAAe;AAAA,YACfJ,EAAI,CAAC,CAAC;AAAA,YACNK,CAAS;AAAA,YACTL,EAAI,CAAC,CAAC;AAAA,YACNA,EAAI,SAAW,EAAIF,EAAO,YAAY,aAAc,OAAO,EAAIE,EAAI,MAAM,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,WAO1F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMX,EAAa,SAAUH,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKsB,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAES1D,GACT,CAAC8B,EAA+B8B,IAAmD,CACjF,IAAMnB,EAAiB,CAAC,EACxB,OAAIX,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,GACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQ+B,GAAKpB,EAAK,KAAK,OAAOoB,CAAC,CAAC,CAAC,EAEzDC,GACH,CAAC,KAAArB,EAAM,SAAUmB,EAAW,SAAU,kBAAmBA,EAAW,iBAAiB,CAAC,CAC5F,EAEE3D,GACF,CAAC8D,EAAyB/B,EAAc4B,EAA8B1B,IAA6B,CACjG,IAAMJ,EAASiC,EAAQ,OACjBC,EACFlC,EAAO,SAAW,EAAI8B,EAAa5D,GAAiC8B,EAAQ8B,CAAU,EAE1FG,EAAQ,QACJhE,GACIiC,EAAM,CAAC,KAAMgC,EAAkB,QAAQ,EAAG,CAAClC,EAAO,CAAC,CAAC,EACpDkC,EAAkB,mBAAqBA,EAAkB,KAAK,SAAW,EAAIlE,GAAOoC,EACpF8B,EAAkB,KAAMlC,EAAO,CAAC,EAAE,SAAUkC,EAAkB,SAC9DA,EAAkB,iBAAiB,EACvC,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEE9D,GAAoB,CAAC6D,EAAyBH,IAAuC,CACzF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,eAAgBH,EANf,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,qBACL,CAC8D,CAChE,EAEM5B,GAAgB,CAAC4D,EAAyBH,IAAuC,CACrF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,EACL,CAC0D,CAC5D,EAEM3B,GAAgB,CAAC2D,EAAyBH,IAAuC,CACrF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,WAAYH,EANX,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,sBACvC,sBACL,CAC0D,CAC5D,EAEM1B,GAAuB,CAAC0D,EAAyBH,IAAuC,CAC5F/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,gBAAgBjB,EAAM,YAAY,aAAa,CAAC,KAChD,qBACL,CACiE,CACnE,EAEMzB,GAAiB,CAACyD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAgB7B9D,GAAiB8D,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAKnC,EAAM,WAAW,eAAgByB,EAAG,CAAC,CAAC,EAIvD,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEMxB,GAAkB,CAACwD,EAAyBH,IAAuC,CACvF/D,GAAekE,EAAQ,MAAM,EAiB7B9D,GAAiB8D,EAAS,aAAcH,EAhBb,CAAC7B,EAAOiB,EAAQP,IAAS,CAClD,IAAI0B,EAAO,EACX,QAASX,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,KAE1C0B,GAAQJ,EAAQ,OAAO,CAAC,EAAE,KAAKP,CAAC,GAIpC,MAAO,CACL,oBACA,GACA,cAAczB,EAAM,YAAY,aAAa,CAAC,KAC9C,eAAeiB,EAAO,KAAK,KAAK,UAAUmB,CAAI,IAChD,CACF,CAC4D,CAC9D,EAEM3D,GAAiB,CAACuD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAgB7B9D,GAAiB8D,EAAS,YAAaH,EAfZ,CAAC7B,EAAOkC,EAASxB,IAAS,CACnD,IAAMyB,EAAU,CAAC,EACjB,QAASV,EAAI,EAAGA,EAAIzB,EAAM,KAAMyB,KAC1Bf,EAAK,QAAQe,CAAC,GAAK,GAAKf,EAAK,SAAW,IAC1CyB,EAAQ,KAAK,gBAAgBV,CAAC,QAAQ,EAI1C,MAAO,CACL,GAAGU,EAAQ,KAAK;AAAA,CAAI,CAAC,GACrB,eAAenC,EAAM,YAAY,aAAa,CAAC,IAC/C,sBAAsBA,EAAM,YAAY,aAAa,CAAC,KACtD,EACF,CACF,CAC2D,CAC7D,EAEMtB,GAAkB,CAACsD,EAAyBH,IAAuC,CACvF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,aAAcH,EANb,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC4D,CAC9D,EAEMrB,GAAiB,CAACqD,EAAyBH,IAAuC,CACtF/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,YAAaH,EANZ,CAAC7B,EAAOiB,IAC/B,CAAC,eAAeA,EAAO,KAAK,OAAO,OAClC,GACA,YAAYjB,EAAM,YAAY,aAAa,CAAC,IAC5C,EACL,CAC2D,CAC7D,EAEMpB,GAAuB,CAACoD,EAAyBH,IAAuC,CAC5F/D,GAAekE,EAAQ,MAAM,EAO7B9D,GAAiB8D,EAAS,kBAAmBH,EANlB,CAAC7B,EAAOiB,IAC/B,CAAC,WAAWA,EAAO,KAAK,KAAK,oBAAoBA,EAAO,KAAK,KAAK,OACjE,GACA,OAAOjB,EAAM,YAAY,aAAa,CAAC,oBACvC,EACL,CACiE,CACnE,EAEMnB,GACF,CAACwD,EAA0B3B,EAAyBH,IAAwC,CAC1F,GAAIG,EAAK,SAAW,EAClB,MAAO,EAAAH,EAGT,IAAIoB,EAAa,EACbW,EAAa,EACjB,QAASC,EAAM,EAAGA,EAAM7B,EAAK,OAAQ6B,IAC/B7B,EAAK,QAAQ6B,CAAG,IAAM,GACxBZ,GAAcU,EAAME,CAAG,EAEvBD,GAAcD,EAAME,CAAG,EAO3B,OAAOD,EAAa,IAAMX,EAAa,IACzC,EAES7C,GAAa,CAACkD,EAAyBH,IAAuC,CACrFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FrD,GAAgBwD,EAASH,CAAU,EAEnCW,GAAiBR,EAASH,CAAU,CAExC,EAEa9C,GAAW,CAACiD,EAAyBH,IAAuC,CACnFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FzD,GAAc4D,EAASH,CAAU,EAEjCY,GAAeT,EAASH,CAAU,CAEtC,EAEa7C,GAAW,CAACgD,EAAyBH,IAAuC,CACnFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FxD,GAAc2D,EAASH,CAAU,EAEjCa,GAAeV,EAASH,CAAU,CAEtC,EAEa5C,GAAkB,CAAC+C,EAAyBH,IAAuC,CAC1FhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FvD,GAAqB0D,EAASH,CAAU,EAExCc,GAAsBX,EAASH,CAAU,CAE7C,EAEa3C,GAAY,CAAC8C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FtD,GAAeyD,EAASH,CAAU,EAElCe,GAAgBZ,EAASH,CAAU,CAEvC,EAEa1C,GAAY,CAAC6C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FpD,GAAeuD,EAASH,CAAU,EAElCgB,GAAgBb,EAASH,CAAU,CAEvC,EAEazC,GAAa,CAAC4C,EAAyBH,IAAuC,CACrFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FnD,GAAgBsD,EAASH,CAAU,EAEnCiB,GAAiBd,EAASH,CAAU,CAExC,EAEaxC,GAAY,CAAC2C,EAAyBH,IAAuC,CACpFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FlD,GAAeqD,EAASH,CAAU,EAElCkB,GAAgBf,EAASH,CAAU,CAEvC,EAEavC,GAAkB,CAAC0C,EAAyBH,IAAuC,CAC1FhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5FjD,GAAqBoD,EAASH,CAAU,EAExCmB,GAAsBhB,EAASH,CAAU,CAE7C,EAEatC,GAAe,CAACyC,EAAyBH,IAAuC,CACvFhD,GAAqBmD,EAAQ,OAAO,CAAC,EAAE,KAAMH,EAAW,KAAMA,EAAW,iBAAiB,EAC5F1D,GAAkB6D,EAASH,CAAU,EAErCoB,GAAmBjB,EAASH,CAAU,CAE1C,EAEarC,GAAyBqC,GAClCE,GAA4BF,CAAiE,ICvXjG,IAcMqB,GAeAC,GAKOC,GA4BAC,GA4BAC,GA1FbC,GAAAC,EAAA,kBAOAC,KAEAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,GAAKA,EAAO,OAAS,EACpD,MAAM,IAAI,MAAM,wCAAwC,EAE1D,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,qBAAqB,CAEzC,EAQMT,GACF,CAACS,EAA+BC,IAC5BC,GACI,CAAC,KAAMD,EAAW,KAAM,SAAUA,EAAW,SAAU,gBAAiBA,EAAW,eAAe,CAAC,EAElGT,GAAS,CAACW,EAAyBF,IAA0C,CACxFX,GAAea,EAAQ,MAAM,EAC7B,IAAMC,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIJ,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEI,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEMI,EACFP,EAAQ,OAAO,SAAW,EAAIF,EAAaV,GAAoCY,EAAQ,OAAQF,CAAU,EAC7GE,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMD,EAAkB,QAAQ,EAAG,CAACP,EAAQ,OAAO,CAAC,CAAC,EAAGC,EAAa,CAACM,EAAkB,IAAI,IACvFA,EAAkB,QAAQ,EAC9C,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEajB,GAAS,CAACU,EAAyBF,IAA0C,CACxFX,GAAea,EAAQ,MAAM,EAC7B,IAAMC,EAAwB,CAACC,EAAOC,EAAQC,IAAS,CACrD,IAAMC,EAAU,CAAC,EACjB,QAASC,EAAI,EAAGA,EAAIJ,EAAM,KAAMI,KAC1BF,EAAK,QAAQE,CAAC,GAAK,GAAKF,EAAK,SAAW,IAC1CC,EAAQ,KAAK,gBAAgBC,CAAC,QAAQ,EAG1C,MAAO,CACL,GAAGD,EAAQ,KAAK;AAAA,CAAI,CAAC,GAAI,eAAeH,EAAM,YAAY,aAAa,CAAC;AAAA,0BACxE,OAAOA,EAAM,YAAY,aAAa,CAAC,IAAIJ,EAAW,gBAAkB,EAAI,KAAO,GAAG;AAAA,mBACzEI,EAAM,YAAY,aAAa,CAAC;AAAA;AAAA,UAG7C,GAAIC,EAAO,YAAY,aAAc,WAAW,CAClD,CACF,EAEMI,EACFP,EAAQ,OAAO,SAAW,EAAIF,EAAaV,GAAoCY,EAAQ,OAAQF,CAAU,EAC7GE,EAAQ,QACJQ,GACI,SAAU,CAAC,KAAMD,EAAkB,QAAQ,EAAG,CAACP,EAAQ,OAAO,CAAC,CAAC,EAAGC,EAAa,CAACM,EAAkB,IAAI,IACvFA,EAAkB,QAAQ,EAC9C,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EAEahB,GAA4BO,GACrCC,GAA4BD,CAAoE,IC3FpG,IASMW,GAkBAC,GAkCOC,GA7DbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEMN,GAAkBO,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,IAAK,IAAK,IAAI,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC9C,MAAM,IAAI,MAAM,+CAA+C,EAGjE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMN,GAA4BM,GAA+C,CAC/E,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAExBE,EAAWF,EAAO,CAAC,EAAE,KAAK,CAAC,EAE3BG,EAAaC,EAAU,KAAKH,CAAW,EAAI,EAE3CI,EAAWL,EAAO,CAAC,EAAE,SACrBM,EAAQC,EAAc,QAASF,EAAUJ,EAAa,CAAC,EACvDO,EAAOD,EAAc,OAAQF,EAAU,CAACH,CAAQ,EAAG,CAAC,EACpDO,EAAWF,EAAc,WAAYF,EAAUJ,EAAa,CAAC,EAC7DS,EAASC,EAAe,SAAUN,EAAUJ,EAAa,CAAC,EAahE,MAAO,CACL,KAAM,UACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CACpE,GACA,gBAjBuBS,GAA+B;AAAA,qBACrCV,CAAQ;AAAA,IACzBU,EAAa,iBAAiBN,EAAOE,EAAMC,EAAUC,CAAM,CAAC;AAAA;AAAA,IAE5DE,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA,kBAClDG,EAAM,YAAY,YAAY,CAAC;AAAA,UACvCE,EAAK,YAAY,uBAAuB,CAAC,MAAMC,EAAS,YAAY,YAAY,CAAC;AAAA,MACrFC,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,IAU7C,CACF,EAEaf,GAAWkB,GAAkC,CACxDpB,GAAeoB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQnB,GAAyBmB,EAAQ,MAAM,CAAC,CAC1D,IChEA,IAeMC,GA4BAC,GAiBOC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAGAC,GASAC,GAIAC,GA8BAC,GAWPC,GAMOC,GAKAC,GAIAC,GAIAC,GAQAC,GAGAC,GAeAC,GAcAC,GAMAC,GAIAC,GAIAC,GAOAC,GAMAC,GAIAC,GAIAC,GAIAC,GAKAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAIAC,GAOAC,GA/QbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMM1C,GACF,CAAC2C,EAA4BC,EAAkBC,EAAuBC,EACrEC,EAAmCC,IAA8C,CAChF,IAAMC,EAAU,KAAK,KAAKL,EAAW,CAAC,EAElCM,EAAa,GACb,OAAOH,GAAa,SACtBG,EAAa,GAAGH,CAAQ,MAExBG,EAAaH,EAAS,GAAG,EAG3B,IAAMI,EAAQC,EAAc,YAAaP,EAAe,CAACI,CAAO,EAAG,CAAC,EAC9DI,EAASC,EAAe,aAAcR,EAAgB,CAACG,CAAO,EAAG,CAAC,EAExE,MAAO;AAAA,QACLN,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBQ,EAAOE,CAAM,CAAC;AAAA;AAAA,IAEnFL,GAA4B,EAAE;AAAA;AAAA,IAE9BL,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA;AAAA,cAE/DQ,EAAM,YAAY,YAAY,CAAC;AAAA,MACvCE,EAAO,YAAY,aAAcH,CAAU,CAAC;AAAA,IAE9C,EAEEjD,GACF,CAACkD,EAAmBI,EAAcR,EAAmCC,EACpEQ,EAAmBV,EAAyBK,EAAM,YAA2B,CAC5E,KAAAI,EACA,YAAa,CAAC,KAAMC,EAAU,kBAAmB,CAAC,MAAM,CAAC,EACzD,gBAAiBb,GAAgB3C,GAC7B2C,EAAcc,EAAU,KAAKN,EAAM,IAAI,EAAGA,EAAM,SAAUL,EAAgBC,EAAUC,CAAwB,EAChH,WAAaU,IAAkB,CAC7B,QAAS,CAAC,CAAC,KAAMP,EAAM,KAAM,SAAUL,CAAc,CAAC,EACtD,cACI,CAAC,EAAG,KAAK,KAAKW,EAAU,KAAKC,EAAa,CAAC,EAAE,IAAI,EAAI,GAA0B,CAAgB,CAAC,EACpG,gBAAiB,CACf,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKD,EAAU,KAAKN,EAAM,IAAI,EAAI,CAAC,CAAC,CAClE,CACF,EACF,GAESjD,GAAOyD,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEaxD,GAAQwD,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEavD,GAASuD,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEatD,GAAQsD,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEarD,GAASqD,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEapD,GAAQoD,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EACanD,GAASmD,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAOalD,GAAuBmD,GAChCC,GAA4BD,CAA0B,EAG7ClD,GAAO,CAACiD,EAAyBC,IAAqC,CACjF,IAAIE,EACJ,OAAQF,EAAW,GAAI,CACrB,QACEE,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,QACEA,EAAO,YACP,MACF,OACEA,EAAO,YACP,MACF,OACEA,EAAO,aACP,MACF,QACE,MAAM,IAAI,WAAW,0EAA0EF,EAAW,EAAE,EAAE,CAClH,CACAD,EAAQ,QACJ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQG,EAAM,OAAWF,EAAW,SAAUA,EAAW,EAAE,CAAC,CAClH,EAOajD,GAAU,CAACgD,EAAyBC,IAAqC,CACpF,IAAMG,EAAWC,GAA4BL,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QACJ1D,GACI0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,GAAK,SAAS,CAAC,0BAA2B;AAAA,4BACnDI,CAAQ,YAAYA,CAAQ,IAAIH,EAAW,GAAG;AAAA,4BAC9CG,CAAQ,YAAYA,CAAQ,IAAIH,EAAW,GAAG;AAAA,EAEhEA,EAAW,QAAQ,EACvB,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACnB,EACMhD,GAAoCqD,GAAkD,CAC1F,IAAMC,EAAOD,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAIE,GAC9DC,EAAOH,EAAO,QAAU,EAAKA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAII,GACpE,OAAOR,GAA4B,CAAC,IAAAK,EAAK,IAAAE,CAAG,CAAC,CAC/C,EAEavD,GAAQ8C,GAAkC,CACrD,IAAMC,EAAahD,GAAiC+C,EAAQ,MAAM,EAClEhD,GAAQgD,EAASC,CAAU,CAC7B,EAEa9C,GAAQ6C,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa5C,GAAO4C,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa3C,GAAQ2C,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAMa1C,GAAwB2C,GACjCC,GAA4BD,CAA6B,EAEhD1C,GAAM,CAACyC,EAAyBC,IAAsC,CACjFD,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,MAAOW,GAAK,YAAYA,CAAC,IAAK;AAAA,gCACvBV,EAAW,KAAK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAS1CA,EAAW,QAAQ,CAAC,CAC1B,EAEazC,GAAU,CAAC4C,EAAkBQ,EAAU,QAAU;AAAA,YAClDA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA,YACPA,CAAO;AAAA;AAAA,iBAEFR,CAAQ,QAAQA,CAAQ;AAAA;AAAA;AAAA;AAAA,GAM5B3C,GAAOuC,GAAkC,CACpD,IAAMI,EAAWC,GAA4BL,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,MAAOW,GAAK,YAAYA,CAAC,IAAKnD,GAAQ,QAAQ4C,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC9F,EAEa1C,GAAOsC,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEarC,GAASqC,GAAkC,CACtDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,QAAS,OAAO,CAAC,CACnF,EAEapC,GAAQoC,GAAkC,CACrD,IAAMI,EAAWC,GAA4BL,EAAQ,OAAO,CAAC,EAAE,QAAQ,EACvEA,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,OAAQW,GAAK,SAASA,CAAC,sBAAsBA,CAAC,0BACjEnD,GAAQ,QAAQ4C,CAAQ,IAAKA,CAAQ,CAAC,CAAC,CAC7C,EAEavC,GAAY,CAACmC,EAAyBC,IAAsC,CACvFD,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,YAAaW,GAAK,8BAA8BA,CAAC,KAAKA,CAAC,KAAKA,CAAC,sBAChF,sCAAsCV,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,CACtF,EAEanC,GAAOkC,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAOW,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa5C,GAAOiC,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAOW,GAAK,IAAIA,CAAC,EAAE,CAAC,CACtF,EAEa3C,GAAcgC,GAAkC,CAC3DA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,aAAcW,GAAK,OAAOA,CAAC,EAAE,CAAC,CAChG,EAEa1C,GAAQ+B,GAAkC,CACrDA,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,OAAQW,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,oBAAoB,CAAC,CAC5F,EAEazC,GAAW8B,GAAkC,CACxDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,UAAWW,GAAK,sBAAsBA,CAAC,KAAK,CAAC,CAC/G,EAEaxC,GAAO6B,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEa5B,GAAQ4B,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa3B,GAAQ2B,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEa1B,GAAO0B,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,EAEazB,GAAQyB,GAAkC,CACrDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,OAAQ,MAAM,CAAC,CACjF,EAEaxB,GAAkB,CAACwB,EAAyBC,KACvDD,EAAQ,QAAQ1D,GACZ0D,EAAQ,OAAO,CAAC,EAAG,kBAAmBW,GAAK,0BAA0BA,CAAC,KAAKA,CAAC,8BAC5E,wDAAwDV,EAAW,KAAK,KAAMA,EAAW,QAAQ,CAAC,EAC/F,GAGIxB,GAAOuB,GAAkC,CACpDA,EAAQ,QAAQ1D,GAA6B0D,EAAQ,OAAO,CAAC,EAAG,MAAO,KAAK,CAAC,CAC/E,ICjRA,IAUMa,GAkBAC,GAwCOC,GApEbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEMP,GAAkBQ,GAAwC,CAC9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,gCAAgC,EAGlD,GAAI,CAAC,CAAC,KAAM,KAAM,KAAK,EAAE,SAASA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EACjD,MAAM,IAAI,MAAM,4CAA4C,EAG9D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMP,GAAkCO,GAA+C,CACrF,IAAMC,EAAcD,EAAO,CAAC,EAAE,KAAK,MAAM,EACzCC,EAAY,CAAC,EAAIA,EAAY,CAAC,EAAI,EAElC,IAAMC,EAAQC,EAAc,QAASH,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EACpEI,EAAOD,EAAc,OAAQH,EAAO,CAAC,EAAE,SAAU,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAAG,CAAC,EACvEK,EAASC,EAAe,SAAUN,EAAO,CAAC,EAAE,SAAUC,EAAa,CAAC,EAEpEM,EAAaC,EAAU,KAAKP,CAAW,EAAI,EAsBjD,MAAO,CACL,KAAM,gBACN,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMA,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKO,EAAa,EAAuB,CAAC,CACpE,GACA,gBA1BuBE,GAA+B;AAAA;AAAA,yBAEjCT,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,EAAI,CAAC;AAAA;AAAA,IAE9CS,EAAa,iBAAiBP,EAAOE,EAAMC,CAAM,CAAC;AAAA;AAAA,IAElDK,GAAQ,OAAO,CAAC;AAAA;AAAA,IAEhBD,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCF,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ9DF,EAAO,YAAY,aAAc,uBAAuB,CAAC;AAAA,IAU7D,CACF,EAEaX,GAAiBiB,GAAkC,CAC9DnB,GAAemB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQlB,GAA+BkB,EAAQ,MAAM,CAAC,CAChE,ICvEA,IAiBMC,GA+FAC,GAqEAC,GAQOC,GAIAC,GAIAC,GAMAC,GAIAC,GAsBAC,GAIAC,GAMAC,GAMAC,GAMAC,GA3PbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KASMjB,GACF,CAACkB,EAA4BC,EAA0BC,EAA0BC,EAChFC,EAAoBC,EAAsBC,EAA8BC,EAAeC,EACvFC,EAAoBC,EAA4BC,IAAsC,CACrF,IAAIC,EACAC,EACA,OAAOP,GAAa,SACtBM,EAAmBC,EAAmB,CAACC,EAAGC,IAAM,GAAGT,CAAQ,KAAKQ,CAAC,MAAMC,CAAC,KAC/D,OAAOT,GAAa,WAC7BM,EAAmBC,EAAmBP,GAEtCM,EAAmBN,EAAS,OAC5BO,EAAmBP,EAAS,QAG9B,IAAMU,EAAoBN,EAAoBT,EAAM,OAASA,EACvDgB,EAAoBP,EAAoBR,EAAM,OAASA,EACvDgB,EAAoBR,EAAoBP,EAAW,OAASA,EAC5DgB,EAASC,EAAe,aAAcX,EAAYS,EAAmB,CAAC,EACtEJ,EAAIO,EAAc,QAASd,EAAOS,EAAmB,CAAC,EACtDD,EAAIM,EAAc,QAASb,EAAOS,EAAmB,CAAC,EAExDK,EACJ,GAAIlB,EACF,GAAIC,EAAa,CACf,IAAMkB,EAAgBC,EAAU,KAAKvB,CAAK,IAAM,EAC1CwB,EAAgBD,EAAU,KAAKtB,CAAK,IAAM,EAC5CqB,GAAiBE,EACnBH,EAAaH,EAAO,YAChB,aACAN,EACIU,EAAgB,GAAGT,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,EACvFW,EAAgB,GAAGV,EAAE,KAAK,KAAK,IAAIA,EAAE,YAAY,GAAG,CAAC,MAAQA,EAAE,YAAY,YAAY,CAAC,CAAC,EAEjGO,EAAa;AAAA,kCACSH,EAAO,gBAAgB,iBAAiB,CAAC;AAAA,4BAC/CL,EAAE,2BAA2B,gBAAiBK,CAAM,CAAC;AAAA,4BACrDJ,EAAE,2BAA2B,gBAAiBI,CAAM,CAAC;AAAA,cAEjEA,EAAO,YACH,aAAcN,EAAiBC,EAAE,YAAY,cAAc,EAAGC,EAAE,YAAY,cAAc,CAAC,CAAC,CAAC;AAAA,WAGzG,MACEO,EAAaH,EAAO,YAChB,aAAcN,EAAiBC,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAEzF,CACL,GAAI,CAACV,EACH,MAAM,IAAI,MAAM,sFAAsF,EAGxG,IAAMqB,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,GAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,GAAc,eAAeH,CAAC,eAAeA,CAAC,IACpD,MAAO;AAAA,+BACcA,CAAC,MAAMT,EAAO,gBAAgB,qBAAqBS,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMd,EAAE,2BAA2B,gBAAgBc,CAAC,GAAIT,CAAM,CAAC;AAAA,yBAChES,CAAC,MAAMb,EAAE,2BAA2B,gBAAgBa,CAAC,GAAIT,CAAM,CAAC;AAAA,wBACjES,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIjB,EAAiBkB,GAAaC,EAAW,CAAC;AAAA,WAE9E,EACItB,IAAe,EACjBa,EAAa;AAAA;AAAA,cAETI,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCJ,EAAa;AAAA,cACTI,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACH1B,EAAa,gBAAgB,WAAY,KAAK,EAAE,iBAAiBc,EAAGC,EAAGI,CAAM,CAAC;AAAA;AAAA,UAE9ER,GAA4B,EAAE;AAAA;AAAA,UAE9BX,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsC,mBAAmB,CAAC;AAAA,UACvEsB,CAAU;AAAA,QAEhB,EAEEvC,GACF,CAACiD,EAAcC,EAAkBnB,EAAeC,EAAeT,EAC9DK,EAAmCuB,EAAyBpB,EAAE,WAA0B,CACvF,IAAMqB,EAAc,CAACX,EAAU,SAASV,EAAE,KAAMC,EAAE,IAAI,EAClDqB,EAActB,EAAE,KAChBuB,EAAab,EAAU,KAAKV,EAAE,IAAI,EAElCV,EAAY,GAGVkC,EAAc,CAACH,CAAW,EAChC,GAAIA,EAAa,CACf,IAAMI,EAAkBC,GAAc,UAAU1B,EAAE,KAAMC,EAAE,KAAM,EAAK,EACrE,GAAI,CAACwB,EACH,MAAM,IAAI,MAAM,8CAA+C,EAEjEH,EAAcG,EACdF,EAAab,EAAU,KAAKY,CAAW,EACvC,IAAMb,EAAgBC,EAAU,KAAKV,EAAE,IAAI,IAAM,EAC3CW,EAAgBD,EAAU,KAAKT,EAAE,IAAI,IAAM,EACjDuB,EAAY,KAAKf,CAAa,EAC9Be,EAAY,KAAKb,CAAa,EAE9B,IAAIgB,EAAkB,EACtB,QAASC,EAAI,EAAGA,EAAIN,EAAY,OAAQM,IAAK,CAC3C,IAAMC,EAAO7B,EAAE,KAAKA,EAAE,KAAK,OAAS4B,CAAC,GAAK,EACpCE,EAAO7B,EAAE,KAAKA,EAAE,KAAK,OAAS2B,CAAC,GAAK,EAC1C,GAAIC,IAASC,EACXH,GAAmBE,MAEnB,MAEJ,EACIF,EAAkB,IAAM,GAAKlB,GAAiBE,KAChDrB,EAAY,GAEhB,MAEEA,EAAY,GAEdkC,EAAY,KAAKlC,CAAS,EAC1B,IAAMM,EAAoBmC,GAAqB/B,EAAE,KAAK,MAAM,GAAK+B,GAAqB9B,EAAE,KAAK,MAAM,GAC/F8B,GAAqBT,EAAY,MAAM,EAC3C,MAAO,CACL,KAAAJ,EACA,YAAa,CACX,KAAMC,EAAWK,EAAY,IAAKV,GAAMA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,EAC9D,kBAAmBlB,EAAoB,CAAC,OAAQ,MAAM,EAAI,CAAC,OAAQ,MAAM,CAC3E,EACA,gBAAkBV,GAAiBlB,GAC/BkB,EAAcc,EAAE,KAAMC,EAAE,KAAMqB,EAAahC,EAAW+B,EAAa7B,EAAUQ,EAAE,SAAUC,EAAE,SAC3FmB,EAAgBxB,EAAmBC,CAAwB,EAC/D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMyB,EAAa,SAAUF,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,GAA0B,CAAsB,CAAC,EAC3F,gBAAiB3B,EACb,CACE,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKc,EAAU,KAAKY,CAAW,EAAI,CAAC,CAAC,EACjE,GAAGU,GAA2BhC,EAAE,IAAI,EACpC,GAAGgC,GAA2B/B,EAAE,IAAI,EACpC,GAAG+B,GAA2BV,CAAW,CAC3C,EACA,CACE,CAAC,KAAM,SAAU,KAAM,KAAK,KAAKZ,EAAU,KAAKY,CAAW,EAAI,CAAC,CAAC,CACnE,CACN,EACF,CACF,EAEEpD,GACF,CAAC+D,EAAyBf,EAAc1B,EAA8BK,EACrEsB,EAAmBC,IAAkC,CACpDa,EAAQ,QAAQhE,GACZiD,EAAMC,GAAY,GAAIc,EAAQ,OAAO,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAGzC,EAAUK,EACtEuB,CAAc,CAAC,CACrB,EAESjD,GAAO8D,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAACjC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa7B,GAAO6D,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAACjC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa5B,GAAS4D,GAAkC,CACtD/D,GACI+D,EAAS,QAAU,CAAC,OAAQ,CAACjC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEa3B,GAAO2D,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAACjC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEa1B,GAAO0D,GAAkC,CACpD,IAAMC,EAAO3B,EAAc,QAAS0B,EAAQ,OAAO,CAAC,EAAE,SAAUA,EAAQ,OAAO,CAAC,EAAE,IAAI,EAAE,KAAK,MAE7F/D,GACI+D,EAAS,MAAQ,CAAC,OAAQ,CAAC,EAAGhC,IAAM,cAAc,CAAC,IAAIA,CAAC,IAAK,OAAQ,CAAC,EAAGA,IAAM,qBAAqB,CAAC,IAAIA,CAAC,GAAG,EAC7G;AAAA,wBACkBiC,CAAI,SAASA,CAAI,QAAQA,CAAI;AAAA,iBACpCA,CAAI;AAAA,iBACJA,CAAI;AAAA,uBACEA,CAAI;AAAA,iBACVA,CAAI;AAAA;AAAA,+BAEUA,CAAI,6BAA6BA,CAAI,qBAAqBA,CAAI,IAV1EA,IAAS,MAAQ,QAAU,EAW5B;AAAA;AAAA,oCAEkBA,CAAI,eAAeA,CAAI,cAAcA,CAAI;AAAA;AAAA,oBAEzDA,CAAI;AAAA;AAAA,OAEjB,CACP,EAEa1D,GAAOyD,GAAkC,CACpD/D,GAAY+D,EAAS,MAAO,CAACjC,EAAGC,IAAM,GAAGD,CAAC,IAAIC,CAAC,EAAE,CACnD,EAEaxB,GAAWwD,GAAkC,CACxD/D,GACI+D,EAAS,UAAY,CAAC,OAAQ,CAACjC,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACtG,QAAwB,CAC9B,EAEavB,GAAQuD,GAAkC,CACrD/D,GACI+D,EAAS,OAAS,CAAC,OAAQ,CAACjC,EAAGC,IAAM,OAAOD,CAAC,IAAIC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,IAAIC,CAAC,GAAG,EAAI,OACnG,QAAwB,CAC9B,EAEatB,GAAkBsD,GAAkC,CAC/D/D,GACI+D,EAAS,iBAAmB,CAAC,OAAQ,CAACjC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EAC3G,OAAW,QAAwB,CACzC,EAEarB,GAAeqD,GAAkC,CAC5D/D,GACI+D,EAAS,cAAgB,CAAC,OAAQ,CAACjC,EAAGC,IAAM,OAAOD,CAAC,KAAKC,CAAC,IAAK,OAAQ,CAACD,EAAGC,IAAM,aAAaD,CAAC,KAAKC,CAAC,GAAG,EACxG,OAAW,QAAwB,CACzC,IC/PA,IAcMkC,GAqBAC,GAWAC,GAmBAC,GAkGOC,GAKAC,GAxKbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMV,GAAkBW,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAGlC,IAAMC,EAAYD,EAAO,CAAC,EAAE,SACtBE,EAAsBF,EAAO,CAAC,EAAE,KAAK,OAE3C,QAAWG,KAASH,EAAQ,CAE1B,GAAIG,EAAM,WAAaF,EACrB,MAAM,IAAI,MAAM,kCAAkC,EAIpD,GAAIE,EAAM,KAAK,SAAWD,EACxB,MAAM,IAAI,MAAM,0CAA0C,CAE9D,CACF,EAEMZ,GAA0B,CAACc,EAAyBC,IAAwC;AAAA;AAAA,wCAE1DD,CAAe,MAAMC,CAAmB;AAAA,gCAChDD,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,KAGtBb,GAAmB,CAACS,EAAkCM,IAA0B,CACpF,IAAMF,EAAkBJ,EAAO,OAEzBO,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIJ,EAAiB,EAAEI,EAAG,CACxC,IAAMC,EAAgBH,EAAO,YAAY,aAAcN,EAAOQ,CAAC,EAAE,aAAa,SAAS,CAAC,EACpFJ,IAAoB,EACtBG,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,qBAAqBC,CAAC,QAAQC,CAAa,IAAI,EACrDD,IAAMJ,EAAkB,EACjCG,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,0BAA0BC,CAAC,OAAOC,CAAa,IAAI,CAEtE,CACA,OAAOF,EAAU,KAAK;AAAA,CAAI,CAC5B,EAEMf,GAA0B,CAACQ,EAA+BU,IAA8B,CAC5F,IAAMC,EAAaX,EAAO,CAAC,EAAE,KAAK,MAAM,EACxC,GAAIU,GAAQC,EAAW,QAAUD,EAAQ,GAAKC,EAAW,OACvD,MAAM,IAAI,MAAM,8DAA+D,EAEjF,IAAMC,EAAgBF,EAAO,EAAKC,EAAW,OAASD,EAAOA,EAGvDG,EAAcF,EAAW,MAAM,CAAC,EACtC,QAASH,EAAI,EAAGA,EAAIR,EAAO,OAAQQ,IAAK,CACtC,IAAMM,EAAad,EAAOQ,CAAC,EAAE,KAAK,MAAM,EACxC,QAASO,EAAY,EAAGA,EAAYJ,EAAW,OAAQI,IAErD,GAAIA,IAAcH,EAChBC,EAAYD,CAAY,GAAKE,EAAWC,CAAS,UAG1CJ,EAAWI,CAAS,IAAMD,EAAWC,CAAS,EACrD,MAAM,IAAI,MAAM,kCAAkC,CAGxD,CAEA,IAAMC,EAAaC,EAAU,KAAKJ,CAAW,EAEvCK,EAAmB,IAAI,MAAclB,EAAO,MAAM,EAClDmB,EAAY,IAAI,MAAqBnB,EAAO,MAAM,EAClDoB,EAAWpB,EAAO,CAAC,EAAE,SAEvBqB,EAAc,EACZC,EAAwD,CAAC,EACzDC,EAAoB,CAAC,EACrBC,EAA4B,CAAC,EAC7BC,EAAoC,CAAC,CAAC,KAAM,SAAU,KAAMT,CAAU,CAAC,EAC7E,QAASR,EAAI,EAAGA,EAAIR,EAAO,OAAQ,EAAEQ,EACnCa,GAAerB,EAAOQ,CAAC,EAAE,KAAKI,CAAY,EAC1CM,EAAiBV,CAAC,EAAIa,EACtBG,EAA0B,KAAKE,GAAqB1B,EAAOQ,CAAC,EAAE,KAAK,MAAM,CAAC,EAC1Ee,EAAkB,KAAKC,EAA0BhB,CAAC,EAAIR,EAAOQ,CAAC,EAAE,KAAK,OAASR,EAAOQ,CAAC,EAAE,IAAI,EAC5FW,EAAUX,CAAC,EAAImB,EAAc,QAAQnB,CAAC,GAAIY,EAAUG,EAAkBf,CAAC,CAAC,EACxEc,EAAkB,KAAKE,EAA0BhB,CAAC,EAAI,OAAS,MAAM,EACrEiB,EAAgB,KAAK,CAAC,KAAM,SAAU,KAAMP,EAAiBV,CAAC,CAAC,CAAC,EAElE,QAASA,EAAI,EAAGA,EAAIR,EAAO,OAAQ,EAAEQ,EAC/BgB,EAA0BhB,CAAC,GAC7BiB,EAAgB,KAAK,GAAGG,GAA2B5B,EAAOQ,CAAC,EAAE,IAAI,CAAC,EAItE,IAAMqB,EAA6BH,GAAqBb,EAAY,MAAM,EACtEgB,GACFJ,EAAgB,KAAK,GAAGG,GAA2Bf,CAAW,CAAC,EAGjE,IAAMiB,EAAoBD,EAA6BhB,EAAY,OAASA,EACtEP,EAASyB,EAAe,SAAUX,EAAUU,CAAiB,EAE7DE,EAAc1B,EAAO,WAAW,UAAWM,CAAY,EACvDP,EACF,MAAM,KAAK,MAAMa,EAAiB,MAAM,EAAE,KAAK,CAAC,EAAE,IAAIV,GAAK,4BAA4BA,CAAC,EAAE,EAAE,KAAK,GAAG,EAClGyB,EAAmBC,GAA+B;AAAA;AAAA,KAErD,IAAM,CACPA,EAAa,gBAAgB,aAAc,KAAK,EAChD,QAAS1B,EAAI,EAAGA,EAAIR,EAAO,OAAQQ,IACjC0B,EAAa,gBAAgB,mBAAmB1B,CAAC,GAAI,KAAK,EAE5D,OAAO0B,EAAa,iBAAiB,GAAGf,EAAWb,CAAM,CAC3D,GAAG,CAAC;AAAA;AAAA,IAEFhB,GAAwB4B,EAAiB,OAAQb,CAAmB,CAAC;AAAA;AAAA,IAErE6B,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsC,qBAAqB,CAAC;AAAA;AAAA,oBAE3D5B,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2CAEb0B,CAAW;AAAA;AAAA,0CAEZd,EAAiB,MAAM,MAAMb,CAAmB;AAAA,QAClF2B,CAAW;AAAA;AAAA;AAAA,MAGbzC,GAAiB4B,EAAWb,CAAM,CAAC;AAAA,KAGvC,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGI,CAAI,GAAI,kBAAAY,CAAiB,EAChD,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMT,EAAa,SAAUb,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKgB,EAAa,EAAuB,CAAC,EAClE,gBAAAS,CACF,GACA,gBAAAQ,CACF,CACF,EAEaxC,GAAS,CAAC0C,EAAyBC,IAAuC,CACrF/C,GAAe8C,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ3C,GAAwB2C,EAAQ,OAAQC,EAAW,IAAI,CAAC,CAC1E,EAEa1C,GAAyB0C,GAClCC,GAA4B,CAAC,KAAMD,EAAW,IAAc,CAAC,ICzKjE,IAYaE,GAsBAC,GAlCbC,GAAAC,EAAA,kBAGAC,KASaJ,GAAuB,CAACK,EAA0CC,IAClB,CACvD,OAAQD,EAAW,WAAY,CAC7B,IAAK,OACH,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,sBAAsBC,CAAS,SAAS,EAC3F,IAAK,UACH,MAAO,CACL,mBAAoB,GACpB,gBAAiB,YAAYA,CAAS,YAAYA,CAAS,wBAC7D,EACF,IAAK,OACH,MAAO,CACL,mBAAoB,mBAAmBA,CAAS,IAAID,EAAW,OAAQ,qBAAqBC,CAAS,IACjGD,EAAW,OAAQ,KACvB,gBAAiB,6CACnB,EAEF,QACE,MAAO,CAAC,mBAAoB,GAAI,gBAAiB,EAAE,CACvD,CACF,EAESJ,GACRI,GAAgF,CAC/E,IAAME,EAAaF,GAAY,YAAwB,GAEvD,GAAIE,IAAe,OAAQ,CACzB,GAAM,CAACC,EAASC,CAAO,EAAIJ,GAAY,mBAAyC,CAACK,GAAUC,EAAQ,EACnG,MAAO,CAAC,WAAAJ,EAAY,QAAAE,EAAS,QAAAD,EAAS,mBAAoB,GAAGD,CAAU,IAAIC,CAAO,IAAIC,CAAO,EAAE,CACjG,CACA,MAAO,CAAC,WAAAF,EAAY,mBAAoBA,CAAU,CACpD,IC3CJ,IAqBaK,GAeAC,GApCbC,GAAAC,EAAA,kBAqBaH,GAAc,CAACI,EAAmBC,IAAqB,CAClE,OAAQD,EAAW,CACjB,IAAK,GACH,OAAOC,EACT,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,IAAK,GACH,MAAO,QAAQA,CAAQ,IACzB,QACE,MAAM,IAAI,MAAM,GAAGD,CAAS,8BAA8B,CAC9D,CACF,EAEaH,GAAeK,GAA6B;AAAA,QACjDA,EAAU,iDAAmD,EAAE;UCrCvE,IAqBaC,GArBbC,GAAAC,EAAA,kBAqBaF,GAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;ICrB7B,IA6BMG,GAiBAC,GAyBOC,GAuFPC,GAiBAC,GAKOC,GAgKPC,GAmFOC,GAvabC,GAAAC,EAAA,kBAsBAC,KAEAC,KACAC,KAEAC,KAEMb,GAA6B,CAACc,EAAoBC,IAClDD,EACK;AAAA;AAAA;AAAA,wDAG6CC,EAAY,iBAAmB,EAAE;AAAA,UAI9E;AAAA;AAAA;AAAA,gDAGqCA,EAAY,iBAAmB,EAAE;AAAA,UAK3Ed,GAAyB,CAACe,EAAqBC,IAC/CD,EACK;AAAA;AAAA;AAAA;AAAA,UAIDC,IAAqB,EAAI,GAAK,6DAA6D;AAAA;AAAA;AAAA;AAAA;AAAA,YAKzFA,IAAqB,EAAI,GAAK,2CAA2C;AAAA,WAG1E;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAMCA,IAAqB,EAAI,GAAK,yCAAyC;AAAA,WAKtEf,GACT,CAACgB,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,KAAe,CACpF,IAAMC,EAAaL,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CO,EAAaN,EAAc,CAAC,EAAID,EAAc,CAAC,EAC/CQ,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EACtCP,EAAmBS,EAAaP,EAAc,CAAC,EAC/CS,EAAgBP,EAAYF,EAAc,CAAC,EAEjD,GAAI,GAAIH,GAAcC,IAAqB,GAAKC,EAAc,CAAC,IAAM,GAC7D,CAACF,IAAeC,IAAqB,GAAKA,IAAqB,KACjES,EAAaP,EAAc,CAAC,IAAM,GAAKE,EAAYF,EAAc,CAAC,IAAM,GAAKD,EAAc,CAAC,IAAM,GACtG,MAAM,IAAI,MAAM,iBAAiBF,CAAU,8BACvCC,CAAgB,yBAAyBC,EAAc,CAAC,CAAC;AAAA,oCACjCD,CAAgB;AAAA,eACrCS,CAAU,yCAAyCP,EAAc,CAAC,CAAC,eACtEE,CAAS,0CAA0CF,EAAc,CAAC,CAAC,kBACnED,EAAc,CAAC,CAAC,aAAa,EAEnC,MAAO;AAAA,yCAC4BD,CAAgB,IAAIG,CAAI,MAAMM,EAAaT,CAAgB,MAAMU,CAAU;AAAA,2CACzEP,CAAI,MAAMK,EAAaP,EAAc,CAAC,CAAC,MAAMG,CAAS;AAAA;AAAA,uBAE1EH,EAAc,CAAC,CAAC;AAAA,uBAChBA,EAAc,CAAC,CAAC;AAAA,2BACZD,CAAgB;AAAA,oBACvBI,CAAS;AAAA;AAAA,2BAEFF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAUrEG,EAAS,IAAM,iBAAiB;AAAA,IAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,8CACvCS,CAAU;AAAA;AAAA,mBAErCF,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,gCAAgC;AAAA,iBACzFC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,wBAE9CH,CAAI;AAAA;AAAA;AAAA,8BAGEQ,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAM/B5B,GAA2BgB,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,0CAInBa,CAAa;AAAA;AAAA;AAAA,sFAI7Cb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAU/BE,IAAqB,EAAI,GAAK,4DAA4D;AAAA;AAAA,YAE1FhB,GAAuBe,EAAYC,CAAgB,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAU5D,EAEEd,GAAyB,CAACW,EAAoBC,IAC9CD,EACK;AAAA;AAAA;AAAA,yCAG8BC,EAAY,iBAAmB,EAAE;AAAA,cAI/D;AAAA;AAAA;AAAA,iCAGsBA,EAAY,iBAAmB,EAAE;AAAA,cAK5DX,GAA2BY,GAC7BA,EAAa,gDAAkD,gDAItDX,GACT,CAACa,EAAyBC,EAAyCC,EAAO,MAAOL,EAChFC,EAAa,GAAOK,EAAY,GAAIC,EAAS,GAAOC,EAAkB,GACtEM,EAA4B,KAAkB,CAC7C,IAAML,EAAaN,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CM,EAAaP,EAAc,CAAC,EAAIC,EAAc,CAAC,EAC/CO,EAAaV,EAAaQ,EAAaH,EACvCM,EAAaX,EAAaK,EAAYG,EAE5C,GAAI,EAAEG,EAAaR,EAAc,CAAC,IAAM,GAAKO,EAAaP,EAAc,CAAC,IAAM,GACzEE,EAAYF,EAAc,CAAC,IAAM,GACrC,MAAM,IAAI,MAAM,cAAcQ,CAAU,yCACpCR,EAAc,CAAC,CAAC,gBAAgBO,CAAU,yCAC1CP,EAAc,CAAC,CAAC,eAAeE,CAAS,yCAAyCF,EAAc,CAAC,CAAC,EAAE,EAEzG,IAAMW,EAAgBH,EAAaR,EAAc,CAAC,EAC5CY,EAAgBL,EAAaP,EAAc,CAAC,EAC5CS,EAAgBP,EAAYF,EAAc,CAAC,EAC3Ca,EAAgBH,EAClB;AAAA;AAAA;AAAA,gDAGsCL,CAAU;AAAA,gDACVC,CAAU;AAAA;AAAA;AAAA;AAAA;AAAA,iDAKTE,CAAU,2BAA2BR,EAAc,CAAC,CAAC;AAAA,mDACnDO,CAAU,2BAA2BP,EAAc,CAAC,CAAC;AAAA,YAC5FhB,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA,iDAIRM,CAAS,2BAA2BF,EAAc,CAAC,CAAC;AAAA,uDAC9CM,CAAU,2BAA2BN,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,uCAGrEJ,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAO5CK,CAAI;AAAA;AAAA;AAAA,2DAG2BD,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA,0BAI7DH,EAAa,oCAAoCG,EAAc,CAAC,CAAC,KACpD,iCAAiCA,EAAc,CAAC,CAAC,OAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0DAUzBA,EAAc,CAAC,CAAC;AAAA;AAAA,4DAEdA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,MAKlE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4CAMkCK,CAAU;AAAA;AAAA,kCAEpBM,CAAa;AAAA,kCACbC,CAAa;AAAA,kCACbH,CAAa;AAAA;AAAA;AAAA;AAAA,sCAITE,CAAa;AAAA,wCACXC,CAAa;AAAA;AAAA;AAAA,QAG7C5B,GAAuBa,EAAYD,CAAS,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,sCAKfa,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8BAMrBb,EAAY,iBAAmB,EAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAOvCK,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOpBhB,GAAwBY,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAkBrC,MAAO;AAAA,yCAC4BI,CAAI,KAAKM,CAAU,MAAMC,CAAU;AAAA,yCACnCP,CAAI,KAAKK,CAAU,MAAMJ,CAAS;AAAA,yBAClDH,EAAc,CAAC,CAAC;AAAA,yBAChBA,EAAc,CAAC,CAAC;AAAA,sBACnBG,CAAS;AAAA;AAAA,2BAEJF,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC,KAAKA,EAAc,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,kBAInEG,EAAS,IAAM,iBAAiB;AAAA,MAC5CP,EAAY,sBAAsBA,EAAU,gBAAgB,YAAY,CAAC,IAAM,EAAE;AAAA,qBAClEO,EAAS,GAAG,KAAK,KAAKC,EAAkBF,CAAS,CAAC,GAAK,gCAAgC;AAAA,mBACzFC,EAAS,qBAAqBC,CAAe,GAAK,GAAG;AAAA;AAAA,4BAE5CH,CAAI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQ1BY,CAAa;AAAA;AAAA,CAGf,EAEE1B,GACF,CAAC2B,EAAmBC,EAAkBC,EAAyBC,EAC9DC,EAAuCC,EAAiB,KAAkB,CACzE,IAAMC,EAAcF,EAAY,CAAC,EAC3BG,EAAcH,EAAY,CAAC,EAC3BI,EAAaJ,EAAY,CAAC,EAC1BK,EAAgBN,EAAU,CAAC,EAC3BO,EAAYP,EAAU,CAAC,EACvBQ,EAAYR,EAAU,CAAC,EACvBS,EAAiBT,EAAU,CAAC,EAC5BU,EAAiBC,GAAiBR,EAAaE,CAAU,EACzDO,EAAiBD,GAAiBP,EAAaC,CAAU,EACzDQ,EAAWC,GAA4Bd,EAAU,CAAC,EAAE,KAAK,MAAM,EAC/De,EAAc,IAAM,CACxB,IAAMC,EAAQT,EAAU,KAClBU,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBX,EAAU,KAAK,OAAO,IACpD,QAASY,EAAIH,EAAQ,EAAI,EAAGI,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAV,EAAe,QAAQS,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcF,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBE,CACT,EACMG,EAAc,IAAM,CACxB,IAAMC,EAAQd,EAAU,KAClBS,EAAYX,EAAc,KAC5BY,EAAS,iBAAiBV,EAAU,KAAK,OAAO,IACpD,QAASW,EAAIG,EAAQ,EAAI,EAAGF,EAAIH,EAAY,EAAGE,GAAK,EAAGA,IAAKC,IAC1DF,GAAU;AAAA,WAAcC,CAAC,OAAOF,EAAY,EAAI,gBAAgBG,CAAC,IAAM,cAAc,IAEvF,OAAAR,EAAe,QAAQO,GAAK,CAC1BD,GAAU;AAAA,WAAcC,CAAC,QAC3B,CAAC,EACDD,GAAU;AAAA,WAAcI,EAAQ,CAAC;AAAA,8BACXA,EAAQ,CAAC,kBACxBJ,CACT,EAwCA,MAvCe;AAAA,kEAC6CZ,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBkB,EAAY,CAAC;AAAA,kBACLR,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kEAKcD,EAAc,KAAK,OAAO,QAClFiB,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,oBACtBU,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BAC1BhB,CAAS;AAAA;AAAA;AAAA,UAGzBwB,EAAY,CAAC;AAAA,kBACLb,EAAU,aAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,6DAKSe,GAAY1B,EAAWgB,CAAQ,CAAC;AAAA,0BACnEhB,CAAS;AAAA;AAAA;AAAA;AAAA,UAKzBC,EACI,mBAAmBI,EAAiB,cAAgB,GAAGqB,GAAY1B,EAAWgB,CAAQ,CAAC,aAAa,IAChE,EAAsC;AAAA,UAC9Ed,CAAe;AAAA,UACfU,EAAe,aAAa,oBAAqB,OAAO,CAAC;AAAA;AAAA;AAAA,KAK/D,EAEStC,GACT,CAACqD,EAA+BC,EAAoDC,EACnFC,EACAzB,EAAiB,KAAyD,CACzE,IAAM0B,EAASJ,EAAO,CAAC,EAAE,KACnBK,EAASL,EAAO,CAAC,EAAE,KAEnBM,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAaF,EAAO,MAAM,EAAG,EAAE,EAC/BG,EAAYL,EAAsBA,EAAoB,MAAM,EAAG,EAAE,EAAID,EAAY,MAAM,EAAG,EAAE,EAC5F/C,EAAYsD,EAAc,YAAaT,EAAO,CAAC,EAAE,SAAUQ,CAAS,EACpEhC,EAAY,CAACrB,CAAS,EACtBsB,EAAc,CAAC6B,EAAYC,EAAYC,CAAS,EAChDE,EAAYC,EAAU,KAAKH,CAAS,EAEpCI,EAAYR,EAAOA,EAAO,OAAS,CAAC,EACpCS,EAAWT,EAAOA,EAAO,OAAS,CAAC,EACnCU,EAAYT,EAAOA,EAAO,OAAS,CAAC,EACpCU,EAASF,EAAW,IAAM,GAAKC,EAAY,IAAM,EAGjDE,EAAoBJ,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDrD,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClD0D,EAAW,CACf,KAAK,KAAKH,EAAYvD,EAAc,CAAC,EAAIyD,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKJ,EAAYrD,EAAc,CAAC,EAAIyD,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKN,EAAYnD,EAAc,CAAC,EAAIyD,EAAkB,CAAC,CAAC,CAC/D,EAEM3B,EAAWC,GAA4BU,EAAO,CAAC,EAAE,QAAQ,EACzDkB,EAAaH,EAAS,EAAI,EAC1BI,EAAIV,EAAc,IAAKT,EAAO,CAAC,EAAE,SAAU,CAAC,GAAGM,EAAYM,EAAWC,EAAWK,CAAU,EAAGA,CAAU,EACxGE,EAAIX,EAAc,IAAKT,EAAO,CAAC,EAAE,SAAU,CAAC,GAAGO,EAAYM,EAAUC,EAAYI,CAAU,EAAGA,CAAU,EACxGG,GACFpC,EAAe,SAAUe,EAAO,CAAC,EAAE,SAAU,CAACU,EAAWE,EAAWE,EAAYI,CAAU,EAAGA,CAAU,EAC3G1C,EAAU,KAAK2C,CAAC,EAChB3C,EAAU,KAAK4C,CAAC,EAChB5C,EAAU,KAAK6C,EAAM,EACrB,IAAMC,GAAiB,CAACH,EAAGC,CAAC,EACtB9C,EAAU0B,EAAO,OAAS,EAC1B,CAAC,mBAAAuB,GAAoB,gBAAAhD,EAAe,EAAIiD,GAAqBvB,EAAsBoB,GAAO,KAAK,KAAK,EACpGI,EACF/E,GAAwBwE,EAAY5C,EAASC,GAAiBC,EAAWC,EAAaC,CAAc,EACxG,GAAIJ,EAAS,CACX,IAAMoD,GAAiBhD,EAAiBwC,EAAa,EACrDI,GAAe,KAAKb,EAAc,OAAQT,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM0B,EAAc,CAAC,CAC/F,CACA,IAAMC,GAAmBC,IAA+B;AAAA,2BACnChB,CAAS;AAAA,2BACTE,CAAS;AAAA,0BACVD,CAAQ;AAAA,IAC9Be,GAAa,iBAAiB,GAAGN,GAAgBD,EAAM,CAAC;AAAA,IACxDE,EAAkB;AAAA,IAClBE,CAAgB;AAAA,IAEVV,EAASzE,GAA2B0E,EAAmBzD,EAAe8B,EAAUlC,CAAS,EAChFV,GAAuBuE,EAAmBzD,EAAe8B,EAAUlC,CAAS,CAAC;AAAA,qBAC3EA,EAAU,KAAK,CAAC,GAC/B,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM8C,EAAqB,kBAAkB,EAC3D,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUF,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAAU,EACF,CACF,IC1eJ,IAiCME,GA6HOC,GA9JbC,GAAAC,EAAA,kBAqBAC,KAEAC,KAEAC,KAEAC,KAEAC,KACAC,KACAC,KAEMV,GACF,CAACW,EAAyBC,EAAoBC,EAAoBC,EAAmBC,EAAU,GAC9FC,EAA4BC,EAAoB,EAAGC,EAAoB,EAAGC,EAAmB,EAC7FC,EAAW,QAAkB,CAC5B,IAAMC,EAAeF,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,uBACT,IAAK,GACH,MAAO,kBAAkBC,CAAQ,8CACnC,IAAK,GACH,MAAO,2BACT,QACE,MAAM,IAAI,MAAM,oBAAoBD,CAAgB,oBAAoB,CAC5E,CACF,EACMG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,qCACT,IAAK,GACH,MAAO,yCACT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBZ,EAAiB;AAAA;AAAA,MAGA;AAAA;AAAA,MAIjCa,EAAkBb,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCc,EAAUd,EAAiB,YAAc,YACzCe,EAASf,EAAiB,YAAc,YACxCgB,EAAMhB,EAAiB,MAAQ,MAC/BiB,EAAMjB,EAAiB,MAAQ,MAC/BkB,EAAe;AAAA;AAAA,qBAENlB,EAAiB,cAAgB,aAAa;AAAA,mBAChDgB,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA,iBAELC,CAAG;AAAA,iBACHA,CAAG;AAAA;AAAA;AAAA,gBAGJA,CAAG;AAAA,oBACCE,GAAYb,EAAmBG,CAAQ,CAAC;AAAA;AAAA;AAAA,8BAG9BK,CAAO,2BAA2BC,CAAM;AAAA,QAC9DH,CAAa;AAAA;AAAA,QAEbF,EAAYJ,CAAiB,CAAC;AAAA;AAAA,qBAI1Bc,EAAUpB,EAAkBC,GAAaE,EAAW;AAAA,wBACxCG,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SACbN,GAAYD,EAAY;AAAA,wBACxCI,CAAiB;AAAA,MACnCY,CAAY,GAC8C;AAAA,wBACxCZ,CAAiB;AAAA;AAAA,QAEjCY,CAAY;AAAA;AAAA,aAEPC,GAAYb,EAAmBG,CAAQ,CAAC,SAEzCY,EAAU,GAAGV,EAAYJ,CAAiB,CAAC,GAE3Ce,EAAUH,GAAYX,EAAkBC,CAAQ,EAChDc,EACFvB,EAAiBmB,GAAYb,EAAmBG,CAAQ,EAAIU,GAAYZ,EAAmBE,CAAQ,EACjGe,EACFxB,EAAiBmB,GAAYZ,EAAmBE,CAAQ,EAAIU,GAAYb,EAAmBG,CAAQ,EACjG,CAAC,mBAAAgB,EAAoB,gBAAAC,EAAe,EAAIC,GAAqBtB,EAAYiB,CAAO,EAuBtF,MAtBiB;AAAA,MACjBG,CAAkB;AAAA,yDACiCF,CAAK;AAAA,QACtDvB,EAAiBoB,EAAUC,CAAO;AAAA;AAAA;AAAA,yDAGeG,CAAK;AAAA,QACtDxB,EAAiBqB,EAAUD,CAAO;AAAA;AAAA;AAAA,gEAGsBE,CAAO;AAAA,0BAC7Cd,CAAgB;AAAA;AAAA;AAAA;AAAA,uBAInBR,EAAiB,cAAgB,aAAa;AAAA,QAC7Da,CAAe;AAAA,QACfe,GAAYxB,CAAO,CAAC;AAAA,QACpBsB,EAAe;AAAA;AAAA;AAAA,MAKnB,EAESpC,GACT,CAACuC,EAA+BxB,EAA4ByB,EAAgCC,EAC3FC,EAAmBC,EAAkBC,EAAkBC,IAAoD,CAC1G,IAAMnC,EAAiBK,EAAW,SAAW,OACvC+B,EAAapC,EAAiB6B,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClEQ,EAAYP,EAAY,CAAC,EACzBQ,EAAWtC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAYvC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAcxC,EAAiB8B,EAAY,CAAC,EAAIA,EAAY,CAAC,EAE7DW,EAASzC,IAAmBoC,EAAa,IAAM,GAAKA,EAAa,IAAM,IAAMI,EAAc,IAAM,EAGjGE,EAAY1C,EAAiBwC,EAAcF,EAAWC,EACtDI,EAAY3C,EAAiBsC,EAAWC,EAAYC,EACpDI,EAA0C,CAAC,EAAG,EAAG,CAAC,EAClDC,EAAoBd,GAAa,EAAI,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EACzDe,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,iCAAiCD,CAAQ,EAAE,EAEtE,IAAMtC,EAAmBiC,EAAUzC,GAAkBoC,EAAa,IAAM,EAAI,EAAI,EAAKS,EAAkB,CAAC,EAElGG,EAAaJ,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDI,EAAaL,EAAc,CAAC,EAAIC,EAAkB,CAAC,EACnDK,EAAY,KAAK,IAAIN,EAAc,CAAC,EAAIpC,EAAkBoC,EAAc,CAAC,CAAC,EAE1E3C,EAAY8B,EAAYiB,IAAe,EACvC9C,GAAY8B,EAAYiB,IAAe,EACvC9C,GAAW8B,EAAWiB,IAAc,EAEpCC,EAAeV,EAAS,CAACjC,EAAkB,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,CAAC,EAC3D4C,GAAIC,GAA4BxB,EAAO,CAAC,EAAE,QAAQ,EAElDyB,GAAgB,CACpB,qDAAqDb,GAAUjC,IAAqB,EAAI,QAAQ4C,EAAC,IAAMA,EAAC,KACxG,qDAAqDX,EAAS,QAAQW,EAAC,IAAMA,EAAC,IAChF,EACIG,EAAmB;AAAA,qDACwBd,EAAS,QAAQW,EAAC,IAAMA,EAAC;AAAA,8BAChDX,EAAS,QAAQW,EAAC,IAAMA,EAAC;AAAA;AAAA,6EAEsBX,EAAS,QAAQW,EAAC,IAAMA,EAAC;AAAA;AAAA,qCAEjEX,EAAS,MAAQ,EAAE;AAAA,SAElD,OAAIP,IACFoB,GAAc,KAAK,wDAAwDb,EAAS,QAAQW,EAAC,IAAMA,EAAC,IAAI,EACxGG,GAAoB;AAAA,0DAC8Bd,EAAS,QAAQW,EAAC,IAAMA,EAAC;AAAA,+BACpDpD,EAAiB,IAAM,GAAG,GAAGyC,EAAS,MAAQ,EAAE;AAAA,YAIlE,CACL,KAAM,eACN,YAAa,CAAC,KAAMpC,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMyB,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAiB,IAAM;AAAA,UACrBU,EAAa;AAAA;AAAA;AAAA;AAAA,UAIbF,GAAc,KAAK,EAAE,CAAC;AAAA,6BACHA,GAAc,MAAM,4CACrCb,EAAS,QAAQW,EAAC,IAAMA,EAAC;AAAA,+BACNE,GAAc,OAAS,CAAC;AAAA;AAAA,+CAERzB,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CACxBA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,iDACtBC,EAAY,KAAK,GAAG,CAAC;AAAA,wDACd2B,EAAU,eAAe3B,CAAW,EAAE,MAAM,EAAG,CAAC,EAAE,KAAK,GAAG,CAAC;AAAA,mDAChEzB,EAAW,YAAY,CAAC,CAAC,KAAKA,EAAW,YAAY,CAAC,CAAC;AAAA,4CAC9DA,EAAW,KAAK,CAAC,CAAC,KAAKA,EAAW,KAAK,CAAC,CAAC;AAAA,+CACtCA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC7CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClE0B,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/BsB,CAAgB;AAAA,UAEdlE,GACIW,EAAgBC,EAAWC,GAAWC,GAAU+B,EAAS7B,EAAY8C,EAAa,CAAC,EAAGA,EAAa,CAAC,EACpGA,EAAa,CAAC,EAAGC,EAAC,CAAC;AAAA,cAEvBX,EACIiB,GAA2Bb,EAAmBD,EAAeQ,GAAG,OAAW,CAACpD,EAAgBkD,CAAS,EACrGS,GACId,EAAmBD,EAAeQ,GAAG,OAAW,CAACpD,EAAgBkD,EAAW,GAAO,OACnFf,CAAyB,CAAC,EACxC,CACF,IChQJ,IAeayB,GAfbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KACAC,KAMaN,GACT,CAACO,EAA+BC,EAC/BC,IAAqF,CACpF,IAAMC,EAAUH,EAAO,OAAS,EAC1BI,EAAcD,EAAU,8BAAgC,GACxDE,EAASL,EAAO,CAAC,EAAE,KACnBM,EAASN,EAAO,CAAC,EAAE,KACnBO,EAAyBD,EAAO,CAAC,EAAIL,EAAW,MAEhDO,EAAgBP,EAAW,SAAW,OACtCQ,EAAcC,GAChBL,EAAQC,EAAQL,EAAW,UAAWA,EAAW,KAAMA,EAAW,QAASO,CAAa,EACtFG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAASC,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAUS,CAAW,EACjE,CAAC,mBAAAM,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBhB,EAAYY,EAAO,KAAK,KAAK,EAC1F,EAAIK,EAAc,IAAKlB,EAAO,CAAC,EAAE,SAAUK,CAAM,EACjDc,EAAID,EAAc,IAAKlB,EAAO,CAAC,EAAE,SAAUM,CAAM,EACjDc,EAAY,CAAC,EAAGD,CAAC,EACnBhB,GACFiB,EAAU,KAAKF,EAAc,IAAKlB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,CAAC,EAGvE,IAAMqB,EAAmBC,GAA+B;AAAA,oCAC1BrB,EAAW,QAAQ,CAAC,CAAC,MAAMA,EAAW,QAAQ,CAAC,CAAC;AAAA,iCACnDA,EAAW,KAAK,CAAC,CAAC,MAAMA,EAAW,KAAK,CAAC,CAAC;AAAA;AAAA,IAEvEqB,EAAa,iBAAiB,GAAGF,EAAWP,CAAM,CAAC;AAAA;AAAA,IAEnDE,CAAkB;AAAA;AAAA,IAElBO,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCX,CAAU,CAAC;AAAA;AAAA,0BAE1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,8CAEhBL,EAAgB,EAAI,CAAC;AAAA,yDACVA,EAAgB,EAAI,CAAC,oBACpEA,EAAgB,EAAI,CAAC;AAAA,2CACYD,CAAsB;AAAA;AAAA,iBAEhDM,EAAO,KAAK,KAAK,MAAMA,EAAO,KAAK,KAAK;AAAA,kDACPP,EAAO,CAAC,CAAC;AAAA,uCACpBA,EAAO,CAAC,CAAC;AAAA,8CACFA,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,yCAE9BI,EAAOG,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,8CAIxBF,EAAO,CAAC,CAAC;AAAA,gDACPL,EAAW,UAAU,CAAC,CAAC;AAAA,yCAC9BI,EAAOG,EAAgB,EAAI,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAK5DA,EAAgB,EAAE,IAAI,QAAS,UAAW,SAAU,eAAe,EACnD,EAAE,IAAI,QAAS,gBAAiB,UAAW,QAAQ,CAAC;AAAA,uBACvDW,EAAE,IAAI,iBAAkB,aAAc,UAAW,QAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,MAK3Ef,CAAW;AAAA,MACXY,CAAe;AAAA,MACfH,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,KAEzC,MAAO,CACL,KAAM,cACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CACR,KAAMC,EAA6BA,EAA2BO,CAAW,EAAIA,EAC7E,SAAUT,EAAO,CAAC,EAAE,QACtB,CAAC,EACD,cAAe,CAAC,EAAG,KAAK,KAAKW,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAU,CACF,CACF,IChGJ,IAcaE,GA6BPC,GAEAC,GAmDAC,GAmBOC,GAgBPC,GAsGAC,GA0BOC,GAnQbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KACAC,KACAC,KACAC,KACAC,KAEahB,GACT,CAACiB,EAA+BC,EAAgCC,EAC/DC,EAA+BC,EAA4BC,IAAqC,CAC/F,IAAMC,EAAYN,EAAW,CAAC,EACxBO,EAAoBP,EAAW,MAAMK,EAAgB,EAAI,EAAGA,EAAgB,EAAI,CAAC,EACjFG,EAAcD,EAAkB,OAChCE,EAAcR,EAAY,CAAC,EAE3BS,EADqBT,EAAY,MAAM,CAAC,EACA,IAAI,CAACU,EAAGC,IAAMD,GAAKA,EAAI,IAAMT,EAAUU,CAAC,EAAI,EAAE,EAEtFC,EAD2BN,EAAkB,IAAI,CAACI,EAAGC,IAAMD,EAAIR,EAAWS,CAAC,EAAIT,EAAWS,EAAIJ,CAAW,CAAC,EAEnF,IAAI,CAACG,EAAGC,IAAM,KAAK,OAAOD,EAAID,EAAmBE,CAAC,EAAIR,EAAQQ,CAAC,GAAKR,EAAQQ,CAAC,CAAC,CAAC,EAC5G,OAAAC,EAAY,OAAO,EAAG,EAAGP,CAAS,EAClCO,EAAY,OAAOR,EAAgB,EAAI,EAAG,EAAGI,CAAW,EACjDI,CACT,EAcE7B,GAA2B,CAAC,EAAG,EAAG,EAAG,CAAC,EAEtCC,GAAiB,CAAC6B,EAA+BC,IAAqC,CAG1F,GAAI,CAACD,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,uCAAuC,EAGzD,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAME,EAAcF,EAAO,CAAC,EAAE,KAAKC,EAAW,SAAW,OAASD,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFG,EAAkBH,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIC,EAAW,MACvD,GAAIC,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAIrE,GAAIH,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAC/F,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMN,EAAcM,EAAO,CAAC,EAAE,KAAK,OAAS,EAE5C,GAAIC,EAAW,UAAU,SAAWP,EAClC,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAIvD,GAAIO,EAAW,QAAQ,SAAWP,EAChC,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAIrD,GAAIO,EAAW,KAAK,SAAWP,EAAc,EAC3C,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAKtD,GAAIO,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWD,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAEM5B,GAA4B,CAA2B6B,EAAeD,IAAqC,CAC/G,IAAMb,EAAcc,EAAW,YAAY,MAAM,EAEjD,QAASH,EAAI,EAAGA,EAAIE,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEF,EACvCX,EAAYW,EAAI,CAAC,IAAM,IACzBX,EAAYW,EAAI,CAAC,EAAIE,EAAO,CAAC,EAAE,KAAKF,CAAC,GAGzC,IAAMM,EAAOH,EAAW,KAAK,MAAM,EACnCI,GAAa,yBACTL,EAAO,CAAC,EAAE,KAAMC,EAAW,QAASA,EAAW,UAAWd,EAAaiB,EAAMH,EAAW,SAAW,OACnGA,EAAW,OAAO,EAGtB,IAAMK,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EACrD,cAAO,OAAOK,EAAe,CAAC,YAAAnB,EAAa,KAAAiB,EAAM,SAAUH,EAAW,QAAQ,CAAC,EACxEK,CACT,EAEajC,GAAuB4B,GAAwD,CAC1F,IAAMM,EAAuBC,GAAkCP,CAAU,EAEnEQ,EAASR,EAAW,OACpBS,EAAU,CAAC,SAAU,QAAS,aAAc,YAAY,EAAET,EAAW,QAAkB,EACvFb,EAAYa,EAAW,UACvBU,EAAQV,EAAW,MACnBd,EAAcc,EAAW,aACzBG,EAAOH,EAAW,KAClBX,EAAUW,EAAW,QACrBW,EAAYX,EAAW,WAA6B,EAE1D,OAAOY,GACH,CAAC,QAAAH,EAAS,OAAAD,EAAQ,UAAArB,EAAW,MAAAuB,EAAO,YAAAxB,EAAa,KAAAiB,EAAM,QAAAd,EAAS,SAAAsB,EAAU,GAAGL,CAAoB,CAAC,CACxG,EAEMjC,GAAS,CAACwC,EAAyBd,EAA+BC,IAAqC,CAC3G,IAAMc,EAAqB3C,GAA0B6B,EAAYD,CAAM,EAKvE,GAAIC,EAAW,QAAU,EAAG,CAC1Ba,EAAQ,QAAQE,GAA6BhB,EAAQe,CAAkB,CAAC,EACxE,MACF,CAEA,IAAME,EAAiBhB,EAAW,SAAW,OACvCiB,EAAUlB,EAAO,SAAW,EAC5BmB,EAAcnB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACnDG,EAAapB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EAClDI,EAAgBrB,EAAO,CAAC,EAAE,KAAKiB,EAAiB,EAAI,CAAC,EACrDK,EAAetB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BuB,EAAcvB,EAAO,CAAC,EAAE,KAAK,CAAC,EAE9BD,EAAc9B,GAChB+B,EAAO,CAAC,EAAE,KAAMA,EAAO,CAAC,EAAE,KAAMC,EAAW,UAAWc,EAAmB,KAAMd,EAAW,QAC1FgB,CAAc,EACZO,EAAYzB,EAAYkB,EAAiB,EAAI,CAAC,EAC9CQ,EAAW1B,EAAYkB,EAAiB,EAAI,CAAC,EAC7CtB,EAAcI,EAAYkB,EAAiB,EAAI,CAAC,EAEhDS,EAAWT,GAAkBK,IAAiBH,GAAeI,IAAgBH,GAC/EnB,EAAW,KAAK,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,EACvD,GAAIyB,GACCJ,IAAiB,GAAKC,IAAgB,GAAKtB,EAAW,UAAU,CAAC,IAAM,GAAKA,EAAW,UAAU,CAAC,IAAM,GACxGA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,QAAQ,CAAC,IAAM,GAAKA,EAAW,KAAK,CAAC,IAAM,GACrFA,EAAW,KAAK,CAAC,IAAM,EAAI,CAE9B,IAAM0B,EAAQ5B,EAAY,CAAC,EACvB6B,EAAWC,EAAWC,GACpBC,GAAe,CAAC,EACtB,GAAId,EAAgB,CAClB,IAAMe,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG9B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC+B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAIlE,GAHIA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAE5BN,EAAU,CACZ,IAAMQ,GAAYf,EAAcC,EAAaC,EAC7CO,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAG2B,EAAOO,EAAS,CAAC,EACnDL,EAAYG,EAAiB,QAAQ,CAAC,EAAGE,GAAWvC,CAAW,CAAC,EAChEmC,GAAoB,CAAC,EAAGH,EAAOhC,CAAW,CAC5C,MACEiC,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAOR,EAAcC,EAAYC,CAAa,CAAC,EAC9EQ,EAAYG,EAAiB,QAAQ,CAAC,EAAGX,EAAe1B,CAAW,CAAC,EACpEmC,GAAoB,CAACH,EAAOH,EAAYC,EAAU9B,CAAW,EAE/DoC,GAAa,KAAKH,CAAS,EAC3BG,GAAa,KAAKF,CAAS,CAC7B,MACED,EAAY5B,EAAO,CAAC,EAAE,QAAQ,CAAC2B,EAAON,EAAeF,EAAcC,CAAU,CAAC,EAC9ES,EAAY7B,EAAO,CAAC,EAAE,QAAQ,CAAC,EAAGL,EAAa0B,CAAa,CAAC,EAC7DS,GAAoB,CAACH,EAAOhC,EAAa6B,EAAYC,CAAQ,EAC7DM,GAAa,KAAKF,CAAS,EAC3BE,GAAa,KAAKH,CAAS,EAEzBV,GACFa,GAAa,KAAK/B,EAAO,CAAC,CAAC,EAE7Bc,EAAQ,QACJqB,GAAwBJ,GAAchB,EAAoBhB,EAAa+B,GAAmBb,CAAc,EACxG,CAAC,OAAQc,EAAY,CAAC,EAC1B,MACF,CAIA,IAAMK,EAAgE,GAGhEJ,EAAoBlB,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJmB,GAA2BjC,EAAO,CAAC,EAAG9B,EAAwB,EAC9D,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAAC+B,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACa,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKkB,GAIhC,IAAMK,EAAa,CAACrC,EAAO,CAAC,EAAGgC,CAAgB,EAC3Cd,GACFmB,EAAW,KAAKrC,EAAO,CAAC,CAAC,EAI3B,IAAMsC,EAAYrB,EAAiBO,EAAYC,EAAW9B,EACpD4C,EAAYtB,EAAiBtB,EAAc6B,EAAYC,EACvDe,EAAWlB,EAAeC,EAAcF,EAC9CP,EAAQ,QACJ2B,GACIJ,EAAYtB,EAAoBhB,EAAauC,EAAWC,EAAWC,EAAUtB,EAC7EkB,CAAyB,EAC7B,CAAC,OAAQC,CAAU,CAAC,CAC1B,EAEM9D,GAAS,CAACuC,EAAyBb,IAAqC,CAE5E,IAAMV,EAAgBU,EAAW,SAAW,OACtCD,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdvB,EAEI,CAACuB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACIA,EAAQ,OAAO,SAAW,GAC5Bd,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAMV,EAAO,CAAC,EAAGH,EAAW,KAAK,CAAC,EAAG,EAAGA,EAAW,KAAK,CAAC,CAAC,EACpDX,EAAU,CAAC,CAAC,EAAE,OAAOW,EAAW,OAAO,EACvCb,EAAY,CAAC,CAAC,EAAE,OAAOa,EAAW,SAAS,EAC3Cd,EAAc,CAAC,CAAC,EAAE,OAAOc,EAAW,WAAW,EAC/Cc,EAAqB3C,GAA0B,CAAC,GAAG6B,EAAY,KAAAG,EAAM,QAAAd,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGa,CAAM,EACnHc,EAAQ,QAAQE,GACZhB,EAAQe,EACRhB,GAAeR,EAAgB,CAACQ,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAAI,CAAC,CAAC,CAAC,CAC3F,EAEavB,GAAO,CAACsC,EAAyBb,IAAqC,CACjF9B,GAAe2C,EAAQ,OAAQb,CAAU,EACrCa,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCvC,GAAOuC,EAASb,CAAU,EAE1B3B,GAAOwC,EAASA,EAAQ,OAAQb,CAAU,CAE9C,IC1QA,IAgCMyC,GA4HOC,GA5JbC,GAAAC,EAAA,kBAqBAC,KAEAC,KAGAC,KAEAC,KACAC,KACAC,KAEMT,GACF,CAACU,EAAyBC,EAAU,GAAOC,EAAqCC,EAAmB,IAAc,CAC/G,IAAMC,EAAOC,GAAYF,EAAkB,KAAK,EAC1CG,EAAeH,GAA6B,CAChD,OAAQA,EAAkB,CACxB,IAAK,GACH,MAAO,iDACT,IAAK,GACH,MAAO;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAUT,QACE,MAAM,IAAI,MAAM,oBAAoBA,CAAgB,oBAAoB,CAC5E,CACF,EACMI,EAAgBP,EAAiB;AAAA;AAAA,QAGA;AAAA;AAAA,QAIjCQ,EAAkBR,EAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQnCS,EAAUT,EAAiB,iBAAmB,iBAC9CU,EAASV,EAAiB,iBAAmB,iBAC7CW,EAAMX,EAAiB,MAAQ,MAC/BY,EAAMZ,EAAiB,MAAQ,MAE/Ba,EAAe;AAAA,yBACFb,EAAiB,iBAAmB,gBAAgB;AAAA,uBACtDA,EAAiB,cAAgB,aAAa;AAAA,qBAChDW,CAAG;AAAA,qBACHA,CAAG;AAAA;AAAA,mBAELC,CAAG;AAAA,mBACHA,CAAG;AAAA;AAAA;AAAA,kCAGYH,CAAO;AAAA,iBACxBL,CAAI;AAAA;AAAA,kCAEaM,CAAM;AAAA,iBACvBN,CAAI;AAAA;AAAA;AAAA;AAAA,kBAIHQ,CAAG;AAAA,QACbL,CAAa;AAAA,qDACgCJ,CAAgB,KAEzDW,EAAUd,EAAiB;AAAA,0BACbG,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SACoB;AAAA,0BACbD,CAAgB;AAAA;AAAA,UAEhCU,CAAY;AAAA;AAAA,eAEPT,CAAI,SAEPW,EAAU;AAAA,0BACIZ,CAAgB;AAAA,yBACjBH,EAAiB,iBAAmB,gBAAgB;AAAA;AAAA;AAAA,YAInEA,EAAiB,oCACA,mCAAmC;AAAA;AAAA;AAAA,UAGpDM,EAAYH,CAAgB,CAAC;AAAA;AAAA,eAExBC,CAAI;AAAA,QAGP,CAAC,mBAAAY,EAAoB,gBAAAC,CAAe,EAAIC,GAAqBhB,EAAYE,CAAI,EAsBnF,MArBiB;AAAA,QACfY,CAAkB;AAAA,uDAC6BZ,CAAI;AAAA,MACrDJ,EAAiBc,EAAUC,CAAO;AAAA;AAAA;AAAA,uDAGeX,CAAI;AAAA,MACrDJ,EAAiBe,EAAUD,CAAO;AAAA;AAAA;AAAA,iEAGyBV,CAAI;AAAA,wBAC7CD,CAAgB;AAAA;AAAA;AAAA,uBAGjBH,EAAiB,cAAgB,aAAa;AAAA,QAC7DQ,CAAe;AAAA,QACfW,GAAYlB,CAAO,CAAC;AAAA,QACpBgB,CAAe;AAAA,sDAC+Bd,CAAgB;AAAA;AAAA,IAIlE,EAESZ,GACT,CAAC6B,EAA+BlB,EAAqCmB,EACpEC,EAAmBC,EAAmBC,EAAkBC,EACxDC,IAAoD,CACnD,IAAM1B,EAAiBE,EAAW,SAAW,OACvCyB,EAAa3B,EAAiBoB,EAAO,CAAC,EAAE,KAAK,CAAC,EAAIA,EAAO,CAAC,EAAE,KAAK,CAAC,EAClEQ,EAAYP,EAAY,CAAC,EACzBQ,EAAW7B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC1DS,EAAY9B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC3DU,EAAc/B,EAAiBqB,EAAY,CAAC,EAAIA,EAAY,CAAC,EAC7DW,EACFhC,EAAiB2B,EAAa,IAAM,GAAKI,EAAc,IAAM,EAAIF,EAAW,IAAM,GAAKE,EAAc,IAAM,EAGzGE,EAAYjC,EAAiB+B,EAAcF,EAAWC,EACtDI,EAAYlC,EAAiB6B,EAAWC,EAAYC,EACpDI,EAA0CH,EAC5C,CAAC,EAAG,EAAG,CAAC,EACR,CAAEC,GAAa,GAAKC,GAAa,EAAK,EAAI,GAAID,EAAY,GAAKC,GAAa,EAAI,EAAI,GAAI,CAAC,EACvFE,EACFJ,EAAS,CAAC,EAAG,EAAG,CAAC,EAAI,CAACC,GAAa,EAAI,EAAI,EAAGA,EAAY,GAAKC,GAAa,EAAI,EAAI,EAAG,CAAC,EACtFG,EAAW,CACf,KAAK,KAAKJ,EAAYE,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKF,EAAYC,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,EAC7D,KAAK,KAAKR,EAAYO,EAAc,CAAC,EAAIC,EAAkB,CAAC,CAAC,CAC/D,EAEAE,GAAU,UAAW,IAAM,wCAAwCD,CAAQ,EAAE,EAE7E,IAAMlC,EAAmB6B,EAAS,EAAI,EAChCO,EAAY,KAAK,IAAIJ,EAAc,CAAC,EAAIhC,EAAkBgC,EAAc,CAAC,CAAC,EAG1EK,EAAgB,CACpB,qDAAqDR,EAAS,YAAc,KAAK,KACjF,yDACF,EACIS,EAAmB,GACvB,OAAIhB,IACFe,EAAc,KAAK,wDAAwDR,EAAS,YAAc,KAAK,IAAI,EAC3GS,GAAoB;AAAA,0DAC8BT,EAAS,YAAc,KAAK;AAAA,+BACvDhC,EAAiB,IAAM,GAAG,GAAGgC,EAAS,MAAQ,EAAE;AAAA,YAGlE,CACL,KAAM,wBACN,YAAa,CAAC,KAAM9B,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMmB,EAAa,SAAUD,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAGiB,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,CAChE,GACA,gBAAiB,IAAM;AAAA,UACrBK,EAAa;AAAA,UACbF,EAAc,KAAK;AAAA,CAAI,CAAC;AAAA,6BACLA,EAAc,MAAM,4CACrCR,EAAS,YAAc,KAAK;AAAA,oDACYZ,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CAC7BA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,+CACxBA,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,iDACtBC,EAAY,KAAK,GAAG,CAAC;AAAA,wDACdsB,EAAU,eAAetB,CAAW,EAAE,MAAM,EAAG,CAAC,EAAE,KAAK,GAAG,CAAC;AAAA,mDAChEnB,EAAW,YAAYF,EAAiB,EAAI,CAAC,CAAC,KACrFE,EAAW,YAAYF,EAAiB,EAAI,CAAC,CAAC;AAAA;AAAA,gBAG9CE,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYF,EAAiB,EAAI,CAAC,EAAI,IAAME,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gBAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYF,EAAiB,EAAI,CAAC,EAAI,IAAME,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,gFAExFA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,8EAEvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,gDACHA,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,iDAC9CA,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA,kCAClEoB,CAAS;AAAA,kCACTC,CAAS;AAAA,iCACVC,CAAQ;AAAA,UAC/BiB,CAAgB;AAAA,UAChBnD,GAA6BU,EAAgByB,EAASvB,EAAYC,CAAgB,CAAC;AAAA,UAEjF6B,EAASY,GACIR,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,CAAS,EAClFM,GACIT,EAAmBD,EAAe,MAAO,OAAW,CAACnC,EAAgBuC,EAAW,GAChF,OAAWb,CAAyB,CAAC,EACxD,CACF,ICvPJ,IA0BMoB,GAsNOC,GAhPbC,GAAAC,EAAA,kBAmBAC,KAEAC,KAEAC,KAGMN,GACF,CAACO,EAA4BC,EAA+BC,EAC3DC,EAAgCC,EAAkBC,EAA+BC,EAAS,GAC1FC,IAA6B,CAC5B,IAAMC,EAAiBN,EAAW,SAAW,OACvCO,EAASD,EAAiB,EAAI,EAC9BE,EAASF,EAAiB,EAAI,EAC9BG,EAAaH,EAAiB,EAAI,EAClCI,EAAaC,EAAU,KAAKV,CAAW,EACvCW,EAAgBR,EAAS,EAAI,EAC7BS,EAAQb,EAAW,MACnBc,EAASf,EAAO,CAAC,EAAE,KACnBgB,EAAwBD,EAAO,CAAC,EAAID,EACpCG,EAAyBF,EAAO,CAAC,EAEnCG,EAAmB;AAAA,iDACoBb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,0BAC9DD,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,KAEvDH,IACFe,GAAoB;AAAA,sDAC0Bb,EAAS,QAAQC,CAAQ,IAAMA,CAAQ;AAAA,2BAClEC,EAAiB,IAAM,GAAG,GAAGF,EAAS,MAAQ,EAAE;AAAA,QAGrE,IAAMc,EAAad,EAAS,EAAI,EAC1Be,EAAIC,EAAc,IAAKrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACrEG,EAAKD,EAAc,KAAMrB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMmB,CAAU,EACvEI,EAAiB,CAACD,EAAIF,CAAC,EACzBjB,GACFoB,EAAe,KAAKF,EAAc,OAAQrB,EAAO,CAAC,EAAE,SAAU,CAACE,EAAYQ,CAAU,CAAC,EAAGS,CAAU,CAAC,EAEtG,IAAMK,EAASC,EAAe,SAAUzB,EAAO,CAAC,EAAE,SAAUE,EAAaiB,CAAU,EAC7EO,EAAe;AAAA,2BACAtB,EAAuB,cAAgB,gBAAgB;AAAA,kBAChEA,EAAuB,cAAgB,gBAAgB;AAAA,kBACvDA,EAAuB,cAAgB,gBAAgB,MAAMS,CAAa;AAAA,wBACpET,EAAuB,cAAgB,gBAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM7CE,CAAQ,MAAMO,CAAa;AAAA,8BAC/BA,CAAa;AAAA,8BACbP,CAAQ;AAAA;AAAA;AAAA,uBAGfA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,oCAExCA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOnBA,CAAQ,kBAAkBA,CAAQ,WAAWA,CAAQ;AAAA,0BACpDA,CAAQ,wBAAwBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sCAO/CA,CAAQ;AAAA;AAAA;AAAA;AAAA,wCAINA,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAUhBc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BAMhBgB,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA;AAAA,iDAEjBhB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAMdI,CAAU;AAAA;AAAA,gCAErBU,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,OAAQ,IAAI,CAAC;AAAA,oCAChChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCASZc,EAAE,IAAI,cAAe,cAAe,KAAM,IAAI,CAAC;AAAA,gCAC/CA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA,gCACnDA,EAAE,IAAI,cAAe,cAAe,SAAU,IAAI,CAAC;AAAA;AAAA,+BAEpDE,EAAG,IAAI,QAAS,OAAQ,QAAS,IAAI,CAAC;AAAA,oCACjChB,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mCAUTO,CAAa;AAAA,qCACXV,EAAU,YAAc,KAAK;AAAA,YACtDqB,EAAO,IAAI,QAAS,IAAK,QAAS,KAAM,OAAO,CAAC;AAAA;AAAA,SAGhDG,GAAc;AAAA,gCACMH,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBAC5CA,EAAO,WAAW,gBAAiB,CAAC,CAAC;AAAA,qBACxCA,EAAO,WAAW,gBAAiBd,CAAU,CAAC;AAAA,oBAC/Cc,EAAO,WAAW,gBAAiBhB,CAAM,CAAC;AAAA,oBAC1CgB,EAAO,WAAW,gBAAiBf,CAAM,CAAC;AAAA;AAAA;AAAA;AAAA,+BAI/BQ,CAAsB;AAAA,6CACRA,CAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAQ1CX,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,sCAEvCA,CAAQ,gBAAgBE,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAUzCF,CAAQ,iBAAiBA,CAAQ,WAAWA,CAAQ;AAAA;AAAA,wCAEvCA,CAAQ,gBAAgBG,CAAM;AAAA;AAAA;AAAA;AAAA;AAAA,6CAKzBO,CAAqB;AAAA,2CACvBA,CAAqB;AAAA,+BAEtDT,EAAiBe,EAAG,IAAI,QAAS,OAAQ,OAAQ,cAAc,EAC9CA,EAAG,IAAI,QAAS,eAAgB,OAAQ,MAAM,CAAC;AAAA,+BAC3CF,EAAE,IAAI,eAAgB,cAAe,cAAe,aAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kCAM/DjB,EAAU,WAAa,KAAK;AAAA,YAClDqB,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,UAG/C,MAAO;AAAA,IACTzB,EAAa,iBAAiB,GAAGwB,EAAgBC,CAAM,CAAC;AAAA,IACxDN,CAAgB;AAAA,2CACuBhB,EAAY,KAAK,GAAG,CAAC;AAAA,8CAClBF,EAAO,CAAC,EAAE,KAAK,KAAK,GAAG,CAAC;AAAA,0CAC5BC,EAAW,QAAQ,CAAC,CAAC,KAAKA,EAAW,QAAQ,CAAC,CAAC;AAAA,6CAC5CA,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC,KACjFN,EAAW,YAAYM,EAAiB,EAAI,CAAC,CAAC;AAAA,4CACZN,EAAW,UAAU,CAAC,CAAC,KAAKA,EAAW,UAAU,CAAC,CAAC;AAAA;AAAA,YAGrFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,YAExFA,EAAW,UAAU,CAAC,GAAK,EACvB,GACCA,EAAW,YAAYM,EAAiB,EAAI,CAAC,EAAI,IAAMN,EAAW,UAAU,CAAC,EAAI,EAAE;AAAA,0EACxBA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,0EACvCA,EAAW,KAAK,CAAC,EAAIA,EAAW,KAAK,CAAC,CAAC;AAAA,MAC3GF,EAAa,UAAU,CAAC;AAAA,MACxBA,EAAa,sCAAsCY,CAAU,CAAC;AAAA,IAChEN,EAASqB,EAAeC,EAAW,GACnC,EAESlC,GACT,CAACO,EAA+BC,EAC/B2B,IAAqF,CACpF,IAAMzB,EAAUH,EAAO,OAAS,EAE1BE,EAAcD,EAAW,YACzBU,EAAaC,EAAU,KAAKV,CAAW,EAMvC2B,EAAW,CACf,KAAK,KAAKlB,EAAa,EAAE,EACzB,EACA,CACF,EACAmB,GAAU,UAAW,IAAM,uCAAuCD,CAAQ,EAAE,EAE5E,IAAMvB,EAAWyB,GAA4B/B,EAAO,CAAC,EAAE,QAAQ,EAC/D,MAAO,CACL,KAAM,kBACN,YAAa,CAAC,KAAMC,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,cAAe,CAAC,EAAG4B,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,EAAG,EAAGA,EAAS,CAAC,CAAC,EAC9D,QAAS,CAAC,CACR,KAAMD,EAA6BA,EAA2B1B,CAAW,EAAIA,EAC7E,SAAUF,EAAO,CAAC,EAAE,QACtB,CAAC,CACH,GACA,gBAAkBD,GAA+BP,GAC7CO,EAAcC,EAAQC,EAAYC,EAAaC,EAAS0B,EAAS,CAAC,IAAM,GAAKA,EAAS,CAAC,IAAM,EAAG,GAChGvB,CAAQ,CACd,CACF,IClRJ,IAaM0B,GAIAC,GAWAC,GAkCAC,GA4COC,GA8BPC,GAqEAC,GAEAC,GAmDAC,GA6COC,GA/SbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAEAC,KACAC,KAEMhB,GACF,CAACiB,EAAeC,EAAgBC,EAAaC,EAAgBC,EAAkBC,KAC1EL,EAAQ,GAAKC,EAASC,GAAOC,EAAS,GAAKC,EAAW,EAAIC,EAE7DrB,GAAoB,CAACsB,EAAkBC,EAAiBC,EAAgBC,EAAcC,IAAiB,CAC3G,IAAMC,EAAW,KAAK,MAAML,EAAW,CAAC,EACpCC,IAAY,cACdC,EAAKC,CAAI,EAAIE,EACbH,EAAKE,CAAI,EAAIJ,EAAWK,GACfJ,IAAY,eACrBC,EAAKC,CAAI,EAAIH,EAAWK,EACxBH,EAAKE,CAAI,EAAIC,EAEjB,EAEM1B,GACF,CAAC2B,EAA+BC,EAAgCC,EAA8BP,EAC7FQ,EAAeP,EAAgBQ,EAA4BC,EAAwBC,EACnFC,IAA0B,CACzB,IAAMC,EAAcR,EAAW,OAAS,EAClCS,EAAoBF,EAAY,SAAW,EACjD,GAAID,EAAc,SAAW,EAC3B,QAASI,EAAI,EAAGA,EAAIF,EAAa,EAAEE,EACjCJ,EAAc,KAAK,CAAC,EAGxB,IAAMK,EAAYX,EAAW,CAAC,EACxBY,EAAcX,EAAYI,EAAgB,EAAI,CAAC,EAAIF,EACzD,QAASO,EAAI,EAAGG,EAAIb,EAAW,OAASQ,GAAeH,EAAgB,EAAI,GAAIK,EAAIF,EAAa,EAAEE,EAAG,EAAEG,EAAG,CACxG,IAAMC,EAASd,EAAWa,CAAC,EACrBpB,EAAUgB,EAAoBK,EAASV,EAAQM,CAAC,EAAIH,EAAYG,CAAC,EACjEhB,EAAWvB,GAAgB2C,EAAQV,EAAQM,CAAC,EAAGd,EAAKc,CAAC,EAAGT,EAAYY,CAAC,EAAGX,EAAUQ,CAAC,EAAGjB,CAAO,EACnGrB,GAAkBsB,EAAUC,EAASC,EAAMc,EAAGA,EAAIF,CAAW,EACzDC,GACFF,EAAY,KACRH,EAAQM,CAAC,GAAKI,EAAS,GAAKR,EAAcI,CAAC,GAAKT,EAAYY,CAAC,EAAI,GAAKX,EAAUQ,CAAC,EAAI,EAAId,EAAKc,CAAC,EAC/Fd,EAAKc,EAAIF,CAAW,CAAC,CAE7B,CACAD,EAAY,OAAO,EAAG,EAAGI,CAAS,EAClCJ,EAAY,OAAOF,EAAgB,EAAI,EAAG,EAAGO,CAAW,CAC1D,EAQEtC,GACF,CAAoCyC,EAAeC,IAAqC,CACtF,IAAMf,EAAcc,EAAW,YAAY,MAAM,EAEjD,GAAIA,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAClGjB,EAAY,OAAS,EACrB,QAASS,EAAI,EAAGA,EAAIM,EAAO,CAAC,EAAE,KAAK,OAAQ,EAAEN,EAC3CT,EAAY,KAAKe,EAAO,CAAC,EAAE,KAAKN,CAAC,CAAC,CAEtC,CACA,IAAMS,EAAiBJ,EAAW,SAAW,OAC7Cd,EAAY,OAAO,EAAG,EAAGe,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAC1Cf,EAAY,OAAOkB,EAAiB,EAAI,EAAG,EAAGH,EAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAE/D,IAAMpB,EAAOmB,EAAW,KAAK,MAAM,EAC7BR,EAAcQ,EAAW,YAAY,MAAM,EAC3CT,EAAgBS,EAAW,cAAc,MAAM,EAC/Cf,EAAagB,EAAO,CAAC,EAAE,KACzBd,EAAYa,EAAW,UAAU,MAAM,EAC3C,GAAIb,EAAU,OAAO,CAACe,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC9C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5Cd,EAAY,IAAI,MAAMM,CAAW,EAAE,KAAK,CAAC,CAC3C,CACA,IAAIJ,EAAUW,EAAW,QAAQ,MAAM,EACvC,GAAIX,EAAQ,OAAO,CAACa,EAAGC,IAAMD,EAAIC,EAAG,CAAC,IAAM,EAAG,CAC5C,IAAMV,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5CZ,EAAU,IAAI,MAAMI,CAAW,EAAE,KAAK,CAAC,CACzC,CAGAnC,GACI2B,EAAYC,EAAaC,EAAWa,EAAW,QAASA,EAAW,MAAOnB,EAAMQ,EAASe,EACzFb,EAAeC,CAAW,EAG9B,IAAMa,EAAmB,OAAO,OAAO,CAAC,EAAGL,CAAU,EAC/CM,EAAWN,EAAW,SAAW,CACrCd,EAAY,KAAK,IAAI,EAAGL,EAAK,KAAK,GAAG,EAAGQ,EAAQ,KAAK,GAAG,EAAGE,EAAc,KAAK,GAAG,EAAGC,EAAY,KAAK,GAAG,EACxGL,EAAU,KAAK,GAAG,CACpB,EAAE,KAAK,GAAG,EACV,cAAO,OAAOkB,EAAe,CAAC,YAAAnB,EAAa,KAAAL,EAAM,cAAAU,EAAe,YAAAC,EAAa,UAAAL,EAAW,QAAAE,EAAS,SAAAiB,CAAQ,CAAC,EACnGD,CACT,EAES7C,GAAgCwC,GAAiE,CAC5G,IAAMO,EAAuBC,GAAkCR,CAAU,EAEnES,EAAST,EAAW,OACpBpB,EACF,CAAC,SAAU,QAAS,aACnB,YAAY,EAAE,OAAOoB,EAAW,QAAW,IAAc,EAAIA,EAAW,OAAiB,EACxFb,EAAYa,EAAW,UACvBZ,EAAQY,EAAW,MACnBd,EAAcc,EAAW,YACzBnB,EAAOmB,EAAW,KAClBX,EAAUW,EAAW,QACrBU,EAAYV,EAAW,SAA2B,EAClDT,EAAgBS,EAAW,cAC3BR,EAAcQ,EAAW,YAC/B,OAAOW,GAA4B,CACjC,QAAA/B,EACA,OAAA6B,EACA,UAAAtB,EACA,MAAAC,EACA,YAAAF,EACA,cAAAK,EACA,YAAAC,EACA,KAAAX,EACA,QAAAQ,EACA,SAAAqB,EACA,GAAGH,CACL,CAAC,CACH,EAEM9C,GAAiB,CAACwC,EAA+BD,IAA8C,CAGnG,GAAI,CAACC,GAAWA,EAAO,SAAW,GAAKA,EAAO,SAAW,EACvD,MAAM,IAAI,MAAM,6BAA6B,EAI/C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,2CAA2C,EAG7D,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM,8CAA8C,EAIhE,IAAMW,EAAcX,EAAO,CAAC,EAAE,KAAKD,EAAW,SAAW,OAASC,EAAO,CAAC,EAAE,KAAK,OAAS,EAAI,CAAC,EACzFY,EAAkBZ,EAAO,CAAC,EAAE,KAAK,CAAC,EACxC,GAAIW,IAAgBC,EAClB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,IAAMC,EAAcb,EAAO,CAAC,EAAE,KAAK,CAAC,EAAID,EAAW,MAGnD,GAAIC,EAAO,SAAW,IAAMA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,CAAC,IAAMa,GAC/E,MAAM,IAAI,MAAM,cAAc,EAGhC,IAAMrB,EAAcQ,EAAO,CAAC,EAAE,KAAK,OAAS,EAG5C,GAFqBD,EAAW,UAAU,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEnDH,EAAW,UAAU,SAAWP,EAClD,MAAM,IAAI,MAAM,uBAAuBA,CAAW,GAAG,EAKvD,GAFmBO,EAAW,QAAQ,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAEjDH,EAAW,QAAQ,SAAWP,EAC9C,MAAM,IAAI,MAAM,qBAAqBA,CAAW,GAAG,EAKrD,GADgBO,EAAW,KAAK,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GAC9CH,EAAW,KAAK,SAAWP,EAAc,EACtD,MAAM,IAAI,MAAM,kBAAkBA,EAAc,CAAC,GAAG,EAItD,GAAIO,EAAW,cAAc,SAAWP,GAAeO,EAAW,cAAc,SAAW,EACzF,MAAM,IAAI,MAAM,4BAA4BP,CAAW,GAAG,EAM5D,GADuBO,EAAW,YAAY,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAI,GACrDH,EAAW,YAAY,SAAW,GACpDA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EAC5D,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAID,EAAW,YAAY,SAAW,GAAKA,EAAW,YAAY,SAAWC,EAAO,CAAC,EAAE,KAAK,OAAS,EACnG,MAAM,IAAI,MAAM,sBAAsB,CAE1C,EAGMvC,GAAsB,CAAC,EAAG,EAAG,EAAG,CAAC,EAEjCC,GACF,CAACoD,EAAyBd,EAA+BD,IAA8C,CACrG,IAAMgB,EAAqBzD,GAAmCyC,EAAYC,CAAM,EAC1EG,EAAiBJ,EAAW,SAAW,OACvCiB,EAAUhB,EAAO,SAAW,EAClC,GAAIe,EAAmB,QAAU,EAAG,CAClCD,EAAQ,QAAQG,GAAiCjB,EAAQe,CAAkB,CAAC,EAC5E,MACF,CACA,IAAMxB,EAAcwB,EAAmB,YACjCG,EAAY3B,EAAYY,EAAiB,EAAI,CAAC,EAC9CgB,EAAW5B,EAAYY,EAAiB,EAAI,CAAC,EAC7CP,EAAcL,EAAYY,EAAiB,EAAI,CAAC,EAChDiB,EAAepB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC/BqB,EAAcrB,EAAO,CAAC,EAAE,KAAK,CAAC,EAC9BsB,EAAgBtB,EAAO,CAAC,EAAE,KAAKG,EAAiB,EAAI,CAAC,EAErDoB,EAAYpB,EAAiBe,EAAYC,EAAWvB,EACpD4B,EAAYrB,EAAiBP,EAAcsB,EAAYC,EACvDM,EAAWL,EAAeC,EAAcC,EAExCI,EAAgE,GAIhEC,EAAoBb,EAAQ,iBAAiB,IAC/CA,EAAQ,QACJc,GAA2B5B,EAAO,CAAC,EAAGvC,EAAmB,EACzD,CAAC,OAAQ,CAAC,CAAC,EAAG,QAAS,CAACsC,EAAW,SAAW,GAAK,EAAE,CAAC,CAAC,EAAE,CAAC,EAC9DA,EAAW,UAAY,CAACe,EAAQ,iBAAiB,KACnDA,EAAQ,iBAAiB,GAAKa,GAIhC,IAAME,EAAsB,CAAC7B,EAAO,CAAC,EAAG2B,CAAgB,EACpDX,IACE,CAACb,GAAkBH,EAAO,CAAC,EAAE,KAAK,SAAW,EAC/C6B,EAAoB,KAAK7B,EAAO,CAAC,EAAE,QAAQ,CAACA,EAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAG,CAAC,CAAC,CAAC,EAErE6B,EAAoB,KAAK7B,EAAO,CAAC,CAAC,GAKtCc,EAAQ,QACJgB,GACID,EAAqBd,EAAoBxB,EAAagC,EAAWC,EAAWC,EAAUT,EACtFU,CAAyB,EAC7B,CAAC,OAAQG,CAAmB,CAAC,CACnC,EAEElE,GAAkB,CAACmD,EAAyBf,IAA8C,CAE9F,IAAMV,EAAgBU,EAAW,SAAW,OAEtCC,EAAS,CACbc,EAAQ,OAAO,CAAC,EAAE,QACdzB,EAEI,CAACyB,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,EAEnF,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,EAE5FA,EAAQ,OAAO,CAAC,EAAE,QAAQ,CAACA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,EAAG,EAAGA,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC,CAChH,EACId,EAAO,SAAW,GACpBA,EAAO,KAAKc,EAAQ,OAAO,CAAC,CAAC,EAE/B,IAAI7B,EAAcc,EAAW,aACzBd,EAAY,SAAW,GAAKA,EAAY,CAAC,IAAM,KACjDA,EAAc,CAAC6B,EAAQ,OAAO,CAAC,EAAE,KAAK,CAAC,CAAC,GAE1C,IAAI5B,EAAYa,EAAW,WACvBb,EAAU,SAAW,GAAKA,EAAU,CAAC,IAAM,KAC7CA,EAAY,CAAC,CAAC,GAEhB,IAAIE,EAAUW,EAAW,SACrBX,EAAQ,SAAW,GAAKA,EAAQ,CAAC,IAAM,KACzCA,EAAU,CAAC,CAAC,GAEd,IAAIR,EAAOmB,EAAW,KAClBnB,EAAK,SAAW,IAClBA,EAAO,CAAC,EAAG,CAAC,GAEdA,EAAO,CAAC,EAAGA,EAAK,CAAC,EAAG,EAAGA,EAAK,CAAC,CAAC,EAC9BQ,EAAU,CAAC,CAAC,EAAE,OAAOA,CAAO,EAC5BF,EAAY,CAAC,CAAC,EAAE,OAAOA,CAAS,EAChCD,EAAc,CAAC,CAAC,EAAE,OAAOA,CAAW,EACpC,IAAM8B,EACFzD,GAAmC,CAAC,GAAGyC,EAAY,KAAAnB,EAAM,QAAAQ,EAAS,UAAAF,EAAW,YAAAD,CAAW,EAAGe,CAAM,EACrGc,EAAQ,QAAQG,GACZjB,EAAQe,EACRxB,GAAeF,EAAgB,CAACE,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,EAC/C,CAACA,EAAY,CAAC,EAAGA,EAAY,CAAC,EAAGA,EAAY,CAAC,CAAC,CAAC,CAAC,CACtF,EAEa3B,GAAgB,CAACkD,EAAyBf,IAA8C,CACnGvC,GAAesD,EAAQ,OAAQf,CAAU,EACrCe,EAAQ,OAAO,CAAC,EAAE,KAAK,SAAW,EACpCnD,GAAgBmD,EAASf,CAAU,EAEnCrC,GAAgBoD,EAASA,EAAQ,OAAQf,CAAU,CAEvD,ICtTA,IAqBMgC,GAEAC,GACAC,GACAC,GACAC,GAQAC,GAqBAC,GA4HAC,GA4FOC,GAKAC,GApRbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAaMd,GACF,qBACEC,GAAc,IAAMD,GAAgB,KACpCE,GAAkB,IAAMD,GAAc,IACtCE,GAAa,IAAMF,GAAc,MAAQA,GACzCG,GAAiB,IAAMD,GAAa,IAQpCE,GAAN,KAAiB,CACf,YAAYU,EAAa,GAAI,CAC3B,KAAK,gBAAkB,IAAI,IAC3B,KAAK,WAAaA,CACpB,CAGA,UAAUC,EAAgBC,EAAe,CACvC,IAAIC,EAAQ,KAAK,gBAAgB,IAAIF,CAAM,EACvCE,IAAU,OACZA,EAAQ,CAACD,CAAK,EAEdC,EAAM,KAAKD,CAAK,EAElB,KAAK,gBAAgB,IAAID,EAAQE,CAAK,CACxC,CAIF,EAEMZ,GAAN,KAAqB,CACnB,YAAYa,EAA+CC,EAAkB,CAAlB,cAAAA,EACzD,KAAK,YAAc,GACnB,KAAK,aAAe,IAAI,IACxB,KAAK,IAAM,IAAI,MACf,KAAK,WAAa,CAAC,EAGnB,GAAI,CAACC,EAAKC,CAAG,EAAIF,EAAS,SAAS,IAAI,EAAIA,EAAS,MAAM,KAAM,CAAC,EAAI,CAACA,EAAU,EAAE,EAClF,GAAI,CAACC,EAAI,MAAM,OAAOjB,EAAc,CAAC,EACnC,MAAM,IAAI,MAAM,kBAAkB,EAapC,GAXmBiB,EAAI,MAAM,GAAG,EACrB,QAAQ,CAACE,EAAWN,IAAU,CACvC,IAAMO,EAAOL,EAAOF,CAAK,EAAE,KAAK,MAAM,EACtC,GAAI,CAACM,EAAU,MAAM,OAAOrB,EAAe,CAAC,EAC1C,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMuB,EAAa,KAAK,YAAYF,EAAW,GAAMC,EAAMP,CAAK,EAChE,KAAK,IAAI,KAAKQ,CAAU,CAC1B,CAAC,EAGGH,IAAQ,GAEVA,GAAO,CAAC,GAAG,KAAK,aAAa,QAAQ,CAAC,EAC1B,OAAO,CAAC,CAACI,EAAKC,CAAI,IAAOA,EAAK,QAAU,GAAKD,IAAQ,KAAM,EAC3D,IAAI,CAAC,CAACA,CAAG,IAAMA,CAAG,EAClB,KAAK,EAAE,UAEf,CAACJ,EAAI,MAAM,OAAOrB,EAAW,CAAC,EAChC,MAAM,IAAI,MAAM,aAAa,EAKdqB,EAAI,MAAM,OAAOtB,GAAe,GAAG,CAAC,GAC3C,QAASgB,GAAW,CAC9B,GAAIA,IAAW,MACb,KAAK,WAAa,KAAK,WAAW,OAAO,KAAK,YAAY,MACrD,CACL,IAAMW,EAAO,KAAK,aAAa,IAAIX,CAAM,EACzC,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,oBAAoB,EAEtC,KAAK,WAAW,KAAKA,EAAK,QAAQ,CACpC,CACF,CAAC,EACD,KAAK,IAAM,KAAK,YAAYL,EAAK,GAAM,KAAK,UAAU,CACxD,CAGA,UAAUN,EAAgBY,EAAkBb,EAAoB,CAC9D,IAAIY,EAAO,KAAK,aAAa,IAAIX,CAAM,EACvC,GAAIW,IAAS,OAAW,CACtB,GAAIA,EAAK,WAAaC,GAAYD,EAAK,QAAU,EAC/C,MAAM,IAAI,MAAM,oBAAoB,EAEpCA,EAAK,QACLA,EAAK,aAAa,KAAKZ,CAAU,CAErC,MACEY,EAAO,CAAC,MAAO,EAAG,SAAAC,EAAU,aAAc,CAACb,CAAU,CAAC,EAExD,KAAK,aAAa,IAAIC,EAAQW,CAAI,CACpC,CAGA,YAAYE,EAAcC,EAAkBN,EAAyBP,EAAQ,GAAgB,CAC3F,IAAMc,EAAOP,EAAK,OACdQ,EAAW,GACXC,EAAe,CAAC,EAChBC,EAAU,EAEd,GAAI,CAACL,EAAK,MAAM,OAAO3B,EAAe,CAAC,GAAM,CAAC4B,GAAWD,IAAS,GAChE,MAAM,IAAI,MAAM,kBAAkB,EAEpC,IAAMM,EAAeN,EAAK,MAAM,OAAO7B,GAAe,GAAG,CAAC,EACpDyB,EAAa,IAAIpB,GAAWY,CAAK,EAEvC,OAAAkB,GAAc,QAAQ,CAACnB,EAAgBoB,IAAc,CACnD,GAAIpB,IAAW,MAAO,CACpB,GAAIgB,EACF,MAAM,IAAI,MAAM,6CAA6C,EAE/DA,EAAW,GACX,IAAMK,EAAoBN,EAAOI,EAAa,OAAS,EACvD,GAAIE,EAAoB,EACtB,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GADAJ,EAAeT,EAAK,MAAMU,EAASA,EAAUG,CAAiB,EAC1D,KAAK,aACP,GAAI,KAAK,aAAa,SAAWJ,EAAa,QAC1C,KAAK,aAAa,SAAS,IAAMA,EAAa,SAAS,EACzD,MAAM,IAAI,MAAM,8BAA8B,UAEvCH,EACT,KAAK,YAAc,GACnB,KAAK,aAAeG,MAEpB,OAAM,IAAI,MAAM,uCAAuC,EAGzD,QAASK,EAAI,EAAGA,EAAIL,EAAa,OAAQK,IAAK,CAC5C,IAAMtB,EAAS,OAAO,aAAa,IAAI,WAAW,CAAC,EAAIoB,CAAC,EACxDX,EAAW,UAAUT,EAAQoB,EAAIE,CAAC,EAClC,KAAK,UAAUtB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAC/C,CACF,MACEQ,EAAW,UAAUT,EAAQoB,CAAC,EAC9B,KAAK,UAAUpB,EAAQQ,EAAKU,GAAS,EAAGjB,CAAK,CAEjD,CAAC,EACMQ,CACT,CAQF,EAEMlB,GAA0B,CAACY,EAA+BoB,IAAgD,CAC9G,IAAMC,EAAWrB,EAAO,CAAC,EAAE,SACrBsB,EAAY,IAAI,MAAqBtB,EAAO,MAAM,EACxD,QAASiB,EAAI,EAAGA,EAAIjB,EAAO,OAAQ,EAAEiB,EACnCK,EAAUL,CAAC,EAAIM,EAAc,QAAQN,CAAC,GAAII,EAAUrB,EAAOiB,CAAC,EAAE,IAAI,EAEpE,IAAMO,EAAcJ,EAAe,WAC7BK,EAAaC,EAAU,KAAKF,CAAW,EACvCG,EAASC,EAAe,SAAUP,EAAUG,CAAW,EACvDK,EAAoB,CAAC,EACrBC,EAAa,MAAM,KAAKV,EAAe,IAAI,gBAAgB,KAAK,CAAC,EACjEW,EAAW,kBACXC,EAAU,iBACVC,EAAY,eACZC,EAAgC,CAAC,EACjCC,EAAiC,CAAC,EAClCC,EAAiC,CAAC,EAClCC,EAA4B,CAAC,EAC7BC,EAAyBlB,EAAe,aAAa,OAASU,EAAW,OAC/EV,EAAe,aAAa,QAAQ,CAACZ,EAAMX,IAAW,CACpD,GAAIiC,EAAW,SAASjC,CAAM,EAAG,CAC/B,IAAM0C,EAAcT,EAAW,QAAQjC,CAAM,EAC7CuB,EAAe,IAAI,QAAQ,CAACV,EAAMO,IAAM,CACtC,GAAIT,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMuB,EAAU9B,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAI2C,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAS1C,IAAU,CACzB+B,EAAQ,KAAK,GACTP,EAAUL,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,GAAO6B,EAAO,WAAW,gBAAiBY,CAAW,CAAC,CAAC,EAAE,CAC3G,CAAC,CACH,CACF,CAAC,CACH,MACEnB,EAAe,IAAI,QAAQ,CAACV,EAAMO,IAAM,CACtC,IAAMT,EAAOY,EAAe,aAAa,IAAIvB,CAAM,EACnD,GAAIW,IAAS,OACX,MAAM,IAAI,MAAM,sBAAsB,EAExC,GAAIA,EAAK,aAAa,SAASS,CAAC,EAAG,CACjC,IAAMuB,EAAU9B,EAAK,gBAAgB,IAAIb,CAAM,EAC/C,GAAI2C,IAAY,OACd,MAAM,IAAI,MAAM,sBAAsB,EAExCA,EAAQ,QAAS1C,IAAU,CACzBoC,EAAoB,KAAK,GAAGZ,EAAUL,CAAC,EAAE,WAAW,QAAQA,CAAC,UAAWnB,GAAO,GAAGD,CAAM,EAAE,CAAC,EAAE,CAC/F,CAAC,EACDwC,EAAgB,KAAK,WAAWf,EAAUL,CAAC,EAAE,aAAa,QAAQA,CAAC,SAAS,CAAC,GAAG,CAClF,CACF,CAAC,EACDkB,EAAqB,KAAK,WAAWtC,CAAM,cAAcA,CAAM,MAC3DuB,EAAe,aAAa,IAAIvB,CAAM,GAAG,QAAQ,KAAKA,CAAM,OAAO,EACvEuC,EAAqB,KAAK,GAAG,CAEjC,CAAC,EACD,IAAMK,EAAYH,EACd,CACE,GAAGT,EACH,aAAaP,EAAU,IAAI,CAACoB,EAAUzB,IAAMyB,EAAS,aAAa,QAAQzB,CAAC,SAAS,CAAC,EAAE,KAAK,KAAK,CAAC,GACpG,EACA,CACE,GAAGY,EACHG,EACA,GAAGG,EACH,GAAGD,EACHH,EACA,GAAGM,EACHJ,EACA,GAAGG,CACL,EACEO,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiB,GAAGtB,EAAWK,CAAM,CAAC;AAAA;AAAA,QAEnDiB,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCnB,CAAU,CAAC;AAAA,8BAC1CE,EAAO,gBAAgB,YAAY,CAAC;AAAA,UACxDL,EAAU,IAAI,CAACoB,EAAUzB,IAAM,YAAYA,CAAC,YAAYK,EAAUL,CAAC,EAAE,KAAK,OAAO,GAAG,EAAE,KAAK;AAAA,CAAI,CAAC;AAAA,UAChGwB,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,UACpBd,EAAO,YAAY,aAAc,KAAK,CAAC;AAAA,SAE/C,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMP,EAAe,QAAQ,EAC3C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMI,EAAa,SAAUxB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAkB,CACF,CACF,EAEatD,GAAS,CAACwD,EAAyBC,IAAuC,CACrF,IAAM1B,EAAiB,IAAIjC,GAAe0D,EAAQ,OAAQC,EAAW,QAAQ,EAC7ED,EAAQ,QAAQzD,GAAwByD,EAAQ,OAAQzB,CAAc,CAAC,CACzE,EAEa9B,GAAyBwD,GAA0D,CAC9F,IAAM7C,EAAY6C,EAAW,SAAoB,QAAQ,OAAQ,EAAE,EACnE,OAAOC,GAA4B,CAAC,SAAA9C,CAAQ,CAAC,CAC/C,ICvRA,IASM+C,GAiBAC,GAYAC,GAIAC,GAuCOC,GAjFbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,0BAA0B,EAE5C,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EAEzDG,EAAaD,EAAM,OAASD,EAAW,OAAS,EAAIC,EAAM,OAASD,EAAW,OAC9EG,EAAkBH,EAAW,OAASC,EAAM,OAAS,EAAID,EAAW,OAASC,EAAM,OACvF,KAAOC,EAAaD,EAAM,QAAUE,EAAkBH,EAAW,OAAQ,EAAEE,EAAY,EAAEC,EACvF,GAAIF,EAAMC,CAAU,IAAMF,EAAWG,CAAe,GAAKF,EAAMC,CAAU,IAAM,GAC3EF,EAAWG,CAAe,IAAM,EAClC,MAAM,IAAI,MAAM,oDAAoD,CAG1E,EAEMZ,GAAmB,CAACa,EAA2BC,IAAwC,CAC3F,IAAMC,EAAOF,EAAO,OAASC,EAAO,OAC9BJ,EAAkB,CAAC,EACzB,QAASM,EAAI,EAAGA,EAAID,EAAM,EAAEC,EAC1BN,EAAM,KAAKG,EAAOG,CAAC,CAAC,EAEtB,QAASA,EAAI,EAAGA,EAAIF,EAAO,OAAQ,EAAEE,EACnCN,EAAM,KAAKI,EAAOE,CAAC,IAAM,EAAIH,EAAOG,EAAID,CAAI,EAAID,EAAOE,CAAC,CAAC,EAE3D,OAAON,CACT,EAEMT,GAAuB,CAACQ,EAA+BC,IACxDD,EAAW,OAASC,EAAM,OAAUV,GAAiBS,EAAYC,CAAK,EAAIV,GAAiBU,EAAOD,CAAU,EAG3GP,GAA2BM,GAA+C,CAC9E,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAAQ,MAAM,KAAKF,EAAO,CAAC,EAAE,iBAAiB,EAAG,MAAM,EACvDS,EAAwBhB,GAAqBQ,EAAYC,CAAK,EAC9DQ,EAAaC,EAAU,KAAKF,CAAW,EAEvCG,EAAWZ,EAAO,CAAC,EAAE,SACrBa,EAAQC,EAAc,QAASF,EAAUX,CAAU,EACnDc,EAASC,EAAe,SAAUJ,EAAUH,CAAW,EAEvDQ,EAAmBC,GAA+B;AAAA,uBACnCL,EAAM,QAAQ,GAAGZ,CAAU,CAAC;AAAA,IAC/CiB,EAAa,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,IAC5CG,EAAa,UAAU,CAAC;AAAA,IACxBA,EAAa,sCAAsCR,CAAU,CAAC;AAAA,0BACxCK,EAAO,gBAAgB,YAAY,CAAC;AAAA,wBACtCF,EAAM,KAAK,OAAO;AAAA,0BAChBZ,EAAW,MAAM;AAAA,YAC/BY,EAAM,WAAW,aAAc,GAAG,CAAC;AAAA,UACrCA,EAAM,WAAW,eAAgB,IAAK,CAAC,CAAC;AAAA;AAAA,UAG5CA,EAAM,WACF,eAAgB,IAAKE,EAAO,WAAW,gBAAiB,OAAON,EAAY,OAASR,EAAW,MAAM,EAAE,CAAC,CAAC;AAAA;AAAA;AAAA,MAG7Gc,EAAO,YAAY,aAAcF,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,KAExE,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAM,GAAGJ,CAAW,EAAE,EACpC,gBAAAQ,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMR,EAAa,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKU,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEaf,GAAUwB,GAAkC,CACvD5B,GAAe4B,EAAQ,MAAM,EAC7BA,EAAQ,QAAQzB,GAAwByB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxE,ICpFA,IAcMC,GAMAC,GAiEOC,GAGAC,GAxFbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,CAE/C,EAEMR,GAA0B,CAACQ,EAA+BC,IAA8C,CAC5G,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAeH,EAAO,CAAC,EAAE,KAEzBI,EAAYF,EAAW,OACvBG,EAAOC,EAAU,cAAcL,EAAW,KAAMG,CAAS,EAEzDG,EAAcL,EAAW,MAAM,CAAC,EACtCK,EAAY,OAAOF,EAAM,EAAG,GAAGF,CAAY,EAE3C,IAAMK,EAAeN,EAAWG,CAAI,EAC9BI,EAAaH,EAAU,KAAKC,CAAW,EAEvCG,EAAOC,EAAc,OAAQX,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/DY,EAAUD,EAAc,eAAgBX,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC1Ea,EAASC,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAUO,CAAW,EACjEQ,EAAkB,IAAc,CACpC,IAAMC,EAAcb,EAAa,OAC7Bc,EAAU,yBAAyBL,EAAQ,KAAK,OAAO,OAC3D,QAASM,EAAI,EAAGA,EAAIF,EAAaE,IAC/BD,GAAW,GAAGD,EAAc,EAAI,kBAAkBE,CAAC,IAAM,gBAAgB,MACrEX,EAAY,OAAS,EAAI,iBAAiBF,EAAOa,CAAC,IAAM,eAAe,IAE7ED,GAAW;AAAA,oBACKL,EAAQ,aAAa,gBAAgB,CAAC;AAAA;AAAA,wBAElCJ,CAAY;AAAA;AAAA,4BAERE,EAAK,KAAK,OAAO;AAAA,QAEzC,QAASQ,EAAI,EAAGC,EAAI,EAAGD,EAAId,EAAWc,IAChCA,IAAMb,GACRY,GAAW,GAAGb,EAAY,EAAI,eAAec,CAAC,IAAM,aAAa,eACjEC,GAAKH,IAELC,GAAW,GAAGb,EAAY,EAAI,eAAec,CAAC,IAAM,aAAa,MAC7DX,EAAY,OAAS,EAAI,iBAAiBY,CAAC,IAAM,eAAe,IACpEA,KAGJ,OAAOF,CACT,EAEMG,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiBX,EAAME,EAASC,CAAM,CAAC;AAAA,QACpDQ,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCZ,CAAU,CAAC;AAAA,8BAC1CI,EAAO,gBAAgB,YAAY,CAAC;AAAA,UACxDE,EAAgB,CAAC;AAAA,sBACLL,EAAK,aAAa,aAAa,CAAC;AAAA,UAC5CG,EAAO,YAAY,aAAc,OAAO,CAAC;AAAA,SAEjD,MAAO,CACL,KAAM,SACN,YAAa,CAAC,KAAMZ,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAMM,EAAa,SAAUP,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAG,KAAK,KAAKS,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAW,CACF,CACF,EAEa3B,GAAyBQ,GAClCqB,GAA4B,CAAC,KAAMrB,EAAW,IAAc,CAAC,EAEpDP,GAAS,CAAC6B,EAAyBtB,IAAuC,CACrF,IAAMD,EAASuB,EAAQ,OACvBhC,GAAeS,CAAM,EACrBuB,EAAQ,QAAQ/B,GAAwB+B,EAAQ,OAAQtB,CAAU,CAAC,CACrE,IC5FA,IAcMuB,GAeAC,GAqEOC,GAGAC,GArGbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAMMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAIA,EAAO,CAAC,EAAE,KAAK,OAAS,EAC1B,MAAM,IAAI,MAAM,2DAA2D,EAG7E,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAWA,EAAO,CAAC,EAAE,KAAK,OAC3C,MAAM,IAAI,MAAM;AAAA,4DACwC,CAE5D,EAEMR,GACF,CAACQ,EAA+BC,IAAsD,CACpF,IAAMC,EAAaF,EAAO,CAAC,EAAE,KACvBG,EAAsBH,EAAO,CAAC,EAAE,SAChCI,EAAYF,EAAW,OACvBG,EAAeC,EAAU,eAAeJ,CAAU,EAClDK,EAAYD,EAAU,KAAKJ,CAAU,EAErCM,EAAeR,EAAO,CAAC,EAAE,KACzBS,EAAkBT,EAAO,CAAC,EAAE,SAC5BU,EAAcJ,EAAU,KAAKE,CAAY,EAEzCG,EAAOL,EAAU,cAAcL,EAAW,KAAMG,CAAS,EACzDQ,EAAeV,EAAWS,CAAI,EAE9BE,EAAcL,EAAa,MAAM,CAAC,EAClCM,EAAaR,EAAU,KAAKO,CAAW,EAEvCE,EAAQC,EAAc,QAASb,EAAqBD,CAAU,EAC9De,EAAUD,EAAc,UAAWP,EAAiB,CAACC,CAAW,CAAC,EACjEQ,EAASC,EAAe,SAAUhB,EAAqBU,CAAW,EAMlEO,EAAmBC,GAA+B;AAAA,wCACtBhB,EAAa,MAAM,KAAKA,EAAa,IAAIiB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,QAChGD,EAAa,iBAAiBN,EAAOE,EAASC,CAAM,CAAC;AAAA,QACrDG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCP,CAAU,CAAC;AAAA;AAAA,4BAE1CI,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,kBAE9CD,EAAQ,YAAY,YAAY,CAAC;AAAA;AAAA,sBAE7BL,CAAY;AAAA;AAAA;AAAA;AAAA;AAAA,4BAKNV,EAAW,MAAM;AAAA,mBAC1BS,CAAI;AAAA;AAAA;AAAA,yBAGEO,EAAO,WAAW,gBAAiB,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAMtBX,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,KAO7C,MAAO,CACL,KAAM,iBACN,YAAa,CAAC,KAAMN,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMY,EAAa,SAAUb,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAM,CACF,CACF,EAES3B,GAAiCQ,GAC1CsB,GAA4B,CAAC,KAAMtB,EAAW,IAAc,CAAC,EAEpDP,GAAiB,CAAC8B,EAAyBvB,IAA+C,CACrG,IAAMD,EAASwB,EAAQ,OACvBjC,GAAeS,CAAM,EACrBwB,EAAQ,QAAQhC,GAAgCgC,EAAQ,OAAQvB,CAAU,CAAC,CAC7E,ICzGA,IAUMwB,GA0BAC,GAmBAC,GAoEOC,GAKAC,GAhIbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAEMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAO,OAAS,GAAKA,EAAO,OAAS,EACvC,MAAM,IAAI,MAAM,sBAAsB,EAIxC,GAAIA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,EACjD,MAAM,IAAI,MAAM,0BAA0B,EAG5C,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,UACjCA,EAAO,SAAW,GAAKA,EAAO,CAAC,EAAE,WAAaA,EAAO,CAAC,EAAE,SAC3D,MAAM,IAAI,MAAM,4BAA4B,CAEhD,EASMT,GAAU,CAACU,EAAWC,EAAWC,IAAoC,CACzE,GAAIA,EAAK,SAAW,EAClB,MAAO,KAGT,IAAMC,EAAcD,EAAK,SAAW,GAAKF,IAAM,GAAOE,EAAK,SAAW,GAAKA,EAAK,CAAC,IAAMF,EACjFI,EAAaF,EAAKA,EAAK,OAAS,CAAC,IAAMD,EAEzCI,EAAS,KACb,OAAKF,IACHE,GAAU,SAASH,EAAKA,EAAK,OAAS,CAAC,CAAC,KAErCE,IACHC,GAAU,MAGLA,CACT,EAEMd,GAAwB,CAACQ,EAA+BO,IAA4C,CACxG,IAAMC,EAASR,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9BS,EAAST,EAAO,CAAC,EAAE,KAAK,MAAM,EAC9B,CAACU,EAAGC,EAAGC,CAAC,EAAIC,GAAS,qBACvBL,EAAQD,EAAW,OAAQE,EAAQF,EAAW,OAAQP,EAAO,SAAW,EAAIA,EAAO,CAAC,EAAE,KAAO,MAAS,EACpGc,EAAc,CAACJ,EAAGC,CAAC,EACzB,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,qCAAsC,EAExD,IAAMC,EAAaC,EAAU,KAAKF,CAAW,EACzCG,EAAO,GACPV,EAAW,QAAUA,EAAW,OAClCU,EAAO,wCACEV,EAAW,QAAU,CAACA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAUA,EAAW,OAC1CU,EAAO,wCACE,CAACV,EAAW,QAAU,CAACA,EAAW,SAC3CU,EAAO,yCAGT,IAAMC,EAAWC,GAA4BnB,EAAO,CAAC,EAAE,QAAQ,EACzDoB,EAAiBb,EAAW,QAAU,EAAI,GAAK,kBAC/Cc,EAAarB,EAAO,SAAW,EAAI,qBAAqBT,GAAQmB,EAAGC,EAAGX,EAAO,CAAC,EAAE,IAAI,CAAC,KAAO,GAC5FsB,EAAkC,CACtC,sDAAsDJ,CAAQ,KAC9D,sDAAsDA,CAAQ,IAChE,EACIlB,EAAO,SAAW,GACpBsB,EAAgC,KAAK,sDAAsDJ,CAAQ,IAAI,EAEzG,IAAMK,EAAmBC,GAA+B;AAAA,mBACvCd,CAAC;AAAA,mBACDC,CAAC;AAAA,mBACDC,CAAC;AAAA,kBACFM,CAAQ,IAAIX,EAAW,KAAK;AAAA,iBAC7BW,CAAQ,IAAIX,EAAW,IAAI;AAAA;AAAA,IAExCe,EAAgC,KAAK;AAAA,CAAI,CAAC;AAAA,uBACvBtB,EAAO,MAAM,6CAA6CkB,CAAQ;AAAA;AAAA,IAErFM,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCT,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,kBAKlDG,CAAQ;AAAA,8BACIN,CAAC;AAAA,QACvBK,CAAI;AAAA;AAAA;AAAA,MAGNG,CAAc;AAAA,MACdC,CAAU;AAAA;AAAA;AAAA,KAId,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAMd,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMO,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKe,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAQ,CACF,CACF,EAEa9B,GAAO,CAACgC,EAAyBlB,IAAqC,CACjFjB,GAAemC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQjC,GAAsBiC,EAAQ,OAAQlB,CAAU,CAAC,CACnE,EAEab,GAAuBa,GAChCmB,GAA4BnB,CAA+D,ICjI/F,IAgBMoB,GAIAC,GA8FAC,GA2GAC,GAgDOC,GAGAC,GAhRbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMX,GAAW,CACf,KAAM,uBACR,EAEMC,GACF,CAACW,EAA+BC,IAAoD,CAClF,IAAMC,EAASF,EAAO,CAAC,EAAE,KAEnBG,EAAcD,EACdE,EAAO,EACPC,EAAYC,EAAU,gBAAgBJ,EAAQE,CAAI,EAClDG,EAAWD,EAAU,kBAAkBJ,EAAQE,CAAI,EACnDI,EAAIN,EAAO,CAAC,EACZO,EAAIC,EAAc,IAAKV,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EAC3EI,EAAQD,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EACjEY,EAAOF,EAAc,OAAQV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,IAAI,EAC/Da,EAASC,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAU,CAACE,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGK,CAAQ,CAAC,EACtFQ,EAAY,CAACN,EAAGE,EAAOC,EAAMC,CAAM,EACnCG,EAAWP,EAAE,KAAK,MAClBQ,EAAgB,GAChBC,EAAmBC,GAA+B;AAAA;AAAA,mBAE3CX,CAAC;AAAA,0BACMD,CAAQ;AAAA,yBACTN,EAAW,OAAO;AAAA,gCACXe,CAAQ;AAAA,uCACDA,CAAQ;AAAA,2CACJA,CAAQ,KAAKC,CAAa;AAAA,0BAC3CA,CAAa;AAAA,IACnCE,EAAa,iBAAiB,GAAGJ,CAAS,CAAC;AAAA,IAC3CI,EAAa,UAAUF,CAAa,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAOtBD,CAAQ;AAAA;AAAA,4BAECP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,0CAahBO,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAOzBP,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mDAkBJO,CAAQ;AAAA,qCACtBL,EAAM,YAAY,SAAS,CAAC;AAAA,yBACxCC,EAAK,YAAY,SAAS,CAAC;AAAA;AAAA,oBAEhCH,EAAE,IAAI,QAAS,UAAW,GAAG,CAAC;AAAA,QAC1CI,EAAO,IAAI,QAAS,UAAW,IAAK,OAAO,CAAC;AAAA;AAAA,KAG9C,MAAO,CACL,GAAGzB,GACH,YAAa,CAAC,KAAMa,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAClD,EACA,cAAe,CAAC,EAAGK,CAAS,CAC9B,GACA,gBAAAa,CACF,CACF,EAEE5B,GACF,CAAC8B,EAAyBC,EAAmBV,EAAmBC,EAAkBU,EAAWC,EAAWC,EACvGC,IAAoB,CACnB,IAAMC,EAAaC,GAAiBH,CAAC,EAC/BI,EAAclB,EAAc,QAASW,EAAM,SAAUA,EAAM,KAAMK,CAAU,EAC3EG,EAAcnB,EAAc,QAASC,EAAM,SAAUA,EAAM,KAAMe,CAAU,EAC3EI,EAAapB,EAAc,OAAQE,EAAK,SAAUA,EAAK,KAAMc,CAAU,EAEvEK,EAAK,GAGLC,EAAaN,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC5DO,EAAcP,IAAe,EAAI,MAAQ,MAAMA,CAAU,IACzDQ,EAAiB,CAACC,EAAcC,IAAiB,GAAGJ,CAAU,IAAIG,CAAI,KAAKC,CAAI,IAC/EC,EAAcf,EAAIE,EAAIE,EACtBY,EAAS,KAAK,KAAKf,EAAIQ,CAAE,EAEzBQ,EAAuBpB,GAA+B;AAAA,mBAC/CI,CAAC;AAAA,mBACDC,EAAIE,CAAU;AAAA,2BACNH,EAAIC,EAAIE,CAAU;AAAA;AAAA,IAEzCP,EAAa,iBAAiBS,CAAW,CAAC;AAAA,kEACoBI,CAAU;AAAA;AAAA,IAExEb,EAAa,UAAUY,CAAE,CAAC;AAAA,4CACcA,CAAE;AAAA,+CACCA,CAAE;AAAA,8BACnBA,CAAE;AAAA,4BACJO,CAAM;AAAA;AAAA;AAAA;AAAA,iCAIDA,CAAM;AAAA;AAAA;AAAA,gBAGvBE,GAAW,MAAOd,CAAU,CAAC;AAAA,uBACtBc,GAAW,MAAOd,CAAU,CAAC;AAAA;AAAA,sBAE9BO,CAAW;AAAA;AAAA;AAAA;AAAA,2BAINC,EAAe,MAAO,YAAY,CAAC;AAAA,KAGlDO,EAAarB,EAAQ,QACvB,CACE,KAAM,0BACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,WAAAM,EAAY,EAAAJ,EAAG,EAAAC,EAAG,EAAAC,CAAC,CAAC,CAAC,EACzD,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAACF,EAAGE,EAAGO,EAAI,CAAC,EAAG,UAAwB,CAChD,EACA,cAAe,CAAC,EAAGT,EAAIE,EAAIE,CAAU,CACvC,GACA,gBAAiBa,CACnB,EACA,CAAC,OAAQ,CAAClB,CAAK,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,EACjCH,EAAmBC,GAA+B;AAAA,mBAC3CI,CAAC;AAAA,mBACDC,EAAIE,CAAU;AAAA,2BACNK,EAAKP,EAAIE,CAAU;AAAA,yBACrBD,CAAO;AAAA;AAAA,2DAE2BO,CAAU;AAAA,2DACVH,EAAY,KAAK,OAAO;AAAA,0DACzBC,EAAW,KAAK,OAAO;AAAA,kEACfE,CAAU;AAAA;AAAA,IAExEb,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsCkB,CAAW,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gBAKrDG,GAAW,MAAOd,CAAU,CAAC;AAAA,uBACtBc,GAAW,MAAOd,CAAU,CAAC;AAAA,+BACrBK,CAAE;AAAA,gEAC+BA,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qCAO7BE,CAAW;AAAA,yBACvBA,CAAW;AAAA;AAAA,2BAETC,EAAe,eAAgB,cAAc,CAAC;AAAA,KAGnE,OAAOd,EAAQ,QACX,CACE,KAAM,uCACN,YAAa,CAAC,KAAM,KAAK,UAAU,CAAC,WAAAM,EAAY,EAAAJ,EAAG,EAAAC,EAAG,EAAAC,EAAG,QAAAC,CAAO,CAAC,CAAC,EAClE,WAAY,KAAO,CACjB,QAAS,CACP,CAAC,KAAM,CAACH,EAAGE,EAAG,CAAC,EAAG,UAAwB,CAC5C,EACA,cAAe,CAAC,EAAG,KAAK,KAAKa,EAAc,EAAuB,CAAC,CACrE,GACA,gBAAAnB,CACF,EACA,CAAC,OAAQ,CAACuB,EAAY9B,EAAOC,CAAI,EAAG,QAAS,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAC3D,EAEErB,GACF,CAAC6B,EAAyBpB,EAA+BC,IAAuC,CAC9F,IAAMC,EAASF,EAAO,CAAC,EAAE,KACnBG,EAAcD,EACdwC,EAAIxC,EAAO,CAAC,EACZM,EAAIN,EAAOA,EAAO,OAAS,CAAC,EAC5ByC,EAAIrC,EAAU,kBAAkBJ,EAAQ,CAAC,EAAIM,EAE7CkB,EAAaC,GAAiBnB,CAAC,EAC/BoC,EAAatC,EAAU,KAAKH,CAAW,EAAIuB,EAC3CE,EAAclB,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM0B,CAAU,EACnFmB,EAAe/B,EAAe,SAAUd,EAAO,CAAC,EAAE,SAAUG,EAAauB,CAAU,EAEnFV,EAAW8B,GAA4B9C,EAAO,CAAC,EAAE,QAAQ,EACzD+C,EAAYrB,IAAe,EAAI,QAAU,QAAQA,CAAU,IAC3DsB,EAAgBtB,IAAe,EAAIV,EAAW,MAAMU,CAAU,IAAIV,CAAQ,IAE1EiC,EAAoB3D,GAAY8B,EAASpB,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAG0C,EAAGC,EAAGnC,EAAGP,EAAW,OAAO,EAErGiB,EAAmBC,GAA+B;AAAA,mBAC3CwB,CAAC;AAAA,mBACDnC,EAAIkB,CAAU;AAAA;AAAA,2DAE0BE,EAAY,KAAK,OAAO;AAAA,gEACnBmB,CAAS;AAAA,kEACPF,EAAa,KAAK,OAAO;AAAA;AAAA,IAEvF1B,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kDAMsB6B,CAAa,eAAeA,CAAa;AAAA,KAErF5B,EAAQ,QACJ,CACE,KAAM,wBACN,YAAa,CAAC,KAAM,GAAGnB,EAAW,QAAQ,EAAE,EAC5C,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAME,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAK4C,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAA1B,CACF,EACA,CAAC,OAAQ,CAAClB,EAAO,CAAC,EAAGiD,CAAiB,CAAC,CAAC,CAC9C,EAESzD,GAA+BS,GACxCiD,GAA4B,CAAC,QAASjD,EAAW,QAAS,OAAQA,EAAW,MAAM,CAAC,EAE3ER,GAAe,CAAC2B,EAAyBnB,IAA6C,CAC7FA,EAAW,SAAW,OACxBV,GAAkC6B,EAASA,EAAQ,OAAQnB,CAAU,EAErEmB,EAAQ,QAAQ/B,GAA8B+B,EAAQ,OAAQnB,CAAU,CAAC,CAE7E,ICtRA,IAgBMkD,GAMAC,GAiGOC,GAGAC,GA1HbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAOMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,CAE3D,EAEMT,GACF,CAACS,EAA+BC,EAAiCC,IAAqC,CACpG,IAAMC,EAASH,EAAO,CAAC,EAAE,KACnBI,EAAQJ,EAAO,CAAC,EAChBK,EAAOL,EAAO,CAAC,EAEfM,EAAcH,EACdI,EAAOC,EAAU,cAAcP,EAAW,KAAME,EAAO,MAAM,EAC7DM,EAAYD,EAAU,gBAAgBL,EAAQI,CAAI,EAClDG,EAAWF,EAAU,kBAAkBL,EAAQI,CAAI,EAEnDI,EAAYH,EAAU,KAAKJ,EAAM,IAAI,EACrCQ,EAAWP,EAAOG,EAAU,KAAKH,EAAK,IAAI,EAAI,EACpD,GAAIM,IAAcD,GAAaL,GAAQO,IAAaF,EAClD,MAAM,IAAI,MAAM,+BAA+BA,CAAQ;AAAA;AAAA,2BAEpCC,CAAS,qBAAqBC,CAAQ,EAAE,EAG7D,IAAMC,EAAmB,CAAC,EAC1B,QAASC,EAAI,EAAGA,EAAIX,EAAO,OAAQ,EAAEW,EAC/BA,EAAIP,EACNM,EAAiB,KAAKV,EAAOW,CAAC,CAAC,EAE/BD,EAAiB,KAAK,CAAC,EAI3B,IAAME,EAAaC,GAAiBN,CAAQ,EACtCO,EAAWC,GAA4BlB,EAAO,CAAC,EAAE,QAAQ,EACzDmB,EAAY,CAChBC,EAAc,IAAKpB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMe,CAAU,EACjEK,EAAc,QAAShB,EAAM,SAAUA,EAAM,KAAMW,CAAU,CAC/D,EACIV,GACFc,EAAU,KAAKC,EAAc,OAAQf,EAAK,SAAUA,EAAK,KAAMU,CAAU,CAAC,EAE5EI,EAAU,KAAKE,EAAe,SAAUrB,EAAO,CAAC,EAAE,SAAUM,EAAaS,CAAU,CAAC,EAEpF,IAAMO,EAAoBpB,EAAc,EAClCqB,EAAkBrB,EAAc,EAElCoB,GACFH,EAAU,KAAKE,EAAe,mBAAkCR,CAAgB,CAAC,EAE/EU,GACFJ,EAAU,KAAKE,EAAe,iBAAgCR,CAAgB,CAAC,EAGjF,IAAMW,EAAmBC,GAA+B;AAAA,0BACpCf,CAAQ;AAAA,oCACEA,EAAWK,CAAU;AAAA,yBAChCd,EAAW,OAAO;AAAA;AAAA,IAEvCwB,EAAa,iBAAiB,GAAGN,CAAS,CAAC;AAAA,IAC3CM,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsChB,CAAS,CAAC;AAAA;AAAA,uBAE5CiB,GAAW,MAAOX,CAAU,CAAC;AAAA,6BACvBW,GAAW,MAAOX,CAAU,CAAC;AAAA;AAAA;AAAA,oBAGtCY,GAAUV,EAAUF,EAAY,eAAe,CAAC;AAAA;AAAA;AAAA;AAAA,iBAInDa,GAAU,aAAcb,CAAU,CAAC;AAAA,4BACxBa,GAAU,mBAAoBb,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI9CY,GAAUV,EAAUF,EAAY,eAAe,CAAC;AAAA,uBAChDY,GAAUV,EAAUF,EAAY,UAAU,CAAC;AAAA,6BACrCI,EAAU,CAAC,EAAE,KAAK,KAAK;AAAA,UAC1Cd,EAAO,KAAKsB,GAAUV,EAAUF,EAAY,SAAS,CAAC,GAAK,EAAE;AAAA;AAAA;AAAA;AAAA,MAIjEO,EAAoB,oCAAsC,EAAE;AAAA,MAC5DC,EAAkB,4CAA8C,EAAE;AAAA,KAE5DM,EAAU,CAAC,CAAC,KAAMvB,EAAa,SAAUN,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIsB,GACFO,EAAQ,KAAK,CAAC,KAAMhB,EAAkB,UAAwB,CAAC,EAE7DU,GACFM,EAAQ,KAAK,CAAC,KAAMhB,EAAkB,UAAwB,CAAC,EAG1D,CACL,KAAM,qBACN,YAAa,CAAC,KAAM,GAAGZ,EAAW,QAAQ,IAAIC,CAAW,IAAIF,EAAO,MAAM,EAAE,EAC5E,WAAY,KAAO,CAAC,QAAA6B,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKpB,EAAY,EAAuB,CAAC,CAAC,GAC/F,gBAAAe,CACF,CACF,EAEShC,GAA4BS,GACrC6B,GAA4B,CAAC,KAAM7B,EAAW,KAAM,QAASA,EAAW,OAAO,CAAC,EAEvER,GAAY,CAACsC,EAAyB9B,IAA0C,CAC3FX,GAAeyC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQxC,GAA2BwC,EAAQ,OAAQ9B,EAAY8B,EAAQ,WAAW,CAAC,CAC7F,IC7HA,IASMC,GAUOC,GAnBbC,GAAAC,EAAA,kBAIAC,KAGAC,KAEML,GAAkBM,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,IAAMA,EAAO,CAAC,EAAE,KAAKA,EAAO,CAAC,EAAE,KAAK,OAAS,CAAC,EACxF,MAAM,IAAI,MAAM,kCAAkC,CAEtD,EAEaL,GAAUM,GAAkC,CACvDP,GAAeO,EAAQ,MAAM,EAC7B,IAAMC,EAAcC,GAAc,UAAUF,EAAQ,OAAO,CAAC,EAAE,KAAMA,EAAQ,OAAO,CAAC,EAAE,KAAM,EAAI,EAChG,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,uCAAwC,EAE1DD,EAAQ,QAAQG,GAAwBH,EAAQ,OAAQ,CAAC,WAAY,GAAI,mBAAoB,EAAE,EAAGC,CAAW,CAAC,CAChH,IC1BA,IAkBMG,GAmBAC,GA8BAC,GA+BAC,GA2BAC,GA2BAC,GAkBAC,GA0BAC,GAaAC,GA0BOC,GAMAC,GAjPbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KASMhB,GAAkBiB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,2BAA2B,EAG7C,GAAIA,EAAO,QAAU,EAAG,CACtB,IAAIC,EAAYD,EAAO,CAAC,EAAE,KAAK,OAAS,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,EAI9D,GAHIA,EAAO,SAAW,IACpBC,EAAYD,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IAAMA,EAAO,CAAC,EAAE,KAAK,CAAC,GAEpD,CAACC,EACH,MAAM,IAAI,MAAM,6EAA6E,CAEjG,CACF,EAEMjB,GACF,CAACkB,EAAuBC,EAA+BC,EACtDC,EAAiCC,EAAgBC,EAAkBC,IAAkC,CACpG,IAAMC,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,sBACKR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,uBAI5CP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA,4BAGPN,EAAaM,CAAC,CAAC;AAAA,UAIrC,MAAO;AAAA,oBACOJ,CAAQ,IAAIC,CAAa;AAAA;AAAA;AAAA;AAAA,cAI/BE,CAAK;AAAA;AAAA;AAAA,OAIf,EAEEzB,GACF,CAACiB,EAAuBC,EAA+BC,EACtDC,EAAiCC,IAA2B,CAC3D,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,gCAKvC,GAAKP,EAAUO,CAAC,EAAI,EAAE;AAAA;AAAA,4BAE1BP,EAAUO,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,gCAIRN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEExB,GACF,CAACgB,EAAuBC,EAA+BC,EACtDC,EAAiCC,IAA2B,CAC3D,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA;AAAA;AAAA,2BAI5CP,EAAUO,CAAC,CAAC;AAAA,wBACfP,EAAUO,CAAC,EAAI,CAAC;AAAA;AAAA,gCAERN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEvB,GACF,CAACe,EAAuBC,EAA+BC,EACtDC,EAAiCC,IAA2B,CAC3D,IAAMG,EAAYL,EAAU,OAExBM,EAAQ,GACZ,QAASC,EAAIF,EAAY,EAAGE,GAAK,EAAG,EAAEA,EACpCD,GAAS;AAAA,0BACSR,EAAO,WAAW,UAAWS,CAAC,CAAC,OAAOL,EAAKK,CAAC,CAAC;AAAA;AAAA,yBAE9CP,EAAUO,CAAC,CAAC;AAAA;AAAA,2BAEVP,EAAUO,CAAC,CAAC;AAAA,yBACdP,EAAUO,CAAC,CAAC;AAAA;AAAA,gCAELN,EAAaM,CAAC,CAAC;AAAA,cAIzC,MAAO;AAAA;AAAA;AAAA,gBAGGD,CAAK;AAAA;AAAA,WAGjB,EAEEtB,GACF,CAACc,EAAuBC,EAA+BC,EACtDC,EAAiCO,EAA2BL,IAA6B,CACxF,OAAQK,EAAW,KAAM,CACvB,IAAK,GACH,OAAO5B,GACHkB,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,KAAML,EAAUK,EAAW,KAAK,EAC9F,IAAK,GACH,OAAO3B,GAAciB,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,IAAI,EACnF,IAAK,GACH,OAAO1B,GAAWgB,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,IAAI,EAChF,IAAK,GACH,OAAOzB,GAAWe,EAAQC,EAAYC,EAAWC,EAAcO,EAAW,IAAI,EAChF,QACE,MAAM,IAAI,MAAM,cAAc,CAClC,CACF,EAEEvB,GACF,CAACwB,EAA4Bb,EAA+BY,EAA2BL,IACzE,CACR,IAAMH,EAAYJ,EAAO,CAAC,EAAE,KACtBG,EAAaW,EAAU,SAASV,EAAU,MAAM,EAAGQ,EAAW,IAAI,EAClEG,EAAaD,EAAU,KAAKX,CAAU,EACtCE,EAAeS,EAAU,eAAeV,CAAS,EAEjDF,EAASc,EAAe,SAAUhB,EAAO,CAAC,EAAE,SAAUG,CAAU,EAChEc,EAAQC,EAAc,IAAKlB,EAAO,CAAC,EAAE,SAAUI,CAAS,EAExDe,EAAa/B,GAAcc,EAAQC,EAAYC,EAAWC,EAAcO,EAAYL,CAAQ,EAYlG,MAXgB;AAAA,gBACVM,EAAa,iBAAiBI,EAAOf,CAAM,CAAC;AAAA,gBAC5CW,EAAa,UAAU,CAAC;AAAA,gBACxBA,EAAa,sCAAsCE,CAAU,CAAC;AAAA;AAAA,8BAEhDb,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,4BAEtCK,CAAQ;AAAA,gBACpBY,CAAU;AAAA;AAAA,YAIlB,EAEF7B,GAAuB,CAACU,EAA+BY,IAA2C,CACtG,IAAMQ,EAAcN,EAAU,SAASd,EAAO,CAAC,EAAE,KAAK,MAAM,EAAGY,EAAW,IAAI,EAC9E,MAAO,CACL,KAAM,MACN,YAAa,CAAC,KAAMA,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMQ,EAAa,SAAUpB,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKc,EAAU,KAAKM,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBP,GAAgBxB,GAAgBwB,EAAcb,EAAQY,EAAY,KAAK,CAC1F,CACF,EAEMrB,GAAgC,CAACS,EAA+BY,IAA6C,CACjH,GAAIZ,EAAO,OAAS,EAAG,CACrB,IAAMqB,EAAerB,EAAO,CAAC,EAAE,iBAAiB,EAC1CsB,EAAStB,EAAO,QAAU,GAAKA,EAAO,CAAC,EAAE,KAAQA,EAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAAI,EAElFS,EAAYT,EAAO,CAAC,EAAE,KAAK,OAC3BuB,EAAa,IAAI,WAAW,EAAId,CAAS,EAAE,KAAK,CAAC,EACvD,GAAIT,EAAO,QAAU,EAAG,CACtB,IAAMwB,EAAOxB,EAAO,CAAC,EAAE,iBAAiB,EACxC,QAASW,EAAI,EAAGA,EAAIa,EAAK,OAAQb,IAC/BY,EAAW,OAAOC,EAAKb,CAAC,CAAC,CAAC,EAAI,OAAOU,EAAaV,CAAC,CAAC,EACpDY,EAAW,OAAOC,EAAKb,CAAC,CAAC,EAAIF,CAAS,EAAI,OAAOY,EAAaV,EAAIa,EAAK,MAAM,CAAC,CAElF,MACEH,EAAa,QAAQ,CAACI,EAAGd,IAAMY,EAAW,OAAOZ,CAAC,CAAC,EAAK,OAAOc,CAAC,CAAE,EAGpE,IAAMnB,EAAiB,CAAC,EACxB,OAAAiB,EAAW,QAAQE,GAAKnB,EAAK,KAAKmB,CAAC,CAAC,EAE7BC,GAA4B,CAAC,KAAMd,EAAW,KAAM,MAAAU,EAAO,KAAAhB,CAAI,CAAC,CACzE,KACE,QAAOM,CAEX,EAEapB,GAAM,CAACmC,EAAyBf,IAAoC,CAC/E7B,GAAe4C,EAAQ,MAAM,EAC7B,IAAMC,EAAoBrC,GAA8BoC,EAAQ,OAAQf,CAAU,EAClFe,EAAQ,QAAQrC,GAAqBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACxF,EAEanC,GAAsBmB,GAAuD,CACxF,IAAMiB,EAAOjB,EAAW,KAClBU,EAAQV,EAAW,MACnBN,EAAOM,EAAW,KACxB,OAAOc,GAA4B,CAAC,KAAAG,EAAM,MAAAP,EAAO,KAAAhB,CAAI,CAAC,CACxD,ICtPA,IAgBMwB,GASAC,GA4BAC,GAwKAC,GAaAC,GA4BOC,GAYAC,GAKPC,GAYOC,GAKAC,GAUPC,GAqBOC,GAKAC,GAgBAC,GAKAC,GAjWbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAQMnB,GAAkBoB,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,4BAA4B,EAE9C,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,GAAKA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC3D,MAAM,IAAI,MAAM,mDAAmD,CAEvE,EAEMnB,GAA0C,CAC5CoB,EAAmBC,EAA2BC,IAAyD,CACzG,IAAMC,EAAiBF,EAAW,SAAW,OACvCG,EAA2BJ,EAAM,KAAK,MAAM,EAC9CG,GACFC,EAAyB,OAAO,EAAG,EAAGA,EAAyB,IAAI,CAAE,EAEvE,IAAMC,EAAe,OAAO,eAAe,KAAKJ,EAAY,WAAW,EACjEK,EAAcL,EAAW,YAAY,MAAM,EAC3CM,EAAUN,EAAW,QAAQ,MAAM,EACnCO,EAAsBH,EAAgBJ,EAAiC,UAAU,MAAM,EAAI,CAAC,EAC5FQ,EAAOR,EAAW,KAAK,MAAM,EACnCS,GAAa,qBAAqBR,EAAkBE,EAA0BE,EAAaC,EAASC,EAAWC,CAAI,EAEnH,IAAME,EAA4BD,GAAa,uBAC3CR,EAAkBE,EAA0BG,EAASC,EAAWF,EAAaG,EAAMR,EAAW,OAAO,EAEnGW,EAAgB,OAAO,OAAO,CAAC,EAAGX,CAAU,EAC9CI,EACF,OAAO,OAAOO,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,UAAAD,EAAW,SAAUP,EAAW,QAAQ,CAAC,EAEnG,OAAO,OAAOW,EAAe,CAAC,YAAAN,EAAa,QAAAC,EAAS,KAAAE,EAAM,SAAUR,EAAW,QAAQ,CAAC,EAE1F,IAAMY,EAA2BF,EAA0B,MAAM,EACjE,OAAAE,EAAyB,KAAKA,EAAyB,OAAO,EAAG,CAAC,EAAE,CAAC,CAAC,EAC/D,CAACD,EAAeT,EAAiBU,EAA2BF,CAAyB,CAC9F,EAEM9B,GAAsB,CACxBiC,EAA4BC,EAAkBC,EAA2BC,EACzEhB,EAA2BiB,EAAaC,EAAaC,IAA0B,CACjF,IAAMjB,EAAiBF,EAAW,SAAW,OACvCoB,EAAYL,EACZM,EAAWP,EAAE,KAAK,MAClBQ,EAAOF,EAAU,OACjBG,EAAaC,EAAU,KAAKR,CAAW,EACvCS,EAASC,EAAe,SAAUZ,EAAE,KAAK,OAAQE,CAAW,EAElE,GAAIhB,EAAW,YAAY,QAAU,EAAG,CACtC,IAAM2B,EAAK3B,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7D4B,EAAK5B,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrD6B,EAAU7B,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxD8B,EAAQ9B,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClD+B,EAAUT,GAAQpB,EAAiB,EAAI,GACzC8B,EAAQ,GACRC,EAAQ,GACRC,EAAW,GAqBf,GApBIL,EAAUC,IAAU,EACtBE,EAAQ;AAAA,4CAC8BL,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,iCAC/CE,CAAO,qBAAqBA,CAAO,QAAQX,EAAUW,CAAO,CAAC;AAAA;AAAA;AAAA;AAAA,kCAI5DjB,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAGjBe,EAAQ;AAAA,4CAC8BL,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,CAAO;AAAA,kCAC9Cf,EAAE,gBAAgB,UAAU,CAAC;AAAA,oBAC3CG,CAAG;AAAA,mBAIfjB,EAAW,YAAY,SAAW,EAAG,CACvC,IAAMmC,EAAKnC,EAAW,YAAYA,EAAW,YAAY,OAAS,CAAC,EAC7DoC,EAAKpC,EAAW,QAAQA,EAAW,QAAQ,OAAS,CAAC,EACrDqC,GAAUrC,EAAW,KAAKA,EAAW,KAAK,OAAS,EAAI,CAAC,EACxDsC,GAAQtC,EAAW,KAAKA,EAAW,KAAK,OAAS,CAAC,EAClDuC,EAAUjB,GAAQpB,EAAiB,EAAI,GACvCsC,GAAOpB,EAAUmB,CAAO,EAC1BF,GAAUC,KAAU,EACtBL,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,EAAO;AAAA,iCAC/CE,CAAO,qBAAqBA,CAAO,QAAQC,EAAI;AAAA,4BACpDb,CAAE;AAAA;AAAA;AAAA,gBAKtBM,EAAQ;AAAA,4CAC4BE,CAAE;AAAA,6BACjBI,CAAO,eAAeA,CAAO,OAAOH,CAAE,MAAMC,EAAO;AAAA,kBAG1EH,EAAW;AAAA;AAAA,aAGb,CAoBA,MAlBoB;AAAA,cACVrB,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,cAExCZ,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,2BAExCJ,CAAQ,MAAMA,CAAQ,IAAIF,CAAK;AAAA;AAAA,gBAE1Cc,CAAK;AAAA,gBACLD,CAAK;AAAA,gBACLE,CAAQ;AAAA,gBACRhB,CAAG;AAAA;AAAA;AAAA,cAKjB,KAAO,CACL,GAAIhB,EACF,MAAM,IAAI,MAAM,uEAAuE,EAEzF,IAAMuC,EAAajB,EAAU,KAAKxB,EAAW,WAAW,EAClD0C,EAAgBlB,EAAU,eAAexB,EAAW,WAAW,EAC/D2C,EAAcD,EAAc,OAC5BE,EAAW5C,EAAW,KAAK,OAC3B6C,EAAU7C,EAAW,KAAK,OAAO,CAAC8C,EAAKC,IAAQD,EAAMC,CAAG,EAC1DC,EAAU,GACd,OAAIH,EACFG,EAAU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAQgBlC,EAAE,gBAAgB,UAAU,CAAC;AAAA,kBAC3CG,CAAG;AAAA,iBAGf+B,EAAU;AAAA;AAAA,8BAEclC,EAAE,gBAAgB,UAAU,CAAC;AAAA,gBAC3CG,CAAG;AAAA,cAGK;AAAA,cACVJ,EAAa,iBAAiBC,EAAGW,CAAM,CAAC;AAAA;AAAA,sCAEhBmB,CAAQ,KAAK5C,EAAW,KAAK,IAAIiD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,2CACnD3B,CAAI,KAAKF,EAAU,IAAI6B,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+CAC1CN,CAAW,KAAKD,EAAc,IAAIO,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC/DN,CAAW,KAAK3C,EAAW,QAAQ,IAAIiD,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA;AAAA,cAEzFpC,EAAa,UAAU,CAAC;AAAA,gBACtBA,EAAa,sCAAsCU,CAAU,CAAC;AAAA;AAAA,8BAEhDE,EAAO,gBAAgB,YAAY,CAAC;AAAA,+BACnCA,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,wCAE3BkB,CAAW;AAAA;AAAA,4BAEvBlB,EAAO,KAAK,KAAK,IAAIN,CAAK;AAAA;AAAA;AAAA;AAAA,0CAIZsB,CAAU;AAAA;AAAA,uCAEbE,EAAc,CAAC;AAAA;AAAA;AAAA;AAAA,0BAI5BA,EAAc,CAAC;AAAA;AAAA;AAAA,+BAGVrB,EAAOqB,CAAW,UAAUrB,CAAI;AAAA,2DACJA,EAAOqB,CAAW;AAAA,oCACzCrB,EAAOqB,CAAW;AAAA,oBAClCK,CAAO;AAAA;AAAA,gBAEX9B,CAAG;AAAA;AAAA;AAAA,cAKjB,CACF,EAcMrC,GAA6BmB,IAA+D,CAChG,OAAQA,EAAW,OACnB,QAAS,CAAC,SAAU,QAAS,aAAc,YAAY,EAAEA,EAAW,QAAkB,EACtF,SAAUA,EAAW,UACrB,YAAaA,EAAW,aACxB,QAASA,EAAW,QACpB,KAAMA,EAAW,IACnB,GAMMlB,GACF,CAACoE,EAAcnD,EAAmBE,EAA2BD,IAAmD,CAC9G,GAAM,CAACmD,EAAoBnC,CAAW,EAClCrC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEwC,EAAajB,EAAU,KAAK2B,EAAmB,WAAW,EAE1DrC,EAAIsC,EAAc,IAAKrD,EAAM,SAAUA,EAAM,IAAI,EACjDsB,EAAWP,EAAE,KAAK,MAElBG,EAAM,kBACRC,EAAM,GACV,OAAIiC,EAAmB,gBACrBjC,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,KAEzCvB,GAAO,YAAYG,CAAQ,IAAIoB,CAAU,WAEpC,CACL,KAAAS,EACA,YAAa,CAAC,KAAMlD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMgB,EAAa,SAAUjB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbjC,GAAoBiC,EAAcC,EAAGf,EAAM,KAAMiB,EAAamC,EAAoBlC,EAAKC,EAAK,KAAK,CACvG,CACF,EAESnC,GAA8BiB,GAA+D,CACxG,IAAMqD,EAAmBrD,EAAW,oBAAiC,EAE/DsD,EAAOzE,GAA0BmB,CAAU,EAEjD,GAAIsD,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,wEAAwE,EAG1F,OAAOC,GAA4B,CAAC,gBAAAF,EAAiB,GAAGC,CAAI,CAAC,CAC/D,EAEatE,GAAc,CAACwE,EAAyBxD,IAA4C,CAC/FtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ1E,GAA6B,cAAe0E,EAAQ,OAAO,CAAC,EAAG,GAAOxD,CAAU,CAAC,CACnG,EAEMf,GAAuB,CAC3B,QAAS,GACT,SAAU,EACV,gBAAiB,GACjB,YAAa,CAAC,EACd,QAAS,CAAC,EACV,KAAM,CAAC,EACP,aAAc,EACd,UAAW,CAAC,EACZ,SAAU,EACZ,EAEaC,GAAoCc,GAA+D,CAC9G,IAAMyD,EAASzD,EAAW,OAC1B,MAAO,CAAC,OAAAyD,EAAQ,GAAGxE,GAAsB,SAAUwE,CAAM,CAC3D,EAEatE,GAAoB,CAACqE,EAAyBxD,IAA4C,CACrGtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQ1E,GAA6B,oBAAqB0E,EAAQ,OAAO,CAAC,EAAG,GAAMxD,CAAU,CAAC,CACxG,EAOMZ,GACF,CAAC8D,EAAcnD,EAAmBE,EAA2BD,IAA+C,CAC1G,GAAM,CAACmD,EAAoBnC,CAAW,EAClCrC,GAAwCoB,EAAOC,EAAYC,CAAgB,EACzEgB,EAAM;AAAA;AAAA,MAGNC,EAAM,GACNJ,EAAIsC,EAAc,IAAKrD,EAAM,SAAUA,EAAM,IAAI,EACvD,MAAO,CACL,KAAAmD,EACA,YAAa,CAAC,KAAMlD,EAAW,QAAQ,EACvC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMgB,EAAa,SAAUjB,EAAM,QAAQ,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKyB,EAAU,KAAKR,CAAW,EAAI,EAAuB,CAAC,CACrF,GACA,gBAAiBH,GACbjC,GAAoBiC,EAAcC,EAAGf,EAAM,KAAMiB,EAAamC,EAAoBlC,EAAKC,EAAK,MAAM,CACxG,CACF,EAES7B,GAAU,CAACmE,EAAyBxD,IAAwC,CACvFtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpE,GAAyB,UAAWoE,EAAQ,OAAO,CAAC,EAAG,GAAOxD,CAAU,CAAC,CAC3F,EAEaV,GAA0BU,GAA2D,CAChG,IAAM0D,EAAe1D,EAAW,cAC1BO,EAAYP,EAAW,UAEvBsD,EAAOzE,GAA0BmB,CAAU,EAEjD,GAAI0D,IAAiB,EACnB,MAAM,IAAI,MAAM,6DAA6D,EAE/E,GAAIJ,EAAK,WAAa,EACpB,MAAM,IAAI,MAAM,oEAAoE,EAGtF,OAAOC,GAA4B,CAAC,aAAAG,EAAc,UAAAnD,EAAW,GAAG+C,CAAI,CAAC,CACvE,EAEa/D,GAAgCS,GAA2D,CACtG,IAAMyD,EAASzD,EAAW,OAC1B,MAAO,CAAC,OAAAyD,EAAQ,GAAGxE,GAAsB,SAAUwE,CAAM,CAC3D,EAEajE,GAAgB,CAACgE,EAAyBxD,IAAwC,CAC7FtB,GAAe8E,EAAQ,MAAM,EAC7BA,EAAQ,QAAQpE,GAAyB,gBAAiBoE,EAAQ,OAAO,CAAC,EAAG,GAAMxD,CAAU,CAAC,CAChG,ICpWA,IAUM2D,GAUAC,GAwBOC,GA5CbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GAAwB,CAACQ,EAAeC,EAAeC,IAAwB,CACnF,IAAMC,EAAiBH,IAAUC,EAC3BG,EAA8BJ,EAAQC,GAASC,EAAQ,EACvDG,EAA8BL,EAAQC,GAASC,EAAQ,EAE7D,GAAIC,GAAkBC,GAA+BC,EACnD,MAAM,IAAI,MAAM,2CAA4C,CAEhE,EAEMZ,GAAyB,CAACO,EAAeC,EAAeC,EAAeI,IAAoC,CAC/G,IAAMC,EAAc,KAAK,IAAI,KAAK,MAAMN,EAAQD,GAASE,CAAK,CAAC,EACzDM,EAAwB,CAACD,CAAW,EACpCE,EAAaF,EAEbG,EAASC,EAAe,SAAUL,EAAUE,CAAW,EACvDI,EAAWF,EAAO,KAAK,QAEvBG,EAAmBC,GAA+B;AAAA,UAChDA,EAAa,iBAAiBJ,CAAM,CAAC;AAAA,UACrCI,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA,+BACzCG,CAAQ,IAAIZ,CAAK,OAAOY,CAAQ,kBAAkBA,CAAQ,IAAIV,CAAK;AAAA,SAEhG,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,CAACF,EAAOC,EAAOC,CAAK,EAAE,IAAIa,GAAKA,EAAE,SAAS,CAAC,EAAE,KAAK,GAAG,CAAC,EAC1E,gBAAAF,EACA,WAAY,KACR,CAAC,QAAS,CAAC,CAAC,KAAML,EAAa,SAAAF,CAAQ,CAAC,EACvC,cAAe,CAAC,EAAG,KAAK,KAAKG,EAAa,EAAuB,CAAC,CAAC,EAC1E,CACF,EAEaf,GAASsB,GAAkC,CACtD,IAAIhB,EAAQ,EACRC,EAAQ,EACRC,EAAQ,EACRc,EAAQ,OAAO,CAAC,EAAE,WAAa,GACjChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,EAC3Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,cAAc,EAAE,CAAC,GAClCA,EAAQ,OAAO,CAAC,EAAE,WAAa,IACxChB,EAAQgB,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cf,EAAQe,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,EAC7Cd,EAAQc,EAAQ,OAAO,CAAC,EAAE,gBAAgB,EAAE,CAAC,GAE3CC,GAAI,OAAO,sBACbzB,GAAsBQ,EAAOC,EAAOC,CAAK,EAG3Cc,EAAQ,QAAQvB,GAAuBO,EAAOC,EAAOC,EAAOc,EAAQ,OAAO,CAAC,EAAE,QAAQ,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CACvG,IC9DA,IAgCME,GAoBAC,GASAC,GA8CAC,GA0CAC,GAkCAC,GAaAC,GAwBAC,GA2BAC,GAsBAC,GAkCAC,GAYAC,GAiDAC,GAwEAC,GA2FAC,GAOOC,GAUAC,GAhiBbC,GAAAC,EAAA,kBAKAC,KACAC,KAGAC,KAuBMrB,GAAiB,CAACsB,EAAkBC,IAAuC,CAK/E,GAJAD,EAAO,MAAOE,GAAUA,EAAQ,IAAM,IAAM,CAClB,MAAM,IAAI,MAAM,oDAAoD,CACtE,EAAE,EAEtBF,EAAO,OAAS,GAClB,GAAIC,EAAW,OAAS,UACtB,GAAI,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,gEAAgE,UAEzEC,EAAW,OAAS,SACzB,EAAED,EAAO,SAAW,GAAMA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC/EA,EAAO,SAAW,GAAKA,EAAO,CAAC,IAAM,GAAKA,EAAO,CAAC,IAAM,GAC7D,MAAM,IAAI,MAAM,+DAA+D,EAIvF,EAEMrB,GAAe,CAACqB,EAA2BG,EAAyBC,IAA2B,CACnGD,EAAK,MAAOD,GAAUA,GAAS,GAAKA,EAAQE,IAAS,IAAM,CACnC,MAAM,IAAI,MAAM,qEAAqE,CACvF,EAAE,EACxB,IAAMC,EAAY,IAAI,MAAMD,CAAI,EAAE,KAAK,CAAG,EAC1C,OAAAD,EAAK,QAAQ,CAACD,EAAOI,IAAUD,EAAUH,CAAK,EAAIF,EAAOM,CAAK,CAAC,EACxDD,CACT,EAEMzB,GACF,CAAC2B,EAA+BN,EAA8BO,EAAsBR,EACnFS,EAAiBC,IAAwB,CACxC,GAAM,CAACC,EAAeC,EAAkBC,CAAe,EAClDL,EAAe,GAAM,CAAC,EAAG,EAAG,CAAC,EAAI,CAAC,GAAKD,EAAO,OAAS,EAAK,EAAI,GAAI,EAAE,EACrEH,EAAOG,EAAO,CAAC,EAAE,KAAK,OAC5B,GAAII,EAAgB,GAAKJ,EAAO,OAASI,GAAiBJ,EAAOI,CAAa,EAAE,KAAK,OAAS,EAC5FJ,EAAOI,CAAa,EAAE,gBAAgB,EAAE,QAAST,GAAUQ,EAAI,KAAKR,CAAK,CAAC,UAEjED,EAAW,0BAA4B,qBAChD,MAAM,IAAI,MAAM,2FAA2F,EAG7G,GAAIW,EAAmB,GAAKL,EAAO,OAASK,GAAoBL,EAAOK,CAAgB,EAAE,KAAK,OAAS,EAAG,CAExG,GADAL,EAAOK,CAAgB,EAAE,gBAAgB,EAAE,QAASV,GAAUF,EAAO,KAAKE,CAAK,CAAC,EAC5EF,EAAO,SAAW,GACjBA,EAAO,SAAWI,GAASI,GAAgB,IAAMR,EAAO,SAAWC,EAAW,KAAK,OACtF,MAAM,IAAI,MACN,6FAA6F,EAEnGvB,GAAesB,EAAQC,CAAU,EAC7BA,EAAW,KAAK,OAAS,GAC3BtB,GAAaqB,EAAQC,EAAW,KAAMG,CAAI,EAAE,QAAQ,CAACF,EAAOI,IAAUN,EAAOM,CAAK,EAAIJ,CAAK,CAE/F,CACA,GAAIW,EAAkB,GAAKN,EAAO,OAASM,IACzCN,EAAOM,CAAe,EAAE,iBAAiB,EAAE,QAASX,GAAUO,EAAM,KAAK,OAAOP,CAAK,CAAC,CAAC,EACnFO,EAAM,SAAWL,GAASI,GAAgB,IAAMC,EAAM,SAAWR,EAAW,KAAK,QACnF,MAAM,IAAI,MAAM,4FAA4F,EAIhH,GAAIA,EAAW,KAAK,OAAS,EAAG,CAC9B,GAAID,EAAO,SAAWC,EAAW,KAAK,OACpC,MAAM,IAAI,MAAM,0FAA0F,EAE5G,GAAIQ,EAAM,SAAWR,EAAW,KAAK,OACnC,MAAM,IAAI,MACN,8FAA8F,CAEtG,CACA,GAAI,OAAOD,EAAW,KAAe,OAAOS,EAAU,KAAeT,EAAO,OAAS,GAAKS,EAAM,OAASL,EACvG,MAAM,IAAI,MAAM,yDAAyD,CAE7E,EAEEvB,GAA8CiC,GAChD,+JAEC,IAAM,CACL,OAAQA,EAAwB,CAC9B,IAAK,aACH,MAAO,4BACT,IAAK,qBACH,MAAO,sKAKT,IAAK,uBACH,MAAO,oCACT,IAAK,gBACH,MAAO,6LAKT,IAAK,qBACH,MAAO,gUAMT,IAAK,uBACH,MAAO,CACL,8CAA+C,kDAC/C,qCAAsC,4CACtC,oDACF,EAAE,KAAK;AAAA,CAAI,EACb,IAAK,aACH,MAAO,4CACT,QACE,MAAM,IAAI,MAAM,6BAA6BA,CAAsB,mBAAmB,CAC1F,CACF,GAAG,EACH,IAEEhC,GAA8B,CAACiC,EAA0BP,IAC3D,+EAAiF,IAAM,CACrF,OAAQO,EAAa,CACnB,IAAK,oBACH,MAAO,yIAKT,IAAK,QACH,MAAO,2BACT,IAAK,OACH,MAAO,0BACT,IAAK,qBACH,MAAO,0KAKT,IAAK,SACL,QACE,GAAIP,EAAe,GACjB,MAAO,mLAOT,MAAM,IAAI,MAAM,gBAAgBO,CAAW,mBAAmB,CAClE,CACF,GAAG,EACH,IAEEhC,GAAY,CAAC2B,EAAwBP,EAAyBC,IAA2B,CAC7F,IAAMY,EAAS,IAAI,MAAMZ,CAAI,EAAE,KAAK,CAAC,EAAE,OAAO,IAAI,MAAMA,CAAI,EAAE,KAAK,CAAC,CAAC,EAC/Da,EAAWP,EAAI,SAAW,EAAIM,EAASN,EAAI,MAAM,EACvD,OAAIP,EAAK,OAAS,GAChBA,EAAK,QAAQ,CAACe,EAAG,IAAM,CACrBF,EAAOE,CAAC,EAAID,EAAS,CAAC,EACtBD,EAAO,EAAIZ,CAAI,EAAIa,EAASd,EAAK,OAAS,CAAC,CAC7C,CAAC,EACMa,GAEFC,CACT,EAEMjC,GACF,CAACmC,EAA+BnB,EAA2BS,EAA0BN,IACrE,CACV,IAAIiB,EAAwB,CAAC,EAC7B,GAAIX,EAAM,OAAS,EACjB,GAAIN,EAAK,OAAS,EAAG,CAEnB,GADAgB,EAAW,QAASD,GAAME,EAAY,KAAKF,CAAC,CAAC,EACzC,KAAK,IAAI,GAAGf,CAAI,EAAIgB,EAAW,OACjC,MAAM,IAAI,MAAM,sBAAsB,EAExChB,EAAK,QAAQ,CAACe,EAAG,IAAME,EAAYF,CAAC,EAAIT,EAAM,CAAC,CAAC,CAClD,MACEA,EAAM,QAASS,GAAME,EAAY,KAAKF,CAAC,CAAC,MAErC,CACL,GAAIlB,EAAO,SAAW,EACpB,MAAM,IAAI,MAAM,yCAAyC,EAEzDoB,EAAcD,EAAW,IAAI,CAACjB,EAAOI,IAAU,KAAK,MAAMJ,EAAQF,EAAOM,CAAK,CAAC,CAAC,CAEpF,CACA,OAAOc,CACT,EAEFnC,GACF,CAACkC,EAA+BC,EAAgCpB,EAAkBC,IAClE,CACV,IAAMoB,GAAiB,IAAM,CAC3B,OAAQpB,EAAW,sBAAuB,CACxC,IAAK,aACH,OAAOA,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAI,GAAKD,EAAO,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGA,EAAQ,OAAO,SAAS,EAC1E,IAAK,cACH,OAAOC,EAAW,KAAK,OAAS,EAAI,KAAK,IAAI,GAAGA,EAAW,KAAK,IAAI,GAAKD,EAAO,CAAC,CAAC,EAAG,OAAO,SAAS,EACjE,KAAK,IAAI,GAAGA,EAAQ,OAAO,SAAS,EAC1E,QACE,MAAM,IAAI,MAAM,4BAA4BC,EAAW,qBAAqB,mBAAmB,CACnG,CACF,GAAG,EACHD,EAAO,KAAK,EAAK,EAAGA,EAAO,MAAM,EACjC,IAAMsB,EAAsBH,EAAW,MAAM,EAC7C,OAAIlB,EAAW,KAAK,OAAS,GAC3BA,EAAW,KAAK,QAASiB,GAAMlB,EAAOkB,CAAC,EAAIG,CAAa,EACxDpB,EAAW,KAAK,QAASiB,GAAMI,EAAoBJ,CAAC,EAAI,KAAK,MAAMC,EAAWD,CAAC,EAAIlB,EAAOkB,CAAC,CAAC,CAAC,IAE7FlB,EAAO,KAAKqB,EAAe,EAAGrB,EAAO,MAAM,EAC3CsB,EAAoB,QAAQ,CAACJ,EAAGK,IAAMD,EAAoBC,CAAC,EAAI,KAAK,MAAML,EAAIlB,EAAOuB,CAAC,CAAC,CAAC,GAEnFD,CACT,EAEFpC,GACF,CAACsC,EAAuBL,EAA+BC,EAAgCpB,EACtFU,IAAmC;AAAA,kEAC0Bc,EAAO,KAAK,OAAO,mBAC7EJ,EAAY,MAAM;AAAA,sCACYD,EAAW,MAAM,KAAKA,EAAW,IAAII,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,uCAC3DH,EAAY,MAAM,KAAKA,EAAY,IAAIG,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,kCACnEvB,EAAO,MAAM,KAAKA,EAAO,IAAIuB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,+BACvDb,EAAI,MAAM,KAAKA,EAAI,IAAIa,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,wCACrCH,EAAY,MAAM;AAAA,gCAC1BA,EAAY,MAAM;AAAA,4BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA,2EAKhBD,EAAW,MAAM;AAAA;AAAA;AAAA;AAAA,OAMtFhC,GACF,CAACsC,EAAsBD,EAAuBL,EAA+BC,EAC5EpB,EAA2BU,EAAwBgB,IAAsC;AAAA,+DAC/BF,EAAO,KAAK,OAAO,QAAQC,EAAM,KAAK,OAAO;AAAA,wCACpEN,EAAW,MAAM,KAAKA,EAAW,IAAII,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,yCAC3DH,EAAY,MAAM,KAAKA,EAAY,IAAIG,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,oCACnEvB,EAAO,MAAM,KAAKA,EAAO,IAAIuB,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,iCACvDb,EAAI,MAAM,KAAKA,EAAI,IAAIa,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,4BACnDE,EAAM,KAAK,OAAO;AAAA,kCACZL,EAAY,MAAM;AAAA,8BACtBA,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,+EAMdD,EAAW,MAAM;AAAA,mBAC7EO,CAAgB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAYvBD,EAAM,WAAW,eAAgB,IAAK,YAAY,CAAC;AAAA;AAAA;AAAA,OAKzDrC,GAAoB,CAACqC,EAAsBN,IAA0C;AAAA,yCAClDM,EAAM,KAAK,OAAO;AAAA,sCACrBN,EAAW,MAAM,KAAKA,EAAW,IAAII,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,gCAClEJ,EAAW,MAAM;AAAA,2BACtBA,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAQjF9B,GACF,CAACoC,EAAsBD,EAAuBL,EAA+BC,EAC5EpB,EAA2B0B,EAA2BC,IAAuC,CAC5F,GAAM,CAACC,EAAUC,EAAWC,EAAUC,CAAU,EAC5CZ,EAAW,SAAW,EAAI,CAAC,GAAI,EAAG,EAAG,EAAE,EAAKnB,EAAO,CAAC,IAAM,EAAM,CAAC,EAAG,EAAG,EAAG,CAAC,EAAI,CAAC,EAAG,EAAG,EAAG,CAAC,EAC9F,MAAO;AAAA;AAAA,0BAEayB,EAAM,KAAK,OAAO;AAAA,qBACvBI,CAAS,uBAAuBV,EAAWU,CAAS,CAAC;AAAA,qBACrDC,CAAQ,uBAAuBX,EAAWW,CAAQ,CAAC;AAAA,YAC5DX,EAAW,MAAM;AAAA,uBACNY,CAAU;AAAA,uBACVH,CAAQ;AAAA;AAAA,qBAEVH,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA;AAAA,8CAGZD,EAAO,KAAK,OAAO;AAAA;AAAA,sCAE3BK,CAAS;AAAA,sCACTC,CAAQ;AAAA,YAClCJ,CAAgB,0BAA0BP,EAAWU,CAAS,CAAC,6BACjEV,EAAWW,CAAQ,CAAC;AAAA,iBACbH,CAAkB;AAAA;AAAA,8BAELR,EAAWU,CAAS,CAAC;AAAA,8BACrBV,EAAWW,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAOtCX,EAAW,OAAS,CAAC;AAAA,wCACOY,CAAU;AAAA,sCACZH,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAY1C,EAEEtC,GACF,CAACmC,EAAsBD,EAAuBL,EAA+BC,EAC5EpB,EAA2BU,EAAwBsB,EAAqBN,EACxEC,EAA4BM,IAAoC,CAC/D,GAAM,CAACJ,EAAWC,CAAQ,EAAIX,EAAW,SAAW,EAAI,CAAC,EAAG,CAAC,EAAKnB,EAAO,CAAC,IAAM,EAAO,CAAC,EAAG,CAAC,EAAI,CAAC,EAAG,CAAC,EAE/FkC,EAAoCC,GAAwB,CAChE,IAAMC,EAAYD,IAAQN,EAAY,MAAQ,MAC9C,MAAO;AAAA,WACJO,CAAS,oCAAoCX,EAAM,KAAK,OAAO,oBAC9DD,EAAO,KAAK,OAAO;AAAA,4BACHJ,EAAY,SAAW,EAAI,gBAAkB,iBAAiBe,CAAG,GAAG;AAAA,8FACFnC,EAAOmC,CAAG,CAAC;AAAA,cAC3Ff,EAAYe,CAAG,CAAC,UAAUhB,EAAWgB,CAAG,CAAC,MAAMzB,EAAIyB,CAAG,CAAC,KAAKzB,EAAIyB,CAAG,CAAC,MAAMhB,EAAW,MAAM;AAAA;AAAA;AAAA;AAAA,cAI3FO,CAAgB,0CAA0CP,EAAWgB,CAAG,CAAC;AAAA,mBACpER,CAAkB;AAAA;AAAA;AAAA;AAAA,gBAIrBS,CAAS;AAAA,gBACTA,CAAS,WAAWA,CAAS,OAAOjB,EAAWgB,CAAG,CAAC;AAAA,kBACjDF,CAAc;AAAA;AAAA;AAAA,yBAGPP,CAAgB;AAAA,uBAClBC,CAAkB;AAAA;AAAA,gBAEzBS,CAAS,iBAAiBA,CAAS,KAAKjB,EAAWgB,CAAG,CAAC;AAAA;AAAA;AAAA,kCAGrCV,EAAM,KAAK,OAAO;AAAA,6BACvBU,CAAG,WAAWC,CAAS;AAAA,0BAC1BD,IAAQN,EAAY,SAASJ,EAAM,gBAAgB,kBAAkB,CAAC,KAAO;AAAA,uGACA;AAAA;AAAA;AAAA,QAIjG,EAEA,MAAO;AAAA,MACPS,EAAiCL,CAAS,CAAC;AAAA,MAC3CK,EAAiCJ,CAAQ,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAO5BE,CAAW,wBAAwBA,CAAW,yBACxDA,CAAW,yBAAyBA,CAAW;AAAA,oBACrCA,CAAW,mBAAmBA,CAAW;AAAA,oBACzCA,CAAW,2BAA2BA,CAAW;AAAA,oBACjDA,CAAW,yBAAyBA,CAAW,0BACzDA,CAAW,0BAA0BA,CAAW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CASfR,EAAO,KAAK,OAAO;AAAA,wBACtCC,EAAM,KAAK,OAAO;AAAA;AAAA;AAAA,KAItC,EAEElC,GACF,CAAC8C,EAAyBpC,EAA8BO,EAAsB8B,EAC7E7B,EAA0B8B,IAA6C,CACtE,IAAMpB,EAAakB,EAAY,KACzB3B,EAAM3B,GAAUwD,EAAUtC,EAAW,KAAMkB,EAAW,MAAM,EAE9DC,EAAcpC,GAAgBmC,EAAYmB,EAAa7B,EAAOR,EAAW,IAAI,EAC7ED,EAASsC,EAAY,MAAM,EAC3BA,EAAY,SAAW,IACzBtC,EAASmB,EAAW,IAAI,CAACjB,EAAOI,IAAUJ,IAAU,EAAI,EAAMkB,EAAYd,CAAK,EAAIJ,CAAK,EACpFD,EAAW,wBAA0B,YACvCmB,EAAcnC,GAAkBkC,EAAYC,EAAapB,EAAQC,CAAU,IAG/E,IAAMuB,EAASgB,EAAe,SAAUH,EAAY,SAAUjB,CAAW,EACnEK,EAAQgB,EAAc,QAASJ,EAAY,SAAUlB,CAAU,EAC/DuB,EAAaC,EAAU,KAAKvB,CAAW,EACvCwB,EAAUzB,EAAW,SAAWC,EAAY,QAAUD,EAAW,MAAM,CAAC0B,EAAGtB,IAAMsB,IAAMzB,EAAYG,CAAC,CAAC,EACrGG,EAAmBzB,EAAW,0BAA4B,qBAC1D6C,EAAmBC,GAA+B;AAAA,QACtDH,EAAU,GAAK;AAAA,QACf/D,GAA2CoB,EAAW,uBAAuB,CAAC;AAAA,SAC7E,IAAM,CACP,OAAQA,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA,gBACHb,GAAkBqC,EAAON,CAAU,CAAC;AAAA,gBACpCrC,GAA4BmB,EAAW,YAAaO,CAAY,CAAC;AAAA,gBAEjErB,GACIsC,EAAOD,EAAQL,EAAYC,EAAapB,EAAQU,EAAKgB,CAAgB,CAAC;AAAA,gBAEhF,IAAK,SACH,MAAO;AAAA,gBACHxC,GAA0CsC,EAAQL,EAAYC,EAAapB,EAAQU,CAAG,CAAC;AAAA,gBAEvFrB,GACIoC,EAAOD,EAAQL,EAAYC,EAAapB,EAAQ0B,EAAkBzB,EAAW,kBAAkB,CAAC;AAAA,gBAE1G,IAAK,QACH,MAAO;AAAA,cAEHX,GACImC,EAAOD,EAAQL,EAAYC,EAAapB,EAAQU,EAAKT,EAAW,YAAayB,EAC7EzB,EAAW,mBAAoBA,EAAW,cAAc,CAAC;AAAA,cAEnE,QACE,MAAM,MAAM,qBAAqB,CACrC,CACF,GAAG,CAAC;AAAA,OACH;AAAA,QACC8C,EAAa,iBAAiBtB,EAAOD,CAAM,CAAC;AAAA,QAC5CuB,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCL,CAAU,CAAC;AAAA,UAC9DE,EAAU,0CAA4C;AAAA,8BAClCpB,EAAO,gBAAgB,YAAY,CAAC;AAAA,4BACtCC,EAAM,KAAK,OAAO;AAAA,WACnC,IAAM,CACT,OAAQxB,EAAW,KAAM,CACvB,IAAK,UACH,MAAO;AAAA;AAAA,+CAE4BwB,EAAM,gBAAgB,cAAc,CAAC;AAAA;AAAA,yCAE3CxB,EAAW,kBAAkB;AAAA,mBAE5D,IAAK,SACH,MAAO,6DACT,IAAK,QACH,MAAO,4DACT,QACE,MAAM,MAAM,4BAA4BA,EAAW,IAAI,EAAE,CAC7D,CACF,GAAG,CAAC;AAAA,SACD;AAAA,SAGH,MAAO,CACL,KAAM,SACN,YAAa,CACX,KAAM,GAAGA,EAAW,QAAQ,IAAIO,CAAY,IAAIR,EAAO,OAAS,EAAIA,EAAS,EAAE,IAC3ES,EAAM,OAAS,EAAIA,EAAQ,EAAE,IAAImC,CAAO,EAC9C,EACA,gBAAAE,EACA,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAM1B,EAAa,SAAUiB,EAAY,QAAQ,CAAC,EAC7D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,EACF,CACF,EAEElD,GAAuCwD,GAAoC,CAC/E,IAAMC,EAAmBD,EAAQ,iBAGjC,OAF2B,IAAI,YAAYC,EAAkBA,EAAiB,WAAY,CAAC,EACnD,CAAC,CAE3C,EAEaxD,GAAS,CAACuD,EAAyB/C,IAAuC,CACrF,IAAMD,EAAmB,CAAC,EACpBS,EAAkB,CAAC,EACnBC,EAAgB,CAAC,EACjBF,EAAehB,GAAoCwD,CAAO,EAChEpE,GAAeoE,EAAQ,OAAQ/C,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAC3EsC,EAAQ,QACJzD,GAAwByD,EAAQ,OAAO,CAAC,EAAG/C,EAAYO,EAAcR,EAAQS,EAAOC,CAAG,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC7G,EAEahB,GAAyBO,GAA0D,CAC9F,IAAMiD,EAAYjD,EAAW,UACvBE,EAAOF,EAAW,KAClBkD,EACFlD,EAAW,wBACT+B,EAAc/B,EAAW,YACzBgC,EAAiBhC,EAAW,iBAA6B,EACzD0B,EAAqB1B,EAAW,mBAChCmD,EAA+CnD,EAAW,sBAC1DoD,EAAapD,EAAW,KAExBc,EAA4Bd,EAAW,cAAgB,GAAK,SAAWA,EAAW,YACxF,OAAOqD,GAA4B,CACjC,UAAAJ,EACA,KAAA/C,EACA,wBAAAgD,EACA,YAAAnB,EACA,eAAAC,EACA,mBAAAN,EACA,sBAAAyB,EACA,KAAAC,EACA,YAAAtC,CACF,CAAC,CACH,ICvjBA,IAeMwC,GAyDAC,GAyFOC,GAoBAC,GArLbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAMMT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,uCAAuC,EAGzD,IAAMC,EAAoBD,EAAO,CAAC,EAC5BE,EAAmBF,EAAO,CAAC,EAC3BG,EAAoBH,EAAO,CAAC,EAElC,GAAIC,EAAM,WAAaC,EAAK,UAAYD,EAAM,WAAaE,EAAM,SAC/D,MAAM,IAAI,MAAM,yCAAyC,EAG3D,GAAIF,EAAM,KAAK,SAAW,GAAKA,EAAM,KAAK,SAAW,EACnD,MAAM,IAAI,MAAM,wBAAwB,EAG1C,GAAIC,EAAK,KAAK,SAAW,GAAKA,EAAK,KAAK,SAAW,EACjD,MAAM,IAAI,MAAM,uBAAuB,EAGzC,IAAME,EAAaH,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EAC7CI,EAAiBJ,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,EACvD,GAAIC,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAME,EACtC,MAAM,IAAI,MAAM,8CAA8C,EAEhE,GAAIF,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMG,EACtC,MAAM,IAAI,MAAM,kDAAkD,EAGpE,GAAIF,EAAM,KAAK,SAAW,EACxB,MAAM,IAAI,MAAM,kBAAkB,EAEpC,GAAIA,EAAM,KAAKA,EAAM,KAAK,OAAS,CAAC,IAAMC,EACxC,MAAM,IAAI,MAAM,+CAA+C,EAEjE,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBN,EAAO,CAAC,EACjC,GAAIM,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMF,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CAEA,GAAIJ,EAAO,OAAS,EAAG,CACrB,IAAMO,EAAmBP,EAAO,CAAC,EACjC,GAAIO,EAAK,KAAK,SAAW,EACvB,MAAM,IAAI,MAAM,iBAAiB,EAEnC,GAAIA,EAAK,KAAKA,EAAK,KAAK,OAAS,CAAC,IAAMH,EACtC,MAAM,IAAI,MAAM,8CAA8C,CAElE,CACF,EAEMb,GACF,CAACS,EAA+BQ,EAAqCC,EAAqBC,IACvE,CACb,IAAMC,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAcH,EACdI,EAAaH,EACbR,EAAaO,EAAW,MAAM,EAAE,EAAE,CAAC,EACnCK,EAAmBN,EAAaC,EAAW,MAAM,EAAG,EAAE,EAAE,OAAO,CAAC,EAAI,CAAC,EACrEM,EAAejB,EAAO,OAAS,EAC/BkB,EAAelB,EAAO,OAAS,EAC/BmB,EAAgBT,GAAcD,EAAc,EAC5CW,EAAqBV,GAAcD,EAAc,EACjDY,EAA4BZ,EAAc,EAE1Ca,EAAaC,GAAiBnB,CAAU,EACxCoB,EAAY,CAChBC,EAAc,IAAKzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACjEG,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,EACpEG,EAAc,QAASzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CACvE,EACIL,GACFO,EAAU,KAAKC,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAElFJ,GACFM,EAAU,KAAKC,EAAc,OAAQzB,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAMsB,CAAU,CAAC,EAEtFE,EAAU,KAAKE,EAAe,SAAU1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAChFH,GACFK,EAAU,KAAKE,EAAe,eAA8BV,CAAgB,CAAC,EAE3EI,GACFI,EAAU,KAAKE,EAAe,iBAAgCV,CAAgB,CAAC,EAE7EK,GACFG,EAAU,KAAKE,EAAe,mBAAoB1B,EAAO,CAAC,EAAE,SAAUc,EAAaQ,CAAU,CAAC,EAEhG,IAAMK,EAAWC,GAA4B5B,EAAO,CAAC,EAAE,QAAQ,EACzD6B,EAAmBC,GAA+B;AAAA,gCAClC1B,CAAU;AAAA,0CACAA,EAAakB,CAAU;AAAA,6BACpCd,EAAW,OAAO;AAAA;AAAA,QAEvCsB,EAAa,iBAAiB,GAAGN,CAAS,CAAC;AAAA;AAAA,QAE3CM,EAAa,UAAU,CAAC;AAAA,UACtBA,EAAa,sCAAsCf,EAAaX,CAAU,CAAC;AAAA;AAAA,oBAEjE2B,GAAW,MAAOT,CAAU,CAAC;AAAA,0BACvBS,GAAW,MAAOT,CAAU,CAAC;AAAA;AAAA;AAAA,4BAG3BJ,EAAe,UAAY,KAAK;AAAA;AAAA;AAAA,YAGhDG,EAA4B,wCAA0C,EAAE;AAAA;AAAA,2BAEzDW,GAAUL,EAAUL,EAAY,OAAO,CAAC;AAAA;AAAA;AAAA;AAAA,qBAI9CW,GAAU,MAAOX,CAAU,CAAC;AAAA,8BACnBW,GAAU,YAAaX,CAAU,CAAC;AAAA,UACtDH,EAAgB,iCAAmC,EAAE;AAAA,UACrDC,EAAqB,6CAA+C,EAAE;AAAA;AAAA,uDAEzBO,CAAQ,aAAaA,CAAQ;AAAA,eACrEV,EAAe,UAAY,KAAK;AAAA;AAAA,SAG/BiB,EAAU,CAAC,CAAC,KAAMpB,EAAa,SAAUd,EAAO,CAAC,EAAE,QAAQ,CAAC,EAClE,OAAIS,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMlB,EAAkB,UAAwB,CAAC,EAE7DP,EAAc,GAChByB,EAAQ,KAAK,CAAC,KAAMvB,EAAY,SAAUX,EAAO,CAAC,EAAE,QAAQ,CAAC,EAGxD,CACL,KAAM,yBACN,YAAa,CAAC,KAAMQ,EAAW,QAAQ,EACvC,gBAAAqB,EACA,WAAY,KAAO,CAAC,QAAAK,EAAS,cAAe,CAAC,EAAG,KAAK,KAAKnB,EAAaX,EAAa,EAAE,CAAC,CAAC,EAC1F,CACF,EAEKZ,GAAgB,CAAC2C,EAAyB3B,IAA8C,CAGnGlB,GAAe6C,EAAQ,MAAM,EAG7B,IAAMD,EAAU,CAAC,CAAC,EACdC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAsB,EAAE,EAE9BC,EAAQ,YAAc,GACxBD,EAAQ,KAAK,CAAC,EAEhBC,EAAQ,QACJ5C,GAA+B4C,EAAQ,OAAQ3B,EAAY2B,EAAQ,YAAa,EAAU,EAAG,CAAC,QAAAD,CAAO,CAAC,CAC5G,EAEazC,GAAgCe,GAAiE,CAC5G,IAAM4B,EAAU5B,EAAW,QAC3B,OAAO6B,GAA4B,CAAC,QAAAD,CAAO,CAAC,CAC9C,ICxLA,IAiBME,GAkBAC,GAcAC,GAeAC,GAcAC,GAkBAC,GA2EOC,GAYAC,GAvLbC,GAAAC,EAAA,kBAGAC,KAEAC,KACAC,KAGAC,KAQMb,GAAiB,CAACc,EAA+BC,IAAsC,CAC3F,GAAI,CAACD,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,EAElC,GAAIC,EAAW,KAAK,SAAW,GAC7B,GAAIA,EAAW,KAAK,SAAWA,EAAW,OAAO,QAAUA,EAAW,KAAK,SAAWA,EAAW,KAAK,OACpG,MAAM,IAAI,MAAM,iDAAiD,UAE1DA,EAAW,OAAO,SAAWA,EAAW,KAAK,OACtD,MAAM,IAAI,MAAM,2CAA2C,EAE7DD,EAAO,MAAM,CAAC,EAAE,QAAQ,CAACE,EAAGC,IAAQ,CAClC,GAAIH,EAAOG,EAAM,CAAC,EAAE,WAAa,GAAkBH,EAAOG,EAAM,CAAC,EAAE,WAAa,EAC9E,MAAM,IAAI,MAAM,SAASA,CAAG,qCAAqC,CAErE,CAAC,CACH,EAEMhB,GAAY,CAACa,EAA+BG,IAA0B,CAC1E,IAAMC,EAAkB,CAAC,EACzB,GAAIJ,EAAO,OAASG,EAClB,GAAIH,EAAOG,CAAG,EAAE,WAAa,EAC3BH,EAAOG,CAAG,EAAE,iBAAiB,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,UACxDL,EAAOG,CAAG,EAAE,WAAa,EAClCH,EAAOG,CAAG,EAAE,cAAc,EAAE,QAAQE,GAAKD,EAAM,KAAK,OAAOC,CAAC,CAAC,CAAC,MAE9D,OAAM,IAAI,MAAM,SAASF,CAAG,qCAAqC,EAGrE,OAAOC,CACT,EAEMhB,GACF,CAACY,EAA+BC,IAAiD,CAC/E,GAAID,EAAO,OAAS,EAAG,CACrB,IAAMM,EAAmBnB,GAAUa,EAAQ,CAAC,EACtCO,EAAiBpB,GAAUa,EAAQ,CAAC,EACtCQ,EAAiBrB,GAAUa,EAAQ,CAAC,EACxC,OAAIQ,EAAK,SAAW,IAClBA,EAAO,CAAC,GAAG,MAAMR,EAAO,CAAC,EAAE,KAAK,MAAM,EAAE,KAAK,CAAC,GAEzCS,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,KACE,QAAOP,CAEX,EAEEZ,GACF,CAACqB,EAAeC,EAAeC,EAA+BJ,EAAyBK,IACzE,CACR,IAAIC,EAAWJ,EAIf,OAHIA,EAAQ,IACVI,GAAYF,EAAWJ,EAAKG,CAAK,CAAC,GAEhCE,EAAMF,CAAK,EAAI,EACV,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,EAAI,CAAC,CAAC,EAE3D,KAAK,IAAI,EAAG,KAAK,IAAIG,EAAUF,EAAWJ,EAAKG,CAAK,CAAC,CAAC,CAAC,CAElE,EAEFrB,GACF,CAACc,EAAsBW,EAAuBH,EAA+BI,IAC/D,2CAA2CD,EAAO,KAAK,OAAO,QAAQX,EAAM,KAAK,OAAO;AAAA,8BAC5EA,EAAM,KAAK,OAAO;AAAA;AAAA,yBAEvBQ,EAAW,MAAM;AAAA,gCACVI,EAAY,SAAW,EAAI,gBAAkB,kBAAkB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAOjFJ,EAAW,SAAW,EAAI,eAAiB,iBAAiB;AAAA;AAAA;AAAA,SAKpErB,GAAyB,CAACS,EAA+BC,IAA6C,CAC1G,IAAMW,EAAaZ,EAAO,CAAC,EAAE,KACvBiB,EAAYC,EAAU,KAAKN,CAAU,EACrCJ,EAAQP,EAAW,KAAK,OAAS,EAAKiB,EAAU,cAAcjB,EAAW,KAAMW,EAAW,MAAM,EAC1D,CAAC,GAAG,MAAMA,EAAW,MAAM,EAAE,KAAK,CAAC,EAC3EC,EAAQ1B,GAAUa,EAAQ,CAAC,EAC/Ba,EAAM,QAASM,GAASA,IAAS,IAAM,IAAM,CACnB,MAAM,IAAI,MAAM,kBAAkB,CACpC,EAAE,EACtBN,EAAM,SAAW,IACnBA,EAAQ,MAAML,EAAK,MAAM,EAAE,KAAK,CAAC,GAEnC,IAAMF,EAASL,EAAW,OAAO,IAAI,CAACmB,EAAOC,IAAMhC,GAAkB+B,EAAOC,EAAGT,EAAYJ,EAAMK,CAAK,CAAC,EAEjGN,EAAON,EAAW,KAAK,IAAI,CAACqB,EAAKD,IAAMhC,GAAkBiC,EAAKD,EAAGT,EAAYJ,EAAMK,CAAK,CAAC,EAE/F,GAAIL,EAAK,SAAWI,EAAW,OAC7B,QAASS,EAAI,EAAGA,EAAIT,EAAW,OAAQ,EAAES,EAClCb,EAAK,SAASa,CAAC,IAClBf,EAAO,OAAOe,EAAG,EAAG,CAAC,EACrBd,EAAK,OAAOc,EAAG,EAAGT,EAAWS,CAAC,CAAC,EAC/BR,EAAM,OAAOQ,EAAG,EAAG,CAAC,GAI1B,IAAME,EAAQV,EAAM,IAAIM,GAAQ,KAAK,KAAKA,CAAI,CAAC,EAE/CN,EAAM,QAAQ,CAACM,EAAME,EAAGG,IAAU,CAChC,GAAIL,EAAO,EAAG,CACZ,IAAMM,GAAYlB,EAAKc,CAAC,EAAIf,EAAOe,CAAC,GAAKF,EACnCO,EAASpB,EAAOe,CAAC,EACjBM,EAAWD,EAASD,EAAWZ,EAAMQ,CAAC,EAC5Cf,EAAOe,CAAC,EAAIM,EACZpB,EAAKc,CAAC,EAAIK,EACVF,EAAMH,CAAC,EAAI,CAACF,CACd,CACF,CAAC,EAED,IAAMH,EAAcJ,EAAW,MAAM,CAAC,EACtCJ,EAAK,QAAQ,CAACoB,EAAM1B,IAAM,CACxBc,EAAYY,CAAI,EAAI,KAAK,MAAMrB,EAAKqB,CAAI,EAAItB,EAAOsB,CAAI,GAAKf,EAAMe,CAAI,CAAC,CACzE,CAAC,EAED,IAAMC,EAA+B,CAAC,KAAMb,EAAa,SAAUhB,EAAO,CAAC,EAAE,QAAQ,EAE/Ee,EAASe,EAAe,SAAU9B,EAAO,CAAC,EAAE,SAAUgB,CAAW,EACjEZ,EAAQ2B,EAAc,QAAS/B,EAAO,CAAC,EAAE,SAAUY,CAAU,EAC7DoB,EAAad,EAAU,KAAKF,CAAW,EAEvCiB,EAAmBC,GAA+B;AAAA,QAClDA,EAAa,iBAAiB9B,EAAOW,CAAM,CAAC;AAAA,mCACjBQ,EAAM,MAAM,KAAKA,EAAM,IAAIF,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,oCACjDf,EAAO,MAAM,KAAKA,EAAO,IAAIe,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,kCACtDd,EAAK,MAAM,KAAKA,EAAK,IAAIc,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,mCAC/CR,EAAM,MAAM,KAAKA,EAAM,IAAIQ,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,wCAC7CT,EAAW,MAAM,KAAKA,EAAW,IAAIS,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA;AAAA,UAE1F/B,GAA0Bc,EAAOW,EAAQH,EAAYI,CAAW,CAAC;AAAA,UACjEkB,EAAa,UAAU,CAAC;AAAA,YACtBA,EAAa,sCAAsCF,CAAU,CAAC;AAAA,gCAC1CjB,EAAO,gBAAgB,YAAY,CAAC;AAAA;AAAA,YAExDA,EAAO,YAAY,aAAcX,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,SAE9E,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAM,GAAGH,EAAW,QAAQ,IAAID,EAAO,CAAC,GAAG,MAAQ,EAAE,EAAE,EACrE,gBAAAiC,EACA,WAAY,KAAO,CACjB,QAAS,CAACJ,CAAgB,EAC1B,cAAe,CAAC,EAAG,KAAK,KAAKZ,EAAY,EAAuB,CAAC,CACnE,EACF,CACF,EAEazB,GAAQ,CAAC2C,EAAyBlC,IAAsC,CACnFf,GAAeiD,EAAQ,OAAQlC,CAAU,EACzC,IAAMmC,EAAoBhD,GAAgC+C,EAAQ,OAAQlC,CAAU,EACpFkC,EAAQ,QAAQ5C,GAAuB4C,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAO1F,EAEa3C,GAAwBQ,GAAyD,CAC5F,IAAMK,EAASL,EAAW,OACpBM,EAAON,EAAW,KAClBO,EAAOP,EAAW,KACxB,OAAOQ,GAA4B,CAAC,OAAAH,EAAQ,KAAAC,EAAM,KAAAC,CAAI,CAAC,CACzD,IC5LA,IAcM6B,GAUAC,GAwHOC,GAKAC,GArJbC,GAAAC,EAAA,kBAQAC,KACAC,KAGAC,KAEMR,GAAkBS,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,8BAA8B,CAElD,EAMMR,GAA2B,CAACS,EAAmBC,IAA+C,CAClG,IAAMC,EAAQF,EAAM,KACdG,EAAaC,EAAU,KAAKF,CAAK,EACjCG,EAAK,GACPC,EAAOL,EAAW,KAItB,GAHIK,EAAO,IACTA,EAAOJ,EAAM,OAASI,GAEpBA,EAAOJ,EAAM,OAAS,EACxB,MAAM,IAAI,MAAM,0CAA0C,EAG5D,IAAMK,EAAOL,EAAMI,CAAI,EACjBE,EAAOL,EAAaI,EACpBE,EAAaC,GAAiBH,CAAI,EAClCI,EAAaJ,EAAOE,EAEpBG,EAAY,CAACC,EAAcJ,IAC3BA,IAAe,EACV,WAAWI,CAAI,OAAOA,CAAI,YAAYA,CAAI,OAAOA,CAAI,OACnDJ,IAAe,EACjB,OAAOI,CAAI,OAAOA,CAAI,MACpBJ,IAAe,EACjB,WAAWI,CAAI,OAAOA,CAAI,QAAQA,CAAI,MAGxCA,EAEHC,EAAIC,EAAc,IAAKf,EAAM,SAAUA,EAAM,KAAMS,CAAU,EAC7DO,EAASC,EAAe,SAAUjB,EAAM,SAAUA,EAAM,KAAMS,CAAU,EACxES,EAAYJ,EAAE,KAAK,MAEnBK,EAAgBC,GAA4BpB,EAAM,QAAQ,IAAM,MAClE,mBAAmBkB,CAAS,oBAC5B,mBAAmBA,CAAS,eAC1BG,EAAmBC,GAA+B;AAAA,sCACpBJ,CAAS;AAAA,sCACTA,CAAS;AAAA,4CACHA,CAAS,KAAKb,CAAE;AAAA;AAAA,4DAEAa,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA,gEAKLA,CAAS;AAAA;AAAA;AAAA;AAAA,QAIjEI,EAAa,gBAAgB,aAAc,KAAK,EAAE,iBAAiBR,EAAGE,CAAM,CAAC;AAAA,QAC7EM,EAAa,UAAU,CAAC;AAAA;AAAA;AAAA,qBAGXjB,CAAE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,UAMbc,CAAa;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAmBID,CAAS,IAAIN,EAAU,kBAAmBH,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA,0BAKtDS,CAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2BAeRA,CAAS,IAAIK,GAAU,kBAAmBd,CAAU,CAAC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SAU9E,MAAO,CACL,KAAM,UACN,YAAa,CAAC,KAAM,GAAGA,CAAU,GAAI,kBAAmB,CAAC,MAAM,CAAC,EAChE,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMP,EAAO,SAAUF,EAAM,QAAQ,CAAC,EACjD,cAAe,CAAC,EAAGQ,CAAI,EACvB,gBAAiB,CAAC,CAAC,KAAM,SAAU,KAAMG,CAAU,CAAC,CACtD,GACA,gBAAAU,CACF,CACF,EAEa7B,GAAU,CAACgC,EAAyBvB,IAAwC,CACvFX,GAAekC,EAAQ,MAAM,EAC7BA,EAAQ,QAAQjC,GAAyBiC,EAAQ,OAAO,CAAC,EAAGvB,CAAU,CAAC,CACzE,EAEaR,GAA0BQ,GACnCwB,GAA4B,CAAC,KAAMxB,EAAW,IAAc,CAAC,ICtJjE,IAgBMyB,GAMAC,GAWAC,GASAC,GAqBAC,GAkDOC,GAOAC,GAxHbC,GAAAC,EAAA,kBAIAC,KACAC,KAGAC,KAQMX,GAAkBY,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,OAAS,EAC7B,MAAM,IAAI,MAAM,gBAAgB,CAEpC,EAEMX,GACF,CAACW,EAA+BC,IAAiD,CAC/E,IAAMC,EAAuB,CAAC,EAC1BC,EAAqBF,EAAW,WACpC,OAAID,EAAO,CAAC,EAAE,KAAK,CAAC,EAAI,IACtBA,EAAO,CAAC,EAAE,iBAAiB,EAAE,QAAQI,GAAKF,EAAW,KAAK,OAAOE,CAAC,CAAC,CAAC,EACpED,EAAaD,EAAW,QAEnBG,GAA4B,CAAC,WAAAF,EAAY,KAAMF,EAAW,KAAM,WAAAC,CAAU,CAAC,CACpF,EAEEZ,GAA4BgB,GAAoC;AAAA;AAAA,gCAEtCA,CAAe;AAAA;AAAA;AAAA;AAAA;AAAA,aAKlCA,CAAe;AAAA,GAEtBf,GAAuBgB,GAAsC,CACjE,IAAMD,EAAkBC,EAAQ,OAC1BC,EAAsB,CAAC,EAC7B,QAASC,EAAI,EAAGA,EAAIH,EAAiB,EAAEG,EAAG,CACxC,IAAMC,EAAgBH,EAAQE,CAAC,EAAE,aAAa,UAAW,mBAAmB,EACxEH,IAAoB,EACtBE,EAAU,KAAKE,CAAa,EACnBD,IAAM,EACfD,EAAU,KAAK,uBAAuBC,CAAC,QAAQC,CAAa,IAAI,EACvDD,IAAMH,EAAkB,EACjCE,EAAU,KAAK,UAAUE,CAAa,IAAI,EAE1CF,EAAU,KAAK,4BAA4BC,CAAC,OAAOC,CAAa,IAAI,CAExE,CACA,MAAO;AAAA,uDAC8CH,EAAQ,CAAC,EAAE,KAAK,OAAO;AAAA,UACpEC,EAAU,KAAK;AAAA,CAAI,CAAC;AAAA,QAE9B,EAEMhB,GAAyB,CAACQ,EAA+BC,IAA6C,CAC1G,IAAMU,EAAaX,EAAO,CAAC,EAAE,KACvBY,EAAYC,EAAU,KAAKF,CAAU,EACrCG,EAAWd,EAAO,CAAC,EAAE,SACrBe,EAAOJ,EAAW,OAClBK,EAAOf,EAAW,KAClBgB,EAAgBD,EAAO,EAAKL,EAAW,OAASK,EAAOA,EACvDT,EAAU,IAAI,MAAqBN,EAAW,UAAU,EACxDiB,EAAQC,EAAc,QAASL,EAAUH,CAAU,EACnDS,EAAmB,IAAI,MAAcnB,EAAW,UAAU,EAC1DoB,EAAkC,CAAC,EACnCC,EAA2B,CAAC,EAC9BC,EAAc,EAClB,QAASd,EAAI,EAAGA,EAAIR,EAAW,WAAYQ,IAAK,CAC9Cc,GAAetB,EAAW,WAAWQ,CAAC,EACtCW,EAAiBX,CAAC,EAAIc,EACtB,IAAMC,EAAcb,EAAW,MAAM,EACrCa,EAAYvB,EAAW,IAAI,EAAIA,EAAW,WAAWQ,CAAC,EACtDa,EAAa,KAAKE,CAAW,EAC7BjB,EAAQE,CAAC,EAAIgB,EAAe,SAAShB,CAAC,GAAIK,EAAUQ,EAAab,CAAC,CAAC,EACnEY,EAAkB,KAAK,CAAC,KAAMC,EAAab,CAAC,EAAG,SAAUT,EAAO,CAAC,EAAE,QAAQ,CAAC,CAC9E,CACA,IAAM0B,EAAcX,EAAO,EAAI,UAAY,WAAWE,CAAY,IAC5DU,EAAmBC,GAA+B;AAAA,IACtDA,EAAa,iBAAiBV,EAAO,GAAGX,CAAO,CAAC;AAAA,wCACZa,EAAiB,MAAM,KAAKA,EAAiB,IAAIX,GAAK,GAAGA,CAAC,GAAG,EAAE,KAAK,GAAG,CAAC;AAAA,IAC5GnB,GAAyB8B,EAAiB,MAAM,CAAC;AAAA,IACjD7B,GAAoBgB,CAAO,CAAC;AAAA;AAAA,IAE5BqB,EAAa,UAAU,CAAC;AAAA,MACtBA,EAAa,sCAAsChB,CAAS,CAAC;AAAA;AAAA,oBAE/CM,EAAM,gBAAgB,YAAY,CAAC;AAAA,8CACTQ,CAAW;AAAA;AAAA,UAE/CA,CAAW;AAAA;AAAA;AAAA,KAInB,MAAO,CACL,KAAM,QACN,YAAa,CAAC,KAAMzB,EAAW,QAAQ,EACvC,gBAAA0B,EACA,WAAY,KAAO,CACjB,QAASN,EACT,cAAe,CAAC,EAAG,KAAK,KAAKT,EAAY,EAAuB,CAAC,CACnE,EACF,CACF,EAEanB,GAAQ,CAACoC,EAAyB5B,IAAsC,CACnFb,GAAeyC,EAAQ,MAAM,EAC7B,IAAMC,EACFD,EAAQ,OAAO,SAAW,EAAI5B,EAAaZ,GAAgCwC,EAAQ,OAAQ5B,CAAU,EACzG4B,EAAQ,QAAQrC,GAAuBqC,EAAQ,OAAQC,CAAiB,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CAC1F,EAEapC,GAAwBO,GAAyD,CAC5F,IAAMe,EAAOf,EAAW,KAClBC,EAAuBD,EAAW,WAClCE,EAAaF,EAAW,WAAuB,EAAIC,EAAW,OAASD,EAAW,WACxF,GAAIE,IAAeD,EAAW,OAC5B,MAAM,IAAI,MAAM,+CAA+C,EAEjE,OAAOG,GAA4B,CAAC,KAAAW,EAAM,WAAAb,EAAY,WAAAD,CAAU,CAAC,CACnE,IChIA,IAUM6B,GAIAC,GAyBAC,GAUOC,GAoCAC,GArFbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMT,GAAcU,GAChB,MAAM,KAAKA,EAAkB,iBAAiB,EAAG,MAAM,EAGrDT,GAAkBU,GAAwC,CAC9D,GAAI,CAACA,GAAUA,EAAO,SAAW,EAC/B,MAAM,IAAI,MAAM,yBAAyB,EAG3C,GAAIA,EAAO,CAAC,EAAE,WAAa,GAAkBA,EAAO,CAAC,EAAE,WAAa,GAChEA,EAAO,CAAC,EAAE,WAAa,GACzB,MAAM,IAAI,MAAM,uDAAuD,EAGzE,GAAIA,EAAO,CAAC,EAAE,WAAa,EACzB,MAAM,IAAI,MAAM,mDAAmD,EAGrE,GAAIA,EAAO,CAAC,EAAE,KAAK,SAAW,EAC5B,MAAM,IAAI,MAAM,oCAAoC,EAKtD,GAFmCX,GAAWW,EAAO,CAAC,CAAC,EAE3C,SAAWA,EAAO,CAAC,EAAE,KAAK,OACpC,MAAM,IAAI,MAAM,uFAAuF,CAE3G,EAEMT,GAAiB,CAACU,EAA+BC,IAAkD,CACvG,IAAMC,EAAwB,CAAC,EAE/B,QAASC,EAAI,EAAGA,EAAIH,EAAW,OAAQ,EAAEG,EACvCD,EAAY,KAAKF,EAAWG,CAAC,EAAIF,EAAQE,CAAC,CAAC,EAG7C,OAAOD,CACT,EAEaX,GAAyBQ,GAA+C,CACnF,IAAMC,EAAaD,EAAO,CAAC,EAAE,KACvBE,EAA6Bb,GAAWW,EAAO,CAAC,CAAC,EACjDG,EAAcZ,GAAeU,EAAYC,CAAO,EAChDG,EAAaC,EAAU,KAAKH,CAAW,EAEvCI,EAAWP,EAAO,CAAC,EAAE,SACrBQ,EAAQC,EAAc,QAASF,EAAUN,CAAU,EACnDS,EAASC,EAAe,SAAUJ,EAAUJ,CAAW,EAEvDS,EAAmBC,GAA+B;AAAA,2BAC/BL,EAAM,QAAQ,GAAGP,CAAU,CAAC;AAAA,QAC/CY,EAAa,iBAAiBL,EAAOE,CAAM,CAAC;AAAA,QAC5CG,EAAa,UAAU,CAAC;AAAA,QACxBA,EAAa,sCAAsCR,CAAU,CAAC;AAAA,4BAC1CK,EAAO,gBAAgB,YAAY,CAAC;AAAA,0BACtCF,EAAM,KAAK,OAAO;AAAA,4BAChBP,EAAW,MAAM;AAAA,8BACfS,EAAO,WAAW,gBAAiB,GAAG,CAAC,OAAOF,EAAM,WAAW,aAAc,GAAG,CAAC;AAAA;AAAA,UAErGA,EAAM,WAAW,eAAgB,IAAK,eAAe,CAAC;AAAA;AAAA,QAExDE,EAAO,YAAY,aAAcF,EAAM,aAAa,cAAc,CAAC,CAAC;AAAA,OAG1E,MAAO,CACL,KAAM,OACN,YAAa,CAAC,KAAM,GAAGN,CAAO,EAAE,EAChC,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUH,EAAO,CAAC,EAAE,QAAQ,CAAC,EAC3D,cAAe,CAAC,EAAG,KAAK,KAAKK,EAAa,EAAuB,CAAC,CACpE,GACA,gBAAAO,CACF,CACF,EAEanB,GAAQqB,GAAkC,CACrDxB,GAAewB,EAAQ,MAAM,EAC7BA,EAAQ,QAAQtB,GAAsBsB,EAAQ,MAAM,EAAG,CAAC,OAAQ,CAAC,CAAC,CAAC,CAAC,CACtE,ICxFA,IAUMC,GA8DAC,GA+BOC,GAvGbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAEMP,GACF,CAACQ,EAA4BC,EAA+BC,EAA+BC,EAC1FC,IAAuB,CACtB,IAAMC,EAAaC,EAAU,KAAKJ,CAAU,EACtCK,EAAU,KAAK,KAAKF,EAAa,CAAC,EAElCG,EAASC,EAAe,aAAcL,EAAYF,EAAY,CAAC,EAC/DQ,EAAIC,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEW,EAAID,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAChEY,EAAIF,EAAc,QAASV,EAAO,CAAC,EAAE,SAAUA,EAAO,CAAC,EAAE,KAAM,CAAC,EAElEa,EACEC,EAAa,CAACL,EAAWE,EAAWC,IAAc,UAAUD,CAAC,KAAKF,CAAC,KAAKG,CAAC,IAC/E,GAAI,CAACV,EACHW,EAAaN,EAAO,YAChB,aACAO,EAAWL,EAAE,YAAY,YAAY,EAAGE,EAAE,YAAY,YAAY,EAAGC,EAAE,YAAY,YAAY,CAAC,CAAC,MAChG,CACL,IAAMG,EAAmB,CAACC,EAAgBC,EAAWC,EAAW,KAAO,CACrE,IAAMC,EAAc,eAAeF,CAAC,eAAeA,CAAC,IAC9CG,EAAc,eAAeH,CAAC,eAAeA,CAAC,IAE9CI,EAAc,oBAAoBJ,CAAC,OAAO,cAAiB,EAAIA,GAAK,CAAE,KAC5E,MAAO;AAAA,+BACcA,CAAC,MAAMV,EAAO,gBAAgB,qBAAqBU,CAAC,GAAG,CAAC;AAAA,yBAC9DA,CAAC,MAAMR,EAAE,2BAA2B,gBAAgBQ,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAMN,EAAE,2BAA2B,gBAAgBM,CAAC,GAAIV,CAAM,CAAC;AAAA,yBAChEU,CAAC,MAAML,EAAE,2BAA2B,gBAAgBK,CAAC,GAAIV,CAAM,CAAC;AAAA,wBACjEU,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,wBACfA,CAAC,aAAaA,CAAC;AAAA,4BACXA,CAAC,aAAaA,CAAC;AAAA,4BACfA,CAAC,aAAaA,CAAC;AAAA,cAC7BD,CAAM,IAAIC,CAAC,OAAOC,CAAQ,IAAIJ,EAAWK,EAAaC,EAAaC,CAAW,CAAC;AAAA,WAErF,EACIlB,IAAe,EACjBU,EAAa;AAAA;AAAA,cAETE,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,cAClCA,EAAiB,OAAQ,EAAG,KAAK,CAAC;AAAA,uGAGtCF,EAAa;AAAA,cACTE,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,cAC7CA,EAAiB,yBAA0B,CAAC,CAAC;AAAA,WAGrD,CAEA,MAAO;AAAA,UACHhB,EAAa,iBAAiBa,EAAGH,EAAGE,EAAGJ,CAAM,CAAC;AAAA,UAC9CR,EAAa,UAAU,CAAC;AAAA,UACxBA,EAAa,sCAAsCO,CAAO,CAAC;AAAA,UAC3DO,CAAU;AAAA,QAEhB,EAEErB,GAA4BQ,GAA+C,CAC/E,IAAMsB,EAAQtB,EAAO,CAAC,EAAE,KAClBuB,EAAQvB,EAAO,CAAC,EAAE,KAClBwB,EAAQxB,EAAO,CAAC,EAAE,KAClByB,EAAiBzB,EAAO,CAAC,EAAE,SAE3BE,EAAc,EAAEG,EAAU,SAASiB,EAAOC,CAAK,GAAKlB,EAAU,SAASkB,EAAOC,CAAK,GACrFE,EAAcJ,EACdlB,EAAaC,EAAU,KAAKiB,CAAK,EAGrC,GAAIpB,EAAa,CACf,IAAMyB,EAAkBC,GAAc,UAAUA,GAAc,UAAUN,EAAOC,EAAO,EAAK,EAAIC,EAAO,EAAK,EAC3G,GAAI,CAACG,EACH,MAAM,IAAI,MAAM,6CAA8C,EAEhED,EAAcC,EACdvB,EAAaC,EAAU,KAAKqB,CAAW,CACzC,CAEA,MAAO,CACL,KAAM,QACN,gBAAkB3B,GACdR,GAA2BQ,EAAcC,EAAQ0B,EAAaxB,EAAauB,CAAc,EAC7F,WAAY,KAAO,CACjB,QAAS,CAAC,CAAC,KAAMC,EAAa,SAAUD,CAAc,CAAC,EACvD,cAAe,CAAC,EAAG,KAAK,KAAKrB,EAAa,GAA0B,CAAgB,CAAC,CACvF,EACF,CACF,EAEaX,GAASoC,GAAkC,CACtDA,EAAQ,QAAQrC,GAAyBqC,EAAQ,MAAM,CAAC,CAC1D,ICzGA,IAqCaC,GArCbC,GAAAC,EAAA,kBAGAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KACAC,KAOa9B,GAA+D,IAAI,IAAI,CAClF,CAAC,MAAO,CAAU+B,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAwB,CAAC,EAC7C,CAAC,SAAU,CAACC,GAAQD,EAAwB,CAAC,EAC7C,CAAC,OAAQ,CAAUE,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAE1B,CAAC,cAAe,CAAMC,GAAkBC,EAA0B,CAAC,EACnE,CAAC,UAAW,CAACC,EAAO,CAAC,EACrB,CAAC,gBAAiB,CAACC,EAAa,CAAC,EACjC,CAAC,OAAQ,CAAUC,GAAeC,EAAmB,CAAC,EACtD,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,UAAW,CAAUC,EAAO,CAAC,EAC9B,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,gBAAiB,CAACC,GAAeC,EAA4B,CAAC,EAC/D,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,MAAO,CAAUC,GAAcC,EAAoB,CAAC,EACrD,CAAC,QAAS,CAAWC,EAAK,CAAC,EAC3B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EACnB,CAAC,QAAS,CAAUC,EAAK,CAAC,EAC1B,CAAC,YAAa,CAACf,GAAMC,EAAmB,CAAC,EACzC,CAAC,SAAU,CAACe,GAAQC,EAAqB,CAAC,EAC1C,CAAC,iBAAkB,CAACC,GAAgBC,EAA6B,CAAC,EAClE,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,OAAQ,CAACC,GAAMC,EAAmB,CAAC,EACpC,CAAC,oBAAqB,CAAMC,GAAwBC,EAAgC,CAAC,EACrF,CAAC,gBAAiB,CAAMC,GAAoBC,EAA4B,CAAC,EACzE,CAAC,UAAW,CAAWC,EAAO,CAAC,EAC/B,CAAC,iBAAkB,CAAWC,EAAc,CAAC,EAC7C,CAAC,wBAAyB,CAACC,GAAcC,EAA2B,CAAC,EACrE,CAAC,qBAAsB,CAACC,GAAWC,EAAwB,CAAC,EAC5D,CAAC,YAAa,CAAUC,GAAoBvB,EAAoB,CAAC,EACjE,CAAC,OAAQ,CAAWwB,EAAI,CAAC,EACzB,CAAC,cAAe,CAAWC,EAAW,CAAC,EACvC,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,SAAU,CAACC,EAAM,CAAC,EAEnB,CAAC,UAAW,CAAMC,GAAcC,EAAsB,CAAC,EACvD,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,MAAO,CAACC,GAAKC,EAAkB,CAAC,EACjC,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,QAAS,CAACC,EAAK,CAAC,EACjB,CAAC,aAAc,CAAUC,EAAU,CAAC,EACpC,CAAC,YAAa,CAACC,GAAWC,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACC,GAAYD,EAAqB,CAAC,EAClD,CAAC,YAAa,CAACE,GAAWF,EAAqB,CAAC,EAChD,CAAC,YAAa,CAACG,GAAWH,EAAqB,CAAC,EAChD,CAAC,aAAc,CAACI,GAAYJ,EAAqB,CAAC,EAClD,CAAC,WAAY,CAACK,GAAUL,EAAqB,CAAC,EAC9C,CAAC,WAAY,CAACM,GAAUN,EAAqB,CAAC,EAC9C,CAAC,eAAgB,CAACO,GAAcP,EAAqB,CAAC,EACtD,CAAC,kBAAmB,CAACQ,GAAiBR,EAAqB,CAAC,EAC5D,CAAC,kBAAmB,CAACS,GAAiBT,EAAqB,CAAC,EAC5D,CAAC,OAAQ,CAAUU,EAAI,CAAC,EACxB,CAAC,SAAU,CAACC,GAAQC,EAAqB,CAAC,EAC1C,CAAC,UAAW,CAAUC,EAAO,CAAC,EAC9B,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,yBAA0B,CAACC,GAAeC,EAA4B,CAAC,EACxE,CAAC,QAAS,CAACC,GAAOC,EAAoB,CAAC,EACvC,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,UAAW,CAACC,GAASC,EAAsB,CAAC,EAC7C,CAAC,MAAO,CAAWC,EAAG,CAAC,EACvB,CAAC,MAAO,CAAUC,EAAG,CAAC,EACtB,CAAC,OAAQ,CAAUC,EAAI,CAAC,EACxB,CAAC,kBAAmB,CAAUC,GAA0BnE,EAAoB,CAAC,EAC7E,CAAC,OAAQ,CAACoE,EAAI,CAAC,EACf,CAAC,YAAa,CAACC,GAAWC,EAAwB,CAAC,EACnD,CAAC,QAAS,CAACC,EAAK,CAAC,CACnB,CAAC,ICzHD,IAoBaC,GApBbC,GAAAC,EAAA,kBAGAC,KAEAC,KAGAC,KAYaL,GAAN,KAAqB,CAI1B,YAAoBM,EAAwB,CAAxB,aAAAA,EAClB,KAAK,KAAO,IAAI,IAChB,KAAK,gBAAkB,EACzB,CACA,YAAYC,EAAkC,CAC5C,OAAO,KAAK,KAAK,IAAIA,CAAG,CAC1B,CACA,YAAYA,EAAcC,EAA0B,CAClD,KAAK,KAAK,IAAID,EAAKC,CAAQ,CAC7B,CACA,IAAIC,EAAyBC,EAAyCC,EAClEC,EAAmBC,EAAoBC,EACvCC,EAA0D,CAC5D,IAAMC,EAAS,KAAK,QAAQ,OAEtBC,EAAqB,KAAK,QAAQ,sBAAsB,EAC9DA,EAAmB,YAAYR,EAAc,eAAe,EAC5D,IAAMS,EAAU,CAAC,EACjB,QAAWC,KAASP,EAClBM,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQC,EAAM,MAAM,CAAC,CAAC,EAE1E,QAAWC,KAAUP,EACnBK,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAU,CAAC,OAAQE,EAAO,MAAM,CAAC,CAAC,EAEvEL,GACFG,EAAQ,KAAK,CAAC,QAASA,EAAQ,OAAQ,SAAUH,CAAoB,CAAC,EAExE,IAAMM,EAAYL,EAAO,gBACrB,CAAC,OAAQP,EAAc,gBAAgB,mBAAmB,CAAC,EAAG,QAAAS,EAAS,MAAOT,EAAc,YAAY,IAAI,CAAC,EAOjH,GANAQ,EAAmB,aAAa,EAAGI,CAAS,EAE5CJ,EAAmB,mBAAmB,GAAGH,CAAa,EAEtD,KAAK,QAAQ,wBAET,KAAK,QAAQ,eAAe,EAAG,CAC7B,OAAO,KAAK,QAAQ,UAAc,MACpC,KAAK,QAAQ,UAAY,KAAK,QAAQ,eAAe,OAEjD,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,aAAa,GAE5F,IAAMQ,EAAW,KAAK,QAAQ,eAAe,OAEzC,KAAK,QAAQ,cAAgB,EAAG,eAAe,SAAW,eAAe,QAAQ,EAErF,KAAK,QAAQ,eAAe,EAC5B,KAAK,QAAQ,kBAAkB,EAAE,gBAAgB,KAAK,QAAQ,SAAW,EAAG,EAAG,KAAK,QAAQ,UAAU,OAAQ,CAAC,EAC/G,KAAK,QAAQ,kBAAkB,EAAE,mBAC7B,KAAK,QAAQ,UAAU,OAAQ,EAAGA,EAAS,OAAQ,EAAG,KAAK,QAAQ,cAAgB,CAAC,EACxF,KAAK,QAAQ,MAAM,EAEnB,IAAMC,EAAW,KAAK,QAAQ,gBACxBC,EAAa,KAAK,QAAQ,QAAQ,IAAID,CAAQ,EAC9CE,EAAa,IAAID,EAAW,CAAC,CAAC,KAAKA,EAAW,CAAC,CAAC,GAEjDF,EAAS,OAAO,SAAS,WAAW,IAAI,EAAE,KAAK,IAAM,CACxD,IAAMI,EAAa,IAAI,eAAeJ,EAAS,OAAO,eAAe,CAAC,EAChEK,EAAeD,EAAW,CAAC,EAC3BE,EAAaF,EAAW,CAAC,EAE/BJ,EAAS,OAAO,MAAM,EAElB,OAAO,KAAK,QAAQ,cAAkB,MACxC,KAAK,QAAQ,cAAgBK,GAG/B,IAAME,EAAY,OAAOF,EAAe,KAAK,QAAQ,aAAa,EAC5DG,EAAU,OAAOF,EAAa,KAAK,QAAQ,aAAa,EAE9D,GAAI,CAAC,OAAO,cAAcC,CAAS,GAAK,CAAC,OAAO,cAAcC,CAAO,EACnE,MAAM,IAAI,WAAW,2BAA2B,EAGlD,KAAK,QAAQ,eAAe,QAAQR,EAAS,EAAE,EAC/C,IAAIS,EAAc,GAClBrB,EAAiB,QAAQ,CAACsB,EAAOC,IAAM,CACrCF,GAAe,SAASE,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC7F,CAAC,EACD,IAAIG,EAAe,GACnBxB,EAAkB,QAAQ,CAACqB,EAAOC,IAAM,CACtCE,GAAgB,UAAUF,CAAC,OAAOD,EAAM,IAAI,OAAOE,GAA2BF,EAAM,QAAQ,CAAC,IAC/F,CAAC,EAED,QAAQ,IAAI,uBAAuBT,CAAQ,IAAIE,CAAU,KAAKM,CAAW,GAAGI,CAAY,mBACpFL,EAAUD,CAAS,KAAK,CAC9B,CAAC,CACH,CAEI,KAAK,QAAQ,uBAAyB,IACxC,KAAK,QAAQ,MAAM,CAEvB,CACA,SAAgB,CAEhB,CACA,MAAMO,EAA0BC,EAAiE,CAC/F,IAAMrB,EAAS,KAAK,QAAQ,OACtBsB,EAAuB,CAAC,EAC1BtB,EAAO,SAAS,IAAI,YAAY,GAClCsB,EAAW,KAAK,aAAa,EAE/B,IAAMC,EAAeC,GAAmBH,CAA2B,EAC7DI,EAAWL,EAAY,gBAAgBG,CAAY,EACnDG,EAAO,GAAGJ,EAAW,KAAK;AAAA,CAAI,CAAC;AAAA,EAAKC,EAAa,yBAAyB;AAAA,EAAKE,CAAQ,GACvFE,EAAe3B,EAAO,mBAAmB,CAAC,KAAA0B,EAAM,MAAON,EAAY,IAAI,CAAC,EAC9EQ,GAAU,UAAW,IAAM,YAAYR,EAAY,IAAI,iBAAiBM,CAAI,EAAE,EAE9E,IAAMG,EAAkB7B,EAAO,sBAC3B,CAAC,QAAS,CAAC,OAAQ2B,EAAc,WAAY,MAAM,EAAG,OAAQ,OAAQ,MAAOP,EAAY,IAAI,CAAC,EAElG,MAAO,CAAC,YAAAA,EAAa,gBAAAS,CAAe,CACtC,CAEA,2BAA2B/B,EACE,CAC3B,IAAMgC,EAAI,OAAOhC,GAAkB,SAAWA,EAAgBA,EAAc,EACtEiC,EAAI,OAAOjC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEkC,EAAI,OAAOlC,GAAkB,SAAW,EAAKA,EAAc,GAAK,EAChEmC,EAAoB,KAAK,QAAQ,OAAO,OAAO,iCACrD,GAAIH,GAAKG,GAAqBF,GAAKE,GAAqBD,GAAKC,EAC3D,MAAO,CAACH,EAAGC,EAAGC,CAAC,EAEjB,IAAME,EAAOJ,EAAIC,EAAIC,EACjBG,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EAC/C,GAAIC,EAAkBF,EAAmB,CAEvC,GADAE,EAAkB,KAAK,KAAK,KAAK,KAAKD,CAAI,CAAC,EACvCC,EAAkBF,EACpB,MAAM,IAAI,MAAM,6CAA6C,EAE/D,MAAO,CAACE,EAAiBA,EAAiBA,CAAe,CAC3D,KACE,OAAO,CAACA,EAAiBA,EAAiB,CAAC,CAE/C,CACF,IC9JA,IAYMC,GA4CAC,GAqBOC,GA7EbC,GAAAC,EAAA,kBAKAC,KACAC,KACAC,KACAC,KACAC,KAGMT,GACF,CAACU,EAAqCC,IAA2E,CAC/G,GAAIA,EAAkB,SAAWD,EAAa,OAC5C,MAAM,IAAI,MAAM,4BAA4BC,EAAkB,MAAM,wCAChED,EAAa,MAAM,GAAG,EAG5B,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIH,EAAa,OAAQ,EAAEG,EAAG,CAC5C,IAAMC,EAAOJ,EAAaG,CAAC,EAAE,SAC7B,OAAQF,EAAkBE,CAAC,EAAG,CAC5B,IAAK,OAAQ,CACXD,EAAW,KAAK,EAAE,EAClB,KACF,CACA,IAAK,OAAQ,CACXA,EAAW,KAAK,GAAGE,CAAI,EAAE,EACzB,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAOL,EAAaG,CAAC,EAAE,KAAK,OAClCD,EAAW,KAAK,GAAGE,CAAI,IAAIC,CAAI,EAAE,EACjC,KACF,CACA,IAAK,OAAQ,CACX,IAAMC,EAAON,EAAaG,CAAC,EAAE,KAAK,KAAK,GAAG,EAC1CD,EAAW,KAAK,GAAGE,CAAI,IAAIE,CAAI,EAAE,EACjC,KACF,CACA,QACE,MAAM,IAAI,MAAM,iCAAiCL,EAAkBE,CAAC,CAAC,EAAE,CAC3E,CACF,CAEA,OAAOD,EAAW,KAAK,GAAG,CAC5B,EASEX,GACF,CAACgB,EAA0BP,EAAqCQ,IAA0C,CAGxG,IAAIC,EAAMF,EAAY,KACtB,OAAIA,EAAY,aAAa,OAC3BE,GAAO,IAAMF,EAAY,YAAY,KAAO,KAE9CE,GAAO,IAAMD,EACT,IACOlB,GACIU,EACAO,EAAY,aAAa,mBACrB,IAAI,MAAwCP,EAAa,MAAM,EAAE,KAAK,MAAM,CAAC,CAAC,GAC1FS,CACT,EAMSjB,GAAN,KAAoB,CAApB,cAiBL,qBAA+B,KAoC/B,KAAQ,eAAyC,KACjD,KAAQ,mBAAiD,KACzD,2BAAwB,EAIxB,mBAAgB,EAQhB,gCAA4E,IAAI,IAlChF,IAAI,yBAAoD,CACtD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,yEAAyE,EAG3F,IAAIkB,EAAO,KAAK,iBAAiB,IAAI,KAAK,eAAe,EACzD,OAAKA,IACHA,EAAO,CAAC,EACR,KAAK,iBAAiB,IAAI,KAAK,gBAAiBA,CAAI,GAG/CA,CACT,CAwBA,MAAM,WAAWC,EAAyB,CACxC,GAAI,CAAC,UAAU,IAEb,MAAM,IAAI,MAAM,yCAAyC,EAG3D,IAAMC,EAAU,MAAM,UAAU,IAAI,eAAe,EACnD,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,2CAA2C,EAG7D,KAAK,IAAMD,EACX,IAAME,EAAqC,CAAC,EACtCC,EAAwC,CAC5C,eAAgB,CACd,+BAAgCF,EAAQ,OAAO,+BAC/C,iCAAkCA,EAAQ,OAAO,iCACjD,4BAA6BA,EAAQ,OAAO,4BAC5C,cAAeA,EAAQ,OAAO,cAC9B,kCAAmCA,EAAQ,OAAO,kCAClD,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,yBACzC,yBAA0BA,EAAQ,OAAO,wBAC3C,EACA,iBAAAC,CACF,EAEID,EAAQ,SAAS,IAAI,iBAAiB,GACxCC,EAAiB,KAAK,iBAAiB,EAErCD,EAAQ,SAAS,IAAI,YAAY,GACnCC,EAAiB,KAAK,YAAY,EAGpC,KAAK,OAAS,MAAMD,EAAQ,cAAcE,CAAgB,EAC1D,KAAK,eAAiBC,GAAqB,IAAI,EAC/C,KAAK,eAAiB,IAAIC,GAAe,IAAI,EAC7C,KAAK,QAAU,IAAI,IACnB,KAAK,qBAAuB,IAAI,IAChC,KAAK,iBAAmB,IAAI,IAG5BC,GAAgBN,EAAI,SAAW,CAAC,CAACA,EAAI,KAAK,EAI1C,KAAK,OAAO,kBAAoBO,GAAM,CAChCA,EAAG,iBAAiB,oBAEtB,QAAQ,MAAM,mDAAmDA,EAAG,MAAM,OAAO,EAAE,CAEvF,EAEA,OAAO,eAAe,KAAK,IAAI,OAAQ,SAAU,CAAC,MAAO,KAAK,MAAM,CAAC,CACvE,CAEA,SAAgB,CACV,OAAO,KAAK,SAAa,KAC3B,KAAK,SAAS,QAAQ,EAExB,KAAK,eAAe,QAAQ,CAC9B,CAEA,mBAAuC,CACrC,OAAK,KAAK,iBACR,KAAK,eAAiB,KAAK,OAAO,qBAAqB,GAElD,KAAK,cACd,CAEA,uBAA+C,CAC7C,GAAI,CAAC,KAAK,mBAAoB,CAC5B,IAAMC,EAAkD,CAAC,EACrD,KAAK,eAAe,IAClB,OAAO,KAAK,SAAa,MAC3B,KAAK,SAAW,KAAK,OAAO,eAAe,CACzC,KAAM,YACN,MAAO,KAAK,aACd,CAAC,GAEHA,EAAsB,gBAAkB,CACtC,SAAU,KAAK,SACf,0BAA2B,EAC3B,oBAAqB,CACvB,GAGF,KAAK,mBAAqB,KAAK,kBAAkB,EAAE,iBAAiBA,CAAqB,CAC3F,CACA,OAAO,KAAK,kBACd,CAEA,gBAAuB,CACjB,KAAK,qBACP,KAAK,mBAAmB,IAAI,EAC5B,KAAK,mBAAqB,KAE9B,CAEA,OAAc,CACR,KAAK,iBACP,KAAK,eAAe,EACpB,KAAK,OAAO,MAAM,OAAO,CAAC,KAAK,kBAAkB,EAAE,OAAO,CAAC,CAAC,EAC5D,KAAK,eAAe,sBAAsB,EAC1C,KAAK,eAAiB,KACtB,KAAK,sBAAwB,EAEjC,CAEA,gBAA0B,CACxB,MAAI,QAAK,OAAO,SAAS,IAAI,iBAAiB,GAAK,KAAK,IAAI,OAAO,gBAAkB,UAKvF,CAaA,IAAIC,EAAsBC,EAAyCC,EAC/DC,EACAC,EAAmG,CAErG,IAAMC,EAAwB,CAAC,EAC/B,QAAStB,EAAI,EAAGA,EAAIkB,EAAiB,OAAQ,EAAElB,EAAG,CAChD,IAAMuB,EAAU,KAAK,eAAe,IAAIL,EAAiBlB,CAAC,EAAE,IAAI,EAChE,GAAI,CAACuB,EACH,MAAM,IAAI,MAAM,0BAA0BL,EAAiBlB,CAAC,EAAE,IAAI,EAAE,EAEtEsB,EAAWtB,CAAC,EAAIuB,CAClB,CAEA,GAAM,CAAC,QAAAC,EAAS,cAAAC,EAAe,gBAAAC,CAAe,EAAIT,EAAQ,WAAWC,CAAgB,EAG/ES,EAAyBR,EAAc,SAAW,EAAIK,EAAQ,IAAI,CAACI,EAAG5B,IAAMA,CAAC,EAAImB,EACvF,GAAIQ,EAAuB,SAAWH,EAAQ,OAC5C,MAAM,IAAI,MAAM,eAAeG,EAAuB,MAAM,qBAAqBH,EAAQ,MAAM,GAAG,EAIpG,IAAMK,EAAkC,CAAC,EACnCC,EAAyB,CAAC,EAChC,QAAS9B,EAAI,EAAGA,EAAIwB,EAAQ,OAAQ,EAAExB,EAAG,CAIvC,GAAI,CAAC,OAAO,UAAU2B,EAAuB3B,CAAC,CAAC,GAAK2B,EAAuB3B,CAAC,EAAI,IAC5E2B,EAAuB3B,CAAC,GAAKwB,EAAQ,OACvC,MAAM,IAAI,MAAM,yBAAyBG,EAAuB3B,CAAC,CAAC,EAAE,EAEtE,GAAI2B,EAAuB3B,CAAC,IAAM,GAChC,SAEF,IAAM+B,EAAcJ,EAAuB3B,CAAC,IAAM,GAC5CgC,EAAeL,EAAuB3B,CAAC,IAAM,GAC7CiC,EAAcF,GAAeC,EAC/BX,EAAyBG,EAAQxB,CAAC,EAAE,SAAUwB,EAAQxB,CAAC,EAAE,IAAI,EAC7DoB,EAAmBO,EAAuB3B,CAAC,EAAGwB,EAAQxB,CAAC,EAAE,SAAUwB,EAAQxB,CAAC,EAAE,IAAI,EAChFuB,EAAU,KAAK,eAAe,IAAIU,EAAW,IAAI,EACvD,GAAI,CAACV,EACH,MAAM,IAAI,MAAM,2BAA2BU,EAAW,IAAI,EAAE,EAK9D,GAHIF,GACF,KAAK,cAAc,KAAKR,CAAO,EAE7BS,EAAc,CAChB,IAAIE,EAAiB,KAAK,qBAAqB,IAAI,KAAK,eAAgB,EACnEA,IACHA,EAAiB,CAAC,EAClB,KAAK,qBAAqB,IAAI,KAAK,gBAAkBA,CAAc,GAErEA,EAAe,KAAKX,CAAO,CAC7B,CACAM,EAAkB,KAAKI,CAAU,EACjCH,EAAY,KAAKP,CAAO,CAC1B,CAMA,IAAIY,EACJ,GAAIT,EAAiB,CACnB,IAAIU,EAAgB,EAChBC,EAAY,EACVC,EAAoB,CAAC,EACvBC,EAAsB,EAC1Bb,EAAgB,QAAQc,GAAK,CAC3B,IAAMjC,GAAO,OAAOiC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACvD,GAAIjC,GAAK,SAAW,EAClB,OAGF,IAAIkC,GACJ,OAAQlC,GAAK,OAAQ,CACnB,IAAK,GACHkC,GAAgB,EAChB,MACF,IAAK,GACHA,GAAgB,EAChB,MACF,IAAK,GACHA,GAAgB,GAChB,MACF,IAAK,GACHA,GAAgB,GAChB,MACF,IAAK,GACHA,GAAgB,GAChB,MACF,IAAK,GACHA,GAAgB,GAChB,MACF,QACE,MAAM,IAAI,MAAM,4BAA4BlC,GAAK,MAAM,EAAE,CAC7D,EAEI8B,IAAc,GAAKA,IAAc,KACnCI,GAAgB,IAEdA,GAAgBF,IAClBA,EAAsBE,IAExBL,EAAgB,KAAK,KAAKA,EAAgBK,EAAa,EAAIA,GAC3DJ,EAAY9B,GAAK,OACjB+B,EAAQ,KAAKF,CAAa,EAC1BA,GAAiB7B,GAAK,OAAS,CACjC,CAAC,EAED6B,EAAgB,KAAK,KAAKA,EAAgBG,CAAmB,EAAIA,EACjE,IAAMG,EAAc,IAAI,YAAYN,CAAa,EACjDV,EAAgB,QAAQ,CAACc,EAAGxC,KAAM,CAChC,IAAM2C,GAASL,EAAQtC,EAAC,EAClBO,EAAO,OAAOiC,EAAE,MAAS,SAAW,CAACA,EAAE,IAAI,EAAIA,EAAE,KACnDA,EAAE,OAAS,QACb,IAAI,WAAWE,EAAaC,GAAQpC,EAAK,MAAM,EAAE,IAAIA,CAAI,EAChDiC,EAAE,OAAS,SACpB,IAAI,YAAYE,EAAaC,GAAQpC,EAAK,MAAM,EAAE,IAAIA,CAAI,EAE1D,IAAI,aAAamC,EAAaC,GAAQpC,EAAK,MAAM,EAAE,IAAIA,CAAI,CAE/D,CAAC,EAED,IAAMqC,EAEF,KAAK,eAAe,OAAOR,EAAe,eAAe,SAAW,eAAe,OAAO,EAC9F,KAAK,OAAO,MAAM,YAAYQ,EAAkB,OAAQ,EAAGF,EAAa,EAAGN,CAAa,EACxF,KAAK,eAAe,QAAQQ,EAAkB,EAAE,EAChDT,EAAuB,CAAC,OAAQ,EAAG,KAAMC,EAAe,OAAQQ,EAAkB,MAAM,CAC1F,CAEA,IAAMC,EAA0B,KAAK,eAAe,2BAA2BpB,CAAa,EACtFpB,EAAuBwC,EAAwB,CAAC,IAAM,GAAKA,EAAwB,CAAC,IAAM,EAE1FvC,EAAMlB,GAAwB6B,EAASC,EAAkBb,CAAoB,EAC/EyC,EAAW,KAAK,eAAe,YAAYxC,CAAG,EAClD,OAAKwC,IACHA,EAAW,KAAK,eAAe,MAAM7B,EAAS4B,CAAuB,EACrE,KAAK,eAAe,YAAYvC,EAAKwC,CAAQ,GAG/CC,GACI,OACA,IAAM,yBAAyB9B,EAAQ,IAAI,UAAUX,CAAG,UAAUuC,EAAwB,CAAC,CAAC,IACxFA,EAAwB,CAAC,CAAC,IAAIA,EAAwB,CAAC,CAAC,EAAE,EAClE,KAAK,eAAe,IAChBC,EAAU5B,EAAkBW,EAAmBP,EAAYQ,EAAae,EACxEV,CAAoB,EAEjBN,CACT,CAEA,OAAOmB,EAAmBzC,EAAwB,CAChD,KAAK,eAAe,OAAOyC,EAAWzC,CAAI,CAC5C,CAEA,OAAO0C,EAAaC,EAAmB,CACrC,KAAK,eAAe,OAAOD,EAAKC,CAAG,CACrC,CAEA,MAAM,SAASF,EAAmBG,EAAkD,CAGlF,MAAM,KAAK,eAAe,SAASH,EAAWG,CAAe,CAC/D,CAEA,MAAMC,EAAsB,CAC1B,OAAO,KAAK,eAAe,OAAOA,CAAI,EAAE,EAC1C,CAEA,KAAKC,EAAqB,CACxB,OAAO,KAAK,eAAe,QAAQA,CAAG,CACxC,CAEA,aAAaC,EAAgBC,EAAkBC,EAAoBC,EAAwB,CACzF,IAAMC,EAAKC,GAAwB,IAAIL,CAAM,EAC7C,GAAI,CAACI,EACH,MAAM,IAAI,MAAM,2BAA2BJ,CAAM,EAAE,EAGrD,KAAK,QAAQ,IAAIC,EAAU,CAACD,EAAQG,EAAUC,EAAG,CAAC,EAAG,CAACA,EAAG,CAAC,EAAGF,CAAS,CAAC,CAAC,CAC1E,CAEA,cAAcD,EAAwB,CACpC,IAAMrB,EAAiB,KAAK,qBAAqB,IAAIqB,CAAQ,EAC7D,GAAIrB,EAAgB,CAClB,QAAW3B,KAAQ2B,EACjB,KAAK,eAAe,QAAQ3B,EAAK,EAAE,EAErC,KAAK,qBAAqB,OAAOgD,CAAQ,CAC3C,CAEA,KAAK,iBAAiB,OAAOA,CAAQ,EACrC,KAAK,QAAQ,OAAOA,CAAQ,CAC9B,CAEA,cAAcA,EAAkBK,EAAyBC,EAA6C,CACpG,IAAMC,EAAS,KAAK,QAAQ,IAAIP,CAAQ,EACxC,GAAI,CAACO,EACH,MAAM,IAAI,MAAM,uBAAuBP,CAAQ,EAAE,EAEnD,GAAM,CAACD,EAAQG,EAAUM,EAAaC,CAAU,EAAIF,EACpD,GAAI,KAAK,kBAAoB,KAC3B,MAAM,IAAI,MAAM,YAAYR,CAAM,KAAKG,CAAQ,2CAA2C,EAE5F,KAAK,gBAAkBF,EAGnBS,EAAW,CAAC,IACdA,EAAW,CAAC,EAAIA,EAAW,CAAC,EAAEA,EAAW,CAAC,CAAC,EAC3CA,EAAW,CAAC,EAAI,QAGlBjB,GAAU,OAAQ,IAAM,kCAAkCO,CAAM,KAAKG,CAAQ,MAAM,EAEnF,IAAMQ,EAAgB,KAAK,IAAI,MAE/B,KAAK,cAAgB,CAAC,EACtB,GAAI,CACF,OAAIA,GACF,KAAK,OAAO,eAAe,YAAY,EAGzCF,EAAYH,EAASI,EAAW,CAAC,CAAC,EAC3B,CACT,OAASE,EAAG,CACV,OAAAL,EAAO,KAAK,QAAQ,QAAQ,qBAAqBP,CAAM,KAAKG,CAAQ,aAAaS,CAAC,EAAE,CAAC,EAC9E,CACT,QAAE,CACID,GACFJ,EAAO,KAAK,KAAK,OAAO,cAAc,EAAE,KACpCM,GAAOA,EAAM,qCAAqCb,CAAM,KAAKG,CAAQ,MAAMU,EAAI,OAAO,GAAK,IAAI,CAAC,EAGtG,QAAW5D,KAAQ,KAAK,cACtB,KAAK,eAAe,QAAQA,EAAK,EAAE,EAErC,KAAK,cAAgB,CAAC,EACtB,KAAK,gBAAkB,IACzB,CACF,CAGA,eAAe6D,EAAmBC,EAAeC,EAAmBlB,EAAsB,CACxF,IAAImB,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EACxEG,IACHA,EAA4B,IAAI,IAChC,KAAK,2BAA2B,IAAIH,EAAWG,CAAyB,GAG1E,IAAMC,EAAiBD,EAA0B,IAAIF,CAAK,EACpDI,EAAK,KAAK,eAAe,uBAAuBH,EAAQlB,EAAMoB,IAAiB,CAAC,CAAC,EACvF,OAAAD,EAA0B,IAAIF,EAAO,CAACI,EAAIH,CAAM,CAAC,EAC1CG,CACT,CACA,kBAAkBL,EAAyB,CACzC,IAAMG,EAA4B,KAAK,2BAA2B,IAAIH,CAAS,EAC3EG,IACFA,EAA0B,QAAQG,GAAc,KAAK,eAAe,yBAAyBA,EAAW,CAAC,CAAC,CAAC,EAC3G,KAAK,2BAA2B,OAAON,CAAS,EAEpD,CACA,UAAUpB,EAA8B,CACtC,IAAMzB,EAAU,KAAK,eAAe,IAAIyB,CAAS,EACjD,GAAI,CAACzB,EACH,MAAM,IAAI,MAAM,2BAA2ByB,CAAS,EAAE,EAExD,OAAOzB,EAAQ,MACjB,CACA,iBAAiBoD,EAAsBvB,EAAcnD,EAClB,CACjC,MAAO,UAAY,CACjB,IAAMM,EAAO,MAAMqE,GAAgB,KAAMD,EAAWvB,CAAI,EACxD,OAAOyB,GAAWtE,EAAK,OAAQN,CAAI,CACrC,CACF,CAEF,ICziBA,IAAA6E,GAAA,GAAAC,GAAAD,GAAA,UAAAE,KAAA,IAgBMC,GAuCAC,GA6EOF,GApIbG,GAAAC,EAAA,kBAMAC,KAEAC,KACAC,KAEAC,KAKMP,GAAN,MAAMQ,CAAqC,CACzC,YACYC,EAAuCC,EAAkCC,EACjEC,EAAyB,CADjC,YAAAH,EAAuC,cAAAC,EAAkC,UAAAC,EACjE,UAAAC,CAA0B,CAE9C,iBAAgC,CAC9B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMC,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,aACJ,IAAI,aAAa,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CAChG,CAEA,kBAAkC,CAChC,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,cACJ,IAAI,cAAc,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjG,CAEA,eAA4B,CAC1B,GAAI,KAAK,WAAa,EACpB,MAAM,IAAI,MAAM,mBAAmB,EAErC,IAAMA,EAAeC,EAAU,KAAK,KAAK,IAAI,EAC7C,OAAOD,IAAiB,EAAI,IAAI,WAAe,IAAI,WAAW,KAAK,OAAO,MAAM,OAAQ,KAAK,KAAMA,CAAY,CACjH,CAEA,QAAQE,EAAwC,CAC9C,GAAID,EAAU,KAAKC,CAAO,IAAMD,EAAU,KAAK,KAAK,IAAI,EACtD,MAAM,IAAI,MAAM,mBAAmB,EAErC,OAAO,IAAIN,EAAe,KAAK,OAAQ,KAAK,SAAU,KAAK,KAAMO,CAAO,CAC1E,CACF,EAEMd,GAAN,KAAmD,CAYjD,YAAoBQ,EAA+BO,EAAwBC,EAA2B,CAAlF,YAAAR,EAA+B,aAAAO,EAFnD,KAAQ,iBAAmB,EAC3B,KAAQ,eAAiB,EAEvB,IAAME,EAAUT,EAAO,QAGnBU,EAAaF,GAAqB,EACtC,KAAK,gBAAkBC,EAAQC,GAAW,EAC1C,IAAMC,EAAaF,EAAQC,GAAW,EACtC,KAAK,YAAcD,EAAQC,GAAW,EACtC,KAAK,iBAAmBD,EAAQC,GAAW,EAC3C,KAAK,eAAiBD,EAAQC,GAAW,EAEzC,IAAME,EAAuB,CAAC,EAC9B,QAASC,EAAI,EAAGA,EAAIF,EAAYE,IAAK,CACnC,IAAMZ,EAAWQ,EAAQC,GAAW,EAC9BR,EAAOO,EAAQC,GAAW,EAC1BI,EAAML,EAAQC,GAAW,EACzBP,EAAiB,CAAC,EACxB,QAASY,EAAI,EAAGA,EAAID,EAAKC,IACvBZ,EAAK,KAAKM,EAAQC,GAAW,CAAC,EAEhCE,EAAO,KAAK,IAAIrB,GAAeS,EAAQC,EAAUC,EAAMC,CAAI,CAAC,CAC9D,CACA,KAAK,OAASS,CAChB,CA/BA,IAAI,kBAA6C,CAC/C,OAAO,KAAK,QAAQ,uBACtB,CACA,IAAI,kBAA+B,CACjC,OAAO,KAAK,OAAO,OAAO,SAAS,KAAK,iBAAkB,KAAK,iBAAmB,KAAK,cAAc,CACvG,CA4BA,QAAQI,EAAsBC,EAAyE,CAErG,IAAMC,EACFD,GAAsB,QAAQ,IAAIJ,GAAK,OAAOA,GAAM,SAAW,KAAK,OAAOA,CAAC,EAAIA,CAAC,GAAK,KAAK,OAEzFM,EAAgBF,GAAsB,SAAW,CAAC,EAClDG,EAAqB,CAACC,EAAepB,EAAkBE,IACzD,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,OAAOoB,EAAOlB,CAAI,EAAGA,CAAI,EACtEmB,EAAwB,CAACrB,EAAkBE,IAAwC,CACvF,IAAMoB,EAAcC,GAAqBvB,CAAQ,EACjD,GAAI,CAACsB,EACH,MAAM,IAAI,MAAM,0BAA0BtB,CAAQ,EAAE,EAEtD,IAAMwB,EAAaF,EAAclB,EAAU,KAAKF,CAAI,EACpD,OAAO,IAAIZ,GAAe,KAAK,OAAQU,EAAU,KAAK,QAAQ,eAAe,OAAOwB,CAAU,EAAE,GAAItB,CAAI,CAC1G,EACA,OAAO,KAAK,QAAQ,IAAIa,EAASE,EAAcC,EAAeC,EAAoBE,CAAqB,CACzG,CAEA,OAAOD,EAAelB,EAAiC,CACrD,IAAMuB,EAAQ,KAAK,OAAO,UAAU,EACpC,GAAI,CACF,IAAMxB,EAAO,KAAK,OAAO,YAAY,EAAIC,EAAK,QAAU,CAAsB,EAC1EwB,EAASzB,GAAQ,EACrB,KAAK,OAAO,QAAQyB,GAAQ,EAAIxB,EAAK,OACrC,QAAS,EAAI,EAAG,EAAIA,EAAK,OAAQ,IAC/B,KAAK,OAAO,QAAQwB,GAAQ,EAAIxB,EAAK,CAAC,EAExC,OAAO,KAAK,OAAO,YAAY,KAAK,gBAAiBkB,EAAOnB,CAAI,CAClE,OAAS0B,EAAG,CACV,MAAM,IAAI,MACN,sCAAsCP,CAAK,gBAAgBlB,CAAI,8GAErDyB,CAAC,EAAE,CACnB,QAAE,CACA,KAAK,OAAO,aAAaF,CAAK,CAChC,CACF,CACF,EAEapC,GAAO,MAAMU,EAAuB6B,IAA4B,CAC3E,IAAMvC,EAAOU,EAAO,SACpB,GAAIV,GAAQ,UAAU,IAAK,CACzB,GAAI,CAACuC,EAAI,KAAK,KACZ,MAAM,IAAI,MACN,mGAAmG,EAEzG,IAAMtB,EAAU,IAAIuB,GACpB,MAAMvB,EAAQ,WAAWsB,CAAG,EAE5BvC,EAEIiB,EAGCwB,GAAiBxB,EAAQ,MAAMwB,CAAI,EAGnCC,GAAgBzB,EAAQ,KAAKyB,CAAG,EAGjC,CAACC,EAAaC,EAAaH,EAAcI,EAAc,KAAU,CAC/D,GAAIA,EACFC,GAAU,UAAW,IAAM,kCAAkCH,CAAG,SAASC,CAAG,UAAUH,CAAI,EAAE,EAC5FxB,EAAQ,OAAO0B,EAAKC,CAAG,MAClB,CACLE,GAAU,UAAW,IAAM,yCAAyCH,CAAG,eAAeC,CAAG,UAAUH,CAAI,EAAE,EACzG,IAAM7B,EAAOF,EAAO,OAAO,SAASiC,EAAKA,EAAMF,CAAI,EACnDxB,EAAQ,OAAO2B,EAAKhC,CAAI,CAC1B,CACF,EAGA,MAAMmC,EAAmBC,EAAoBP,IACxB,CACfK,GACI,UACA,IAAM,wCAAwCC,CAAS,gBAAgBC,CAAU,UAAUP,CAAI,EAAE,EAErG,MAAMxB,EAAQ,SAAS8B,EAAW,IAAMrC,EAAO,OAAO,SAASsC,EAAYA,EAAaP,CAAI,CAAC,CAC/F,EAGJ,CAACQ,EAAcC,EAAgBC,IAAuBlC,EAAQ,aAC1DgC,EAAMC,EAAQC,EACdZ,EAAI,OAASA,EAAI,OAAO,gBAAkB,UAAY7B,EAAO,aAAaA,EAAO,iBAAiBwC,CAAM,CAAC,EACnD,GAAGA,CAAM,EAAE,EAGpEA,GAAmBjC,EAAQ,cAAciC,CAAM,EAGhD,CAACA,EAAgBhC,EAA2BkC,EAAuBC,IAAwC,CACzGP,GACI,UACA,IAAM,mCAAmCM,CAAa,YAAYF,CAAM,uBACpEhC,CAAiB,EAAE,EAC3B,IAAMoC,EAAU,IAAIpD,GAAmBQ,EAAQO,EAASC,CAAiB,EACzE,OAAOD,EAAQ,cAAciC,EAAQI,EAASD,CAAM,CACtD,CAAC,CACP,CACF,ICjMA,IAYIE,GAOEC,GAoBAC,GAWOC,GA+CPC,GAEOC,GAMAC,GAgBAC,GA+FAC,GAMAC,GAoBAC,GAqEAC,GA6NAC,GAgBAC,GApiBbC,GAAAC,EAAA,kBAMAC,KACAC,KACAC,KACAC,KACAC,KAEIpB,GAAoB,GAOlBC,GAA8BoB,GAA4C,CAC9E,IAAMC,EAAOC,GAAY,EACnBC,EAAQF,EAAK,UAAU,EAC7B,GAAI,CACF,IAAMG,EAAaH,EAAK,WAAW,CAAC,EAEpC,OADkBA,EAAK,wBAAwBD,EAAeI,EAAYA,EAAa,CAAC,IACtE,GAChBC,GAAe,uCAAwC,EAElD,CAACJ,EAAK,OAAOG,EAAa,CAAC,EAAGH,EAAK,OAAOG,EAAa,EAAI,CAAC,CAAC,CACtE,QAAE,CACAH,EAAK,aAAaE,CAAK,CACzB,CACF,EAOMtB,GAAU,CAACyB,EAAoBC,IAA+B,CAChDL,GAAY,EAAE,SAASI,EAAYC,CAAY,IAC/C,GAChBF,GAAe,+BAAgC,CAEnD,EAMavB,GAAc,MAAM0B,GAA4B,CAE3D3B,GAAQ2B,EAAI,KAAK,WAAaC,GAAqBD,EAAI,QAAQ,CAAC,EAEhC,CAI9B,IAAME,EAAW,cAAuB,KACxC,MAAMA,EAASR,GAAY,EAAGM,CAAG,CACnC,CAEA7B,GAAoB,EACtB,EAkCMI,GAAiB,IAAI,IAEdC,GAAsB,IAAeL,GAMrCM,GAAyB0B,GAAwC,CAC5E,IAAMV,EAAOC,GAAY,EACnBU,EAAkBX,EAAK,QAAQU,EAAM,UAAU,EACrD,GAAIC,IAAoB,EACtB,MAAM,IAAI,MAAM,+DAA+DD,EAAM,UAAU,GAAG,EAEpG,OAAAV,EAAK,OAAO,IAAIU,EAAOC,CAAe,EAC/B,CAACA,EAAiBD,EAAM,UAAU,CAC3C,EAQazB,GACT,CAAC2B,EAAkCC,IAA2E,CAC5G,IAAMb,EAAOC,GAAY,EAErBF,EAAgB,EAChBe,EAAuB,EACvBC,EAAkB,EAClBC,EAAmB,CAAC,EAClBC,EAAwB,CAAC,EACzBC,EAAyB,CAAC,EAEhC,GAAI,CACF,CAACJ,EAAsBE,CAAM,EAAIG,GAAkBN,CAAO,EAE1Dd,EAAgBC,EAAK,kBAAkBY,EAAU,CAAC,EAAGA,EAAU,CAAC,EAAGE,CAAoB,EACnFf,IAAkB,GACpBK,GAAe,yBAA0B,EAG3C,GAAM,CAACgB,EAAYC,CAAW,EAAI1C,GAA2BoB,CAAa,EAEpEuB,EAAa,CAAC,EACdC,EAAc,CAAC,EACfC,EAAwE,CAAC,EAC/E,QAASC,EAAI,EAAGA,EAAIL,EAAYK,IAAK,CACnC,IAAMC,EAAO1B,EAAK,iBAAiBD,EAAe0B,CAAC,EAC/CC,IAAS,GACXtB,GAAe,0BAA2B,EAE5Ca,EAAsB,KAAKS,CAAI,EAC/BJ,EAAW,KAAKtB,EAAK,aAAa0B,CAAI,CAAC,CACzC,CACA,QAASD,EAAI,EAAGA,EAAIJ,EAAaI,IAAK,CACpC,IAAMC,EAAO1B,EAAK,kBAAkBD,EAAe0B,CAAC,EAChDC,IAAS,GACXtB,GAAe,2BAA4B,EAE7Cc,EAAuB,KAAKQ,CAAI,EAChC,IAAMC,EAAa3B,EAAK,aAAa0B,CAAI,EACzCH,EAAY,KAAKI,CAAU,EAEK,CAC9B,IAAMC,EAAW,OAAOf,GAAS,yBAA4B,SACzDA,EAAQ,wBACRA,GAAS,0BAA0Bc,CAAU,GAAK,MACtD,GAAIC,IAAa,OAASA,IAAa,cAAgBA,IAAa,aAClE,MAAM,IAAI,MAAM,4CAA4CA,CAAQ,GAAG,EAEzEJ,EAAyB,KAAKI,CAAQ,CACxC,CACF,CAGA,IAAIC,EAAoC,KACxC,OAAkCL,EAAyB,KAAKM,GAAKA,IAAM,YAAY,IACrFf,EAAkBf,EAAK,kBAAkBD,CAAa,EAClDgB,IAAoB,GACtBX,GAAe,0BAA2B,EAG5CyB,EAAe,CACb,OAAQd,EACR,yBAAAS,EACA,gCAAiCA,EAAyB,IAAIM,GAAKC,GAAyBD,CAAC,CAAC,CAChG,GAGFhD,GAAe,IAAIiB,EAAe,CAACA,EAAekB,EAAuBC,EAAwBW,CAAY,CAAC,EACvG,CAAC9B,EAAeuB,EAAYC,CAAW,CAChD,OAASS,EAAG,CACV,MAAAf,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EAEpDlB,IAAoB,GACtBf,EAAK,mBAAmBe,CAAe,EAGrChB,IAAkB,GACpBC,EAAK,mBAAmBD,CAAa,EAEjCiC,CACR,QAAE,CACAhC,EAAK,MAAMY,EAAU,CAAC,CAAC,EACnBE,IAAyB,GAC3Bd,EAAK,0BAA0Bc,CAAoB,EAErDE,EAAO,QAAQkB,GAASlC,EAAK,MAAMkC,CAAK,CAAC,CAC3C,CACF,EAOShD,GACT,CAACwB,EAAmBG,IAA2E,CAC7F,IAAMD,EAAmC5B,GAAsB0B,CAAK,EACpE,OAAOzB,GAAsB2B,EAAWC,CAAO,CACjD,EAES1B,GAAkBgD,GAA4B,CACzD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,+CAA+CD,CAAS,EAAE,EAE5E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEnFC,GACFrC,EAAK,mBAAmBqC,EAAe,MAAM,EAG/CrC,EAAK,wBAAwBmC,CAAS,EAEtClB,EAAsB,QAAQgB,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACvDf,EAAuB,QAAQe,GAAOjC,EAAK,SAASiC,CAAG,CAAC,EACxDjC,EAAK,mBAAmBD,CAAa,EACrCjB,GAAe,OAAOqD,CAAS,CACjC,EAEa/C,GACT,CAACkD,EAA6BC,EAAyBvB,EAAkBmB,EAAmBK,IAChF,CACN,GAAI,CAACF,EAAQ,CACXC,EAAc,KAAK,CAAC,EACpB,MACF,CAEA,IAAMvC,EAAOC,GAAY,EAEnBwC,EAAWH,EAAO,CAAC,EACnBI,EAAOJ,EAAO,CAAC,EACfV,EAAWU,EAAO,CAAC,EAErBK,EACAC,EAEJ,GAAIH,IAAa,UAAYb,IAAa,aACxC,MAAM,IAAI,MAAM,wCAAwC,EAG1D,GAAIA,IAAa,aAAc,CAC7B,IAAMiB,EAAYP,EAAO,CAAC,EAAE,UACtBQ,EAAqBC,GAAqBC,GAA2BP,CAAQ,CAAC,EACpFG,EAAiBF,EAAK,OAAO,CAACO,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAIJ,EACnDH,EAAU3C,EAAK,mBAAmBmC,EAAWK,EAAOK,EAAWD,CAAc,CAC/E,KAAO,CACL,IAAMO,EAAOb,EAAO,CAAC,EAErB,GAAI,MAAM,QAAQa,CAAI,EAAG,CAEvBP,EAAiB,EAAIO,EAAK,OAC1BR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB,IAAIS,EAAYT,EAAU,EAC1B,QAASlB,EAAI,EAAGA,EAAI0B,EAAK,OAAQ1B,IAAK,CACpC,GAAI,OAAO0B,EAAK1B,CAAC,GAAM,SACrB,MAAM,IAAI,UAAU,wBAAwBA,CAAC,kBAAkB,EAEjEzB,EAAK,QAAQoD,GAAW,EAAIC,GAAgBF,EAAK1B,CAAC,EAAGT,CAAM,CAC7D,CACF,MACE4B,EAAiBO,EAAK,WACtBR,EAAU3C,EAAK,QAAQ4C,CAAc,EACrC5B,EAAO,KAAK2B,CAAO,EACnB3C,EAAK,OAAO,IAAI,IAAI,WAAWmD,EAAK,OAAQA,EAAK,WAAYP,CAAc,EAAGD,CAAO,CAEzF,CAEA,IAAMzC,EAAQF,EAAK,UAAU,EACvBsD,EAAatD,EAAK,WAAW,EAAI0C,EAAK,MAAM,EAClD,GAAI,CACF,IAAIa,EAAWD,EAAa,EAC5BZ,EAAK,QAAQc,GAAKxD,EAAK,OAAOuD,GAAU,EAAIC,CAAC,EAC7C,IAAMlB,EAAStC,EAAK,iBAChBgD,GAA2BP,CAAQ,EAAGE,EAASC,EAAgBU,EAAYZ,EAAK,OAChFX,GAAyBH,CAAQ,CAAC,EAClCU,IAAW,GACblC,GAAe,iDAAiD+B,CAAS,WAAWK,CAAK,GAAG,EAE9FD,EAAc,KAAKD,CAAM,CAC3B,QAAE,CACAtC,EAAK,aAAaE,CAAK,CACzB,CACF,EAKKb,GAAM,MACf8C,EAAmBsB,EAAwBC,EAAgCC,EAC3EC,EAA2C/C,IAAoE,CACjH,IAAMb,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,6CAA6CD,CAAS,EAAE,EAE1E,GAAM,CAACpC,EAAekB,EAAuBC,EAAwBmB,CAAc,EAAID,EAEjFhB,EAAaqC,EAAa,OAC1BpC,EAAcsC,EAAc,OAE9BE,EAAmB,EACnBC,EAA6B,CAAC,EAE5BC,EAA+B,CAAC,EAChCC,EAAgC,CAAC,EACjCC,EAA8B,CAAC,EAE/BC,EAAiBlE,EAAK,UAAU,EAChCmE,EAAoBnE,EAAK,WAAWoB,EAAa,CAAC,EAClDgD,EAAmBpE,EAAK,WAAWoB,EAAa,CAAC,EACjDiD,EAAqBrE,EAAK,WAAWqB,EAAc,CAAC,EACpDiD,EAAoBtE,EAAK,WAAWqB,EAAc,CAAC,EAEzD,GAAI,CACF,CAACwC,EAAkBC,CAAgB,EAAIS,GAAc1D,CAAO,EAG5D,QAASY,EAAI,EAAGA,EAAIL,EAAYK,IAC9BrC,GAAyBsE,EAAajC,CAAC,EAAGsC,EAAoBE,EAAmB9B,EAAWsB,EAAahC,CAAC,CAAC,EAI7G,QAASA,EAAI,EAAGA,EAAIJ,EAAaI,IAC/BrC,GACIwE,EAAcnC,CAAC,EAAGuC,EAAqBC,EAAmB9B,EAAWf,EAAauC,EAAclC,CAAC,CAAC,EAGxG,IAAI+C,EAAmBL,EAAoB,EACvCM,GAAkBL,EAAmB,EACrCM,GAAoBL,EAAqB,EACzCM,EAAmBL,EAAoB,EAC3C,QAAS7C,EAAI,EAAGA,EAAIL,EAAYK,IAC9BzB,EAAK,QAAQwE,GAAkB,EAAIT,EAAmBtC,CAAC,EACvDzB,EAAK,QAAQyE,IAAiB,EAAIxD,EAAsBwC,EAAahC,CAAC,CAAC,EAEzE,QAASA,EAAI,EAAGA,EAAIJ,EAAaI,IAC/BzB,EAAK,QAAQ0E,IAAmB,EAAIV,EAAoBvC,CAAC,EACzDzB,EAAK,QAAQ2E,GAAkB,EAAIzD,EAAuByC,EAAclC,CAAC,CAAC,EAG5E,GAAkCY,EAAgB,CAChD,GAAM,CAAC,OAAAuC,EAAQ,yBAAApD,GAA0B,gCAAAqD,EAA+B,EAAIxC,EAE5E,GAAIpB,EAAsB,SAAWG,EACnC,MAAM,IAAI,MAAM,2BACZA,CAAU,4DAA4DH,EAAsB,MAAM,IAAI,EAI5G,QAASQ,GAAI,EAAGA,GAAIL,EAAYK,KAAK,CACnC,IAAMe,GAAQiB,EAAahC,EAAC,EACV,MAAMzB,EAAK,cAAc4E,EAAQ3D,EAAsBuB,EAAK,EAAGuB,EAAmBtC,EAAC,CAAC,IACpF,GAChBrB,GAAe,oBAAoBqB,EAAC,iBAAiBU,CAAS,GAAG,CAErE,CAGA,QAASV,GAAI,EAAGA,GAAIJ,EAAaI,KAAK,CACpC,IAAMe,GAAQmB,EAAclC,EAAC,EACZmC,EAAcnC,EAAC,IAAI,CAAC,EAIjBzB,EAAK,eAAe4E,EAAQ1D,EAAuBsB,EAAK,EAAGwB,EAAoBvC,EAAC,EAAG,CAAC,IACpF,GAChBrB,GAAe,mCAAmCqB,EAAC,iBAAiBU,CAAS,GAAG,EAK9EnC,EAAK,eAAe4E,EAAQ1D,EAAuBsB,EAAK,EAAG,EAAGqC,GAAgCrC,EAAK,CAAC,IACtF,GAChBpC,GAAe,qBAAqBqB,EAAC,QAAQD,GAAyBC,EAAC,CAAC,gBAAgBU,CAAS,GAAG,CAG1G,CACF,CAEA,IAAI2C,GAE8BzC,EAChCyC,GAAY,MAAM9E,EAAK,mBACnBD,EAAesC,EAAe,OAAQhB,EAAagD,EAAoBR,CAAgB,EAE3FiB,GAAY,MAAM9E,EAAK,QACnBD,EAAeqE,EAAkBD,EAAmB/C,EAAYkD,EAAmBjD,EACnFgD,EAAoBR,CAAgB,EAGtCiB,KAAc,GAChB1E,GAAe,0BAA0B,EAG3C,IAAM2E,GAA2B,CAAC,EAElC,QAAStD,EAAI,EAAGA,EAAIJ,EAAaI,IAAK,CACpC,IAAMa,GAAStC,EAAK,QAAQqE,EAAqB,EAAI5C,CAAC,EACtD,GAAIa,KAAW0B,EAAoBvC,CAAC,EAAG,CAErCsD,GAAO,KAAKnB,EAAcnC,CAAC,CAAE,EAC7B,QACF,CAEA,IAAMuD,GAA2BhF,EAAK,UAAU,EAE1CiF,GAAmBjF,EAAK,WAAW,EAAI,CAAC,EAE1CkF,GAAmB,GACnBC,GAA6BhF,GAAa,EAC9C,GAAI,CACgBH,EAAK,kBACnBsC,GAAQ2C,GAAkBA,GAAmB,EAAGA,GAAmB,EAAGA,GAAmB,EAAE,IAC7E,GAChB7E,GAAe,4CAA4CqB,CAAC,GAAG,EAEjE,IAAI2D,GAAkBH,GAAmB,EACnCxC,GAAWzC,EAAK,QAAQoF,IAAiB,EAC/CjF,GAAaH,EAAK,QAAQoF,IAAiB,EAC3C,IAAM9B,EAAatD,EAAK,QAAQoF,IAAiB,EAC3CC,GAAarF,EAAK,QAAQoF,IAAiB,EAC3C1C,GAAO,CAAC,EACd,QAASjB,GAAI,EAAGA,GAAI4D,GAAY5D,KAC9BiB,GAAK,KAAK1C,EAAK,QAAQsD,EAAa,EAAI7B,EAAC,CAAC,EAE5CzB,EAAK,SAASsD,CAAU,EAExB,IAAMgC,GAAO5C,GAAK,OAAO,CAACO,GAAGC,KAAMD,GAAIC,GAAG,CAAC,EAC3CiC,GAAOI,GAA2B9C,EAAQ,EAE1C,IAAM+C,GAAoBnD,GAAgB,yBAAyBsB,EAAclC,CAAC,CAAC,EAEnF,GAAI0D,KAAS,SAAU,CACrB,GAAIK,KAAsB,aACxB,MAAM,IAAI,MAAM,wCAAwC,EAE1D,IAAMC,GAAuB,CAAC,EAC1BrC,GAAYjD,GAAa,EAC7B,QAASsB,GAAI,EAAGA,GAAI6D,GAAM7D,KAAK,CAC7B,IAAMiE,GAAS1F,EAAK,QAAQoD,IAAW,EACjCuC,GAAiBlE,KAAM6D,GAAO,EAAI,OAAYtF,EAAK,QAAQoD,EAAS,EAAIsC,GAC9ED,GAAW,KAAKzF,EAAK,aAAa0F,GAAQC,EAAc,CAAC,CAC3D,CACAZ,GAAO,KAAK,CAACI,GAAMzC,GAAM+C,GAAY,KAAK,CAAC,CAC7C,SAGMD,KAAsB,cAAgBF,GAAO,EAAG,CAClD,IAAMzC,GAAY7C,EAAK,cAAcG,EAAU,EACzCyF,GAAc7C,GAAqBN,EAAQ,EACjD,GAAImD,KAAgB,QAAa,CAACC,GAAyBV,EAAI,EAC7D,MAAM,IAAI,MAAM,0BAA0BA,EAAI,EAAE,EAIlDD,GAAmB,GAEnBH,GAAO,KAAK,CACVI,GAAMzC,GAAM,CACV,UAAAG,GACA,SAAU7C,EAAK,qBAAqB6C,GAAWyC,GAAOM,GAAaT,EAAI,EACvE,QAAS,IAAM,CACbnF,EAAK,kBAAkBsC,EAAM,CAC/B,CACF,EACA,YACF,CAAC,CACH,KAAO,CACL,IAAMwD,GAAwBC,GAAkCZ,EAAI,EAC9DhC,GAAO,IAAI2C,GAAsBR,EAAI,EAC3C,IAAI,WAAWnC,GAAK,OAAQA,GAAK,WAAYA,GAAK,UAAU,EACvD,IAAInD,EAAK,OAAO,SAASG,GAAYA,GAAagD,GAAK,UAAU,CAAC,EACvE4B,GAAO,KAAK,CAACI,GAAMzC,GAAMS,GAAM,KAAK,CAAC,CACvC,CAEJ,QAAE,CACAnD,EAAK,aAAagF,EAAwB,EACtCG,KAAS,UAAYhF,IACvBH,EAAK,MAAMG,EAAU,EAElB+E,IACHlF,EAAK,kBAAkBsC,EAAM,CAEjC,CACF,CAEA,OAAID,GACFrC,EAAK,sBAAsBqC,EAAe,MAAM,EAG3C0C,EACT,QAAE,CACA/E,EAAK,aAAakE,CAAc,EAEhCH,EAAmB,QAAQiC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EACzDhC,EAAoB,QAAQgC,GAAKhG,EAAK,kBAAkBgG,CAAC,CAAC,EAC1D/B,EAAkB,QAAQgC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,EAExCpC,IAAqB,GACvB7D,EAAK,sBAAsB6D,CAAgB,EAE7CC,EAAiB,QAAQmC,GAAKjG,EAAK,MAAMiG,CAAC,CAAC,CAC7C,CACF,EAKa3G,GAAgB6C,GAA4B,CACvD,IAAMnC,EAAOC,GAAY,EACnBmC,EAAUtD,GAAe,IAAIqD,CAAS,EAC5C,GAAI,CAACC,EACH,MAAM,IAAI,MAAM,oBAAoB,EAEtC,IAAMrC,EAAgBqC,EAAQ,CAAC,EAGzB8D,EAAkBlG,EAAK,iBAAiBD,CAAa,EACvDmG,IAAoB,GACtB9F,GAAe,iCAAkC,EAEnDJ,EAAK,SAASkG,CAAe,CAC/B,EAEa3G,GAA8B4G,GAAsE,CAC/G,IAAMC,EAA6B,CAAC,EACpC,QAAW9D,KAAU6D,EAAS,CAC5B,IAAMhD,EAAOb,EAAO,CAAC,EACjB,CAAC,MAAM,QAAQa,CAAI,GAAK,WAAYA,GACtCiD,EAAQ,KAAKjD,EAAK,MAAM,CAE5B,CACA,OAAOiD,CACT,IC7iBA,IAAAC,GAAAC,GAAA,CAAAC,GAAAC,KAAA,CAAAA,GAAA,utmQCAA,IASMC,GACFC,GACAC,GACAC,GACAC,GAKAC,GACAC,GACEC,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GAEAC,GAMAC,GAwEAC,GAEOC,GA6CAC,GAaAC,GAaAC,GAcAC,GAkBAC,GAaAC,GAyBAC,GAaAC,GAtQbC,GAAAC,EAAA,kBAGAC,KAGAC,KACAC,KAEM9B,GAAU,IAAe,CAAC,CAAC+B,GAAI,KAAK,OAAS,OAAO,SAAa,IAEnE7B,GAAe,GACfC,GAAc,GACdC,GAAU,GAORG,GAAiF,CAAC,EAClFC,GAAuF,CAAC,EACxFC,GAA+E,CAAC,EAChFC,GAAyD,CAAC,EAC1DC,GAAsE,CAAC,EACvEC,GAAuD,CAAC,EACxDC,GAAiE,CAAC,EAElEC,GAAe,IAAY,CAC/B,GAAIZ,IAAgB,CAACC,IAAeC,IAAW,CAACH,GAC9C,MAAM,IAAI,MAAM,kBAAkB,CAEtC,EAEMc,GAAwBiB,GAA2C,CACvE,OAAQA,EAAG,KAAK,KAAM,CACpB,IAAK,YACH9B,GAAe,GACX8B,EAAG,KAAK,KACV5B,GAAU,GACVC,GAAkB,CAAC,EAAE2B,EAAG,KAAK,GAAG,IAEhC7B,GAAc,GACdE,GAAkB,CAAC,EAAE,GAEvB,MACF,IAAK,WACC2B,EAAG,KAAK,IACV1B,GAAiB,CAAC,EAAE0B,EAAG,KAAK,GAAG,EAE/B1B,GAAiB,CAAC,EAAE,EAEtB,MACF,IAAK,kBACC0B,EAAG,KAAK,IACVzB,GAA+B,MAAM,EAAG,CAAC,EAAEyB,EAAG,KAAK,GAAG,EAEtDzB,GAA+B,MAAM,EAAG,CAAC,EAAEyB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,kBACCA,EAAG,KAAK,IACVxB,GAA+B,MAAM,EAAG,CAAC,EAAEwB,EAAG,KAAK,GAAG,EAEtDxB,GAA+B,MAAM,EAAG,CAAC,EAAEwB,EAAG,KAAK,GAAI,EAEzD,MACF,IAAK,SACCA,EAAG,KAAK,IACVvB,GAAuB,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAG,EAE9CvB,GAAuB,MAAM,EAAG,CAAC,EAAEuB,EAAG,KAAK,GAAI,EAEjD,MACF,IAAK,UACCA,EAAG,KAAK,IACVtB,GAAwB,MAAM,EAAG,CAAC,EAAEsB,EAAG,KAAK,GAAG,EAE/CtB,GAAwB,MAAM,EAAG,CAAC,EAAE,EAEtC,MACF,IAAK,MACCsB,EAAG,KAAK,IACVrB,GAAa,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAG,EAEpCrB,GAAa,MAAM,EAAG,CAAC,EAAEqB,EAAG,KAAK,GAAI,EAEvC,MACF,IAAK,gBACCA,EAAG,KAAK,IACVpB,GAAsB,MAAM,EAAG,CAAC,EAAEoB,EAAG,KAAK,GAAG,EAE7CpB,GAAsB,MAAM,EAAG,CAAC,EAAE,EAEpC,MACF,IAAK,yBACCoB,EAAG,KAAK,IACVnB,GAA6B,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAG,EAEpDnB,GAA6B,MAAM,EAAG,CAAC,EAAEmB,EAAG,KAAK,GAAI,EAEvD,MACF,QACF,CACF,EAEMhB,GAAY,OAAO,SAAa,IAAe,UAAU,eAAqC,IAAM,OAE7FC,GAAgC,SAA0B,CACrE,GAAsCjB,GAAQ,EAAG,CAC/C,GAAIG,GACF,OAEF,GAAID,GACF,MAAM,IAAI,MAAM,0CAA4C,EAE9D,GAAIE,GACF,MAAM,IAAI,MAAM,uCAAyC,EAG3D,OAAAF,GAAe,GAGX6B,GAAI,KAAK,YAAc,QACrBf,IAAaA,GAAU,QAAQ,OAAO,IAAM,IAC9Ce,GAAI,KAAK,UAAYf,GAAU,OAAO,EAAG,CAAEA,GAAW,YAAY,GAAG,EAAI,CAAC,GAIvE,IAAI,QAAc,CAACiB,EAASC,IAAW,CAC5CjC,IAAa,UAAU,EAEvB,IAAMkC,EAAY,IAAI,gBAAgB,IAAI,KACtC,CAGE,IACF,EACA,CAAC,KAAM,iBAAiB,CAAC,CAAC,EAC9BlC,GAAc,IAAI,OAAOkC,EAAW,CAAC,KAAM,uBAAuB,CAAC,EACnElC,GAAY,QAAW+B,GAAmBE,EAAOF,CAAE,EACnD/B,GAAY,UAAYc,GACxB,IAAI,gBAAgBoB,CAAS,EAC7B9B,GAAoB,CAAC4B,EAASC,CAAM,EACpC,IAAME,EAA0B,CAAC,KAAM,YAAa,GAAKL,GAAI,IAAI,EACjE9B,GAAY,YAAYmC,CAAO,CACjC,CAAC,CAEH,KACE,QAAOC,GAAsBN,GAAI,IAAI,CAEzC,EAEab,GAAoB,MAAMa,GAA4B,CACjE,GAAsC/B,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5C5B,GAAmB,CAAC2B,EAASC,CAAM,EACnC,IAAME,EAA0B,CAAC,KAAM,WAAY,GAAKL,CAAG,EAC3D9B,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAED,MAAWE,GAAYP,CAAG,CAE9B,EAEaZ,GAAwB,MAAMoB,GACHvC,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAA+B,CAACmB,EAASC,IAAW,CAC7D3B,GAA+B,KAAK,CAAC0B,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,MAAAG,CAAK,CAAC,EACtEtC,GAAa,YAAYmC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,GAEWpB,GAAsBoB,CAAK,EAI9BnB,GAAwB,MAAMoB,EAAkCC,IAEjCzC,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAAqC,CAACmB,EAASC,IAAW,CACnE1B,GAA+B,KAAK,CAACyB,EAASC,CAAM,CAAC,EACrD,IAAME,EAA0B,CAAC,KAAM,kBAAmB,GAAK,CAAC,UAAAI,EAAW,QAAAC,CAAO,CAAC,EACnFxC,GAAa,YAAYmC,CAAO,CAClC,CAAC,GAEWhB,GAAsBoB,EAAWC,CAAO,EAI/CpB,GACT,MAAMkB,EAAmBE,IAAoF,CAC/G,GAAsCzC,GAAQ,EAAG,CAE/C,GAAIyC,GAAS,wBACX,MAAM,IAAI,MAAM,sEAAsE,EAExF,OAAA3B,GAAa,EACN,IAAI,QAAqC,CAACmB,EAASC,IAAW,CACnEzB,GAAuB,KAAK,CAACwB,EAASC,CAAM,CAAC,EAC7C,IAAME,EAA0B,CAAC,KAAM,SAAU,GAAK,CAAC,MAAAG,EAAO,QAAAE,CAAO,CAAC,EACtExC,GAAa,YAAYmC,EAAS,CAACG,EAAM,MAAM,CAAC,CAClD,CAAC,CACH,KACE,QAAYlB,GAAckB,EAAOE,CAAO,CAE5C,EAEanB,GAAiB,MAAMoB,GAAqC,CACvE,GAAsC1C,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5CxB,GAAwB,KAAK,CAACuB,EAASC,CAAM,CAAC,EAC9C,IAAME,EAA0B,CAAC,KAAM,UAAW,GAAKM,CAAS,EAChEzC,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAEId,GAAeoB,CAAS,CAEjC,EAEanB,GAAM,MACfmB,EAAmBC,EAAwBC,EAA0BC,EACrEC,EAAqCL,IAAoE,CAC3G,GAAsCzC,GAAQ,EAAG,CAE/C,GAAI4C,EAAO,KAAKG,GAAKA,EAAE,CAAC,IAAM,KAAK,EACjC,MAAM,IAAI,MAAM,iDAAiD,EAGnE,GAAID,EAAQ,KAAKC,GAAKA,CAAC,EACrB,MAAM,IAAI,MAAM,yDAAyD,EAE3E,OAAAjC,GAAa,EACN,IAAI,QAAsC,CAACmB,EAASC,IAAW,CACpEvB,GAAa,KAAK,CAACsB,EAASC,CAAM,CAAC,EACnC,IAAMc,EAAqBJ,EACrBR,EACF,CAAC,KAAM,MAAO,GAAK,CAAC,UAAAM,EAAW,aAAAC,EAAc,OAAQK,EAAoB,cAAAH,EAAe,QAAAJ,CAAO,CAAC,EACpGxC,GAAa,YAAYmC,EAAca,GAA2BD,CAAkB,CAAC,CACvF,CAAC,CACH,KACE,QAAYzB,GAAImB,EAAWC,EAAcC,EAAQC,EAAeC,EAASL,CAAO,CAEpF,EAEajB,GAAe,MAAMkB,GAAqC,CACrE,GAAsC1C,GAAQ,EAC5C,OAAAc,GAAa,EACN,IAAI,QAAc,CAACmB,EAASC,IAAW,CAC5CtB,GAAsB,KAAK,CAACqB,EAASC,CAAM,CAAC,EAC5C,IAAME,EAA0B,CAAC,KAAM,gBAAiB,GAAKM,CAAS,EACtEzC,GAAa,YAAYmC,CAAO,CAClC,CAAC,EAEIZ,GAAakB,CAAS,CAE/B,EAEajB,GAAsB,SACKzB,GAAQ,GAC5Cc,GAAa,EACN,IAAI,QAAiB,CAACmB,EAASC,IAAW,CAC/CrB,GAA6B,KAAK,CAACoB,EAASC,CAAM,CAAC,EACnD,IAAME,EAA0B,CAAC,KAAM,wBAAwB,EAC/DnC,GAAa,YAAYmC,CAAO,CAClC,CAAC,GAEWX,GAAoB,IC/QpC,IAUIyB,GAESC,GAWAC,GAiBAC,GAxCbC,GAAAC,EAAA,kBAIAC,KAGAC,KACAC,KAIaP,GAAuB,CAACQ,EAAgBC,IAA0C,CAC7F,OAAQD,EAAO,SAAU,CACvB,IAAK,MACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAMA,EAAO,KAAM,KAAK,EACtD,IAAK,aACH,MAAO,CAACA,EAAO,KAAMA,EAAO,KAAM,CAAC,UAAWA,EAAO,SAAS,EAAG,YAAY,EAC/E,QACE,MAAM,IAAI,MAAM,0BAA0BA,EAAO,QAAQ,QAAQC,EAAQ,CAAC,EAAE,CAChF,CACF,EAEaR,GAAwBO,GAAmC,CACtE,OAAQA,EAAO,CAAC,EAAG,CACjB,IAAK,MACH,OAAO,IAAIE,GAAOF,EAAO,CAAC,EAAGA,EAAO,CAAC,EAAGA,EAAO,CAAC,CAAC,EACnD,IAAK,aAAc,CACjB,IAAMG,EAAWH,EAAO,CAAC,EACzB,GAAI,CAACI,GAAyBD,CAAQ,EACpC,MAAM,IAAI,MAAM,4BAA4BA,CAAQ,+BAA+B,EAErF,GAAM,CAAC,UAAAE,EAAW,SAAAC,EAAU,QAAAC,CAAO,EAAIP,EAAO,CAAC,EAC/C,OAAOE,GAAO,cAAcG,EAAW,CAAC,SAAAF,EAAU,KAAMH,EAAO,CAAC,EAAG,SAAAM,EAAU,QAAAC,CAAO,CAAC,CACvF,CACA,QACE,MAAM,IAAI,MAAM,0BAA0BP,EAAO,CAAC,CAAC,EAAE,CACzD,CACF,EAEaN,GAAN,KAA8E,CAMnF,MAAM,sBAAsBc,EAA8C,CAGxE,IAAMC,EAAW,MAAM,MAAMD,CAAI,EACjC,GAAIC,EAAS,SAAW,IACtB,MAAM,IAAI,MAAM,yBAAyBD,CAAI,EAAE,EAEjD,IAAME,EAAc,MAAMD,EAAS,YAAY,EAC/C,OAAOE,GAAsB,IAAI,WAAWD,CAAW,CAAC,CAC1D,CAEA,MAAM,UAAUE,EAAiCC,EAA0D,CASzG,GARM,MAAMC,GAAoB,IACzBvB,KACHA,GAA+BwB,GAAkBC,EAAG,GAEtD,MAAMzB,GACNA,GAA+B,QAG7B,OAAOqB,GAAiB,SAC1B,GAAI,OAAO,QAAY,KAAe,QAAQ,UAAY,QAAQ,SAAS,KAAM,CAE/E,IAAMK,EAAQ,KAAM,SAASL,CAAY,EACzC,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMM,GAAcD,EAAOJ,CAAO,CAC1F,KAAO,CAGL,IAAMM,EAAmC,MAAM,KAAK,sBAAsBP,CAAY,EAEtF,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMQ,GAAsBD,EAAWN,CAAO,CACtG,KAEA,CAAC,KAAK,UAAW,KAAK,WAAY,KAAK,WAAW,EAAI,MAAMK,GAAcN,EAAcC,CAAO,CAEnG,CAEA,MAAM,SAAyB,CAC7B,OAAOQ,GAAe,KAAK,SAAS,CACtC,CAEA,MAAM,IAAIC,EAAiCC,EAAqCV,EACzC,CACrC,IAAMW,EAAuB,CAAC,EACxBC,EAAyB,CAAC,EAChC,OAAO,QAAQH,CAAK,EAAE,QAAQI,GAAO,CACnC,IAAMC,EAAOD,EAAI,CAAC,EACZ1B,EAAS0B,EAAI,CAAC,EACdE,EAAQ,KAAK,WAAW,QAAQD,CAAI,EAC1C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,kBAAkBD,CAAI,GAAG,EAE3CH,EAAW,KAAKxB,CAAM,EACtByB,EAAa,KAAKG,CAAK,CACzB,CAAC,EAED,IAAMC,EAAkC,CAAC,EACnCC,EAA0B,CAAC,EACjC,OAAO,QAAQP,CAAO,EAAE,QAAQG,GAAO,CACrC,IAAMC,EAAOD,EAAI,CAAC,EACZ1B,EAAS0B,EAAI,CAAC,EACdE,EAAQ,KAAK,YAAY,QAAQD,CAAI,EAC3C,GAAIC,IAAU,GACZ,MAAM,IAAI,MAAM,mBAAmBD,CAAI,GAAG,EAE5CE,EAAY,KAAK7B,CAAM,EACvB8B,EAAc,KAAKF,CAAK,CAC1B,CAAC,EAED,IAAMG,EACFP,EAAW,IAAI,CAACQ,EAAGC,IAAMzC,GAAqBwC,EAAG,IAAM,UAAU,KAAK,WAAWP,EAAaQ,CAAC,CAAC,CAAC,GAAG,CAAC,EACnGC,EAAUL,EAAY,IACxB,CAACG,EAAGC,IAAMD,EAAIxC,GAAqBwC,EAAG,IAAM,WAAW,KAAK,YAAYF,EAAcG,CAAC,CAAC,CAAC,GAAG,EAAI,IAAI,EAElGE,EAAU,MAAMC,GAAI,KAAK,UAAWX,EAAcM,EAAQD,EAAeI,EAASrB,CAAO,EAEzFwB,EAAuC,CAAC,EAC9C,QAASJ,EAAI,EAAGA,EAAIE,EAAQ,OAAQF,IAClCI,EAAU,KAAK,YAAYP,EAAcG,CAAC,CAAC,CAAC,EAAIJ,EAAYI,CAAC,GAAKxC,GAAqB0C,EAAQF,CAAC,CAAC,EAEnG,OAAOI,CACT,CAEA,gBAAuB,CAEvB,CAEA,cAAqB,CACdC,GAAa,KAAK,SAAS,CAClC,CACF,ICxIA,IAeaC,GAmBAC,GAlCbC,GAAAC,EAAA,kBAIAC,KAEAC,KACAC,KAQaN,GAAkB,IAAY,CAazC,IAZI,OAAOO,GAAI,KAAK,aAAgB,UAAYA,GAAI,KAAK,YAAc,KACrEA,GAAI,KAAK,YAAc,GAGrB,OAAOA,GAAI,KAAK,MAAS,YAC3BA,GAAI,KAAK,KAAO,IAGd,OAAOA,GAAI,KAAK,OAAU,YAC5BA,GAAI,KAAK,MAAQ,IAGf,OAAOA,GAAI,KAAK,YAAe,UAAY,CAAC,OAAO,UAAUA,GAAI,KAAK,UAAU,GAAKA,GAAI,KAAK,YAAc,EAAG,CACjH,IAAMC,EAAqB,OAAO,UAAc,IAAc,SAAK,EAAE,OAAS,UAAU,oBACxFD,GAAI,KAAK,WAAa,KAAK,IAAI,EAAG,KAAK,MAAMC,GAAsB,GAAK,CAAC,CAAC,CAC5E,CACF,EAEaP,GAAN,KAAuD,CAC5D,MAAM,MAAsB,CAE1BD,GAAgB,EAGhB,MAAMS,GAA8B,CACtC,CAKA,MAAM,8BAA8BC,EAAiCC,EAChC,CACnC,IAAMC,EAAU,IAAIC,GACpB,aAAMD,EAAQ,UAAUF,EAAcC,CAAO,EACtC,QAAQ,QAAQC,CAAO,CAChC,CACF,ICpDA,IAAAE,GAAA,GAAAC,GAAAD,GAAA,iBAAAE,KAAA,IAIaA,GAJbC,GAAAC,EAAA,kBAGAC,KACaH,GAAc,IAAII,KCI/BC,KACAA,KAGAA,KCNO,IAAMC,GAAU,SDIvB,IAAOC,GAAQC,GAUe,CAC5B,IAAMC,EAA4C,cAAoC,YAEpD,OAAO,UAAc,KAAe,UAAU,KAC9EC,GAAgB,SAAUD,EAAa,CAAC,EAE1CC,GAAgB,MAAOD,EAAa,EAAE,EACtCC,GAAgB,OAAQD,EAAa,EAAE,EAErCC,GAAgB,UAAWD,EAAa,CAAC,EACzCC,GAAgB,QAASD,EAAa,CAAC,CAE3C,CAEA,OAAO,eAAeE,GAAI,SAAU,MAAO,CAAC,MAAOC,GAAS,WAAY,EAAI,CAAC",
  "names": ["backends", "backendsSortedByPriority", "registerBackend", "resolveBackend", "init_backend_impl", "__esmMin", "name", "backend", "priority", "currentBackend", "i", "backendHints", "backendNames", "errors", "backendName", "backendInfo", "isInitializing", "e", "init_backend", "__esmMin", "init_backend_impl", "version", "init_version", "__esmMin", "logLevelValue", "env", "init_env_impl", "__esmMin", "init_version", "version", "value", "env", "init_env", "__esmMin", "init_env_impl", "tensorToDataURL", "tensorToImageData", "init_tensor_conversion_impl", "__esmMin", "tensor", "options", "canvas", "pixels2DContext", "width", "height", "inputformat", "norm", "normMean", "normBias", "stride", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "j", "R", "G", "B", "A", "image", "channels", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "bufferToTensor", "tensorFromImage", "tensorFromTexture", "tensorFromGpuBuffer", "tensorFromPinnedBuffer", "init_tensor_factory_impl", "__esmMin", "init_tensor_impl", "buffer", "options", "height", "width", "norm", "normMean", "normBias", "inputformat", "outputformat", "stride", "float32Data", "step", "rImagePointer", "gImagePointer", "bImagePointer", "aImagePointer", "rTensorPointer", "gTensorPointer", "bTensorPointer", "aTensorPointer", "i", "Tensor", "image", "isHTMLImageEle", "isImageDataEle", "isImageBitmap", "isString", "data", "bufferToTensorOptions", "canvas", "pixels2DContext", "tempCanvas", "resolve", "reject", "context", "newImage", "img", "texture", "download", "dispose", "dims", "gpuBuffer", "dataType", "type", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "isBigIntChecked", "checkBigInt", "init_tensor_impl_type_mapping", "__esmMin", "isBigInt64ArrayAvailable", "isBigUint64ArrayAvailable", "calculateSize", "tensorReshape", "init_tensor_utils_impl", "__esmMin", "init_tensor_impl", "dims", "size", "i", "dim", "tensor", "Tensor", "Tensor", "init_tensor_impl", "__esmMin", "init_tensor_conversion_impl", "init_tensor_factory_impl", "init_tensor_impl_type_mapping", "init_tensor_utils_impl", "arg0", "arg1", "arg2", "checkBigInt", "type", "dims", "expectedTypedArrayConstructor", "NUMERIC_TENSOR_TYPE_TO_TYPEDARRAY_MAP", "data", "maybeDims", "typedArrayConstructor", "firstElementType", "mappedType", "NUMERIC_TENSOR_TYPEDARRAY_TO_TYPE_MAP", "size", "calculateSize", "image", "options", "tensorFromImage", "texture", "tensorFromTexture", "gpuBuffer", "tensorFromGpuBuffer", "buffer", "tensorFromPinnedBuffer", "tensorToDataURL", "tensorToImageData", "releaseData", "tensorReshape", "Tensor", "init_tensor", "__esmMin", "init_tensor_impl", "InferenceSession", "init_inference_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_InferenceSession", "handler", "feeds", "arg1", "arg2", "fetches", "options", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "arg0", "arg3", "filePathOrUint8Array", "buffer", "byteOffset", "byteLength", "backendHints", "i", "resolveBackend", "InferenceSession", "init_inference_session", "__esmMin", "init_inference_session_impl", "init_onnx_value", "__esmMin", "noBackendErrMsg", "TrainingSession", "init_training_session_impl", "__esmMin", "init_backend_impl", "init_tensor", "_TrainingSession", "handler", "trainingOptions", "sessionOptions", "evalModel", "optimizerModel", "options", "backendHints", "i", "backend", "resolveBackend", "feeds", "arg1", "arg2", "fetches", "Tensor", "isFetchesEmpty", "name", "isFetches", "arg1Keys", "v", "results", "returnValue", "key", "result", "_array", "_trainableOnly", "TrainingSession", "init_training_session", "__esmMin", "init_training_session_impl", "esm_exports", "__export", "InferenceSession", "Tensor", "TrainingSession", "env", "registerBackend", "init_esm", "__esmMin", "init_backend", "init_env", "init_inference_session", "init_tensor", "init_onnx_value", "init_training_session", "fs_exports", "__export", "readFile", "init_fs", "__esmMin", "path_exports", "__export", "join", "init_path", "__esmMin", "require_ort_wasm_simd_jsep", "__commonJSMin", "exports", "module", "ortWasm", "_scriptDir", "moduleArg", "d", "aa", "k", "a", "b", "c", "e", "f", "h", "l", "n", "m", "q", "p", "u", "w", "t", "g", "r", "ba", "ca", "da", "x", "ea", "y", "fa", "z", "ha", "A", "B", "fs", "ia", "ja", "C", "D", "noExitRuntime", "E", "F", "G", "I", "J", "K", "L", "M", "N", "ka", "la", "ma", "O", "na", "oa", "pa", "qa", "P", "ra", "Q", "sa", "R", "ta", "ua", "va", "wa", "xa", "S", "ya", "T", "v", "za", "Aa", "Ba", "Ca", "Da", "Ea", "Fa", "Ga", "Ha", "U", "Ia", "Ja", "La", "Ka", "Ma", "Na", "Oa", "Ra", "Qa", "Sa", "Ta", "Ua", "Va", "Wa", "Pa", "H", "V", "Xa", "W", "X", "Ya", "Za", "$a", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "jb", "kb", "Y", "Z", "lb", "mb", "ob", "nb", "pb", "qb", "rb", "sb", "tb", "ub", "vb", "require_worker_threads", "__commonJSMin", "require_perf_hooks", "__commonJSMin", "os_exports", "__export", "cpus", "init_os", "__esmMin", "require_ort_wasm_simd_threaded_jsep", "__commonJSMin", "exports", "module", "ortWasmThreaded", "_scriptDir", "moduleArg", "e", "m", "q", "v", "x", "aa", "ba", "ca", "da", "ea", "y", "fa", "A", "ha", "ia", "ja", "ka", "la", "B", "ma", "na", "a", "b", "c", "d", "f", "g", "k", "l", "n", "p", "r", "u", "w", "C", "h", "t", "oa", "pa", "qa", "ra", "sa", "D", "E", "F", "G", "ta", "ua", "va", "wa", "fs", "xa", "ya", "za", "Aa", "Ba", "H", "I", "Ca", "J", "K", "L", "Da", "Ea", "Fa", "Ga", "Ha", "Ia", "Ja", "Ka", "La", "Ma", "Na", "Oa", "Pa", "Qa", "Ra", "Sa", "M", "z", "Ta", "Ua", "Va", "N", "O", "Wa", "Xa", "Ya", "P", "$a", "Za", "ab", "bb", "cb", "db", "eb", "fb", "gb", "hb", "ib", "jb", "kb", "lb", "mb", "nb", "ob", "pb", "qb", "rb", "sb", "tb", "ub", "vb", "wb", "xb", "yb", "zb", "Ab", "Bb", "Cb", "Db", "Eb", "Fb", "Q", "Gb", "Hb", "Ib", "R", "Jb", "S", "Kb", "Lb", "T", "Mb", "U", "V", "Nb", "Ob", "Pb", "Qb", "Rb", "Sb", "Tb", "Ub", "Vb", "Wb", "Xb", "Yb", "Zb", "ac", "$b", "bc", "cc", "dc", "fc", "ec", "W", "gc", "hc", "ic", "jc", "kc", "lc", "mc", "nc", "oc", "pc", "qc", "rc", "tc", "uc", "vc", "wc", "yc", "xc", "zc", "Ac", "Bc", "Dc", "Cc", "Ec", "Fc", "Gc", "Hc", "Ic", "Jc", "Kc", "Lc", "Mc", "Nc", "Oc", "Pc", "sc", "X", "Qc", "Rc", "Y", "Sc", "Z", "Tc", "Uc", "Vc", "Wc", "Xc", "Yc", "Zc", "$c", "ad", "bd", "cd", "dd", "ed", "gd", "hd", "jd", "ld", "kd", "md", "nd", "od", "pd", "require_ort_wasm_threaded_worker", "__commonJSMin", "exports", "module", "ortWasmFactory", "ortWasmFactoryThreaded", "wasm", "initialized", "initializing", "aborted", "isMultiThreadSupported", "isSimdSupported", "getWasmFileName", "initializeWebAssembly", "getInstance", "init_wasm_factory", "__esmMin", "useSimd", "useThreads", "flags", "timeout", "numThreads", "simd", "wasmPaths", "wasmPrefixOverride", "wasmFileName", "wasmPathOverride", "isTimeout", "tasks", "resolve", "reject", "factory", "config", "fileName", "scriptDirectory", "prefix", "scriptSourceCode", "module", "what", "allocWasmString", "iterateExtraOptions", "checkLastError", "init_wasm_utils", "__esmMin", "init_wasm_factory", "data", "allocs", "wasm", "getInstance", "dataLength", "dataOffset", "options", "prefix", "seen", "handler", "key", "value", "name", "message", "stack", "paramsOffset", "errorCode", "errorMessagePointer", "errorMessage", "setRunOptions", "init_run_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "options", "wasm", "getInstance", "runOptionsHandle", "allocs", "runOptions", "tagDataOffset", "allocWasmString", "checkLastError", "iterateExtraOptions", "key", "value", "keyDataOffset", "valueDataOffset", "e", "alloc", "getGraphOptimzationLevel", "getExecutionMode", "appendDefaultOptions", "setExecutionProviders", "setSessionOptions", "init_session_options", "__esmMin", "init_wasm_factory", "init_wasm_utils", "graphOptimizationLevel", "executionMode", "options", "session", "ep", "sessionOptionsHandle", "executionProviders", "allocs", "epName", "webnnOptions", "keyDataOffset", "allocWasmString", "valueDataOffset", "getInstance", "checkLastError", "numThreads", "webgpuOptions", "epNameDataOffset", "wasm", "sessionOptions", "logIdDataOffset", "logSeverityLevel", "logVerbosityLevel", "optimizedModelFilePathOffset", "name", "value", "nameOffset", "iterateExtraOptions", "key", "e", "alloc", "tensorDataTypeStringToEnum", "tensorDataTypeEnumToString", "getTensorElementSize", "tensorTypeToTypedArrayConstructor", "logLevelStringToEnum", "isGpuBufferSupportedType", "dataLocationStringToEnum", "init_wasm_common", "__esmMin", "type", "typeProto", "dateType", "logLevel", "location", "logLevelPrefix", "doLog", "configLogLevel", "debug", "configureLogger", "LOG", "LOG_DEBUG", "init_log", "__esmMin", "init_wasm_common", "level", "message", "$configLogLevel", "$debug", "logLevel", "msg", "messageLevel", "logLevelStringToEnum", "configLevel", "args", "createView", "init_tensor_view", "__esmMin", "init_wasm_common", "dataBuffer", "type", "tensorTypeToTypedArrayConstructor", "init_types", "__esmMin", "calcNormalizedBufferSize", "guid", "createNewGpuDataId", "downloadGpuData", "GpuDataManagerImpl", "createGpuDataManager", "init_gpu_data_manager", "__esmMin", "init_log", "init_types", "size", "backend", "gpuBuffer", "originalSize", "getTargetBuffer", "bufferSize", "gpuReadBuffer", "commandEncoder", "arrayBuffer", "targetBuffer", "id", "data", "srcArrayBuffer", "srcOffset", "srcLength", "gpuDataCache", "gpuBufferForUploading", "LOG_DEBUG", "sourceId", "destinationId", "sourceGpuDataCache", "destinationGpuDataCache", "buffer", "previousBuffer", "usage", "isStorage", "isUniform", "freeBuffers", "buffers", "gpuData", "cachedData", "storage", "args", "AttributeWithCacheKeyImpl", "createAttributeWithCacheKey", "init_attribute_with_cache_key", "__esmMin", "attribute", "name", "MatMulUtil", "BroadcastUtil", "ShapeUtil", "PoolConvUtil", "GemmUtil", "MIN_CLIP", "MAX_CLIP", "init_util", "__esmMin", "a", "b", "adims", "bdims", "isMatMul", "arank", "brank", "crank", "cdims", "cShapeMatMul", "i", "aLen", "bLen", "shape", "finalShape", "inputRank", "finalRank", "_ShapeUtil", "dims", "axis", "start", "end", "size", "rank", "strides", "tensorRank", "axes", "x", "perm", "v", "pad", "shape1", "shape2", "_PoolConvUtil", "isGlobalOperator", "inputDims", "kernelShape", "dilations", "pads", "dim", "isChannelLast", "autoPad", "outputDims", "filterDims", "inSize", "stride", "dilation", "kernel", "padHeadIndex", "padTailIndex", "dkernel", "padNeeded", "leftShape", "transLeft", "rightShape", "transRight", "biasShape", "M", "K", "N", "kDim", "WORKGROUP_SIZE", "getWgslMappedType", "tensorTypeToWsglStorageType", "createTensorShapeVariables", "getMaxComponents", "fillVector", "castToF32", "sumVector", "createIndicesHelper", "inputVariable", "outputVariable", "ShaderHelperImpl", "createShaderHelper", "getBroadcastDims", "enableShapesUniforms", "init_common", "__esmMin", "init_wasm_common", "init_util", "type", "components", "mappedType", "dims", "ShapeUtil", "size", "dataType", "value", "name", "tensorType", "shapeOrRank", "isInput", "useUniform", "rank", "rankIdentity", "indicesType", "valueType", "storageType", "normalizeDim", "dim", "implementationUsed", "uniformPrefix", "shape", "strides", "o2iSnippet", "i", "offsetToIndicesImplementation", "offsetToIndices", "varOffset", "offsets", "indicesToOffsetImplementation", "indicesToOffset", "varIndices", "indices", "init", "indicesGet", "idx", "indicesSet", "broadcastedIndicesToOffsetImplementation", "broadcastedIndicesToOffset", "output", "implKey", "setByOffset", "offset", "getByOffset", "getByIndicesImplementation", "getImplementation", "functionParams", "dimsParams", "get", "normalizedIndices", "getByIndices", "setByIndicesImplementation", "setImplementation", "impls", "impl", "indicesAndValue", "normalizedDispatchGroup", "workgroupSize", "workgroupSizeX", "workgroupSizeY", "workgroupSizeZ", "is1DimensionDispatch", "paramList", "globalIdxDefinition", "variable", "bindingIndex", "access", "variables", "v", "uniformSnippets", "dispatchGroup", "inShape", "outShape", "inRank", "a", "validateInputs", "getAdjustedPerm", "getOutputShape", "permFunctionBody", "createTransposeProgramInfo", "transpose", "parseTransposeAttributes", "init_transpose", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputRank", "perm", "inputShape", "ShapeUtil", "rank", "input", "output", "reverseFunc", "i", "inputTensor", "permAttr", "inputDataType", "useShapesUniforms", "enableShapesUniforms", "outputShape", "outShapeOrRank", "inShapeOrRank", "outputVariable", "inputVariable", "getShaderSource", "shaderHelper", "outputSize", "createTensorShapeVariables", "context", "attributes", "createAttributeWithCacheKey", "reduceOps", "reduceSharedOps", "reduceInitValues", "reduceOutputValues", "getInnerMostAxes", "computeOutAndReduceShapes", "expandShapeToKeepDim", "areAxesInnerMostDims", "getAxesPermutation", "createReduceSharedProgramInfo", "reduceCommon", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "init_reduce_shared", "__esmMin", "init_util", "init_common", "init_reduce", "init_transpose", "numInnerAxes", "rank", "res", "i", "shape", "axes", "outputShape", "dim", "reduceShape", "expandShape", "shapeIdx", "axis", "name", "shaderCache", "inputs", "reduceType", "outputDataType", "inputShape", "outputSize", "ShapeUtil", "reduceSize", "input", "inputVariable", "output", "outputVariable", "workgroupSize", "sharedMemorySnippet", "shaderHelper", "context", "attributes", "updatedAttributes", "createReduceAttributesFromInputs", "updatedAxes", "s", "normalizeAxes", "permutedAxes", "createTransposeProgramInfo", "finalOutputShape", "validateInputs", "noOp", "createReduceProgramInfo", "createReduceAttributesFromInputs", "runReduceProgram", "reduceLogSumNaive", "reduceL1Naive", "reduceL2Naive", "reduceLogSumExpNaive", "reduceMaxNaive", "reduceMeanNaive", "reduceMinNaive", "reduceProdNaive", "reduceSumNaive", "reduceSumSquareNaive", "useNaiveReduceMethod", "reduceMean", "reduceL1", "reduceL2", "reduceLogSumExp", "reduceMax", "reduceMin", "reduceProd", "reduceSum", "reduceSumSquare", "reduceLogSum", "parseReduceAttributes", "init_reduce", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "init_reduce_shared", "inputs", "input", "name", "shaderCache", "reduceOp", "axesInput", "outputDataType", "keepDims", "noopWithEmptyAxes", "outputShape", "inputShape", "axes", "ShapeUtil", "reduceOnAllAxes", "d", "i", "idxCopy", "inputVariable", "output", "outputVariable", "ops", "inputOffsetAssignment", "initinputOffsetLet", "initinputOffsetVar", "initinputOffset", "reduceOps", "k", "l", "outputSize", "shaderHelper", "attributes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "_output", "idxZero", "size", "shape", "reduceSize", "dim", "reduceMeanShared", "reduceL1Shared", "reduceL2Shared", "reduceLogSumExpShared", "reduceMaxShared", "reduceMinShared", "reduceProdShared", "reduceSumShared", "reduceSumSquareShared", "reduceLogSumShared", "validateInputs", "createArgMinMaxAttributesFromInputs", "argMin", "argMax", "parseArgMinMaxAttributes", "init_argminmax", "__esmMin", "init_wasm_common", "init_attribute_with_cache_key", "init_reduce", "inputs", "attributes", "createAttributeWithCacheKey", "context", "argMinMaxOp", "input", "output", "axes", "idxZero", "k", "updatedAttributes", "createReduceProgramInfo", "validateInputs", "createBiasAddProgramInfo", "biasAdd", "init_bias_add", "__esmMin", "init_util", "init_common", "inputs", "outputShape", "channels", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "bias", "residual", "output", "outputVariable", "shaderHelper", "context", "createElementwiseProgramShader", "createElementwiseProgramInfo", "abs", "acos", "acosh", "asin", "asinh", "atan", "atanh", "parseCastAttributes", "cast", "clipV10", "generateClipAttributesFromInputs", "clip", "ceil", "cos", "cosh", "parseAlphaAttributes", "elu", "erfImpl", "erf", "exp", "floor", "gelu", "leakyRelu", "not", "neg", "reciprocal", "relu", "sigmoid", "sin", "sinh", "sqrt", "tan", "tanh", "thresholdedRelu", "log", "init_unary_op", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "shaderHelper", "datasize", "inputDataType", "outputDataType", "funcCall", "additionalImplementation", "vecSize", "expression", "input", "inputVariable", "output", "outputVariable", "name", "cacheKey", "ShapeUtil", "inputTensors", "context", "attributes", "createAttributeWithCacheKey", "func", "dataType", "tensorTypeToWsglStorageType", "inputs", "min", "MIN_CLIP", "max", "MAX_CLIP", "a", "varType", "validateInputs", "createBiasSplitGeluProgramInfo", "biasSplitGelu", "init_bias_split_gelu", "__esmMin", "init_util", "init_common", "init_unary_op", "inputs", "outputShape", "input", "inputVariable", "bias", "output", "outputVariable", "outputSize", "ShapeUtil", "shaderHelper", "erfImpl", "context", "createBinaryOpProgramShader", "createBinaryOpProgramInfo", "runBinaryOp", "add", "div", "equal", "mul", "pow", "sub", "greater", "less", "greaterOrEqual", "lessOrEqual", "init_binary_op", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "dimsA", "dimsB", "dimsOutput", "vectorize", "doBroadcast", "funcCall", "typeA", "typeB", "typeOutput", "useShapesUniforms", "additionalImplementation", "expressionScalar", "expressionVector", "a", "b", "inputAShapeOrRank", "inputBShapeOrRank", "outputShapeOrRank", "output", "outputVariable", "inputVariable", "assignment", "isAOneElement", "ShapeUtil", "isBOneElement", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "name", "cacheKey", "outputDataType", "isBroadcast", "outputShape", "outputSize", "cacheKeyAux", "calculatedShape", "BroadcastUtil", "sharedDimension", "i", "dimA", "dimB", "enableShapesUniforms", "createTensorShapeVariables", "context", "type", "validateInputs", "calculateInputIndexImpl", "assignOutputData", "createConcatProgramInfo", "concat", "parseConcatAttributes", "init_concat", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "inputType", "inputDimensionality", "input", "numberOfTensors", "sizeInConcatAxisStr", "output", "codeLines", "i", "returnSnippet", "axis", "inputShape", "adjustedAxis", "outputShape", "dataNShape", "axisIndex", "outputSize", "ShapeUtil", "sizeInConcatAxis", "inputVars", "dataType", "previousSum", "inputDependencies", "inputShapeOrRanks", "enableInputShapesUniforms", "programUniforms", "enableShapesUniforms", "inputVariable", "createTensorShapeVariables", "enableOutputShapesUniforms", "outputShapeOrRank", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "attributes", "createAttributeWithCacheKey", "getActivationSnippet", "parseInternalActivationAttributes", "init_fuse_utils", "__esmMin", "init_util", "attributes", "valueType", "activation", "clipMin", "clipMax", "MIN_CLIP", "MAX_CLIP", "typeSnippet", "biasSnippet", "init_activation_util", "__esmMin", "component", "dataType", "hasBias", "utilFunctions", "init_conv_util", "__esmMin", "writeDataToSubAVec4Snippet", "calculateResultSnippet", "makeMatMulPackedVec4Source", "writeDataToSubASnippet", "readDataFromSubASnippet", "makeMatMulPackedSource", "matMulReadWriteFnSource", "createMatmulProgramInfo", "init_matmul_packed_webgpu", "__esmMin", "init_util", "init_common", "init_fuse_utils", "init_activation_util", "transpose", "batchDims", "transposeA", "innerElementSize", "workPerThread", "workgroupSize", "type", "tileInner", "splitK", "splitedDimInner", "tileAOuter", "tileBOuter", "tileAWidth", "tileAHight", "rowPerThreadB", "sequentialAccessByThreads", "rowPerThreadA", "colPerThreadA", "matmulSnippet", "component", "hasBias", "applyActivation", "variables", "batchShapes", "isChannelsLast", "batchAShape", "batchBShape", "batchShape", "batchVariable", "aVariable", "bVariable", "outputVariable", "broadCastADims", "getBroadcastDims", "broadCastBDims", "dataType", "tensorTypeToWsglStorageType", "getAIndices", "aRank", "batchRank", "resStr", "i", "j", "getBIndices", "bRank", "typeSnippet", "inputs", "activationAttributes", "outputShape", "reshapedOutputShape", "aShape", "bShape", "outerDimsA", "outerDimsB", "outerDims", "inputVariable", "batchSize", "ShapeUtil", "dimAOuter", "dimInner", "dimBOuter", "isVec4", "elementsPerThread", "dispatch", "components", "A", "B", "output", "inputVariables", "activationFunction", "getActivationSnippet", "declareFunctions", "biasComponents", "getShaderSource", "shaderHelper", "conv2dCommonSnippet", "createConv2DMatMulProgramInfo", "init_conv2d_mm_webgpu", "__esmMin", "init_log", "init_util", "init_common", "init_fuse_utils", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "fitAOuter", "fitBOuter", "fitInner", "addBias", "attributes", "innerElementSizeX", "innerElementSizeW", "innerElementSize", "dataType", "getXSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readXSnippet", "typeSnippet", "sampleX", "sampleW", "resType", "aType", "bType", "activationFunction", "applyActivation", "getActivationSnippet", "biasSnippet", "inputs", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileAOuter", "tileBOuter", "tileInner", "elementsSize", "t", "tensorTypeToWsglStorageType", "declareInputs", "declareFunctions", "utilFunctions", "ShapeUtil", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createGroupedConvProgramInfo", "init_conv_grouped", "__esmMin", "init_util", "init_common", "init_conv", "init_fuse_utils", "inputs", "attributes", "squeezeOutputShapeFunction", "hasBias", "processBias", "xShape", "wShape", "outputChannelsPerGroup", "isChannelLast", "outputShape", "calculateOutputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "activationFunction", "applyActivation", "getActivationSnippet", "inputVariable", "w", "inputVars", "getShaderSource", "shaderHelper", "calculateOutputShape", "weightTransposeAttribute", "validateInputs", "getAdjustedConvAttributes", "parseConvAttributes", "conv2d", "conv1d", "conv", "init_conv", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_conv2d_mm_webgpu", "init_matmul_packed_webgpu", "init_conv_grouped", "init_fuse_utils", "init_transpose", "inputShape", "kernelShape", "dilations", "adjustPads", "strides", "isChannelLast", "batchSize", "inputSpatialShape", "spatialRank", "outChannels", "dilatedKernelShape", "v", "i", "outputShape", "inputs", "attributes", "dataChannel", "filterInChannel", "pads", "PoolConvUtil", "newAttributes", "activationAttributes", "parseInternalActivationAttributes", "format", "autoPad", "group", "wIsConst", "createAttributeWithCacheKey", "context", "adjustedAttributes", "createGroupedConvProgramInfo", "isChannelsLast", "hasBias", "inputHeight", "inputWidth", "inputChannels", "weightHeight", "weightWidth", "outHeight", "outWidth", "sameSize", "batch", "xReshaped", "wReshaped", "matmulOutputShape", "matmulInputs", "transposedWeight", "createTransposeProgramInfo", "sharedDim", "createMatmulProgramInfo", "sequentialAccessByThreads", "convInputs", "dimAOuter", "dimBOuter", "dimInner", "createConv2DMatMulProgramInfo", "conv2dTransposeCommonSnippet", "createConv2DTransposeMatMulProgramInfo", "init_conv_backprop_mm_webgpu", "__esmMin", "init_log", "init_util", "init_fuse_utils", "init_activation_util", "init_conv_util", "init_matmul_packed_webgpu", "isChannelsLast", "addBias", "attributes", "innerElementSize", "type", "typeSnippet", "getWSnippet", "coordASnippet", "coordResSnippet", "xHeight", "xWidth", "row", "col", "readASnippet", "sampleA", "sampleW", "activationFunction", "applyActivation", "getActivationSnippet", "biasSnippet", "inputs", "outputShape", "dimAOuter", "dimBOuter", "dimInner", "hasBias", "sequentialAccessByThreads", "inChannels", "batchSize", "outWidth", "outHeight", "outChannels", "isVec4", "dispatchX", "dispatchY", "workGroupSize", "elementsPerThread", "dispatch", "LOG_DEBUG", "tileInner", "declareInputs", "declareFunctions", "utilFunctions", "ShapeUtil", "makeMatMulPackedVec4Source", "makeMatMulPackedSource", "createConvTranspose2DOpProgramShaderSource", "createConvTranspose2DProgramInfo", "init_conv_backprop_webgpu", "__esmMin", "init_log", "init_util", "init_common", "shaderHelper", "inputs", "attributes", "outputShape", "hasBias", "is1DimensionDispatch", "isVec4", "dataType", "isChannelsLast", "rowDim", "colDim", "channelDim", "outputSize", "ShapeUtil", "workPerThread", "group", "wShape", "inputChannelsPerGroup", "outputChannelsPerGroup", "declareFunctions", "components", "w", "inputVariable", "dy", "inputVariables", "output", "outputVariable", "codeSnippet4", "codeSnippet", "squeezeOutputShapeFunction", "dispatch", "LOG_DEBUG", "tensorTypeToWsglStorageType", "computeTotalPad", "distributePadding", "calculateOutputShapeAndPads", "getAdjustedConvTransposeAttributes", "parseConvTransposeAttributes", "validateInputs", "weightTransposePerm", "convTranspose2d", "convTranspose1d", "convTranspose", "init_conv_transpose", "__esmMin", "init_attribute_with_cache_key", "init_conv_backprop_mm_webgpu", "init_conv_backprop_webgpu", "init_fuse_utils", "init_transpose", "inDim", "stride", "adj", "kernel", "dilation", "outSize", "totalPad", "autoPad", "pads", "head", "tail", "smallPad", "inputShape", "kernelShape", "dilations", "group", "strides", "isChannelLast", "outputPadding", "outputShape", "spatialRank", "updateOutputShape", "i", "batchSize", "outChannels", "j", "inSize", "attributes", "inputs", "a", "b", "isChannelsLast", "newAttributes", "cacheKey", "activationAttributes", "parseInternalActivationAttributes", "format", "wIsConst", "createAttributeWithCacheKey", "dataChannel", "filterInChannel", "featureMaps", "context", "adjustedAttributes", "hasBias", "createConvTranspose2DProgramInfo", "outHeight", "outWidth", "weightHeight", "weightWidth", "inputChannels", "dimAOuter", "dimBOuter", "dimInner", "sequentialAccessByThreads", "transposedWeight", "createTransposeProgramInfo", "convTransposeInputs", "createConv2DTransposeMatMulProgramInfo", "symbolPattern", "termPattern", "termPatternOnly", "lhsPattern", "lhsPatternOnly", "EinsumTerm", "EinsumEquation", "createEinsumProgramInfo", "einsum", "parseEinsumAttributes", "init_einsum", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputIndex", "symbol", "index", "value", "inputs", "equation", "lhs", "rhs", "inputTerm", "dims", "einsumTerm", "sym", "info", "dimValue", "term", "isInput", "rank", "ellipsis", "ellipsisDims", "nextDim", "indexSymbols", "i", "ellipsisDimLength", "j", "einsumEquation", "dataType", "inputVars", "inputVariable", "outputShape", "outputSize", "ShapeUtil", "output", "outputVariable", "idxCopy", "rhsSymbols", "initProd", "initSum", "updateSum", "reduceOpsSetIndices", "reduceOpsLoopHeaders", "reduceOpsLoopFooters", "reduceOpCompute", "isReduceOpsWithoutLoop", "outputIndex", "indices", "reduceOps", "inputVar", "getShaderSource", "shaderHelper", "context", "attributes", "createAttributeWithCacheKey", "validateInputs", "getAdjustedShape", "calculateOutputShape", "createExpandProgramInfo", "expand", "init_expand", "__esmMin", "init_util", "init_common", "inputs", "inputShape", "shape", "shapeIndex", "inputShapeIndex", "shape1", "shape2", "diff", "i", "outputShape", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "context", "validateInputs", "createGatherProgramInfo", "parseGatherAttributes", "gather", "init_gather", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "indicesShape", "inputRank", "axis", "ShapeUtil", "outputShape", "axisDimLimit", "outputSize", "data", "inputVariable", "indices", "output", "outputVariable", "calcDataIndices", "indicesRank", "calcStr", "i", "j", "getShaderSource", "shaderHelper", "createAttributeWithCacheKey", "context", "validateInputs", "createGatherElementsProgramInfo", "parseGatherElementsAttributes", "gatherElements", "init_gather_elements", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "inputShape", "inputOutputDataType", "inputRank", "inputStrides", "ShapeUtil", "inputSize", "indicesShape", "indicesDataType", "indicesSize", "axis", "axisDimLimit", "outputShape", "outputSize", "input", "inputVariable", "indices", "output", "outputVariable", "getShaderSource", "shaderHelper", "i", "createAttributeWithCacheKey", "context", "validateInputs", "offsetC", "createGemmProgramInfo", "gemm", "parseGemmAttributes", "init_gemm", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "m", "n", "dims", "broadcastM", "broadcastN", "offset", "attributes", "aShape", "bShape", "M", "N", "K", "GemmUtil", "outputShape", "outputSize", "ShapeUtil", "line", "dataType", "tensorTypeToWsglStorageType", "calculateAlpha", "calculateC", "inputStorageBuffersDeclarations", "getShaderSource", "shaderHelper", "context", "createAttributeWithCacheKey", "metadata", "createInstanceNormProgramInfo", "computeMean", "createInstanceNormNHWCProgramInfo", "parseInstanceNormAttributes", "instanceNorm", "init_instance_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "xShape", "outputShape", "axis", "normCount", "ShapeUtil", "normSize", "C", "x", "inputVariable", "scale", "bias", "output", "outputVariable", "variables", "dataType", "workgroupSize", "getShaderSource", "shaderHelper", "context", "input", "n", "h", "c", "epsilon", "components", "getMaxComponents", "inputHelper", "scaleHelper", "biasHelper", "WG", "outputType", "sumCastType", "setOutputValue", "var1", "var2", "unitsOfWork", "wgSize", "getMeanShaderSource", "fillVector", "meanValues", "N", "H", "outputSize", "outputHelper", "tensorTypeToWsglStorageType", "scaleType", "scaleCastType", "channelScaleShift", "createAttributeWithCacheKey", "validateInputs", "createLayerNormProgramInfo", "parseLayerNormAttributes", "layerNorm", "init_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "outputCount", "xShape", "scale", "bias", "outputShape", "axis", "ShapeUtil", "normCount", "normSize", "scaleSize", "biasSize", "meanInvStdDevDim", "i", "components", "getMaxComponents", "dataType", "tensorTypeToWsglStorageType", "variables", "inputVariable", "outputVariable", "hasMeanDataOutput", "hasInvStdOutput", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "outputs", "createAttributeWithCacheKey", "context", "validateInputs", "matMul", "init_matmul", "__esmMin", "init_util", "init_matmul_packed_webgpu", "inputs", "context", "outputShape", "BroadcastUtil", "createMatmulProgramInfo", "validateInputs", "getPadConstant", "getPadReflect", "getPadEdge", "getPadWrap", "getPadSnippet", "generatePadCode", "createPadProgramInfo", "createPadAttributesFromInputs", "pad", "parsePadAttributes", "init_pad", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "validPads", "output", "outputDims", "inputDims", "inputStrides", "pads", "dataType", "constantValue", "inputRank", "block", "i", "attributes", "shaderHelper", "ShapeUtil", "outputSize", "outputVariable", "input", "inputVariable", "padSnippet", "outputShape", "bigInt64Pads", "value", "updatePads", "axes", "v", "createAttributeWithCacheKey", "context", "updatedAttributes", "mode", "validateInputs", "getAdjustedPoolAttributesAndOutputShape", "generatePoolingCode", "parsePoolCommonAttributes", "createAveragePoolProgramInfo", "parseAveragePoolAttributes", "averagePool", "globalPoolAttributes", "parseGlobalAveragePoolAttributes", "globalAveragePool", "createMaxPoolProgramInfo", "maxPool", "parseMaxPoolAttributes", "parseGlobalMaxPoolAttributes", "globalMaxPool", "init_pool", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "isGlobalOperator", "isChannelsLast", "inputShapeAsChannelFirst", "hasDilations", "kernelShape", "strides", "dilations", "pads", "PoolConvUtil", "outputShapeAsChannelFirst", "newAttributes", "outputShapeAsChannelLast", "shaderHelper", "x", "xShape", "outputShape", "op1", "op2", "start", "inputDims", "dataType", "rank", "outputSize", "ShapeUtil", "output", "outputVariable", "kw", "sw", "pwStart", "pwEnd", "dimIdxW", "codeW", "codeH", "codeHEnd", "kh", "sh", "phStart", "phEnd", "dimIdxH", "dimH", "kernelSize", "kernelStrides", "stridesRank", "padsRank", "hasPads", "sum", "cur", "padCode", "i", "name", "adjustedAttributes", "inputVariable", "countIncludePad", "attr", "createAttributeWithCacheKey", "context", "format", "storageOrder", "validateInputsContent", "createRangeProgramInfo", "range", "init_range", "__esmMin", "init_esm", "init_wasm_common", "init_common", "start", "limit", "delta", "sameStartLimit", "increasingRangeNegativeStep", "decreasingRangePositiveStep", "dataType", "numElements", "outputShape", "outputSize", "output", "outputVariable", "wgslType", "getShaderSource", "shaderHelper", "x", "context", "env", "validateScales", "updateScales", "validateInputs", "getOriginalCoordinateFromResizedCoordinate", "getNearestPixelFromOriginal", "updateRoI", "initOutputShape", "adjustOutputShape", "calculateOriginalIndicesFromOutputIndices", "calculateInputIndicesFromOutputIndices", "checkInputIndices", "bilinearInterpolation", "bicubicInterpolation", "createResizeProgramInfo", "getOpsetVersionFromCustomDataBuffer", "resize", "parseResizeAttributes", "init_resize", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "scales", "attributes", "value", "axes", "rank", "newScales", "index", "inputs", "opsetVersion", "sizes", "roi", "roiInputIndex", "scalesInputIndex", "sizesInputIndex", "coordinateTransferMode", "nearestMode", "roiTmp", "roiLocal", "v", "inputShape", "outputShape", "scaleInPolicy", "adjustedOutputShape", "i", "output", "input", "useExtrapolation", "extrapolationValue", "batchIdx", "heightIdx", "widthIdx", "channelIdx", "cubicCoeffA", "excludeOutside", "createCubicInterpolationFunction", "idx", "direction", "inputTensor", "scalesInput", "roiInput", "outputVariable", "inputVariable", "outputSize", "ShapeUtil", "noScale", "d", "getShaderSource", "shaderHelper", "context", "customDataBuffer", "antialias", "coordinateTransformMode", "keepAspectRatioPolicy", "mode", "createAttributeWithCacheKey", "validateInputs", "createSkipLayerNormProgramInfo", "skipLayerNorm", "parseSkipLayerNormAttributes", "init_skip_layer_norm", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "skip", "gamma", "hiddenSize", "sequenceLength", "beta", "bias", "attributes", "outputCount", "isTraining", "inputShape", "inputSize", "ShapeUtil", "outputShape", "outputSize", "meanInvStdDevDim", "hasBetaInput", "hasBiasInput", "hasMeanOutput", "hasInvStdDevOutput", "hasInputSkipBiasSumOutput", "components", "getMaxComponents", "variables", "inputVariable", "outputVariable", "dataType", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "fillVector", "castToF32", "sumVector", "outputs", "context", "epsilon", "createAttributeWithCacheKey", "validateInputs", "readInput", "createSliceAttributesFromInputs", "fixStartEndValues", "calculateInputIndicesImpl", "createSliceProgramInfo", "slice", "parseSliceAttributes", "init_slice", "__esmMin", "init_wasm_common", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "_", "idx", "input", "v", "starts", "ends", "axes", "createAttributeWithCacheKey", "value", "index", "inputShape", "steps", "newValue", "output", "outputShape", "inputSize", "ShapeUtil", "step", "start", "i", "end", "signs", "array", "numSteps", "newEnd", "newStart", "axis", "outputTensorInfo", "outputVariable", "inputVariable", "outputSize", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "validateInputs", "createSoftmaxProgramInfo", "softmax", "parseSoftmaxAttributes", "init_softmax", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "input", "attributes", "shape", "outputSize", "ShapeUtil", "WG", "axis", "cols", "rows", "components", "getMaxComponents", "packedCols", "maxVector", "name", "x", "inputVariable", "output", "outputVariable", "valueType", "threadMaxDecl", "tensorTypeToWsglStorageType", "getShaderSource", "shaderHelper", "sumVector", "context", "createAttributeWithCacheKey", "validateInputs", "createSplitAttributesFromInputs", "calculateOutputIndexImpl", "writeBufferDataImpl", "createSplitProgramInfo", "split", "parseSplitAttributes", "init_split", "__esmMin", "init_util", "init_attribute_with_cache_key", "init_common", "inputs", "attributes", "splitSizes", "numOutputs", "v", "createAttributeWithCacheKey", "numberOfTensors", "outputs", "codeLines", "i", "returnSnippet", "inputShape", "inputSize", "ShapeUtil", "dataType", "rank", "axis", "adjustedAxis", "input", "inputVariable", "sizeInConcatAxis", "outputsTensorInfo", "outputShapes", "previousSum", "outputShape", "outputVariable", "indicesAxis", "getShaderSource", "shaderHelper", "context", "updatedAttributes", "getRepeats", "validateInputs", "getOutputShape", "createTileProgramInfo", "tile", "init_tile", "__esmMin", "init_wasm_common", "init_util", "init_common", "repeatsTensorView", "inputs", "inputShape", "repeats", "outputShape", "i", "outputSize", "ShapeUtil", "dataType", "input", "inputVariable", "output", "outputVariable", "getShaderSource", "shaderHelper", "context", "createWhereOpProgramShader", "createWhereOpProgramInfo", "where", "init_where", "__esmMin", "init_wasm_common", "init_util", "init_common", "shaderHelper", "inputs", "dimsOutput", "isBroadcast", "typeOutput", "outputSize", "ShapeUtil", "vecSize", "output", "outputVariable", "a", "inputVariable", "b", "c", "assignment", "expression", "singleAssignment", "resStr", "x", "typeCast", "expressionA", "expressionB", "expressionC", "dimsA", "dimsB", "dimsC", "outputDataType", "outputShape", "calculatedShape", "BroadcastUtil", "context", "WEBGPU_OP_RESOLVE_RULES", "init_op_resolve_rules", "__esmMin", "init_argminmax", "init_bias_add", "init_bias_split_gelu", "init_binary_op", "init_concat", "init_conv", "init_conv_transpose", "init_einsum", "init_expand", "init_gather", "init_gather_elements", "init_gemm", "init_instance_norm", "init_layer_norm", "init_matmul", "init_pad", "init_pool", "init_range", "init_reduce", "init_resize", "init_skip_layer_norm", "init_slice", "init_softmax", "init_split", "init_tile", "init_transpose", "init_unary_op", "init_where", "abs", "acos", "acosh", "add", "argMax", "parseArgMinMaxAttributes", "argMin", "asin", "asinh", "atan", "atanh", "averagePool", "parseAveragePoolAttributes", "biasAdd", "biasSplitGelu", "cast", "parseCastAttributes", "ceil", "clipV10", "clip", "concat", "parseConcatAttributes", "conv", "parseConvAttributes", "convTranspose", "parseConvTransposeAttributes", "cos", "cosh", "div", "einsum", "parseEinsumAttributes", "elu", "parseAlphaAttributes", "equal", "erf", "exp", "expand", "floor", "gather", "parseGatherAttributes", "gatherElements", "parseGatherElementsAttributes", "gelu", "gemm", "parseGemmAttributes", "globalAveragePool", "parseGlobalAveragePoolAttributes", "globalMaxPool", "parseGlobalMaxPoolAttributes", "greater", "greaterOrEqual", "instanceNorm", "parseInstanceNormAttributes", "layerNorm", "parseLayerNormAttributes", "leakyRelu", "less", "lessOrEqual", "log", "matMul", "maxPool", "parseMaxPoolAttributes", "mul", "neg", "not", "pad", "parsePadAttributes", "pow", "range", "reciprocal", "reduceMin", "parseReduceAttributes", "reduceMean", "reduceMax", "reduceSum", "reduceProd", "reduceL1", "reduceL2", "reduceLogSum", "reduceLogSumExp", "reduceSumSquare", "relu", "resize", "parseResizeAttributes", "sigmoid", "sin", "sinh", "slice", "parseSliceAttributes", "skipLayerNorm", "parseSkipLayerNormAttributes", "split", "parseSplitAttributes", "sqrt", "softmax", "parseSoftmaxAttributes", "sub", "tan", "tanh", "thresholdedRelu", "tile", "transpose", "parseTransposeAttributes", "where", "ProgramManager", "init_program_manager", "__esmMin", "init_wasm_common", "init_log", "init_common", "backend", "key", "artifact", "buildArtifact", "inputTensorViews", "outputTensorViews", "inputs", "outputs", "dispatchGroup", "uniformBufferBinding", "device", "computePassEncoder", "entries", "input", "output", "bindGroup", "syncData", "kernelId", "kernelInfo", "kernelName", "mappedData", "startTimeU64", "endTimeU64", "startTime", "endTime", "inputShapes", "value", "i", "tensorDataTypeEnumToString", "outputShapes", "programInfo", "normalizedDispatchGroupSize", "extensions", "shaderHelper", "createShaderHelper", "userCode", "code", "shaderModule", "LOG_DEBUG", "computePipeline", "x", "y", "z", "limitPerDimension", "size", "dispatchAverage", "getProgramInputTensorInfoDependencyKey", "getProgramInfoUniqueKey", "WebGpuBackend", "init_backend_webgpu", "__esmMin", "init_log", "init_tensor_view", "init_gpu_data_manager", "init_op_resolve_rules", "init_program_manager", "inputTensors", "inputDependencies", "inputInfos", "i", "type", "rank", "dims", "programInfo", "is1DimensionDispatch", "key", "data", "env", "adapter", "requiredFeatures", "deviceDescriptor", "createGpuDataManager", "ProgramManager", "configureLogger", "ev", "computePassDescriptor", "program", "inputTensorViews", "outputIndices", "createKernelOutput", "createIntermediateOutput", "inputDatas", "gpuData", "outputs", "dispatchGroup", "programUniforms", "validatedOutputIndices", "_", "outputTensorViews", "outputDatas", "isTemporary", "isPersistent", "tensorView", "persistentData", "uniformBufferBinding", "currentOffset", "preLength", "offsets", "maxAlignmentOfField", "v", "baseAlignment", "arrayBuffer", "offset", "uniformBufferData", "normalizedDispatchGroup", "artifact", "LOG_DEBUG", "gpuDataId", "src", "dst", "getTargetBuffer", "size", "ptr", "opType", "kernelId", "attribute", "nodeName", "op", "WEBGPU_OP_RESOLVE_RULES", "context", "errors", "kernel", "kernelEntry", "attributes", "useErrorScope", "e", "err", "sessionId", "index", "buffer", "sessionInputOutputMapping", "previousBuffer", "id", "bufferInfo", "gpuBuffer", "downloadGpuData", "createView", "init_exports", "__export", "init", "TensorViewImpl", "ComputeContextImpl", "init_init", "__esmMin", "init_wasm_common", "init_backend_webgpu", "init_log", "init_util", "_TensorViewImpl", "module", "dataType", "data", "dims", "elementCount", "ShapeUtil", "newDims", "backend", "contextDataOffset", "heapU32", "dataIndex", "inputCount", "inputs", "i", "dim", "d", "program", "inputsOutputsMapping", "mappedInputs", "outputIndices", "createKernelOutput", "index", "createTemporaryOutput", "elementSize", "getTensorElementSize", "bufferSize", "stack", "offset", "e", "env", "WebGpuBackend", "size", "ptr", "src", "dst", "isSourceGpu", "LOG_DEBUG", "gpuDataId", "dataOffset", "name", "kernel", "attribute", "sessionHandle", "errors", "context", "ortEnvInitialized", "getSessionInputOutputCount", "initOrt", "initRuntime", "activeSessions", "isOrtEnvInitialized", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "prepareInputOutputTensor", "run", "endProfiling", "extractTransferableBuffers", "init_wasm_core_impl", "__esmMin", "init_run_options", "init_session_options", "init_wasm_common", "init_wasm_factory", "init_wasm_utils", "sessionHandle", "wasm", "getInstance", "stack", "dataOffset", "checkLastError", "numThreads", "loggingLevel", "env", "logLevelStringToEnum", "initJsep", "model", "modelDataOffset", "modelData", "options", "sessionOptionsHandle", "ioBindingHandle", "allocs", "inputNamesUTF8Encoded", "outputNamesUTF8Encoded", "setSessionOptions", "inputCount", "outputCount", "inputNames", "outputNames", "outputPreferredLocations", "i", "name", "nameString", "location", "bindingState", "l", "dataLocationStringToEnum", "e", "buf", "alloc", "sessionId", "session", "ioBindingState", "tensor", "tensorHandles", "index", "dataType", "dims", "rawData", "dataByteLength", "gpuBuffer", "elementSizeInBytes", "getTensorElementSize", "tensorDataTypeStringToEnum", "a", "b", "data", "dataIndex", "allocWasmString", "dimsOffset", "dimIndex", "d", "inputIndices", "inputTensors", "outputIndices", "outputTensors", "runOptionsHandle", "runOptionsAllocs", "inputTensorHandles", "outputTensorHandles", "inputOutputAllocs", "beforeRunStack", "inputValuesOffset", "inputNamesOffset", "outputValuesOffset", "outputNamesOffset", "setRunOptions", "inputValuesIndex", "inputNamesIndex", "outputValuesIndex", "outputNamesIndex", "handle", "outputPreferredLocationsEncoded", "errorCode", "output", "beforeGetTensorDataStack", "tensorDataOffset", "keepOutputTensor", "type", "tensorDataIndex", "dimsLength", "size", "tensorDataTypeEnumToString", "preferredLocation", "stringData", "offset", "maxBytesToRead", "elementSize", "isGpuBufferSupportedType", "typedArrayConstructor", "tensorTypeToTypedArrayConstructor", "v", "p", "profileFileName", "tensors", "buffers", "require_main", "__commonJSMin", "exports", "module", "isProxy", "proxyWorker", "initializing", "initialized", "aborted", "initWasmCallbacks", "initOrtCallbacks", "createSessionAllocateCallbacks", "createSessionFinalizeCallbacks", "createSessionCallbacks", "releaseSessionCallbacks", "runCallbacks", "endProfilingCallbacks", "isOrtEnvInitializedCallbacks", "ensureWorker", "onProxyWorkerMessage", "scriptSrc", "initializeWebAssemblyInstance", "initializeRuntime", "createSessionAllocate", "createSessionFinalize", "createSession", "releaseSession", "run", "endProfiling", "isOrtEnvInitialized", "init_proxy_wrapper", "__esmMin", "init_esm", "init_wasm_core_impl", "init_wasm_factory", "env", "ev", "resolve", "reject", "workerUrl", "message", "initializeWebAssembly", "initRuntime", "model", "modeldata", "options", "sessionId", "inputIndices", "inputs", "outputIndices", "outputs", "t", "serializableInputs", "extractTransferableBuffers", "runtimeInitializationPromise", "encodeTensorMetadata", "decodeTensorMetadata", "OnnxruntimeWebAssemblySessionHandler", "init_session_handler_inference", "__esmMin", "init_esm", "init_proxy_wrapper", "init_wasm_common", "tensor", "getName", "Tensor", "dataType", "isGpuBufferSupportedType", "gpuBuffer", "download", "dispose", "path", "response", "arrayBuffer", "createSessionAllocate", "pathOrBuffer", "options", "isOrtEnvInitialized", "initializeRuntime", "env", "model", "createSession", "modelData", "createSessionFinalize", "releaseSession", "feeds", "fetches", "inputArray", "inputIndices", "kvp", "name", "index", "outputArray", "outputIndices", "inputs", "t", "i", "outputs", "results", "run", "resultMap", "endProfiling", "initializeFlags", "OnnxruntimeWebAssemblyBackend", "init_backend_wasm", "__esmMin", "init_esm", "init_proxy_wrapper", "init_session_handler_inference", "env", "numCpuLogicalCores", "initializeWebAssemblyInstance", "pathOrBuffer", "options", "handler", "OnnxruntimeWebAssemblySessionHandler", "backend_wasm_inference_exports", "__export", "wasmBackend", "init_backend_wasm_inference", "__esmMin", "init_backend_wasm", "OnnxruntimeWebAssemblyBackend", "init_esm", "version", "lib_default", "esm_exports", "wasmBackend", "registerBackend", "env", "version"]
}
